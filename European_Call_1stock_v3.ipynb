{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "European_Call_nstock_auto.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NwN6aLFDnwiy",
        "TY_9g3tbdLiY",
        "JIa4c_aHz15a",
        "u2_89jOknwjH"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Erin/European_Call_1stock_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xk52L4czj5x"
      },
      "source": [
        "nstock = 1"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCR6hhw5Xq_R"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSxOZk3ls2XQ",
        "outputId": "a59bf888-d44a-4224-9c74-8bb1db11a2a5"
      },
      "source": [
        "!curl https://colab.chainer.org/install |sh -\n",
        "import cupy"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1580  100  1580    0     0  10128      0 --:--:-- --:--:-- --:--:-- 10128\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "+ set +ex\n",
            "Installation succeeded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwN6aLFDnwiy"
      },
      "source": [
        "### Deep Learning Barrier Option\n",
        "\n",
        "We used Numba and CuPy in the previous notebook to run Monte Carlo simulation to determine the price of the Asian Barrier option. A Monte Carlo simulation needs millions of paths to get an accurate answer which is computationally intensive. [Ryan et al (2018)](https://arxiv.org/abs/1809.02233) showed that a deep learning model can be trained to value derivatives. The deep learning model is accurate and very fast, capable of producing valuations a million times faster than traditional models. In the this notebook, we will use a fully connected network to learn the pricing mode of the Asian Barrier option. Monte Carlo simulation is used as pricing ground truth for the training. We use the same Asian Barrier Option model as last notebook with parameters listed as following:\n",
        "\n",
        "```\n",
        "T - Maturity (yrs.)\n",
        "S - Spot (usd)\n",
        "K - Strike (usd)\n",
        "sigma - Volatility (per.)\n",
        "r - Risk Free Rate (per.)\n",
        "mu - Stock Drift Rate (per.)\n",
        "B - Barrier (usd)\n",
        "```\n",
        "\n",
        "### Batched Data generation\n",
        "\n",
        "The dataset is an important part of the Deep learning training. We will modify the previous single Asian Barrier Option pricing code to handle a batch of Barrier Option pricing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHYrh4iYfP-n",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "###Test: Judy's new X code\n",
        "#N_STOCKS = 3"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy7qGwT0jv4A",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#X = cupy.array([])\n",
        "#for i in range(0,N_STOCKS):\n",
        "  #X =  cupy.concatenate((X,cupy.array([1,1]), cupy.random.rand(3),cupy.array([1])))\n",
        "#X = X.reshape(N_STOCKS,6)\n",
        "#X"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OHtAXC8hVae",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#X = X * ((cupy.array([200.0, 0, 200.0, 0.4, 0.2, 0.2] * N_STOCKS, dtype = cupy.float32)).reshape(N_STOCKS, 6))\n",
        "#X"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY_9g3tbdLiY"
      },
      "source": [
        "### Train(Erin Version)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBxT9Eida-c_"
      },
      "source": [
        "# ################################# TEST ########################################\n",
        "# %%writefile cupy_dataset.py\n",
        "\n",
        "# import numba\n",
        "# from numba import cuda\n",
        "# import random\n",
        "# import cupy\n",
        "# import numpy as np\n",
        "# import math\n",
        "# import time\n",
        "# import torch\n",
        "# cupy.cuda.set_allocator(None)\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# @cuda.jit\n",
        "# def batch_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_BATCH):\n",
        "#     # ii - overall thread index\n",
        "#     ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "#     stride = cuda.gridDim.x * cuda.blockDim.x\n",
        "#     tmp3 = math.sqrt(T/N_STEPS)\n",
        "#     for i in range(ii, N_PATHS * N_BATCH, stride):\n",
        "#         batch_id = i // N_PATHS\n",
        "#         path_id = i % N_PATHS\n",
        "#         tmp1 = mu[batch_id]*T/N_STEPS\n",
        "#         tmp2 = math.exp(-r[batch_id]*T)\n",
        "#         running_average = 0.0\n",
        "#         s_curr = S0[batch_id]\n",
        "#         for n in range(N_STEPS):\n",
        "#             s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH] # stock price\n",
        "#             running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average) # average of the path\n",
        "#             if i==0 and batch_id == 2:\n",
        "#                 print(s_curr)\n",
        "#             if running_average <= B[batch_id]: # if reach barrier, drop out the path\n",
        "#                 break\n",
        "#         payoff = running_average - K[batch_id] if running_average > K[batch_id] else 0\n",
        "#         d_s[i] = tmp2 * payoff\n",
        "\n",
        "# class NumbaOptionDataSet(object):\n",
        "    \n",
        "#     def __init__(self, max_len=10, number_path = 1000, batch=2, threads=512, seed=15, stocks=3):  # 3 stocks\n",
        "#         self.num = 0\n",
        "#         self.max_length = max_len\n",
        "#         self.N_PATHS = number_path\n",
        "#         self.N_STEPS = 365\n",
        "#         self.N_BATCH = batch\n",
        "#         self.N_STOCKS = stocks\n",
        "#         self.T = np.float32(1.0)\n",
        "#         self.output = cupy.zeros(self.N_STOCKS*self.N_PATHS, dtype=cupy.float32) \n",
        "#         self.number_of_blocks = (self.N_PATHS * self.N_STOCKS - 1) // threads + 1\n",
        "#         self.number_of_threads = threads\n",
        "#         cupy.random.seed(seed)\n",
        "        \n",
        "#     def __len__(self):\n",
        "#         return self.max_length\n",
        "        \n",
        "#     def __iter__(self):\n",
        "#         self.num = 0\n",
        "#         return self\n",
        "    \n",
        "#     def __next__(self):\n",
        "#         if self.num > self.max_length:\n",
        "#             raise StopIteration\n",
        "        \n",
        "#         Y = cupy.zeros(self.N_BATCH, dtype=cupy.float32)\n",
        "#         paras = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "#         for op in range(self.N_BATCH):\n",
        "          \n",
        "#           X = cupy.array([])\n",
        "#           K_rand = cupy.random.rand(1)[0]\n",
        "#           B_rand = cupy.random.rand(1)[0]\n",
        "#           r_rand = cupy.random.rand(1)[0]\n",
        "#           for i in range(0,self.N_STOCKS):\n",
        "#             X =  cupy.concatenate((X,cupy.array([K_rand,B_rand]), cupy.random.rand(3),cupy.array([r_rand]))) #[K,B,S0,sigma,mu,r], K B r are shared\n",
        "#           X = X.reshape(self.N_STOCKS,6)\n",
        "#           X = X * ((cupy.array([200.0, 0.1, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6))\n",
        "#           #X = cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)\n",
        "#           #X = 0.9 + cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)*0.1\n",
        "#           # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "#           #X = (X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6)\n",
        "\n",
        "#           # make sure the Barrier is smaller than the Strike price\n",
        "#           # X[:, 1] = X[:, 0] * X[:, 1]\n",
        "#           for i in range(self.N_STOCKS):\n",
        "#             paras[op,i*6:(i+1)*6] = X[i,:]\n",
        "\n",
        "#           stocks_randoms_mean = cupy.zeros(self.N_STOCKS, dtype = cupy.float32)\n",
        "#           rho = cupy.random.normal(0, 1, self.N_STOCKS, dtype = cupy.float32)\n",
        "\n",
        "#           #stocks_randoms_cov = cupy.ones((self.N_STOCKS, self.N_STOCKS), dtype = cupy.float32)\n",
        "#           #cupy.fill_diagonal(stocks_randoms_cov, rho)\n",
        "\n",
        "#           #stocks_randoms_cov = (-0.99 + cupy.random.rand(self.N_STOCKS*self.N_STOCKS, dtype=cupy.float32)*2*0.99).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "#           stocks_randoms_cov = cupy.array([1] * self.N_STOCKS*self.N_STOCKS, dtype = cupy.float32).reshape(self.N_STOCKS,self.N_STOCKS)  #Covariance\n",
        "#           cupy.fill_diagonal(stocks_randoms_cov, 1)\n",
        "\n",
        "#           num_of_randoms_each_stock = self.N_PATHS * self.N_STEPS\n",
        "#           randoms_gpu = cupy.random.multivariate_normal(stocks_randoms_mean, stocks_randoms_cov,\n",
        "#                                                         num_of_randoms_each_stock, dtype=cupy.float32)\n",
        "#           b1_r = randoms_gpu[:,0]\n",
        "#           b2_r = randoms_gpu[:,1]\n",
        "#           randoms = cupy.zeros(self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "#           interval = int((self.N_PATHS * self.N_STEPS * self.N_STOCKS) / self.N_PATHS)\n",
        "#           for i in range(interval):\n",
        "#             if i % 2 == 0:\n",
        "#                 ind = int(i/2)\n",
        "#                 randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b1_r[ind:(ind+self.N_PATHS)]\n",
        "#             else:\n",
        "#                 ind = int(i//2)\n",
        "#                 randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b2_r[ind:(ind+self.N_PATHS)]\n",
        "\n",
        "#           randoms = cupy.random.normal(0, 1, self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "#           batch_barrier_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, self.T, X[:, 0], \n",
        "#                                 X[:, 1], X[:, 2], X[:, 3], X[:, 4], X[:, 5], randoms, self.N_STEPS, self.N_PATHS, self.N_STOCKS)\n",
        "          \n",
        "#           o = self.output.reshape(self.N_STOCKS, self.N_PATHS)\n",
        "#           Y[op] = o.mean(axis = 0).mean()\n",
        "\n",
        "#         self.num += 1\n",
        "#         return (from_dlpack(paras.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "\n",
        "# # ds = NumbaOptionDataSet(10, number_path=100000, batch=3, seed=random.randint(0,100), stocks=5)\n",
        "# # for i in ds:\n",
        "# #     print(i[0])\n",
        "# ################################# TEST ########################################"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6dZnWTTfbf1"
      },
      "source": [
        "### Train (European Call option)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeREuPw0fguQ",
        "outputId": "0ac36a9d-7a8d-457f-c692-9ae073a3ce6b"
      },
      "source": [
        "################################# TEST ########################################\n",
        "%%writefile cupy_dataset.py\n",
        "\n",
        "import numba\n",
        "from numba import cuda\n",
        "import random\n",
        "import cupy\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "cupy.cuda.set_allocator(None)\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "@cuda.jit\n",
        "def European_call_option(d_s, T, K, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_BATCH):\n",
        "    # ii - overall thread index\n",
        "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
        "    #tmp3 = math.sqrt(T/N_STEPS)\n",
        "    for i in range(ii, N_PATHS * N_BATCH, stride):\n",
        "        batch_id = i // N_PATHS\n",
        "        path_id = i % N_PATHS\n",
        "        h = T[batch_id] / N_STEPS\n",
        "        tmp1 = r[batch_id]*T[batch_id]/N_STEPS \n",
        "        tmp2 = math.exp(-r[batch_id]*T[batch_id]) # discount\n",
        "        tmp3 = math.sqrt(T[batch_id]/N_STEPS)\n",
        "        #running_average = 0.0\n",
        "        s_curr = S0[batch_id]\n",
        "        for n in range(N_STEPS):\n",
        "          s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH] # stock price\n",
        "          #s_curr = s_curr * math.exp((r[batch_id] - (1/2)*sigma[batch_id]**2)*h + sigma[batch_id] * tmp3 * d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH])\n",
        "          #running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average) # average of the path\n",
        "          #if i==0 and batch_id == 2:\n",
        "          #    print(s_curr)\n",
        "          #if running_average <= B[batch_id]: # if reach barrier, drop out the path\n",
        "          #    break\n",
        "        #payoff = running_average - K[batch_id] if running_average > K[batch_id] else 0\n",
        "        #payoff = s_curr - K[batch_id] if s_curr > K[batch_id] else 0\n",
        "        #d_s[i] = tmp2 * payoff\n",
        "        d_s[i] = s_curr\n",
        "\n",
        "class NumbaOptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len=10, number_path = 1000, batch=2, threads=512, seed=15, stocks=3):  # 3 stocks\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        #self.N_STEPS = 365\n",
        "        self.N_STEPS = 10000\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        #self.T = np.float32(1.0)\n",
        "        self.output = cupy.zeros(self.N_STOCKS*self.N_PATHS, dtype=cupy.float32)\n",
        "        self.number_of_blocks = (self.N_PATHS * self.N_STOCKS - 1) // threads + 1\n",
        "        self.number_of_threads = threads\n",
        "        cupy.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num > self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros(self.N_BATCH, dtype=cupy.float32)\n",
        "        paras = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "        #paras = cupy.zeros((self.N_BATCH, self.N_STOCKS * 5), dtype = cupy.float32)\n",
        "\n",
        "        for op in range(self.N_BATCH):\n",
        "          \n",
        "          X = cupy.array([])\n",
        "          #T_rand = cupy.random.rand(1)[0]\n",
        "          K_rand = cupy.random.rand(1)\n",
        "          #B_rand = cupy.random.rand(1)[0]\n",
        "          r_rand = cupy.random.rand(1)\n",
        "          for i in range(0, self.N_STOCKS):\n",
        "            #X =  cupy.concatenate((X, cupy.array([K_rand,B_rand]), cupy.random.rand(3), cupy.array([r_rand]))) #[K,B,S0,sigma,mu,r], K B r are shared\n",
        "            X = cupy.concatenate((X, cupy.array([1.0]), K_rand, cupy.random.rand(3), r_rand))\n",
        "          \n",
        "          X = X.reshape(self.N_STOCKS, 6)\n",
        "          #X = X * ((cupy.array([200.0, 0.1, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6))\n",
        "          #[T, K, S0, sigma, mu, r]\n",
        "          X = X * ((cupy.array([1, 150.0, 150.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6))\n",
        "          #X = cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)\n",
        "          #X = 0.9 + cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)*0.1\n",
        "          # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "          #X = (X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6)\n",
        "\n",
        "          # make sure the Barrier is smaller than the Strike price\n",
        "          # X[:, 1] = X[:, 0] * X[:, 1]\n",
        "          for i in range(self.N_STOCKS):\n",
        "            paras[op,i*6:(i+1)*6] = X[i,:]\n",
        "            #paras[op, i*5:(i+1)*5] = X[i,:]\n",
        "\n",
        "          stocks_randoms_mean = cupy.zeros(self.N_STOCKS, dtype = cupy.float32)\n",
        "          rho = cupy.random.normal(0, 1, self.N_STOCKS, dtype = cupy.float32)\n",
        "\n",
        "          #stocks_randoms_cov = cupy.ones((self.N_STOCKS, self.N_STOCKS), dtype = cupy.float32)\n",
        "          #cupy.fill_diagonal(stocks_randoms_cov, rho)\n",
        "\n",
        "          #stocks_randoms_cov = (-0.99 + cupy.random.rand(self.N_STOCKS*self.N_STOCKS, dtype=cupy.float32)*2*0.99).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "          if self.N_STOCKS != 1:\n",
        "            randoms = cupy.random.normal(0, 1, self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "            # stocks_randoms_cov = cupy.array([0] * self.N_STOCKS*self.N_STOCKS, dtype = cupy.float32).reshape(self.N_STOCKS,self.N_STOCKS)  #Covariance\n",
        "            # cupy.fill_diagonal(stocks_randoms_cov, 1)\n",
        "\n",
        "            # num_of_randoms_each_stock = self.N_PATHS * self.N_STEPS\n",
        "            # randoms_gpu = cupy.random.multivariate_normal(stocks_randoms_mean, stocks_randoms_cov,\n",
        "            #                                               num_of_randoms_each_stock, dtype=cupy.float32)\n",
        "            # b1_r = randoms_gpu[:,0]\n",
        "            # b2_r = randoms_gpu[:,1]\n",
        "            # randoms = cupy.zeros(self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "            # interval = int((self.N_PATHS * self.N_STEPS * self.N_STOCKS) / self.N_PATHS)\n",
        "            # for i in range(interval):\n",
        "            #   if i % 2 == 0:\n",
        "            #       ind = int(i/2)\n",
        "            #       randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b1_r[ind:(ind+self.N_PATHS)]\n",
        "            #   else:\n",
        "            #       ind = int(i//2)\n",
        "            #       randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b2_r[ind:(ind+self.N_PATHS)]\n",
        "          if self.N_STOCKS == 1:\n",
        "            randoms = cupy.random.normal(0, 1, self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "          \n",
        "          European_call_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, X[:, 0], \n",
        "                                X[:, 1], X[:, 2], X[:, 3], X[:, 4], X[:, 5], randoms, self.N_STEPS, self.N_PATHS, self.N_STOCKS)\n",
        "          \n",
        "          o = self.output.reshape(self.N_STOCKS, self.N_PATHS) # this contains prices for each stock for each path at time T\n",
        "          K = K_rand * 150\n",
        "          r = r_rand * 0.2\n",
        "          o = o.mean(axis = 0) # average across stocks end prices\n",
        "          payoff = np.maximum(o - K, 0) # compute payoff\n",
        "          payoff = payoff * np.exp(-r*1) # T=1, discount\n",
        "          Y[op] = payoff.mean()\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(paras.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "# ds = NumbaOptionDataSet(1, number_path = 10000, batch = 3, seed = random.randint(0,100), stocks=nstock)\n",
        "# for i in ds:\n",
        "#     print(i)\n",
        "################################# TEST ########################################"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting cupy_dataset.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIa4c_aHz15a"
      },
      "source": [
        "### For verification (Monte Carlo for n-stocks basket)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DTuXR1ANZPC"
      },
      "source": [
        "# def test(array):\n",
        "#   S1 = array[2]\n",
        "#   S2 = array[8]\n",
        "#   S3 = array[14]\n",
        "#   sigma1 = array[3]\n",
        "#   sigma2 = array[9]\n",
        "#   sigma3 = array[15]\n",
        "#   T = 1  \n",
        "#   K = array[1]\n",
        "#   r = array[5]\n",
        "\n",
        "#   dt = 1/1000\n",
        "#   N = round(T/dt)\n",
        "#   t = np.linspace(0, T, N)\n",
        "\n",
        "#   out = []\n",
        "\n",
        "#   for i in range(10000):\n",
        "#     W1 = np.random.standard_normal(size = N)\n",
        "#     W1 = np.cumsum(W1) * np.sqrt(dt)\n",
        "#     W2 = np.random.standard_normal(size = N)\n",
        "#     W2 = np.cumsum(W2) * np.sqrt(dt)\n",
        "#     W3 = np.random.standard_normal(size = N)\n",
        "#     W3 = np.cumsum(W3) * np.sqrt(dt)\n",
        "\n",
        "#     # W = np.random.standard_normal(size = N)\n",
        "#     # W = np.cumsum(W) * np.sqrt(dt)\n",
        "    \n",
        "#     P1_T = (S1 * np.exp((r - 0.5*sigma1**2) *t + sigma1 * W1))[-1]\n",
        "#     P2_T = (S2 * np.exp((r - 0.5*sigma2**2) *t + sigma2 * W2))[-1]\n",
        "#     P3_T = (S3 * np.exp((r - 0.5*sigma3**2) *t + sigma3 * W3))[-1]\n",
        "#     payoff = (P1_T+P2_T+P3_T)/3 - K if (P1_T+P2_T+P3_T)/3 > K else 0\n",
        "#     out.append(payoff * np.exp(-r*T))\n",
        "  \n",
        "#   return(np.array(out).mean())\n",
        "\n",
        "# print(test(np.array([1.0000e+00, 5.8549e+00, 3.6871e+01, 2.6866e-01, 1.9026e-01, 1.8305e-01,\n",
        "#          1.0000e+00, 5.8549e+00, 4.1110e+00, 2.3714e-01, 5.9547e-02, 1.8305e-01,\n",
        "#          1.0000e+00, 5.8549e+00, 1.6189e+01, 7.3936e-02, 1.1713e-01, 1.8305e-01])))\n",
        "# print(test(np.array([1.0000e+00, 1.1296e+02, 7.4318e+01, 2.0409e-01, 1.9133e-01, 5.3904e-02,\n",
        "#          1.0000e+00, 1.1296e+02, 5.3453e+01, 4.8439e-02, 5.8557e-02, 5.3904e-02,\n",
        "#          1.0000e+00, 1.1296e+02, 3.8721e+01, 2.0259e-01, 6.0423e-02, 5.3904e-02])))\n",
        "# print(test(np.array([1.0000e+00, 3.2307e+01, 3.8874e+01, 2.5820e-01, 1.9522e-01, 8.6353e-02,\n",
        "#          1.0000e+00, 3.2307e+01, 3.6077e+01, 3.7123e-01, 1.8810e-01, 8.6353e-02,\n",
        "#          1.0000e+00, 3.2307e+01, 6.9274e+01, 2.4100e-01, 1.9839e-01, 8.6353e-02])))\n",
        "# print(test(np.array([1.0000e+00, 2.4764e+01, 6.6956e+01, 2.0769e-01, 9.8127e-02, 1.7302e-01,\n",
        "#          1.0000e+00, 2.4764e+01, 3.6483e+01, 8.9075e-02, 1.9375e-01, 1.7302e-01,\n",
        "#          1.0000e+00, 2.4764e+01, 9.4748e+01, 2.6420e-01, 1.2015e-01, 1.7302e-01])))\n",
        "# print(test(np.array([1.0000e+00, 8.4591e+01, 1.2730e+02, 2.8949e-02, 1.0954e-01, 1.3706e-01,\n",
        "#          1.0000e+00, 8.4591e+01, 1.2859e+02, 1.5262e-01, 1.4064e-03, 1.3706e-01,\n",
        "#          1.0000e+00, 8.4591e+01, 4.6679e+01, 2.6688e-01, 1.5895e-01, 1.3706e-01])))\n",
        "# print(test(np.array([1.0000e+00, 6.8433e+01, 3.5593e+01, 6.5870e-02, 6.8068e-02, 1.3578e-02,\n",
        "#          1.0000e+00, 6.8433e+01, 2.3864e+01, 9.5815e-02, 1.6075e-01, 1.3578e-02,\n",
        "#          1.0000e+00, 6.8433e+01, 1.1863e+02, 3.0400e-01, 5.6958e-02, 1.3578e-02])))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqx6hNuucM5U"
      },
      "source": [
        "# array = np.array([1.0000e+00, 8.3754e+01, 1.2787e+02, 2.7420e-01, 1.2507e-01, 1.7700e-01,\n",
        "#          1.0000e+00, 8.3754e+01, 4.0869e+01, 3.3302e-01, 1.7439e-01, 1.7700e-01,\n",
        "#          1.0000e+00, 8.3754e+01, 1.1031e+02, 3.5945e-01, 1.5382e-01, 1.7700e-01])\n",
        "\n",
        "# S1 = array[2]\n",
        "# S2 = array[8]\n",
        "# S3 = array[14]\n",
        "# sigma1 = array[3]\n",
        "# sigma2 = array[9]\n",
        "# sigma3 = array[15]\n",
        "# T = 1  \n",
        "# K = array[1]\n",
        "# r = array[5]\n",
        "\n",
        "# dt = 1/100\n",
        "# N = round(T/dt)\n",
        "# t = np.linspace(0, T, N)\n",
        "\n",
        "# out = []\n",
        "\n",
        "# #for i in range(1000):\n",
        "# W = np.random.standard_normal(size = N)\n",
        "# W = np.cumsum(W) * np.sqrt(dt)\n",
        "# P1_T = (S1 * np.exp((r - 0.5*sigma1**2) *t + sigma1 * W))\n",
        "# P2_T = (S2 * np.exp((r - 0.5*sigma2**2) *t + sigma2 * W))[-1]\n",
        "# P3_T = (S3 * np.exp((r - 0.5*sigma3**2) *t + sigma3 * W))[-1]\n",
        "# #ayoff = (P1_T+P2_T+P3_T)/3 - K if (P1_T+P2_T+P3_T)/3 > K else 0\n",
        "# #out.append(payoff * np.exp(-r*T))\n",
        "\n",
        "# #return(np.array(out).mean())\n",
        "# #P1_T\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.plot(t, P1_T)\n",
        "# plt.show()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tpLw9WDhx8b"
      },
      "source": [
        "# stocks_randoms_cov = cupy.array([0.99999] * 3 * 3, dtype = cupy.float32).reshape(3,3)  #Covariance\n",
        "# cupy.fill_diagonal(stocks_randoms_cov, 1)\n",
        "\n",
        "# stocks_randoms_mean = cupy.zeros(3, dtype = cupy.float32)\n",
        "\n",
        "# num_of_randoms_each_stock = 2 * 3\n",
        "# randoms_gpu = cupy.random.multivariate_normal(stocks_randoms_mean, stocks_randoms_cov,\n",
        "#                                               num_of_randoms_each_stock, dtype=cupy.float32)\n",
        "# randoms_gpu"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2_89jOknwjH"
      },
      "source": [
        "### Model\n",
        "To map the option parameters to price, we use 6 layers of fully connected neural network with hidden dimension 512 as inspired by [this paper](https://arxiv.org/abs/1809.02233). Writing this DL price model into a file `model.py`:-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMHqzJycx8XH"
      },
      "source": [
        "### Modified Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTn7iJQryAIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b55cd8d4-01d6-46e3-b91d-54f99fd70e63"
      },
      "source": [
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024, nstock=3):\n",
        "        super(Net, self).__init__()\n",
        "        self.nstock = nstock\n",
        "        self.fc1 = nn.Linear(6 * self.nstock, hidden)\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 1)\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1, 150.0, 150.0, 0.4, 0.2, 0.2] * self.nstock)) # don't use numpy here - will give error later\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting model.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSPRFqyznwjI"
      },
      "source": [
        "As we know the random parameters' scaling factors, the input parameters are first scaled back to a range of (0-1) by dividing them by (200.0, 198.0, 200.0, 0.4, 0.2, 0.2). Then they are projected 5 times to the hidden dimension of 512 after the `ELu` activation function. `ELu` is chosen because we need to compute the second order differentiation of the parameters. If use ReLu, the second order differentiation will always be zero. The last layer is a linear layer that maps the hidden dimension to the predicted option price. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM8J2liPnwjJ"
      },
      "source": [
        "For training, we use [Ignite](https://github.com/pytorch/ignite) which is a high-level library to train neural networks in PyTorch. We use `MSELoss` as the loss function, `Adam` as the optimizer and `CosineAnnealingScheduler` as the learning rate scheduler. The following code is feeding the random option data to the pricing model to train it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yACi4ge13_rd"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TyZT8_AH35M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b73c445-97a9-41a7-8353-e4a7eef58ac2"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.7/dist-packages (0.4.6)\n",
            "Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Ej82G8nwjJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3fb96a7c-2d4b-4334-c7c1-2a35096f63f9"
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import NumbaOptionDataSet\n",
        "import random\n",
        "timer = Timer(average=True)\n",
        "model = Net(nstock = nstock).cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "# dataset = NumbaOptionDataSet(max_len = 10000, number_path = 1024, batch = 4800)\n",
        "# dataset = NumbaOptionDataSet(max_len = 100, number_path = 1024, batch = 32, stocks = 3)\n",
        "dataset = NumbaOptionDataSet(max_len = 1000, number_path = 2048, batch = 32, seed = random.randint(0, 100), stocks = nstock)\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred[:,0], y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 500)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss 1696.8017578125 average time 0.018963083000016923 iter num 20\n",
            "loss 1206.5595703125 average time 0.010892367575047501 iter num 40\n",
            "loss 870.9207153320312 average time 0.008213849000064026 iter num 60\n",
            "loss 380.3311767578125 average time 0.006896034437545495 iter num 80\n",
            "loss 40.382713317871094 average time 0.00606193029003407 iter num 100\n",
            "loss 7.633145809173584 average time 0.005513362933349223 iter num 120\n",
            "loss 6.773252010345459 average time 0.005115438878588716 iter num 140\n",
            "loss 6.684213638305664 average time 0.004826922312514625 iter num 160\n",
            "loss 6.397936820983887 average time 0.004597012888901493 iter num 180\n",
            "loss 5.73484992980957 average time 0.004409126810014641 iter num 200\n",
            "loss 2.021898031234741 average time 0.004255954527285543 iter num 220\n",
            "loss 2.5581514835357666 average time 0.004129479604171138 iter num 240\n",
            "loss 6.419672012329102 average time 0.004020478011541574 iter num 260\n",
            "loss 4.252986907958984 average time 0.003957130842854895 iter num 280\n",
            "loss 4.2150187492370605 average time 0.003884346836669768 iter num 300\n",
            "loss 2.7084884643554688 average time 0.0038128624062522933 iter num 320\n",
            "loss 5.014249801635742 average time 0.0037501428764725835 iter num 340\n",
            "loss 2.6376256942749023 average time 0.0036947777611152964 iter num 360\n",
            "loss 3.927104949951172 average time 0.003649066350003762 iter num 380\n",
            "loss 2.0411171913146973 average time 0.0036067923625046207 iter num 400\n",
            "loss 9.988428115844727 average time 0.0035644089857106293 iter num 420\n",
            "loss 4.995698928833008 average time 0.0035352362886297587 iter num 440\n",
            "loss 3.9592182636260986 average time 0.003499137960868567 iter num 460\n",
            "loss 3.8836913108825684 average time 0.003467140762489862 iter num 480\n",
            "loss 1.7114319801330566 average time 0.0034392184379812532 iter num 500\n",
            "loss 7.3870391845703125 average time 0.003410940011506752 iter num 520\n",
            "loss 3.593172311782837 average time 0.003392975774051121 iter num 540\n",
            "loss 3.421940326690674 average time 0.0033688002053411637 iter num 560\n",
            "loss 4.013236045837402 average time 0.0033468793430905673 iter num 580\n",
            "loss 6.169260501861572 average time 0.0033327587666599355 iter num 600\n",
            "loss 3.91772198677063 average time 0.0033149874886960113 iter num 620\n",
            "loss 7.281310081481934 average time 0.003297055890614331 iter num 640\n",
            "loss 2.4577040672302246 average time 0.00328065117424475 iter num 660\n",
            "loss 2.164862871170044 average time 0.003266905398538042 iter num 680\n",
            "loss 0.9882439970970154 average time 0.003258302911437048 iter num 700\n",
            "loss 2.5367257595062256 average time 0.0032449407333425976 iter num 720\n",
            "loss 4.23974609375 average time 0.0032320707756851434 iter num 740\n",
            "loss 3.245455741882324 average time 0.0032195761250034738 iter num 760\n",
            "loss 3.339765787124634 average time 0.0032068102166715852 iter num 780\n",
            "loss 2.4908459186553955 average time 0.0031953915575070367 iter num 800\n",
            "loss 3.202049732208252 average time 0.0031839139597572863 iter num 820\n",
            "loss 2.2468855381011963 average time 0.003172635428569222 iter num 840\n",
            "loss 1.3974589109420776 average time 0.0031616724267466852 iter num 860\n",
            "loss 2.8507161140441895 average time 0.003151458854554014 iter num 880\n",
            "loss 1.8490817546844482 average time 0.003141743441118605 iter num 900\n",
            "loss 2.631226062774658 average time 0.0031333219728297912 iter num 920\n",
            "loss 1.9165714979171753 average time 0.0031243955021356203 iter num 940\n",
            "loss 1.9046365022659302 average time 0.0031166801447994885 iter num 960\n",
            "loss 4.04222297668457 average time 0.003108220488781756 iter num 980\n",
            "loss 2.5094058513641357 average time 0.0031018756570056214 iter num 1000\n",
            "loss 5.794036865234375 average time 0.018330065300142452 iter num 20\n",
            "loss 3.242098331451416 average time 0.010558594750136763 iter num 40\n",
            "loss 2.2805404663085938 average time 0.007972424933420067 iter num 60\n",
            "loss 1.4382669925689697 average time 0.006662181250067079 iter num 80\n",
            "loss 6.285485744476318 average time 0.005891996410027787 iter num 100\n",
            "loss 4.238051891326904 average time 0.005368427558384307 iter num 120\n",
            "loss 5.803274154663086 average time 0.0049916551000283756 iter num 140\n",
            "loss 2.676051616668701 average time 0.004708660237508866 iter num 160\n",
            "loss 1.5010186433792114 average time 0.0044904538222302415 iter num 180\n",
            "loss 2.5350184440612793 average time 0.00432370338500732 iter num 200\n",
            "loss 1.2332545518875122 average time 0.0041798166091211895 iter num 220\n",
            "loss 3.7395167350769043 average time 0.004057862675025111 iter num 240\n",
            "loss 2.439093589782715 average time 0.003954882392337403 iter num 260\n",
            "loss 4.162744045257568 average time 0.0038678873071733375 iter num 280\n",
            "loss 2.6661274433135986 average time 0.003791414263347785 iter num 300\n",
            "loss 0.8807847499847412 average time 0.003723827056273876 iter num 320\n",
            "loss 3.8181962966918945 average time 0.003666253723552954 iter num 340\n",
            "loss 2.975813865661621 average time 0.0036169975416820914 iter num 360\n",
            "loss 2.32424259185791 average time 0.0035691988737055094 iter num 380\n",
            "loss 2.0317370891571045 average time 0.0035265789875165866 iter num 400\n",
            "loss 2.300596237182617 average time 0.0034879110190688934 iter num 420\n",
            "loss 0.8825287818908691 average time 0.0034585292500320395 iter num 440\n",
            "loss 2.078902244567871 average time 0.0034261006869952403 iter num 460\n",
            "loss 1.7503881454467773 average time 0.003398164241707491 iter num 480\n",
            "loss 1.7374513149261475 average time 0.0033719363260352113 iter num 500\n",
            "loss 1.3430073261260986 average time 0.0033466203654195573 iter num 520\n",
            "loss 1.7524898052215576 average time 0.003322650942626987 iter num 540\n",
            "loss 1.6302988529205322 average time 0.003300361005387588 iter num 560\n",
            "loss 1.3049581050872803 average time 0.0032825102552092645 iter num 580\n",
            "loss 0.9590863585472107 average time 0.003264883795042503 iter num 600\n",
            "loss 1.1931053400039673 average time 0.0032479264435829876 iter num 620\n",
            "loss 2.5106005668640137 average time 0.003233758398465625 iter num 640\n",
            "loss 2.320911407470703 average time 0.003219158413657803 iter num 660\n",
            "loss 1.0306299924850464 average time 0.0032041291764953175 iter num 680\n",
            "loss 1.039029836654663 average time 0.0031896637900250165 iter num 700\n",
            "loss 1.9601763486862183 average time 0.00317710141391419 iter num 720\n",
            "loss 3.3584728240966797 average time 0.0031681711865039195 iter num 740\n",
            "loss 1.1072603464126587 average time 0.003158612423703744 iter num 760\n",
            "loss 1.0574250221252441 average time 0.003149098619250696 iter num 780\n",
            "loss 1.3708959817886353 average time 0.003138403363770976 iter num 800\n",
            "loss 1.0788841247558594 average time 0.003130277507337202 iter num 820\n",
            "loss 0.8767926692962646 average time 0.0031206109738247637 iter num 840\n",
            "loss 1.421319603919983 average time 0.0031125100814109784 iter num 860\n",
            "loss 1.0937600135803223 average time 0.003103436820467984 iter num 880\n",
            "loss 1.1345205307006836 average time 0.0030944148889021665 iter num 900\n",
            "loss 1.251235008239746 average time 0.0030862439989327276 iter num 920\n",
            "loss 1.1379814147949219 average time 0.003078137711719969 iter num 940\n",
            "loss 1.9698567390441895 average time 0.0030744434687714297 iter num 960\n",
            "loss 1.9551374912261963 average time 0.003069461983695688 iter num 980\n",
            "loss 1.1060559749603271 average time 0.003061916540016682 iter num 1000\n",
            "loss 0.7837343215942383 average time 0.01830655619978643 iter num 20\n",
            "loss 1.1656360626220703 average time 0.010513461699974868 iter num 40\n",
            "loss 2.4267969131469727 average time 0.007915685599952364 iter num 60\n",
            "loss 1.075399398803711 average time 0.00664239223747245 iter num 80\n",
            "loss 0.5751667618751526 average time 0.005858031820025644 iter num 100\n",
            "loss 4.974043846130371 average time 0.005332117141688286 iter num 120\n",
            "loss 0.8123571872711182 average time 0.004959998200021281 iter num 140\n",
            "loss 1.175155758857727 average time 0.0046811352812937915 iter num 160\n",
            "loss 2.116708278656006 average time 0.004462934966704779 iter num 180\n",
            "loss 2.0766148567199707 average time 0.004288964080051301 iter num 200\n",
            "loss 1.5131311416625977 average time 0.004145517986398772 iter num 220\n",
            "loss 2.2713217735290527 average time 0.004026688966678194 iter num 240\n",
            "loss 1.614572286605835 average time 0.003924596296159367 iter num 260\n",
            "loss 0.27283725142478943 average time 0.0038499505142941155 iter num 280\n",
            "loss 0.5173415541648865 average time 0.0037799019399911535 iter num 300\n",
            "loss 0.7463311553001404 average time 0.0037166671781221792 iter num 320\n",
            "loss 1.3097829818725586 average time 0.003660962726473158 iter num 340\n",
            "loss 0.4263002276420593 average time 0.0036096815388848174 iter num 360\n",
            "loss 0.7406668066978455 average time 0.003563306910535558 iter num 380\n",
            "loss 1.5293102264404297 average time 0.0035200661650060285 iter num 400\n",
            "loss 0.770942747592926 average time 0.0034823234928851544 iter num 420\n",
            "loss 0.8462513089179993 average time 0.0034499506636662277 iter num 440\n",
            "loss 0.5823042392730713 average time 0.0034170465804653875 iter num 460\n",
            "loss 0.9875441789627075 average time 0.0033866141271156874 iter num 480\n",
            "loss 0.35414454340934753 average time 0.0033590869280269546 iter num 500\n",
            "loss 0.7129090428352356 average time 0.003334814378873629 iter num 520\n",
            "loss 1.3347443342208862 average time 0.0033112487981809494 iter num 540\n",
            "loss 1.780524492263794 average time 0.003289875346467852 iter num 560\n",
            "loss 0.7118832468986511 average time 0.003270678844860256 iter num 580\n",
            "loss 0.5951899290084839 average time 0.003253946903363006 iter num 600\n",
            "loss 0.7134407758712769 average time 0.0032380358177702406 iter num 620\n",
            "loss 0.8160994052886963 average time 0.003222415434399295 iter num 640\n",
            "loss 0.713090181350708 average time 0.0032069050591086454 iter num 660\n",
            "loss 0.39714905619621277 average time 0.0031929961882430206 iter num 680\n",
            "loss 0.8832743167877197 average time 0.0031795762000079515 iter num 700\n",
            "loss 0.7930992841720581 average time 0.0031668695347333497 iter num 720\n",
            "loss 0.8274174928665161 average time 0.003155454714878697 iter num 740\n",
            "loss 0.865475594997406 average time 0.0031461261447451472 iter num 760\n",
            "loss 0.602869987487793 average time 0.0031348172333379738 iter num 780\n",
            "loss 0.2661241888999939 average time 0.003132537915003013 iter num 800\n",
            "loss 0.7193922400474548 average time 0.003124140371954393 iter num 820\n",
            "loss 0.6759259104728699 average time 0.003114791035713573 iter num 840\n",
            "loss 0.38610947132110596 average time 0.0031055801744197344 iter num 860\n",
            "loss 0.9275461435317993 average time 0.0030970483556881268 iter num 880\n",
            "loss 0.3890339434146881 average time 0.0030898728844577917 iter num 900\n",
            "loss 0.6713845729827881 average time 0.0030820894271844576 iter num 920\n",
            "loss 0.4442821145057678 average time 0.0030822947744785236 iter num 940\n",
            "loss 0.3694327473640442 average time 0.0030743456218885966 iter num 960\n",
            "loss 0.606099009513855 average time 0.00306681785511816 iter num 980\n",
            "loss 0.7545772194862366 average time 0.003059636924019287 iter num 1000\n",
            "loss 0.8227737545967102 average time 0.018420818800132112 iter num 20\n",
            "loss 0.4588419795036316 average time 0.01056554382507784 iter num 40\n",
            "loss 1.227925181388855 average time 0.007942845316604993 iter num 60\n",
            "loss 2.144239902496338 average time 0.006631882549891088 iter num 80\n",
            "loss 6.53372859954834 average time 0.0058590443499088 iter num 100\n",
            "loss 1.1903421878814697 average time 0.005369553316556145 iter num 120\n",
            "loss 0.7353183627128601 average time 0.004991629664190051 iter num 140\n",
            "loss 1.0928659439086914 average time 0.0047080881749025135 iter num 160\n",
            "loss 0.8909496068954468 average time 0.004495969099894461 iter num 180\n",
            "loss 1.0600601434707642 average time 0.004317792094907418 iter num 200\n",
            "loss 0.5800704956054688 average time 0.004169719295400269 iter num 220\n",
            "loss 0.3529431223869324 average time 0.0040689671457660856 iter num 240\n",
            "loss 1.4158806800842285 average time 0.003971036319168119 iter num 260\n",
            "loss 0.585087776184082 average time 0.003879332432078237 iter num 280\n",
            "loss 0.7531830072402954 average time 0.003801525253256841 iter num 300\n",
            "loss 0.14959222078323364 average time 0.00373420153744064 iter num 320\n",
            "loss 0.1583031713962555 average time 0.0036745779028880114 iter num 340\n",
            "loss 0.7121310830116272 average time 0.0036198111055202593 iter num 360\n",
            "loss 0.7021410465240479 average time 0.0035721931868178407 iter num 380\n",
            "loss 0.7322937250137329 average time 0.0035347473574847753 iter num 400\n",
            "loss 0.48326626420021057 average time 0.0034955907976014023 iter num 420\n",
            "loss 0.5148637890815735 average time 0.0034630064045276495 iter num 440\n",
            "loss 0.6018031239509583 average time 0.003431497797808571 iter num 460\n",
            "loss 0.745581865310669 average time 0.0034017352270704275 iter num 480\n",
            "loss 0.45781219005584717 average time 0.0033741123419895303 iter num 500\n",
            "loss 0.34855079650878906 average time 0.0033502615846023568 iter num 520\n",
            "loss 0.4440317451953888 average time 0.003325667298139268 iter num 540\n",
            "loss 0.18534231185913086 average time 0.00330603584462941 iter num 560\n",
            "loss 0.5712581872940063 average time 0.0032861750344668037 iter num 580\n",
            "loss 0.43719905614852905 average time 0.0032672321566648557 iter num 600\n",
            "loss 0.4132891297340393 average time 0.003249234803229962 iter num 620\n",
            "loss 0.5441387295722961 average time 0.003232672026564387 iter num 640\n",
            "loss 0.26964932680130005 average time 0.0032192510272745327 iter num 660\n",
            "loss 0.4537869393825531 average time 0.0032046474617586414 iter num 680\n",
            "loss 0.3437228500843048 average time 0.0031909098128588605 iter num 700\n",
            "loss 0.33060526847839355 average time 0.0031779813222253023 iter num 720\n",
            "loss 0.7190439701080322 average time 0.003165614205416303 iter num 740\n",
            "loss 0.1620866358280182 average time 0.003155810978959332 iter num 760\n",
            "loss 0.5025298595428467 average time 0.0031442834756559863 iter num 780\n",
            "loss 0.317457914352417 average time 0.0031355646150132087 iter num 800\n",
            "loss 0.2257266789674759 average time 0.0031251399341627115 iter num 820\n",
            "loss 0.30181998014450073 average time 0.0031156657702467784 iter num 840\n",
            "loss 0.3053578734397888 average time 0.003106611261634054 iter num 860\n",
            "loss 0.8222081661224365 average time 0.003097860539777354 iter num 880\n",
            "loss 0.23587046563625336 average time 0.003089570454449131 iter num 900\n",
            "loss 0.29629361629486084 average time 0.0030829479521739616 iter num 920\n",
            "loss 0.2651249170303345 average time 0.003074645918086196 iter num 940\n",
            "loss 0.13028956949710846 average time 0.0030668247052157466 iter num 960\n",
            "loss 0.23789578676223755 average time 0.0030596326418385524 iter num 980\n",
            "loss 0.24723336100578308 average time 0.003052418479002881 iter num 1000\n",
            "loss 0.23124007880687714 average time 0.018332976799774768 iter num 20\n",
            "loss 1.038666009902954 average time 0.010537634199818059 iter num 40\n",
            "loss 0.540726363658905 average time 0.007943788966531428 iter num 60\n",
            "loss 0.3120851516723633 average time 0.006636132612425172 iter num 80\n",
            "loss 0.9785287380218506 average time 0.005849183039881609 iter num 100\n",
            "loss 1.1782615184783936 average time 0.005328202308267767 iter num 120\n",
            "loss 1.0195893049240112 average time 0.004953216935648795 iter num 140\n",
            "loss 0.38845616579055786 average time 0.0046698140749526825 iter num 160\n",
            "loss 1.2326472997665405 average time 0.004452310005550923 iter num 180\n",
            "loss 0.4657489061355591 average time 0.004278994815003898 iter num 200\n",
            "loss 0.529768168926239 average time 0.004143108704548384 iter num 220\n",
            "loss 0.34580594301223755 average time 0.004039781412507182 iter num 240\n",
            "loss 0.34782540798187256 average time 0.003943892838462769 iter num 260\n",
            "loss 0.3435669541358948 average time 0.0038620648000167943 iter num 280\n",
            "loss 0.28910231590270996 average time 0.003786371336688414 iter num 300\n",
            "loss 0.8276188373565674 average time 0.003723158446916841 iter num 320\n",
            "loss 0.729149341583252 average time 0.0036643579765255068 iter num 340\n",
            "loss 2.7699501514434814 average time 0.0036116316028407406 iter num 360\n",
            "loss 0.682223916053772 average time 0.0035630052974355703 iter num 380\n",
            "loss 0.4002547860145569 average time 0.0035233218425719313 iter num 400\n",
            "loss 0.3825984299182892 average time 0.00348465610481764 iter num 420\n",
            "loss 0.19669407606124878 average time 0.0034606984773166583 iter num 440\n",
            "loss 1.6240437030792236 average time 0.003428195189162184 iter num 460\n",
            "loss 0.5053643584251404 average time 0.003397531985456226 iter num 480\n",
            "loss 0.5920048356056213 average time 0.003370275676039455 iter num 500\n",
            "loss 0.14722460508346558 average time 0.0033445099692681443 iter num 520\n",
            "loss 0.40137723088264465 average time 0.003321244038929931 iter num 540\n",
            "loss 0.26776158809661865 average time 0.0033056360393142574 iter num 560\n",
            "loss 0.2417028695344925 average time 0.003285741548301428 iter num 580\n",
            "loss 0.3394443988800049 average time 0.003267125548363765 iter num 600\n",
            "loss 0.20434415340423584 average time 0.0032490568048600716 iter num 620\n",
            "loss 0.8268527984619141 average time 0.0032322245000187878 iter num 640\n",
            "loss 0.5767257213592529 average time 0.0032170233788058273 iter num 660\n",
            "loss 0.21710319817066193 average time 0.0032029675632630266 iter num 680\n",
            "loss 0.274625301361084 average time 0.0031891094943135353 iter num 700\n",
            "loss 0.3202812671661377 average time 0.003176680055581629 iter num 720\n",
            "loss 0.2607477009296417 average time 0.0031649254094829942 iter num 740\n",
            "loss 0.17902427911758423 average time 0.00315262301712784 iter num 760\n",
            "loss 0.49771273136138916 average time 0.003144533187192932 iter num 780\n",
            "loss 0.3687323331832886 average time 0.0031332822262629635 iter num 800\n",
            "loss 0.24703752994537354 average time 0.003123115864648908 iter num 820\n",
            "loss 0.2508198022842407 average time 0.0031131509369277497 iter num 840\n",
            "loss 0.2255556285381317 average time 0.00310382336281395 iter num 860\n",
            "loss 0.255331814289093 average time 0.0030944823466081124 iter num 880\n",
            "loss 0.3757932186126709 average time 0.0030853238377878574 iter num 900\n",
            "loss 0.43087026476860046 average time 0.0030789830043589893 iter num 920\n",
            "loss 0.2682911157608032 average time 0.0030708882180891686 iter num 940\n",
            "loss 0.3262317180633545 average time 0.00306415711770948 iter num 960\n",
            "loss 0.13845083117485046 average time 0.0030568726081694375 iter num 980\n",
            "loss 0.17112481594085693 average time 0.00304968088100577 iter num 1000\n",
            "loss 2.3033289909362793 average time 0.018194530800246866 iter num 20\n",
            "loss 0.9703148007392883 average time 0.010458572925199406 iter num 40\n",
            "loss 1.9185959100723267 average time 0.007879938300114494 iter num 60\n",
            "loss 0.4040588140487671 average time 0.006578502337606551 iter num 80\n",
            "loss 1.0382001399993896 average time 0.005806169360057538 iter num 100\n",
            "loss 1.2869013547897339 average time 0.0052952362917039865 iter num 120\n",
            "loss 0.3711819052696228 average time 0.004937797750023622 iter num 140\n",
            "loss 0.4822888672351837 average time 0.004661044200042852 iter num 160\n",
            "loss 1.1004137992858887 average time 0.004475549833387049 iter num 180\n",
            "loss 0.24333132803440094 average time 0.004301697025075555 iter num 200\n",
            "loss 1.2872755527496338 average time 0.004155121572760188 iter num 220\n",
            "loss 0.8282526731491089 average time 0.004034545075031323 iter num 240\n",
            "loss 0.7363450527191162 average time 0.003931818865427116 iter num 260\n",
            "loss 1.9162064790725708 average time 0.003849572289313333 iter num 280\n",
            "loss 0.733881950378418 average time 0.0037719330533642886 iter num 300\n",
            "loss 0.4598676860332489 average time 0.0037050090437844574 iter num 320\n",
            "loss 0.6685858964920044 average time 0.0036530151735592775 iter num 340\n",
            "loss 0.3031022250652313 average time 0.003601279900031942 iter num 360\n",
            "loss 0.26908838748931885 average time 0.00355333896581406 iter num 380\n",
            "loss 0.5791642665863037 average time 0.003522457770022811 iter num 400\n",
            "loss 0.2127166986465454 average time 0.0034847359833596178 iter num 420\n",
            "loss 0.40055108070373535 average time 0.0034548915454830752 iter num 440\n",
            "loss 0.2950877547264099 average time 0.003424550923935622 iter num 460\n",
            "loss 0.4456441402435303 average time 0.0033941878479367914 iter num 480\n",
            "loss 1.4253203868865967 average time 0.003374488742014364 iter num 500\n",
            "loss 1.6037616729736328 average time 0.0033481259769464838 iter num 520\n",
            "loss 0.37395596504211426 average time 0.003328914698172243 iter num 540\n",
            "loss 0.14195552468299866 average time 0.0033085665000239066 iter num 560\n",
            "loss 0.22795796394348145 average time 0.0032882318207126007 iter num 580\n",
            "loss 0.5766440033912659 average time 0.0032712684216888496 iter num 600\n",
            "loss 0.22879695892333984 average time 0.003255101532279021 iter num 620\n",
            "loss 0.12407270073890686 average time 0.003237964050029518 iter num 640\n",
            "loss 0.4484166204929352 average time 0.0032218414863922533 iter num 660\n",
            "loss 0.33983930945396423 average time 0.0032066522485552818 iter num 680\n",
            "loss 0.20402419567108154 average time 0.003193286188600593 iter num 700\n",
            "loss 0.3732672333717346 average time 0.0031811299000360626 iter num 720\n",
            "loss 0.251221239566803 average time 0.003169238097330349 iter num 740\n",
            "loss 0.46460312604904175 average time 0.0031565386750332294 iter num 760\n",
            "loss 0.1408606916666031 average time 0.003144639976949876 iter num 780\n",
            "loss 0.38934648036956787 average time 0.0031333111075241503 iter num 800\n",
            "loss 0.12922309339046478 average time 0.0031233758439268016 iter num 820\n",
            "loss 0.21797843277454376 average time 0.003113703453601331 iter num 840\n",
            "loss 0.15737265348434448 average time 0.0031045389965372525 iter num 860\n",
            "loss 0.3399742841720581 average time 0.003095728300025836 iter num 880\n",
            "loss 0.15566906332969666 average time 0.003086800283361097 iter num 900\n",
            "loss 0.23879320919513702 average time 0.0030789254326306116 iter num 920\n",
            "loss 0.16996297240257263 average time 0.003070887738322973 iter num 940\n",
            "loss 0.3044939637184143 average time 0.003062769861480774 iter num 960\n",
            "loss 0.2354670912027359 average time 0.003056008863285922 iter num 980\n",
            "loss 0.41617143154144287 average time 0.0030488914480156382 iter num 1000\n",
            "loss 0.5478557348251343 average time 0.018263602499882837 iter num 20\n",
            "loss 0.387808620929718 average time 0.010484984725007963 iter num 40\n",
            "loss 0.6352365612983704 average time 0.007888710483409037 iter num 60\n",
            "loss 0.3997230529785156 average time 0.006589300087625816 iter num 80\n",
            "loss 1.391188621520996 average time 0.0058163195700763025 iter num 100\n",
            "loss 1.9382246732711792 average time 0.0052985164167239415 iter num 120\n",
            "loss 0.9322628974914551 average time 0.0049358066429054555 iter num 140\n",
            "loss 0.528639554977417 average time 0.004662770143772832 iter num 160\n",
            "loss 0.5752694010734558 average time 0.00446556047226194 iter num 180\n",
            "loss 0.335692435503006 average time 0.004293236620032986 iter num 200\n",
            "loss 0.34536927938461304 average time 0.004160258104572925 iter num 220\n",
            "loss 2.0296401977539062 average time 0.004049026720857303 iter num 240\n",
            "loss 0.6919464468955994 average time 0.0039507317500255545 iter num 260\n",
            "loss 0.1306329369544983 average time 0.0038628804107507415 iter num 280\n",
            "loss 0.31258004903793335 average time 0.003788294456699077 iter num 300\n",
            "loss 0.08805601298809052 average time 0.0037246918469122647 iter num 320\n",
            "loss 1.510474681854248 average time 0.0036716351618023882 iter num 340\n",
            "loss 0.4240257143974304 average time 0.003620128313918435 iter num 360\n",
            "loss 0.24622878432273865 average time 0.0035718848947621346 iter num 380\n",
            "loss 0.3424813747406006 average time 0.0035308562050204275 iter num 400\n",
            "loss 0.5425398349761963 average time 0.0034918865619450417 iter num 420\n",
            "loss 0.3700285255908966 average time 0.003456383522763479 iter num 440\n",
            "loss 0.2997574806213379 average time 0.003426891252207576 iter num 460\n",
            "loss 0.45122724771499634 average time 0.0033972517979502 iter num 480\n",
            "loss 0.5327339172363281 average time 0.0033706928440369664 iter num 500\n",
            "loss 0.20174454152584076 average time 0.0033505254346472124 iter num 520\n",
            "loss 0.6162636280059814 average time 0.003327678185218651 iter num 540\n",
            "loss 0.0836883932352066 average time 0.003305616305393804 iter num 560\n",
            "loss 0.331003338098526 average time 0.0032852470224529026 iter num 580\n",
            "loss 0.2277401089668274 average time 0.0032695044866977697 iter num 600\n",
            "loss 0.2769175171852112 average time 0.0032510294097113316 iter num 620\n",
            "loss 0.22169657051563263 average time 0.0032344364672212576 iter num 640\n",
            "loss 0.25233882665634155 average time 0.003217856701543166 iter num 660\n",
            "loss 0.21862849593162537 average time 0.0032037050838452535 iter num 680\n",
            "loss 0.44100555777549744 average time 0.0031897893500198345 iter num 700\n",
            "loss 0.21087141335010529 average time 0.0031794727000235275 iter num 720\n",
            "loss 0.2567402422428131 average time 0.0031674674446155737 iter num 740\n",
            "loss 0.27139151096343994 average time 0.00315705243159707 iter num 760\n",
            "loss 0.2067757099866867 average time 0.0031462903974594763 iter num 780\n",
            "loss 0.46882230043411255 average time 0.003135832981272415 iter num 800\n",
            "loss 0.12903587520122528 average time 0.003135252793928397 iter num 820\n",
            "loss 0.1856732964515686 average time 0.003128811422647275 iter num 840\n",
            "loss 0.14491736888885498 average time 0.0031189046453767143 iter num 860\n",
            "loss 0.2809445261955261 average time 0.003109422742070158 iter num 880\n",
            "loss 0.16769051551818848 average time 0.0031003437622469693 iter num 900\n",
            "loss 0.20526254177093506 average time 0.0030920556772007727 iter num 920\n",
            "loss 0.32824018597602844 average time 0.0030838548223692534 iter num 940\n",
            "loss 0.10902567207813263 average time 0.0030759262083601396 iter num 960\n",
            "loss 0.2684124708175659 average time 0.0030685294500230787 iter num 980\n",
            "loss 0.5076333284378052 average time 0.0030615575480205733 iter num 1000\n",
            "loss 0.5955303311347961 average time 0.01839934555018772 iter num 20\n",
            "loss 0.3985602855682373 average time 0.01055481492517174 iter num 40\n",
            "loss 0.3678852319717407 average time 0.008010782216782293 iter num 60\n",
            "loss 0.6948610544204712 average time 0.006705799237533938 iter num 80\n",
            "loss 1.4515161514282227 average time 0.005919488610034023 iter num 100\n",
            "loss 1.1207275390625 average time 0.005385520050049308 iter num 120\n",
            "loss 2.06614089012146 average time 0.005002158221447774 iter num 140\n",
            "loss 1.5360312461853027 average time 0.0047145700437909 iter num 160\n",
            "loss 0.8903317451477051 average time 0.004492810194501039 iter num 180\n",
            "loss 0.8702225685119629 average time 0.0043148063850730976 iter num 200\n",
            "loss 1.211693525314331 average time 0.004177267363675955 iter num 220\n",
            "loss 0.7087075114250183 average time 0.0040541113500542755 iter num 240\n",
            "loss 1.2947850227355957 average time 0.003962451065427348 iter num 260\n",
            "loss 0.2383326292037964 average time 0.003869093928597067 iter num 280\n",
            "loss 0.30268043279647827 average time 0.003799322466687348 iter num 300\n",
            "loss 0.37777644395828247 average time 0.0037329037531492306 iter num 320\n",
            "loss 0.4455951452255249 average time 0.003673765705886634 iter num 340\n",
            "loss 0.42663902044296265 average time 0.003620601744453072 iter num 360\n",
            "loss 1.9249112606048584 average time 0.0035749493631556106 iter num 380\n",
            "loss 1.417646050453186 average time 0.003531700559988167 iter num 400\n",
            "loss 0.5338073372840881 average time 0.0034941749761812735 iter num 420\n",
            "loss 0.2897639274597168 average time 0.0034584028908987174 iter num 440\n",
            "loss 0.5611364841461182 average time 0.003429634308691754 iter num 460\n",
            "loss 0.2951636016368866 average time 0.0034075212333277705 iter num 480\n",
            "loss 0.3351135849952698 average time 0.0033843339440027195 iter num 500\n",
            "loss 0.22000043094158173 average time 0.0033592251442384554 iter num 520\n",
            "loss 0.33306369185447693 average time 0.003335790287049652 iter num 540\n",
            "loss 0.5250677466392517 average time 0.003314144417868192 iter num 560\n",
            "loss 0.5395012497901917 average time 0.0032952711086338617 iter num 580\n",
            "loss 0.27375170588493347 average time 0.0032768975033498765 iter num 600\n",
            "loss 0.25939732789993286 average time 0.0032606290242080333 iter num 620\n",
            "loss 0.30247998237609863 average time 0.0032437377546955305 iter num 640\n",
            "loss 0.24605333805084229 average time 0.0032293602363758756 iter num 660\n",
            "loss 0.15560626983642578 average time 0.003215657992656334 iter num 680\n",
            "loss 0.2880009412765503 average time 0.003202590751438298 iter num 700\n",
            "loss 0.12762333452701569 average time 0.003192572250009107 iter num 720\n",
            "loss 0.19967812299728394 average time 0.0031817065162244576 iter num 740\n",
            "loss 0.2860315442085266 average time 0.003173813857902611 iter num 760\n",
            "loss 0.17275689542293549 average time 0.003163412233339048 iter num 780\n",
            "loss 0.33330458402633667 average time 0.003157637031260947 iter num 800\n",
            "loss 0.2472454458475113 average time 0.0031477901341554018 iter num 820\n",
            "loss 0.21835243701934814 average time 0.0031431647250103976 iter num 840\n",
            "loss 0.46904003620147705 average time 0.003134904953496389 iter num 860\n",
            "loss 0.2121068239212036 average time 0.0031263982920542977 iter num 880\n",
            "loss 0.08477210253477097 average time 0.003117702180006745 iter num 900\n",
            "loss 0.12047690153121948 average time 0.0031093307739193613 iter num 920\n",
            "loss 0.26401156187057495 average time 0.0031021104957483447 iter num 940\n",
            "loss 0.17951977252960205 average time 0.003094726512500756 iter num 960\n",
            "loss 0.32688555121421814 average time 0.003087249664284692 iter num 980\n",
            "loss 0.3036097288131714 average time 0.003081194283995501 iter num 1000\n",
            "loss 0.8889561891555786 average time 0.018335218749871273 iter num 20\n",
            "loss 1.8993678092956543 average time 0.010534296749983695 iter num 40\n",
            "loss 0.5891223549842834 average time 0.007938530583366325 iter num 60\n",
            "loss 2.640817642211914 average time 0.006669821387549746 iter num 80\n",
            "loss 1.0551443099975586 average time 0.0058977133600456 iter num 100\n",
            "loss 0.6058322787284851 average time 0.005368568750054692 iter num 120\n",
            "loss 0.3440724015235901 average time 0.004995450385740697 iter num 140\n",
            "loss 0.47073811292648315 average time 0.004731863862514274 iter num 160\n",
            "loss 0.41415539383888245 average time 0.0045213015389284315 iter num 180\n",
            "loss 0.3649776577949524 average time 0.00435509869004818 iter num 200\n",
            "loss 1.027894377708435 average time 0.0042111629636648025 iter num 220\n",
            "loss 0.34965986013412476 average time 0.004089439212536187 iter num 240\n",
            "loss 0.6903207302093506 average time 0.003986830073098155 iter num 260\n",
            "loss 0.23166823387145996 average time 0.0039024758964712547 iter num 280\n",
            "loss 0.972444474697113 average time 0.0038246907333814306 iter num 300\n",
            "loss 1.2397220134735107 average time 0.0037579383687955216 iter num 320\n",
            "loss 1.1966619491577148 average time 0.0036991700559102516 iter num 340\n",
            "loss 0.5643900632858276 average time 0.0036505932805792124 iter num 360\n",
            "loss 0.3023378849029541 average time 0.003603840276326465 iter num 380\n",
            "loss 0.32240357995033264 average time 0.0035624177375075308 iter num 400\n",
            "loss 0.3202410936355591 average time 0.0035257216523729897 iter num 420\n",
            "loss 0.39794859290122986 average time 0.0034898860204479703 iter num 440\n",
            "loss 0.173851877450943 average time 0.003457585691297066 iter num 460\n",
            "loss 0.22385017573833466 average time 0.003428621089581914 iter num 480\n",
            "loss 0.5142710208892822 average time 0.003401350903990533 iter num 500\n",
            "loss 0.26726099848747253 average time 0.003377126303831364 iter num 520\n",
            "loss 0.2792518436908722 average time 0.0033536211166594714 iter num 540\n",
            "loss 0.477603018283844 average time 0.003333358912504991 iter num 560\n",
            "loss 0.1987641602754593 average time 0.0033138226758731844 iter num 580\n",
            "loss 0.28118571639060974 average time 0.0033081385483425645 iter num 600\n",
            "loss 0.5016887187957764 average time 0.003290903264531798 iter num 620\n",
            "loss 0.387925922870636 average time 0.0032743398890801244 iter num 640\n",
            "loss 0.41153720021247864 average time 0.003258286925767717 iter num 660\n",
            "loss 0.26990067958831787 average time 0.0032426396367715342 iter num 680\n",
            "loss 0.33509647846221924 average time 0.0032285868114403067 iter num 700\n",
            "loss 0.2913132607936859 average time 0.003216119141668767 iter num 720\n",
            "loss 0.22004231810569763 average time 0.0032041264648673736 iter num 740\n",
            "loss 0.17070385813713074 average time 0.0031943336197328837 iter num 760\n",
            "loss 0.2536148428916931 average time 0.0031826950782021576 iter num 780\n",
            "loss 0.14551463723182678 average time 0.003172098333743634 iter num 800\n",
            "loss 0.3191218674182892 average time 0.00316375699756064 iter num 820\n",
            "loss 0.16333317756652832 average time 0.003155040857143918 iter num 840\n",
            "loss 0.10366978496313095 average time 0.003145714717439385 iter num 860\n",
            "loss 0.16199633479118347 average time 0.0031366345579520137 iter num 880\n",
            "loss 0.30428382754325867 average time 0.0031278192988793306 iter num 900\n",
            "loss 0.3129524886608124 average time 0.003119127972810099 iter num 920\n",
            "loss 0.04855397343635559 average time 0.0031112987425331085 iter num 940\n",
            "loss 0.16653741896152496 average time 0.003103837770813319 iter num 960\n",
            "loss 0.15940865874290466 average time 0.003097147264266749 iter num 980\n",
            "loss 0.048793088644742966 average time 0.0030901083129829202 iter num 1000\n",
            "loss 0.19308578968048096 average time 0.018405919799897676 iter num 20\n",
            "loss 0.489471435546875 average time 0.010594738524923741 iter num 40\n",
            "loss 0.8433189392089844 average time 0.008010942966696652 iter num 60\n",
            "loss 4.153400421142578 average time 0.006695014037563851 iter num 80\n",
            "loss 1.6957931518554688 average time 0.005908751470069546 iter num 100\n",
            "loss 1.2153149843215942 average time 0.005382115941711163 iter num 120\n",
            "loss 0.1977895200252533 average time 0.005012210585742391 iter num 140\n",
            "loss 0.434781014919281 average time 0.004732579537562742 iter num 160\n",
            "loss 0.41435056924819946 average time 0.004510679822265552 iter num 180\n",
            "loss 0.40008100867271423 average time 0.004336092420044224 iter num 200\n",
            "loss 0.4024803936481476 average time 0.004199400622796516 iter num 220\n",
            "loss 0.5299096703529358 average time 0.004085831150064223 iter num 240\n",
            "loss 0.35120439529418945 average time 0.003990526065452006 iter num 260\n",
            "loss 0.3584805727005005 average time 0.003909778864350041 iter num 280\n",
            "loss 0.3350667357444763 average time 0.0038339176400586437 iter num 300\n",
            "loss 0.16981112957000732 average time 0.0037665782531973945 iter num 320\n",
            "loss 0.3950748145580292 average time 0.0037066210824217277 iter num 340\n",
            "loss 0.4857759177684784 average time 0.003654154683383442 iter num 360\n",
            "loss 0.4549335241317749 average time 0.0036063569131951417 iter num 380\n",
            "loss 0.49779263138771057 average time 0.003561310225031775 iter num 400\n",
            "loss 0.5067651867866516 average time 0.0035204407548008023 iter num 420\n",
            "loss 0.241105318069458 average time 0.0034927455841294764 iter num 440\n",
            "loss 0.08926334977149963 average time 0.0034591254304636413 iter num 460\n",
            "loss 0.200851172208786 average time 0.0034283795041915254 iter num 480\n",
            "loss 0.2239331305027008 average time 0.0033997209160370402 iter num 500\n",
            "loss 0.1863434910774231 average time 0.0033724746942600456 iter num 520\n",
            "loss 0.28874456882476807 average time 0.0033490450537370904 iter num 540\n",
            "loss 0.27015358209609985 average time 0.0033259470393204537 iter num 560\n",
            "loss 0.28808003664016724 average time 0.0033068749396863556 iter num 580\n",
            "loss 0.2791157364845276 average time 0.003287889850025749 iter num 600\n",
            "loss 0.12395361065864563 average time 0.0032718634145391164 iter num 620\n",
            "loss 0.24056926369667053 average time 0.003254296876588114 iter num 640\n",
            "loss 0.3130122423171997 average time 0.0032384031469932365 iter num 660\n",
            "loss 0.09010190516710281 average time 0.0032240103029567654 iter num 680\n",
            "loss 0.37273404002189636 average time 0.003210447981437028 iter num 700\n",
            "loss 0.39796337485313416 average time 0.003197175020841314 iter num 720\n",
            "loss 0.1691383719444275 average time 0.003185144085155362 iter num 740\n",
            "loss 0.2392125129699707 average time 0.0031765705829074203 iter num 760\n",
            "loss 0.1081140786409378 average time 0.003166341053864203 iter num 780\n",
            "loss 0.074466273188591 average time 0.003158548591266026 iter num 800\n",
            "loss 0.364109069108963 average time 0.003148182697570031 iter num 820\n",
            "loss 0.12548795342445374 average time 0.0031398412047695143 iter num 840\n",
            "loss 0.1574915647506714 average time 0.00313096582907916 iter num 860\n",
            "loss 0.23335584998130798 average time 0.003123109029553978 iter num 880\n",
            "loss 0.13965332508087158 average time 0.0031147309566788156 iter num 900\n",
            "loss 0.29611504077911377 average time 0.003106527584795122 iter num 920\n",
            "loss 0.3802151083946228 average time 0.0031003220744810762 iter num 940\n",
            "loss 0.22763559222221375 average time 0.00309258890105563 iter num 960\n",
            "loss 0.17480456829071045 average time 0.0030854035265459674 iter num 980\n",
            "loss 0.22841420769691467 average time 0.003079425447016547 iter num 1000\n",
            "loss 0.3116415739059448 average time 0.01837502865028 iter num 20\n",
            "loss 1.2143375873565674 average time 0.010557318375140312 iter num 40\n",
            "loss 0.1912650167942047 average time 0.007939140266717003 iter num 60\n",
            "loss 1.6971538066864014 average time 0.006634250537513253 iter num 80\n",
            "loss 0.5843101143836975 average time 0.005852027810014988 iter num 100\n",
            "loss 0.3314933180809021 average time 0.005333074183348193 iter num 120\n",
            "loss 3.55936861038208 average time 0.004966797628614066 iter num 140\n",
            "loss 3.3224868774414062 average time 0.0046910369812735555 iter num 160\n",
            "loss 0.4589812159538269 average time 0.004482328138894647 iter num 180\n",
            "loss 0.3634338080883026 average time 0.004304454499979329 iter num 200\n",
            "loss 1.0797836780548096 average time 0.004160312781806914 iter num 220\n",
            "loss 0.2700105905532837 average time 0.0040453821791667606 iter num 240\n",
            "loss 0.40300625562667847 average time 0.003959377407703029 iter num 260\n",
            "loss 0.5791987180709839 average time 0.0038713852000260627 iter num 280\n",
            "loss 0.3295426666736603 average time 0.003812168476682321 iter num 300\n",
            "loss 0.7038580775260925 average time 0.0037461572156360034 iter num 320\n",
            "loss 0.6299166679382324 average time 0.0036873695264629906 iter num 340\n",
            "loss 0.13029849529266357 average time 0.0036336399305431162 iter num 360\n",
            "loss 0.9408904314041138 average time 0.0035846148236726694 iter num 380\n",
            "loss 0.15129204094409943 average time 0.003541465277489806 iter num 400\n",
            "loss 0.3839053809642792 average time 0.0035028318761717294 iter num 420\n",
            "loss 0.5335510969161987 average time 0.0034687834613371456 iter num 440\n",
            "loss 0.3055541515350342 average time 0.003435753184753001 iter num 460\n",
            "loss 0.09892973303794861 average time 0.003406524229133841 iter num 480\n",
            "loss 0.33941781520843506 average time 0.0033868897019528957 iter num 500\n",
            "loss 0.28352469205856323 average time 0.0033660934941823284 iter num 520\n",
            "loss 0.09390299022197723 average time 0.003348944783283514 iter num 540\n",
            "loss 0.20306545495986938 average time 0.003326035676734916 iter num 560\n",
            "loss 0.8481838703155518 average time 0.0033046687982246584 iter num 580\n",
            "loss 0.24123357236385345 average time 0.003290118996616608 iter num 600\n",
            "loss 0.267516553401947 average time 0.003274538661242977 iter num 620\n",
            "loss 0.23555678129196167 average time 0.0032587233655760883 iter num 640\n",
            "loss 0.19922953844070435 average time 0.003245628131772912 iter num 660\n",
            "loss 0.3383484482765198 average time 0.003234304516134965 iter num 680\n",
            "loss 0.27900856733322144 average time 0.003227308641391054 iter num 700\n",
            "loss 0.11508219689130783 average time 0.003213822036079566 iter num 720\n",
            "loss 0.19392070174217224 average time 0.0032006202296936347 iter num 740\n",
            "loss 0.254505455493927 average time 0.003188167567063111 iter num 760\n",
            "loss 0.2226036787033081 average time 0.0031761955999545766 iter num 780\n",
            "loss 0.11704139411449432 average time 0.003165104656204676 iter num 800\n",
            "loss 0.11804242432117462 average time 0.003154146803608899 iter num 820\n",
            "loss 0.16499754786491394 average time 0.003144022002329837 iter num 840\n",
            "loss 0.500676691532135 average time 0.003135126309250556 iter num 860\n",
            "loss 0.19072458148002625 average time 0.003126071311314924 iter num 880\n",
            "loss 0.10098780691623688 average time 0.0031194366243956512 iter num 900\n",
            "loss 0.1309201717376709 average time 0.003110711920599778 iter num 920\n",
            "loss 0.17263945937156677 average time 0.0031029091042058853 iter num 940\n",
            "loss 0.13357138633728027 average time 0.003095090298910463 iter num 960\n",
            "loss 0.10284577310085297 average time 0.0030894550458655506 iter num 980\n",
            "loss 0.08353699743747711 average time 0.003082051563947971 iter num 1000\n",
            "loss 0.5223273038864136 average time 0.01839645139989443 iter num 20\n",
            "loss 0.3196045458316803 average time 0.01054880177493942 iter num 40\n",
            "loss 0.3118531107902527 average time 0.007934119816673047 iter num 60\n",
            "loss 0.17464657127857208 average time 0.006624083049996443 iter num 80\n",
            "loss 0.34793877601623535 average time 0.005844149989970901 iter num 100\n",
            "loss 0.9699432253837585 average time 0.005320228599975963 iter num 120\n",
            "loss 0.7989553213119507 average time 0.004949779842809221 iter num 140\n",
            "loss 0.8134138584136963 average time 0.004679726062408918 iter num 160\n",
            "loss 0.2734507918357849 average time 0.004464836605428799 iter num 180\n",
            "loss 1.4115854501724243 average time 0.0042928421698889 iter num 200\n",
            "loss 0.40669894218444824 average time 0.004164507190820256 iter num 220\n",
            "loss 0.40414226055145264 average time 0.004060554466597447 iter num 240\n",
            "loss 0.23686569929122925 average time 0.003957806903753617 iter num 260\n",
            "loss 0.4641825556755066 average time 0.003885360910628931 iter num 280\n",
            "loss 0.6709649562835693 average time 0.0038168637566013785 iter num 300\n",
            "loss 0.28843724727630615 average time 0.0037573954624519957 iter num 320\n",
            "loss 0.4472822844982147 average time 0.003700204361720192 iter num 340\n",
            "loss 0.38092470169067383 average time 0.0036475047916206273 iter num 360\n",
            "loss 0.6384376287460327 average time 0.0035982699683747917 iter num 380\n",
            "loss 0.347494512796402 average time 0.0035547626499646866 iter num 400\n",
            "loss 0.18365755677223206 average time 0.003513649028532416 iter num 420\n",
            "loss 0.22654461860656738 average time 0.0034824692090420616 iter num 440\n",
            "loss 0.17845885455608368 average time 0.0034519741412662804 iter num 460\n",
            "loss 0.18798072636127472 average time 0.0034199375228809005 iter num 480\n",
            "loss 0.27813857793807983 average time 0.0033922020479767523 iter num 500\n",
            "loss 0.18501827120780945 average time 0.0033667209384370487 iter num 520\n",
            "loss 0.3889787495136261 average time 0.003343782798128814 iter num 540\n",
            "loss 0.1918318271636963 average time 0.003338635792835833 iter num 560\n",
            "loss 0.10629644989967346 average time 0.0033166303999835156 iter num 580\n",
            "loss 0.21129828691482544 average time 0.003296314464984486 iter num 600\n",
            "loss 0.22608011960983276 average time 0.0032766138903166245 iter num 620\n",
            "loss 0.08183092623949051 average time 0.0032831879968711064 iter num 640\n",
            "loss 0.2870948314666748 average time 0.0032658887454503696 iter num 660\n",
            "loss 0.14545118808746338 average time 0.003252218601464312 iter num 680\n",
            "loss 0.17375792562961578 average time 0.003238539954277907 iter num 700\n",
            "loss 0.13241684436798096 average time 0.0032268252652733684 iter num 720\n",
            "loss 0.08484329283237457 average time 0.003213444683781229 iter num 740\n",
            "loss 0.2771849036216736 average time 0.0032007042539517945 iter num 760\n",
            "loss 0.07103703916072845 average time 0.0031882512628260136 iter num 780\n",
            "loss 0.17139053344726562 average time 0.0031758355512579326 iter num 800\n",
            "loss 0.14908139407634735 average time 0.003165928065859256 iter num 820\n",
            "loss 0.13158470392227173 average time 0.0031554165809579682 iter num 840\n",
            "loss 0.22241781651973724 average time 0.0031450063081413034 iter num 860\n",
            "loss 0.1826726496219635 average time 0.0031351936954520584 iter num 880\n",
            "loss 0.14991772174835205 average time 0.0031256800788873485 iter num 900\n",
            "loss 0.2138494849205017 average time 0.0031185000423924383 iter num 920\n",
            "loss 0.14596077799797058 average time 0.0031106158319144403 iter num 940\n",
            "loss 0.18195563554763794 average time 0.00310402311875464 iter num 960\n",
            "loss 0.23830646276474 average time 0.003096461946940081 iter num 980\n",
            "loss 0.15389372408390045 average time 0.003088485614005549 iter num 1000\n",
            "loss 0.6768020391464233 average time 0.018366700450042118 iter num 20\n",
            "loss 1.0005009174346924 average time 0.010546966425044957 iter num 40\n",
            "loss 0.2952405512332916 average time 0.007928474483439156 iter num 60\n",
            "loss 0.36360567808151245 average time 0.006624854212577702 iter num 80\n",
            "loss 0.329331636428833 average time 0.005848266770117334 iter num 100\n",
            "loss 1.1034302711486816 average time 0.005333491991723349 iter num 120\n",
            "loss 0.3537858724594116 average time 0.004976906521473471 iter num 140\n",
            "loss 1.4031652212142944 average time 0.00469481722503815 iter num 160\n",
            "loss 0.1618340164422989 average time 0.004472579222248088 iter num 180\n",
            "loss 0.13842254877090454 average time 0.004294620455020777 iter num 200\n",
            "loss 0.5569814443588257 average time 0.004152307381818074 iter num 220\n",
            "loss 0.14809733629226685 average time 0.004041706595838453 iter num 240\n",
            "loss 2.435246467590332 average time 0.003947188865388923 iter num 260\n",
            "loss 1.9779433012008667 average time 0.0038655373642995984 iter num 280\n",
            "loss 0.47875162959098816 average time 0.003789458730007027 iter num 300\n",
            "loss 1.0670700073242188 average time 0.0037256135718905627 iter num 320\n",
            "loss 0.5857253670692444 average time 0.0036734308147167802 iter num 340\n",
            "loss 0.2640165686607361 average time 0.003622594044453662 iter num 360\n",
            "loss 0.6337449550628662 average time 0.0035757572605210667 iter num 380\n",
            "loss 2.4031338691711426 average time 0.003535185009991437 iter num 400\n",
            "loss 0.16726374626159668 average time 0.0034952457237956143 iter num 420\n",
            "loss 0.46607157588005066 average time 0.003459224381805887 iter num 440\n",
            "loss 0.4258001446723938 average time 0.0034283793543300302 iter num 460\n",
            "loss 0.3036082983016968 average time 0.0033984877458048384 iter num 480\n",
            "loss 0.19177766144275665 average time 0.0033761644159676506 iter num 500\n",
            "loss 0.1315324306488037 average time 0.0033501371788028896 iter num 520\n",
            "loss 0.33462393283843994 average time 0.003326786351799119 iter num 540\n",
            "loss 0.15141448378562927 average time 0.0033051292695972733 iter num 560\n",
            "loss 0.4918956160545349 average time 0.003284435313751852 iter num 580\n",
            "loss 0.20878422260284424 average time 0.0032648927182981425 iter num 600\n",
            "loss 0.15766167640686035 average time 0.0032470882789986657 iter num 620\n",
            "loss 0.2130938172340393 average time 0.0032298115640287508 iter num 640\n",
            "loss 0.34169793128967285 average time 0.0032163304499700836 iter num 660\n",
            "loss 0.22844617068767548 average time 0.003201929424968137 iter num 680\n",
            "loss 0.3334621787071228 average time 0.0031890217356859854 iter num 700\n",
            "loss 0.10882945358753204 average time 0.0031758370263661262 iter num 720\n",
            "loss 0.07024909555912018 average time 0.0031641913770112592 iter num 740\n",
            "loss 0.1399463564157486 average time 0.0031521543736720272 iter num 760\n",
            "loss 0.1294250786304474 average time 0.0031403919230610765 iter num 780\n",
            "loss 0.24446548521518707 average time 0.0031317534424852057 iter num 800\n",
            "loss 0.15820562839508057 average time 0.0031274279243783585 iter num 820\n",
            "loss 0.1861075460910797 average time 0.003118390516658023 iter num 840\n",
            "loss 0.1420309841632843 average time 0.00310861354185384 iter num 860\n",
            "loss 0.2682420313358307 average time 0.003099544137498097 iter num 880\n",
            "loss 0.15824846923351288 average time 0.0030903753355556144 iter num 900\n",
            "loss 0.20728495717048645 average time 0.0030815963880385148 iter num 920\n",
            "loss 0.11539483070373535 average time 0.0030734586010615376 iter num 940\n",
            "loss 0.11901135742664337 average time 0.0030703214260408155 iter num 960\n",
            "loss 0.2874390780925751 average time 0.003066230884694366 iter num 980\n",
            "loss 0.18858717381954193 average time 0.0030674595499986025 iter num 1000\n",
            "loss 1.6874778270721436 average time 0.018382351899799688 iter num 20\n",
            "loss 0.6323665380477905 average time 0.010543924874946242 iter num 40\n",
            "loss 0.13430088758468628 average time 0.007963467983275525 iter num 60\n",
            "loss 0.7113097310066223 average time 0.006653834674943937 iter num 80\n",
            "loss 0.23553045094013214 average time 0.005864920139920286 iter num 100\n",
            "loss 0.5500199794769287 average time 0.00533639132489346 iter num 120\n",
            "loss 0.25542837381362915 average time 0.0049594963570338485 iter num 140\n",
            "loss 0.513588547706604 average time 0.004677287124900431 iter num 160\n",
            "loss 1.7050302028656006 average time 0.004461533161005112 iter num 180\n",
            "loss 0.427736759185791 average time 0.004286676179908681 iter num 200\n",
            "loss 6.4300994873046875 average time 0.004144330368093176 iter num 220\n",
            "loss 1.9948278665542603 average time 0.004022563849950226 iter num 240\n",
            "loss 1.0669596195220947 average time 0.003924011534588947 iter num 260\n",
            "loss 0.5920149087905884 average time 0.003843255921427564 iter num 280\n",
            "loss 0.9345018863677979 average time 0.003770229896666327 iter num 300\n",
            "loss 0.41933202743530273 average time 0.0037028715312317217 iter num 320\n",
            "loss 0.8035685420036316 average time 0.003643569573491464 iter num 340\n",
            "loss 0.5699586272239685 average time 0.0035940565777562166 iter num 360\n",
            "loss 0.40259015560150146 average time 0.0035517785262862544 iter num 380\n",
            "loss 0.24890564382076263 average time 0.003509311442485341 iter num 400\n",
            "loss 0.3506162166595459 average time 0.003473835285707797 iter num 420\n",
            "loss 0.3170192837715149 average time 0.0034388377363525663 iter num 440\n",
            "loss 0.29067981243133545 average time 0.0034069524130364184 iter num 460\n",
            "loss 0.10988222807645798 average time 0.0033833807937450424 iter num 480\n",
            "loss 0.19143715500831604 average time 0.0033596177879880998 iter num 500\n",
            "loss 0.29182231426239014 average time 0.0033361337230627002 iter num 520\n",
            "loss 0.29257136583328247 average time 0.0033130231444408343 iter num 540\n",
            "loss 0.1748819649219513 average time 0.0032925451250028865 iter num 560\n",
            "loss 0.11231931298971176 average time 0.0032719828931006083 iter num 580\n",
            "loss 0.1523374319076538 average time 0.0032527416299975207 iter num 600\n",
            "loss 0.2932935953140259 average time 0.003235582053222911 iter num 620\n",
            "loss 0.08571156859397888 average time 0.0032186967468703642 iter num 640\n",
            "loss 0.2122754007577896 average time 0.0032025278363603735 iter num 660\n",
            "loss 0.11541254073381424 average time 0.003189415235288727 iter num 680\n",
            "loss 0.19899216294288635 average time 0.003176091644272674 iter num 700\n",
            "loss 0.1304870843887329 average time 0.003162373755546671 iter num 720\n",
            "loss 0.11374670267105103 average time 0.0031492965229665206 iter num 740\n",
            "loss 0.08605556190013885 average time 0.003137289482889939 iter num 760\n",
            "loss 0.09716737270355225 average time 0.0031264612564066343 iter num 780\n",
            "loss 0.17599497735500336 average time 0.0031157190087537858 iter num 800\n",
            "loss 0.12159159034490585 average time 0.003105771385364234 iter num 820\n",
            "loss 0.16757255792617798 average time 0.003096258752380198 iter num 840\n",
            "loss 0.3468541204929352 average time 0.003086971284878822 iter num 860\n",
            "loss 0.1497671753168106 average time 0.003078227029540027 iter num 880\n",
            "loss 0.2160043716430664 average time 0.0030700552755519714 iter num 900\n",
            "loss 0.1663667857646942 average time 0.003061526530435636 iter num 920\n",
            "loss 0.0936044231057167 average time 0.003053900925537396 iter num 940\n",
            "loss 0.3401811420917511 average time 0.0030462888104276923 iter num 960\n",
            "loss 0.1735498011112213 average time 0.0030394032122581403 iter num 980\n",
            "loss 0.3618594706058502 average time 0.003036878833017909 iter num 1000\n",
            "loss 0.16256846487522125 average time 0.018359753149798052 iter num 20\n",
            "loss 0.14556503295898438 average time 0.010529138999982025 iter num 40\n",
            "loss 0.3410208821296692 average time 0.007935445883291928 iter num 60\n",
            "loss 0.4095748960971832 average time 0.006638951837521745 iter num 80\n",
            "loss 0.45785969495773315 average time 0.005848435540010541 iter num 100\n",
            "loss 0.2921033501625061 average time 0.00531968184999035 iter num 120\n",
            "loss 0.26166966557502747 average time 0.004942040192807846 iter num 140\n",
            "loss 0.2120681256055832 average time 0.004660930237434968 iter num 160\n",
            "loss 0.3427320718765259 average time 0.004441439811075219 iter num 180\n",
            "loss 0.2138511687517166 average time 0.004265993790022548 iter num 200\n",
            "loss 0.12187202274799347 average time 0.004122695686394515 iter num 220\n",
            "loss 0.47593411803245544 average time 0.004004350979221272 iter num 240\n",
            "loss 0.2003766894340515 average time 0.0039052664423462166 iter num 260\n",
            "loss 0.47502660751342773 average time 0.003820088721470581 iter num 280\n",
            "loss 0.4921262860298157 average time 0.0037465714200455597 iter num 300\n",
            "loss 0.48322153091430664 average time 0.0036827762031748533 iter num 320\n",
            "loss 0.4646068513393402 average time 0.0036248889706364616 iter num 340\n",
            "loss 0.1885768175125122 average time 0.003586737444483232 iter num 360\n",
            "loss 0.15171882510185242 average time 0.0035452828763673574 iter num 380\n",
            "loss 0.26755642890930176 average time 0.00350532192755054 iter num 400\n",
            "loss 0.5050338506698608 average time 0.0034729290786258173 iter num 420\n",
            "loss 0.22844475507736206 average time 0.0034459882455104723 iter num 440\n",
            "loss 0.16763471066951752 average time 0.003418298389177558 iter num 460\n",
            "loss 0.3652360439300537 average time 0.0033887055271179635 iter num 480\n",
            "loss 0.5387002825737 average time 0.0033611060960174657 iter num 500\n",
            "loss 0.1998148113489151 average time 0.0033519170327053873 iter num 520\n",
            "loss 0.3335721790790558 average time 0.0033268729537229338 iter num 540\n",
            "loss 0.366336464881897 average time 0.0033090759428854913 iter num 560\n",
            "loss 0.21927669644355774 average time 0.0032893784276203752 iter num 580\n",
            "loss 0.08090296387672424 average time 0.0032695891900372466 iter num 600\n",
            "loss 0.2157205045223236 average time 0.0032523974419687404 iter num 620\n",
            "loss 0.08087232708930969 average time 0.0032348000625404437 iter num 640\n",
            "loss 0.17510879039764404 average time 0.0032188349151924325 iter num 660\n",
            "loss 0.2772098481655121 average time 0.0032048111838642347 iter num 680\n",
            "loss 0.18859250843524933 average time 0.00319000659289616 iter num 700\n",
            "loss 0.18026575446128845 average time 0.003176889602819857 iter num 720\n",
            "loss 0.3054927587509155 average time 0.0031675032270622734 iter num 740\n",
            "loss 0.15880760550498962 average time 0.0031570520579407456 iter num 760\n",
            "loss 0.1932128667831421 average time 0.0031468479320933395 iter num 780\n",
            "loss 0.21935603022575378 average time 0.0031351224487866603 iter num 800\n",
            "loss 0.2708761990070343 average time 0.0031260758415001186 iter num 820\n",
            "loss 0.3003547787666321 average time 0.003118034021458914 iter num 840\n",
            "loss 0.27686768770217896 average time 0.003108563336073255 iter num 860\n",
            "loss 0.15208566188812256 average time 0.0031015694352556074 iter num 880\n",
            "loss 0.2555406093597412 average time 0.0030956734400287033 iter num 900\n",
            "loss 0.4716871976852417 average time 0.0030912464554662816 iter num 920\n",
            "loss 0.15674549341201782 average time 0.003086337639396856 iter num 940\n",
            "loss 0.2065572887659073 average time 0.0030808632354497453 iter num 960\n",
            "loss 0.10927657037973404 average time 0.003073285004114839 iter num 980\n",
            "loss 0.18769222497940063 average time 0.0030656064160302777 iter num 1000\n",
            "loss 0.490934282541275 average time 0.018240407000121195 iter num 20\n",
            "loss 0.8645169138908386 average time 0.010465505475121973 iter num 40\n",
            "loss 0.28698670864105225 average time 0.007888883983287086 iter num 60\n",
            "loss 5.219671726226807 average time 0.006611614199960059 iter num 80\n",
            "loss 0.358294814825058 average time 0.00585038553996128 iter num 100\n",
            "loss 0.34292057156562805 average time 0.005321455699974346 iter num 120\n",
            "loss 1.4956904649734497 average time 0.004956054649976847 iter num 140\n",
            "loss 1.7892035245895386 average time 0.00469387782496824 iter num 160\n",
            "loss 0.575913667678833 average time 0.004476267783320509 iter num 180\n",
            "loss 0.30131062865257263 average time 0.004298547184998824 iter num 200\n",
            "loss 0.247339129447937 average time 0.004153512359111614 iter num 220\n",
            "loss 0.5775307416915894 average time 0.004036315558361518 iter num 240\n",
            "loss 0.24355056881904602 average time 0.003933356615415016 iter num 260\n",
            "loss 0.19484645128250122 average time 0.003858747367881473 iter num 280\n",
            "loss 0.47550445795059204 average time 0.0037826622066738005 iter num 300\n",
            "loss 0.4722774028778076 average time 0.003715935818763683 iter num 320\n",
            "loss 0.20120306313037872 average time 0.0036592246441239907 iter num 340\n",
            "loss 0.22599174082279205 average time 0.0036111112527780482 iter num 360\n",
            "loss 0.08688607811927795 average time 0.0035634397973664913 iter num 380\n",
            "loss 0.4983000159263611 average time 0.003521590332507003 iter num 400\n",
            "loss 0.5683085918426514 average time 0.003483594647635376 iter num 420\n",
            "loss 0.2843535244464874 average time 0.0034476925909116703 iter num 440\n",
            "loss 0.5996670126914978 average time 0.0034142985239075485 iter num 460\n",
            "loss 0.18590620160102844 average time 0.003391526741669774 iter num 480\n",
            "loss 0.2869999408721924 average time 0.0033652307160009515 iter num 500\n",
            "loss 0.5080858469009399 average time 0.003340351373085818 iter num 520\n",
            "loss 0.1453775316476822 average time 0.003317488979640378 iter num 540\n",
            "loss 0.2672603130340576 average time 0.003297922339298306 iter num 560\n",
            "loss 0.1836819052696228 average time 0.0032767411293175897 iter num 580\n",
            "loss 0.1528344750404358 average time 0.003257539773336854 iter num 600\n",
            "loss 0.16762292385101318 average time 0.0032407773967802755 iter num 620\n",
            "loss 0.09645789861679077 average time 0.003223884825004575 iter num 640\n",
            "loss 0.3501552641391754 average time 0.003207737600002998 iter num 660\n",
            "loss 0.28209495544433594 average time 0.00319330123971293 iter num 680\n",
            "loss 0.1176665648818016 average time 0.0031791300071563455 iter num 700\n",
            "loss 0.1629772186279297 average time 0.0031662062055728612 iter num 720\n",
            "loss 0.05485744774341583 average time 0.003154428778391259 iter num 740\n",
            "loss 0.24349023401737213 average time 0.0031442281236961304 iter num 760\n",
            "loss 0.29317715764045715 average time 0.0031347675500210943 iter num 780\n",
            "loss 0.33504727482795715 average time 0.003125307801269628 iter num 800\n",
            "loss 0.1700933873653412 average time 0.0031227517512400858 iter num 820\n",
            "loss 0.14890334010124207 average time 0.003113101779776376 iter num 840\n",
            "loss 0.24131833016872406 average time 0.0031043439476889033 iter num 860\n",
            "loss 0.2480483502149582 average time 0.0030958978466080886 iter num 880\n",
            "loss 0.31768763065338135 average time 0.0030872368600103075 iter num 900\n",
            "loss 0.1233990415930748 average time 0.00307856802067007 iter num 920\n",
            "loss 0.3812950849533081 average time 0.003070819851082172 iter num 940\n",
            "loss 0.08165569603443146 average time 0.0030634380416832605 iter num 960\n",
            "loss 0.24448880553245544 average time 0.0030554048479792314 iter num 980\n",
            "loss 0.22004292905330658 average time 0.003049067568024839 iter num 1000\n",
            "loss 0.2786230444908142 average time 0.018328123750143276 iter num 20\n",
            "loss 0.19163575768470764 average time 0.010531681324846432 iter num 40\n",
            "loss 0.5854172706604004 average time 0.007923920616606968 iter num 60\n",
            "loss 0.6424150466918945 average time 0.006617325549950692 iter num 80\n",
            "loss 0.5505964756011963 average time 0.005841788639972947 iter num 100\n",
            "loss 0.38110142946243286 average time 0.005322134466632633 iter num 120\n",
            "loss 0.5358020663261414 average time 0.004953834899944403 iter num 140\n",
            "loss 0.8212366104125977 average time 0.004677920268704838 iter num 160\n",
            "loss 0.34127479791641235 average time 0.004459426483299467 iter num 180\n",
            "loss 0.33024361729621887 average time 0.0042897136049759865 iter num 200\n",
            "loss 0.2500336766242981 average time 0.0041481802181806415 iter num 220\n",
            "loss 0.18622052669525146 average time 0.004027183995829849 iter num 240\n",
            "loss 0.515132486820221 average time 0.003928031515393881 iter num 260\n",
            "loss 0.9677781462669373 average time 0.0038407840500050434 iter num 280\n",
            "loss 0.7333654761314392 average time 0.003766499016674061 iter num 300\n",
            "loss 0.24908386170864105 average time 0.0037061790156315056 iter num 320\n",
            "loss 0.2086624950170517 average time 0.0036470401558825172 iter num 340\n",
            "loss 0.22475787997245789 average time 0.0036063308305529064 iter num 360\n",
            "loss 0.4535951018333435 average time 0.003566680744719825 iter num 380\n",
            "loss 0.3206884264945984 average time 0.003523364734983261 iter num 400\n",
            "loss 0.15606212615966797 average time 0.003484600133322688 iter num 420\n",
            "loss 0.36806362867355347 average time 0.003448419722727439 iter num 440\n",
            "loss 0.4463057518005371 average time 0.0034178892369630415 iter num 460\n",
            "loss 0.34908103942871094 average time 0.0033901075833417354 iter num 480\n",
            "loss 0.4200827479362488 average time 0.0033684897540042585 iter num 500\n",
            "loss 0.10220590233802795 average time 0.0033445145903897356 iter num 520\n",
            "loss 0.6230462789535522 average time 0.0033219937500150454 iter num 540\n",
            "loss 0.3618581295013428 average time 0.0032997034357224817 iter num 560\n",
            "loss 0.06364244222640991 average time 0.003279276194835206 iter num 580\n",
            "loss 0.624813437461853 average time 0.003261108976679073 iter num 600\n",
            "loss 0.24484100937843323 average time 0.003248067695169025 iter num 620\n",
            "loss 0.3393423557281494 average time 0.0032317847812606713 iter num 640\n",
            "loss 0.38270893692970276 average time 0.003217851256070417 iter num 660\n",
            "loss 0.5134084820747375 average time 0.0032099235294187085 iter num 680\n",
            "loss 0.15988576412200928 average time 0.0031952042442935633 iter num 700\n",
            "loss 0.4991505742073059 average time 0.0031806607111219717 iter num 720\n",
            "loss 0.1411556601524353 average time 0.0031711136554214456 iter num 740\n",
            "loss 0.08680159598588943 average time 0.0031614101500149682 iter num 760\n",
            "loss 0.29902002215385437 average time 0.003149301383342763 iter num 780\n",
            "loss 0.10428295284509659 average time 0.003142058785001609 iter num 800\n",
            "loss 0.13275764882564545 average time 0.003134682025605931 iter num 820\n",
            "loss 0.3909882605075836 average time 0.0031242336702299715 iter num 840\n",
            "loss 0.37103867530822754 average time 0.003114419676734711 iter num 860\n",
            "loss 0.21360115706920624 average time 0.003106378545443146 iter num 880\n",
            "loss 0.15576530992984772 average time 0.0030980209966502215 iter num 900\n",
            "loss 0.2955833673477173 average time 0.0030936096054238475 iter num 920\n",
            "loss 0.2745217978954315 average time 0.003085518320202685 iter num 940\n",
            "loss 0.06613239645957947 average time 0.0030793311791607416 iter num 960\n",
            "loss 0.12305663526058197 average time 0.003071579912241815 iter num 980\n",
            "loss 0.17009025812149048 average time 0.003067093804997057 iter num 1000\n",
            "loss 0.7508070468902588 average time 0.01845331644990438 iter num 20\n",
            "loss 0.3944964110851288 average time 0.010706629974902172 iter num 40\n",
            "loss 0.34529709815979004 average time 0.008052536916632864 iter num 60\n",
            "loss 0.23873862624168396 average time 0.0067154491249993955 iter num 80\n",
            "loss 0.6383771896362305 average time 0.005928269570031262 iter num 100\n",
            "loss 0.8433952331542969 average time 0.005388430683357607 iter num 120\n",
            "loss 0.3463517427444458 average time 0.005006749235716207 iter num 140\n",
            "loss 0.36078354716300964 average time 0.004731458037508673 iter num 160\n",
            "loss 0.43088680505752563 average time 0.004507856350008095 iter num 180\n",
            "loss 0.6447105407714844 average time 0.004325854845010326 iter num 200\n",
            "loss 0.24045589566230774 average time 0.004177191481821038 iter num 220\n",
            "loss 0.452041357755661 average time 0.00405671607916247 iter num 240\n",
            "loss 0.21965961158275604 average time 0.00395547688077176 iter num 260\n",
            "loss 0.384490042924881 average time 0.003872124417862973 iter num 280\n",
            "loss 0.40352827310562134 average time 0.0037957369633537987 iter num 300\n",
            "loss 0.17054980993270874 average time 0.0037282498500474047 iter num 320\n",
            "loss 0.16889530420303345 average time 0.003673657285354934 iter num 340\n",
            "loss 0.2180967926979065 average time 0.0036196324389493385 iter num 360\n",
            "loss 0.4363313913345337 average time 0.003574612289522568 iter num 380\n",
            "loss 0.23862172663211823 average time 0.0035308652650292063 iter num 400\n",
            "loss 0.5448472499847412 average time 0.003497508850012396 iter num 420\n",
            "loss 0.2624049782752991 average time 0.0034620242477434327 iter num 440\n",
            "loss 0.3588014841079712 average time 0.003429228400004238 iter num 460\n",
            "loss 0.14125469326972961 average time 0.003398874222921222 iter num 480\n",
            "loss 0.28246188163757324 average time 0.003369957388007606 iter num 500\n",
            "loss 0.21872478723526 average time 0.0033458084865427597 iter num 520\n",
            "loss 0.13973727822303772 average time 0.0033215100444370666 iter num 540\n",
            "loss 0.20948871970176697 average time 0.0032996472142778135 iter num 560\n",
            "loss 0.4099465608596802 average time 0.0032777986430997334 iter num 580\n",
            "loss 0.31456777453422546 average time 0.0032667707149994386 iter num 600\n",
            "loss 0.25116509199142456 average time 0.003250029077418965 iter num 620\n",
            "loss 0.2079269289970398 average time 0.003234966098438008 iter num 640\n",
            "loss 0.10954128205776215 average time 0.0032190503303023764 iter num 660\n",
            "loss 0.08040957152843475 average time 0.003206589998516767 iter num 680\n",
            "loss 0.06683652102947235 average time 0.003192352242843169 iter num 700\n",
            "loss 0.10105401277542114 average time 0.0031788920541506132 iter num 720\n",
            "loss 0.11313465237617493 average time 0.0031668622986339994 iter num 740\n",
            "loss 0.06743445992469788 average time 0.0031550054618276735 iter num 760\n",
            "loss 0.1297130584716797 average time 0.003142970388447653 iter num 780\n",
            "loss 0.16132017970085144 average time 0.00313210478998144 iter num 800\n",
            "loss 0.1617131531238556 average time 0.003121533490229922 iter num 820\n",
            "loss 0.0722188726067543 average time 0.0031112332428381794 iter num 840\n",
            "loss 0.10727880150079727 average time 0.0031015037197438117 iter num 860\n",
            "loss 0.40359362959861755 average time 0.0030917369658833528 iter num 880\n",
            "loss 0.16428251564502716 average time 0.0030825046833120318 iter num 900\n",
            "loss 0.18592283129692078 average time 0.0030749783554157423 iter num 920\n",
            "loss 0.2797337472438812 average time 0.0030687732329615176 iter num 940\n",
            "loss 0.07706844061613083 average time 0.003061764562484844 iter num 960\n",
            "loss 0.28968632221221924 average time 0.0030539543795830284 iter num 980\n",
            "loss 0.12550358474254608 average time 0.0030465183169908414 iter num 1000\n",
            "loss 0.14471547305583954 average time 0.018523845899926526 iter num 20\n",
            "loss 0.7895286083221436 average time 0.0106151318749653 iter num 40\n",
            "loss 0.5562557578086853 average time 0.007999818849930307 iter num 60\n",
            "loss 0.3789157271385193 average time 0.006672439787439544 iter num 80\n",
            "loss 0.6556100845336914 average time 0.005874290519932402 iter num 100\n",
            "loss 1.4272009134292603 average time 0.0053509631416091 iter num 120\n",
            "loss 0.8702068328857422 average time 0.0049668585856904555 iter num 140\n",
            "loss 0.17488723993301392 average time 0.004686195331225917 iter num 160\n",
            "loss 0.5294122695922852 average time 0.004493843638859592 iter num 180\n",
            "loss 1.4500625133514404 average time 0.004314453199995114 iter num 200\n",
            "loss 0.3630982041358948 average time 0.00416777833635768 iter num 220\n",
            "loss 0.3022429347038269 average time 0.0040473055999806695 iter num 240\n",
            "loss 0.6292381286621094 average time 0.0039461540730511705 iter num 260\n",
            "loss 0.23610985279083252 average time 0.003865894249975099 iter num 280\n",
            "loss 0.2745243310928345 average time 0.003787388539967651 iter num 300\n",
            "loss 0.26725462079048157 average time 0.0037211686374746477 iter num 320\n",
            "loss 0.19306717813014984 average time 0.003659749370559867 iter num 340\n",
            "loss 0.7786564826965332 average time 0.0036066266472011598 iter num 360\n",
            "loss 0.2101225107908249 average time 0.003560330984198931 iter num 380\n",
            "loss 0.2015475332736969 average time 0.0035161260449876864 iter num 400\n",
            "loss 0.4365423321723938 average time 0.003497244669034401 iter num 420\n",
            "loss 0.19329562783241272 average time 0.0034612590818183394 iter num 440\n",
            "loss 0.07978630810976028 average time 0.003428818871737388 iter num 460\n",
            "loss 0.24980810284614563 average time 0.003400071364580981 iter num 480\n",
            "loss 0.20597991347312927 average time 0.0033727228800016747 iter num 500\n",
            "loss 0.22130361199378967 average time 0.003348573050002065 iter num 520\n",
            "loss 0.2595159411430359 average time 0.0033256057333380376 iter num 540\n",
            "loss 0.21848240494728088 average time 0.0033038700785807252 iter num 560\n",
            "loss 0.15911228954792023 average time 0.0032834629017245254 iter num 580\n",
            "loss 0.19673171639442444 average time 0.0032645052166723567 iter num 600\n",
            "loss 0.2653382420539856 average time 0.003253706748387964 iter num 620\n",
            "loss 0.13160981237888336 average time 0.003237399746868164 iter num 640\n",
            "loss 0.20402735471725464 average time 0.0032269275818097493 iter num 660\n",
            "loss 0.1713627427816391 average time 0.003212665777934543 iter num 680\n",
            "loss 0.1367214322090149 average time 0.003198643452851684 iter num 700\n",
            "loss 0.1511254608631134 average time 0.0031882165875029185 iter num 720\n",
            "loss 0.7262756824493408 average time 0.0031748068256830094 iter num 740\n",
            "loss 0.2347773313522339 average time 0.0031617581302725737 iter num 760\n",
            "loss 0.17324893176555634 average time 0.003149844437193212 iter num 780\n",
            "loss 0.13496540486812592 average time 0.0031382261925068634 iter num 800\n",
            "loss 0.12892299890518188 average time 0.003127471539032629 iter num 820\n",
            "loss 0.23682901263237 average time 0.0031170072964392774 iter num 840\n",
            "loss 0.22301682829856873 average time 0.0031073769395461143 iter num 860\n",
            "loss 0.16116070747375488 average time 0.003098096713644984 iter num 880\n",
            "loss 0.042824529111385345 average time 0.003089555433339734 iter num 900\n",
            "loss 0.29458776116371155 average time 0.0030832575087001517 iter num 920\n",
            "loss 0.10268275439739227 average time 0.0030766080042570697 iter num 940\n",
            "loss 0.26026827096939087 average time 0.0030740315270899525 iter num 960\n",
            "loss 0.24801820516586304 average time 0.0030663877755169053 iter num 980\n",
            "loss 0.08323615789413452 average time 0.0030596341180025776 iter num 1000\n",
            "loss 0.24001269042491913 average time 0.018360346400004345 iter num 20\n",
            "loss 0.9991973638534546 average time 0.010525112549885307 iter num 40\n",
            "loss 1.2961084842681885 average time 0.007912568516591516 iter num 60\n",
            "loss 0.48193588852882385 average time 0.006645011087448438 iter num 80\n",
            "loss 0.29649659991264343 average time 0.005858062419956695 iter num 100\n",
            "loss 0.136488139629364 average time 0.005329374558292936 iter num 120\n",
            "loss 0.23273965716362 average time 0.004958745378475474 iter num 140\n",
            "loss 2.037867546081543 average time 0.004699007243686992 iter num 160\n",
            "loss 1.2208757400512695 average time 0.004476777394423455 iter num 180\n",
            "loss 0.6490160226821899 average time 0.004309216244973868 iter num 200\n",
            "loss 0.5184280872344971 average time 0.004162160640862567 iter num 220\n",
            "loss 0.20060443878173828 average time 0.0040423114207821225 iter num 240\n",
            "loss 0.5264572501182556 average time 0.003943878842276788 iter num 260\n",
            "loss 0.5502493977546692 average time 0.003858398607111927 iter num 280\n",
            "loss 1.1005277633666992 average time 0.0037827553166243887 iter num 300\n",
            "loss 0.18041262030601501 average time 0.0037253199999724984 iter num 320\n",
            "loss 0.5252628922462463 average time 0.003669169244093449 iter num 340\n",
            "loss 0.9849353432655334 average time 0.003614793480528533 iter num 360\n",
            "loss 0.7961108684539795 average time 0.0035753516683861993 iter num 380\n",
            "loss 0.13770776987075806 average time 0.0035337127349612273 iter num 400\n",
            "loss 0.2798943817615509 average time 0.003499366890446254 iter num 420\n",
            "loss 0.18527168035507202 average time 0.003473244695433922 iter num 440\n",
            "loss 0.1874503344297409 average time 0.003441490810837422 iter num 460\n",
            "loss 0.35361525416374207 average time 0.003412951987483363 iter num 480\n",
            "loss 0.3957657814025879 average time 0.0033903012339796985 iter num 500\n",
            "loss 0.11626500636339188 average time 0.003368609973057783 iter num 520\n",
            "loss 0.23370078206062317 average time 0.0033437973518293464 iter num 540\n",
            "loss 0.20087796449661255 average time 0.003321940089257883 iter num 560\n",
            "loss 0.2340041697025299 average time 0.0033030544172200685 iter num 580\n",
            "loss 0.18501508235931396 average time 0.0032828304033167416 iter num 600\n",
            "loss 0.2218061089515686 average time 0.0032642711257839466 iter num 620\n",
            "loss 0.16540223360061646 average time 0.0032481822187207855 iter num 640\n",
            "loss 0.19567982852458954 average time 0.0032334586287630154 iter num 660\n",
            "loss 0.2172652930021286 average time 0.003218519366154236 iter num 680\n",
            "loss 0.3199657201766968 average time 0.003203474234269379 iter num 700\n",
            "loss 0.0885007381439209 average time 0.003189450602763423 iter num 720\n",
            "loss 0.2725110650062561 average time 0.0031762004594433216 iter num 740\n",
            "loss 0.24662941694259644 average time 0.0031643706802457782 iter num 760\n",
            "loss 0.1741737723350525 average time 0.0031565857922988727 iter num 780\n",
            "loss 0.13685885071754456 average time 0.003147408568740957 iter num 800\n",
            "loss 0.16203097999095917 average time 0.0031376915341375356 iter num 820\n",
            "loss 0.3782327175140381 average time 0.003127297022616577 iter num 840\n",
            "loss 0.4150087237358093 average time 0.0031177858825579934 iter num 860\n",
            "loss 0.19197982549667358 average time 0.0031135847602317052 iter num 880\n",
            "loss 0.27278855443000793 average time 0.003104086183340971 iter num 900\n",
            "loss 0.5699059367179871 average time 0.003099223173923905 iter num 920\n",
            "loss 0.35572004318237305 average time 0.003091532291503601 iter num 940\n",
            "loss 0.10431955754756927 average time 0.0030874720250077797 iter num 960\n",
            "loss 0.181366965174675 average time 0.0030800957214412437 iter num 980\n",
            "loss 0.16216833889484406 average time 0.0030725029000132054 iter num 1000\n",
            "loss 1.0387784242630005 average time 0.018213767849920258 iter num 20\n",
            "loss 0.5867910981178284 average time 0.010468661224967946 iter num 40\n",
            "loss 0.3370160162448883 average time 0.00788648431665327 iter num 60\n",
            "loss 0.31570008397102356 average time 0.006598832062422844 iter num 80\n",
            "loss 0.2217440903186798 average time 0.0058812904298793 iter num 100\n",
            "loss 1.6236354112625122 average time 0.0053801568582305965 iter num 120\n",
            "loss 1.9395393133163452 average time 0.004995375499934848 iter num 140\n",
            "loss 0.34529149532318115 average time 0.004729158337443096 iter num 160\n",
            "loss 2.373586654663086 average time 0.004506311316617939 iter num 180\n",
            "loss 0.342447966337204 average time 0.004326086424944151 iter num 200\n",
            "loss 0.3719199597835541 average time 0.004179812904492957 iter num 220\n",
            "loss 0.36873140931129456 average time 0.004056130174922146 iter num 240\n",
            "loss 0.49520301818847656 average time 0.003951537730699783 iter num 260\n",
            "loss 0.4907897412776947 average time 0.003862982921373259 iter num 280\n",
            "loss 0.5091261267662048 average time 0.003787053989957106 iter num 300\n",
            "loss 0.11778242141008377 average time 0.0037201521530846548 iter num 320\n",
            "loss 0.1555076688528061 average time 0.0036600157146708893 iter num 340\n",
            "loss 0.5277725458145142 average time 0.0036115370638526655 iter num 360\n",
            "loss 0.7086315751075745 average time 0.0035640599447153937 iter num 380\n",
            "loss 0.11867673695087433 average time 0.0035300769824834787 iter num 400\n",
            "loss 0.22834911942481995 average time 0.003497183928547678 iter num 420\n",
            "loss 0.23174157738685608 average time 0.00346259860451193 iter num 440\n",
            "loss 0.18731537461280823 average time 0.0034301249086401303 iter num 460\n",
            "loss 0.27128076553344727 average time 0.003399683889536694 iter num 480\n",
            "loss 0.13663147389888763 average time 0.0033721799179584197 iter num 500\n",
            "loss 0.2957240343093872 average time 0.0033510175999498853 iter num 520\n",
            "loss 0.1800430417060852 average time 0.0033264875295976205 iter num 540\n",
            "loss 0.36368700861930847 average time 0.003306140437471835 iter num 560\n",
            "loss 0.1721498668193817 average time 0.003286121860316504 iter num 580\n",
            "loss 0.2948266267776489 average time 0.0032686706233077227 iter num 600\n",
            "loss 0.1858818531036377 average time 0.0032523768435244313 iter num 620\n",
            "loss 0.13255783915519714 average time 0.003236367645286009 iter num 640\n",
            "loss 0.10621917247772217 average time 0.0032208199939139544 iter num 660\n",
            "loss 0.21331200003623962 average time 0.0032060126087986537 iter num 680\n",
            "loss 0.205486461520195 average time 0.0031918979785431085 iter num 700\n",
            "loss 0.10358189046382904 average time 0.003178059887469923 iter num 720\n",
            "loss 0.3006269037723541 average time 0.003169331737806076 iter num 740\n",
            "loss 0.13192445039749146 average time 0.003157403061806307 iter num 760\n",
            "loss 0.09687592834234238 average time 0.0031458293166206903 iter num 780\n",
            "loss 0.06063474342226982 average time 0.003135135063703274 iter num 800\n",
            "loss 0.0553324893116951 average time 0.003125931697519352 iter num 820\n",
            "loss 0.23531337082386017 average time 0.003115930699964121 iter num 840\n",
            "loss 0.19032958149909973 average time 0.0031061073383361238 iter num 860\n",
            "loss 0.14401723444461823 average time 0.003096844999969438 iter num 880\n",
            "loss 0.08276794850826263 average time 0.003089238837742919 iter num 900\n",
            "loss 0.0886460617184639 average time 0.003081215781491625 iter num 920\n",
            "loss 0.2291642427444458 average time 0.003073545582952028 iter num 940\n",
            "loss 0.12918663024902344 average time 0.003065639622892983 iter num 960\n",
            "loss 0.17657756805419922 average time 0.0030577578663074484 iter num 980\n",
            "loss 0.17409037053585052 average time 0.0030507305929822906 iter num 1000\n",
            "loss 0.2434624433517456 average time 0.018307859050037224 iter num 20\n",
            "loss 0.21650204062461853 average time 0.010503946199969505 iter num 40\n",
            "loss 1.312126874923706 average time 0.007904258399927736 iter num 60\n",
            "loss 0.48449015617370605 average time 0.006612085899928388 iter num 80\n",
            "loss 0.2487524449825287 average time 0.005827427029907994 iter num 100\n",
            "loss 0.2647377550601959 average time 0.005308504424904944 iter num 120\n",
            "loss 0.1922873854637146 average time 0.004949103385622169 iter num 140\n",
            "loss 0.7526959180831909 average time 0.004677209856185982 iter num 160\n",
            "loss 0.08588714897632599 average time 0.0044571309832665265 iter num 180\n",
            "loss 0.32561951875686646 average time 0.004304851774932104 iter num 200\n",
            "loss 0.2427477240562439 average time 0.0041623508999360966 iter num 220\n",
            "loss 0.31700918078422546 average time 0.004042086804126181 iter num 240\n",
            "loss 0.25233927369117737 average time 0.003939950649943897 iter num 260\n",
            "loss 0.12572963535785675 average time 0.003851678821359071 iter num 280\n",
            "loss 0.4624660611152649 average time 0.00377503723993262 iter num 300\n",
            "loss 0.22125360369682312 average time 0.003709304006184766 iter num 320\n",
            "loss 0.13342934846878052 average time 0.003651756741125128 iter num 340\n",
            "loss 0.19866281747817993 average time 0.0036016211638373835 iter num 360\n",
            "loss 0.6965806484222412 average time 0.00355697774468928 iter num 380\n",
            "loss 0.5839614272117615 average time 0.0035146081174616483 iter num 400\n",
            "loss 0.8901745080947876 average time 0.003476459673783254 iter num 420\n",
            "loss 0.8374053239822388 average time 0.0034413349272447457 iter num 440\n",
            "loss 0.7437365055084229 average time 0.0034179743108364597 iter num 460\n",
            "loss 0.18501317501068115 average time 0.0033882774687147804 iter num 480\n",
            "loss 0.35307738184928894 average time 0.003360638511974685 iter num 500\n",
            "loss 0.445402592420578 average time 0.003335796815361811 iter num 520\n",
            "loss 0.1380717158317566 average time 0.003313005059236376 iter num 540\n",
            "loss 0.5849756002426147 average time 0.0032915822910484036 iter num 560\n",
            "loss 0.10844935476779938 average time 0.0032721939775691333 iter num 580\n",
            "loss 0.3098543584346771 average time 0.0032536973199967178 iter num 600\n",
            "loss 0.2626591622829437 average time 0.0032380348338700705 iter num 620\n",
            "loss 0.08538295328617096 average time 0.0032218674234343325 iter num 640\n",
            "loss 0.18256539106369019 average time 0.003211156413627495 iter num 660\n",
            "loss 0.18787825107574463 average time 0.003197261591169402 iter num 680\n",
            "loss 0.15493297576904297 average time 0.003187071641425843 iter num 700\n",
            "loss 0.2748677432537079 average time 0.0031776950000019294 iter num 720\n",
            "loss 0.27347779273986816 average time 0.003171404190544382 iter num 740\n",
            "loss 0.2195340394973755 average time 0.0031619269000059016 iter num 760\n",
            "loss 0.17816731333732605 average time 0.0031502253410321712 iter num 780\n",
            "loss 0.11720356345176697 average time 0.003140489596257794 iter num 800\n",
            "loss 0.20142492651939392 average time 0.003130791219516651 iter num 820\n",
            "loss 0.12602198123931885 average time 0.003120261752389654 iter num 840\n",
            "loss 0.19516879320144653 average time 0.0031109671744288365 iter num 860\n",
            "loss 0.19106295704841614 average time 0.0031020251840986517 iter num 880\n",
            "loss 0.16013425588607788 average time 0.003093230542225582 iter num 900\n",
            "loss 0.06911525875329971 average time 0.0030883956826133012 iter num 920\n",
            "loss 0.43245285749435425 average time 0.0030806349670243396 iter num 940\n",
            "loss 0.10390415042638779 average time 0.0030740120385435907 iter num 960\n",
            "loss 0.046363960951566696 average time 0.0030663167806147724 iter num 980\n",
            "loss 0.12231709063053131 average time 0.003059023049003372 iter num 1000\n",
            "loss 0.24501754343509674 average time 0.018266840599790158 iter num 20\n",
            "loss 0.32800939679145813 average time 0.010514166274970194 iter num 40\n",
            "loss 0.15231946110725403 average time 0.007930118866746246 iter num 60\n",
            "loss 0.7364897131919861 average time 0.00663969360007286 iter num 80\n",
            "loss 1.1192409992218018 average time 0.005876531230023829 iter num 100\n",
            "loss 0.4932372570037842 average time 0.0053467081333261985 iter num 120\n",
            "loss 0.9002299308776855 average time 0.0049668931000529225 iter num 140\n",
            "loss 1.2371153831481934 average time 0.0046875556063014304 iter num 160\n",
            "loss 0.07142682373523712 average time 0.004468286244526907 iter num 180\n",
            "loss 0.24913257360458374 average time 0.004292069555085618 iter num 200\n",
            "loss 0.5366629362106323 average time 0.004160869900054174 iter num 220\n",
            "loss 3.29573392868042 average time 0.004038938041723365 iter num 240\n",
            "loss 0.11500121653079987 average time 0.003937015176968719 iter num 260\n",
            "loss 0.5337419509887695 average time 0.003849510428601986 iter num 280\n",
            "loss 0.3175804913043976 average time 0.003773311203355358 iter num 300\n",
            "loss 0.270905077457428 average time 0.0037086849343950234 iter num 320\n",
            "loss 0.20604941248893738 average time 0.0036509851441330872 iter num 340\n",
            "loss 0.35983139276504517 average time 0.003605028833357614 iter num 360\n",
            "loss 0.18732723593711853 average time 0.0035589479526415267 iter num 380\n",
            "loss 0.11488717049360275 average time 0.0035165353200136452 iter num 400\n",
            "loss 0.7126614451408386 average time 0.0034781176857298607 iter num 420\n",
            "loss 0.22014120221138 average time 0.0034427589772886595 iter num 440\n",
            "loss 0.26438191533088684 average time 0.0034108661826157123 iter num 460\n",
            "loss 0.13714586198329926 average time 0.003389351143755448 iter num 480\n",
            "loss 0.17671546339988708 average time 0.003362087350000365 iter num 500\n",
            "loss 0.13737063109874725 average time 0.0033369593999990543 iter num 520\n",
            "loss 0.37816399335861206 average time 0.003312630409268254 iter num 540\n",
            "loss 0.1571142077445984 average time 0.003291164925011409 iter num 560\n",
            "loss 0.2724478244781494 average time 0.003275784062071611 iter num 580\n",
            "loss 0.056835561990737915 average time 0.003256531768329296 iter num 600\n",
            "loss 0.11586088687181473 average time 0.0032394639032205423 iter num 620\n",
            "loss 0.43755853176116943 average time 0.003227954603110561 iter num 640\n",
            "loss 0.08838552236557007 average time 0.0032129949302901824 iter num 660\n",
            "loss 0.2198016345500946 average time 0.003198338824984817 iter num 680\n",
            "loss 0.17234563827514648 average time 0.0031840875856999316 iter num 700\n",
            "loss 0.11172766238451004 average time 0.0031717320888750085 iter num 720\n",
            "loss 0.05013497918844223 average time 0.0031604233837685103 iter num 740\n",
            "loss 0.10195434093475342 average time 0.003149651674991554 iter num 760\n",
            "loss 0.42695337533950806 average time 0.0031379106474233617 iter num 780\n",
            "loss 0.19581928849220276 average time 0.0031275242549827454 iter num 800\n",
            "loss 0.33426228165626526 average time 0.0031191329182747277 iter num 820\n",
            "loss 0.19132104516029358 average time 0.003111189688074557 iter num 840\n",
            "loss 0.48519015312194824 average time 0.003102171247659033 iter num 860\n",
            "loss 0.08399368822574615 average time 0.0030936846568010877 iter num 880\n",
            "loss 0.08650854229927063 average time 0.0030877553322049304 iter num 900\n",
            "loss 0.1519118696451187 average time 0.003080465005416994 iter num 920\n",
            "loss 0.08227908611297607 average time 0.0030732451052999554 iter num 940\n",
            "loss 0.20670445263385773 average time 0.0030705453687327614 iter num 960\n",
            "loss 0.07462357729673386 average time 0.003063475483659018 iter num 980\n",
            "loss 0.23830804228782654 average time 0.003056090942984156 iter num 1000\n",
            "loss 0.3214017450809479 average time 0.01828512040028727 iter num 20\n",
            "loss 0.4542648494243622 average time 0.0105019689501205 iter num 40\n",
            "loss 0.31451916694641113 average time 0.007903881350072577 iter num 60\n",
            "loss 0.915041983127594 average time 0.006610058925048179 iter num 80\n",
            "loss 0.5321441292762756 average time 0.005837598310099565 iter num 100\n",
            "loss 0.7604951858520508 average time 0.0053170979251111325 iter num 120\n",
            "loss 0.6494572162628174 average time 0.004978479257260915 iter num 140\n",
            "loss 0.5207311511039734 average time 0.004702142337600889 iter num 160\n",
            "loss 0.5196195840835571 average time 0.004481927072265535 iter num 180\n",
            "loss 0.3631489872932434 average time 0.004302661630044895 iter num 200\n",
            "loss 0.5296329855918884 average time 0.004156981800059095 iter num 220\n",
            "loss 0.35175663232803345 average time 0.004040531687564908 iter num 240\n",
            "loss 0.26726117730140686 average time 0.003942183634689382 iter num 260\n",
            "loss 0.16359843313694 average time 0.003852327914338665 iter num 280\n",
            "loss 0.389232337474823 average time 0.003775355866710015 iter num 300\n",
            "loss 0.30324816703796387 average time 0.0037116498437967495 iter num 320\n",
            "loss 0.2523818910121918 average time 0.0036605813471129187 iter num 340\n",
            "loss 0.4811062514781952 average time 0.0036169913500644826 iter num 360\n",
            "loss 0.1235123872756958 average time 0.003577872552686083 iter num 380\n",
            "loss 0.2759503722190857 average time 0.003536148462540041 iter num 400\n",
            "loss 0.24666887521743774 average time 0.00349840552385753 iter num 420\n",
            "loss 0.07729250937700272 average time 0.0034622203568646496 iter num 440\n",
            "loss 0.2898176610469818 average time 0.0034306260044064877 iter num 460\n",
            "loss 0.29686373472213745 average time 0.0033998731146425596 iter num 480\n",
            "loss 0.10796152055263519 average time 0.003371560590050649 iter num 500\n",
            "loss 0.21799804270267487 average time 0.0033456763288960737 iter num 520\n",
            "loss 0.30572372674942017 average time 0.003323168401901192 iter num 540\n",
            "loss 0.061046160757541656 average time 0.00330182333040219 iter num 560\n",
            "loss 0.30519407987594604 average time 0.0032811016828010655 iter num 580\n",
            "loss 0.2735700011253357 average time 0.00326142532837063 iter num 600\n",
            "loss 0.14933083951473236 average time 0.0032443866113270256 iter num 620\n",
            "loss 0.2593879699707031 average time 0.0032297430328469545 iter num 640\n",
            "loss 0.33316004276275635 average time 0.003216485883367017 iter num 660\n",
            "loss 0.33661890029907227 average time 0.0032047007191495676 iter num 680\n",
            "loss 0.19752974808216095 average time 0.0031893866800315404 iter num 700\n",
            "loss 0.15534339845180511 average time 0.003175915161139326 iter num 720\n",
            "loss 0.2712922692298889 average time 0.0031691095284062418 iter num 740\n",
            "loss 0.08361154049634933 average time 0.003157870638187887 iter num 760\n",
            "loss 0.46704593300819397 average time 0.0031461213577271196 iter num 780\n",
            "loss 0.14078500866889954 average time 0.003135843440034023 iter num 800\n",
            "loss 0.12548844516277313 average time 0.0031299932927140615 iter num 820\n",
            "loss 0.2750265300273895 average time 0.0031204291107423203 iter num 840\n",
            "loss 0.1661464422941208 average time 0.003110901459335447 iter num 860\n",
            "loss 0.15379047393798828 average time 0.003101730148893528 iter num 880\n",
            "loss 0.14583030343055725 average time 0.0030928830478114833 iter num 900\n",
            "loss 0.38853585720062256 average time 0.0030849622935143683 iter num 920\n",
            "loss 0.15100592374801636 average time 0.0030815823106751577 iter num 940\n",
            "loss 0.16025486588478088 average time 0.0030737650083741148 iter num 960\n",
            "loss 0.1671893149614334 average time 0.003069211043917416 iter num 980\n",
            "loss 0.1116504892706871 average time 0.0030630457090337587 iter num 1000\n",
            "loss 0.3351702392101288 average time 0.01821957645006478 iter num 20\n",
            "loss 0.3389551043510437 average time 0.010465801925010964 iter num 40\n",
            "loss 0.1699768602848053 average time 0.007880574366633178 iter num 60\n",
            "loss 1.0051430463790894 average time 0.006600489462493897 iter num 80\n",
            "loss 0.4470803737640381 average time 0.005821793509985582 iter num 100\n",
            "loss 0.5536389350891113 average time 0.005304375949996635 iter num 120\n",
            "loss 0.4949648976325989 average time 0.004934208921401608 iter num 140\n",
            "loss 0.5233592987060547 average time 0.004656673299962222 iter num 160\n",
            "loss 0.8210633993148804 average time 0.00444390212220848 iter num 180\n",
            "loss 0.6238450407981873 average time 0.004270425514987437 iter num 200\n",
            "loss 0.8498415946960449 average time 0.004153330259057177 iter num 220\n",
            "loss 2.2651596069335938 average time 0.004035649029143921 iter num 240\n",
            "loss 0.8789657354354858 average time 0.003932899626887284 iter num 260\n",
            "loss 0.2445642352104187 average time 0.003845083160682147 iter num 280\n",
            "loss 0.18273988366127014 average time 0.0037713429333113405 iter num 300\n",
            "loss 0.2562790513038635 average time 0.0037054756531176734 iter num 320\n",
            "loss 0.18372061848640442 average time 0.003646686197054591 iter num 340\n",
            "loss 0.8660590052604675 average time 0.0035943999916475556 iter num 360\n",
            "loss 0.1800134778022766 average time 0.0035464888552317127 iter num 380\n",
            "loss 0.15015195310115814 average time 0.0035055053799806046 iter num 400\n",
            "loss 0.5478272438049316 average time 0.0034698764428347725 iter num 420\n",
            "loss 0.18205994367599487 average time 0.0034384750090835454 iter num 440\n",
            "loss 0.2273830622434616 average time 0.003408376382614496 iter num 460\n",
            "loss 0.17525988817214966 average time 0.003379959764587663 iter num 480\n",
            "loss 0.15663886070251465 average time 0.0033521647980160195 iter num 500\n",
            "loss 0.1562754064798355 average time 0.0033397915673294147 iter num 520\n",
            "loss 0.7582436800003052 average time 0.003318234666686395 iter num 540\n",
            "loss 0.2175096869468689 average time 0.0032973777607237156 iter num 560\n",
            "loss 0.1682044118642807 average time 0.003276716610356555 iter num 580\n",
            "loss 0.12755447626113892 average time 0.003259069766684964 iter num 600\n",
            "loss 0.2919173836708069 average time 0.0032417521258344827 iter num 620\n",
            "loss 0.24913150072097778 average time 0.0032252456718964593 iter num 640\n",
            "loss 0.4214828610420227 average time 0.0032099108136676617 iter num 660\n",
            "loss 0.12432454526424408 average time 0.0031959948691484682 iter num 680\n",
            "loss 0.042385030537843704 average time 0.0031826362285989618 iter num 700\n",
            "loss 0.15104900300502777 average time 0.0031714902319713977 iter num 720\n",
            "loss 0.11114968359470367 average time 0.003164049300021115 iter num 740\n",
            "loss 0.24434705078601837 average time 0.00315093806186604 iter num 760\n",
            "loss 0.27615368366241455 average time 0.0031397748359268006 iter num 780\n",
            "loss 0.11682374775409698 average time 0.003128478306282432 iter num 800\n",
            "loss 0.10867656767368317 average time 0.0031172568439260208 iter num 820\n",
            "loss 0.21051102876663208 average time 0.003109917772651118 iter num 840\n",
            "loss 0.20881487429141998 average time 0.0030987268046860556 iter num 860\n",
            "loss 0.03955733776092529 average time 0.0030882679432166203 iter num 880\n",
            "loss 0.05698755383491516 average time 0.003078256442256841 iter num 900\n",
            "loss 0.10957039147615433 average time 0.003070997582642082 iter num 920\n",
            "loss 0.19939178228378296 average time 0.0030638874170534187 iter num 940\n",
            "loss 0.16470372676849365 average time 0.0030588517812778567 iter num 960\n",
            "loss 0.16362157464027405 average time 0.0030536153990044336 iter num 980\n",
            "loss 0.09239441156387329 average time 0.00304842578302123 iter num 1000\n",
            "loss 0.23747554421424866 average time 0.018362955700013117 iter num 20\n",
            "loss 0.46465879678726196 average time 0.010518020100062132 iter num 40\n",
            "loss 2.694862127304077 average time 0.007913098583412648 iter num 60\n",
            "loss 1.4354517459869385 average time 0.006610516737600847 iter num 80\n",
            "loss 0.4263688325881958 average time 0.005847192320143222 iter num 100\n",
            "loss 0.7579841017723083 average time 0.005320555200129699 iter num 120\n",
            "loss 0.33266210556030273 average time 0.004941187728685951 iter num 140\n",
            "loss 0.36371809244155884 average time 0.00465868506885272 iter num 160\n",
            "loss 0.5757502317428589 average time 0.004445393238964041 iter num 180\n",
            "loss 0.17195618152618408 average time 0.004268200685046395 iter num 200\n",
            "loss 0.5395112037658691 average time 0.0041516501318834675 iter num 220\n",
            "loss 0.3137055039405823 average time 0.004029475704229905 iter num 240\n",
            "loss 0.5651203393936157 average time 0.003928405126967286 iter num 260\n",
            "loss 0.10655122995376587 average time 0.0038391765357443674 iter num 280\n",
            "loss 0.242548406124115 average time 0.0037613819033504112 iter num 300\n",
            "loss 0.4467843770980835 average time 0.0036995574937520813 iter num 320\n",
            "loss 0.15271960198879242 average time 0.0036401678147205316 iter num 340\n",
            "loss 0.3453332781791687 average time 0.0035879034861106144 iter num 360\n",
            "loss 0.1992490440607071 average time 0.003541671597361672 iter num 380\n",
            "loss 0.24986529350280762 average time 0.003510691994983972 iter num 400\n",
            "loss 0.24373123049736023 average time 0.0034757855166433383 iter num 420\n",
            "loss 0.49372002482414246 average time 0.0034436190272530936 iter num 440\n",
            "loss 0.5929241180419922 average time 0.0034132777195420363 iter num 460\n",
            "loss 0.13955485820770264 average time 0.0033851961937216403 iter num 480\n",
            "loss 0.1465161144733429 average time 0.003359008133975294 iter num 500\n",
            "loss 0.10602451860904694 average time 0.003332582774971972 iter num 520\n",
            "loss 0.10983867943286896 average time 0.00331206805737936 iter num 540\n",
            "loss 0.2501123547554016 average time 0.003289456462480952 iter num 560\n",
            "loss 0.20422673225402832 average time 0.0032713707913617014 iter num 580\n",
            "loss 0.3216652274131775 average time 0.003256459506643902 iter num 600\n",
            "loss 0.09607479721307755 average time 0.0032514602612624707 iter num 620\n",
            "loss 0.20267285406589508 average time 0.003238438118717113 iter num 640\n",
            "loss 0.3147474527359009 average time 0.0032221029620814077 iter num 660\n",
            "loss 0.21804070472717285 average time 0.0032065760999611323 iter num 680\n",
            "loss 0.17210295796394348 average time 0.0031927343956808076 iter num 700\n",
            "loss 0.1514693647623062 average time 0.003192375627749142 iter num 720\n",
            "loss 0.1653091311454773 average time 0.003181248798628567 iter num 740\n",
            "loss 0.20316144824028015 average time 0.0031689481447205923 iter num 760\n",
            "loss 0.12750297784805298 average time 0.0031570941153754224 iter num 780\n",
            "loss 0.2958487868309021 average time 0.0031454095674894236 iter num 800\n",
            "loss 0.21392367780208588 average time 0.0031344161402269426 iter num 820\n",
            "loss 0.17231039702892303 average time 0.003123653271404692 iter num 840\n",
            "loss 0.33605843782424927 average time 0.003113973158123858 iter num 860\n",
            "loss 0.12156078219413757 average time 0.003104529584077847 iter num 880\n",
            "loss 0.175268292427063 average time 0.003095232033319917 iter num 900\n",
            "loss 0.495327353477478 average time 0.003086112024991804 iter num 920\n",
            "loss 0.10445234924554825 average time 0.003077610396796948 iter num 940\n",
            "loss 0.048044875264167786 average time 0.003069781698944022 iter num 960\n",
            "loss 0.6024235486984253 average time 0.0030624228897828958 iter num 980\n",
            "loss 0.23852315545082092 average time 0.003055895800984217 iter num 1000\n",
            "loss 0.24418076872825623 average time 0.018441541000083817 iter num 20\n",
            "loss 0.2138478308916092 average time 0.010713716550162644 iter num 40\n",
            "loss 0.20772436261177063 average time 0.008041153716779567 iter num 60\n",
            "loss 0.7556753158569336 average time 0.006704625900079008 iter num 80\n",
            "loss 0.6497902274131775 average time 0.005914275190007174 iter num 100\n",
            "loss 0.5864639282226562 average time 0.005381180475023939 iter num 120\n",
            "loss 0.7274277210235596 average time 0.004997961799965976 iter num 140\n",
            "loss 1.2036222219467163 average time 0.0047110420374792735 iter num 160\n",
            "loss 0.169548898935318 average time 0.004487178972218923 iter num 180\n",
            "loss 0.5332320928573608 average time 0.004309248219988149 iter num 200\n",
            "loss 0.23658959567546844 average time 0.004188446763617486 iter num 220\n",
            "loss 0.15613657236099243 average time 0.004066822758318267 iter num 240\n",
            "loss 0.2468697428703308 average time 0.003963328553828222 iter num 260\n",
            "loss 1.41685950756073 average time 0.0038811527571267234 iter num 280\n",
            "loss 0.6294512748718262 average time 0.0038003132033130288 iter num 300\n",
            "loss 0.11546950787305832 average time 0.0037324991312345903 iter num 320\n",
            "loss 0.27031147480010986 average time 0.0036720714205597796 iter num 340\n",
            "loss 0.10224619507789612 average time 0.0036195019360699614 iter num 360\n",
            "loss 0.4978688061237335 average time 0.0035697318341781762 iter num 380\n",
            "loss 0.16301168501377106 average time 0.003526105429968993 iter num 400\n",
            "loss 0.25147098302841187 average time 0.0034863297380720074 iter num 420\n",
            "loss 0.32515856623649597 average time 0.0034514617590792277 iter num 440\n",
            "loss 0.20684625208377838 average time 0.003417923143467266 iter num 460\n",
            "loss 0.17811429500579834 average time 0.003389806866653089 iter num 480\n",
            "loss 0.25636911392211914 average time 0.0033674947319886996 iter num 500\n",
            "loss 0.3030296862125397 average time 0.0033417594942140847 iter num 520\n",
            "loss 0.3442929983139038 average time 0.00331838277405849 iter num 540\n",
            "loss 0.06348447501659393 average time 0.0032955173892690124 iter num 560\n",
            "loss 0.06512176245450974 average time 0.003274298127576787 iter num 580\n",
            "loss 0.5649606585502625 average time 0.0032545652399888544 iter num 600\n",
            "loss 0.13043911755084991 average time 0.0032378144661232644 iter num 620\n",
            "loss 0.23404766619205475 average time 0.0032227308234325847 iter num 640\n",
            "loss 0.14137764275074005 average time 0.0032131822636294986 iter num 660\n",
            "loss 0.08022952079772949 average time 0.0031971966573404215 iter num 680\n",
            "loss 0.2348758578300476 average time 0.0031822546257041853 iter num 700\n",
            "loss 0.04270508140325546 average time 0.0031686507013773736 iter num 720\n",
            "loss 0.23533514142036438 average time 0.0031560341418716653 iter num 740\n",
            "loss 0.1121138483285904 average time 0.0031450321486748804 iter num 760\n",
            "loss 0.047699254006147385 average time 0.0031335819692242532 iter num 780\n",
            "loss 0.2951318621635437 average time 0.003122733769989736 iter num 800\n",
            "loss 0.23511147499084473 average time 0.0031120099267953755 iter num 820\n",
            "loss 0.0651879832148552 average time 0.0031018645214035564 iter num 840\n",
            "loss 0.21184049546718597 average time 0.003092995127873258 iter num 860\n",
            "loss 0.1919240653514862 average time 0.0030858771670058227 iter num 880\n",
            "loss 0.15101578831672668 average time 0.0030795157255225705 iter num 900\n",
            "loss 0.2595767676830292 average time 0.0030722451499514136 iter num 920\n",
            "loss 0.32808008790016174 average time 0.0030637353478228527 iter num 940\n",
            "loss 0.18144209682941437 average time 0.0030569784322456903 iter num 960\n",
            "loss 0.058281466364860535 average time 0.003049259992813135 iter num 980\n",
            "loss 0.07995190471410751 average time 0.003043739333958001 iter num 1000\n",
            "loss 0.5641930103302002 average time 0.01828765105055936 iter num 20\n",
            "loss 1.054992914199829 average time 0.010492282125142083 iter num 40\n",
            "loss 0.5650153756141663 average time 0.007920407216867412 iter num 60\n",
            "loss 0.8467986583709717 average time 0.006610552237725642 iter num 80\n",
            "loss 0.7341353893280029 average time 0.005825487680122024 iter num 100\n",
            "loss 0.2387596070766449 average time 0.00530227142504979 iter num 120\n",
            "loss 0.10184334963560104 average time 0.004928482028585027 iter num 140\n",
            "loss 0.9068289995193481 average time 0.004648553587480819 iter num 160\n",
            "loss 0.20823875069618225 average time 0.0044287317666506475 iter num 180\n",
            "loss 1.0742075443267822 average time 0.004277304695006023 iter num 200\n",
            "loss 0.08556054532527924 average time 0.0041376047727350275 iter num 220\n",
            "loss 0.2386922389268875 average time 0.004015993600038807 iter num 240\n",
            "loss 6.392314910888672 average time 0.003912862546237123 iter num 260\n",
            "loss 0.9470347166061401 average time 0.0038288889678759525 iter num 280\n",
            "loss 0.10583819448947906 average time 0.003753290160020697 iter num 300\n",
            "loss 0.2781546711921692 average time 0.0036952437562604245 iter num 320\n",
            "loss 0.1368425041437149 average time 0.003637742629432657 iter num 340\n",
            "loss 0.2492140233516693 average time 0.003589829858366203 iter num 360\n",
            "loss 0.22023306787014008 average time 0.0035429941211029808 iter num 380\n",
            "loss 0.059116579592227936 average time 0.0035007876700547057 iter num 400\n",
            "loss 0.1492597460746765 average time 0.0034620669405177025 iter num 420\n",
            "loss 0.29069873690605164 average time 0.0034266152750453993 iter num 440\n",
            "loss 0.11011286824941635 average time 0.003398426317439969 iter num 460\n",
            "loss 0.2156028300523758 average time 0.003371710206314068 iter num 480\n",
            "loss 0.2551039159297943 average time 0.0033439025640618638 iter num 500\n",
            "loss 0.4417531490325928 average time 0.0033197721020000103 iter num 520\n",
            "loss 0.1639014482498169 average time 0.0032966492815561382 iter num 540\n",
            "loss 0.08987100422382355 average time 0.003275428214348202 iter num 560\n",
            "loss 0.36393362283706665 average time 0.003255824605228805 iter num 580\n",
            "loss 0.331527978181839 average time 0.0032378226450722044 iter num 600\n",
            "loss 0.17493930459022522 average time 0.0032212824420170248 iter num 620\n",
            "loss 0.05588732287287712 average time 0.0032047500234909875 iter num 640\n",
            "loss 0.10408288240432739 average time 0.0031884782485245853 iter num 660\n",
            "loss 0.2070094496011734 average time 0.003174046563264496 iter num 680\n",
            "loss 0.17047229409217834 average time 0.003161374435736174 iter num 700\n",
            "loss 0.05069922283291817 average time 0.003148756322237508 iter num 720\n",
            "loss 0.21810045838356018 average time 0.0031379406581264276 iter num 740\n",
            "loss 0.2276841551065445 average time 0.003126487168427909 iter num 760\n",
            "loss 0.10919464379549026 average time 0.003115666884621486 iter num 780\n",
            "loss 0.04633841663599014 average time 0.003104937007506123 iter num 800\n",
            "loss 0.2589802145957947 average time 0.0030951749585455685 iter num 820\n",
            "loss 0.11572922766208649 average time 0.00308826717143044 iter num 840\n",
            "loss 0.0676070973277092 average time 0.003078607498837512 iter num 860\n",
            "loss 0.2854493260383606 average time 0.0030697657238678484 iter num 880\n",
            "loss 0.29183048009872437 average time 0.0030635333266723643 iter num 900\n",
            "loss 0.10420046746730804 average time 0.0030566586826194985 iter num 920\n",
            "loss 0.14843973517417908 average time 0.003051137657460826 iter num 940\n",
            "loss 0.0737726166844368 average time 0.0030441221552223396 iter num 960\n",
            "loss 0.06017380952835083 average time 0.0030363427530741022 iter num 980\n",
            "loss 0.15788495540618896 average time 0.0030295191130280726 iter num 1000\n",
            "loss 0.5760078430175781 average time 0.018381007600146403 iter num 20\n",
            "loss 1.117153525352478 average time 0.010590112575027889 iter num 40\n",
            "loss 0.22100070118904114 average time 0.007957648266832014 iter num 60\n",
            "loss 0.3566572666168213 average time 0.006648817125051209 iter num 80\n",
            "loss 0.242284893989563 average time 0.005899994579958729 iter num 100\n",
            "loss 0.4859166741371155 average time 0.005404962708295594 iter num 120\n",
            "loss 0.21742135286331177 average time 0.005031749128517861 iter num 140\n",
            "loss 0.3910665810108185 average time 0.004744896162446821 iter num 160\n",
            "loss 0.5353811979293823 average time 0.00452134745557689 iter num 180\n",
            "loss 0.3631850779056549 average time 0.004338180730010208 iter num 200\n",
            "loss 4.41379451751709 average time 0.00418811781819386 iter num 220\n",
            "loss 0.3966958522796631 average time 0.004073732812518453 iter num 240\n",
            "loss 0.21730446815490723 average time 0.003968255334649047 iter num 260\n",
            "loss 0.40325015783309937 average time 0.003876479325013601 iter num 280\n",
            "loss 0.1098741888999939 average time 0.003797456280044571 iter num 300\n",
            "loss 0.3676322400569916 average time 0.0037325716563032076 iter num 320\n",
            "loss 0.26992738246917725 average time 0.003672378994173521 iter num 340\n",
            "loss 0.20853039622306824 average time 0.0036343498417611246 iter num 360\n",
            "loss 0.21244603395462036 average time 0.0035827813369140034 iter num 380\n",
            "loss 0.5713746547698975 average time 0.0035420209950734714 iter num 400\n",
            "loss 0.14532332122325897 average time 0.003503008581044144 iter num 420\n",
            "loss 0.42757663130760193 average time 0.003466166895544699 iter num 440\n",
            "loss 0.16485440731048584 average time 0.003436489863119989 iter num 460\n",
            "loss 0.3972626328468323 average time 0.003416190727140626 iter num 480\n",
            "loss 0.24938622117042542 average time 0.0033892529680306324 iter num 500\n",
            "loss 0.18046976625919342 average time 0.003365532240408916 iter num 520\n",
            "loss 0.29712384939193726 average time 0.0033432312185511736 iter num 540\n",
            "loss 0.22830036282539368 average time 0.003321838380380931 iter num 560\n",
            "loss 0.2503436207771301 average time 0.0032991577051783177 iter num 580\n",
            "loss 0.1469188928604126 average time 0.003280450025007061 iter num 600\n",
            "loss 0.3212118148803711 average time 0.003265544724214828 iter num 620\n",
            "loss 0.18735304474830627 average time 0.0032479231281627107 iter num 640\n",
            "loss 0.5169222354888916 average time 0.003232597825786577 iter num 660\n",
            "loss 0.14707288146018982 average time 0.003216065526510861 iter num 680\n",
            "loss 0.21148017048835754 average time 0.0032029821986257695 iter num 700\n",
            "loss 0.11820875108242035 average time 0.003192634163936721 iter num 720\n",
            "loss 0.45761656761169434 average time 0.0031815328513943855 iter num 740\n",
            "loss 0.18076330423355103 average time 0.003170736548714845 iter num 760\n",
            "loss 0.10787805914878845 average time 0.0031598070756724784 iter num 780\n",
            "loss 0.08248259127140045 average time 0.0031485929312884764 iter num 800\n",
            "loss 0.21996071934700012 average time 0.0031381580707691282 iter num 820\n",
            "loss 0.050398439168930054 average time 0.0031320383750426117 iter num 840\n",
            "loss 0.17332863807678223 average time 0.0031246566907252283 iter num 860\n",
            "loss 0.2731771767139435 average time 0.00311793240683652 iter num 880\n",
            "loss 0.11196596175432205 average time 0.003108870196689774 iter num 900\n",
            "loss 0.10569054633378983 average time 0.003105468569593422 iter num 920\n",
            "loss 0.07949396967887878 average time 0.0031009463415218905 iter num 940\n",
            "loss 0.10029200464487076 average time 0.003096188778173807 iter num 960\n",
            "loss 0.1555236279964447 average time 0.003090700253121714 iter num 980\n",
            "loss 0.13665425777435303 average time 0.0030837298620572254 iter num 1000\n",
            "loss 0.34400928020477295 average time 0.01824252699952922 iter num 20\n",
            "loss 0.5271643400192261 average time 0.010509274449577787 iter num 40\n",
            "loss 0.7111902832984924 average time 0.007914968699697055 iter num 60\n",
            "loss 0.8234765529632568 average time 0.006595881512339474 iter num 80\n",
            "loss 0.21727992594242096 average time 0.005810664349846775 iter num 100\n",
            "loss 0.2227034717798233 average time 0.005292898224918948 iter num 120\n",
            "loss 0.4178689122200012 average time 0.004918517800043836 iter num 140\n",
            "loss 0.5780692100524902 average time 0.004652485900032843 iter num 160\n",
            "loss 0.4557345509529114 average time 0.004435609733405323 iter num 180\n",
            "loss 0.21592102944850922 average time 0.0042563146850261545 iter num 200\n",
            "loss 0.1367456018924713 average time 0.004112363950000806 iter num 220\n",
            "loss 0.26536500453948975 average time 0.003992633124941373 iter num 240\n",
            "loss 0.2101539522409439 average time 0.0038913874422667923 iter num 260\n",
            "loss 0.12742696702480316 average time 0.003805511199971079 iter num 280\n",
            "loss 0.064411461353302 average time 0.003738447579938414 iter num 300\n",
            "loss 0.22645288705825806 average time 0.0036729708062011924 iter num 320\n",
            "loss 0.23081830143928528 average time 0.003622548388193536 iter num 340\n",
            "loss 0.13097542524337769 average time 0.0035738564305069706 iter num 360\n",
            "loss 0.114969901740551 average time 0.0035307710078421608 iter num 380\n",
            "loss 0.26978692412376404 average time 0.00348927118496249 iter num 400\n",
            "loss 0.13566046953201294 average time 0.0034510261475935253 iter num 420\n",
            "loss 0.14551770687103271 average time 0.003415520331790586 iter num 440\n",
            "loss 0.3035869300365448 average time 0.0033889103043016487 iter num 460\n",
            "loss 0.2599809169769287 average time 0.0033609446958128802 iter num 480\n",
            "loss 0.1950150728225708 average time 0.0033331785319678604 iter num 500\n",
            "loss 0.26318323612213135 average time 0.003307981261528207 iter num 520\n",
            "loss 0.13619033992290497 average time 0.003283785327760227 iter num 540\n",
            "loss 0.269741028547287 average time 0.0032621332232013497 iter num 560\n",
            "loss 0.10210427641868591 average time 0.003245038901714624 iter num 580\n",
            "loss 0.24937598407268524 average time 0.0032274718399821723 iter num 600\n",
            "loss 0.13199307024478912 average time 0.0032130290515969165 iter num 620\n",
            "loss 0.42662933468818665 average time 0.003196808524995731 iter num 640\n",
            "loss 0.15390989184379578 average time 0.0031821040833275413 iter num 660\n",
            "loss 0.33124178647994995 average time 0.0031673995470341385 iter num 680\n",
            "loss 0.16382408142089844 average time 0.0031529612814223842 iter num 700\n",
            "loss 0.38094568252563477 average time 0.0031397305486077836 iter num 720\n",
            "loss 0.11857837438583374 average time 0.003126459047298586 iter num 740\n",
            "loss 0.16524283587932587 average time 0.0031146612644701427 iter num 760\n",
            "loss 0.1311236470937729 average time 0.003105183191016691 iter num 780\n",
            "loss 0.08286510407924652 average time 0.003097127038740837 iter num 800\n",
            "loss 0.09302837401628494 average time 0.003086803436568383 iter num 820\n",
            "loss 0.12543454766273499 average time 0.0030766031380889693 iter num 840\n",
            "loss 0.23827627301216125 average time 0.0030674525906866875 iter num 860\n",
            "loss 0.10822159051895142 average time 0.0030592132977124657 iter num 880\n",
            "loss 0.3060738444328308 average time 0.0030501954688710005 iter num 900\n",
            "loss 0.07604774832725525 average time 0.003042961589115926 iter num 920\n",
            "loss 0.1102033257484436 average time 0.003035464111684284 iter num 940\n",
            "loss 0.45647066831588745 average time 0.003027705480193769 iter num 960\n",
            "loss 0.06920257210731506 average time 0.0030201472999746033 iter num 980\n",
            "loss 0.1926126629114151 average time 0.003013284650976857 iter num 1000\n",
            "loss 0.3088819980621338 average time 0.018392811049670853 iter num 20\n",
            "loss 0.4154534935951233 average time 0.010520714049835077 iter num 40\n",
            "loss 0.39544975757598877 average time 0.007904958549988805 iter num 60\n",
            "loss 0.5051416158676147 average time 0.006595176237351552 iter num 80\n",
            "loss 0.7406154274940491 average time 0.005812286329819472 iter num 100\n",
            "loss 0.2515523135662079 average time 0.005307687916532207 iter num 120\n",
            "loss 0.1256735771894455 average time 0.004932958514161458 iter num 140\n",
            "loss 3.730192184448242 average time 0.004651603774914292 iter num 160\n",
            "loss 2.736225128173828 average time 0.004433359777633288 iter num 180\n",
            "loss 0.5800524950027466 average time 0.0042548648448973835 iter num 200\n",
            "loss 0.63036048412323 average time 0.004115818936241505 iter num 220\n",
            "loss 0.3889641761779785 average time 0.003995883208229619 iter num 240\n",
            "loss 0.4178807735443115 average time 0.0038935205422183992 iter num 260\n",
            "loss 0.1030341386795044 average time 0.003802771835632614 iter num 280\n",
            "loss 0.19743205606937408 average time 0.0037306062066030186 iter num 300\n",
            "loss 0.22730602324008942 average time 0.0036681484217979234 iter num 320\n",
            "loss 0.14829815924167633 average time 0.003616023994072748 iter num 340\n",
            "loss 0.5104300379753113 average time 0.0035658010666237616 iter num 360\n",
            "loss 0.21227262914180756 average time 0.0035256268183729844 iter num 380\n",
            "loss 0.4605119228363037 average time 0.003484508809942781 iter num 400\n",
            "loss 0.5077224373817444 average time 0.0034479378999440953 iter num 420\n",
            "loss 0.40883708000183105 average time 0.003412773238605124 iter num 440\n",
            "loss 0.22710490226745605 average time 0.0033890151108489194 iter num 460\n",
            "loss 0.24633431434631348 average time 0.0033599692249860406 iter num 480\n",
            "loss 0.11870403587818146 average time 0.0033335519899774227 iter num 500\n",
            "loss 0.13945889472961426 average time 0.003307185565378089 iter num 520\n",
            "loss 0.3181648254394531 average time 0.0032856807611096883 iter num 540\n",
            "loss 0.3174900412559509 average time 0.0032661136035585514 iter num 560\n",
            "loss 0.17307958006858826 average time 0.00325195432756902 iter num 580\n",
            "loss 0.16674906015396118 average time 0.003244706094980453 iter num 600\n",
            "loss 0.20342294871807098 average time 0.003227172706430147 iter num 620\n",
            "loss 0.31978046894073486 average time 0.003211922843723869 iter num 640\n",
            "loss 0.06933072209358215 average time 0.003194957672701893 iter num 660\n",
            "loss 0.2921544015407562 average time 0.0031907881676274613 iter num 680\n",
            "loss 0.1754927933216095 average time 0.003179007819978454 iter num 700\n",
            "loss 0.20768532156944275 average time 0.0031655639652550843 iter num 720\n",
            "loss 0.21070051193237305 average time 0.0031519977891622222 iter num 740\n",
            "loss 0.11512519419193268 average time 0.003144608859192407 iter num 760\n",
            "loss 0.3592352867126465 average time 0.003133233676910608 iter num 780\n",
            "loss 0.27556031942367554 average time 0.0031227296712313547 iter num 800\n",
            "loss 0.16793571412563324 average time 0.0031127944414614966 iter num 820\n",
            "loss 0.09775727987289429 average time 0.0031046013154731812 iter num 840\n",
            "loss 0.1006459891796112 average time 0.003095300752322019 iter num 860\n",
            "loss 0.04928202927112579 average time 0.00308661873523306 iter num 880\n",
            "loss 0.14363224804401398 average time 0.0030772390133400524 iter num 900\n",
            "loss 0.278767853975296 average time 0.0030688932587074067 iter num 920\n",
            "loss 0.10809993743896484 average time 0.003060265920237029 iter num 940\n",
            "loss 0.11304358392953873 average time 0.0030569761135628443 iter num 960\n",
            "loss 0.035979632288217545 average time 0.0030516859061449674 iter num 980\n",
            "loss 0.09887616336345673 average time 0.0030446381910223864 iter num 1000\n",
            "loss 1.060886025428772 average time 0.01838921269918501 iter num 20\n",
            "loss 0.25905320048332214 average time 0.010619572874475125 iter num 40\n",
            "loss 0.35066938400268555 average time 0.007998236899766198 iter num 60\n",
            "loss 0.8044246435165405 average time 0.006763290524577315 iter num 80\n",
            "loss 0.3111947774887085 average time 0.005956678119691788 iter num 100\n",
            "loss 0.40873053669929504 average time 0.005429620674719141 iter num 120\n",
            "loss 0.07953006029129028 average time 0.0050652560926339775 iter num 140\n",
            "loss 0.47359275817871094 average time 0.004785808687233839 iter num 160\n",
            "loss 0.44121313095092773 average time 0.004567219199695198 iter num 180\n",
            "loss 0.8484190702438354 average time 0.004387187464799353 iter num 200\n",
            "loss 1.0255565643310547 average time 0.004241890967998849 iter num 220\n",
            "loss 0.6139253377914429 average time 0.004136350978963795 iter num 240\n",
            "loss 0.3517376780509949 average time 0.004037741269068927 iter num 260\n",
            "loss 0.27344784140586853 average time 0.003951355785609069 iter num 280\n",
            "loss 0.8075618743896484 average time 0.003870515456571108 iter num 300\n",
            "loss 0.6066809892654419 average time 0.00380402025928106 iter num 320\n",
            "loss 0.5443999767303467 average time 0.003745752029306673 iter num 340\n",
            "loss 0.3265940248966217 average time 0.003690949286040753 iter num 360\n",
            "loss 0.2305564284324646 average time 0.0036412814762450964 iter num 380\n",
            "loss 0.21979984641075134 average time 0.0035984054649361497 iter num 400\n",
            "loss 0.2496720403432846 average time 0.00358395729040023 iter num 420\n",
            "loss 0.2670465409755707 average time 0.0035461246453947254 iter num 440\n",
            "loss 0.3006376624107361 average time 0.0035142971434217306 iter num 460\n",
            "loss 0.15438729524612427 average time 0.0034851485645352414 iter num 480\n",
            "loss 0.1348389983177185 average time 0.0034559551959537204 iter num 500\n",
            "loss 0.3213651478290558 average time 0.0034306164345532754 iter num 520\n",
            "loss 0.3392455577850342 average time 0.0034065722166040494 iter num 540\n",
            "loss 0.18817830085754395 average time 0.0033828236767346554 iter num 560\n",
            "loss 0.36627113819122314 average time 0.0033623013016918337 iter num 580\n",
            "loss 0.31913483142852783 average time 0.003343924973293421 iter num 600\n",
            "loss 0.26027294993400574 average time 0.003331206875760296 iter num 620\n",
            "loss 0.201438769698143 average time 0.003313772584334629 iter num 640\n",
            "loss 0.0979735255241394 average time 0.0033004125499494627 iter num 660\n",
            "loss 0.11235006898641586 average time 0.003283337232299827 iter num 680\n",
            "loss 0.1835891753435135 average time 0.003267748401371396 iter num 700\n",
            "loss 0.1340516358613968 average time 0.0032538902430031967 iter num 720\n",
            "loss 0.17003943026065826 average time 0.003240537514815318 iter num 740\n",
            "loss 0.17037823796272278 average time 0.003227186498607855 iter num 760\n",
            "loss 0.08769726753234863 average time 0.0032149503409247978 iter num 780\n",
            "loss 0.09026488661766052 average time 0.0032090436386397413 iter num 800\n",
            "loss 0.20355573296546936 average time 0.0031990506133297457 iter num 820\n",
            "loss 0.1659761667251587 average time 0.003188232745162081 iter num 840\n",
            "loss 0.22514809668064117 average time 0.0031781013243363664 iter num 860\n",
            "loss 0.3419961929321289 average time 0.0031685816567418937 iter num 880\n",
            "loss 0.1799221783876419 average time 0.003159436217704044 iter num 900\n",
            "loss 0.05153023451566696 average time 0.0031542177868845024 iter num 920\n",
            "loss 0.20771285891532898 average time 0.0031465082180186575 iter num 940\n",
            "loss 0.13892105221748352 average time 0.0031463897405577274 iter num 960\n",
            "loss 0.10641362518072128 average time 0.0031393031836067127 iter num 980\n",
            "loss 0.01920001395046711 average time 0.003132223781940411 iter num 1000\n",
            "loss 1.0261545181274414 average time 0.018262141899867856 iter num 20\n",
            "loss 0.38339585065841675 average time 0.010517242624791834 iter num 40\n",
            "loss 0.9363846778869629 average time 0.007945578266359613 iter num 60\n",
            "loss 1.2723515033721924 average time 0.006639693387342049 iter num 80\n",
            "loss 0.35669049620628357 average time 0.005857203499836032 iter num 100\n",
            "loss 0.10145646333694458 average time 0.0053316057998320805 iter num 120\n",
            "loss 0.1009025126695633 average time 0.0049594903927365 iter num 140\n",
            "loss 0.41246259212493896 average time 0.004677578437394914 iter num 160\n",
            "loss 0.5990767478942871 average time 0.004481078283283245 iter num 180\n",
            "loss 1.0747313499450684 average time 0.004323707029943762 iter num 200\n",
            "loss 0.5187314748764038 average time 0.0041918773999482664 iter num 220\n",
            "loss 0.3314708471298218 average time 0.0040772300208269975 iter num 240\n",
            "loss 0.428320050239563 average time 0.003973679061499961 iter num 260\n",
            "loss 0.19301511347293854 average time 0.0038825508499420332 iter num 280\n",
            "loss 0.4841815233230591 average time 0.0038133254466204865 iter num 300\n",
            "loss 0.23767782747745514 average time 0.003743307571846799 iter num 320\n",
            "loss 0.191205233335495 average time 0.0036967550294053474 iter num 340\n",
            "loss 0.41960951685905457 average time 0.003644172849959028 iter num 360\n",
            "loss 0.148908331990242 average time 0.003604091978942099 iter num 380\n",
            "loss 0.23758471012115479 average time 0.0035616371600281126 iter num 400\n",
            "loss 0.27712932229042053 average time 0.0035274412357639883 iter num 420\n",
            "loss 0.19056092202663422 average time 0.0034895211000730343 iter num 440\n",
            "loss 0.09355843812227249 average time 0.0034670251957362305 iter num 460\n",
            "loss 0.22609946131706238 average time 0.003436549231317561 iter num 480\n",
            "loss 0.13146938383579254 average time 0.0034151844000662097 iter num 500\n",
            "loss 0.33543068170547485 average time 0.0033892456231394766 iter num 520\n",
            "loss 0.17931076884269714 average time 0.0033684993389383805 iter num 540\n",
            "loss 0.11006229370832443 average time 0.003348755035754688 iter num 560\n",
            "loss 0.17619162797927856 average time 0.0033305928448655697 iter num 580\n",
            "loss 0.2113361358642578 average time 0.0033142900200437 iter num 600\n",
            "loss 0.21203529834747314 average time 0.003294409482294859 iter num 620\n",
            "loss 0.3419932425022125 average time 0.0032840157000407545 iter num 640\n",
            "loss 0.08384497463703156 average time 0.0032671420348792295 iter num 660\n",
            "loss 0.18654578924179077 average time 0.003258718682381561 iter num 680\n",
            "loss 0.031115300953388214 average time 0.0032438766957368767 iter num 700\n",
            "loss 0.188350647687912 average time 0.0032304492000194943 iter num 720\n",
            "loss 0.1743989735841751 average time 0.003217954570278085 iter num 740\n",
            "loss 0.25882965326309204 average time 0.0032077568171045736 iter num 760\n",
            "loss 0.08836784958839417 average time 0.003195986917956198 iter num 780\n",
            "loss 0.07856474816799164 average time 0.003184959391260236 iter num 800\n",
            "loss 0.06472338736057281 average time 0.0031735192731857974 iter num 820\n",
            "loss 0.138304203748703 average time 0.0031629949273900863 iter num 840\n",
            "loss 0.2673434913158417 average time 0.0031528276372291444 iter num 860\n",
            "loss 0.10843440145254135 average time 0.0031437527125159582 iter num 880\n",
            "loss 0.1497838795185089 average time 0.0031350365266795657 iter num 900\n",
            "loss 0.022701289504766464 average time 0.0031260353108811378 iter num 920\n",
            "loss 0.1728076934814453 average time 0.003117718836186581 iter num 940\n",
            "loss 0.1798124462366104 average time 0.003109756081270613 iter num 960\n",
            "loss 0.3692907989025116 average time 0.0031018632020611537 iter num 980\n",
            "loss 0.17494536936283112 average time 0.003093985200019233 iter num 1000\n",
            "loss 0.2871857285499573 average time 0.018334188349763282 iter num 20\n",
            "loss 1.0227752923965454 average time 0.010509227149850631 iter num 40\n",
            "loss 0.3898082375526428 average time 0.007900078533384657 iter num 60\n",
            "loss 0.2203102707862854 average time 0.006594781987450915 iter num 80\n",
            "loss 0.8540561199188232 average time 0.005821397139916371 iter num 100\n",
            "loss 0.7902371883392334 average time 0.0053090586416146834 iter num 120\n",
            "loss 0.7008289098739624 average time 0.004933163021399066 iter num 140\n",
            "loss 0.1656450778245926 average time 0.004648856450012317 iter num 160\n",
            "loss 0.3481915593147278 average time 0.004428854588877584 iter num 180\n",
            "loss 0.3860466480255127 average time 0.004259459234945097 iter num 200\n",
            "loss 0.2377849668264389 average time 0.004126291322625713 iter num 220\n",
            "loss 0.17682898044586182 average time 0.0040042909206931656 iter num 240\n",
            "loss 0.418773889541626 average time 0.0039042299267748604 iter num 260\n",
            "loss 0.3389226198196411 average time 0.0038259163427678037 iter num 280\n",
            "loss 0.5484811067581177 average time 0.0037500788465695224 iter num 300\n",
            "loss 0.08809642493724823 average time 0.0036847170968030696 iter num 320\n",
            "loss 0.19651715457439423 average time 0.0036269387205239206 iter num 340\n",
            "loss 0.06426502764225006 average time 0.003578403566613512 iter num 360\n",
            "loss 0.4944193661212921 average time 0.00353525718413661 iter num 380\n",
            "loss 0.2929750680923462 average time 0.003491475787404852 iter num 400\n",
            "loss 0.18603459000587463 average time 0.003455802956999659 iter num 420\n",
            "loss 0.27111542224884033 average time 0.0034198362475763135 iter num 440\n",
            "loss 0.2823997437953949 average time 0.0033903496585638926 iter num 460\n",
            "loss 0.16497734189033508 average time 0.003360350670694364 iter num 480\n",
            "loss 0.46164777874946594 average time 0.003333754819861497 iter num 500\n",
            "loss 0.12713244557380676 average time 0.003309169874857896 iter num 520\n",
            "loss 0.40518325567245483 average time 0.003294510960970203 iter num 540\n",
            "loss 0.1865776777267456 average time 0.0032728394088085873 iter num 560\n",
            "loss 0.2855030596256256 average time 0.00325504860848641 iter num 580\n",
            "loss 0.1065998375415802 average time 0.003239167606528402 iter num 600\n",
            "loss 0.20471835136413574 average time 0.0032217407159893605 iter num 620\n",
            "loss 0.2961055636405945 average time 0.003204715798307234 iter num 640\n",
            "loss 0.05782890319824219 average time 0.0031894585786534607 iter num 660\n",
            "loss 0.13358339667320251 average time 0.003173638548399621 iter num 680\n",
            "loss 0.05803133174777031 average time 0.0031591293241581297 iter num 700\n",
            "loss 0.14727497100830078 average time 0.0031458735040410424 iter num 720\n",
            "loss 0.04848465695977211 average time 0.0031361461147359996 iter num 740\n",
            "loss 0.1700907051563263 average time 0.00313127997488233 iter num 760\n",
            "loss 0.12088239192962646 average time 0.0031198797024514463 iter num 780\n",
            "loss 0.3284769654273987 average time 0.0031116926223876363 iter num 800\n",
            "loss 0.3729025721549988 average time 0.003100454753550322 iter num 820\n",
            "loss 0.3163350224494934 average time 0.003092359645130013 iter num 840\n",
            "loss 0.0798056498169899 average time 0.003082764008036594 iter num 860\n",
            "loss 0.10732190310955048 average time 0.003073842709004153 iter num 880\n",
            "loss 0.06942214071750641 average time 0.003064780972146966 iter num 900\n",
            "loss 0.11033642292022705 average time 0.003057318523852977 iter num 920\n",
            "loss 0.10279523581266403 average time 0.00304931287335305 iter num 940\n",
            "loss 0.1299697756767273 average time 0.0030424176759917525 iter num 960\n",
            "loss 0.1934964954853058 average time 0.003035111612192924 iter num 980\n",
            "loss 0.19418998062610626 average time 0.0030276354019406425 iter num 1000\n",
            "loss 0.18534423410892487 average time 0.018411057850244106 iter num 20\n",
            "loss 0.6276126503944397 average time 0.010553448950031453 iter num 40\n",
            "loss 0.36487603187561035 average time 0.007938764616725772 iter num 60\n",
            "loss 0.3936384320259094 average time 0.006619838025108038 iter num 80\n",
            "loss 0.24957743287086487 average time 0.005828920470157754 iter num 100\n",
            "loss 0.25200945138931274 average time 0.005302056141711849 iter num 120\n",
            "loss 0.5232661962509155 average time 0.0049357083714442395 iter num 140\n",
            "loss 1.2937514781951904 average time 0.004657482074958352 iter num 160\n",
            "loss 0.2120869904756546 average time 0.004435686777691849 iter num 180\n",
            "loss 1.1766644716262817 average time 0.0042614716099342335 iter num 200\n",
            "loss 0.438010573387146 average time 0.004125404699929773 iter num 220\n",
            "loss 0.5151970982551575 average time 0.004004264420776356 iter num 240\n",
            "loss 0.2176835536956787 average time 0.003906446811491221 iter num 260\n",
            "loss 0.5911205410957336 average time 0.003817732503492672 iter num 280\n",
            "loss 0.41718631982803345 average time 0.0037412544265801747 iter num 300\n",
            "loss 0.17270876467227936 average time 0.003695869921773465 iter num 320\n",
            "loss 0.3478790521621704 average time 0.0036353572087083354 iter num 340\n",
            "loss 0.27002978324890137 average time 0.0035833092776657496 iter num 360\n",
            "loss 0.2713165283203125 average time 0.003536372694610404 iter num 380\n",
            "loss 0.1461026817560196 average time 0.0035024118723777065 iter num 400\n",
            "loss 0.449709415435791 average time 0.0034633177951209726 iter num 420\n",
            "loss 0.15743105113506317 average time 0.0034294193317360956 iter num 440\n",
            "loss 0.23449863493442535 average time 0.0033969183325098127 iter num 460\n",
            "loss 0.3821510672569275 average time 0.003377004295733362 iter num 480\n",
            "loss 0.4124029576778412 average time 0.0033474367499075016 iter num 500\n",
            "loss 0.18942353129386902 average time 0.0033230829037655405 iter num 520\n",
            "loss 0.5192660093307495 average time 0.0033050802925033537 iter num 540\n",
            "loss 0.08888033032417297 average time 0.003287262501693736 iter num 560\n",
            "loss 0.6347578763961792 average time 0.003267798365438999 iter num 580\n",
            "loss 0.13369998335838318 average time 0.0032488830116017197 iter num 600\n",
            "loss 0.039108652621507645 average time 0.0032362750063956837 iter num 620\n",
            "loss 0.4916107952594757 average time 0.003218488653061513 iter num 640\n",
            "loss 0.14767467975616455 average time 0.0032026727393299967 iter num 660\n",
            "loss 0.1712096631526947 average time 0.0031895279984650296 iter num 680\n",
            "loss 0.14361564815044403 average time 0.0031789283656689805 iter num 700\n",
            "loss 0.2066943347454071 average time 0.0031645865860708807 iter num 720\n",
            "loss 0.4805530309677124 average time 0.0031561290742772416 iter num 740\n",
            "loss 0.028166165575385094 average time 0.0031455997275722774 iter num 760\n",
            "loss 0.17407970130443573 average time 0.003137414592268984 iter num 780\n",
            "loss 0.26177769899368286 average time 0.003127147276204596 iter num 800\n",
            "loss 0.20701640844345093 average time 0.0031181482158078836 iter num 820\n",
            "loss 0.2161692976951599 average time 0.003107714959484535 iter num 840\n",
            "loss 0.14958453178405762 average time 0.0031040450057675073 iter num 860\n",
            "loss 0.22275815904140472 average time 0.003098484835192556 iter num 880\n",
            "loss 0.1318623572587967 average time 0.0030922977333062186 iter num 900\n",
            "loss 0.061844952404499054 average time 0.0030828397543107553 iter num 920\n",
            "loss 0.14054907858371735 average time 0.0030752540978473335 iter num 940\n",
            "loss 0.38614994287490845 average time 0.0030663676499936327 iter num 960\n",
            "loss 0.03935576230287552 average time 0.003060507359185401 iter num 980\n",
            "loss 0.4392835199832916 average time 0.0030532227420117125 iter num 1000\n",
            "loss 0.2600724697113037 average time 0.018408294950131677 iter num 20\n",
            "loss 1.608771800994873 average time 0.010530492000452796 iter num 40\n",
            "loss 0.2996583878993988 average time 0.007912506933522915 iter num 60\n",
            "loss 0.1401413232088089 average time 0.006601965237587137 iter num 80\n",
            "loss 0.6629898548126221 average time 0.00583440155009157 iter num 100\n",
            "loss 0.2917936444282532 average time 0.005307096200037146 iter num 120\n",
            "loss 0.38848382234573364 average time 0.00493758472148329 iter num 140\n",
            "loss 2.0789706707000732 average time 0.004652830018790155 iter num 160\n",
            "loss 2.6553688049316406 average time 0.00443301213334861 iter num 180\n",
            "loss 0.46144574880599976 average time 0.004257213119926746 iter num 200\n",
            "loss 0.20059943199157715 average time 0.0041132611499382285 iter num 220\n",
            "loss 0.3987269401550293 average time 0.003990928270786754 iter num 240\n",
            "loss 0.1690676212310791 average time 0.003888182403800154 iter num 260\n",
            "loss 0.2522333264350891 average time 0.0037980695284984124 iter num 280\n",
            "loss 0.3602730929851532 average time 0.0037212437032576417 iter num 300\n",
            "loss 0.07496024668216705 average time 0.0036681010593270003 iter num 320\n",
            "loss 0.3313254714012146 average time 0.003614837982283515 iter num 340\n",
            "loss 0.1901082694530487 average time 0.0035627864499070305 iter num 360\n",
            "loss 0.1714022010564804 average time 0.0035182606946794915 iter num 380\n",
            "loss 0.4005320966243744 average time 0.003474840617463997 iter num 400\n",
            "loss 0.08275635540485382 average time 0.003438402142819541 iter num 420\n",
            "loss 0.2899356484413147 average time 0.003409318565900321 iter num 440\n",
            "loss 0.44428199529647827 average time 0.0033864160717079674 iter num 460\n",
            "loss 0.5067736506462097 average time 0.0033591552187317575 iter num 480\n",
            "loss 0.13289980590343475 average time 0.0033432488899925376 iter num 500\n",
            "loss 0.34507471323013306 average time 0.003329141692302073 iter num 520\n",
            "loss 0.40100541710853577 average time 0.003308445979638674 iter num 540\n",
            "loss 0.03551838919520378 average time 0.0032906559196492578 iter num 560\n",
            "loss 0.15020766854286194 average time 0.003277532048290094 iter num 580\n",
            "loss 0.10417822003364563 average time 0.0032616972850155433 iter num 600\n",
            "loss 0.08380933851003647 average time 0.0032484494451813176 iter num 620\n",
            "loss 0.5124397277832031 average time 0.003237573007834271 iter num 640\n",
            "loss 0.14526018500328064 average time 0.0032211495515487814 iter num 660\n",
            "loss 0.15159446001052856 average time 0.003215182916204974 iter num 680\n",
            "loss 0.09253521263599396 average time 0.0032001085143097694 iter num 700\n",
            "loss 0.3597068190574646 average time 0.003186198109748754 iter num 720\n",
            "loss 0.14953093230724335 average time 0.0031745636216500487 iter num 740\n",
            "loss 0.4337303638458252 average time 0.0031682672565885267 iter num 760\n",
            "loss 0.17658406496047974 average time 0.003158253392323856 iter num 780\n",
            "loss 0.23295260965824127 average time 0.0031478311612727337 iter num 800\n",
            "loss 0.1762205958366394 average time 0.0031407604695298844 iter num 820\n",
            "loss 0.101744145154953 average time 0.0031315616452524237 iter num 840\n",
            "loss 0.14058808982372284 average time 0.0031251410907168257 iter num 860\n",
            "loss 0.21661649644374847 average time 0.0031166205670780816 iter num 880\n",
            "loss 0.030504733324050903 average time 0.0031073203489197314 iter num 900\n",
            "loss 0.12297996878623962 average time 0.003099764878282693 iter num 920\n",
            "loss 0.2043067216873169 average time 0.0030940884276826684 iter num 940\n",
            "loss 0.07321011275053024 average time 0.00308631998960512 iter num 960\n",
            "loss 0.0536683052778244 average time 0.0030814481398177733 iter num 980\n",
            "loss 0.04360869899392128 average time 0.003075727198029199 iter num 1000\n",
            "loss 0.7608318328857422 average time 0.01843387664976035 iter num 20\n",
            "loss 0.4387175440788269 average time 0.010631001825186105 iter num 40\n",
            "loss 0.2728149890899658 average time 0.008010730583312883 iter num 60\n",
            "loss 0.267760694026947 average time 0.006702839262607086 iter num 80\n",
            "loss 1.251969575881958 average time 0.005918481090084242 iter num 100\n",
            "loss 0.6663454174995422 average time 0.005395336825101064 iter num 120\n",
            "loss 0.16914136707782745 average time 0.005033286085771189 iter num 140\n",
            "loss 0.3069327473640442 average time 0.004788218143835366 iter num 160\n",
            "loss 0.23211365938186646 average time 0.00459749668342637 iter num 180\n",
            "loss 0.10787206888198853 average time 0.004414519300044048 iter num 200\n",
            "loss 0.1972026824951172 average time 0.004260835418228287 iter num 220\n",
            "loss 0.14658083021640778 average time 0.004137225179207841 iter num 240\n",
            "loss 0.35521960258483887 average time 0.004032159169289046 iter num 260\n",
            "loss 0.17718398571014404 average time 0.003937820325050519 iter num 280\n",
            "loss 0.1213611587882042 average time 0.0038555329933418155 iter num 300\n",
            "loss 0.18681222200393677 average time 0.0037844689750613724 iter num 320\n",
            "loss 0.07942631840705872 average time 0.003720810905927946 iter num 340\n",
            "loss 0.1927608996629715 average time 0.0036638794611563853 iter num 360\n",
            "loss 0.7211005687713623 average time 0.0036174056395458665 iter num 380\n",
            "loss 0.7382678985595703 average time 0.003572287640054128 iter num 400\n",
            "loss 0.24449536204338074 average time 0.003530269238148148 iter num 420\n",
            "loss 0.13487671315670013 average time 0.003492349595498209 iter num 440\n",
            "loss 0.1248653456568718 average time 0.0034571204522169706 iter num 460\n",
            "loss 0.3236194849014282 average time 0.0034259148792140574 iter num 480\n",
            "loss 0.44304755330085754 average time 0.003398852082034864 iter num 500\n",
            "loss 0.23127727210521698 average time 0.0033744240134882812 iter num 520\n",
            "loss 0.19089703261852264 average time 0.0033538612240860215 iter num 540\n",
            "loss 0.36471763253211975 average time 0.003334666033944294 iter num 560\n",
            "loss 0.24801398813724518 average time 0.0033170313517420537 iter num 580\n",
            "loss 0.28959891200065613 average time 0.0032990138116898984 iter num 600\n",
            "loss 0.22946305572986603 average time 0.0032811391774474384 iter num 620\n",
            "loss 0.15559011697769165 average time 0.00326483742813366 iter num 640\n",
            "loss 0.08302830159664154 average time 0.0032486629363891995 iter num 660\n",
            "loss 0.19940945506095886 average time 0.0032327197500201105 iter num 680\n",
            "loss 0.11957482993602753 average time 0.0032179068542973256 iter num 700\n",
            "loss 0.08754561841487885 average time 0.003204084356947432 iter num 720\n",
            "loss 0.14211590588092804 average time 0.0031983289148597945 iter num 740\n",
            "loss 0.22097846865653992 average time 0.003184738681571425 iter num 760\n",
            "loss 0.29691898822784424 average time 0.003172408407688356 iter num 780\n",
            "loss 0.1339583545923233 average time 0.003160853263766512 iter num 800\n",
            "loss 0.2126569151878357 average time 0.0031509627951358775 iter num 820\n",
            "loss 0.2202889323234558 average time 0.003141502502391328 iter num 840\n",
            "loss 0.0835287868976593 average time 0.003132547559310529 iter num 860\n",
            "loss 0.3025822937488556 average time 0.0031233901000012505 iter num 880\n",
            "loss 0.17867285013198853 average time 0.0031148842466629705 iter num 900\n",
            "loss 0.15336841344833374 average time 0.003106511483688139 iter num 920\n",
            "loss 0.11443076282739639 average time 0.0030998306872324394 iter num 940\n",
            "loss 0.30144184827804565 average time 0.003093735708330314 iter num 960\n",
            "loss 0.1481577306985855 average time 0.003087403086743618 iter num 980\n",
            "loss 0.1596960723400116 average time 0.003080372819007607 iter num 1000\n",
            "loss 0.6083632111549377 average time 0.01835583725023753 iter num 20\n",
            "loss 0.2539829909801483 average time 0.010525230350049241 iter num 40\n",
            "loss 0.18271973729133606 average time 0.007922123449983094 iter num 60\n",
            "loss 0.32962995767593384 average time 0.006622703137554709 iter num 80\n",
            "loss 0.5091732144355774 average time 0.005840168060058204 iter num 100\n",
            "loss 1.6046829223632812 average time 0.005317795458449836 iter num 120\n",
            "loss 0.5808495879173279 average time 0.0049463973857720184 iter num 140\n",
            "loss 0.4727851152420044 average time 0.004675301425027101 iter num 160\n",
            "loss 0.1958087831735611 average time 0.00446207409444873 iter num 180\n",
            "loss 0.48276543617248535 average time 0.004288327390022459 iter num 200\n",
            "loss 0.4224332869052887 average time 0.004151153927291902 iter num 220\n",
            "loss 0.2549416124820709 average time 0.004037497354192965 iter num 240\n",
            "loss 0.6995943784713745 average time 0.0039777178077061905 iter num 260\n",
            "loss 0.370096355676651 average time 0.0038941152035736845 iter num 280\n",
            "loss 0.7359898686408997 average time 0.0038194887933059364 iter num 300\n",
            "loss 0.20742464065551758 average time 0.003760291096864421 iter num 320\n",
            "loss 0.1641901582479477 average time 0.003702686041191662 iter num 340\n",
            "loss 0.7479981184005737 average time 0.00365897788889116 iter num 360\n",
            "loss 0.4434424638748169 average time 0.0036102557289268587 iter num 380\n",
            "loss 0.6657487750053406 average time 0.0035658733624677552 iter num 400\n",
            "loss 0.17872554063796997 average time 0.003526143283289414 iter num 420\n",
            "loss 0.1032758578658104 average time 0.003492377199960505 iter num 440\n",
            "loss 0.38448822498321533 average time 0.0034610417869534223 iter num 460\n",
            "loss 0.22302842140197754 average time 0.0034297030687715354 iter num 480\n",
            "loss 0.1516193002462387 average time 0.003403334688016912 iter num 500\n",
            "loss 0.06964074075222015 average time 0.003376240761526088 iter num 520\n",
            "loss 0.25036317110061646 average time 0.0033517494111139157 iter num 540\n",
            "loss 0.21074846386909485 average time 0.003332371216077133 iter num 560\n",
            "loss 0.15730789303779602 average time 0.0033118873707092557 iter num 580\n",
            "loss 0.20767182111740112 average time 0.0032914995400399978 iter num 600\n",
            "loss 0.13891375064849854 average time 0.0032721616726297314 iter num 620\n",
            "loss 0.1417040377855301 average time 0.0032547320641015177 iter num 640\n",
            "loss 0.2775285840034485 average time 0.00323944626823394 iter num 660\n",
            "loss 0.20096349716186523 average time 0.003225324754459828 iter num 680\n",
            "loss 0.12607912719249725 average time 0.0032160029986126964 iter num 700\n",
            "loss 0.22160744667053223 average time 0.0032013446861633888 iter num 720\n",
            "loss 0.06765539199113846 average time 0.0031940749865375317 iter num 740\n",
            "loss 0.1713748276233673 average time 0.0031810477645242492 iter num 760\n",
            "loss 0.1701144576072693 average time 0.0031687209398044685 iter num 780\n",
            "loss 0.26691871881484985 average time 0.0031585411813057364 iter num 800\n",
            "loss 0.09277279675006866 average time 0.0031482834037222613 iter num 820\n",
            "loss 0.04601426422595978 average time 0.0031402083786339235 iter num 840\n",
            "loss 0.07918967306613922 average time 0.003130356015182854 iter num 860\n",
            "loss 0.09836409986019135 average time 0.0031206050625562716 iter num 880\n",
            "loss 0.13026849925518036 average time 0.003111354895619216 iter num 900\n",
            "loss 0.18442165851593018 average time 0.003105230030490455 iter num 920\n",
            "loss 0.12655864655971527 average time 0.003096729618130454 iter num 940\n",
            "loss 0.20438727736473083 average time 0.0030902703990060825 iter num 960\n",
            "loss 0.31325656175613403 average time 0.0030823893622904767 iter num 980\n",
            "loss 0.11986380070447922 average time 0.0030790621990599903 iter num 1000\n",
            "loss 0.5097151398658752 average time 0.01841123095018702 iter num 20\n",
            "loss 0.08331920206546783 average time 0.010558269650300645 iter num 40\n",
            "loss 0.2373649775981903 average time 0.007947977850320361 iter num 60\n",
            "loss 1.1144497394561768 average time 0.006676316025186679 iter num 80\n",
            "loss 0.39525914192199707 average time 0.005881697760087263 iter num 100\n",
            "loss 0.1955161988735199 average time 0.0053976945917384 iter num 120\n",
            "loss 0.24550393223762512 average time 0.005019425700083957 iter num 140\n",
            "loss 0.2365713268518448 average time 0.004729224681341293 iter num 160\n",
            "loss 0.5163487792015076 average time 0.004505578211218462 iter num 180\n",
            "loss 2.173524856567383 average time 0.0043329565400199496 iter num 200\n",
            "loss 0.5347645878791809 average time 0.004190480281861462 iter num 220\n",
            "loss 0.410256028175354 average time 0.004067751529252443 iter num 240\n",
            "loss 0.1408502459526062 average time 0.003971547338551318 iter num 260\n",
            "loss 0.16607874631881714 average time 0.003885345857218324 iter num 280\n",
            "loss 0.2074923813343048 average time 0.003808372190069349 iter num 300\n",
            "loss 0.39582157135009766 average time 0.0037581451063374515 iter num 320\n",
            "loss 0.210596963763237 average time 0.0036983491736357205 iter num 340\n",
            "loss 0.11598364263772964 average time 0.0036423362500803097 iter num 360\n",
            "loss 0.22112508118152618 average time 0.0035938180658712025 iter num 380\n",
            "loss 0.2085483819246292 average time 0.0035493209026026306 iter num 400\n",
            "loss 0.14884629845619202 average time 0.0035102109310260164 iter num 420\n",
            "loss 0.3958399295806885 average time 0.00347381060461306 iter num 440\n",
            "loss 0.3387986421585083 average time 0.003445901326172727 iter num 460\n",
            "loss 0.48267775774002075 average time 0.0034257626729868205 iter num 480\n",
            "loss 0.23195505142211914 average time 0.003396286788090947 iter num 500\n",
            "loss 1.0150814056396484 average time 0.0033721329116185817 iter num 520\n",
            "loss 0.28624284267425537 average time 0.003349844174132428 iter num 540\n",
            "loss 0.1896536648273468 average time 0.00332768646256097 iter num 560\n",
            "loss 0.19955065846443176 average time 0.0033088901914480034 iter num 580\n",
            "loss 0.14625237882137299 average time 0.0032913873550751305 iter num 600\n",
            "loss 0.19860932230949402 average time 0.0032743530129723253 iter num 620\n",
            "loss 0.24596813321113586 average time 0.0032617184391654066 iter num 640\n",
            "loss 0.24476391077041626 average time 0.0032478081046451047 iter num 660\n",
            "loss 0.1323750913143158 average time 0.0032399778721596438 iter num 680\n",
            "loss 0.17630642652511597 average time 0.003228513341522817 iter num 700\n",
            "loss 0.13530051708221436 average time 0.0032207389862075313 iter num 720\n",
            "loss 0.12124462425708771 average time 0.003210139824413754 iter num 740\n",
            "loss 0.09973359107971191 average time 0.003198636121143002 iter num 760\n",
            "loss 0.2423972189426422 average time 0.0031875043744525426 iter num 780\n",
            "loss 0.08183974027633667 average time 0.0031761399888364395 iter num 800\n",
            "loss 0.2311684489250183 average time 0.0031647142476441976 iter num 820\n",
            "loss 0.3954260051250458 average time 0.0031542771310385086 iter num 840\n",
            "loss 0.07224489748477936 average time 0.0031452257187105036 iter num 860\n",
            "loss 0.3645242750644684 average time 0.0031354893341978655 iter num 880\n",
            "loss 0.14343926310539246 average time 0.0031266867400982948 iter num 900\n",
            "loss 0.2564661502838135 average time 0.003117428335973154 iter num 920\n",
            "loss 0.09936872869729996 average time 0.0031103052969016025 iter num 940\n",
            "loss 0.08383600413799286 average time 0.003105687312590059 iter num 960\n",
            "loss 0.3129423260688782 average time 0.003099137799071453 iter num 980\n",
            "loss 0.06847169995307922 average time 0.0030910031560888456 iter num 1000\n",
            "loss 0.2877318859100342 average time 0.018494772400299554 iter num 20\n",
            "loss 0.7723457217216492 average time 0.010620420100258344 iter num 40\n",
            "loss 0.3096327483654022 average time 0.008073435083436683 iter num 60\n",
            "loss 0.3339807093143463 average time 0.006743627162495614 iter num 80\n",
            "loss 0.5283699035644531 average time 0.005969889500083809 iter num 100\n",
            "loss 0.13782180845737457 average time 0.005448827158276496 iter num 120\n",
            "loss 0.20232993364334106 average time 0.005067592057067876 iter num 140\n",
            "loss 0.4940297603607178 average time 0.004776568724923891 iter num 160\n",
            "loss 0.20591457188129425 average time 0.004560363216599702 iter num 180\n",
            "loss 0.1254844218492508 average time 0.004378390534893697 iter num 200\n",
            "loss 0.3481988310813904 average time 0.004233512531721896 iter num 220\n",
            "loss 0.3620927929878235 average time 0.0041148538915270665 iter num 240\n",
            "loss 0.734916090965271 average time 0.004022177026770525 iter num 260\n",
            "loss 0.19679200649261475 average time 0.00393821057848202 iter num 280\n",
            "loss 0.21118947863578796 average time 0.003875163583252288 iter num 300\n",
            "loss 1.0334315299987793 average time 0.003807003456165603 iter num 320\n",
            "loss 0.1671036034822464 average time 0.0037474543587129173 iter num 340\n",
            "loss 0.2592853903770447 average time 0.0036977402582629615 iter num 360\n",
            "loss 0.19777092337608337 average time 0.0036615899130993056 iter num 380\n",
            "loss 0.3596344590187073 average time 0.003624260524929923 iter num 400\n",
            "loss 0.09587396681308746 average time 0.0035921077880023706 iter num 420\n",
            "loss 0.19531548023223877 average time 0.003566224754434767 iter num 440\n",
            "loss 0.19212259352207184 average time 0.0035307745999212468 iter num 460\n",
            "loss 0.29340505599975586 average time 0.0034976015332555716 iter num 480\n",
            "loss 0.2960607707500458 average time 0.003467665687931003 iter num 500\n",
            "loss 0.1984322965145111 average time 0.003440458453762683 iter num 520\n",
            "loss 0.2622309625148773 average time 0.0034151283295445695 iter num 540\n",
            "loss 0.29691341519355774 average time 0.003392870953491313 iter num 560\n",
            "loss 0.2721743583679199 average time 0.0033725352843938365 iter num 580\n",
            "loss 0.2709125876426697 average time 0.003351726759883604 iter num 600\n",
            "loss 0.29214954376220703 average time 0.0033314694966623303 iter num 620\n",
            "loss 0.4027082920074463 average time 0.0033123159655076505 iter num 640\n",
            "loss 0.1375478357076645 average time 0.003295050527175948 iter num 660\n",
            "loss 0.2644117772579193 average time 0.0032782144895945214 iter num 680\n",
            "loss 0.41855546832084656 average time 0.0032635566084562536 iter num 700\n",
            "loss 0.2853008806705475 average time 0.003249161637374224 iter num 720\n",
            "loss 0.14319388568401337 average time 0.0032382509944688313 iter num 740\n",
            "loss 0.12454021722078323 average time 0.003226063763036348 iter num 760\n",
            "loss 0.1329742819070816 average time 0.0032136368434713893 iter num 780\n",
            "loss 0.2493511587381363 average time 0.0032071533123871634 iter num 800\n",
            "loss 0.1306309998035431 average time 0.0031963845450152847 iter num 820\n",
            "loss 0.2109995186328888 average time 0.0031850921998912303 iter num 840\n",
            "loss 0.12174344062805176 average time 0.0031749887429235292 iter num 860\n",
            "loss 0.17215502262115479 average time 0.003164678453313999 iter num 880\n",
            "loss 0.09883593022823334 average time 0.0031559133987927148 iter num 900\n",
            "loss 0.2809118628501892 average time 0.0031470265564245855 iter num 920\n",
            "loss 0.11496327817440033 average time 0.0031377277956554724 iter num 940\n",
            "loss 0.11825232207775116 average time 0.003129985628027043 iter num 960\n",
            "loss 0.20191341638565063 average time 0.0031221501713194553 iter num 980\n",
            "loss 0.11064693331718445 average time 0.0031149041978933384 iter num 1000\n",
            "loss 0.3506218492984772 average time 0.018414706350085908 iter num 20\n",
            "loss 0.5544671416282654 average time 0.01062063767476502 iter num 40\n",
            "loss 0.5325050354003906 average time 0.008004000283108326 iter num 60\n",
            "loss 0.37777742743492126 average time 0.006706756937319369 iter num 80\n",
            "loss 0.3792251944541931 average time 0.005922201319772284 iter num 100\n",
            "loss 0.40401023626327515 average time 0.0054238462748799066 iter num 120\n",
            "loss 0.37656092643737793 average time 0.005038792299819761 iter num 140\n",
            "loss 0.7287429571151733 average time 0.0047515712873519075 iter num 160\n",
            "loss 0.3024527430534363 average time 0.004527822622104496 iter num 180\n",
            "loss 0.5366131663322449 average time 0.004351255974834203 iter num 200\n",
            "loss 0.6202224493026733 average time 0.0042075965044535805 iter num 220\n",
            "loss 0.19357959926128387 average time 0.004085135087431506 iter num 240\n",
            "loss 0.36473599076271057 average time 0.003986489426866823 iter num 260\n",
            "loss 0.14499187469482422 average time 0.0039009871892631055 iter num 280\n",
            "loss 0.1835629940032959 average time 0.0038269500899574876 iter num 300\n",
            "loss 0.05658074840903282 average time 0.0037589245499702884 iter num 320\n",
            "loss 1.213537573814392 average time 0.0037086050058539564 iter num 340\n",
            "loss 0.5302621126174927 average time 0.003655596769416055 iter num 360\n",
            "loss 0.1865561604499817 average time 0.003608789528956741 iter num 380\n",
            "loss 0.22415398061275482 average time 0.0035704681100105517 iter num 400\n",
            "loss 0.1804843246936798 average time 0.003534912483380703 iter num 420\n",
            "loss 0.06658989191055298 average time 0.003498947497775424 iter num 440\n",
            "loss 0.5473694801330566 average time 0.0034782702761494083 iter num 460\n",
            "loss 0.13077005743980408 average time 0.0034496164250488923 iter num 480\n",
            "loss 0.1737869679927826 average time 0.003422576648037648 iter num 500\n",
            "loss 0.13488049805164337 average time 0.0034006352904095995 iter num 520\n",
            "loss 0.1391897350549698 average time 0.003377207855549016 iter num 540\n",
            "loss 0.08042849600315094 average time 0.0033551999178468707 iter num 560\n",
            "loss 0.1227472573518753 average time 0.0033355798603412856 iter num 580\n",
            "loss 0.08496088534593582 average time 0.0033157311816466974 iter num 600\n",
            "loss 0.11372788995504379 average time 0.0032991971709693205 iter num 620\n",
            "loss 0.324219673871994 average time 0.003281144010929893 iter num 640\n",
            "loss 0.09389694780111313 average time 0.0032648506181651485 iter num 660\n",
            "loss 0.13128642737865448 average time 0.0032485275102825495 iter num 680\n",
            "loss 0.1696423441171646 average time 0.003234162931418853 iter num 700\n",
            "loss 0.21758437156677246 average time 0.003236799868040584 iter num 720\n",
            "loss 0.5227421522140503 average time 0.003222388147278744 iter num 740\n",
            "loss 0.11176786571741104 average time 0.0032097750565586274 iter num 760\n",
            "loss 0.08164556324481964 average time 0.003201722394833968 iter num 780\n",
            "loss 0.14423874020576477 average time 0.003190758136220211 iter num 800\n",
            "loss 0.15732327103614807 average time 0.003184166679229969 iter num 820\n",
            "loss 0.17974919080734253 average time 0.0031734129345014003 iter num 840\n",
            "loss 0.12607252597808838 average time 0.003162937972063996 iter num 860\n",
            "loss 0.20848719775676727 average time 0.003155328846564358 iter num 880\n",
            "loss 0.352588951587677 average time 0.0031458846388583575 iter num 900\n",
            "loss 0.5831259489059448 average time 0.0031377788238822414 iter num 920\n",
            "loss 0.18412092328071594 average time 0.0031293470201799595 iter num 940\n",
            "loss 0.3474354147911072 average time 0.0031219372124799824 iter num 960\n",
            "loss 0.21797165274620056 average time 0.003113773445904965 iter num 980\n",
            "loss 0.02431192435324192 average time 0.0031062050799846473 iter num 1000\n",
            "loss 0.19015172123908997 average time 0.018348262649851677 iter num 20\n",
            "loss 0.7415684461593628 average time 0.010566244599795027 iter num 40\n",
            "loss 1.0954736471176147 average time 0.007956683399788745 iter num 60\n",
            "loss 0.36279505491256714 average time 0.00666874753733282 iter num 80\n",
            "loss 0.27874425053596497 average time 0.005886119339811558 iter num 100\n",
            "loss 0.17000393569469452 average time 0.005365287241450763 iter num 120\n",
            "loss 0.25320398807525635 average time 0.0049928088212254805 iter num 140\n",
            "loss 0.2601638436317444 average time 0.00472442751233757 iter num 160\n",
            "loss 1.5278353691101074 average time 0.0045014742554485565 iter num 180\n",
            "loss 0.801693320274353 average time 0.004321981859902735 iter num 200\n",
            "loss 0.2763407528400421 average time 0.004179849263511477 iter num 220\n",
            "loss 0.31747251749038696 average time 0.0040740139248706935 iter num 240\n",
            "loss 0.29223668575286865 average time 0.0039701990613908635 iter num 260\n",
            "loss 0.08622018247842789 average time 0.0038818223320049583 iter num 280\n",
            "loss 0.49638354778289795 average time 0.003805241296540771 iter num 300\n",
            "loss 0.16683416068553925 average time 0.0037451259311183094 iter num 320\n",
            "loss 0.2087264358997345 average time 0.003685797244018913 iter num 340\n",
            "loss 0.2678472101688385 average time 0.0036339918693253518 iter num 360\n",
            "loss 0.37188389897346497 average time 0.003589904415687335 iter num 380\n",
            "loss 0.1631501317024231 average time 0.0035556261948931933 iter num 400\n",
            "loss 0.07913784682750702 average time 0.003517445245129888 iter num 420\n",
            "loss 0.17117087543010712 average time 0.003483065933993533 iter num 440\n",
            "loss 0.41382622718811035 average time 0.003450247710774736 iter num 460\n",
            "loss 0.39008796215057373 average time 0.0034197008165847364 iter num 480\n",
            "loss 0.23593413829803467 average time 0.003391962049921858 iter num 500\n",
            "loss 0.18628466129302979 average time 0.0033667644903149405 iter num 520\n",
            "loss 0.05074837803840637 average time 0.003344791840660306 iter num 540\n",
            "loss 0.26221901178359985 average time 0.0033265201017197146 iter num 560\n",
            "loss 0.17086607217788696 average time 0.0033071290275356975 iter num 580\n",
            "loss 0.2459937334060669 average time 0.0032885042482909436 iter num 600\n",
            "loss 0.1321895867586136 average time 0.003271684396713681 iter num 620\n",
            "loss 0.2455647885799408 average time 0.0032542292077607725 iter num 640\n",
            "loss 0.14641505479812622 average time 0.0032378328226927394 iter num 660\n",
            "loss 0.22168225049972534 average time 0.003222099783798673 iter num 680\n",
            "loss 0.2483903020620346 average time 0.0032072417914085754 iter num 700\n",
            "loss 0.08274267613887787 average time 0.0031993063347120674 iter num 720\n",
            "loss 0.17368566989898682 average time 0.0031866219405511965 iter num 740\n",
            "loss 0.2151637077331543 average time 0.003174604413183452 iter num 760\n",
            "loss 0.27309757471084595 average time 0.0031644127859181024 iter num 780\n",
            "loss 0.2084086686372757 average time 0.0031543316037641487 iter num 800\n",
            "loss 0.17460089921951294 average time 0.003144918597562781 iter num 820\n",
            "loss 0.1297094225883484 average time 0.00313571389404041 iter num 840\n",
            "loss 0.13877971470355988 average time 0.003126182389530376 iter num 860\n",
            "loss 0.15109610557556152 average time 0.003117332473836789 iter num 880\n",
            "loss 0.20520144701004028 average time 0.0031085257488626264 iter num 900\n",
            "loss 0.1835656464099884 average time 0.0031004811314944715 iter num 920\n",
            "loss 0.157618910074234 average time 0.0030925412106180953 iter num 940\n",
            "loss 0.11229535937309265 average time 0.0030850305478945 iter num 960\n",
            "loss 0.17717349529266357 average time 0.003084865074483137 iter num 980\n",
            "loss 0.08868587017059326 average time 0.003077471510008763 iter num 1000\n",
            "loss 0.15990006923675537 average time 0.018305866550144857 iter num 20\n",
            "loss 0.21261757612228394 average time 0.010510979925220454 iter num 40\n",
            "loss 0.3397582173347473 average time 0.00791228856669477 iter num 60\n",
            "loss 0.33063068985939026 average time 0.006618646500055547 iter num 80\n",
            "loss 0.38432320952415466 average time 0.005841908159964077 iter num 100\n",
            "loss 0.1884494423866272 average time 0.005333834683278837 iter num 120\n",
            "loss 0.34638047218322754 average time 0.004991768149998929 iter num 140\n",
            "loss 0.40961337089538574 average time 0.004724317975001213 iter num 160\n",
            "loss 0.42293208837509155 average time 0.004503359955540671 iter num 180\n",
            "loss 0.5682837963104248 average time 0.004325758539998788 iter num 200\n",
            "loss 0.5894899368286133 average time 0.004180239659101723 iter num 220\n",
            "loss 0.5337135791778564 average time 0.004057430249986282 iter num 240\n",
            "loss 0.08597709238529205 average time 0.0039558556846084406 iter num 260\n",
            "loss 0.8443828225135803 average time 0.0038691867285836324 iter num 280\n",
            "loss 0.2988140285015106 average time 0.0037933004633547776 iter num 300\n",
            "loss 0.0910724550485611 average time 0.0037245259750307014 iter num 320\n",
            "loss 0.45479607582092285 average time 0.003664748052987681 iter num 340\n",
            "loss 0.11429071426391602 average time 0.0036190140945109306 iter num 360\n",
            "loss 0.10505417734384537 average time 0.003570746105307128 iter num 380\n",
            "loss 0.1848701536655426 average time 0.0035325339775226896 iter num 400\n",
            "loss 0.2069489061832428 average time 0.0034952074214656716 iter num 420\n",
            "loss 0.39672788977622986 average time 0.0034583310000181715 iter num 440\n",
            "loss 0.3892139792442322 average time 0.003423788291302512 iter num 460\n",
            "loss 0.20690715312957764 average time 0.0033925540895779704 iter num 480\n",
            "loss 0.2663164734840393 average time 0.0033663890499810805 iter num 500\n",
            "loss 0.11729741096496582 average time 0.003343282586523016 iter num 520\n",
            "loss 0.10677590221166611 average time 0.0033216250592414762 iter num 540\n",
            "loss 0.13859841227531433 average time 0.003302249283901152 iter num 560\n",
            "loss 0.14659355580806732 average time 0.0032962463551516052 iter num 580\n",
            "loss 0.21415671706199646 average time 0.003280526579977353 iter num 600\n",
            "loss 0.12785731256008148 average time 0.0032635838241819124 iter num 620\n",
            "loss 0.271152138710022 average time 0.003248773451565512 iter num 640\n",
            "loss 0.3470127284526825 average time 0.0032328557969528693 iter num 660\n",
            "loss 0.09686203300952911 average time 0.003218329045563116 iter num 680\n",
            "loss 0.14919161796569824 average time 0.0032039245814095402 iter num 700\n",
            "loss 0.21214066445827484 average time 0.0031950629305154306 iter num 720\n",
            "loss 0.2729320228099823 average time 0.003184997887792879 iter num 740\n",
            "loss 0.46745991706848145 average time 0.003176964314417618 iter num 760\n",
            "loss 0.1484072357416153 average time 0.003165822937136489 iter num 780\n",
            "loss 0.13774794340133667 average time 0.003154871711217311 iter num 800\n",
            "loss 0.22424964606761932 average time 0.003144477399970439 iter num 820\n",
            "loss 0.175506591796875 average time 0.003134282067826245 iter num 840\n",
            "loss 0.15952199697494507 average time 0.003125167722054209 iter num 860\n",
            "loss 0.1893906593322754 average time 0.0031175067851811696 iter num 880\n",
            "loss 0.15717022120952606 average time 0.003108841648839492 iter num 900\n",
            "loss 0.3059556782245636 average time 0.0031004536629908493 iter num 920\n",
            "loss 0.06795191764831543 average time 0.0030929908818778016 iter num 940\n",
            "loss 0.0976017564535141 average time 0.0030859906531077287 iter num 960\n",
            "loss 0.11940120160579681 average time 0.0030827362295783632 iter num 980\n",
            "loss 0.1481325626373291 average time 0.0030798073259902595 iter num 1000\n",
            "loss 3.185126304626465 average time 0.018373981349213864 iter num 20\n",
            "loss 0.11044236272573471 average time 0.010558512149509624 iter num 40\n",
            "loss 1.1021404266357422 average time 0.007950710299883212 iter num 60\n",
            "loss 1.0322577953338623 average time 0.006652951999831203 iter num 80\n",
            "loss 0.06509272754192352 average time 0.005869296849850798 iter num 100\n",
            "loss 0.8031265735626221 average time 0.005346785916511484 iter num 120\n",
            "loss 0.3062273859977722 average time 0.004973698571198578 iter num 140\n",
            "loss 0.3357916474342346 average time 0.004702287068516853 iter num 160\n",
            "loss 0.11095704138278961 average time 0.004484043660906738 iter num 180\n",
            "loss 0.14791244268417358 average time 0.0043287804748069906 iter num 200\n",
            "loss 0.14515456557273865 average time 0.004188356236260337 iter num 220\n",
            "loss 0.2252621352672577 average time 0.004066641841594294 iter num 240\n",
            "loss 0.122160404920578 average time 0.00398474328069894 iter num 260\n",
            "loss 0.9171798825263977 average time 0.0039010420677836268 iter num 280\n",
            "loss 0.2852872610092163 average time 0.0038234195833016806 iter num 300\n",
            "loss 0.664806604385376 average time 0.0037559287312205923 iter num 320\n",
            "loss 0.33887791633605957 average time 0.003697166641123819 iter num 340\n",
            "loss 0.15685489773750305 average time 0.00364412885550741 iter num 360\n",
            "loss 0.24777302145957947 average time 0.0035970466367967005 iter num 380\n",
            "loss 0.1438022255897522 average time 0.0035545162799553508 iter num 400\n",
            "loss 0.1036922037601471 average time 0.003518069721368582 iter num 420\n",
            "loss 0.5992056131362915 average time 0.0034824959772446493 iter num 440\n",
            "loss 0.3318970799446106 average time 0.0034505524260685376 iter num 460\n",
            "loss 0.13053317368030548 average time 0.003421460466635532 iter num 480\n",
            "loss 0.3325243592262268 average time 0.003394021341955522 iter num 500\n",
            "loss 0.1672235131263733 average time 0.003369208771108298 iter num 520\n",
            "loss 0.038495827466249466 average time 0.003350100374033597 iter num 540\n",
            "loss 0.2717474102973938 average time 0.0033283743785237417 iter num 560\n",
            "loss 0.1409558653831482 average time 0.003309983082701741 iter num 580\n",
            "loss 0.07504355162382126 average time 0.0032906057499531016 iter num 600\n",
            "loss 0.25280308723449707 average time 0.0032726823693073745 iter num 620\n",
            "loss 0.25790637731552124 average time 0.0032565248562036685 iter num 640\n",
            "loss 0.1505783200263977 average time 0.0032458338014872755 iter num 660\n",
            "loss 0.14246341586112976 average time 0.003233690441132186 iter num 680\n",
            "loss 0.22900331020355225 average time 0.003222955405659117 iter num 700\n",
            "loss 0.1799953281879425 average time 0.003212191156879069 iter num 720\n",
            "loss 0.06169876828789711 average time 0.003198813263460997 iter num 740\n",
            "loss 0.1617223024368286 average time 0.003187919930204723 iter num 760\n",
            "loss 0.18035420775413513 average time 0.0031763717397086276 iter num 780\n",
            "loss 0.06587135791778564 average time 0.0031660672049611096 iter num 800\n",
            "loss 0.22464677691459656 average time 0.00315562707922853 iter num 820\n",
            "loss 0.28801584243774414 average time 0.0031601275642363664 iter num 840\n",
            "loss 0.14080658555030823 average time 0.003149715034834476 iter num 860\n",
            "loss 0.055336844176054 average time 0.0031409734965481303 iter num 880\n",
            "loss 0.06339267641305923 average time 0.003134214597747713 iter num 900\n",
            "loss 0.17604348063468933 average time 0.003126352265177917 iter num 920\n",
            "loss 0.08159688860177994 average time 0.003119442570177272 iter num 940\n",
            "loss 0.03748130798339844 average time 0.0031173068499621573 iter num 960\n",
            "loss 0.14300234615802765 average time 0.003111437632629086 iter num 980\n",
            "loss 0.2125372439622879 average time 0.0031071677369764075 iter num 1000\n",
            "loss 0.7358183860778809 average time 0.018258451849578704 iter num 20\n",
            "loss 5.137197971343994 average time 0.010489253849482339 iter num 40\n",
            "loss 1.0563502311706543 average time 0.007898952516067462 iter num 60\n",
            "loss 0.4858032464981079 average time 0.006603505737075466 iter num 80\n",
            "loss 0.4027908444404602 average time 0.005839568279625383 iter num 100\n",
            "loss 0.27751725912094116 average time 0.005318509924654791 iter num 120\n",
            "loss 0.44307374954223633 average time 0.004949995721186237 iter num 140\n",
            "loss 0.28110015392303467 average time 0.004674345149737746 iter num 160\n",
            "loss 0.3113713562488556 average time 0.004456937399724362 iter num 180\n",
            "loss 0.7639410495758057 average time 0.004286645519732702 iter num 200\n",
            "loss 0.19374462962150574 average time 0.004151657481584566 iter num 220\n",
            "loss 1.0769374370574951 average time 0.00403279774565514 iter num 240\n",
            "loss 0.2901761829853058 average time 0.0039348073305658406 iter num 260\n",
            "loss 0.4304506182670593 average time 0.003857467514106767 iter num 280\n",
            "loss 0.24173229932785034 average time 0.0037829772731492995 iter num 300\n",
            "loss 0.11484534293413162 average time 0.003716901631082692 iter num 320\n",
            "loss 0.40534621477127075 average time 0.003660873876352151 iter num 340\n",
            "loss 0.6173014640808105 average time 0.003627054813791296 iter num 360\n",
            "loss 0.6087183356285095 average time 0.0035793536341148673 iter num 380\n",
            "loss 0.08334947377443314 average time 0.003539584264917721 iter num 400\n",
            "loss 0.20561596751213074 average time 0.0035057414356353027 iter num 420\n",
            "loss 0.15060755610466003 average time 0.003476116129472344 iter num 440\n",
            "loss 0.4726269543170929 average time 0.0034437526694882366 iter num 460\n",
            "loss 0.1779954582452774 average time 0.003414680904082464 iter num 480\n",
            "loss 0.055448442697525024 average time 0.0033947584979105157 iter num 500\n",
            "loss 0.2429397702217102 average time 0.003370862599925973 iter num 520\n",
            "loss 0.2081204652786255 average time 0.003349730485098445 iter num 540\n",
            "loss 0.2943064272403717 average time 0.003326675567788178 iter num 560\n",
            "loss 0.3185247778892517 average time 0.003310937584413703 iter num 580\n",
            "loss 0.06345174461603165 average time 0.0032917540049311354 iter num 600\n",
            "loss 0.2362399697303772 average time 0.0032775098096129614 iter num 620\n",
            "loss 0.10365283489227295 average time 0.0032607730780569 iter num 640\n",
            "loss 0.08935938775539398 average time 0.0032452752150813028 iter num 660\n",
            "loss 0.15403839945793152 average time 0.003230593754350968 iter num 680\n",
            "loss 0.08230157196521759 average time 0.003217143361372499 iter num 700\n",
            "loss 0.0714033842086792 average time 0.0032036706638437964 iter num 720\n",
            "loss 0.31950628757476807 average time 0.0031906602526539023 iter num 740\n",
            "loss 0.19746911525726318 average time 0.003178662443367916 iter num 760\n",
            "loss 0.136736199259758 average time 0.003168492698662307 iter num 780\n",
            "loss 0.4273430109024048 average time 0.003157685979949747 iter num 800\n",
            "loss 0.16154207289218903 average time 0.0031468278999454923 iter num 820\n",
            "loss 0.14377129077911377 average time 0.003136479590431831 iter num 840\n",
            "loss 0.3116571307182312 average time 0.0031265716359950265 iter num 860\n",
            "loss 0.11525557935237885 average time 0.0031183406283616932 iter num 880\n",
            "loss 0.1771673858165741 average time 0.0031103852988316146 iter num 900\n",
            "loss 0.0825614407658577 average time 0.003102027333637164 iter num 920\n",
            "loss 0.21647527813911438 average time 0.0030961502914424077 iter num 940\n",
            "loss 0.092493437230587 average time 0.0030891318530772574 iter num 960\n",
            "loss 0.07061752676963806 average time 0.00308264154281627 iter num 980\n",
            "loss 0.06537777185440063 average time 0.0030791722689573362 iter num 1000\n",
            "loss 0.09916014224290848 average time 0.01858502920022147 iter num 20\n",
            "loss 1.018787145614624 average time 0.010650706199976412 iter num 40\n",
            "loss 1.0316904783248901 average time 0.008039091166513876 iter num 60\n",
            "loss 0.23274382948875427 average time 0.006723657824977636 iter num 80\n",
            "loss 0.3496469259262085 average time 0.00593877192997752 iter num 100\n",
            "loss 0.6944764852523804 average time 0.005401672108200728 iter num 120\n",
            "loss 0.19633087515830994 average time 0.005023908928446222 iter num 140\n",
            "loss 0.3452491760253906 average time 0.0047371183561836 iter num 160\n",
            "loss 0.1504077911376953 average time 0.0045180709777317436 iter num 180\n",
            "loss 0.12428924441337585 average time 0.004345144954968418 iter num 200\n",
            "loss 0.4270523190498352 average time 0.004199122159033405 iter num 220\n",
            "loss 0.40930062532424927 average time 0.004076679762465574 iter num 240\n",
            "loss 0.15626780688762665 average time 0.003976368119177866 iter num 260\n",
            "loss 0.24078762531280518 average time 0.0038871841142151553 iter num 280\n",
            "loss 0.26540061831474304 average time 0.0038124262432635684 iter num 300\n",
            "loss 0.4317637085914612 average time 0.0037547263218243644 iter num 320\n",
            "loss 0.235604390501976 average time 0.003693630558786133 iter num 340\n",
            "loss 0.37875843048095703 average time 0.0036472654083000737 iter num 360\n",
            "loss 0.3361264765262604 average time 0.003606485844714993 iter num 380\n",
            "loss 0.15157711505889893 average time 0.003565266147479633 iter num 400\n",
            "loss 0.28266143798828125 average time 0.003525707333323052 iter num 420\n",
            "loss 0.07000591605901718 average time 0.0034890452772742718 iter num 440\n",
            "loss 0.24418553709983826 average time 0.0034597200499932946 iter num 460\n",
            "loss 0.07945474982261658 average time 0.003435150377087363 iter num 480\n",
            "loss 0.1412733793258667 average time 0.0034082698820129737 iter num 500\n",
            "loss 0.11263088881969452 average time 0.0033833637211920665 iter num 520\n",
            "loss 0.22006265819072723 average time 0.003361003372265259 iter num 540\n",
            "loss 0.1886904090642929 average time 0.0033387378536060297 iter num 560\n",
            "loss 0.15807434916496277 average time 0.0033184696586588337 iter num 580\n",
            "loss 0.3361895680427551 average time 0.0032993705966873677 iter num 600\n",
            "loss 0.3007620573043823 average time 0.003282787146787497 iter num 620\n",
            "loss 0.31496843695640564 average time 0.0032682955578195562 iter num 640\n",
            "loss 0.14307115972042084 average time 0.003257207634851511 iter num 660\n",
            "loss 0.18559612333774567 average time 0.00324223665147656 iter num 680\n",
            "loss 0.13295629620552063 average time 0.0032279154785958652 iter num 700\n",
            "loss 0.20373252034187317 average time 0.0032146135625225726 iter num 720\n",
            "loss 0.16752327978610992 average time 0.0032035033513779666 iter num 740\n",
            "loss 0.12229090929031372 average time 0.0031920945250308967 iter num 760\n",
            "loss 0.15939649939537048 average time 0.003180016771815038 iter num 780\n",
            "loss 0.15843525528907776 average time 0.003169069037517147 iter num 800\n",
            "loss 0.15957385301589966 average time 0.00315836678781169 iter num 820\n",
            "loss 0.12054882943630219 average time 0.003148599567854641 iter num 840\n",
            "loss 0.1790643334388733 average time 0.0031400574093040207 iter num 860\n",
            "loss 0.357186883687973 average time 0.003137790696601686 iter num 880\n",
            "loss 0.25476691126823425 average time 0.003131577612237177 iter num 900\n",
            "loss 0.15395933389663696 average time 0.003127793261955958 iter num 920\n",
            "loss 0.2117723822593689 average time 0.003120968643622504 iter num 940\n",
            "loss 0.048861436545848846 average time 0.0031132829322965943 iter num 960\n",
            "loss 0.12077006697654724 average time 0.003105754851027569 iter num 980\n",
            "loss 0.095753014087677 average time 0.00310082290201899 iter num 1000\n",
            "loss 1.8588471412658691 average time 0.018428915900221908 iter num 20\n",
            "loss 0.19284853339195251 average time 0.01057077007544649 iter num 40\n",
            "loss 0.23607267439365387 average time 0.007968232766991908 iter num 60\n",
            "loss 0.26391562819480896 average time 0.00668114650015923 iter num 80\n",
            "loss 0.3282483220100403 average time 0.005891199650068302 iter num 100\n",
            "loss 0.2112548053264618 average time 0.005364798450106415 iter num 120\n",
            "loss 0.33372756838798523 average time 0.00500776620013182 iter num 140\n",
            "loss 1.2003252506256104 average time 0.004727588250102599 iter num 160\n",
            "loss 0.7884863018989563 average time 0.004505470616701738 iter num 180\n",
            "loss 0.885315477848053 average time 0.0043336618000648745 iter num 200\n",
            "loss 0.5541421175003052 average time 0.00419444832735859 iter num 220\n",
            "loss 0.4209073781967163 average time 0.0040815655375809005 iter num 240\n",
            "loss 0.3987921476364136 average time 0.0039788987000765 iter num 260\n",
            "loss 0.1828664094209671 average time 0.003893014021494829 iter num 280\n",
            "loss 0.21593478322029114 average time 0.003815569200075212 iter num 300\n",
            "loss 0.2748984396457672 average time 0.0037502884907098634 iter num 320\n",
            "loss 0.33702802658081055 average time 0.0036978091177147956 iter num 340\n",
            "loss 0.14567597210407257 average time 0.003644054397278119 iter num 360\n",
            "loss 0.1948113739490509 average time 0.0035954620947545902 iter num 380\n",
            "loss 0.18235063552856445 average time 0.003550689212497673 iter num 400\n",
            "loss 0.0885465145111084 average time 0.0035210800952318964 iter num 420\n",
            "loss 0.16895033419132233 average time 0.0034851089340918406 iter num 440\n",
            "loss 0.14650964736938477 average time 0.0034534023848011757 iter num 460\n",
            "loss 0.2435738444328308 average time 0.0034234261708434134 iter num 480\n",
            "loss 0.11012467741966248 average time 0.003397024074016372 iter num 500\n",
            "loss 0.14678171277046204 average time 0.0033743607192613686 iter num 520\n",
            "loss 0.2591530680656433 average time 0.0033537339796735235 iter num 540\n",
            "loss 0.3909055292606354 average time 0.0033306751304085732 iter num 560\n",
            "loss 0.13553887605667114 average time 0.0033096251310968817 iter num 580\n",
            "loss 0.13176916539669037 average time 0.0032934231917291375 iter num 600\n",
            "loss 0.08704584836959839 average time 0.0032761237129776536 iter num 620\n",
            "loss 0.31462743878364563 average time 0.0032596409156951723 iter num 640\n",
            "loss 0.34501442313194275 average time 0.0032430025470327538 iter num 660\n",
            "loss 0.11642012745141983 average time 0.0032344211971148443 iter num 680\n",
            "loss 0.0845453143119812 average time 0.0032202387529209125 iter num 700\n",
            "loss 0.09755433350801468 average time 0.0032160531445091086 iter num 720\n",
            "loss 0.17972302436828613 average time 0.003208764781157771 iter num 740\n",
            "loss 0.18284828960895538 average time 0.0031964673487412877 iter num 760\n",
            "loss 0.2866259515285492 average time 0.003184063991083792 iter num 780\n",
            "loss 0.1475188285112381 average time 0.0031729913350591232 iter num 800\n",
            "loss 0.2904546856880188 average time 0.0031617021122478835 iter num 820\n",
            "loss 0.21659335494041443 average time 0.003151454357192138 iter num 840\n",
            "loss 0.1261964589357376 average time 0.003141355408200091 iter num 860\n",
            "loss 0.1714344322681427 average time 0.003133351247780328 iter num 880\n",
            "loss 0.04718930646777153 average time 0.0031240746478296286 iter num 900\n",
            "loss 0.09194114059209824 average time 0.003118306515261793 iter num 920\n",
            "loss 0.23733484745025635 average time 0.0031108706351508945 iter num 940\n",
            "loss 0.20106852054595947 average time 0.003103608946908783 iter num 960\n",
            "loss 0.29430079460144043 average time 0.0030973407755463624 iter num 980\n",
            "loss 0.22250688076019287 average time 0.003090717259030498 iter num 1000\n",
            "loss 0.5166267156600952 average time 0.018489048550509323 iter num 20\n",
            "loss 1.6056602001190186 average time 0.01065006370026822 iter num 40\n",
            "loss 0.3618864417076111 average time 0.008011304800129437 iter num 60\n",
            "loss 0.7992050647735596 average time 0.006706025650009906 iter num 80\n",
            "loss 0.18248343467712402 average time 0.00594984392006154 iter num 100\n",
            "loss 0.07454395294189453 average time 0.005413870541633514 iter num 120\n",
            "loss 0.707291305065155 average time 0.005031460442790246 iter num 140\n",
            "loss 1.7896463871002197 average time 0.004744795237456856 iter num 160\n",
            "loss 0.14818456768989563 average time 0.004520982111110546 iter num 180\n",
            "loss 0.3874295651912689 average time 0.004347719144989242 iter num 200\n",
            "loss 0.19957880675792694 average time 0.0042201555227372655 iter num 220\n",
            "loss 0.3370157480239868 average time 0.00410195131665508 iter num 240\n",
            "loss 0.17977535724639893 average time 0.004008786003816147 iter num 260\n",
            "loss 0.19327443838119507 average time 0.003919008142812735 iter num 280\n",
            "loss 0.19235464930534363 average time 0.0038400330532628382 iter num 300\n",
            "loss 0.24423594772815704 average time 0.0037720337155860762 iter num 320\n",
            "loss 0.2713339924812317 average time 0.0037123168264502856 iter num 340\n",
            "loss 0.1541811227798462 average time 0.003663447619429563 iter num 360\n",
            "loss 0.20399326086044312 average time 0.0036203746947266104 iter num 380\n",
            "loss 0.16298823058605194 average time 0.0035760524549823458 iter num 400\n",
            "loss 0.3677283823490143 average time 0.0035354121452179418 iter num 420\n",
            "loss 0.21837729215621948 average time 0.003498129865899748 iter num 440\n",
            "loss 0.24722853302955627 average time 0.0034647380738929115 iter num 460\n",
            "loss 0.17132654786109924 average time 0.003434504852035995 iter num 480\n",
            "loss 0.17983579635620117 average time 0.003407862451967958 iter num 500\n",
            "loss 0.28402382135391235 average time 0.0033865161634331832 iter num 520\n",
            "loss 0.062172286212444305 average time 0.0033633551944014335 iter num 540\n",
            "loss 0.19317466020584106 average time 0.003340904128546234 iter num 560\n",
            "loss 0.0480031855404377 average time 0.0033231642672286272 iter num 580\n",
            "loss 0.18603351712226868 average time 0.00330405396999898 iter num 600\n",
            "loss 0.12691064178943634 average time 0.003285379135471181 iter num 620\n",
            "loss 0.18064767122268677 average time 0.0032681217749825466 iter num 640\n",
            "loss 0.1383185088634491 average time 0.0032647832439221076 iter num 660\n",
            "loss 0.09641334414482117 average time 0.0032510752999769465 iter num 680\n",
            "loss 0.17993572354316711 average time 0.0032389399656884573 iter num 700\n",
            "loss 0.2610319256782532 average time 0.003224468699980005 iter num 720\n",
            "loss 0.14903144538402557 average time 0.003211155705395032 iter num 740\n",
            "loss 0.18239933252334595 average time 0.0031988157052518017 iter num 760\n",
            "loss 0.08122052252292633 average time 0.0031864391064048573 iter num 780\n",
            "loss 0.28086841106414795 average time 0.0031752947837367174 iter num 800\n",
            "loss 0.19342562556266785 average time 0.003164071864610866 iter num 820\n",
            "loss 0.12311931699514389 average time 0.00315597038688793 iter num 840\n",
            "loss 0.13499701023101807 average time 0.0031500672546234307 iter num 860\n",
            "loss 0.1485159695148468 average time 0.003140708288604153 iter num 880\n",
            "loss 0.10525067150592804 average time 0.003135824067742053 iter num 900\n",
            "loss 0.3287676274776459 average time 0.003126937734755895 iter num 920\n",
            "loss 0.1014404296875 average time 0.0031190021840070293 iter num 940\n",
            "loss 0.08583252131938934 average time 0.0031132010749729488 iter num 960\n",
            "loss 0.1407492458820343 average time 0.003105093712225908 iter num 980\n",
            "loss 0.06964009255170822 average time 0.003097488107971003 iter num 1000\n",
            "loss 1.0129616260528564 average time 0.018607711799995742 iter num 20\n",
            "loss 0.5715446472167969 average time 0.010658035624965123 iter num 40\n",
            "loss 0.9241312742233276 average time 0.008033734416615819 iter num 60\n",
            "loss 0.4309549927711487 average time 0.006800384262442094 iter num 80\n",
            "loss 0.4535464644432068 average time 0.005988784369910718 iter num 100\n",
            "loss 1.1034302711486816 average time 0.005452903366616132 iter num 120\n",
            "loss 0.6664222478866577 average time 0.005061194799990127 iter num 140\n",
            "loss 0.18568147718906403 average time 0.004770837625005697 iter num 160\n",
            "loss 0.40286919474601746 average time 0.0045545301555951784 iter num 180\n",
            "loss 0.7992396354675293 average time 0.00438217851004083 iter num 200\n",
            "loss 0.22067305445671082 average time 0.004230932650038581 iter num 220\n",
            "loss 0.5172166228294373 average time 0.004114910583348319 iter num 240\n",
            "loss 0.5098236799240112 average time 0.004010880542325769 iter num 260\n",
            "loss 0.25853970646858215 average time 0.003948384685710542 iter num 280\n",
            "loss 0.11507885158061981 average time 0.003872551526680278 iter num 300\n",
            "loss 0.1378333568572998 average time 0.003805289615638685 iter num 320\n",
            "loss 0.15269377827644348 average time 0.0037477528264978043 iter num 340\n",
            "loss 0.08038322627544403 average time 0.0036913206028354275 iter num 360\n",
            "loss 0.335126668214798 average time 0.003641463278999206 iter num 380\n",
            "loss 0.2316717654466629 average time 0.003597511302550629 iter num 400\n",
            "loss 0.12794339656829834 average time 0.0035583417333934146 iter num 420\n",
            "loss 0.16319885849952698 average time 0.0035256070478019617 iter num 440\n",
            "loss 0.17130640149116516 average time 0.00349157989138526 iter num 460\n",
            "loss 0.19844236969947815 average time 0.0034651465125762116 iter num 480\n",
            "loss 0.5152151584625244 average time 0.0034373356580908875 iter num 500\n",
            "loss 0.14761219918727875 average time 0.0034104560654808526 iter num 520\n",
            "loss 0.06443743407726288 average time 0.003388090509354327 iter num 540\n",
            "loss 0.1107129454612732 average time 0.0033648735429518896 iter num 560\n",
            "loss 0.24688959121704102 average time 0.0033433611276795375 iter num 580\n",
            "loss 0.07154236733913422 average time 0.0033229008117450576 iter num 600\n",
            "loss 0.26208430528640747 average time 0.003302924521044441 iter num 620\n",
            "loss 0.36513012647628784 average time 0.003286007400078006 iter num 640\n",
            "loss 0.12970678508281708 average time 0.003268714512198516 iter num 660\n",
            "loss 0.16121259331703186 average time 0.00325951339713998 iter num 680\n",
            "loss 0.24503371119499207 average time 0.003246362604357793 iter num 700\n",
            "loss 0.1348767876625061 average time 0.003233150794514788 iter num 720\n",
            "loss 0.3023725152015686 average time 0.0032200932716895713 iter num 740\n",
            "loss 0.08615189790725708 average time 0.003209829226369421 iter num 760\n",
            "loss 0.12372483313083649 average time 0.003199628755175628 iter num 780\n",
            "loss 0.17162081599235535 average time 0.003187190205044317 iter num 800\n",
            "loss 0.064064159989357 average time 0.0031773546500494933 iter num 820\n",
            "loss 0.09191912412643433 average time 0.0031672418583790812 iter num 840\n",
            "loss 0.21753022074699402 average time 0.003162735959347967 iter num 860\n",
            "loss 0.40071362257003784 average time 0.003153153186407177 iter num 880\n",
            "loss 0.08679261803627014 average time 0.0031436498356035574 iter num 900\n",
            "loss 0.3130655288696289 average time 0.0031352756381001316 iter num 920\n",
            "loss 0.15214408934116364 average time 0.0031263111213310694 iter num 940\n",
            "loss 0.12710650265216827 average time 0.0031187646771362173 iter num 960\n",
            "loss 0.11280529201030731 average time 0.003111986417392547 iter num 980\n",
            "loss 0.20167548954486847 average time 0.0031040866910261684 iter num 1000\n",
            "loss 0.12312266230583191 average time 0.01848066084967286 iter num 20\n",
            "loss 0.10851699113845825 average time 0.010607939749843354 iter num 40\n",
            "loss 0.16017505526542664 average time 0.007990295083072852 iter num 60\n",
            "loss 0.22300925850868225 average time 0.006679304187309753 iter num 80\n",
            "loss 0.8307146430015564 average time 0.005901411879785883 iter num 100\n",
            "loss 0.18638300895690918 average time 0.005372360533177319 iter num 120\n",
            "loss 0.44319185614585876 average time 0.005007697307051525 iter num 140\n",
            "loss 0.3869500160217285 average time 0.0047485908249200294 iter num 160\n",
            "loss 0.2327202707529068 average time 0.0045284249554849035 iter num 180\n",
            "loss 0.14758911728858948 average time 0.004349845089982409 iter num 200\n",
            "loss 0.40422821044921875 average time 0.004209883795391017 iter num 220\n",
            "loss 0.39328837394714355 average time 0.004091509937416049 iter num 240\n",
            "loss 0.4369438886642456 average time 0.004002186476869751 iter num 260\n",
            "loss 0.27876168489456177 average time 0.003911701489232655 iter num 280\n",
            "loss 0.14416900277137756 average time 0.003832780479970097 iter num 300\n",
            "loss 0.3694585859775543 average time 0.0037649031656314946 iter num 320\n",
            "loss 0.27643507719039917 average time 0.003711549852949461 iter num 340\n",
            "loss 0.20559316873550415 average time 0.003659540072213632 iter num 360\n",
            "loss 0.314316987991333 average time 0.003609890918433896 iter num 380\n",
            "loss 0.452411413192749 average time 0.0035647251100454015 iter num 400\n",
            "loss 0.21208684146404266 average time 0.0035261615262459686 iter num 420\n",
            "loss 0.20486541092395782 average time 0.003491774918256851 iter num 440\n",
            "loss 0.3933708667755127 average time 0.0034581328152932618 iter num 460\n",
            "loss 0.19516201317310333 average time 0.003427013520899891 iter num 480\n",
            "loss 0.1316341757774353 average time 0.003400670818060462 iter num 500\n",
            "loss 0.2993620038032532 average time 0.00337532113657849 iter num 520\n",
            "loss 0.3746723532676697 average time 0.0033497706722267107 iter num 540\n",
            "loss 0.38924428820610046 average time 0.003334058332159527 iter num 560\n",
            "loss 0.21219313144683838 average time 0.003313939389666083 iter num 580\n",
            "loss 0.27827030420303345 average time 0.0032972870549989844 iter num 600\n",
            "loss 0.2593476474285126 average time 0.003278617682248765 iter num 620\n",
            "loss 0.24148425459861755 average time 0.0032620932656186596 iter num 640\n",
            "loss 0.6247509121894836 average time 0.0032490159515101836 iter num 660\n",
            "loss 0.14268435537815094 average time 0.0032375070044027405 iter num 680\n",
            "loss 0.10978780686855316 average time 0.0032231987885617333 iter num 700\n",
            "loss 0.3700290024280548 average time 0.003212304254141903 iter num 720\n",
            "loss 0.23027783632278442 average time 0.0031984744553827456 iter num 740\n",
            "loss 0.11885586380958557 average time 0.0031875244868148768 iter num 760\n",
            "loss 0.1713685691356659 average time 0.003175277924329305 iter num 780\n",
            "loss 0.12483717501163483 average time 0.003163853719975123 iter num 800\n",
            "loss 0.15119501948356628 average time 0.0031533528475315175 iter num 820\n",
            "loss 0.23426605761051178 average time 0.0031433148106771113 iter num 840\n",
            "loss 0.18867400288581848 average time 0.003133553082528145 iter num 860\n",
            "loss 0.30890047550201416 average time 0.0031252225636101438 iter num 880\n",
            "loss 0.3113807737827301 average time 0.0031160032788668307 iter num 900\n",
            "loss 0.09735212475061417 average time 0.003107217641279377 iter num 920\n",
            "loss 0.35784438252449036 average time 0.0030985012031723796 iter num 940\n",
            "loss 0.25805580615997314 average time 0.0030902603041568 iter num 960\n",
            "loss 0.07347852736711502 average time 0.003088290629580579 iter num 980\n",
            "loss 0.1631269007921219 average time 0.0030826803939926323 iter num 1000\n",
            "loss 0.5600082278251648 average time 0.01835773739931028 iter num 20\n",
            "loss 1.2219586372375488 average time 0.010636483549205877 iter num 40\n",
            "loss 0.5405166149139404 average time 0.00800715968289296 iter num 60\n",
            "loss 0.14932402968406677 average time 0.006719727374775175 iter num 80\n",
            "loss 0.6005503535270691 average time 0.005919426329819543 iter num 100\n",
            "loss 0.2869550585746765 average time 0.005388245366551321 iter num 120\n",
            "loss 0.3223150372505188 average time 0.005008042942764795 iter num 140\n",
            "loss 0.1234624907374382 average time 0.004730499999891435 iter num 160\n",
            "loss 0.25379079580307007 average time 0.0045124702054535094 iter num 180\n",
            "loss 0.4141297936439514 average time 0.004337181344908458 iter num 200\n",
            "loss 0.18980365991592407 average time 0.004189489790819193 iter num 220\n",
            "loss 0.606523871421814 average time 0.00406811397074307 iter num 240\n",
            "loss 0.13538961112499237 average time 0.003962274061450444 iter num 260\n",
            "loss 0.7355244159698486 average time 0.003872843049910963 iter num 280\n",
            "loss 0.13943856954574585 average time 0.0037956641066314964 iter num 300\n",
            "loss 0.16969813406467438 average time 0.0037272123124807875 iter num 320\n",
            "loss 0.32626134157180786 average time 0.0036685044558479978 iter num 340\n",
            "loss 0.22786861658096313 average time 0.003616260527744291 iter num 360\n",
            "loss 0.3791068196296692 average time 0.0035692300683876966 iter num 380\n",
            "loss 0.30238616466522217 average time 0.003542123117495066 iter num 400\n",
            "loss 0.06173854321241379 average time 0.0035066393333008385 iter num 420\n",
            "loss 0.19254045188426971 average time 0.0034748677522409045 iter num 440\n",
            "loss 0.2348760962486267 average time 0.0034435982673486527 iter num 460\n",
            "loss 0.22995486855506897 average time 0.003416475345799578 iter num 480\n",
            "loss 0.22499677538871765 average time 0.003389362917980179 iter num 500\n",
            "loss 0.38645604252815247 average time 0.0033714419038285716 iter num 520\n",
            "loss 0.3521866500377655 average time 0.003347859661078945 iter num 540\n",
            "loss 0.13533619046211243 average time 0.0033272499606937346 iter num 560\n",
            "loss 0.22805270552635193 average time 0.003307545649991441 iter num 580\n",
            "loss 0.10712414979934692 average time 0.0032879029216686226 iter num 600\n",
            "loss 0.03264877200126648 average time 0.003271881327424536 iter num 620\n",
            "loss 0.1199323758482933 average time 0.0032553583718822666 iter num 640\n",
            "loss 0.20626111328601837 average time 0.0032414908075721048 iter num 660\n",
            "loss 0.08521907776594162 average time 0.003225732538232799 iter num 680\n",
            "loss 0.24874630570411682 average time 0.0032099496614266952 iter num 700\n",
            "loss 0.10041716694831848 average time 0.0031959995888882985 iter num 720\n",
            "loss 0.26965272426605225 average time 0.003183313414872926 iter num 740\n",
            "loss 0.2846953570842743 average time 0.0031720838855395224 iter num 760\n",
            "loss 0.1532587856054306 average time 0.003162395496152525 iter num 780\n",
            "loss 0.05954999476671219 average time 0.0031580091799878573 iter num 800\n",
            "loss 0.10315042734146118 average time 0.003146096521941661 iter num 820\n",
            "loss 0.15895511209964752 average time 0.0031339248154706313 iter num 840\n",
            "loss 0.28879883885383606 average time 0.003124493318598049 iter num 860\n",
            "loss 0.2614096403121948 average time 0.003119897882945886 iter num 880\n",
            "loss 0.08258412778377533 average time 0.0031120083977617063 iter num 900\n",
            "loss 0.07742572575807571 average time 0.003103497258689458 iter num 920\n",
            "loss 0.3486681282520294 average time 0.003097834554241575 iter num 940\n",
            "loss 0.119140625 average time 0.0030915803541612754 iter num 960\n",
            "loss 0.19908387959003448 average time 0.003085633161223383 iter num 980\n",
            "loss 0.0937294140458107 average time 0.0030800670299977353 iter num 1000\n",
            "loss 0.35510870814323425 average time 0.018572177999703853 iter num 20\n",
            "loss 0.7586404085159302 average time 0.010649888524767448 iter num 40\n",
            "loss 0.526918888092041 average time 0.007997903599971323 iter num 60\n",
            "loss 0.3284547030925751 average time 0.006712175187340108 iter num 80\n",
            "loss 0.42706310749053955 average time 0.005933058469963726 iter num 100\n",
            "loss 0.8812204599380493 average time 0.005410158700002891 iter num 120\n",
            "loss 0.27086132764816284 average time 0.0050292655142974195 iter num 140\n",
            "loss 0.13507413864135742 average time 0.004746063906236486 iter num 160\n",
            "loss 0.04116103798151016 average time 0.0045272594165807175 iter num 180\n",
            "loss 1.2124085426330566 average time 0.0043517564850299095 iter num 200\n",
            "loss 0.23845148086547852 average time 0.004211770850038606 iter num 220\n",
            "loss 0.33446019887924194 average time 0.00409518813756525 iter num 240\n",
            "loss 0.03548574447631836 average time 0.003990422350090319 iter num 260\n",
            "loss 0.14788535237312317 average time 0.003907254028698455 iter num 280\n",
            "loss 0.39665523171424866 average time 0.0038255853701169447 iter num 300\n",
            "loss 0.2858865559101105 average time 0.003753490343831345 iter num 320\n",
            "loss 0.11545322090387344 average time 0.003694272885374684 iter num 340\n",
            "loss 0.24109616875648499 average time 0.0036403477528741254 iter num 360\n",
            "loss 0.6328281164169312 average time 0.003592733636890587 iter num 380\n",
            "loss 1.3850805759429932 average time 0.00354657197753113 iter num 400\n",
            "loss 0.17895546555519104 average time 0.003508074780984316 iter num 420\n",
            "loss 0.3023633360862732 average time 0.0034711165318516246 iter num 440\n",
            "loss 0.23473072052001953 average time 0.003439755541330669 iter num 460\n",
            "loss 0.43538880348205566 average time 0.0034106558729566435 iter num 480\n",
            "loss 0.3633520007133484 average time 0.0033936768900457537 iter num 500\n",
            "loss 0.22350993752479553 average time 0.003369751519284574 iter num 520\n",
            "loss 0.2748035788536072 average time 0.0033471080833906955 iter num 540\n",
            "loss 0.26559001207351685 average time 0.003323639785756833 iter num 560\n",
            "loss 0.4494214653968811 average time 0.0033063553620979354 iter num 580\n",
            "loss 0.10424287617206573 average time 0.0032860263133625265 iter num 600\n",
            "loss 0.14348196983337402 average time 0.0032708114436020203 iter num 620\n",
            "loss 0.11333920061588287 average time 0.0032532623000236073 iter num 640\n",
            "loss 0.19224108755588531 average time 0.0032367401288204496 iter num 660\n",
            "loss 0.21387413144111633 average time 0.0032222439485581965 iter num 680\n",
            "loss 0.12554635107517242 average time 0.0032119898800218446 iter num 700\n",
            "loss 0.1415100246667862 average time 0.0031971557361430312 iter num 720\n",
            "loss 0.2279731184244156 average time 0.0031835637189401864 iter num 740\n",
            "loss 0.13331639766693115 average time 0.003172389332915995 iter num 760\n",
            "loss 0.4800751209259033 average time 0.0031605247218230476 iter num 780\n",
            "loss 0.11345431953668594 average time 0.0031516451812876765 iter num 800\n",
            "loss 0.05773437023162842 average time 0.003139907634200737 iter num 820\n",
            "loss 0.20079784095287323 average time 0.003128753379812787 iter num 840\n",
            "loss 0.18128564953804016 average time 0.003119036460495493 iter num 860\n",
            "loss 0.39496397972106934 average time 0.0031081558852623526 iter num 880\n",
            "loss 0.18728169798851013 average time 0.003098102921151925 iter num 900\n",
            "loss 0.24410486221313477 average time 0.003089709750043846 iter num 920\n",
            "loss 0.2007153332233429 average time 0.0030808672425917663 iter num 940\n",
            "loss 0.11247804760932922 average time 0.003072286342747551 iter num 960\n",
            "loss 0.21069136261940002 average time 0.0030634323449406538 iter num 980\n",
            "loss 0.2501675486564636 average time 0.003055833013047959 iter num 1000\n",
            "loss 0.1231703907251358 average time 0.018772998250278762 iter num 20\n",
            "loss 0.2505039870738983 average time 0.01081092187523609 iter num 40\n",
            "loss 0.27083486318588257 average time 0.008102564800234783 iter num 60\n",
            "loss 2.0011816024780273 average time 0.006742122950208795 iter num 80\n",
            "loss 0.5753989219665527 average time 0.005927085250150412 iter num 100\n",
            "loss 0.1784513294696808 average time 0.005389432441734243 iter num 120\n",
            "loss 0.06094130873680115 average time 0.005017404671525583 iter num 140\n",
            "loss 0.35103631019592285 average time 0.004736853181316292 iter num 160\n",
            "loss 0.29558661580085754 average time 0.004517717850083298 iter num 180\n",
            "loss 0.11198911815881729 average time 0.004340793505052716 iter num 200\n",
            "loss 0.1259278953075409 average time 0.004196747404570157 iter num 220\n",
            "loss 0.45008280873298645 average time 0.004072713916699892 iter num 240\n",
            "loss 0.4202372431755066 average time 0.003985539084687144 iter num 260\n",
            "loss 0.1613440215587616 average time 0.0038928699107860405 iter num 280\n",
            "loss 0.32907870411872864 average time 0.0038125976700393947 iter num 300\n",
            "loss 0.20713964104652405 average time 0.00374582756566042 iter num 320\n",
            "loss 0.14355674386024475 average time 0.003681804017683402 iter num 340\n",
            "loss 0.17307451367378235 average time 0.0036254291695008256 iter num 360\n",
            "loss 0.2486853301525116 average time 0.003578176073728843 iter num 380\n",
            "loss 0.377748042345047 average time 0.003541905622532795 iter num 400\n",
            "loss 0.17243243753910065 average time 0.0035011859762259217 iter num 420\n",
            "loss 0.5362468957901001 average time 0.0034628109159463996 iter num 440\n",
            "loss 0.1452742964029312 average time 0.0034322053500427103 iter num 460\n",
            "loss 0.3397548794746399 average time 0.0034034383771161933 iter num 480\n",
            "loss 0.08213748782873154 average time 0.003378373030049261 iter num 500\n",
            "loss 0.2703331708908081 average time 0.00335061643660223 iter num 520\n",
            "loss 0.282594233751297 average time 0.003326698927830202 iter num 540\n",
            "loss 0.225897416472435 average time 0.0033078164464898563 iter num 560\n",
            "loss 0.18320110440254211 average time 0.003287576982833782 iter num 580\n",
            "loss 0.19732871651649475 average time 0.0032676444050715268 iter num 600\n",
            "loss 0.23105569183826447 average time 0.0032477497161967368 iter num 620\n",
            "loss 0.4116455316543579 average time 0.0032288677422513956 iter num 640\n",
            "loss 0.206843763589859 average time 0.0032142511667188956 iter num 660\n",
            "loss 0.14311960339546204 average time 0.0032063751765182293 iter num 680\n",
            "loss 0.23024573922157288 average time 0.0031951138614593737 iter num 700\n",
            "loss 0.11425215750932693 average time 0.0031871202847519775 iter num 720\n",
            "loss 0.3887299597263336 average time 0.003174954471634575 iter num 740\n",
            "loss 0.3156798183917999 average time 0.003165354788172025 iter num 760\n",
            "loss 0.41094648838043213 average time 0.0031558889769281125 iter num 780\n",
            "loss 0.06315874308347702 average time 0.0031466405075070724 iter num 800\n",
            "loss 0.1791050136089325 average time 0.003139215880489756 iter num 820\n",
            "loss 0.16846376657485962 average time 0.0031307493214279974 iter num 840\n",
            "loss 0.12763068079948425 average time 0.0031221565558151396 iter num 860\n",
            "loss 0.23182329535484314 average time 0.003114155655682473 iter num 880\n",
            "loss 0.18727776408195496 average time 0.003104684346678065 iter num 900\n",
            "loss 0.30370405316352844 average time 0.0030949807206564835 iter num 920\n",
            "loss 0.14529693126678467 average time 0.0030863308787337836 iter num 940\n",
            "loss 0.34285759925842285 average time 0.0030777696156330117 iter num 960\n",
            "loss 0.15321524441242218 average time 0.0030703384887898694 iter num 980\n",
            "loss 0.13116870820522308 average time 0.0030628563450118234 iter num 1000\n",
            "loss 0.10741433501243591 average time 0.01841897135018371 iter num 20\n",
            "loss 0.24445895850658417 average time 0.010874729075112555 iter num 40\n",
            "loss 0.2067359983921051 average time 0.008192854583285225 iter num 60\n",
            "loss 0.5798901915550232 average time 0.006819370787479784 iter num 80\n",
            "loss 0.9940954446792603 average time 0.005994338869968487 iter num 100\n",
            "loss 0.6098774671554565 average time 0.005440792908302683 iter num 120\n",
            "loss 0.5906901359558105 average time 0.00504336137138515 iter num 140\n",
            "loss 0.2335227131843567 average time 0.004753014743710082 iter num 160\n",
            "loss 0.2161509394645691 average time 0.004535581555481056 iter num 180\n",
            "loss 0.1870521754026413 average time 0.00435915047497474 iter num 200\n",
            "loss 0.6092621088027954 average time 0.004213848800000877 iter num 220\n",
            "loss 0.7359429597854614 average time 0.004107824350012379 iter num 240\n",
            "loss 0.2921634018421173 average time 0.0040057840461835996 iter num 260\n",
            "loss 0.28827232122421265 average time 0.003927449053584756 iter num 280\n",
            "loss 0.13209310173988342 average time 0.0038622225033517073 iter num 300\n",
            "loss 0.29025912284851074 average time 0.0038007352531280957 iter num 320\n",
            "loss 0.21112209558486938 average time 0.003738037726447253 iter num 340\n",
            "loss 0.12434956431388855 average time 0.0037049875444204695 iter num 360\n",
            "loss 0.15458601713180542 average time 0.003655779036824625 iter num 380\n",
            "loss 0.055920183658599854 average time 0.003628301582475615 iter num 400\n",
            "loss 0.39952462911605835 average time 0.0035873501356815853 iter num 420\n",
            "loss 0.29738372564315796 average time 0.003550580095419388 iter num 440\n",
            "loss 0.19329321384429932 average time 0.0035326266173639023 iter num 460\n",
            "loss 0.5211613178253174 average time 0.0035089272374686214 iter num 480\n",
            "loss 0.3216310143470764 average time 0.003484584873971471 iter num 500\n",
            "loss 0.3846737742424011 average time 0.003456144834602198 iter num 520\n",
            "loss 0.22165913879871368 average time 0.003428029366646283 iter num 540\n",
            "loss 0.14035192131996155 average time 0.003402984328541996 iter num 560\n",
            "loss 0.08302977681159973 average time 0.003378543218943754 iter num 580\n",
            "loss 0.17981407046318054 average time 0.0033601865983049115 iter num 600\n",
            "loss 0.07650184631347656 average time 0.0033413230015867158 iter num 620\n",
            "loss 0.12644614279270172 average time 0.003321329407782514 iter num 640\n",
            "loss 0.4264298975467682 average time 0.003303634636347741 iter num 660\n",
            "loss 0.07512334734201431 average time 0.0032860116602718976 iter num 680\n",
            "loss 0.14473043382167816 average time 0.0032694963399626433 iter num 700\n",
            "loss 0.2923043370246887 average time 0.0032544759902521036 iter num 720\n",
            "loss 0.18650773167610168 average time 0.0032396859864732234 iter num 740\n",
            "loss 0.15894055366516113 average time 0.003226819839456814 iter num 760\n",
            "loss 0.5196173191070557 average time 0.0032172456692140445 iter num 780\n",
            "loss 0.1923268437385559 average time 0.0032072149474788605 iter num 800\n",
            "loss 0.72096848487854 average time 0.0031957360426664617 iter num 820\n",
            "loss 0.15893465280532837 average time 0.0031852603618799115 iter num 840\n",
            "loss 0.17082545161247253 average time 0.0031745042999699402 iter num 860\n",
            "loss 0.07227650284767151 average time 0.003163786786328935 iter num 880\n",
            "loss 0.11480431258678436 average time 0.0031576821277445157 iter num 900\n",
            "loss 0.21179386973381042 average time 0.003147820372799723 iter num 920\n",
            "loss 0.30615171790122986 average time 0.0031401787063627356 iter num 940\n",
            "loss 0.11420509964227676 average time 0.0031324154468582795 iter num 960\n",
            "loss 0.494407057762146 average time 0.003122994458142933 iter num 980\n",
            "loss 0.08948652446269989 average time 0.003120742758979759 iter num 1000\n",
            "loss 0.1920272409915924 average time 0.01848633389981842 iter num 20\n",
            "loss 0.22973835468292236 average time 0.010591935375032335 iter num 40\n",
            "loss 0.13903778791427612 average time 0.00798270915026175 iter num 60\n",
            "loss 0.5867202281951904 average time 0.006683720750106659 iter num 80\n",
            "loss 0.41248705983161926 average time 0.005892641890168307 iter num 100\n",
            "loss 0.4353185296058655 average time 0.005393576408429605 iter num 120\n",
            "loss 0.5096753835678101 average time 0.005027401792982086 iter num 140\n",
            "loss 0.14872826635837555 average time 0.004737312731390375 iter num 160\n",
            "loss 0.2536783218383789 average time 0.004506407277848565 iter num 180\n",
            "loss 0.5625309944152832 average time 0.004326271700028883 iter num 200\n",
            "loss 0.690539538860321 average time 0.004181120895439315 iter num 220\n",
            "loss 0.1688096523284912 average time 0.0040621509916339464 iter num 240\n",
            "loss 0.16743528842926025 average time 0.003955858788378044 iter num 260\n",
            "loss 0.9266732335090637 average time 0.0038654487642166453 iter num 280\n",
            "loss 0.36314207315444946 average time 0.003794111039909088 iter num 300\n",
            "loss 0.06051619350910187 average time 0.0037294250717764045 iter num 320\n",
            "loss 0.27022218704223633 average time 0.003671109014623439 iter num 340\n",
            "loss 0.2592450976371765 average time 0.0036167987471445585 iter num 360\n",
            "loss 1.6572093963623047 average time 0.003583232239438267 iter num 380\n",
            "loss 0.39366424083709717 average time 0.0035387115949652072 iter num 400\n",
            "loss 0.05307073891162872 average time 0.0035002399428256986 iter num 420\n",
            "loss 0.14624951779842377 average time 0.003467050574966958 iter num 440\n",
            "loss 0.17944331467151642 average time 0.003437270184748859 iter num 460\n",
            "loss 0.26550060510635376 average time 0.00341195963330847 iter num 480\n",
            "loss 0.11402814090251923 average time 0.0033942829139705284 iter num 500\n",
            "loss 0.4934869706630707 average time 0.0033692665384758304 iter num 520\n",
            "loss 0.16782893240451813 average time 0.0033523845833567773 iter num 540\n",
            "loss 0.3496571183204651 average time 0.0033303761053697857 iter num 560\n",
            "loss 0.0692305713891983 average time 0.0033083529051697856 iter num 580\n",
            "loss 0.18562105298042297 average time 0.003287589798328554 iter num 600\n",
            "loss 0.10759470611810684 average time 0.003268636954834942 iter num 620\n",
            "loss 0.08710505068302155 average time 0.0032506126296880213 iter num 640\n",
            "loss 0.31952911615371704 average time 0.0032341357121285085 iter num 660\n",
            "loss 0.40426430106163025 average time 0.0032206055838394283 iter num 680\n",
            "loss 0.1521972119808197 average time 0.0032052834228878573 iter num 700\n",
            "loss 0.2337123602628708 average time 0.0031971355819627612 iter num 720\n",
            "loss 0.12270813435316086 average time 0.0031825591473141294 iter num 740\n",
            "loss 0.14706723392009735 average time 0.0031697828473768726 iter num 760\n",
            "loss 0.14956817030906677 average time 0.003158455153863589 iter num 780\n",
            "loss 0.05682932585477829 average time 0.003146591565014205 iter num 800\n",
            "loss 0.041647106409072876 average time 0.003136582650009453 iter num 820\n",
            "loss 0.18752746284008026 average time 0.003125850945239758 iter num 840\n",
            "loss 0.14881235361099243 average time 0.0031158597314060897 iter num 860\n",
            "loss 0.09190428256988525 average time 0.0031090927818282084 iter num 880\n",
            "loss 0.24489641189575195 average time 0.0031005434122441024 iter num 900\n",
            "loss 0.1370299756526947 average time 0.003093716420675185 iter num 920\n",
            "loss 0.05345163494348526 average time 0.0030883746989700815 iter num 940\n",
            "loss 0.2048700898885727 average time 0.003080101089612223 iter num 960\n",
            "loss 0.04968687891960144 average time 0.003072190619408205 iter num 980\n",
            "loss 0.36592191457748413 average time 0.0030670809720177205 iter num 1000\n",
            "loss 0.9880236387252808 average time 0.01838084799965145 iter num 20\n",
            "loss 0.1714816689491272 average time 0.01055483820000518 iter num 40\n",
            "loss 0.38314515352249146 average time 0.007956706566801586 iter num 60\n",
            "loss 0.3372504711151123 average time 0.006643213700181149 iter num 80\n",
            "loss 1.6728484630584717 average time 0.005854059920093278 iter num 100\n",
            "loss 0.24792169034481049 average time 0.005329121641716483 iter num 120\n",
            "loss 0.467609167098999 average time 0.004954296128640376 iter num 140\n",
            "loss 0.17835834622383118 average time 0.004670007300092038 iter num 160\n",
            "loss 0.7271531224250793 average time 0.004455180272311231 iter num 180\n",
            "loss 0.32085585594177246 average time 0.004286871730109851 iter num 200\n",
            "loss 0.1538301557302475 average time 0.004140496095566381 iter num 220\n",
            "loss 0.3942781090736389 average time 0.00402969557931101 iter num 240\n",
            "loss 0.36417078971862793 average time 0.0039248281385600705 iter num 260\n",
            "loss 0.2276451587677002 average time 0.003840929728656712 iter num 280\n",
            "loss 0.11683858931064606 average time 0.003765005663432627 iter num 300\n",
            "loss 0.19703027606010437 average time 0.003699033703196619 iter num 320\n",
            "loss 0.15844547748565674 average time 0.0036423127206837626 iter num 340\n",
            "loss 0.1478358954191208 average time 0.0035906856584410384 iter num 360\n",
            "loss 0.16837233304977417 average time 0.003543966779043809 iter num 380\n",
            "loss 0.23644573986530304 average time 0.003501608502583622 iter num 400\n",
            "loss 0.4211864471435547 average time 0.0034661409572263003 iter num 420\n",
            "loss 0.6162592172622681 average time 0.0034346877523603325 iter num 440\n",
            "loss 0.24623113870620728 average time 0.0034027258218133206 iter num 460\n",
            "loss 0.1870223581790924 average time 0.0033733948312980526 iter num 480\n",
            "loss 0.11612321436405182 average time 0.003347003292044974 iter num 500\n",
            "loss 0.14717517793178558 average time 0.0033219584365584663 iter num 520\n",
            "loss 0.15288731455802917 average time 0.0032986759055549757 iter num 540\n",
            "loss 0.26777517795562744 average time 0.0032770885678538825 iter num 560\n",
            "loss 0.18875640630722046 average time 0.0032583235224027986 iter num 580\n",
            "loss 0.11192440241575241 average time 0.0032427035199846916 iter num 600\n",
            "loss 0.08887582272291183 average time 0.003225612806431121 iter num 620\n",
            "loss 0.4021303057670593 average time 0.003210171503098991 iter num 640\n",
            "loss 0.26367121934890747 average time 0.003198005116637708 iter num 660\n",
            "loss 0.0903538167476654 average time 0.0031828438043917497 iter num 680\n",
            "loss 0.1414867341518402 average time 0.00316825241569729 iter num 700\n",
            "loss 0.12929324805736542 average time 0.0031550286277706617 iter num 720\n",
            "loss 0.14882199466228485 average time 0.003143164898638379 iter num 740\n",
            "loss 0.25232717394828796 average time 0.0031330180684084265 iter num 760\n",
            "loss 0.2614388167858124 average time 0.003122163801270243 iter num 780\n",
            "loss 0.1924135535955429 average time 0.0031137182062366264 iter num 800\n",
            "loss 0.170607790350914 average time 0.0031054700658365263 iter num 820\n",
            "loss 0.11962559819221497 average time 0.0030972681511706296 iter num 840\n",
            "loss 0.30398043990135193 average time 0.0030917199697415884 iter num 860\n",
            "loss 0.0893685594201088 average time 0.0030849857977045757 iter num 880\n",
            "loss 0.15236324071884155 average time 0.00307888863887557 iter num 900\n",
            "loss 0.383709579706192 average time 0.00307108887063805 iter num 920\n",
            "loss 0.0788695216178894 average time 0.003066234462761365 iter num 940\n",
            "loss 0.08626517653465271 average time 0.0030598183708207215 iter num 960\n",
            "loss 0.24350284039974213 average time 0.0030547378663144703 iter num 980\n",
            "loss 0.23755069077014923 average time 0.0030507632259796085 iter num 1000\n",
            "loss 0.6988338232040405 average time 0.018398660200182347 iter num 20\n",
            "loss 0.7724709510803223 average time 0.010587100950215245 iter num 40\n",
            "loss 0.11728871613740921 average time 0.007998000166844576 iter num 60\n",
            "loss 0.2200813889503479 average time 0.006702860900122687 iter num 80\n",
            "loss 0.31823015213012695 average time 0.005913063719999627 iter num 100\n",
            "loss 0.18188849091529846 average time 0.005378068008455254 iter num 120\n",
            "loss 0.120207279920578 average time 0.004993363207254983 iter num 140\n",
            "loss 0.27079030871391296 average time 0.004709932650121118 iter num 160\n",
            "loss 0.6787301301956177 average time 0.004484418527903876 iter num 180\n",
            "loss 0.23798637092113495 average time 0.00430486422508693 iter num 200\n",
            "loss 0.9163225293159485 average time 0.004158276736416155 iter num 220\n",
            "loss 0.4478311240673065 average time 0.0040382838583961226 iter num 240\n",
            "loss 0.30202415585517883 average time 0.003937556846176448 iter num 260\n",
            "loss 0.5500224232673645 average time 0.003849222507142258 iter num 280\n",
            "loss 0.22591964900493622 average time 0.0037715470600232946 iter num 300\n",
            "loss 0.2015979290008545 average time 0.0037041160749822664 iter num 320\n",
            "loss 0.04909643903374672 average time 0.0036506628146526056 iter num 340\n",
            "loss 0.3532615900039673 average time 0.0035981705888540696 iter num 360\n",
            "loss 0.22537371516227722 average time 0.0035504675078539692 iter num 380\n",
            "loss 0.25727379322052 average time 0.003511443549969044 iter num 400\n",
            "loss 0.2721543312072754 average time 0.00347243159760096 iter num 420\n",
            "loss 0.11136828362941742 average time 0.0034397515159153872 iter num 440\n",
            "loss 0.4159560203552246 average time 0.0034090165086878266 iter num 460\n",
            "loss 0.26169607043266296 average time 0.0033798980458414007 iter num 480\n",
            "loss 0.12592674791812897 average time 0.003352336636002292 iter num 500\n",
            "loss 0.18296243250370026 average time 0.00332768587692184 iter num 520\n",
            "loss 0.061392612755298615 average time 0.0033039235129628517 iter num 540\n",
            "loss 0.05852174758911133 average time 0.0032842695821467976 iter num 560\n",
            "loss 0.07992184162139893 average time 0.0032669392068908503 iter num 580\n",
            "loss 0.13655269145965576 average time 0.003247802051658558 iter num 600\n",
            "loss 0.25505489110946655 average time 0.0032303559113056363 iter num 620\n",
            "loss 0.10882614552974701 average time 0.0032145290765754455 iter num 640\n",
            "loss 0.23608900606632233 average time 0.0032031535091102178 iter num 660\n",
            "loss 0.12013237178325653 average time 0.0031896779809037126 iter num 680\n",
            "loss 0.16179460287094116 average time 0.0031775416814395743 iter num 700\n",
            "loss 0.08536575734615326 average time 0.003167616913894259 iter num 720\n",
            "loss 0.23299717903137207 average time 0.0031575427445991286 iter num 740\n",
            "loss 0.11538433283567429 average time 0.003146165306584168 iter num 760\n",
            "loss 0.10950500518083572 average time 0.003134587294875811 iter num 780\n",
            "loss 0.10542351007461548 average time 0.0031291741174982236 iter num 800\n",
            "loss 0.13455092906951904 average time 0.0031186413646160298 iter num 820\n",
            "loss 0.07589863985776901 average time 0.0031087272940480727 iter num 840\n",
            "loss 0.1694180816411972 average time 0.0031010430883661897 iter num 860\n",
            "loss 0.037013791501522064 average time 0.0030925313477258567 iter num 880\n",
            "loss 0.17218264937400818 average time 0.0030843005700040118 iter num 900\n",
            "loss 0.08568015694618225 average time 0.003082688964146339 iter num 920\n",
            "loss 0.1067131757736206 average time 0.0030749319255459766 iter num 940\n",
            "loss 0.045030977576971054 average time 0.003073133290630873 iter num 960\n",
            "loss 0.1073259711265564 average time 0.0030680575744999983 iter num 980\n",
            "loss 0.12419327348470688 average time 0.0030623461970062634 iter num 1000\n",
            "loss 0.3109475374221802 average time 0.018339800499597915 iter num 20\n",
            "loss 0.5298974514007568 average time 0.010575863324811507 iter num 40\n",
            "loss 0.6556427478790283 average time 0.00795392511645332 iter num 60\n",
            "loss 0.7204626798629761 average time 0.006683685762345704 iter num 80\n",
            "loss 0.12837252020835876 average time 0.005890250549928169 iter num 100\n",
            "loss 0.6568446159362793 average time 0.005363913241581031 iter num 120\n",
            "loss 0.2714258134365082 average time 0.00498497890712315 iter num 140\n",
            "loss 0.11263176798820496 average time 0.004698067749950496 iter num 160\n",
            "loss 0.16546568274497986 average time 0.004482120833219799 iter num 180\n",
            "loss 0.35384857654571533 average time 0.0043079969998871094 iter num 200\n",
            "loss 0.1820971667766571 average time 0.004160043572631945 iter num 220\n",
            "loss 0.2600763738155365 average time 0.004036898874862042 iter num 240\n",
            "loss 0.9376049041748047 average time 0.003935497519145988 iter num 260\n",
            "loss 0.49802398681640625 average time 0.0038504296035171137 iter num 280\n",
            "loss 0.3255283236503601 average time 0.003775311306635558 iter num 300\n",
            "loss 0.3781315088272095 average time 0.003709857815590567 iter num 320\n",
            "loss 0.37011638283729553 average time 0.003655927564667603 iter num 340\n",
            "loss 0.1428702026605606 average time 0.0036160711166404427 iter num 360\n",
            "loss 0.28295284509658813 average time 0.003568395236815329 iter num 380\n",
            "loss 0.07792732119560242 average time 0.0035299638049855276 iter num 400\n",
            "loss 0.23623253405094147 average time 0.0034921685809292413 iter num 420\n",
            "loss 0.1364477276802063 average time 0.0034579655590774067 iter num 440\n",
            "loss 0.14962849020957947 average time 0.0034278577673751936 iter num 460\n",
            "loss 0.1507999300956726 average time 0.0034026553645768822 iter num 480\n",
            "loss 0.0681513100862503 average time 0.0033777431760099717 iter num 500\n",
            "loss 0.1868966668844223 average time 0.003351716180776958 iter num 520\n",
            "loss 0.27399179339408875 average time 0.0033273587592635456 iter num 540\n",
            "loss 0.1539853811264038 average time 0.0033048754339168747 iter num 560\n",
            "loss 0.3362675607204437 average time 0.0032881818034278193 iter num 580\n",
            "loss 0.4571573734283447 average time 0.003268155373316404 iter num 600\n",
            "loss 0.24601374566555023 average time 0.0032493310386921474 iter num 620\n",
            "loss 0.21289369463920593 average time 0.0032375711109295935 iter num 640\n",
            "loss 0.23360484838485718 average time 0.003226661503013571 iter num 660\n",
            "loss 0.17145061492919922 average time 0.0032109426558664007 iter num 680\n",
            "loss 0.12461448460817337 average time 0.00319820438570397 iter num 700\n",
            "loss 0.08147534728050232 average time 0.0031846871874980326 iter num 720\n",
            "loss 0.23701320588588715 average time 0.003171530486483912 iter num 740\n",
            "loss 0.19090239703655243 average time 0.0031633260118580533 iter num 760\n",
            "loss 0.45111560821533203 average time 0.0031535910692419306 iter num 780\n",
            "loss 0.09566650539636612 average time 0.0031449889100031215 iter num 800\n",
            "loss 0.12369342148303986 average time 0.0031337836512049274 iter num 820\n",
            "loss 0.124884232878685 average time 0.003123552717850197 iter num 840\n",
            "loss 0.33974772691726685 average time 0.003115118639517425 iter num 860\n",
            "loss 0.07763374596834183 average time 0.00311101253861869 iter num 880\n",
            "loss 0.04544700309634209 average time 0.003102316365532008 iter num 900\n",
            "loss 0.4241485595703125 average time 0.003093837561933153 iter num 920\n",
            "loss 0.0793609470129013 average time 0.0030863738489101027 iter num 940\n",
            "loss 0.0769825279712677 average time 0.0030788355083169942 iter num 960\n",
            "loss 0.22115826606750488 average time 0.0030722112357078894 iter num 980\n",
            "loss 0.24320589005947113 average time 0.003064509073996305 iter num 1000\n",
            "loss 0.611473560333252 average time 0.018461843049590244 iter num 20\n",
            "loss 0.3061375319957733 average time 0.010578774149871606 iter num 40\n",
            "loss 0.30351999402046204 average time 0.007955246866549715 iter num 60\n",
            "loss 0.15233933925628662 average time 0.006645969374858396 iter num 80\n",
            "loss 0.2929985225200653 average time 0.0058676157999434505 iter num 100\n",
            "loss 0.393520325422287 average time 0.0053440749832285896 iter num 120\n",
            "loss 0.28256848454475403 average time 0.004962741457036048 iter num 140\n",
            "loss 1.1572740077972412 average time 0.004681299168623809 iter num 160\n",
            "loss 0.291071355342865 average time 0.0044598872888147725 iter num 180\n",
            "loss 0.21008482575416565 average time 0.004301845909940312 iter num 200\n",
            "loss 0.21669510006904602 average time 0.0041614682680863714 iter num 220\n",
            "loss 0.5242586135864258 average time 0.0040393925249342525 iter num 240\n",
            "loss 0.15761518478393555 average time 0.003937775119126085 iter num 260\n",
            "loss 0.24315081536769867 average time 0.0038500555999235074 iter num 280\n",
            "loss 0.3784834146499634 average time 0.0037726117032555826 iter num 300\n",
            "loss 0.5083482265472412 average time 0.0037034618905749995 iter num 320\n",
            "loss 0.20361272990703583 average time 0.0036453441234912403 iter num 340\n",
            "loss 0.15524806082248688 average time 0.0035994438860850802 iter num 360\n",
            "loss 0.5454064607620239 average time 0.0035609658315431596 iter num 380\n",
            "loss 0.20893609523773193 average time 0.0035214975024882734 iter num 400\n",
            "loss 0.08141228556632996 average time 0.0034858052285580057 iter num 420\n",
            "loss 0.4083501994609833 average time 0.003454712611338354 iter num 440\n",
            "loss 0.15843354165554047 average time 0.0034237577217224855 iter num 460\n",
            "loss 0.3326702117919922 average time 0.0033968570312254086 iter num 480\n",
            "loss 0.27333489060401917 average time 0.0033725494619866367 iter num 500\n",
            "loss 0.14975140988826752 average time 0.0033475035038253945 iter num 520\n",
            "loss 0.2621188461780548 average time 0.003325365724056071 iter num 540\n",
            "loss 0.17793914675712585 average time 0.0033017985321358925 iter num 560\n",
            "loss 0.16282153129577637 average time 0.003284414970679289 iter num 580\n",
            "loss 0.39851129055023193 average time 0.003264444355008891 iter num 600\n",
            "loss 0.14203982055187225 average time 0.003246755743554874 iter num 620\n",
            "loss 0.10680893063545227 average time 0.0032338188984340375 iter num 640\n",
            "loss 0.052282318472862244 average time 0.0032233768393780337 iter num 660\n",
            "loss 0.12260057777166367 average time 0.003214723027924586 iter num 680\n",
            "loss 0.05328666418790817 average time 0.003201709911398731 iter num 700\n",
            "loss 0.14599794149398804 average time 0.0031870897235775275 iter num 720\n",
            "loss 0.21220922470092773 average time 0.0031743006594272603 iter num 740\n",
            "loss 0.2141937017440796 average time 0.003163008488124768 iter num 760\n",
            "loss 0.15863949060440063 average time 0.003151205479442955 iter num 780\n",
            "loss 0.11948317289352417 average time 0.0031402176274514205 iter num 800\n",
            "loss 0.1987602561712265 average time 0.0031295591597172018 iter num 820\n",
            "loss 0.2683839797973633 average time 0.0031191784761523153 iter num 840\n",
            "loss 0.07216881215572357 average time 0.003109431698790421 iter num 860\n",
            "loss 0.21731218695640564 average time 0.003100181890853161 iter num 880\n",
            "loss 0.08266108483076096 average time 0.0030934037366104248 iter num 900\n",
            "loss 0.07089783251285553 average time 0.0030851318738551407 iter num 920\n",
            "loss 0.08689926564693451 average time 0.003077543902068004 iter num 940\n",
            "loss 0.2153829038143158 average time 0.0030712874988997403 iter num 960\n",
            "loss 0.09586896002292633 average time 0.00306838136014133 iter num 980\n",
            "loss 0.18936309218406677 average time 0.003060835445940029 iter num 1000\n",
            "loss 0.5494568347930908 average time 0.01861671224996826 iter num 20\n",
            "loss 0.2023315727710724 average time 0.010674238150295423 iter num 40\n",
            "loss 0.15651357173919678 average time 0.00801569555005699 iter num 60\n",
            "loss 0.3541393578052521 average time 0.006681103450000591 iter num 80\n",
            "loss 0.2800426483154297 average time 0.005885747299944341 iter num 100\n",
            "loss 0.21288427710533142 average time 0.005364608933299072 iter num 120\n",
            "loss 0.3071609139442444 average time 0.004981686507094959 iter num 140\n",
            "loss 0.10213217884302139 average time 0.004708910812382783 iter num 160\n",
            "loss 0.684684693813324 average time 0.004487007483233659 iter num 180\n",
            "loss 0.3437958061695099 average time 0.00431035603991404 iter num 200\n",
            "loss 0.5934950113296509 average time 0.004172403431717116 iter num 220\n",
            "loss 0.21688146889209747 average time 0.004051169295720077 iter num 240\n",
            "loss 0.27678653597831726 average time 0.003945787946059471 iter num 260\n",
            "loss 0.07942239940166473 average time 0.0038559302641910367 iter num 280\n",
            "loss 0.15569157898426056 average time 0.00377792297656318 iter num 300\n",
            "loss 0.20318055152893066 average time 0.0037121185467981375 iter num 320\n",
            "loss 0.2266322821378708 average time 0.003652033788143051 iter num 340\n",
            "loss 0.15839996933937073 average time 0.003600376238814028 iter num 360\n",
            "loss 0.182632714509964 average time 0.0035551739578295384 iter num 380\n",
            "loss 0.17241737246513367 average time 0.003526569074965664 iter num 400\n",
            "loss 0.2371034026145935 average time 0.003492908711875013 iter num 420\n",
            "loss 0.15322130918502808 average time 0.0034600066272684094 iter num 440\n",
            "loss 0.3165755569934845 average time 0.0034270993565018136 iter num 460\n",
            "loss 0.2418537139892578 average time 0.0033988996145732624 iter num 480\n",
            "loss 0.28733980655670166 average time 0.0033698515599680833 iter num 500\n",
            "loss 0.3179911673069 average time 0.003343762749976192 iter num 520\n",
            "loss 0.12477031350135803 average time 0.0033212197222046262 iter num 540\n",
            "loss 0.3111969828605652 average time 0.003305950042840777 iter num 560\n",
            "loss 0.21063873171806335 average time 0.0032868288568979236 iter num 580\n",
            "loss 0.6691992878913879 average time 0.003270432801673451 iter num 600\n",
            "loss 0.16179552674293518 average time 0.0032600901580794486 iter num 620\n",
            "loss 0.20442508161067963 average time 0.0032440687968971816 iter num 640\n",
            "loss 0.12910598516464233 average time 0.0032285843454673974 iter num 660\n",
            "loss 0.18745046854019165 average time 0.0032167507911949273 iter num 680\n",
            "loss 0.3058474361896515 average time 0.0032033726200305476 iter num 700\n",
            "loss 0.12548446655273438 average time 0.0031916083264150073 iter num 720\n",
            "loss 0.0806717500090599 average time 0.003179400609479745 iter num 740\n",
            "loss 0.19124457240104675 average time 0.0031683858079113157 iter num 760\n",
            "loss 0.14590713381767273 average time 0.003156271505129273 iter num 780\n",
            "loss 0.21423792839050293 average time 0.003145586128762261 iter num 800\n",
            "loss 0.14387208223342896 average time 0.003137405519537868 iter num 820\n",
            "loss 0.21469497680664062 average time 0.003132136922648074 iter num 840\n",
            "loss 0.2188066840171814 average time 0.003123228395380402 iter num 860\n",
            "loss 0.15242457389831543 average time 0.003113987007988974 iter num 880\n",
            "loss 0.1610826849937439 average time 0.0031054159255816355 iter num 900\n",
            "loss 0.13585428893566132 average time 0.003097088461977957 iter num 920\n",
            "loss 0.20250767469406128 average time 0.003091189729817183 iter num 940\n",
            "loss 0.12425152957439423 average time 0.003084249013572086 iter num 960\n",
            "loss 0.12384015321731567 average time 0.00307699028676232 iter num 980\n",
            "loss 0.12602491676807404 average time 0.0030711719400351284 iter num 1000\n",
            "loss 0.35856789350509644 average time 0.01828004860035435 iter num 20\n",
            "loss 0.5966696739196777 average time 0.01043760505017417 iter num 40\n",
            "loss 2.435577392578125 average time 0.007819628766568106 iter num 60\n",
            "loss 1.7978527545928955 average time 0.006510183799764491 iter num 80\n",
            "loss 0.3625987768173218 average time 0.005715129599884676 iter num 100\n",
            "loss 0.4554014205932617 average time 0.005191171674899427 iter num 120\n",
            "loss 0.236236572265625 average time 0.004809339271352135 iter num 140\n",
            "loss 0.12925070524215698 average time 0.004529092518737343 iter num 160\n",
            "loss 0.35889965295791626 average time 0.0043101592832398535 iter num 180\n",
            "loss 0.15266479551792145 average time 0.004137282494921238 iter num 200\n",
            "loss 0.1644449383020401 average time 0.004006282799987689 iter num 220\n",
            "loss 0.45237788558006287 average time 0.0038835979583382143 iter num 240\n",
            "loss 0.19013522565364838 average time 0.003785027719235446 iter num 260\n",
            "loss 0.355617880821228 average time 0.00369918595001114 iter num 280\n",
            "loss 0.12573689222335815 average time 0.0036225850866928038 iter num 300\n",
            "loss 0.9079124927520752 average time 0.003557403434410844 iter num 320\n",
            "loss 0.1017184779047966 average time 0.003497496232343752 iter num 340\n",
            "loss 0.8320642709732056 average time 0.0034453570249954484 iter num 360\n",
            "loss 0.27498459815979004 average time 0.0033998991842102105 iter num 380\n",
            "loss 0.32441768050193787 average time 0.0033578952024981845 iter num 400\n",
            "loss 0.05453738570213318 average time 0.003322821095224797 iter num 420\n",
            "loss 0.5156463384628296 average time 0.0032927999386215974 iter num 440\n",
            "loss 0.18568284809589386 average time 0.0032623815934604626 iter num 460\n",
            "loss 0.09449014812707901 average time 0.003233377806259341 iter num 480\n",
            "loss 0.20192740857601166 average time 0.003208058726027957 iter num 500\n",
            "loss 0.21431969106197357 average time 0.003196487005789095 iter num 520\n",
            "loss 0.21725018322467804 average time 0.0031773704296466786 iter num 540\n",
            "loss 0.19551369547843933 average time 0.003160644558952949 iter num 560\n",
            "loss 0.2395324558019638 average time 0.003147191887941956 iter num 580\n",
            "loss 0.29897043108940125 average time 0.0031271987950033994 iter num 600\n",
            "loss 0.15722818672657013 average time 0.0031126816129178605 iter num 620\n",
            "loss 0.3083269000053406 average time 0.0030972400562689017 iter num 640\n",
            "loss 0.05140122026205063 average time 0.0030839868848653914 iter num 660\n",
            "loss 0.24725459516048431 average time 0.003077443933847569 iter num 680\n",
            "loss 0.28068673610687256 average time 0.003062859051465888 iter num 700\n",
            "loss 0.17462167143821716 average time 0.0030488080639063104 iter num 720\n",
            "loss 0.2987273335456848 average time 0.0030360967743429165 iter num 740\n",
            "loss 0.17766480147838593 average time 0.003023387921075482 iter num 760\n",
            "loss 0.14079609513282776 average time 0.0030117390025761544 iter num 780\n",
            "loss 0.06510865688323975 average time 0.0030002332487538298 iter num 800\n",
            "loss 0.24228720366954803 average time 0.002991019348794397 iter num 820\n",
            "loss 0.14701113104820251 average time 0.0029797887488279056 iter num 840\n",
            "loss 0.18322838842868805 average time 0.0029695201349081903 iter num 860\n",
            "loss 0.1291770040988922 average time 0.0029602142193322256 iter num 880\n",
            "loss 0.32809701561927795 average time 0.002952840027792263 iter num 900\n",
            "loss 0.059455398470163345 average time 0.0029478022347852262 iter num 920\n",
            "loss 0.17611509561538696 average time 0.0029395817893600905 iter num 940\n",
            "loss 0.05728911608457565 average time 0.0029314820416554235 iter num 960\n",
            "loss 0.07762172818183899 average time 0.00292395187346728 iter num 980\n",
            "loss 0.05316391587257385 average time 0.0029158293880027484 iter num 1000\n",
            "loss 0.1048818975687027 average time 0.018309959250291285 iter num 20\n",
            "loss 0.127064049243927 average time 0.010433532550177916 iter num 40\n",
            "loss 0.29453426599502563 average time 0.007821608766850357 iter num 60\n",
            "loss 0.4001004695892334 average time 0.00651642583766261 iter num 80\n",
            "loss 0.18209674954414368 average time 0.005733767570200143 iter num 100\n",
            "loss 0.17529845237731934 average time 0.005221028150178123 iter num 120\n",
            "loss 1.0921428203582764 average time 0.004841394171541781 iter num 140\n",
            "loss 0.31969907879829407 average time 0.004559976962627843 iter num 160\n",
            "loss 0.11119099706411362 average time 0.0043464648279041285 iter num 180\n",
            "loss 0.3895713984966278 average time 0.004203355545105297 iter num 200\n",
            "loss 0.13571688532829285 average time 0.004055852854633651 iter num 220\n",
            "loss 0.3361339867115021 average time 0.003932375837590977 iter num 240\n",
            "loss 0.6912887692451477 average time 0.0038349726231759773 iter num 260\n",
            "loss 0.3574761748313904 average time 0.0037438415715119583 iter num 280\n",
            "loss 0.28154754638671875 average time 0.003669817150112067 iter num 300\n",
            "loss 0.37869173288345337 average time 0.0036032924625942543 iter num 320\n",
            "loss 0.21346810460090637 average time 0.0035464282236502827 iter num 340\n",
            "loss 0.28052133321762085 average time 0.0034988292167933348 iter num 360\n",
            "loss 0.28912487626075745 average time 0.0034469522764323446 iter num 380\n",
            "loss 0.27131977677345276 average time 0.0034037344126045354 iter num 400\n",
            "loss 0.12246157228946686 average time 0.00336247749532742 iter num 420\n",
            "loss 0.1420741081237793 average time 0.0033275084977917274 iter num 440\n",
            "loss 0.2593047022819519 average time 0.0032911856457244343 iter num 460\n",
            "loss 0.10990793257951736 average time 0.003259145554246364 iter num 480\n",
            "loss 0.23196765780448914 average time 0.0032303916141099764 iter num 500\n",
            "loss 0.07933036237955093 average time 0.0032016689654763186 iter num 520\n",
            "loss 0.10242117941379547 average time 0.0031746331037774563 iter num 540\n",
            "loss 0.43513280153274536 average time 0.0031527567643804236 iter num 560\n",
            "loss 0.20931226015090942 average time 0.00314447307596781 iter num 580\n",
            "loss 0.12523655593395233 average time 0.0031251013367727867 iter num 600\n",
            "loss 0.06440255045890808 average time 0.0031141663000990747 iter num 620\n",
            "loss 0.20364561676979065 average time 0.003100325686017413 iter num 640\n",
            "loss 0.14261169731616974 average time 0.0030865321061355642 iter num 660\n",
            "loss 0.3233764171600342 average time 0.0030733575353652292 iter num 680\n",
            "loss 0.2916492819786072 average time 0.003063712130065791 iter num 700\n",
            "loss 0.07990829646587372 average time 0.003057562430603866 iter num 720\n",
            "loss 0.27807459235191345 average time 0.0030502554338208694 iter num 740\n",
            "loss 0.22891080379486084 average time 0.003042897688187383 iter num 760\n",
            "loss 0.06919503211975098 average time 0.0030361411448981157 iter num 780\n",
            "loss 0.22700664401054382 average time 0.0030279366825243415 iter num 800\n",
            "loss 0.10644639283418655 average time 0.003018754243926307 iter num 820\n",
            "loss 0.07472972571849823 average time 0.0030074430345415574 iter num 840\n",
            "loss 0.21608811616897583 average time 0.002996963761633683 iter num 860\n",
            "loss 0.12573041021823883 average time 0.0029868637431842548 iter num 880\n",
            "loss 0.21039563417434692 average time 0.0029775448500004133 iter num 900\n",
            "loss 0.20316669344902039 average time 0.00296962788151691 iter num 920\n",
            "loss 0.09766922891139984 average time 0.0029602236010643846 iter num 940\n",
            "loss 0.14607016742229462 average time 0.002951950334374942 iter num 960\n",
            "loss 0.09674075245857239 average time 0.002944352997956787 iter num 980\n",
            "loss 0.20645585656166077 average time 0.0029367431580030823 iter num 1000\n",
            "loss 1.251098871231079 average time 0.018255703750219253 iter num 20\n",
            "loss 0.2849014401435852 average time 0.010425275900161068 iter num 40\n",
            "loss 0.8360522389411926 average time 0.007843477049937065 iter num 60\n",
            "loss 0.19711101055145264 average time 0.00658893752502081 iter num 80\n",
            "loss 0.8837249279022217 average time 0.005796039730084885 iter num 100\n",
            "loss 0.9606347680091858 average time 0.005261394891719343 iter num 120\n",
            "loss 0.6871273517608643 average time 0.004874450778619835 iter num 140\n",
            "loss 0.5221744775772095 average time 0.004598914812527255 iter num 160\n",
            "loss 0.2367745190858841 average time 0.004366604344431835 iter num 180\n",
            "loss 0.8762529492378235 average time 0.004187150075013051 iter num 200\n",
            "loss 0.2942754924297333 average time 0.00404336006362097 iter num 220\n",
            "loss 1.690153956413269 average time 0.00391457657498601 iter num 240\n",
            "loss 0.14411437511444092 average time 0.0038084776500069825 iter num 260\n",
            "loss 0.2384539395570755 average time 0.003715798710722343 iter num 280\n",
            "loss 0.2137165069580078 average time 0.0036366794566250367 iter num 300\n",
            "loss 0.08360176533460617 average time 0.0035687009124785616 iter num 320\n",
            "loss 0.07750523090362549 average time 0.003506742479390489 iter num 340\n",
            "loss 0.13259784877300262 average time 0.003458044563861525 iter num 360\n",
            "loss 0.19886469841003418 average time 0.00341342461312084 iter num 380\n",
            "loss 0.10058243572711945 average time 0.0033724299849836824 iter num 400\n",
            "loss 0.10790576040744781 average time 0.0033495176357194265 iter num 420\n",
            "loss 0.34090304374694824 average time 0.0033186431159017296 iter num 440\n",
            "loss 0.345020592212677 average time 0.0032916038326062415 iter num 460\n",
            "loss 0.3053944408893585 average time 0.003267988516646862 iter num 480\n",
            "loss 0.23394298553466797 average time 0.0032508463459744235 iter num 500\n",
            "loss 0.10228191316127777 average time 0.003231920624973729 iter num 520\n",
            "loss 0.11715170741081238 average time 0.003213797907382185 iter num 540\n",
            "loss 0.2919229567050934 average time 0.003198292489261283 iter num 560\n",
            "loss 0.24884453415870667 average time 0.003178043165518892 iter num 580\n",
            "loss 0.37878745794296265 average time 0.003161193536658781 iter num 600\n",
            "loss 0.16073240339756012 average time 0.0031463364871078445 iter num 620\n",
            "loss 0.3839607834815979 average time 0.0031281198781300647 iter num 640\n",
            "loss 0.2369719296693802 average time 0.0031177855833558364 iter num 660\n",
            "loss 0.12287995219230652 average time 0.0031044823441441303 iter num 680\n",
            "loss 0.364837110042572 average time 0.003093159402872386 iter num 700\n",
            "loss 0.13003019988536835 average time 0.003078697158353963 iter num 720\n",
            "loss 0.1693238914012909 average time 0.00306801647164173 iter num 740\n",
            "loss 0.43702802062034607 average time 0.00305441984738584 iter num 760\n",
            "loss 0.10881106555461884 average time 0.003040844806421844 iter num 780\n",
            "loss 0.18601417541503906 average time 0.00302795059750224 iter num 800\n",
            "loss 0.364423930644989 average time 0.0030157501707435584 iter num 820\n",
            "loss 0.20179963111877441 average time 0.003009244795252709 iter num 840\n",
            "loss 0.11312855780124664 average time 0.003001682316286416 iter num 860\n",
            "loss 0.08714103698730469 average time 0.0029917001590960847 iter num 880\n",
            "loss 0.06566616147756577 average time 0.0029865430055724573 iter num 900\n",
            "loss 0.19305938482284546 average time 0.002982490952189951 iter num 920\n",
            "loss 0.06305932998657227 average time 0.002978965870236007 iter num 940\n",
            "loss 0.19251377880573273 average time 0.0029754985354429665 iter num 960\n",
            "loss 0.2013104259967804 average time 0.002971818214305409 iter num 980\n",
            "loss 0.08636772632598877 average time 0.0029685146910233017 iter num 1000\n",
            "loss 0.7139567732810974 average time 0.01873472684983426 iter num 20\n",
            "loss 0.8744189739227295 average time 0.010750660074972985 iter num 40\n",
            "loss 0.6704355478286743 average time 0.008046496500355715 iter num 60\n",
            "loss 0.9081852436065674 average time 0.006743967975262421 iter num 80\n",
            "loss 0.2572679817676544 average time 0.00593525069019961 iter num 100\n",
            "loss 0.491999089717865 average time 0.005378762408448286 iter num 120\n",
            "loss 0.22872145473957062 average time 0.004982721292981296 iter num 140\n",
            "loss 0.05530090630054474 average time 0.004682413625187109 iter num 160\n",
            "loss 0.3519801199436188 average time 0.004446314916822303 iter num 180\n",
            "loss 0.4105146527290344 average time 0.004265536055136181 iter num 200\n",
            "loss 0.3091341257095337 average time 0.004111533231943296 iter num 220\n",
            "loss 0.7075315713882446 average time 0.00398716341258781 iter num 240\n",
            "loss 0.3384476900100708 average time 0.003880903788586483 iter num 260\n",
            "loss 0.1772499680519104 average time 0.0037899218822920896 iter num 280\n",
            "loss 0.1838884949684143 average time 0.0037103560468312933 iter num 300\n",
            "loss 0.30381226539611816 average time 0.0036376534657620143 iter num 320\n",
            "loss 0.4734466075897217 average time 0.0035748611207215134 iter num 340\n",
            "loss 0.3897484540939331 average time 0.0035263389029144793 iter num 360\n",
            "loss 0.15977194905281067 average time 0.003476254389610595 iter num 380\n",
            "loss 0.42771250009536743 average time 0.003433926972638801 iter num 400\n",
            "loss 0.18049317598342896 average time 0.0033958536953789353 iter num 420\n",
            "loss 0.23211465775966644 average time 0.0033583687160568263 iter num 440\n",
            "loss 0.3918737471103668 average time 0.003325566043610667 iter num 460\n",
            "loss 0.5664060711860657 average time 0.003297789150102896 iter num 480\n",
            "loss 0.15681874752044678 average time 0.0032679323021147866 iter num 500\n",
            "loss 0.23260048031806946 average time 0.0032440816635523964 iter num 520\n",
            "loss 0.16393965482711792 average time 0.003234600838967944 iter num 540\n",
            "loss 0.043852128088474274 average time 0.0032215333482781714 iter num 560\n",
            "loss 0.2687813341617584 average time 0.0032056430517984373 iter num 580\n",
            "loss 0.42392104864120483 average time 0.0031837591584250426 iter num 600\n",
            "loss 0.10136889666318893 average time 0.003163649595256673 iter num 620\n",
            "loss 0.24750687181949615 average time 0.003149921726657112 iter num 640\n",
            "loss 0.2582303285598755 average time 0.003139610257670883 iter num 660\n",
            "loss 0.1322598159313202 average time 0.00312477458096777 iter num 680\n",
            "loss 0.2335050106048584 average time 0.0031099396672289005 iter num 700\n",
            "loss 0.4170970916748047 average time 0.003097635101474023 iter num 720\n",
            "loss 0.11529809236526489 average time 0.0030830391217023132 iter num 740\n",
            "loss 0.16549260914325714 average time 0.0030695635777192366 iter num 760\n",
            "loss 0.14604011178016663 average time 0.0030545754064988636 iter num 780\n",
            "loss 0.12033767253160477 average time 0.0030410541063338316 iter num 800\n",
            "loss 0.07580551505088806 average time 0.003027355515946621 iter num 820\n",
            "loss 0.1825444996356964 average time 0.0030197525810416706 iter num 840\n",
            "loss 0.08687511086463928 average time 0.0030094176245002865 iter num 860\n",
            "loss 0.05119527876377106 average time 0.002998072601216832 iter num 880\n",
            "loss 0.16434147953987122 average time 0.0029880815089685106 iter num 900\n",
            "loss 0.17984095215797424 average time 0.0029771006761660354 iter num 920\n",
            "loss 0.13604949414730072 average time 0.0029704183777404126 iter num 940\n",
            "loss 0.19828249514102936 average time 0.0029600660386298236 iter num 960\n",
            "loss 0.20170888304710388 average time 0.002952239181709325 iter num 980\n",
            "loss 0.3086501955986023 average time 0.0029430142860765044 iter num 1000\n",
            "loss 0.1857951283454895 average time 0.018154533799861382 iter num 20\n",
            "loss 0.6769084930419922 average time 0.010326916624762816 iter num 40\n",
            "loss 0.09953639656305313 average time 0.007710332683321515 iter num 60\n",
            "loss 0.639208972454071 average time 0.006412306412585167 iter num 80\n",
            "loss 0.10477340966463089 average time 0.005623206420132192 iter num 100\n",
            "loss 0.2285417765378952 average time 0.005096478583436692 iter num 120\n",
            "loss 0.6238043904304504 average time 0.004737783764332042 iter num 140\n",
            "loss 0.5274049043655396 average time 0.004456743781247496 iter num 160\n",
            "loss 0.15332947671413422 average time 0.004237728322247373 iter num 180\n",
            "loss 0.6857472658157349 average time 0.0040664623100383325 iter num 200\n",
            "loss 0.5245314836502075 average time 0.003924256718230688 iter num 220\n",
            "loss 0.2517021596431732 average time 0.0038081575625407518 iter num 240\n",
            "loss 0.32460543513298035 average time 0.0037088498461693795 iter num 260\n",
            "loss 0.3387190103530884 average time 0.00362240763572897 iter num 280\n",
            "loss 0.18113449215888977 average time 0.0035486556699955447 iter num 300\n",
            "loss 0.3705959916114807 average time 0.0034846964968664905 iter num 320\n",
            "loss 0.1258179396390915 average time 0.003428272088250892 iter num 340\n",
            "loss 0.1096903532743454 average time 0.0033748452666461366 iter num 360\n",
            "loss 0.23653821647167206 average time 0.0033284291394777123 iter num 380\n",
            "loss 0.17476895451545715 average time 0.0032993516100123087 iter num 400\n",
            "loss 0.07761003077030182 average time 0.003265502940493683 iter num 420\n",
            "loss 0.19689467549324036 average time 0.003236016743217492 iter num 440\n",
            "loss 0.18466125428676605 average time 0.003232254923940396 iter num 460\n",
            "loss 0.40302756428718567 average time 0.0032170253333864214 iter num 480\n",
            "loss 0.7768470048904419 average time 0.0032013519160755096 iter num 500\n",
            "loss 0.2650286853313446 average time 0.0031875140635258085 iter num 520\n",
            "loss 0.26002106070518494 average time 0.0031742499056202143 iter num 540\n",
            "loss 0.19493672251701355 average time 0.0031620679339864313 iter num 560\n",
            "loss 0.2165878415107727 average time 0.00314861251384894 iter num 580\n",
            "loss 0.06706304103136063 average time 0.003138937246712885 iter num 600\n",
            "loss 0.1748935729265213 average time 0.003125461661341345 iter num 620\n",
            "loss 0.23941513895988464 average time 0.0031091628844251316 iter num 640\n",
            "loss 0.15031956136226654 average time 0.00309611662278533 iter num 660\n",
            "loss 0.25042110681533813 average time 0.00308062512505036 iter num 680\n",
            "loss 0.05436420440673828 average time 0.003067659345771452 iter num 700\n",
            "loss 0.17237544059753418 average time 0.0030577824875611744 iter num 720\n",
            "loss 0.19006472826004028 average time 0.0030437108879079852 iter num 740\n",
            "loss 0.16497115790843964 average time 0.003035768392165712 iter num 760\n",
            "loss 0.38804423809051514 average time 0.003024627674406078 iter num 780\n",
            "loss 0.040847498923540115 average time 0.0030129557000373097 iter num 800\n",
            "loss 0.09297136962413788 average time 0.0030028748305151723 iter num 820\n",
            "loss 0.16760621964931488 average time 0.002992332671450034 iter num 840\n",
            "loss 0.09979492425918579 average time 0.0029826507849023518 iter num 860\n",
            "loss 0.16084100306034088 average time 0.0029731373750192607 iter num 880\n",
            "loss 0.18752415478229523 average time 0.002965354214457976 iter num 900\n",
            "loss 0.7944380044937134 average time 0.00295943691850445 iter num 920\n",
            "loss 0.10744725167751312 average time 0.00295137638619595 iter num 940\n",
            "loss 0.14506204426288605 average time 0.0029460463062681206 iter num 960\n",
            "loss 0.16757437586784363 average time 0.0029391860571603484 iter num 980\n",
            "loss 0.1655532717704773 average time 0.002932632870019006 iter num 1000\n",
            "loss 0.5189776420593262 average time 0.018223123850111732 iter num 20\n",
            "loss 0.46892523765563965 average time 0.010455199775060464 iter num 40\n",
            "loss 0.6625169515609741 average time 0.007900009600173992 iter num 60\n",
            "loss 0.06786675751209259 average time 0.0065883093126558375 iter num 80\n",
            "loss 0.18834003806114197 average time 0.005794111610193795 iter num 100\n",
            "loss 0.4680413007736206 average time 0.0052586147750541086 iter num 120\n",
            "loss 0.13816294074058533 average time 0.004883859671567084 iter num 140\n",
            "loss 0.3290843367576599 average time 0.0045915652314079125 iter num 160\n",
            "loss 0.4000345766544342 average time 0.00437582080012362 iter num 180\n",
            "loss 0.28152868151664734 average time 0.004210352060163132 iter num 200\n",
            "loss 0.28800562024116516 average time 0.0040823770728986184 iter num 220\n",
            "loss 0.30920809507369995 average time 0.003961124637650452 iter num 240\n",
            "loss 0.30413153767585754 average time 0.0038523508040060944 iter num 260\n",
            "loss 0.13355447351932526 average time 0.003765748639463189 iter num 280\n",
            "loss 0.44003063440322876 average time 0.0036863440634988366 iter num 300\n",
            "loss 0.2140660583972931 average time 0.0036144993845482532 iter num 320\n",
            "loss 0.15136688947677612 average time 0.0035537377325133147 iter num 340\n",
            "loss 0.32141414284706116 average time 0.0035070038140272825 iter num 360\n",
            "loss 0.7249025106430054 average time 0.0034700503685311753 iter num 380\n",
            "loss 0.11976853758096695 average time 0.003428132850094698 iter num 400\n",
            "loss 0.2511940002441406 average time 0.003389361990550588 iter num 420\n",
            "loss 0.40280550718307495 average time 0.003355014609165995 iter num 440\n",
            "loss 0.38251447677612305 average time 0.003323318154418856 iter num 460\n",
            "loss 0.5296194553375244 average time 0.003292811010457323 iter num 480\n",
            "loss 0.1590367555618286 average time 0.0032632258420198924 iter num 500\n",
            "loss 0.26320767402648926 average time 0.0032359257904108047 iter num 520\n",
            "loss 0.3548673391342163 average time 0.003212902737060277 iter num 540\n",
            "loss 0.25963079929351807 average time 0.0031914748161073346 iter num 560\n",
            "loss 0.10519500076770782 average time 0.003173192400026892 iter num 580\n",
            "loss 0.1118946373462677 average time 0.0031540100683560015 iter num 600\n",
            "loss 0.224687859416008 average time 0.0031351256613033323 iter num 620\n",
            "loss 0.09947245568037033 average time 0.003118772673434478 iter num 640\n",
            "loss 0.1763647198677063 average time 0.0031021214515269753 iter num 660\n",
            "loss 0.12029963731765747 average time 0.0030882531147065437 iter num 680\n",
            "loss 0.24748444557189941 average time 0.003073906701424026 iter num 700\n",
            "loss 0.18195702135562897 average time 0.003060453009715679 iter num 720\n",
            "loss 0.2561004161834717 average time 0.003048049998643684 iter num 740\n",
            "loss 0.22555744647979736 average time 0.003037860872355898 iter num 760\n",
            "loss 0.10097163170576096 average time 0.0030320338551087516 iter num 780\n",
            "loss 0.24876835942268372 average time 0.0030247332799717697 iter num 800\n",
            "loss 0.10252004116773605 average time 0.0030155545853365147 iter num 820\n",
            "loss 0.05053691193461418 average time 0.003005391446402514 iter num 840\n",
            "loss 0.17901648581027985 average time 0.0029971184569572065 iter num 860\n",
            "loss 0.13177156448364258 average time 0.0029883229806645516 iter num 880\n",
            "loss 0.24826276302337646 average time 0.0029818619355299033 iter num 900\n",
            "loss 0.07522661983966827 average time 0.002972726549978688 iter num 920\n",
            "loss 0.0809907615184784 average time 0.002964547143590685 iter num 940\n",
            "loss 0.17998799681663513 average time 0.002959674555180906 iter num 960\n",
            "loss 0.09873083233833313 average time 0.002959683161193703 iter num 980\n",
            "loss 0.21362167596817017 average time 0.002954960372968344 iter num 1000\n",
            "loss 1.1200883388519287 average time 0.018264456200449787 iter num 20\n",
            "loss 1.1563841104507446 average time 0.010429995775484712 iter num 40\n",
            "loss 0.5952427387237549 average time 0.00781663678365779 iter num 60\n",
            "loss 0.4721512794494629 average time 0.006562570025153036 iter num 80\n",
            "loss 0.38412994146347046 average time 0.005766731760195399 iter num 100\n",
            "loss 0.2989056706428528 average time 0.005238241300079002 iter num 120\n",
            "loss 1.1999115943908691 average time 0.0048578217857669055 iter num 140\n",
            "loss 0.5121538043022156 average time 0.004576469187554721 iter num 160\n",
            "loss 1.1555588245391846 average time 0.004353939361236472 iter num 180\n",
            "loss 0.416184663772583 average time 0.0041777605651259365 iter num 200\n",
            "loss 0.1446429193019867 average time 0.004040749850090916 iter num 220\n",
            "loss 0.27455490827560425 average time 0.003932875062582752 iter num 240\n",
            "loss 0.2332770824432373 average time 0.003830157923179146 iter num 260\n",
            "loss 0.0899135172367096 average time 0.003738418050124892 iter num 280\n",
            "loss 0.07680854946374893 average time 0.0036632843967648416 iter num 300\n",
            "loss 0.4172830581665039 average time 0.0036029013250981736 iter num 320\n",
            "loss 0.3216511011123657 average time 0.0035480005207051257 iter num 340\n",
            "loss 0.09297852218151093 average time 0.0034957810334364896 iter num 360\n",
            "loss 0.27565479278564453 average time 0.0034529508422182467 iter num 380\n",
            "loss 0.2556808292865753 average time 0.0034129277251213354 iter num 400\n",
            "loss 0.12640973925590515 average time 0.003376973790580537 iter num 420\n",
            "loss 0.31519508361816406 average time 0.0033425911432707588 iter num 440\n",
            "loss 0.17911240458488464 average time 0.00331091791966806 iter num 460\n",
            "loss 0.13613595068454742 average time 0.0032815248376058055 iter num 480\n",
            "loss 0.1360761523246765 average time 0.003256884172093123 iter num 500\n",
            "loss 0.09675764292478561 average time 0.0032372575904796226 iter num 520\n",
            "loss 0.15778325498104095 average time 0.003225987811182912 iter num 540\n",
            "loss 0.48057353496551514 average time 0.003208439117913388 iter num 560\n",
            "loss 0.24300424754619598 average time 0.003191825300049898 iter num 580\n",
            "loss 0.4133957028388977 average time 0.0031738686433891417 iter num 600\n",
            "loss 0.13170906901359558 average time 0.0031604770226382945 iter num 620\n",
            "loss 0.12814611196517944 average time 0.003143173048499648 iter num 640\n",
            "loss 0.18040359020233154 average time 0.0031304971152084447 iter num 660\n",
            "loss 0.4722878634929657 average time 0.0031142126206385214 iter num 680\n",
            "loss 0.2341199368238449 average time 0.0030996267057551968 iter num 700\n",
            "loss 0.16952146589756012 average time 0.0030928231361334233 iter num 720\n",
            "loss 0.10692814737558365 average time 0.0030788360297388075 iter num 740\n",
            "loss 0.08982633054256439 average time 0.0030661684552701204 iter num 760\n",
            "loss 0.06116950139403343 average time 0.0030552232218048095 iter num 780\n",
            "loss 0.219429612159729 average time 0.0030444625625204937 iter num 800\n",
            "loss 0.2229006290435791 average time 0.003033843443926144 iter num 820\n",
            "loss 0.10157398879528046 average time 0.0030240187738291707 iter num 840\n",
            "loss 0.153498113155365 average time 0.003013721731410844 iter num 860\n",
            "loss 0.1955108493566513 average time 0.0030040469181999057 iter num 880\n",
            "loss 0.12297665327787399 average time 0.0029971482333429676 iter num 900\n",
            "loss 0.07349242269992828 average time 0.002991278509793831 iter num 920\n",
            "loss 0.21043041348457336 average time 0.0029848629468185034 iter num 940\n",
            "loss 0.11596575379371643 average time 0.002976776767722337 iter num 960\n",
            "loss 0.1720043122768402 average time 0.0029708507194151695 iter num 980\n",
            "loss 0.12109306454658508 average time 0.002963512387024821 iter num 1000\n",
            "loss 0.23063614964485168 average time 0.01857066845004738 iter num 20\n",
            "loss 0.6474823355674744 average time 0.01059069727498354 iter num 40\n",
            "loss 0.3770149052143097 average time 0.007908118650023728 iter num 60\n",
            "loss 0.28822535276412964 average time 0.006575861987357712 iter num 80\n",
            "loss 0.4924316704273224 average time 0.005773843259885325 iter num 100\n",
            "loss 0.40465930104255676 average time 0.005244081916498544 iter num 120\n",
            "loss 0.45445749163627625 average time 0.00486027910701523 iter num 140\n",
            "loss 0.6462929248809814 average time 0.004578510668557101 iter num 160\n",
            "loss 0.5158300995826721 average time 0.004356657783157263 iter num 180\n",
            "loss 0.5478155612945557 average time 0.004181011599757767 iter num 200\n",
            "loss 0.24478264153003693 average time 0.00403714520428118 iter num 220\n",
            "loss 0.6653441786766052 average time 0.003928311483059587 iter num 240\n",
            "loss 0.14047491550445557 average time 0.0038312508151368374 iter num 260\n",
            "loss 0.40847349166870117 average time 0.0037450363711806337 iter num 280\n",
            "loss 0.4352495074272156 average time 0.0036687033964820635 iter num 300\n",
            "loss 0.3273780345916748 average time 0.0036036227123531716 iter num 320\n",
            "loss 0.13873779773712158 average time 0.0035443423204389334 iter num 340\n",
            "loss 0.14507657289505005 average time 0.003493670702624109 iter num 360\n",
            "loss 0.14741607010364532 average time 0.0034484809630253277 iter num 380\n",
            "loss 0.08788254857063293 average time 0.003412694664866649 iter num 400\n",
            "loss 0.03437483683228493 average time 0.0033739928832108575 iter num 420\n",
            "loss 0.28112292289733887 average time 0.0033463681043940595 iter num 440\n",
            "loss 0.18122759461402893 average time 0.0033279913585394514 iter num 460\n",
            "loss 0.15037310123443604 average time 0.003303285447767242 iter num 480\n",
            "loss 0.2896348536014557 average time 0.0032769252418438557 iter num 500\n",
            "loss 0.19605226814746857 average time 0.003251003992157236 iter num 520\n",
            "loss 0.13245318830013275 average time 0.003224002627649935 iter num 540\n",
            "loss 0.5322713255882263 average time 0.003202365294516442 iter num 560\n",
            "loss 0.14239022135734558 average time 0.0031824700533277417 iter num 580\n",
            "loss 0.25782787799835205 average time 0.0031633474765355154 iter num 600\n",
            "loss 0.204237163066864 average time 0.0031446233369581845 iter num 620\n",
            "loss 0.1329960823059082 average time 0.0031275442436083266 iter num 640\n",
            "loss 0.32718348503112793 average time 0.0031111771362371987 iter num 660\n",
            "loss 0.10119354724884033 average time 0.0030964583513409974 iter num 680\n",
            "loss 0.14018581807613373 average time 0.0030822985684374415 iter num 700\n",
            "loss 0.14812211692333221 average time 0.0030689627165277973 iter num 720\n",
            "loss 0.24311691522598267 average time 0.0030575079039015297 iter num 740\n",
            "loss 0.1628236621618271 average time 0.0030485103722209094 iter num 760\n",
            "loss 0.37680506706237793 average time 0.0030403257216349653 iter num 780\n",
            "loss 0.03900262713432312 average time 0.003029346576095122 iter num 800\n",
            "loss 0.043144505470991135 average time 0.003019055962054486 iter num 820\n",
            "loss 0.05972902476787567 average time 0.0030093739332057467 iter num 840\n",
            "loss 0.146528422832489 average time 0.0030011308591743136 iter num 860\n",
            "loss 0.13784722983837128 average time 0.0029923642941908344 iter num 880\n",
            "loss 0.1008768156170845 average time 0.002983769942091183 iter num 900\n",
            "loss 0.18856367468833923 average time 0.002974902402045542 iter num 920\n",
            "loss 0.13302098214626312 average time 0.002966226993494468 iter num 940\n",
            "loss 0.12094472348690033 average time 0.0029596035352975982 iter num 960\n",
            "loss 0.1252710521221161 average time 0.0029524103570278087 iter num 980\n",
            "loss 0.0502125546336174 average time 0.0029472793918903337 iter num 1000\n",
            "loss 0.42390453815460205 average time 0.01838571240023157 iter num 20\n",
            "loss 0.392586886882782 average time 0.010531697425449238 iter num 40\n",
            "loss 0.37571823596954346 average time 0.007891005750207115 iter num 60\n",
            "loss 1.1046931743621826 average time 0.006581120150258357 iter num 80\n",
            "loss 1.0216047763824463 average time 0.0057838333702238745 iter num 100\n",
            "loss 0.40171951055526733 average time 0.005256501750075889 iter num 120\n",
            "loss 0.6302207708358765 average time 0.00488077795000988 iter num 140\n",
            "loss 0.62530118227005 average time 0.004597214643786174 iter num 160\n",
            "loss 0.1602722853422165 average time 0.004403731100016254 iter num 180\n",
            "loss 0.3551275134086609 average time 0.004220810674942186 iter num 200\n",
            "loss 0.5122286677360535 average time 0.004072227599912863 iter num 220\n",
            "loss 0.4171926975250244 average time 0.003947756591514917 iter num 240\n",
            "loss 0.31643617153167725 average time 0.0038433884306589157 iter num 260\n",
            "loss 0.5592047572135925 average time 0.003757800960595757 iter num 280\n",
            "loss 0.17821280658245087 average time 0.003694318366566828 iter num 300\n",
            "loss 0.406603068113327 average time 0.003630012196788357 iter num 320\n",
            "loss 0.08494983613491058 average time 0.0035685803558140727 iter num 340\n",
            "loss 0.25522899627685547 average time 0.00351693382490339 iter num 360\n",
            "loss 0.12297900021076202 average time 0.003479887531485522 iter num 380\n",
            "loss 0.19179482758045197 average time 0.003434520244900341 iter num 400\n",
            "loss 0.3209322988986969 average time 0.0033947184760888508 iter num 420\n",
            "loss 0.22827978432178497 average time 0.0033585904817383296 iter num 440\n",
            "loss 0.411048948764801 average time 0.0033258863825366184 iter num 460\n",
            "loss 0.16852548718452454 average time 0.003295505212433151 iter num 480\n",
            "loss 0.15004445612430573 average time 0.003277791445943876 iter num 500\n",
            "loss 0.21496276557445526 average time 0.003253376155722575 iter num 520\n",
            "loss 0.19197335839271545 average time 0.0032398631092291907 iter num 540\n",
            "loss 0.3344879746437073 average time 0.0032161789714077065 iter num 560\n",
            "loss 0.2885398864746094 average time 0.0031963051223948273 iter num 580\n",
            "loss 0.19539129734039307 average time 0.0031786110049930962 iter num 600\n",
            "loss 0.15132194757461548 average time 0.003160586770959086 iter num 620\n",
            "loss 0.16951587796211243 average time 0.0031446385343883777 iter num 640\n",
            "loss 0.4008975625038147 average time 0.0031410735636282798 iter num 660\n",
            "loss 0.1572660654783249 average time 0.0031237662250051096 iter num 680\n",
            "loss 0.5627087354660034 average time 0.003110229451439019 iter num 700\n",
            "loss 0.14596810936927795 average time 0.0030950083402886876 iter num 720\n",
            "loss 0.12769080698490143 average time 0.003084282117585669 iter num 740\n",
            "loss 0.2485390305519104 average time 0.0030720883908112516 iter num 760\n",
            "loss 0.11897999048233032 average time 0.003059270248741086 iter num 780\n",
            "loss 0.03501524776220322 average time 0.003047752625029716 iter num 800\n",
            "loss 0.3415253758430481 average time 0.003038563895150707 iter num 820\n",
            "loss 0.22059407830238342 average time 0.003030192619085678 iter num 840\n",
            "loss 0.12513276934623718 average time 0.003021003326775403 iter num 860\n",
            "loss 0.0761919766664505 average time 0.0030108248397937134 iter num 880\n",
            "loss 0.2352304756641388 average time 0.0030011942100261675 iter num 900\n",
            "loss 0.1377895623445511 average time 0.0029921848315493465 iter num 920\n",
            "loss 0.05248181149363518 average time 0.002982914595784368 iter num 940\n",
            "loss 0.034649066627025604 average time 0.002974569292750099 iter num 960\n",
            "loss 0.11038368940353394 average time 0.002965997304120404 iter num 980\n",
            "loss 0.06749846041202545 average time 0.002959138744048687 iter num 1000\n",
            "loss 0.25293904542922974 average time 0.01855928525037598 iter num 20\n",
            "loss 0.1231987476348877 average time 0.010581233100037935 iter num 40\n",
            "loss 0.3816569447517395 average time 0.007941673016830464 iter num 60\n",
            "loss 0.5265079140663147 average time 0.006601455450072536 iter num 80\n",
            "loss 0.19830244779586792 average time 0.005815170719979505 iter num 100\n",
            "loss 0.37351304292678833 average time 0.005277802991683226 iter num 120\n",
            "loss 0.14262047410011292 average time 0.004892150399999602 iter num 140\n",
            "loss 0.2983587384223938 average time 0.004606337531254212 iter num 160\n",
            "loss 0.165236696600914 average time 0.004383262499949423 iter num 180\n",
            "loss 0.2799195647239685 average time 0.004201042654894991 iter num 200\n",
            "loss 0.19401994347572327 average time 0.004071967418117724 iter num 220\n",
            "loss 0.37289583683013916 average time 0.003966572983260145 iter num 240\n",
            "loss 0.08644723147153854 average time 0.0038625066691635695 iter num 260\n",
            "loss 0.3142475485801697 average time 0.0037703292677828616 iter num 280\n",
            "loss 0.497802197933197 average time 0.003691363616611246 iter num 300\n",
            "loss 0.1588006615638733 average time 0.003623615881213027 iter num 320\n",
            "loss 0.038906924426555634 average time 0.0035641196940773895 iter num 340\n",
            "loss 0.15537312626838684 average time 0.003509914616632967 iter num 360\n",
            "loss 0.18296410143375397 average time 0.003464123039444339 iter num 380\n",
            "loss 0.15133917331695557 average time 0.0034184797974558022 iter num 400\n",
            "loss 0.047594692558050156 average time 0.003380719242826065 iter num 420\n",
            "loss 0.1399841159582138 average time 0.00334491587951065 iter num 440\n",
            "loss 0.0634535551071167 average time 0.0033120554934493673 iter num 460\n",
            "loss 0.1354215294122696 average time 0.0032813305978910043 iter num 480\n",
            "loss 0.12907862663269043 average time 0.003252511827966373 iter num 500\n",
            "loss 0.3988966941833496 average time 0.003232222578823824 iter num 520\n",
            "loss 0.19288697838783264 average time 0.0032116519129313354 iter num 540\n",
            "loss 0.22166696190834045 average time 0.0031881173320990846 iter num 560\n",
            "loss 0.3870673179626465 average time 0.0031707630223661845 iter num 580\n",
            "loss 0.21095502376556396 average time 0.0031567400399459683 iter num 600\n",
            "loss 0.15400047600269318 average time 0.0031461640773716593 iter num 620\n",
            "loss 0.1969396471977234 average time 0.003130446610884974 iter num 640\n",
            "loss 0.14139804244041443 average time 0.0031131782423637396 iter num 660\n",
            "loss 0.2591843605041504 average time 0.003099864899949727 iter num 680\n",
            "loss 0.0903279185295105 average time 0.0030865749770964614 iter num 700\n",
            "loss 0.13849657773971558 average time 0.0030722068888432356 iter num 720\n",
            "loss 0.19071196019649506 average time 0.0030583560012953084 iter num 740\n",
            "loss 0.20785346627235413 average time 0.003046823377587172 iter num 760\n",
            "loss 0.0735018327832222 average time 0.0030343368114933047 iter num 780\n",
            "loss 0.17667746543884277 average time 0.003023426852460034 iter num 800\n",
            "loss 0.17080281674861908 average time 0.003012819162159292 iter num 820\n",
            "loss 0.06843366473913193 average time 0.00300334272139177 iter num 840\n",
            "loss 0.14764899015426636 average time 0.0029937269371784654 iter num 860\n",
            "loss 0.17324653267860413 average time 0.002984742388596053 iter num 880\n",
            "loss 0.13718630373477936 average time 0.002979079826626629 iter num 900\n",
            "loss 0.15318061411380768 average time 0.0029709628075658616 iter num 920\n",
            "loss 0.2875094413757324 average time 0.00296287861589743 iter num 940\n",
            "loss 0.32335299253463745 average time 0.0029547515270299603 iter num 960\n",
            "loss 0.22792215645313263 average time 0.0029472655856584516 iter num 980\n",
            "loss 0.065420001745224 average time 0.00294252609794421 iter num 1000\n",
            "loss 0.33180928230285645 average time 0.018507389949991192 iter num 20\n",
            "loss 0.7309430837631226 average time 0.010536858374962321 iter num 40\n",
            "loss 0.23257754743099213 average time 0.00787987681657493 iter num 60\n",
            "loss 0.6044473648071289 average time 0.006561528675001682 iter num 80\n",
            "loss 0.8611280918121338 average time 0.005761751649952202 iter num 100\n",
            "loss 0.3733484447002411 average time 0.005240954899970045 iter num 120\n",
            "loss 0.42818599939346313 average time 0.004867678807048443 iter num 140\n",
            "loss 0.30084335803985596 average time 0.004575271774911016 iter num 160\n",
            "loss 0.31498655676841736 average time 0.00435372488888485 iter num 180\n",
            "loss 0.34845075011253357 average time 0.004189529305058386 iter num 200\n",
            "loss 0.21901825070381165 average time 0.004100823259151102 iter num 220\n",
            "loss 0.2328718602657318 average time 0.003977513191694015 iter num 240\n",
            "loss 0.8234477043151855 average time 0.0038718872307911692 iter num 260\n",
            "loss 0.24325060844421387 average time 0.0037863565643160004 iter num 280\n",
            "loss 0.10152734071016312 average time 0.0037054416100484864 iter num 300\n",
            "loss 0.20758303999900818 average time 0.003636464575095033 iter num 320\n",
            "loss 0.2428474724292755 average time 0.0035759760530388175 iter num 340\n",
            "loss 0.5382595062255859 average time 0.0035245958334295816 iter num 360\n",
            "loss 0.15963605046272278 average time 0.0034772024684954026 iter num 380\n",
            "loss 0.1725635528564453 average time 0.0034330424400650372 iter num 400\n",
            "loss 0.12518984079360962 average time 0.0033931704286390284 iter num 420\n",
            "loss 0.34410378336906433 average time 0.0033585740909571047 iter num 440\n",
            "loss 0.5372146368026733 average time 0.0033267368652678156 iter num 460\n",
            "loss 0.5587409138679504 average time 0.0032996820500405494 iter num 480\n",
            "loss 0.5210393667221069 average time 0.0032699656880504336 iter num 500\n",
            "loss 0.41807839274406433 average time 0.003241175390415335 iter num 520\n",
            "loss 0.12624356150627136 average time 0.00321548098891745 iter num 540\n",
            "loss 0.08184093236923218 average time 0.003191412839305485 iter num 560\n",
            "loss 0.2519965171813965 average time 0.0031742124810424967 iter num 580\n",
            "loss 0.23076781630516052 average time 0.0031544546833356434 iter num 600\n",
            "loss 0.2976919710636139 average time 0.003135034390323844 iter num 620\n",
            "loss 0.07370012998580933 average time 0.0031307573125161524 iter num 640\n",
            "loss 0.42856770753860474 average time 0.0031207783121455137 iter num 660\n",
            "loss 0.21546053886413574 average time 0.003111685023550843 iter num 680\n",
            "loss 0.269596129655838 average time 0.003104766955735353 iter num 700\n",
            "loss 0.20233312249183655 average time 0.003097361527807152 iter num 720\n",
            "loss 0.32407906651496887 average time 0.003090275750037108 iter num 740\n",
            "loss 0.25541600584983826 average time 0.003083208522404771 iter num 760\n",
            "loss 0.22288891673088074 average time 0.00307385416030089 iter num 780\n",
            "loss 0.1367747187614441 average time 0.0030619218588071816 iter num 800\n",
            "loss 0.2566576302051544 average time 0.0030518485098094436 iter num 820\n",
            "loss 0.09715905785560608 average time 0.003042514931010893 iter num 840\n",
            "loss 0.16243614256381989 average time 0.003032932740753431 iter num 860\n",
            "loss 0.07840757817029953 average time 0.003024589304612329 iter num 880\n",
            "loss 0.11345037817955017 average time 0.0030143577422980647 iter num 900\n",
            "loss 0.08875066787004471 average time 0.0030043837544207748 iter num 920\n",
            "loss 0.13602983951568604 average time 0.0029952614266686066 iter num 940\n",
            "loss 0.2455889880657196 average time 0.0029878239886102164 iter num 960\n",
            "loss 0.16208693385124207 average time 0.002980259442921699 iter num 980\n",
            "loss 0.24974563717842102 average time 0.002973601453057199 iter num 1000\n",
            "loss 0.08172570914030075 average time 0.018396412050060464 iter num 20\n",
            "loss 0.32939064502716064 average time 0.010501597174879862 iter num 40\n",
            "loss 0.0700620487332344 average time 0.007897948266509048 iter num 60\n",
            "loss 1.6633944511413574 average time 0.006622176137443603 iter num 80\n",
            "loss 0.3067324161529541 average time 0.005813379570063262 iter num 100\n",
            "loss 0.16766715049743652 average time 0.005276050950033096 iter num 120\n",
            "loss 0.2596611976623535 average time 0.004896756328551939 iter num 140\n",
            "loss 1.0162360668182373 average time 0.004619719462493776 iter num 160\n",
            "loss 0.20273935794830322 average time 0.004393335777806189 iter num 180\n",
            "loss 0.19112607836723328 average time 0.004213003395016131 iter num 200\n",
            "loss 0.4208267331123352 average time 0.0040666873090892544 iter num 220\n",
            "loss 0.2529965937137604 average time 0.00395144414163345 iter num 240\n",
            "loss 0.16809886693954468 average time 0.003845186123026696 iter num 260\n",
            "loss 0.14673712849617004 average time 0.003753035421362126 iter num 280\n",
            "loss 0.4053425192832947 average time 0.003676930083274783 iter num 300\n",
            "loss 0.4258163273334503 average time 0.003610111815578421 iter num 320\n",
            "loss 0.1460569053888321 average time 0.0035517571293466436 iter num 340\n",
            "loss 0.06749968230724335 average time 0.0035013214999505887 iter num 360\n",
            "loss 0.284354567527771 average time 0.0034575171920407325 iter num 380\n",
            "loss 0.1519089639186859 average time 0.0034153888574655865 iter num 400\n",
            "loss 0.4344671964645386 average time 0.003376704857102942 iter num 420\n",
            "loss 0.16173353791236877 average time 0.0033406204226511444 iter num 440\n",
            "loss 0.1826900839805603 average time 0.003308115089068609 iter num 460\n",
            "loss 0.47982245683670044 average time 0.003280912287436877 iter num 480\n",
            "loss 0.29292169213294983 average time 0.003252614207944134 iter num 500\n",
            "loss 0.272718220949173 average time 0.0032295783653563167 iter num 520\n",
            "loss 0.25827574729919434 average time 0.003206001625895388 iter num 540\n",
            "loss 0.05563735216856003 average time 0.003183912533865753 iter num 560\n",
            "loss 0.1561703234910965 average time 0.0031628616482051036 iter num 580\n",
            "loss 0.17700156569480896 average time 0.003143886601610575 iter num 600\n",
            "loss 0.23922882974147797 average time 0.0031263615370276496 iter num 620\n",
            "loss 0.10321144759654999 average time 0.0031094586686720048 iter num 640\n",
            "loss 0.2529677748680115 average time 0.003101601049914307 iter num 660\n",
            "loss 0.2967972755432129 average time 0.003090408392558054 iter num 680\n",
            "loss 0.14050664007663727 average time 0.003075514577051633 iter num 700\n",
            "loss 0.04623693227767944 average time 0.0030630246207490725 iter num 720\n",
            "loss 0.08228404819965363 average time 0.003051008198560118 iter num 740\n",
            "loss 0.2168809473514557 average time 0.003038743110449248 iter num 760\n",
            "loss 0.18900492787361145 average time 0.0030267134806938253 iter num 780\n",
            "loss 0.20767877995967865 average time 0.003016269156173621 iter num 800\n",
            "loss 0.16821855306625366 average time 0.0030054481389636682 iter num 820\n",
            "loss 0.05015964061021805 average time 0.0029949799618450576 iter num 840\n",
            "loss 0.1673787534236908 average time 0.002986599851101346 iter num 860\n",
            "loss 0.14899155497550964 average time 0.002979682659022067 iter num 880\n",
            "loss 0.04590381309390068 average time 0.0029717250588227116 iter num 900\n",
            "loss 0.06079736351966858 average time 0.0029705350814607377 iter num 920\n",
            "loss 0.1693645566701889 average time 0.0029620732701508305 iter num 940\n",
            "loss 0.4556889832019806 average time 0.0029540248592979878 iter num 960\n",
            "loss 0.13243138790130615 average time 0.0029461359744141656 iter num 980\n",
            "loss 0.08186656981706619 average time 0.002940787373914645 iter num 1000\n",
            "loss 0.1777036190032959 average time 0.018289280299723033 iter num 20\n",
            "loss 0.3374673128128052 average time 0.010436846699394663 iter num 40\n",
            "loss 0.18940991163253784 average time 0.007808979033082627 iter num 60\n",
            "loss 0.20906779170036316 average time 0.006502450137259075 iter num 80\n",
            "loss 0.21847139298915863 average time 0.005755087399775221 iter num 100\n",
            "loss 1.1967408657073975 average time 0.005227929899804925 iter num 120\n",
            "loss 0.3365762233734131 average time 0.004848644464073004 iter num 140\n",
            "loss 0.38602545857429504 average time 0.004566134062315541 iter num 160\n",
            "loss 0.32312726974487305 average time 0.004353972860937776 iter num 180\n",
            "loss 0.49632006883621216 average time 0.004180875449801533 iter num 200\n",
            "loss 0.07800720632076263 average time 0.004036470308876067 iter num 220\n",
            "loss 0.4423125982284546 average time 0.003923684191492308 iter num 240\n",
            "loss 0.6029489040374756 average time 0.00381788954210396 iter num 260\n",
            "loss 0.19183167815208435 average time 0.003728269921196313 iter num 280\n",
            "loss 0.3058749735355377 average time 0.003658271506416592 iter num 300\n",
            "loss 0.09708696603775024 average time 0.0035910632841591903 iter num 320\n",
            "loss 0.34529823064804077 average time 0.003535369976217386 iter num 340\n",
            "loss 0.2004142850637436 average time 0.003483507463675374 iter num 360\n",
            "loss 0.368408739566803 average time 0.003438985155059383 iter num 380\n",
            "loss 0.3079814314842224 average time 0.003398601559792951 iter num 400\n",
            "loss 0.16000071167945862 average time 0.0033607008926645945 iter num 420\n",
            "loss 0.11383112519979477 average time 0.0033296752589194512 iter num 440\n",
            "loss 0.24026542901992798 average time 0.003307390067200923 iter num 460\n",
            "loss 0.1874837726354599 average time 0.0032841306873251596 iter num 480\n",
            "loss 0.12790793180465698 average time 0.003263795995822875 iter num 500\n",
            "loss 0.42770466208457947 average time 0.0032448721825158616 iter num 520\n",
            "loss 0.193356454372406 average time 0.0032259816202120555 iter num 540\n",
            "loss 0.08350760489702225 average time 0.0032084232034126866 iter num 560\n",
            "loss 0.296541690826416 average time 0.0031963621653693704 iter num 580\n",
            "loss 0.14210838079452515 average time 0.003180213056524129 iter num 600\n",
            "loss 0.18335846066474915 average time 0.0031664892804920165 iter num 620\n",
            "loss 0.048021137714385986 average time 0.0031534015310853646 iter num 640\n",
            "loss 0.3366188406944275 average time 0.003142396374085255 iter num 660\n",
            "loss 0.2836754322052002 average time 0.003135667377789693 iter num 680\n",
            "loss 0.1260600984096527 average time 0.003125378752733273 iter num 700\n",
            "loss 0.39193981885910034 average time 0.0031156330234959266 iter num 720\n",
            "loss 0.0976635068655014 average time 0.0031047265161071886 iter num 740\n",
            "loss 0.15463662147521973 average time 0.0030950795406888094 iter num 760\n",
            "loss 0.1669468879699707 average time 0.0030833918101658736 iter num 780\n",
            "loss 0.07147718220949173 average time 0.0030722115011576536 iter num 800\n",
            "loss 0.5293112993240356 average time 0.0030640721864939424 iter num 820\n",
            "loss 0.08939693868160248 average time 0.0030522902046738764 iter num 840\n",
            "loss 0.15926919877529144 average time 0.0030439233034062346 iter num 860\n",
            "loss 0.28959113359451294 average time 0.003033885544250965 iter num 880\n",
            "loss 0.10138634592294693 average time 0.003027236103270196 iter num 900\n",
            "loss 0.10462522506713867 average time 0.0030185433901470274 iter num 920\n",
            "loss 0.20779797434806824 average time 0.0030099241446108903 iter num 940\n",
            "loss 0.11608336865901947 average time 0.003003945123881143 iter num 960\n",
            "loss 0.17034968733787537 average time 0.0030004864438004527 iter num 980\n",
            "loss 0.09485279023647308 average time 0.002996791631925589 iter num 1000\n",
            "loss 0.22860071063041687 average time 0.018660729700241064 iter num 20\n",
            "loss 0.3256951570510864 average time 0.010754126975461986 iter num 40\n",
            "loss 0.5347676277160645 average time 0.00811147301701567 iter num 60\n",
            "loss 0.15161564946174622 average time 0.00677776622537749 iter num 80\n",
            "loss 0.8183998465538025 average time 0.005972313530364772 iter num 100\n",
            "loss 0.36124730110168457 average time 0.005441393000304136 iter num 120\n",
            "loss 0.2607487440109253 average time 0.005058120536003636 iter num 140\n",
            "loss 1.179570198059082 average time 0.004780742494040169 iter num 160\n",
            "loss 0.33973032236099243 average time 0.00455747591695399 iter num 180\n",
            "loss 0.38897639513015747 average time 0.004378960165267926 iter num 200\n",
            "loss 0.2603859305381775 average time 0.004236279445715561 iter num 220\n",
            "loss 0.4493103623390198 average time 0.004115966429405186 iter num 240\n",
            "loss 0.10581134259700775 average time 0.004013119046360841 iter num 260\n",
            "loss 0.15924511849880219 average time 0.00392886751090243 iter num 280\n",
            "loss 0.3427647650241852 average time 0.003852226603497305 iter num 300\n",
            "loss 0.5459474325180054 average time 0.003794265422038734 iter num 320\n",
            "loss 0.15216489136219025 average time 0.0037450098119199324 iter num 340\n",
            "loss 0.16486161947250366 average time 0.0036938326889968368 iter num 360\n",
            "loss 0.12915635108947754 average time 0.0036460758763975096 iter num 380\n",
            "loss 0.36881953477859497 average time 0.0036184806800611115 iter num 400\n",
            "loss 0.12767398357391357 average time 0.0035830214857577674 iter num 420\n",
            "loss 0.5563620328903198 average time 0.0035449365636767735 iter num 440\n",
            "loss 0.29216712713241577 average time 0.0035096557174177216 iter num 460\n",
            "loss 0.15290768444538116 average time 0.003484358583348997 iter num 480\n",
            "loss 0.14148205518722534 average time 0.003454317426025227 iter num 500\n",
            "loss 0.15225253999233246 average time 0.0034262177904285916 iter num 520\n",
            "loss 0.22408148646354675 average time 0.0034022257185656432 iter num 540\n",
            "loss 0.32764118909835815 average time 0.0033816256054121497 iter num 560\n",
            "loss 0.2896706759929657 average time 0.003360461981092471 iter num 580\n",
            "loss 0.11791634559631348 average time 0.0033444119150711532 iter num 600\n",
            "loss 0.14522399008274078 average time 0.003323715846824099 iter num 620\n",
            "loss 0.3965491056442261 average time 0.0033056843344184015 iter num 640\n",
            "loss 0.33401864767074585 average time 0.0032876993970079858 iter num 660\n",
            "loss 0.13882869482040405 average time 0.0032708099706082175 iter num 680\n",
            "loss 0.34488892555236816 average time 0.0032582454328647665 iter num 700\n",
            "loss 0.07441288232803345 average time 0.003243589268074882 iter num 720\n",
            "loss 0.13519057631492615 average time 0.0032301048162431422 iter num 740\n",
            "loss 0.13707610964775085 average time 0.0032180812105539907 iter num 760\n",
            "loss 0.15728935599327087 average time 0.003208225126945763 iter num 780\n",
            "loss 0.09041418135166168 average time 0.0031961138025280887 iter num 800\n",
            "loss 0.03670215979218483 average time 0.0031881631780623404 iter num 820\n",
            "loss 0.15828457474708557 average time 0.0031776036202505304 iter num 840\n",
            "loss 0.11497847735881805 average time 0.003167393146514071 iter num 860\n",
            "loss 0.11231594532728195 average time 0.0031570271545495582 iter num 880\n",
            "loss 0.20088163018226624 average time 0.003146868717784754 iter num 900\n",
            "loss 0.0592094287276268 average time 0.0031385121750131277 iter num 920\n",
            "loss 0.09218171238899231 average time 0.00313012632979851 iter num 940\n",
            "loss 0.1202937588095665 average time 0.0031226096521019524 iter num 960\n",
            "loss 0.1704208254814148 average time 0.003115025329616958 iter num 980\n",
            "loss 0.14118286967277527 average time 0.0031079888560234395 iter num 1000\n",
            "loss 0.5523775815963745 average time 0.01836953519996314 iter num 20\n",
            "loss 2.3043901920318604 average time 0.010572452925043763 iter num 40\n",
            "loss 0.38201749324798584 average time 0.007954309066614465 iter num 60\n",
            "loss 0.0980478897690773 average time 0.006653804537518226 iter num 80\n",
            "loss 0.18718798458576202 average time 0.005871300040016649 iter num 100\n",
            "loss 0.6777151823043823 average time 0.005356563983301991 iter num 120\n",
            "loss 0.7816759347915649 average time 0.004995724992763176 iter num 140\n",
            "loss 0.30698877573013306 average time 0.004712672206187563 iter num 160\n",
            "loss 0.15349224209785461 average time 0.004494348072168779 iter num 180\n",
            "loss 0.2698170244693756 average time 0.004317645084956894 iter num 200\n",
            "loss 0.3696326017379761 average time 0.004175531663630946 iter num 220\n",
            "loss 1.4573636054992676 average time 0.0040559304457929105 iter num 240\n",
            "loss 0.19054841995239258 average time 0.0039554526845677175 iter num 260\n",
            "loss 0.11746364831924438 average time 0.0038690394642409438 iter num 280\n",
            "loss 0.16360290348529816 average time 0.003792029059950437 iter num 300\n",
            "loss 0.27520495653152466 average time 0.003725915774975874 iter num 320\n",
            "loss 0.1443248987197876 average time 0.0036706382735193234 iter num 340\n",
            "loss 0.4941745698451996 average time 0.0036211769194475587 iter num 360\n",
            "loss 0.11593271046876907 average time 0.003589840547369692 iter num 380\n",
            "loss 1.2155286073684692 average time 0.0035518780650090776 iter num 400\n",
            "loss 0.2242317795753479 average time 0.003512769580958688 iter num 420\n",
            "loss 0.18600958585739136 average time 0.003477368811375279 iter num 440\n",
            "loss 0.1271839439868927 average time 0.003447031121718085 iter num 460\n",
            "loss 0.3077479600906372 average time 0.003416743943724517 iter num 480\n",
            "loss 0.27015605568885803 average time 0.0033893216519863927 iter num 500\n",
            "loss 0.08743233978748322 average time 0.003366680671143303 iter num 520\n",
            "loss 0.22173087298870087 average time 0.0033501350351933207 iter num 540\n",
            "loss 0.11261595040559769 average time 0.0033284144946524714 iter num 560\n",
            "loss 0.37305185198783875 average time 0.003308405589663819 iter num 580\n",
            "loss 0.09634648263454437 average time 0.003289825786681225 iter num 600\n",
            "loss 0.4916343688964844 average time 0.003272311806475984 iter num 620\n",
            "loss 0.16028203070163727 average time 0.0032558415094058545 iter num 640\n",
            "loss 0.0938190147280693 average time 0.0032394820879165886 iter num 660\n",
            "loss 0.06756476312875748 average time 0.0032261059147512083 iter num 680\n",
            "loss 0.21684369444847107 average time 0.0032133163329074576 iter num 700\n",
            "loss 0.12400045245885849 average time 0.003199623201438347 iter num 720\n",
            "loss 0.3567960858345032 average time 0.0031903631460040373 iter num 740\n",
            "loss 0.07910694181919098 average time 0.003177610769776756 iter num 760\n",
            "loss 0.20262856781482697 average time 0.003166309561563069 iter num 780\n",
            "loss 0.12148158997297287 average time 0.0031569172875242657 iter num 800\n",
            "loss 0.28127574920654297 average time 0.0031469838366098065 iter num 820\n",
            "loss 0.14832890033721924 average time 0.0031404991690578755 iter num 840\n",
            "loss 0.12259604781866074 average time 0.0031333313255916353 iter num 860\n",
            "loss 0.0855933278799057 average time 0.003126037243191604 iter num 880\n",
            "loss 0.16249056160449982 average time 0.00311713695777952 iter num 900\n",
            "loss 0.0887528508901596 average time 0.0031082610847790976 iter num 920\n",
            "loss 0.07740295678377151 average time 0.0031001629223263738 iter num 940\n",
            "loss 0.11808715760707855 average time 0.00309373701873407 iter num 960\n",
            "loss 0.06866012513637543 average time 0.0030868195377516546 iter num 980\n",
            "loss 0.30559802055358887 average time 0.0030809040160020233 iter num 1000\n",
            "loss 0.09877312928438187 average time 0.018586561350457487 iter num 20\n",
            "loss 0.351423054933548 average time 0.010666052450505958 iter num 40\n",
            "loss 0.37225449085235596 average time 0.008028990066911016 iter num 60\n",
            "loss 0.3010707497596741 average time 0.006707575387781617 iter num 80\n",
            "loss 0.2960497736930847 average time 0.005947543540241895 iter num 100\n",
            "loss 0.22903481125831604 average time 0.005425658325202675 iter num 120\n",
            "loss 0.15673717856407166 average time 0.005045547342966269 iter num 140\n",
            "loss 0.22315645217895508 average time 0.00475425257511688 iter num 160\n",
            "loss 0.18137824535369873 average time 0.004535141294501146 iter num 180\n",
            "loss 0.2424597144126892 average time 0.004361807524983306 iter num 200\n",
            "loss 0.2425236999988556 average time 0.004207964200015174 iter num 220\n",
            "loss 0.2622096836566925 average time 0.004070323666655895 iter num 240\n",
            "loss 0.15042561292648315 average time 0.003954996269203548 iter num 260\n",
            "loss 0.4786595404148102 average time 0.0038667823535174 iter num 280\n",
            "loss 0.3867150545120239 average time 0.0037897095633040103 iter num 300\n",
            "loss 3.0701770782470703 average time 0.0037231500874781885 iter num 320\n",
            "loss 0.3424471318721771 average time 0.0036621058999705435 iter num 340\n",
            "loss 0.35502365231513977 average time 0.0036019024610444224 iter num 360\n",
            "loss 0.3304178714752197 average time 0.0035496472946665325 iter num 380\n",
            "loss 0.0751359611749649 average time 0.003501665454950853 iter num 400\n",
            "loss 0.12099020183086395 average time 0.003455392954709255 iter num 420\n",
            "loss 0.27409636974334717 average time 0.0034142330794814124 iter num 440\n",
            "loss 0.11334621906280518 average time 0.0033803590803670332 iter num 460\n",
            "loss 0.12288293242454529 average time 0.0033514020457914738 iter num 480\n",
            "loss 0.14530488848686218 average time 0.003321967835960095 iter num 500\n",
            "loss 0.28073835372924805 average time 0.0032958744461141646 iter num 520\n",
            "loss 0.2769244313240051 average time 0.0032688474240381363 iter num 540\n",
            "loss 0.06536104530096054 average time 0.003252636019604844 iter num 560\n",
            "loss 0.04373149201273918 average time 0.0032327247275855463 iter num 580\n",
            "loss 0.16954511404037476 average time 0.0032148035633387433 iter num 600\n",
            "loss 0.3545931875705719 average time 0.0031934332096904155 iter num 620\n",
            "loss 0.21334755420684814 average time 0.003172524632833529 iter num 640\n",
            "loss 0.2039327174425125 average time 0.0031547242651647663 iter num 660\n",
            "loss 0.1938241720199585 average time 0.0031391089985417613 iter num 680\n",
            "loss 0.13908803462982178 average time 0.003122869937183818 iter num 700\n",
            "loss 0.16036054491996765 average time 0.0031081094208831117 iter num 720\n",
            "loss 0.460708349943161 average time 0.0030935911567998905 iter num 740\n",
            "loss 0.16842445731163025 average time 0.003082341728967501 iter num 760\n",
            "loss 0.3257465362548828 average time 0.0030698876282258423 iter num 780\n",
            "loss 0.30815058946609497 average time 0.003059463876265909 iter num 800\n",
            "loss 0.27542316913604736 average time 0.0030528397926900654 iter num 820\n",
            "loss 0.15893815457820892 average time 0.003041357010728721 iter num 840\n",
            "loss 0.1570560485124588 average time 0.003030553883729945 iter num 860\n",
            "loss 0.10356636345386505 average time 0.003022316375001372 iter num 880\n",
            "loss 0.25324898958206177 average time 0.0030143276777703757 iter num 900\n",
            "loss 0.08871062099933624 average time 0.003004741694558502 iter num 920\n",
            "loss 0.5668927431106567 average time 0.0029971864372163644 iter num 940\n",
            "loss 0.13916482031345367 average time 0.002993156318727112 iter num 960\n",
            "loss 0.21960461139678955 average time 0.002984525719378381 iter num 980\n",
            "loss 0.20665961503982544 average time 0.0029764379219996044 iter num 1000\n",
            "loss 0.4414825141429901 average time 0.018105251800261613 iter num 20\n",
            "loss 0.26889538764953613 average time 0.010430668375192909 iter num 40\n",
            "loss 0.4259184002876282 average time 0.007860219416943436 iter num 60\n",
            "loss 0.4308186173439026 average time 0.006547987150088375 iter num 80\n",
            "loss 0.5915412902832031 average time 0.005751606460071343 iter num 100\n",
            "loss 0.5128697752952576 average time 0.005240082775011009 iter num 120\n",
            "loss 0.2685232162475586 average time 0.004883388450070925 iter num 140\n",
            "loss 0.2325775921344757 average time 0.004618915562582515 iter num 160\n",
            "loss 0.13546663522720337 average time 0.00440970946122737 iter num 180\n",
            "loss 0.2904534935951233 average time 0.00423273695010721 iter num 200\n",
            "loss 0.42388415336608887 average time 0.004082988540986579 iter num 220\n",
            "loss 0.37356969714164734 average time 0.003958263016753941 iter num 240\n",
            "loss 0.3998774588108063 average time 0.0038566105423832107 iter num 260\n",
            "loss 0.19113050401210785 average time 0.0037631052607529063 iter num 280\n",
            "loss 0.24170467257499695 average time 0.003683522886688782 iter num 300\n",
            "loss 0.5430856943130493 average time 0.0036326791687883997 iter num 320\n",
            "loss 0.4388837516307831 average time 0.0035811419265134163 iter num 340\n",
            "loss 0.20727592706680298 average time 0.0035489820611676096 iter num 360\n",
            "loss 0.41034650802612305 average time 0.003506029884250127 iter num 380\n",
            "loss 0.6410383582115173 average time 0.0034588060850273905 iter num 400\n",
            "loss 0.09450368583202362 average time 0.0034167340000272987 iter num 420\n",
            "loss 0.1168748065829277 average time 0.0033796380295660292 iter num 440\n",
            "loss 0.7765070199966431 average time 0.003346750458710986 iter num 460\n",
            "loss 0.19353394210338593 average time 0.003315647000007023 iter num 480\n",
            "loss 0.25779590010643005 average time 0.0032933907020051265 iter num 500\n",
            "loss 0.23542456328868866 average time 0.003266057474999028 iter num 520\n",
            "loss 0.09093581885099411 average time 0.003244568224080366 iter num 540\n",
            "loss 0.24884894490242004 average time 0.0032200643678606867 iter num 560\n",
            "loss 0.16283594071865082 average time 0.0031997508120749163 iter num 580\n",
            "loss 0.2523784637451172 average time 0.0031820537800073606 iter num 600\n",
            "loss 0.10535281896591187 average time 0.0031631006612916545 iter num 620\n",
            "loss 0.705930233001709 average time 0.0031477612265632614 iter num 640\n",
            "loss 0.2715316116809845 average time 0.003131974327268174 iter num 660\n",
            "loss 0.1846708059310913 average time 0.0031157481911845133 iter num 680\n",
            "loss 0.1378154158592224 average time 0.003103052684288871 iter num 700\n",
            "loss 0.2658866345882416 average time 0.003088287465283833 iter num 720\n",
            "loss 0.08215010166168213 average time 0.003076253491904149 iter num 740\n",
            "loss 0.09813603013753891 average time 0.003070874726319361 iter num 760\n",
            "loss 0.13728709518909454 average time 0.0030611041423141546 iter num 780\n",
            "loss 0.1538446843624115 average time 0.0030488532625076916 iter num 800\n",
            "loss 0.0534018874168396 average time 0.003037385812191443 iter num 820\n",
            "loss 0.13315840065479279 average time 0.003027984520239053 iter num 840\n",
            "loss 0.30120161175727844 average time 0.003017602130226848 iter num 860\n",
            "loss 0.06783127784729004 average time 0.00300918813522499 iter num 880\n",
            "loss 0.06426144391298294 average time 0.003000022472224373 iter num 900\n",
            "loss 0.3061842918395996 average time 0.0029919164565359573 iter num 920\n",
            "loss 0.20017626881599426 average time 0.0029834258223498645 iter num 940\n",
            "loss 0.12291909754276276 average time 0.0029747373062718905 iter num 960\n",
            "loss 0.30424803495407104 average time 0.0029689536887992883 iter num 980\n",
            "loss 0.09767262637615204 average time 0.0029629373680181742 iter num 1000\n",
            "loss 0.14449504017829895 average time 0.018292795750130608 iter num 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Engine run is terminating due to exception: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-8dd9b566280b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    799\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m           \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STOCKS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_PATHS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this contains prices for each stock for each path at time T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m           \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK_rand\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m           \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_rand\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m           \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# average across stocks end prices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.__mul__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.__array_ufunc__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy._core._kernel.ufunc.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy._core._kernel._Ops.guess_routine\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy._core._kernel._min_scalar_type\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmin_scalar_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU1EpGuInwjJ"
      },
      "source": [
        "$2365$ seconds The loss is keeping decreasing which means the pricing model can predict the option prices better. It takes about $12ms$ to compute one mini-batch in average, In the following sections, we will try to expore the full potentials of the GPU to accelerate the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8McNtejRNFT"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRtOr1XIPOvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02cfd2a7-45f9-45bf-b6da-ff234c46792c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndftly2yPEaM"
      },
      "source": [
        "import torch\n",
        "model_save_name = f'EuCall_{str(nstock)}_v3_Erin.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6DRO9K2RQoJ"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnn917db7hkG"
      },
      "source": [
        "model_save_name = f'EuCall_{str(nstock)}_v3_Erin.pth'"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGXZSV_YRT8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f306b8e1-d840-4bb9-b6ab-dc152dcabf26"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ntY-N5bOqdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be089865-eebe-40e0-f4cb-ae39e4db4e12"
      },
      "source": [
        "import torch\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0GAGPAgPmgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57fbc25f-dcfb-4894-a22f-f5d8183ce9b3"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net(nstock = nstock).cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=6, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc5): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc6): Linear(in_features=1024, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXT4Bg0wdL7l"
      },
      "source": [
        "### Continue to train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfa9cp6CdG8T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f8211bf-e06a-44b3-a318-3eb7715df4aa"
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import NumbaOptionDataSet\n",
        "timer = Timer(average=True)\n",
        "#model = Net(nstock = nstock).cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "# dataset = NumbaOptionDataSet(max_len=10000, number_path = 1024, batch=4800)\n",
        "dataset = NumbaOptionDataSet(max_len=500, number_path = 1024, batch=32, seed = random.randint(0, 100), stocks=nstock)\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred[:,0], y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs=20)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss 1.5823490619659424 average time 0.01786679090000689 iter num 20\n",
            "loss 0.22086486220359802 average time 0.010210896699845762 iter num 40\n",
            "loss 0.19065448641777039 average time 0.007650170466695272 iter num 60\n",
            "loss 0.1304394006729126 average time 0.006390860062401771 iter num 80\n",
            "loss 0.3821221590042114 average time 0.005632484079906135 iter num 100\n",
            "loss 0.15677478909492493 average time 0.005129766933290133 iter num 120\n",
            "loss 0.4356291890144348 average time 0.00476775904997859 iter num 140\n",
            "loss 0.4874846339225769 average time 0.004502000550019147 iter num 160\n",
            "loss 0.5089256167411804 average time 0.004287443488829012 iter num 180\n",
            "loss 0.6373453736305237 average time 0.0041148867899573815 iter num 200\n",
            "loss 0.38128143548965454 average time 0.003994045404512938 iter num 220\n",
            "loss 0.8491618037223816 average time 0.003876261070854525 iter num 240\n",
            "loss 0.18831130862236023 average time 0.003773140784617751 iter num 260\n",
            "loss 0.30728602409362793 average time 0.0036958842463978465 iter num 280\n",
            "loss 0.4781438410282135 average time 0.003623011126619531 iter num 300\n",
            "loss 0.5388761758804321 average time 0.0035617209593056033 iter num 320\n",
            "loss 0.27677619457244873 average time 0.0035007943087561324 iter num 340\n",
            "loss 0.5449455380439758 average time 0.00344780402214787 iter num 360\n",
            "loss 0.37148335576057434 average time 0.003405345526258124 iter num 380\n",
            "loss 0.47054481506347656 average time 0.003363214937444354 iter num 400\n",
            "loss 0.17034678161144257 average time 0.0033229502071013225 iter num 420\n",
            "loss 0.8069314956665039 average time 0.0032928012522213316 iter num 440\n",
            "loss 0.8369894027709961 average time 0.0032599303564695772 iter num 460\n",
            "loss 0.4238404631614685 average time 0.00323281929370296 iter num 480\n",
            "loss 0.6338930726051331 average time 0.003205257601955964 iter num 500\n",
            "loss 0.7045097947120667 average time 0.0174458447507277 iter num 20\n",
            "loss 0.6982458829879761 average time 0.010012935550639668 iter num 40\n",
            "loss 0.43068820238113403 average time 0.007514490366944907 iter num 60\n",
            "loss 0.6186349391937256 average time 0.0062619725627882875 iter num 80\n",
            "loss 0.2272341549396515 average time 0.005515230200217047 iter num 100\n",
            "loss 1.0565104484558105 average time 0.005031630175138465 iter num 120\n",
            "loss 0.9010277986526489 average time 0.004679381064436582 iter num 140\n",
            "loss 0.9036542177200317 average time 0.004425083450109923 iter num 160\n",
            "loss 0.1462412178516388 average time 0.0042267016389612565 iter num 180\n",
            "loss 0.6108096241950989 average time 0.004057871635031915 iter num 200\n",
            "loss 0.7135320901870728 average time 0.003918846368171878 iter num 220\n",
            "loss 0.2002740204334259 average time 0.003799719650047943 iter num 240\n",
            "loss 0.6678434610366821 average time 0.0037012118885076445 iter num 260\n",
            "loss 0.2634592354297638 average time 0.0036157120321799346 iter num 280\n",
            "loss 0.36557674407958984 average time 0.0035412264300248354 iter num 300\n",
            "loss 0.33542346954345703 average time 0.003478026821869662 iter num 320\n",
            "loss 0.22065633535385132 average time 0.003421889167646655 iter num 340\n",
            "loss 0.17285943031311035 average time 0.003371975880549548 iter num 360\n",
            "loss 0.1649802029132843 average time 0.003329713786852632 iter num 380\n",
            "loss 0.2766484320163727 average time 0.0032908489250166894 iter num 400\n",
            "loss 0.36850878596305847 average time 0.0032559743857442907 iter num 420\n",
            "loss 0.218727707862854 average time 0.0032265268568483986 iter num 440\n",
            "loss 0.12480200827121735 average time 0.003196703915241612 iter num 460\n",
            "loss 0.26789548993110657 average time 0.0031698975104366887 iter num 480\n",
            "loss 0.23859137296676636 average time 0.0031531090680291525 iter num 500\n",
            "loss 0.9613290429115295 average time 0.01799098840019724 iter num 20\n",
            "loss 0.2606615424156189 average time 0.010297184275259497 iter num 40\n",
            "loss 0.2638603746891022 average time 0.0077066907168045875 iter num 60\n",
            "loss 0.09025787562131882 average time 0.006453531887655117 iter num 80\n",
            "loss 0.7573431730270386 average time 0.0056791835700278175 iter num 100\n",
            "loss 0.3845985531806946 average time 0.005182491933313335 iter num 120\n",
            "loss 0.589755654335022 average time 0.004801675278603008 iter num 140\n",
            "loss 0.49562686681747437 average time 0.004526199493784589 iter num 160\n",
            "loss 0.378144234418869 average time 0.004306517722256507 iter num 180\n",
            "loss 0.3944694995880127 average time 0.004130247250013781 iter num 200\n",
            "loss 0.7612213492393494 average time 0.003986638386347543 iter num 220\n",
            "loss 0.6746338605880737 average time 0.0038623757249297342 iter num 240\n",
            "loss 0.27028223872184753 average time 0.003760647123034197 iter num 260\n",
            "loss 0.6081628203392029 average time 0.0036808543535309063 iter num 280\n",
            "loss 0.6823203563690186 average time 0.0036107780366243483 iter num 300\n",
            "loss 0.25473758578300476 average time 0.0035505605249682047 iter num 320\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Engine run is terminating due to exception: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-bbbe47ad48fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    799\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m           \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STOCKS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_PATHS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# this contains prices for each stock for each path at time T\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m           \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK_rand\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m           \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_rand\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m           \u001b[0mo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# average across stocks end prices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.__mul__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.__array_ufunc__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy._core._kernel.ufunc.__call__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy._core._kernel._Ops.guess_routine\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_kernel.pyx\u001b[0m in \u001b[0;36mcupy._core._kernel._min_scalar_type\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmin_scalar_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_KTvu9N4oSY"
      },
      "source": [
        "model_save_name = f'EuCall_{str(nstock)}_v3_Erin.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehmhDw8BUtLi"
      },
      "source": [
        "### Inference and Greeks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uiro43mOU0Ro"
      },
      "source": [
        "We can load the model parameters and use it to do inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svlu6tGTRx1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd66a9b-537f-4bde-e500-20b9d79babb4"
      },
      "source": [
        "import torch\n",
        "\n",
        "inputs = torch.tensor([[1, 110.0, 110.0, 0.35, 0.1, 0.05] * nstock]).cuda()\n",
        "model(inputs.float())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[17.7854]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1Iy-9pWVRDO"
      },
      "source": [
        "One of the benefits of building a deep learning model is that the [Greeks](<https://en.wikipedia.org/wiki/Greeks_(finance)#First-order_Greeks>) can be easily computed. \n",
        "We just need to take advantage of the auto-grad feature in Pytorch. We can use `grad` function to compute the first order differentiation for parameters 'K, B, S0, sigma, mu, r'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytBZaYHKSnDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "306965e5-63b6-4ed6-9796-6d92d3867d51"
      },
      "source": [
        "inputs = torch.tensor([[1, 110.0, 110.0, 0.35, 0.1, 0.05] * nstock]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-18.2999,  -0.4691,   0.6368,  43.9693,  -1.3526,  54.8471]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KeijaDDVZGd"
      },
      "source": [
        "Here we are going to plot the Delta graph:-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skwgeVDsA_Mr"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi_2Dqnx3_oP"
      },
      "source": [
        "#### Using gradient, Change only 1 S0 at a time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USh3qaADSYQp"
      },
      "source": [
        "#### Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "def compute_delta(S, ith):\n",
        "    inputs = torch.tensor([[1, 110.0, 110.0, 0.35, 0.1, 0.05]*(ith-1)\\\n",
        "                           + [1, 110.0, S, 0.35, 0.1, 0.05]\\\n",
        "                           + ([1, 110.0, 110.0, 0.35, 0.1, 0.05]*(nstock-ith))]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "4MfZKJlv13SC",
        "outputId": "a23634af-4634-4319-b224-4881d2d72e64"
      },
      "source": [
        "for i in range(1, nstock+1):\n",
        "  prices = np.arange(0, 150, 0.1)\n",
        "  deltas = []\n",
        "  for p in prices:\n",
        "      deltas.append(compute_delta(p, i).item())\n",
        "  fig = pylab.plot(prices, deltas, label = f'{i}th stock')\n",
        "  pylab.legend(loc = 'lower right')\n",
        "  pylab.xlabel('prices')\n",
        "  pylab.ylabel('Delta')\n",
        "  fig"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXixHQic35iI"
      },
      "source": [
        "#### Using Finite Difference, Change only 1 S0 at a time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "VGk5Hw64fMdh",
        "outputId": "16d907cd-3162-4553-850e-60caa9740765"
      },
      "source": [
        "## Using Finite Difference, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_delta(S, ith):\n",
        "    epsilon = 0.01\n",
        "    inputs1 = torch.tensor([[1, 110.0, 110.0, 0.35, 0.1, 0.05]*(ith-1)\\\n",
        "                           + [1, 110.0, S, 0.35, 0.1, 0.05]\\\n",
        "                           + ([1, 110.0, 110.0, 0.35, 0.1, 0.05]*(nstock-ith))]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, 110.0, 0.35, 0.1, 0.05]*(ith-1)\\\n",
        "                           + [1, 110.0, S + epsilon, 0.35, 0.1, 0.05]\\\n",
        "                           + ([1, 110.0, 110.0, 0.35, 0.1, 0.05]*(nstock-ith))]).cuda()\n",
        "    delta = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return delta\n",
        "\n",
        "for i in range(1, nstock+1):\n",
        "  prices = np.arange(0, 150, 0.1)\n",
        "  deltas = []\n",
        "  for p in prices:\n",
        "      deltas.append(compute_delta(p, i).item())\n",
        "  fig = pylab.plot(prices, deltas, label = f'{i}th stock')\n",
        "  pylab.legend(loc = 'lower right')\n",
        "  pylab.xlabel('prices')\n",
        "  pylab.ylabel('Delta')\n",
        "  fig"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fIJe36fJ4JFO"
      },
      "source": [
        "#### Using Finite Difference, Change 3 S0 at a time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "4O1I8COnUxnz",
        "outputId": "aa87558d-eee8-475e-e437-298507addaee"
      },
      "source": [
        "##Using Finite Difference, Change 3 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    epsilon = 0.01\n",
        "    inputs1 = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]*nstock]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, S + epsilon, 0.35, 0.1, 0.05]*nstock]).cuda()\n",
        "    delta = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return delta\n",
        "\n",
        "\n",
        "prices = np.arange(0, 150, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f6000e1f210>]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4DfOK_a4nuEt",
        "outputId": "cc05536a-740e-4137-b165-eb6cdc25975b"
      },
      "source": [
        "compute_delta(110)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6367]], device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNB8LPwfBMHQ"
      },
      "source": [
        "# Gamma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLO_5nEGVcEc"
      },
      "source": [
        "Calculating the second order derivative is easy in PyTorch too. We just need to apply the `grad` function twice. Use this mechanism, we can calculate the second order derivatives $\\frac{\\partial^2 P}{\\partial K \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial B \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial S_0^2}$, $\\frac{\\partial^2 P}{\\partial \\sigma \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial \\mu \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial r \\partial S_0}$ in the following example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGzj7A3sThZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7ca34ad-cb43-4ca4-dc42-0f3dbaaa9150"
      },
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import grad\n",
        "from torch import nn\n",
        "\n",
        "inputs = torch.tensor([[1, 110.0, 110.0, 0.35, 0.1, 0.05]*nstock]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs)\n",
        "\n",
        "# instead of using loss.backward(), use torch.autograd.grad() to compute gradients\n",
        "# https://pytorch.org/docs/stable/autograd.html#torch.autograd.grad\n",
        "loss_grads = grad(x, inputs, create_graph=True)\n",
        "drv = grad(loss_grads[0][0][2], inputs)\n",
        "drv"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.2574, -0.0118,  0.0121,  0.0515, -0.0018,  1.2643]],\n",
              "        device='cuda:0'),)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJbZYtvhVmSo"
      },
      "source": [
        "Gamma is the second order differenation of `S`. We can plot the the Gamma curve as a function of the stock price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlXVePiK4UH5"
      },
      "source": [
        "#### Using gradient, Change only 1 S0 at a time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JpQa3EJToA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "8ff19037-0bfa-49c8-ac59-857ce0e11644"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "import pylab\n",
        "import numpy as np\n",
        "def compute_gamma(S, ith):\n",
        "  inputs = torch.tensor([[1, 110.0, 110.0, 0.35, 0.1, 0.05]*(ith-1)\\\n",
        "                           + [1, 110.0, S, 0.35, 0.1, 0.05]\\\n",
        "                           + ([1, 110.0, 110.0, 0.35, 0.1, 0.05]*(nstock-ith))]).cuda()\n",
        "  # inputs = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05] + ([1, 110.0, 110.0, 0.35, 0.1, 0.05]*2)]).cuda()\n",
        "  inputs.requires_grad = True\n",
        "  x = model(inputs.float())\n",
        "  #x = model(inputs)\n",
        "  loss_grads = grad(x, inputs, create_graph=True)\n",
        "  drv = grad(loss_grads[0][0][2], inputs)\n",
        "  return drv[0][0][2]\n",
        "\n",
        "for i in range(1, nstock+1):\n",
        "  prices = np.arange(0, 150, 0.1)\n",
        "  gammas = []\n",
        "  for p in prices:\n",
        "      gammas.append(compute_gamma(p, i).item())\n",
        "  fig2 = pylab.plot(prices, gammas, label = f'{i}th stock')\n",
        "  pylab.legend(loc = 'upper right')\n",
        "  pylab.xlabel('prices')\n",
        "  pylab.ylabel('Gamma')\n",
        "  fig2"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDEmn97t4xxJ"
      },
      "source": [
        "#### Using Finite Difference, Change only 1 S0 at a time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsoaOyCDxQy0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "c492e4f4-167b-42d8-dd2b-75660c131548"
      },
      "source": [
        "##Using Finite Difference, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_gamma(S, ith):\n",
        "    epsilon = 0.5\n",
        "    inputs1 = torch.tensor([[1, 110.0, 110.0, 0.35, 0.1, 0.05]*(ith-1)\\\n",
        "                           + [1, 110.0, S, 0.35, 0.1, 0.05]\\\n",
        "                           + ([1, 110.0, 110.0, 0.35, 0.1, 0.05]*(nstock-ith))]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, 110.0, 0.35, 0.1, 0.05]*(ith-1)\\\n",
        "                           + [1, 110.0, S+epsilon, 0.35, 0.1, 0.05]\\\n",
        "                           + ([1, 110.0, 110.0, 0.35, 0.1, 0.05]*(nstock-ith))]).cuda()\n",
        "    inputs3 = torch.tensor([[1, 110.0, 110.0, 0.35, 0.1, 0.05]*(ith-1)\\\n",
        "                           + [1, 110.0, S-epsilon, 0.35, 0.1, 0.05]\\\n",
        "                           + ([1, 110.0, 110.0, 0.35, 0.1, 0.05]*(nstock-ith))]).cuda()\n",
        "    # inputs1 = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]  + ([1, 110.0, 110.0, 0.35, 0.1, 0.05]*2)]).cuda()\n",
        "    # inputs2 = torch.tensor([[1, 110.0, S + epsilon, 0.35, 0.1, 0.05]  + ([1, 110.0, 110.0, 0.35, 0.1, 0.05]*2)]).cuda()\n",
        "    # inputs3 = torch.tensor([[1, 110.0, S - epsilon, 0.35, 0.1, 0.05]  + ([1, 110.0, 110.0, 0.35, 0.1, 0.05]*2)]).cuda()\n",
        "    gamma = (model(inputs2.float()) - 2*model(inputs1.float()) + model(inputs3.float()))/(epsilon**2)\n",
        "    return gamma\n",
        "\n",
        "for i in range(1, nstock+1):\n",
        "  prices = np.arange(0, 150, 0.1)\n",
        "  gammas = []\n",
        "  for p in prices:\n",
        "      gammas.append(compute_gamma(p, i).item())\n",
        "  fig = pylab.plot(prices, gammas, label = f'{i}th stock')\n",
        "  pylab.legend(loc = 'upper right')\n",
        "  pylab.xlabel('prices')\n",
        "  pylab.ylabel('Gamma')\n",
        "  fig"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnRaSM685NCq"
      },
      "source": [
        "#### Using Finite Difference, Change 3 S0 at a time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "aOsXgOwWZ_ru",
        "outputId": "870ffc0b-717e-4172-e015-cf3b10b15597"
      },
      "source": [
        "##Using Finite Difference, Change 3 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_gamma(S):\n",
        "    epsilon = 0.5\n",
        "    inputs1 = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]*nstock]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, S + epsilon, 0.35, 0.1, 0.05]*nstock]).cuda()\n",
        "    inputs3 = torch.tensor([[1, 110.0, S - epsilon, 0.35, 0.1, 0.05]*nstock]).cuda()\n",
        "    gamma = (model(inputs2.float()) - 2*model(inputs1.float()) + model(inputs3.float()))/(epsilon**2)\n",
        "    return gamma\n",
        "\n",
        "prices = np.arange(0, 150, 0.1)\n",
        "gammas = []\n",
        "for p in prices:\n",
        "    gammas.append(compute_gamma(p).item())\n",
        "fig = pylab.plot(prices, gammas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Gamma')\n",
        "fig"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5fcfebbf10>]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67lca2xrBh9a"
      },
      "source": [
        "# Vega"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuETeg-e53wz"
      },
      "source": [
        "#### Using finite difference, Change only 1 S0 at a time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muozc-hzhSGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "9757ed91-1951-4731-e13e-ecba249b4bcc"
      },
      "source": [
        "##Using finite difference, Change only 1 S0 at a time\n",
        "# vega\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_vega(S, ith):\n",
        "    epsilon = 0.5\n",
        "\n",
        "    inputs1 = torch.tensor([[1, 110.0, 110.0, 0.35, 0.1, 0.05]*(ith-1)\\\n",
        "                           + [1, 110.0, S, 0.35, 0.1, 0.05]\\\n",
        "                           + ([1, 110.0, 110.0, 0.35, 0.1, 0.05]*(nstock-ith))]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, 110.0, 0.35, 0.1, 0.05]*(ith-1)\\\n",
        "                           + [1, 110.0, S, 0.35+epsilon, 0.1, 0.05]\\\n",
        "                           + ([1, 110.0, 110.0, 0.35, 0.1, 0.05]*(nstock-ith))]).cuda()\n",
        "\n",
        "    vega = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return vega\n",
        "\n",
        "for i in range(1, nstock+1):\n",
        "  prices = np.arange(0, 150, 0.1)\n",
        "  vegas = []\n",
        "  for p in prices:\n",
        "      vegas.append(compute_vega(p, i).item())\n",
        "  fig = pylab.plot(prices, vegas, label = f'{i}th stock')\n",
        "  pylab.legend(loc = 'upper left')\n",
        "  pylab.xlabel('prices')\n",
        "  pylab.ylabel('Vega')\n",
        "  fig"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_BYyL9d584w"
      },
      "source": [
        "#### Using Finite Difference, Change 3 S0 at a time"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "0KATxBCAdlFt",
        "outputId": "921733cb-951f-4162-bb9b-a983dbb1c2b5"
      },
      "source": [
        "##Using Finite Difference, Change 3 S0 at a time\n",
        "# vega\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_vega(S):\n",
        "    epsilon = 0.5\n",
        "    inputs1 = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]*nstock]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, S, 0.35 + epsilon, 0.1, 0.05]*nstock]).cuda()\n",
        "    vega = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return vega\n",
        "\n",
        "\n",
        "prices = np.arange(0, 150, 0.1)\n",
        "vegas = []\n",
        "for p in prices:\n",
        "    vegas.append(compute_vega(p).item())\n",
        "fig = pylab.plot(prices, vegas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Vega')\n",
        "fig"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5fcfdb6a50>]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj7NlW6GVqSA"
      },
      "source": [
        "[Implied volatility](https://en.wikipedia.org/wiki/Implied_volatility) is the forecasted volatility of the underlying asset based on the quoted prices of the option. It is the reverse mapping of price to the option parameter given the model which is hard to do with the Monte Carlo simulation approach. But if we have the deep learning pricing model, it is an easy task. We can first plot the relationship between volatility and the option price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yrCw5UNT07t"
      },
      "source": [
        "# import pylab\n",
        "# import numpy as np\n",
        "# def compute_price(sigma):\n",
        "#     inputs = torch.tensor([[1, 110.0, 110.0, sigma, 0.1, 0.05]]).cuda()\n",
        "#     x = model(inputs.float())\n",
        "#     #x = model(inputs)\n",
        "#     return x.item()\n",
        "# sigmas = np.arange(0, 0.5, 0.1)\n",
        "# prices = []\n",
        "# for s in sigmas:\n",
        "#     prices.append(compute_price(s))\n",
        "# fig3 = pylab.plot(sigmas, prices)\n",
        "# pylab.xlabel('Sigma')\n",
        "# pylab.ylabel('Price')\n",
        "# fig3"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU25Cj29VtCa"
      },
      "source": [
        "Given the prices `P`, the implied volatility is the root of the function `compute_price`. We can use bisection to find the root."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddHnwm_zUBYD"
      },
      "source": [
        "# def bisection_root(small, large, fun, target, EPS=1e-6):\n",
        "#     if fun(large) - target < 0:\n",
        "#         print('upper bound is too small')\n",
        "#         return None\n",
        "#     if fun(small) - target > 0:\n",
        "#         print('lower bound is too large')\n",
        "#         return None\n",
        "#     while large - small > EPS:\n",
        "#         mid = (large + small) / 2.0\n",
        "#         if fun(mid) - target >= 0:\n",
        "#             large = mid\n",
        "#         else:\n",
        "#             small = mid\n",
        "#     mid = (large + small) / 2.0\n",
        "#     return mid, abs(fun(mid) - target)\n",
        "# quoted_price = 16.0\n",
        "# sigma, err = bisection_root(0, 0.5, compute_price, quoted_price)\n",
        "# print('implied volativity', sigma, 'error', err)     "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEiAredqQGxf"
      },
      "source": [
        ""
      ],
      "execution_count": 57,
      "outputs": []
    }
  ]
}