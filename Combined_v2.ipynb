{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Combined_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NwN6aLFDnwiy",
        "dBOv_RiBsCWa",
        "u2_89jOknwjH"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Erin/Combined_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCR6hhw5Xq_R"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSxOZk3ls2XQ",
        "outputId": "3df751f0-fb77-4f55-c35a-d63634ed2072"
      },
      "source": [
        "!curl https://colab.chainer.org/install |sh -\n",
        "import cupy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1580  100  1580    0     0  20519      0 --:--:-- --:--:-- --:--:-- 20519\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "\u001b[K     |████████████████████████████████| 58.9MB 51kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 34.5MB/s \n",
            "\u001b[?25h  Building wheel for chainer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "+ set +ex\n",
            "Installation succeeded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwN6aLFDnwiy"
      },
      "source": [
        "### Deep Learning Barrier Option\n",
        "\n",
        "We used Numba and CuPy in the previous notebook to run Monte Carlo simulation to determine the price of the Asian Barrier option. A Monte Carlo simulation needs millions of paths to get an accurate answer which is computationally intensive. [Ryan et al (2018)](https://arxiv.org/abs/1809.02233) showed that a deep learning model can be trained to value derivatives. The deep learning model is accurate and very fast, capable of producing valuations a million times faster than traditional models. In the this notebook, we will use a fully connected network to learn the pricing mode of the Asian Barrier option. Monte Carlo simulation is used as pricing ground truth for the training. We use the same Asian Barrier Option model as last notebook with parameters listed as following:\n",
        "\n",
        "```\n",
        "T - Maturity (yrs.)\n",
        "S - Spot (usd)\n",
        "K - Strike (usd)\n",
        "sigma - Volatility (per.)\n",
        "r - Risk Free Rate (per.)\n",
        "mu - Stock Drift Rate (per.)\n",
        "B - Barrier (usd)\n",
        "```\n",
        "\n",
        "### Batched Data generation\n",
        "\n",
        "The dataset is an important part of the Deep learning training. We will modify the previous single Asian Barrier Option pricing code to handle a batch of Barrier Option pricing. \n",
        "\n",
        "Loading all the necessary libraries:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu6no5JzH-B6"
      },
      "source": [
        "# !pip install cupy-cuda101"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbkx3hXWnwi8"
      },
      "source": [
        "# import cupy\n",
        "# import numpy as np\n",
        "# import math\n",
        "# import time\n",
        "# import torch\n",
        "# cupy.cuda.set_allocator(None)\n",
        "# from torch.utils.dlpack import from_dlpack"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqBN3YFOnwi-"
      },
      "source": [
        "The CuPy version of batched barrier option pricing simulation is as follows:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzhj4DtLnwi-"
      },
      "source": [
        "# cupy_batched_barrier_option = cupy.RawKernel(r'''\n",
        "# extern \"C\" __global__ void batched_barrier_option(\n",
        "#     float *d_s,\n",
        "#     const float T,\n",
        "#     const float * K,\n",
        "#     const float * B,\n",
        "#     const float * S0,\n",
        "#     const float * sigma,\n",
        "#     const float * mu,\n",
        "#     const float * r,\n",
        "#     const float * d_normals,\n",
        "#     const long N_STEPS,\n",
        "#     const long N_PATHS,\n",
        "#     const long N_BATCH)\n",
        "# {\n",
        "#   unsigned idx =  threadIdx.x + blockIdx.x * blockDim.x;\n",
        "#   unsigned stride = blockDim.x * gridDim.x;\n",
        "#   unsigned tid = threadIdx.x;\n",
        "#   const float tmp3 = sqrt(T/N_STEPS);\n",
        "\n",
        "\n",
        "#   for (unsigned i = idx; i<N_PATHS * N_BATCH; i+=stride)\n",
        "#   {\n",
        "#     int batch_id = i / N_PATHS;\n",
        "#     int path_id = i % N_PATHS;\n",
        "#     float s_curr = S0[batch_id];\n",
        "#     float tmp1 = mu[batch_id]*T/N_STEPS;\n",
        "#     float tmp2 = exp(-r[batch_id]*T);\n",
        "#     unsigned n=0;\n",
        "#     double running_average = 0.0;\n",
        "#     for(unsigned n = 0; n < N_STEPS; n++){\n",
        "#        s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH];\n",
        "#        running_average += (s_curr - running_average) / (n + 1.0);\n",
        "#        if (running_average <= B[batch_id]){\n",
        "#            break;\n",
        "#        }\n",
        "#     }\n",
        "\n",
        "#     float payoff = (running_average>K[batch_id] ? running_average-K[batch_id] : 0.f); \n",
        "#     d_s[i] = tmp2 * payoff;\n",
        "#   }\n",
        "# }\n",
        "\n",
        "# ''', 'batched_barrier_option')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRjmX5zcnwi_"
      },
      "source": [
        "Note, the parameters (K, B, S0, sigma, mu, r) are passed in as an array with length of batch size. The output array is a two dimensional array flatten to 1-D. The first dimension is for Batch and the second dimension is for Path. \n",
        "\n",
        "Testing it out by entering two sets of option parameters:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn4PMo7Inwi_"
      },
      "source": [
        "# N_PATHS = 2048000\n",
        "# N_STEPS = 365\n",
        "# N_BATCH = 2\n",
        "# T = 1.0\n",
        "\n",
        "# K = cupy.array([110.0, 120.0], dtype=cupy.float32)\n",
        "# B = cupy.array([100.0, 90.0], dtype=cupy.float32)\n",
        "# S0 = cupy.array([120.0, 100.0], dtype=cupy.float32)\n",
        "# sigma = cupy.array([0.35, 0.2], dtype=cupy.float32)\n",
        "# mu = cupy.array([0.15, 0.1], dtype=cupy.float32)\n",
        "# r =cupy.array([0.05, 0.05], dtype=cupy.float32)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpWK3wcEnwjA"
      },
      "source": [
        "Put everything into a simple function to launch this GPU kernel. The option prices for each batch is the average of the corresponding path terminal values. This can be computed easily by Cupy function `mean(axis=1)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhAb34NTnwjA"
      },
      "source": [
        "# def batch_run():\n",
        "#     number_of_threads = 256\n",
        "#     number_of_blocks = (N_PATHS * N_BATCH - 1) // number_of_threads + 1\n",
        "#     randoms_gpu = cupy.random.normal(0, 1, N_BATCH*N_PATHS * N_STEPS, dtype=cupy.float32)\n",
        "#     output = cupy.zeros(N_BATCH*N_PATHS, dtype=cupy.float32)\n",
        "#     cupy.cuda.stream.get_current_stream().synchronize()\n",
        "#     s = time.time()\n",
        "#     cupy_batched_barrier_option((number_of_blocks,), (number_of_threads,),\n",
        "#                        (output, np.float32(T), K, B, S0, sigma, mu, r,\n",
        "#                         randoms_gpu, N_STEPS, N_PATHS, N_BATCH))\n",
        "#     v = output.reshape(N_BATCH, N_PATHS).mean(axis=1)\n",
        "#     cupy.cuda.stream.get_current_stream().synchronize()\n",
        "#     e = time.time()\n",
        "#     print('time', e-s, 'v',v)\n",
        "# batch_run()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puRgQCelnwjC"
      },
      "source": [
        "This produces the option prices $21.22$ and $0.848$ for these two sets of option parameters in $66ms$.\n",
        "\n",
        "It works efficiently hence we will construct an `OptionDataSet` class to wrap the above code so we can use it in Pytorch. For every `next` element, it generates uniform distributed random option parameters in the specified range, launches the GPU kernel to compute the option prices, convert the CuPy array to Pytorch tensors with zero copy via the DLPack. Note how we implemented the iterable Dataset interface:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1KUra7ZnwjC"
      },
      "source": [
        "# class OptionDataSet(torch.utils.data.IterableDataset):\n",
        "    \n",
        "#     def __init__(self, max_len=10, number_path = 1000, batch=2, threads=256,seed=15):\n",
        "#         self.num = 0\n",
        "#         self.max_length = max_len\n",
        "#         self.N_PATHS = number_path\n",
        "#         self.N_STEPS = 365\n",
        "#         self.N_BATCH = batch\n",
        "#         self.T = np.float32(1.0)\n",
        "#         self.output = cupy.zeros(self.N_BATCH*self.N_PATHS, dtype=cupy.float32) \n",
        "#         self.number_of_blocks = (self.N_PATHS * self.N_BATCH - 1) // threads + 1\n",
        "#         self.number_of_threads = threads\n",
        "#         cupy.random.seed(seed)\n",
        "        \n",
        "#     def __len__(self):\n",
        "#         return self.max_length\n",
        "        \n",
        "#     def __iter__(self):\n",
        "#         self.num = 0\n",
        "#         return self\n",
        "    \n",
        "#     def __next__(self):\n",
        "#         if self.num > self.max_length:\n",
        "#             raise StopIteration\n",
        "#         X = cupy.random.rand(self.N_BATCH, 6, dtype=cupy.float32)\n",
        "#         # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "#         X = X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2], dtype=cupy.float32)\n",
        "#         # make sure the Barrier is smaller than the Strike price\n",
        "#         X[:, 1] = X[:, 0] * X[:, 1]\n",
        "#         randoms = cupy.random.normal(0, 1, self.N_BATCH * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "#         cupy_batched_barrier_option((self.number_of_blocks,), (self.number_of_threads,), (self.output, self.T, cupy.ascontiguousarray(X[:, 0]), \n",
        "#                               cupy.ascontiguousarray(X[:, 1]), cupy.ascontiguousarray(X[:, 2]), cupy.ascontiguousarray(X[:, 3]), cupy.ascontiguousarray(X[:, 4]), cupy.ascontiguousarray(X[:, 5]), randoms, self.N_STEPS, self.N_PATHS, self.N_BATCH))\n",
        "#         Y = self.output.reshape(self.N_BATCH, self.N_PATHS).mean(axis=1)\n",
        "#         self.num += 1\n",
        "#         return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo46Vf4XnwjD"
      },
      "source": [
        "Put everything related to Pytorch dataset into a file `cupy_dataset.py`:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwQUGMBlnwjE"
      },
      "source": [
        "# #%%writefile cupy_dataset.py \n",
        "# import cupy\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "# cupy.cuda.set_allocator(None)\n",
        "\n",
        "# cupy_batched_barrier_option = cupy.RawKernel(r'''\n",
        "# extern \"C\" __global__ void batched_barrier_option(\n",
        "#     float *d_s,\n",
        "#     const float T,\n",
        "#     const float * K,\n",
        "#     const float * B,\n",
        "#     const float * S0,\n",
        "#     const float * sigma,\n",
        "#     const float * mu,\n",
        "#     const float * r,\n",
        "#     const float * d_normals,\n",
        "#     const long N_STEPS,\n",
        "#     const long N_PATHS,\n",
        "#     const long N_BATCH)\n",
        "# {\n",
        "#   unsigned idx =  threadIdx.x + blockIdx.x * blockDim.x;\n",
        "#   unsigned stride = blockDim.x * gridDim.x;\n",
        "#   unsigned tid = threadIdx.x;\n",
        "#   const float tmp3 = sqrt(T/N_STEPS);\n",
        "\n",
        "\n",
        "#   for (unsigned i = idx; i<N_PATHS * N_BATCH; i+=stride)\n",
        "#   {\n",
        "#     int batch_id = i / N_PATHS;\n",
        "#     int path_id = i % N_PATHS;\n",
        "#     float s_curr = S0[batch_id];\n",
        "#     float tmp1 = mu[batch_id]*T/N_STEPS;\n",
        "#     float tmp2 = exp(-r[batch_id]*T);\n",
        "#     unsigned n=0;\n",
        "#     double running_average = 0.0;\n",
        "#     for(unsigned n = 0; n < N_STEPS; n++){\n",
        "#        s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH];\n",
        "#        running_average += (s_curr - running_average) / (n + 1.0);\n",
        "#        if (running_average <= B[batch_id]){\n",
        "#            break;\n",
        "#        }\n",
        "#     }\n",
        "\n",
        "#     float payoff = (running_average>K[batch_id] ? running_average-K[batch_id] : 0.f); \n",
        "#     d_s[i] = tmp2 * payoff;\n",
        "#   }\n",
        "# }\n",
        "\n",
        "# ''', 'batched_barrier_option')\n",
        "\n",
        "# class OptionDataSet(torch.utils.data.IterableDataset):\n",
        "    \n",
        "#     def __init__(self, max_len=10, number_path = 1000, batch=2, threads=256,seed=15):\n",
        "#         self.num = 0\n",
        "#         self.max_length = max_len\n",
        "#         self.N_PATHS = number_path\n",
        "#         self.N_STEPS = 365\n",
        "#         self.N_BATCH = batch\n",
        "#         self.T = np.float32(1.0)\n",
        "#         self.output = cupy.zeros(self.N_BATCH*self.N_PATHS, dtype=cupy.float32) \n",
        "#         self.number_of_blocks = (self.N_PATHS * self.N_BATCH - 1) // threads + 1\n",
        "#         self.number_of_threads = threads\n",
        "#         cupy.random.seed(seed)\n",
        "        \n",
        "#     def __len__(self):\n",
        "#         return self.max_length\n",
        "        \n",
        "#     def __iter__(self):\n",
        "#         self.num = 0\n",
        "#         return self\n",
        "    \n",
        "#     def __next__(self):\n",
        "#         if self.num > self.max_length:\n",
        "#             raise StopIteration\n",
        "#         X = cupy.random.rand(self.N_BATCH, 6, dtype=cupy.float32)\n",
        "#         # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "#         X = X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2], dtype=cupy.float32)\n",
        "#         # make sure the Barrier is smaller than the Strike price\n",
        "#         X[:, 1] = X[:, 0] * X[:, 1]\n",
        "#         randoms = cupy.random.normal(0, 1, self.N_BATCH * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "#         cupy_batched_barrier_option((self.number_of_blocks,), (self.number_of_threads,), (self.output, self.T, cupy.ascontiguousarray(X[:, 0]), \n",
        "#                               cupy.ascontiguousarray(X[:, 1]), cupy.ascontiguousarray(X[:, 2]), cupy.ascontiguousarray(X[:, 3]), cupy.ascontiguousarray(X[:, 4]), cupy.ascontiguousarray(X[:, 5]), randoms, self.N_STEPS, self.N_PATHS, self.N_BATCH))\n",
        "#         Y = self.output.reshape(self.N_BATCH, self.N_PATHS).mean(axis=1)\n",
        "#         self.num += 1\n",
        "#         return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyPAsh7JnwjF"
      },
      "source": [
        "Here is a test code to sample 10 data points with batch size 16:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLKxMF05nwjF"
      },
      "source": [
        "# from cupy_dataset import OptionDataSet\n",
        "# ds = OptionDataSet(10, number_path=100000, batch=16, seed=15)\n",
        "# for i in ds:\n",
        "#     print(i[1])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTlzRTD0nwjG"
      },
      "source": [
        "We can implement the same code by using Numba to accelerate the calculation in GPU:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IsfSwVwnwjG"
      },
      "source": [
        "# import numba\n",
        "# from numba import cuda\n",
        "\n",
        "# @cuda.jit\n",
        "# def batch_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_BATCH):\n",
        "#     # ii - overall thread index\n",
        "#     ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "#     stride = cuda.gridDim.x * cuda.blockDim.x\n",
        "#     tmp3 = math.sqrt(T/N_STEPS)\n",
        "#     for i in range(ii, N_PATHS * N_BATCH, stride):\n",
        "#         batch_id = i // N_PATHS\n",
        "#         path_id = i % N_PATHS\n",
        "#         tmp1 = mu[batch_id]*T/N_STEPS\n",
        "#         tmp2 = math.exp(-r[batch_id]*T)\n",
        "#         running_average = 0.0\n",
        "#         s_curr = S0[batch_id]\n",
        "#         for n in range(N_STEPS):\n",
        "\n",
        "#             s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH]\n",
        "#             running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average)\n",
        "#             if i==0 and batch_id == 2:\n",
        "#                 print(s_curr)\n",
        "#             if running_average <= B[batch_id]:\n",
        "#                 break\n",
        "#         payoff = running_average - K[batch_id] if running_average > K[batch_id] else 0\n",
        "#         d_s[i] = tmp2 * payoff\n",
        "\n",
        "# class NumbaOptionDataSet(object):\n",
        "    \n",
        "#     def __init__(self, max_len=10, number_path = 1000, batch=2, threads=512, seed=15):\n",
        "#         self.num = 0\n",
        "#         self.max_length = max_len\n",
        "#         self.N_PATHS = number_path\n",
        "#         self.N_STEPS = 365\n",
        "#         self.N_BATCH = batch\n",
        "#         self.T = np.float32(1.0)\n",
        "#         self.output = cupy.zeros(self.N_BATCH*self.N_PATHS, dtype=cupy.float32) \n",
        "#         self.number_of_blocks = (self.N_PATHS * self.N_BATCH - 1) // threads + 1\n",
        "#         self.number_of_threads = threads\n",
        "#         cupy.random.seed(seed)\n",
        "        \n",
        "#     def __len__(self):\n",
        "#         return self.max_length\n",
        "\n",
        "#     def __iter__(self):\n",
        "#         self.num = 0\n",
        "#         return self\n",
        "    \n",
        "#     def __next__(self):\n",
        "#         if self.num > self.max_length:\n",
        "#             raise StopIteration\n",
        "#         X = cupy.random.rand(self.N_BATCH, 6, dtype=cupy.float32)\n",
        "#         # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "#         X = X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2], dtype=cupy.float32)\n",
        "#         # make sure the Barrier is smaller than the Strike price\n",
        "#         X[:, 1] = X[:, 0] * X[:, 1]\n",
        "#         randoms = cupy.random.normal(0, 1, self.N_BATCH * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "#         batch_barrier_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, self.T, X[:, 0], \n",
        "#                               X[:, 1], X[:, 2], X[:, 3], X[:, 4], X[:, 5], randoms, self.N_STEPS, self.N_PATHS, self.N_BATCH)\n",
        "#         o = self.output.reshape(self.N_BATCH, self.N_PATHS)\n",
        "#         Y = o.mean(axis = 1) \n",
        "#         self.num += 1\n",
        "#         return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "# ds = NumbaOptionDataSet(10, number_path=100000, batch=1, seed=15)\n",
        "# for i in ds:\n",
        "#     print(i[1])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY_9g3tbdLiY"
      },
      "source": [
        "# TEST_ERIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBxT9Eida-c_",
        "outputId": "597c8262-48b0-49bc-d259-7fbe90bb20ec"
      },
      "source": [
        "################################# TEST ########################################\n",
        "%%writefile cupy_dataset.py\n",
        "\n",
        "import numba\n",
        "from numba import cuda\n",
        "import random\n",
        "import cupy\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "cupy.cuda.set_allocator(None)\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "@cuda.jit\n",
        "def batch_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_BATCH):\n",
        "    # ii - overall thread index\n",
        "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
        "    tmp3 = math.sqrt(T/N_STEPS)\n",
        "    for i in range(ii, N_PATHS * N_BATCH, stride):\n",
        "        batch_id = i // N_PATHS\n",
        "        path_id = i % N_PATHS\n",
        "        tmp1 = mu[batch_id]*T/N_STEPS\n",
        "        tmp2 = math.exp(-r[batch_id]*T)\n",
        "        running_average = 0.0\n",
        "        s_curr = S0[batch_id]\n",
        "        for n in range(N_STEPS):\n",
        "            s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH] # stock price\n",
        "            running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average) # average of the path\n",
        "            if i==0 and batch_id == 2:\n",
        "                print(s_curr)\n",
        "            if running_average <= B[batch_id]: # if reach barrier, drop out the path\n",
        "                break\n",
        "        payoff = running_average - K[batch_id] if running_average > K[batch_id] else 0\n",
        "        d_s[i] = tmp2 * payoff\n",
        "\n",
        "class NumbaOptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len=10, number_path = 1000, batch=2, threads=512, seed=15, stocks=3):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 365\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = np.float32(1.0)\n",
        "        self.output = cupy.zeros(self.N_STOCKS*self.N_PATHS, dtype=cupy.float32) \n",
        "        self.number_of_blocks = (self.N_PATHS * self.N_STOCKS - 1) // threads + 1\n",
        "        self.number_of_threads = threads\n",
        "        cupy.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num > self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros(self.N_BATCH, dtype=cupy.float32)\n",
        "        paras = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "        for op in range(self.N_BATCH):\n",
        "\n",
        "          X = cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)\n",
        "          #X = 0.9 + cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)*0.1\n",
        "\n",
        "          # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "          X = (X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6)\n",
        "\n",
        "          # make sure the Barrier is smaller than the Strike price\n",
        "          # X[:, 1] = X[:, 0] * X[:, 1]\n",
        "          for i in range(self.N_STOCKS):\n",
        "            paras[op,i*6:(i+1)*6] = X[i,:]\n",
        "\n",
        "          stocks_randoms_mean = cupy.zeros(self.N_STOCKS, dtype = cupy.float32)\n",
        "          rho = cupy.random.normal(0, 1, self.N_STOCKS, dtype = cupy.float32)\n",
        "\n",
        "          #stocks_randoms_cov = cupy.ones((self.N_STOCKS, self.N_STOCKS), dtype = cupy.float32)\n",
        "          #cupy.fill_diagonal(stocks_randoms_cov, rho)\n",
        "\n",
        "          #stocks_randoms_cov = (-0.99 + cupy.random.rand(self.N_STOCKS*self.N_STOCKS, dtype=cupy.float32)*2*0.99).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "          stocks_randoms_cov = cupy.array([0.9] * self.N_STOCKS*self.N_STOCKS, dtype = cupy.float32).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "          cupy.fill_diagonal(stocks_randoms_cov, 1)\n",
        "\n",
        "          num_of_randoms_each_stock = self.N_PATHS * self.N_STEPS\n",
        "          randoms_gpu = cupy.random.multivariate_normal(stocks_randoms_mean, stocks_randoms_cov,\n",
        "                                                        num_of_randoms_each_stock, dtype=cupy.float32)\n",
        "          b1_r = randoms_gpu[:,0]\n",
        "          b2_r = randoms_gpu[:,1]\n",
        "          randoms = cupy.zeros(self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "          interval = int((self.N_PATHS * self.N_STEPS * self.N_STOCKS) / self.N_PATHS)\n",
        "          for i in range(interval):\n",
        "            if i % 2 == 0:\n",
        "                ind = int(i/2)\n",
        "                randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b1_r[ind:(ind+self.N_PATHS)]\n",
        "            else:\n",
        "                ind = int(i//2)\n",
        "                randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b2_r[ind:(ind+self.N_PATHS)]\n",
        "\n",
        "          randoms = cupy.random.normal(0, 1, self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "          batch_barrier_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, self.T, X[:, 0], \n",
        "                                X[:, 1], X[:, 2], X[:, 3], X[:, 4], X[:, 5], randoms, self.N_STEPS, self.N_PATHS, self.N_STOCKS)\n",
        "          \n",
        "          o = self.output.reshape(self.N_STOCKS, self.N_PATHS)\n",
        "          Y[op] = o.mean(axis = 0).mean()\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(paras.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "\n",
        "# ds = NumbaOptionDataSet(10, number_path=100000, batch=3, seed=random.randint(0,100), stocks=5)\n",
        "# for i in ds:\n",
        "#     print(i[0])\n",
        "################################# TEST ########################################"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing cupy_dataset.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBOv_RiBsCWa"
      },
      "source": [
        "### PUI TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BME87CgGsFrd"
      },
      "source": [
        "# %%writefile cupy_dataset.py\n",
        "# import numba\n",
        "# from numba import cuda\n",
        "# import cupy\n",
        "# import numpy as np\n",
        "# import math\n",
        "# import time\n",
        "# import torch\n",
        "# cupy.cuda.set_allocator(None)\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# @cuda.jit\n",
        "# def single_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_STOCKS, s_curr):\n",
        "\n",
        "#     # ii - overall thread index\n",
        "#     ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "#     stride = cuda.gridDim.x * cuda.blockDim.x\n",
        "#     tmp2 = math.exp(-r*T)\n",
        "#     tmp3 = math.sqrt(T/N_STEPS)    \n",
        "\n",
        "#     for i in range(ii, N_PATHS, stride): # for each path          \n",
        "#         running_average = 0.0\n",
        "\n",
        "#         for j in range(N_STOCKS): # initialize S0\n",
        "#             s_curr[j] = S0[j]\n",
        "\n",
        "#         for n in range(N_STEPS): # for each step\n",
        "#             s_curr_avg = 0.0\n",
        "\n",
        "#             for j in range(N_STOCKS): # for each stock\n",
        "#                 tmp1 = mu[j]*T/N_STEPS  \n",
        "#                 s_curr[j] += tmp1 * s_curr[j] + sigma[j]*s_curr[j]*tmp3*d_normals[i,n,j]\n",
        "#                 s_curr_avg = s_curr_avg + 1.0/(j + 1.0) * (s_curr[j] - s_curr_avg) # S average in this step\n",
        "\n",
        "#             # add stock average to running average\n",
        "#             running_average = running_average + 1.0/(n + 1.0) * (s_curr_avg - running_average)\n",
        "\n",
        "#             # compare to barrier\n",
        "#             if running_average <= B:\n",
        "#                 break\n",
        "\n",
        "#         payoff = running_average - K if running_average > K else 0\n",
        "#         d_s[i] = tmp2 * payoff\n",
        "    \n",
        "\n",
        "# class NumbaOptionDataSet(object):\n",
        "    \n",
        "#     def __init__(self, max_len=10, number_path = 1000, number_stocks = 3, batch=1, threads=512, seed=15, T=1):\n",
        "#         self.num = 0\n",
        "#         self.max_length = max_len\n",
        "#         self.N_PATHS = number_path\n",
        "#         self.N_STEPS = 365\n",
        "#         self.N_STOCKS = number_stocks\n",
        "#         self.N_BATCH = batch\n",
        "#         self.T = np.float32(T)\n",
        "#         self.output = cupy.zeros(self.N_PATHS, dtype=cupy.float32) \n",
        "#         self.number_of_blocks = (self.N_PATHS * self.N_STOCKS - 1) // threads + 1\n",
        "#         self.number_of_threads = threads\n",
        "#         cupy.random.seed(seed)\n",
        "\n",
        "#         ############ <new\n",
        "#         self.Z_mean = cupy.zeros(self.N_STOCKS, dtype=cupy.float32)\n",
        "#         self.Z_cov = (-0.2 + cupy.random.rand(self.N_STOCKS*self.N_STOCKS, dtype=cupy.float32)*0.4).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "#         cupy.fill_diagonal(self.Z_cov, 1)\n",
        "#         ############ new>\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.max_length\n",
        "        \n",
        "#     def __iter__(self):\n",
        "#         self.num = 0\n",
        "#         return self\n",
        "    \n",
        "#     def __next__(self):\n",
        "#         if self.num > self.max_length:\n",
        "#             raise StopIteration\n",
        "\n",
        "#         X = cupy.zeros((self.N_BATCH, 3 + self.N_STOCKS * 3), dtype=cupy.float32)\n",
        "#         Y = cupy.zeros(self.N_BATCH, dtype=cupy.float32)\n",
        "\n",
        "#         for i in range(self.N_BATCH): # for each batch\n",
        "#           self.S0 = cupy.random.rand(self.N_STOCKS, dtype=cupy.float32) * 200\n",
        "#           self.K = 110.0\n",
        "#           self.B = 100.0\n",
        "#           self.sigma = cupy.random.rand(self.N_STOCKS, dtype=cupy.float32) * 0.2\n",
        "#           self.mu = cupy.random.rand(self.N_STOCKS, dtype=cupy.float32) * 0.2\n",
        "#           self.r = 0.05\n",
        "#           self.s_curr = cupy.zeros(self.N_STOCKS, dtype=cupy.float32) # used to store s_curr in kernel\n",
        "\n",
        "#           ############ <new - add correlation between stocks\n",
        "#           all_normals = cupy.random.multivariate_normal(self.Z_mean, self.Z_cov, (self.N_PATHS, self.N_STEPS), dtype=cupy.float32)\n",
        "#           ############ new>\n",
        "          \n",
        "#           single_barrier_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, self.T, self.K, self.B, self.S0, \n",
        "#                                                                                     self.sigma, self.mu, self.r, all_normals, self.N_STEPS, self.N_PATHS, self.N_STOCKS, self.s_curr)\n",
        "#           Y[i] = self.output.mean()\n",
        "\n",
        "#           ############ <new - combine to get X matrix\n",
        "#           X[i,:] = cupy.array([self.K, self.B] + self.S0.tolist() +\n",
        "#                                 self.sigma.tolist() + self.mu.tolist() + [self.r], dtype=cupy.float32)\n",
        "#           ############ new>\n",
        "        \n",
        "#         self.num += 1\n",
        "#         return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "# ds = NumbaOptionDataSet(max_len=10, number_path=100, batch=2, seed=15)\n",
        "# for i in ds:\n",
        "#   print(i)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2_89jOknwjH"
      },
      "source": [
        "### Model\n",
        "To map the option parameters to price, we use 6 layers of fully connected neural network with hidden dimension 512 as inspired by [this paper](https://arxiv.org/abs/1809.02233). Writing this DL price model into a file `model.py`:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cQt8PqinwjI"
      },
      "source": [
        "# %%writefile model.py\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import torch\n",
        "\n",
        "\n",
        "# class Net(nn.Module):\n",
        "\n",
        "#     def __init__(self, hidden=1024):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.fc1 = nn.Linear(6, hidden)\n",
        "#         self.fc2 = nn.Linear(hidden, hidden)\n",
        "#         self.fc3 = nn.Linear(hidden, hidden)\n",
        "#         self.fc4 = nn.Linear(hidden, hidden)\n",
        "#         self.fc5 = nn.Linear(hidden, hidden)\n",
        "#         self.fc6 = nn.Linear(hidden, 1)\n",
        "#         self.register_buffer('norm',\n",
        "#                              torch.tensor([200.0,\n",
        "#                                            198.0,\n",
        "#                                            200.0,\n",
        "#                                            0.4,\n",
        "#                                            0.2,\n",
        "#                                            0.2,]))\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # normalize the parameter to range [0-1] \n",
        "#         x = x / self.norm\n",
        "#         x = F.elu(self.fc1(x))\n",
        "#         x = F.elu(self.fc2(x))\n",
        "#         x = F.elu(self.fc3(x))\n",
        "#         x = F.elu(self.fc4(x))\n",
        "#         x = F.elu(self.fc5(x))\n",
        "#         return self.fc6(x)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMHqzJycx8XH"
      },
      "source": [
        "### Modified Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTn7iJQryAIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67d16730-3924-4051-a9a2-eb88180d111d"
      },
      "source": [
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(18, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 1)\n",
        "        self.register_buffer('norm', torch.tensor([200.0, 198.0, 200.0, 0.4, 0.2, 0.2] * 6))\n",
        "        # self.register_buffer('norm',\n",
        "        #                      torch.tensor([200.0, 198.0, 200.0, 0.4, 0.2, 0.2,\n",
        "        #                                    200.0, 198.0, 200.0, 0.4, 0.2, 0.2,\n",
        "        #                                    200.0, 198.0, 200.0, 0.4, 0.2, 0.2])) # don't use numpy here - will give error later\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting model.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSPRFqyznwjI"
      },
      "source": [
        "As we know the random parameters' scaling factors, the input parameters are first scaled back to a range of (0-1) by dividing them by (200.0, 198.0, 200.0, 0.4, 0.2, 0.2). Then they are projected 5 times to the hidden dimension of 512 after the `ELu` activation function. `ELu` is chosen because we need to compute the second order differentiation of the parameters. If use ReLu, the second order differentiation will always be zero. The last layer is a linear layer that maps the hidden dimension to the predicted option price. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM8J2liPnwjJ"
      },
      "source": [
        "For training, we use [Ignite](https://github.com/pytorch/ignite) which is a high-level library to train neural networks in PyTorch. We use `MSELoss` as the loss function, `Adam` as the optimizer and `CosineAnnealingScheduler` as the learning rate scheduler. The following code is feeding the random option data to the pricing model to train it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yACi4ge13_rd"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TyZT8_AH35M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37160741-79bc-4a06-a383-0b9a556d4a00"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/c3/f472843797b5ccbb2f0e806a6927f52c7c9522bfcea8e7e881d39258368b/pytorch_ignite-0.4.5-py3-none-any.whl (221kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 23.0MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 28.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 30kB 32.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 40kB 34.2MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 51kB 33.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 61kB 34.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 71kB 35.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 81kB 34.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 92kB 35.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 102kB 36.0MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 112kB 36.0MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 122kB 36.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 133kB 36.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 143kB 36.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 153kB 36.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 163kB 36.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 174kB 36.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 184kB 36.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 194kB 36.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 204kB 36.0MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 215kB 36.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 36.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Ej82G8nwjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1282dc48-65e0-41bc-f663-601f1d0c4909"
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import NumbaOptionDataSet\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "# dataset = NumbaOptionDataSet(max_len=100, number_path = 1024, batch=8, stocks=3)\n",
        "dataset = NumbaOptionDataSet(max_len=100, number_path = 1024, batch=10, stocks=3)\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred[:,0], y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 100\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value())\n",
        "        \n",
        "trainer.run(dataset, max_epochs=100)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss 429.3121032714844 average time 0.005109264370005349\n",
            "loss 268.0606384277344 average time 0.004697461300022496\n",
            "loss 72.69419860839844 average time 0.004790183280001656\n",
            "loss 118.10224914550781 average time 0.004846206399981838\n",
            "loss 136.30938720703125 average time 0.0047960454200006095\n",
            "loss 68.50856018066406 average time 0.0047902481499886565\n",
            "loss 120.22077941894531 average time 0.00493563585001084\n",
            "loss 151.65782165527344 average time 0.004895548729998609\n",
            "loss 69.19258880615234 average time 0.004999654200007626\n",
            "loss 116.73146057128906 average time 0.004971814939999604\n",
            "loss 182.6442108154297 average time 0.005003348110005845\n",
            "loss 172.07568359375 average time 0.004920107540001482\n",
            "loss 83.1666488647461 average time 0.004917029929995351\n",
            "loss 52.03811264038086 average time 0.004893031590006558\n",
            "loss 104.8680648803711 average time 0.004882041769997158\n",
            "loss 45.72146224975586 average time 0.004955011889994694\n",
            "loss 225.66250610351562 average time 0.004794967209986681\n",
            "loss 148.3410186767578 average time 0.004875677560005442\n",
            "loss 175.20884704589844 average time 0.004989051790007579\n",
            "loss 90.13277435302734 average time 0.00501925936002408\n",
            "loss 75.82722473144531 average time 0.0049569155299832345\n",
            "loss 91.57463073730469 average time 0.004872894650034141\n",
            "loss 105.90316009521484 average time 0.004850745319972702\n",
            "loss 41.402278900146484 average time 0.004905920329993024\n",
            "loss 116.45035552978516 average time 0.004862613419968511\n",
            "loss 59.586524963378906 average time 0.004813229250030418\n",
            "loss 197.66893005371094 average time 0.004919444340021073\n",
            "loss 113.4457015991211 average time 0.004831743479994657\n",
            "loss 122.97045135498047 average time 0.004882233039970743\n",
            "loss 148.5536651611328 average time 0.004893209000028946\n",
            "loss 148.8271484375 average time 0.004863815840030839\n",
            "loss 195.38677978515625 average time 0.004801479949992427\n",
            "loss 54.70500564575195 average time 0.004844225219981127\n",
            "loss 65.79725646972656 average time 0.00481006503000117\n",
            "loss 97.1707992553711 average time 0.00485310944997309\n",
            "loss 233.216796875 average time 0.005089290569990226\n",
            "loss 153.58030700683594 average time 0.005044545550008479\n",
            "loss 61.454627990722656 average time 0.00506451634998939\n",
            "loss 49.64054489135742 average time 0.005089094640015901\n",
            "loss 176.49827575683594 average time 0.005021477179984686\n",
            "loss 169.01768493652344 average time 0.004995277190023444\n",
            "loss 60.494300842285156 average time 0.004994829240013132\n",
            "loss 48.67232131958008 average time 0.005002646719999575\n",
            "loss 36.26953125 average time 0.004973941269977331\n",
            "loss 43.5953369140625 average time 0.0049710714599996205\n",
            "loss 44.04114532470703 average time 0.004940382209965719\n",
            "loss 24.4812068939209 average time 0.004964185129997531\n",
            "loss 13.866861343383789 average time 0.004926136710014362\n",
            "loss 21.335834503173828 average time 0.005039673429992036\n",
            "loss 11.968955993652344 average time 0.0049372253299952715\n",
            "loss 16.64473533630371 average time 0.0050077726800054735\n",
            "loss 8.21501636505127 average time 0.004936736009990454\n",
            "loss 19.44160270690918 average time 0.004978567530038162\n",
            "loss 13.569991111755371 average time 0.004930577980017006\n",
            "loss 9.468140602111816 average time 0.005051801500007969\n",
            "loss 5.981672763824463 average time 0.00504535197000223\n",
            "loss 4.2928147315979 average time 0.004985698340005911\n",
            "loss 7.259307861328125 average time 0.005023969460003172\n",
            "loss 6.443759918212891 average time 0.004939734599975054\n",
            "loss 9.21899700164795 average time 0.005002306660026079\n",
            "loss 9.357295036315918 average time 0.00492183941001258\n",
            "loss 19.342247009277344 average time 0.004967155969980013\n",
            "loss 8.137547492980957 average time 0.004955001390030702\n",
            "loss 15.22650146484375 average time 0.004918765249981334\n",
            "loss 6.899606227874756 average time 0.005014170719991853\n",
            "loss 7.998968601226807 average time 0.0051129860700029894\n",
            "loss 6.905844211578369 average time 0.005019885090005119\n",
            "loss 7.361332893371582 average time 0.005006630990010308\n",
            "loss 5.888904094696045 average time 0.005071947430024011\n",
            "loss 4.699662685394287 average time 0.004989473230007206\n",
            "loss 10.163060188293457 average time 0.005024382660008086\n",
            "loss 7.337663173675537 average time 0.005044363889965098\n",
            "loss 7.666507244110107 average time 0.005022268260004239\n",
            "loss 10.87409782409668 average time 0.004947798250000233\n",
            "loss 5.935073375701904 average time 0.0049728933799679\n",
            "loss 5.192002773284912 average time 0.004972190309972575\n",
            "loss 6.915050029754639 average time 0.005025974669983953\n",
            "loss 3.862436056137085 average time 0.005008424399966316\n",
            "loss 8.667876243591309 average time 0.004942363690011007\n",
            "loss 5.831428527832031 average time 0.004935390980012926\n",
            "loss 11.933523178100586 average time 0.0049121243100080396\n",
            "loss 7.2259840965271 average time 0.005031015940007819\n",
            "loss 9.779075622558594 average time 0.005017345379978905\n",
            "loss 3.50121808052063 average time 0.005000239810001404\n",
            "loss 7.053175449371338 average time 0.005018912600039584\n",
            "loss 8.525656700134277 average time 0.004923833140010174\n",
            "loss 4.832056999206543 average time 0.0049710301400045865\n",
            "loss 2.921863555908203 average time 0.005000471100015602\n",
            "loss 4.216065406799316 average time 0.00496614338002928\n",
            "loss 6.7292656898498535 average time 0.004970805250013655\n",
            "loss 5.440213203430176 average time 0.004966927339974063\n",
            "loss 6.064446926116943 average time 0.0050208959699966724\n",
            "loss 15.210309028625488 average time 0.005117753169993193\n",
            "loss 6.697686672210693 average time 0.0049180372499813526\n",
            "loss 5.753148078918457 average time 0.004913735840013942\n",
            "loss 5.414229869842529 average time 0.004910923900015404\n",
            "loss 9.24586009979248 average time 0.004861121359972458\n",
            "loss 2.576474905014038 average time 0.0049266051700442405\n",
            "loss 2.252312421798706 average time 0.004915857940022761\n",
            "loss 5.622444152832031 average time 0.004895819780026614\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 10000\n",
              "\tepoch: 100\n",
              "\tepoch_length: 100\n",
              "\tmax_epochs: 100\n",
              "\toutput: 5.622444152832031\n",
              "\tbatch: <class 'tuple'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: <class 'cupy_dataset.NumbaOptionDataSet'>\n",
              "\tseed: <class 'NoneType'>\n",
              "\ttimes: <class 'dict'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU1EpGuInwjJ"
      },
      "source": [
        "The loss is keeping decreasing which means the pricing model can predict the option prices better. It takes about $12ms$ to compute one mini-batch in average, In the following sections, we will try to expore the full potentials of the GPU to accelerate the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehmhDw8BUtLi"
      },
      "source": [
        "### Inference and Greeks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uiro43mOU0Ro"
      },
      "source": [
        "We can load the model parameters and use it to do inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svlu6tGTRx1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67a44c3d-f759-4d63-d3be-c025ea4e0d80"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "model(inputs.float())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[17.1461]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1Iy-9pWVRDO"
      },
      "source": [
        "One of the benefits of building a deep learning model is that the [Greeks](<https://en.wikipedia.org/wiki/Greeks_(finance)#First-order_Greeks>) can be easily computed. \n",
        "We just need to take advantage of the auto-grad feature in Pytorch. We can use `grad` function to compute the first order differentiation for parameters 'K, B, S0, sigma, mu, r'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytBZaYHKSnDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "293267b7-8105-4e6b-946e-bf39ef3125c4"
      },
      "source": [
        "inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.4782e-01, -1.4773e-02,  1.5972e-01,  4.5312e+00,  1.1895e+01,\n",
              "         -8.1477e+00, -2.0898e-01, -2.7671e-02,  2.2940e-01,  3.1936e+00,\n",
              "          1.0741e+01, -1.7567e+01, -1.8518e-01,  1.1177e-02,  1.9782e-01,\n",
              "          4.7921e+00,  1.3251e+01, -5.4986e+00]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KeijaDDVZGd"
      },
      "source": [
        "Here we are going to plot the Delta graph:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USh3qaADSYQp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "1adef402-5b6e-441c-8e54-177f1035ac62"
      },
      "source": [
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[110.0, 100.0, S, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "prices = np.arange(10, 300, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7bec33f610>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLO_5nEGVcEc"
      },
      "source": [
        "Calculating the second order derivative is easy in PyTorch too. We just need to apply the `grad` function twice. Use this mechanism, we can calculate the second order derivatives $\\frac{\\partial^2 P}{\\partial K \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial B \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial S_0^2}$, $\\frac{\\partial^2 P}{\\partial \\sigma \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial \\mu \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial r \\partial S_0}$ in the following example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGzj7A3sThZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65f58f0c-ba24-4df3-f565-e5484b78865e"
      },
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import grad\n",
        "from torch import nn\n",
        "\n",
        "inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs)\n",
        "\n",
        "# instead of using loss.backward(), use torch.autograd.grad() to compute gradients\n",
        "# https://pytorch.org/docs/stable/autograd.html#torch.autograd.grad\n",
        "loss_grads = grad(x, inputs, create_graph=True)\n",
        "drv = grad(loss_grads[0][0][2], inputs)\n",
        "drv"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-2.9503e-03, -1.4950e-04,  2.9872e-03, -3.3329e-03,  2.4572e-01,\n",
              "          -2.6549e-01,  2.3768e-04, -1.3733e-04, -2.8891e-04,  1.1860e-02,\n",
              "          -4.2475e-02, -6.6538e-03,  2.4919e-04, -2.0901e-04, -3.4583e-04,\n",
              "           8.0622e-03,  1.6289e-02, -8.9697e-03]], device='cuda:0'),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJbZYtvhVmSo"
      },
      "source": [
        "Gamma is the second order differenation of `S`. We can plot the the Gamma curve as a function of the stock price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JpQa3EJToA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "4e5d3d2b-0a2b-483e-a4ad-cb05b9ce3283"
      },
      "source": [
        "import pylab\n",
        "import numpy as np\n",
        "def compute_gamma(S):\n",
        "    inputs = torch.tensor([[110.0, 100.0, S, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    loss_grads = grad(x, inputs, create_graph=True)\n",
        "    drv = grad(loss_grads[0][0][2], inputs)\n",
        "    return drv[0][0][2]\n",
        "\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_gamma(p).item())\n",
        "fig2 = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Gamma')\n",
        "fig2"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f7bd3db67d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj7NlW6GVqSA"
      },
      "source": [
        "[Implied volatility](https://en.wikipedia.org/wiki/Implied_volatility) is the forecasted volatility of the underlying asset based on the quoted prices of the option. It is the reverse mapping of price to the option parameter given the model which is hard to do with the Monte Carlo simulation approach. But if we have the deep learning pricing model, it is an easy task. We can first plot the relationship between volatility and the option price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yrCw5UNT07t"
      },
      "source": [
        "import pylab\n",
        "import numpy as np\n",
        "def compute_price(sigma):\n",
        "    inputs = torch.tensor([[110.0, 100.0, 120.0, sigma, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    return x.item()\n",
        "sigmas = np.arange(0, 0.5, 0.1)\n",
        "prices = []\n",
        "for s in sigmas:\n",
        "    prices.append(compute_price(s))\n",
        "fig3 = pylab.plot(sigmas, prices)\n",
        "pylab.xlabel('Sigma')\n",
        "pylab.ylabel('Price')\n",
        "fig3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU25Cj29VtCa"
      },
      "source": [
        "Given the prices `P`, the implied volatility is the root of the function `compute_price`. We can use bisection to find the root."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddHnwm_zUBYD"
      },
      "source": [
        "def bisection_root(small, large, fun, target, EPS=1e-6):\n",
        "    if fun(large) - target < 0:\n",
        "        print('upper bound is too small')\n",
        "        return None\n",
        "    if fun(small) - target > 0:\n",
        "        print('lower bound is too large')\n",
        "        return None\n",
        "    while large - small > EPS:\n",
        "        mid = (large + small) / 2.0\n",
        "        if fun(mid) - target >= 0:\n",
        "            large = mid\n",
        "        else:\n",
        "            small = mid\n",
        "    mid = (large + small) / 2.0\n",
        "    return mid, abs(fun(mid) - target)\n",
        "quoted_price = 16.0\n",
        "sigma, err = bisection_root(0, 0.5, compute_price, quoted_price)\n",
        "print('implied volativity', sigma, 'error', err)     "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}