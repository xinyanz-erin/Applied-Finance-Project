{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "European_Call_jax.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Judy/1027_Judy_European_Jax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1RYKgBifCYw"
      },
      "source": [
        "# Test (Skip this if not trying to test, to make sure that functions are defined correctly in cells below without running this cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWYfON_marpj",
        "outputId": "2df807cc-1af0-4a8f-80c9-efdfdd6df03a"
      },
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T):\n",
        "  return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
        "\n",
        "numstocks = 3\n",
        "numsteps = 50\n",
        "numpaths = 100000\n",
        "\n",
        "rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.]*numstocks)\n",
        "r = drift\n",
        "cov = jnp.identity(numstocks)*0.25*0.25\n",
        "initial_stocks = jnp.array([100.]*numstocks) # must be float\n",
        "T = 1.0\n",
        "K = 110.0\n",
        "\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "keys = jax.random.split(key, numpaths)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "%timeit optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T)\n",
        "\n",
        "# delta test\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "%timeit goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.378865\n",
            "100 loops, best of 5: 7.59 ms per loop\n",
            "[0.09441341 0.0943141  0.09417713]\n",
            "10 loops, best of 5: 45.2 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxFUnc_iBVcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7506e7a2-46b3-4e4a-8b40-57b3ea0c4be9"
      },
      "source": [
        "%%writefile cupy_dataset.py\n",
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T, keys): # need to pass 'keys'\n",
        "    return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
        "\n",
        "###################################################################################################\n",
        "# these 2 functions must be defined outside class in order to be used in 'optionvalueavg' function\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "###################################################################################################\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len, number_path, batch, seed, stocks):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 50\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = 1.0 # assume T = 1, use float here\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros((self.N_BATCH, 1 + self.N_STOCKS), dtype=cupy.float32) # output: price, delta1, delta2, delta3\n",
        "        X = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "\n",
        "        for op in range(self.N_BATCH):\n",
        "          \n",
        "          rng = jax.random.PRNGKey(self.seed)\n",
        "          rng, key = jax.random.split(rng)\n",
        "\n",
        "          ################################################################################################### generate random input numbers\n",
        "\n",
        "          initial_stocks = jnp.array(np.random.random(self.N_STOCKS) * 10.0)\n",
        "\n",
        "          corr = jnp.diag(jnp.array([1]*self.N_STOCKS)) # assume no correlation between stocks here\n",
        "          sigma = jnp.array(np.random.random(self.N_STOCKS) * 0.3)\n",
        "          cov = (jnp.diag(sigma)).dot(corr).dot(jnp.diag(sigma))\n",
        "\n",
        "          r = jnp.repeat(jnp.array(np.random.random(1) * 0.1), self.N_STOCKS)\n",
        "          drift = jnp.array(np.random.random(self.N_STOCKS) * 0.1)\n",
        "\n",
        "          T = self.T\n",
        "          K = np.random.random(1) * 10.0\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### apply functions to compute price and deltas\n",
        "          \n",
        "          keys = jax.random.split(key, self.N_PATHS)\n",
        "\n",
        "          European_Call_price = optionvalueavg(key, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "          gooptionvalue = jax.grad(optionvalueavg, argnums=1)\n",
        "          Deltas = gooptionvalue(keys, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### store input and output numbers in X and Y\n",
        "\n",
        "          Y[op, 0] = European_Call_price\n",
        "          Y[op, 1:4] = cupy.array(Deltas, dtype=cupy.float32)\n",
        "\n",
        "          # T, K, S, sigma, mu, r\n",
        "          paras = (jnp.repeat(jnp.array(T), self.N_STOCKS), jnp.repeat(jnp.array(K), self.N_STOCKS), initial_stocks, sigma, drift, r)\n",
        "          paras = np.column_stack(paras).reshape(1,-1)[0]\n",
        "          X[op,] = cupy.array(paras)\n",
        "\n",
        "          ###################################################################################################\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "# ds = OptionDataSet(max_len = 2, number_path = 10000, batch = 2, seed = 15, stocks=3) # for testing purpose, use constant seed. When training, change to random seed\n",
        "# for i in ds:\n",
        "#     print(i)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cupy_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6JO9OBHdvv",
        "outputId": "ac3ca281-585d-4186-e06c-82cef8cbcb80"
      },
      "source": [
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*3, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 1) # 4 outputs: price, delta1, delta2, delta3\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1, 1.0, 1.0, 0.3, 0.1, 0.1]*3)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlXD80xPNVc6",
        "outputId": "14141307-da94-42c4-8b47-ba4b50c1ee5c"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 22.9 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 26.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 24.0 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 19.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 13.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S3CyULkENYKb",
        "outputId": "8dca17b4-6277-43d9-8191-c3602321a19b"
      },
      "source": [
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 1024, batch = 32, seed = np.random.randint(10000), stocks = 3) # must have random seed\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    # print(x)\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    y_pred = model(x)\n",
        "    # print(y_pred)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2,8,14]]\n",
        "\n",
        "    # print(torch.unbind(x))\n",
        "    # print([compute_deltas(x) for x in torch.unbind(x)])\n",
        "    # print(torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0))\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "    # print(y_pred)\n",
        "\n",
        "    loss_weight = 1/(y.mean(axis=0)**2)\n",
        "    # print(y.mean(axis=0))\n",
        "    # print((y.mean(axis=0)**2))\n",
        "    # print(1/(y.mean(axis=0)**2))\n",
        "    \n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    # print(loss_weight)\n",
        "    # print(loss_weight_normalized)\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean() # compute weighted MSE between the 2 arrays\n",
        "    # print((y_pred - y) ** 2)\n",
        "    # print((y_pred - y) ** 2 * loss_weight_normalized)\n",
        "    # print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output * 10000, 'average time', timer.value(), 'iter num', iter) # print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 62.85283714532852 average time 0.3371759483000005 iter num 20\n",
            "loss 29.766627121716738 average time 0.1931963503750012 iter num 40\n",
            "loss 19.74338898435235 average time 0.14513002846664827 iter num 60\n",
            "loss 13.059934135526419 average time 0.12134355134999168 iter num 80\n",
            "loss 8.015744388103485 average time 0.10729082889999063 iter num 100\n",
            "loss 7.934159366413951 average time 0.12018975800000362 iter num 20\n",
            "loss 5.782941589131951 average time 0.08521880077499873 iter num 40\n",
            "loss 8.659048471599817 average time 0.07341153380000758 iter num 60\n",
            "loss 7.262335857376456 average time 0.06701079847500183 iter num 80\n",
            "loss 4.9087259685620666 average time 0.06386421830999779 iter num 100\n",
            "loss 4.135486960876733 average time 0.11847400660000176 iter num 20\n",
            "loss 3.6153505789116025 average time 0.08358861020000745 iter num 40\n",
            "loss 2.1831812046002597 average time 0.07345936621668443 iter num 60\n",
            "loss 3.6939658457413316 average time 0.06702267298750542 iter num 80\n",
            "loss 5.405551055446267 average time 0.06319797211000605 iter num 100\n",
            "loss 4.122644895687699 average time 0.11747343544999467 iter num 20\n",
            "loss 3.1365518225356936 average time 0.08335347775001764 iter num 40\n",
            "loss 4.275630344636738 average time 0.07291814871667839 iter num 60\n",
            "loss 4.202952841296792 average time 0.06756389473750915 iter num 80\n",
            "loss 3.3035367960110307 average time 0.0637862784400022 iter num 100\n",
            "loss 2.717745373956859 average time 0.11894667809998509 iter num 20\n",
            "loss 1.5127009828574955 average time 0.08448452002497789 iter num 40\n",
            "loss 3.0884580337442458 average time 0.07305301286666387 iter num 60\n",
            "loss 1.476434408687055 average time 0.0672973776874926 iter num 80\n",
            "loss 2.0225095795467496 average time 0.0636534698899959 iter num 100\n",
            "loss 1.2378726387396455 average time 0.12064334315000451 iter num 20\n",
            "loss 1.3884455256629735 average time 0.08575184225001067 iter num 40\n",
            "loss 2.454074565321207 average time 0.07382692620000171 iter num 60\n",
            "loss 2.181727468268946 average time 0.06748858711249284 iter num 80\n",
            "loss 3.523944178596139 average time 0.06382326523999154 iter num 100\n",
            "loss 1.8154957797378302 average time 0.11773069880002822 iter num 20\n",
            "loss 2.1898151317145675 average time 0.08381313375002719 iter num 40\n",
            "loss 2.1820294205099344 average time 0.07207643746668282 iter num 60\n",
            "loss 1.8579760217107832 average time 0.06672863017501811 iter num 80\n",
            "loss 2.9975484358146787 average time 0.06342632436001396 iter num 100\n",
            "loss 2.4559395387768745 average time 0.11985158394998052 iter num 20\n",
            "loss 2.9045154224149883 average time 0.08503619832498543 iter num 40\n",
            "loss 2.177780552301556 average time 0.07343768108332066 iter num 60\n",
            "loss 1.6855841386131942 average time 0.06746305458748339 iter num 80\n",
            "loss 0.8486732258461416 average time 0.06410454541999115 iter num 100\n",
            "loss 2.2001683828420937 average time 0.12130051359995378 iter num 20\n",
            "loss 0.9708749712444842 average time 0.08554780777499219 iter num 40\n",
            "loss 2.016084181377664 average time 0.07357011580002108 iter num 60\n",
            "loss 1.6938152839429677 average time 0.06740310143753163 iter num 80\n",
            "loss 3.1723224674351513 average time 0.06342814183002247 iter num 100\n",
            "loss 1.7463101539760828 average time 0.12083016494996172 iter num 20\n",
            "loss 2.0989193581044674 average time 0.08462524024995446 iter num 40\n",
            "loss 1.0526851110626012 average time 0.07251126119996722 iter num 60\n",
            "loss 1.533656904939562 average time 0.06708593598748394 iter num 80\n",
            "loss 1.3258602120913565 average time 0.06353366941999866 iter num 100\n",
            "loss 2.812021702993661 average time 0.1213310422500399 iter num 20\n",
            "loss 2.7791428146883845 average time 0.08553207977505509 iter num 40\n",
            "loss 1.7453497275710106 average time 0.07238594898336335 iter num 60\n",
            "loss 1.006492238957435 average time 0.06629408266250607 iter num 80\n",
            "loss 1.180479594040662 average time 0.06322887005001121 iter num 100\n",
            "loss 1.5906697080936283 average time 0.12202221995000855 iter num 20\n",
            "loss 1.320283190580085 average time 0.08667192250002245 iter num 40\n",
            "loss 1.0171294707106426 average time 0.07496700210002322 iter num 60\n",
            "loss 0.8052459452301264 average time 0.06927453951248594 iter num 80\n",
            "loss 0.8017505024326965 average time 0.06550915152997731 iter num 100\n",
            "loss 2.1354772616177797 average time 0.12075369820008745 iter num 20\n",
            "loss 1.7961781122721732 average time 0.0860761056750448 iter num 40\n",
            "loss 2.7937916456721723 average time 0.07444316850004119 iter num 60\n",
            "loss 0.49857735575642437 average time 0.0682541100500373 iter num 80\n",
            "loss 0.6638452032348141 average time 0.06439807004002887 iter num 100\n",
            "loss 2.124414313584566 average time 0.12336365209994256 iter num 20\n",
            "loss 1.4010051381774247 average time 0.08646055332496871 iter num 40\n",
            "loss 1.1923802958335727 average time 0.07429585369997464 iter num 60\n",
            "loss 0.8018212247407064 average time 0.06753930857497607 iter num 80\n",
            "loss 2.9636919498443604 average time 0.06420306907997202 iter num 100\n",
            "loss 1.1695660941768438 average time 0.12240994649994263 iter num 20\n",
            "loss 1.250901259481907 average time 0.08711691692495833 iter num 40\n",
            "loss 1.8730448209680617 average time 0.07520946379998653 iter num 60\n",
            "loss 2.0458090875763446 average time 0.06846772116250577 iter num 80\n",
            "loss 0.7363673648796976 average time 0.06486908657000186 iter num 100\n",
            "loss 0.7060145435389131 average time 0.1206103710000889 iter num 20\n",
            "loss 0.7631978951394558 average time 0.08458959882508452 iter num 40\n",
            "loss 0.7887036917963997 average time 0.07318051083338256 iter num 60\n",
            "loss 2.0503922132775187 average time 0.06763553477501887 iter num 80\n",
            "loss 0.8568809425923973 average time 0.0638295455600246 iter num 100\n",
            "loss 1.3299052079673856 average time 0.1175532865000605 iter num 20\n",
            "loss 1.0813237895490602 average time 0.0830653064750095 iter num 40\n",
            "loss 1.1660381278488785 average time 0.07279188898332904 iter num 60\n",
            "loss 0.5528025212697685 average time 0.06655479253748808 iter num 80\n",
            "loss 1.311596715822816 average time 0.06291519666998738 iter num 100\n",
            "loss 1.504394313087687 average time 0.1202346684500526 iter num 20\n",
            "loss 0.6550775287905708 average time 0.0847631366250198 iter num 40\n",
            "loss 1.7656598356552422 average time 0.0725191274833378 iter num 60\n",
            "loss 1.692626829026267 average time 0.06650521903750359 iter num 80\n",
            "loss 2.459692768752575 average time 0.06285861599000327 iter num 100\n",
            "loss 1.1604050087044016 average time 0.11792425340004228 iter num 20\n",
            "loss 1.2511367094703019 average time 0.08323738335001281 iter num 40\n",
            "loss 1.2264007818885148 average time 0.07190041833332543 iter num 60\n",
            "loss 0.6061353633413091 average time 0.06725269766249084 iter num 80\n",
            "loss 0.8410170266870409 average time 0.06413707879999038 iter num 100\n",
            "loss 0.3470612136879936 average time 0.12286661405003088 iter num 20\n",
            "loss 0.4115800402360037 average time 0.08605733567501375 iter num 40\n",
            "loss 0.8758646436035633 average time 0.0734306423666491 iter num 60\n",
            "loss 1.979664375539869 average time 0.06753059746251892 iter num 80\n",
            "loss 0.36319452192401513 average time 0.06395311347001552 iter num 100\n",
            "loss 1.435607555322349 average time 0.11953959864997614 iter num 20\n",
            "loss 0.8804096432868391 average time 0.08436575094998489 iter num 40\n",
            "loss 1.653411891311407 average time 0.07257982436664558 iter num 60\n",
            "loss 1.213581272168085 average time 0.06722426031248574 iter num 80\n",
            "loss 0.5577427509706467 average time 0.06402961095999217 iter num 100\n",
            "loss 0.39569789805682376 average time 0.11776121385005353 iter num 20\n",
            "loss 0.4305020047468133 average time 0.0837635219750382 iter num 40\n",
            "loss 0.7561034726677462 average time 0.07226629245001277 iter num 60\n",
            "loss 0.6783378194086254 average time 0.06658421849998604 iter num 80\n",
            "loss 1.6408714873250574 average time 0.06319582593998348 iter num 100\n",
            "loss 0.8343980880454183 average time 0.11972070544993585 iter num 20\n",
            "loss 0.7771706441417336 average time 0.08393203612497473 iter num 40\n",
            "loss 1.7705056234262884 average time 0.07221671919995364 iter num 60\n",
            "loss 0.45698980102315545 average time 0.06657534026247731 iter num 80\n",
            "loss 1.949761644937098 average time 0.0635619899199628 iter num 100\n",
            "loss 0.8703531057108194 average time 0.12150971244996071 iter num 20\n",
            "loss 0.431115367973689 average time 0.08641831167492456 iter num 40\n",
            "loss 1.5576285659335554 average time 0.07340745944999677 iter num 60\n",
            "loss 2.2392181563191116 average time 0.06816466047498579 iter num 80\n",
            "loss 0.9358342504128814 average time 0.06420301474000553 iter num 100\n",
            "loss 0.6541037873830646 average time 0.1182624397001291 iter num 20\n",
            "loss 0.6711644527968019 average time 0.0828587305250494 iter num 40\n",
            "loss 2.6465277187526226 average time 0.07233293650003057 iter num 60\n",
            "loss 0.800734487711452 average time 0.06629211703751707 iter num 80\n",
            "loss 1.153031043941155 average time 0.06304917756999202 iter num 100\n",
            "loss 1.1168514902237803 average time 0.11837028919985641 iter num 20\n",
            "loss 1.360980240860954 average time 0.08368547612490147 iter num 40\n",
            "loss 0.7722935697529465 average time 0.07252367594990877 iter num 60\n",
            "loss 0.7727197225904092 average time 0.06639085892492176 iter num 80\n",
            "loss 0.3735705467988737 average time 0.06289880826991066 iter num 100\n",
            "loss 1.4557990652974695 average time 0.11833335500014072 iter num 20\n",
            "loss 0.6960709288250655 average time 0.08433899437509354 iter num 40\n",
            "loss 0.7852396811358631 average time 0.07251026288337623 iter num 60\n",
            "loss 0.34231368772452697 average time 0.06676422008757754 iter num 80\n",
            "loss 0.8033172343857586 average time 0.06360785558007592 iter num 100\n",
            "loss 0.9122307528741658 average time 0.12069584669989127 iter num 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c8c30e4018d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     85\u001b[0m           \u001b[0mEuropean_Call_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptionvalueavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m           \u001b[0mgooptionvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptionvalueavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m           \u001b[0mDeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgooptionvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m           \u001b[0;31m###################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mgrad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mapi_boundary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgrad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_and_grad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mvalue_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0m_check_input_dtype_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholomorphic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_py\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdyn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       ans, vjp_py, aux = _vjp(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, reduce_axes, *primals)\u001b[0m\n\u001b[1;32m   2144\u001b[0m     \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun_nokwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m     out_primal, out_vjp = ad.vjp(\n\u001b[0;32m-> 2146\u001b[0;31m         flat_fun, primals_flat, reduce_axes=reduce_axes)\n\u001b[0m\u001b[1;32m   2147\u001b[0m     \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux, reduce_axes)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m   \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tangents_pvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_primal_pval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout_primal_pval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    506\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJaxprTrace\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m     \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36moptionvalueavg\u001b[0;34m(key, initial_stocks, numsteps, drift, r, cov, K, T, keys)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moptionvalueavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m###################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices)\u001b[0m\n\u001b[1;32m   5653\u001b[0m   \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_index_for_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5654\u001b[0m   return _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[0;32m-> 5655\u001b[0;31m                  unique_indices)\n\u001b[0m\u001b[1;32m   5656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5657\u001b[0m \u001b[0;31m# TODO(phawkins): re-enable jit after fixing excessive recompilation for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices)\u001b[0m\n\u001b[1;32m   5661\u001b[0m             unique_indices):\n\u001b[1;32m   5662\u001b[0m   \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_merge_static_and_dynamic_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5663\u001b[0;31m   \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_index_to_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shared with _scatter_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5664\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_index_to_gather\u001b[0;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[1;32m   5852\u001b[0m         \u001b[0;31m# XLA gives error when indexing into an axis of size 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5853\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"index is out of bounds for axis {x_axis} with size 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5854\u001b[0;31m       \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnormalize_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5855\u001b[0m       \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_element_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5856\u001b[0m       \u001b[0mgather_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgather_indices_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_normalize_index\u001b[0;34m(index, axis_size)\u001b[0m\n\u001b[1;32m   5437\u001b[0m     \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_constant_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5438\u001b[0m     \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_size_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5439\u001b[0;31m     index)\n\u001b[0m\u001b[1;32m   5440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5441\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_wraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_along_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_doc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(pred, on_true, on_false)\u001b[0m\n\u001b[1;32m    841\u001b[0m   \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m   \"\"\"\n\u001b[0;32m--> 843\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mselect_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_false\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m def slice(operand: Array, start_indices: Sequence[int],\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         args, used_axis_names(self, params) if self._dispatch_on_params else None)\n\u001b[1;32m    266\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    274\u001b[0m   \u001b[0;34m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m   \u001b[0mcompiled_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxla_primitive_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0munsafe_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled_primitive\u001b[0;34m(prim, compiled, result_handler, *args)\u001b[0m\n\u001b[1;32m    390\u001b[0m   \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m   \u001b[0minput_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_put\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m   \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e3d117-c8db-4728-b40d-b649b4b470ca"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_test_2.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Judy/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75ddae46-6ceb-410c-d9d5-10e1c71b9538"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40eeb0c8-3def-4d04-d34a-b54f17ad1ea8"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_test_2.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Judy/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67f9d034-4096-48d5-b2e5-a88f3a733d2a"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=18, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc5): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc6): Linear(in_features=1024, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b73f3581-d3b3-427a-cc5d-0e1d9e139808"
      },
      "source": [
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "#dataset = OptionDataSet(max_len = 100, number_path = 1024, batch = 32, seed = np.random.randint(10000), stocks = 3) # must have random seed\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 100000, batch = 8, seed = np.random.randint(10000), stocks = 3) # must have random seed\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    # print(x)\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    y_pred = model(x)\n",
        "    # print(y_pred)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2,8,14]]\n",
        "\n",
        "    # print(torch.unbind(x))\n",
        "    # print([compute_deltas(x) for x in torch.unbind(x)])\n",
        "    # print(torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0))\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "    # print(y_pred)\n",
        "\n",
        "    loss_weight = 1/(y.mean(axis=0)**2)\n",
        "    # print(y.mean(axis=0))\n",
        "    # print((y.mean(axis=0)**2))\n",
        "    # print(1/(y.mean(axis=0)**2))\n",
        "    \n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    # print(loss_weight)\n",
        "    # print(loss_weight_normalized)\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean() # compute weighted MSE between the 2 arrays\n",
        "    # print((y_pred - y) ** 2)\n",
        "    # print((y_pred - y) ** 2 * loss_weight_normalized)\n",
        "    # print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 10\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output * 10000, 'average time', timer.value(), 'iter num', iter) # print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 50)\n",
        "\n",
        "model_save_name = 'jax_european_test_3.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 15.717815840616822 average time 0.19071597360016312 iter num 10\n",
            "loss 18.05482665076852 average time 0.103503191450136 iter num 20\n",
            "loss 4.709016066044569 average time 0.07433077916675757 iter num 30\n",
            "loss 1.3023313658777624 average time 0.0597561436500655 iter num 40\n",
            "loss 1.557377545395866 average time 0.051512649780070204 iter num 50\n",
            "loss 2.7776064234785736 average time 0.0456800497833683 iter num 60\n",
            "loss 0.6010754441376776 average time 0.04130442325717273 iter num 70\n",
            "loss 0.3037628448510077 average time 0.03814848525004209 iter num 80\n",
            "loss 3.414661332499236 average time 0.03562231491117321 iter num 90\n",
            "loss 0.9597632015356794 average time 0.033724988800040594 iter num 100\n",
            "loss 3.0150607926771045 average time 0.08022687010006849 iter num 10\n",
            "loss 3.517350705806166 average time 0.048253943050031015 iter num 20\n",
            "loss 3.7684536073356867 average time 0.03737538133333752 iter num 30\n",
            "loss 4.602020489983261 average time 0.03210902810001244 iter num 40\n",
            "loss 1.031756546581164 average time 0.02885546069999691 iter num 50\n",
            "loss 0.3087309960392304 average time 0.02701959226665167 iter num 60\n",
            "loss 1.296802656725049 average time 0.025424342314272506 iter num 70\n",
            "loss 0.614802775089629 average time 0.024399977187476905 iter num 80\n",
            "loss 0.5723767390009016 average time 0.02350077406664342 iter num 90\n",
            "loss 0.7133177132345736 average time 0.02285491322996677 iter num 100\n",
            "loss 1.0259775444865227 average time 0.0800978751999537 iter num 10\n",
            "loss 1.1729531979653984 average time 0.04779778904990053 iter num 20\n",
            "loss 0.9648891864344478 average time 0.03735987959992902 iter num 30\n",
            "loss 0.4878534673480317 average time 0.03206952984990039 iter num 40\n",
            "loss 3.6625168286263943 average time 0.028716463779910554 iter num 50\n",
            "loss 0.5215487908571959 average time 0.026727845866571443 iter num 60\n",
            "loss 0.5932800559094176 average time 0.025200040914218593 iter num 70\n",
            "loss 0.3325301076984033 average time 0.02391472653742994 iter num 80\n",
            "loss 0.9674687316874042 average time 0.022994069988827606 iter num 90\n",
            "loss 0.3901749732904136 average time 0.02228910831993744 iter num 100\n",
            "loss 0.7778590952511877 average time 0.08087285149986201 iter num 10\n",
            "loss 1.3796507846564054 average time 0.04851830704997155 iter num 20\n",
            "loss 3.5644107265397906 average time 0.03766615600003812 iter num 30\n",
            "loss 1.7035551718436182 average time 0.032074089925026784 iter num 40\n",
            "loss 3.057410358451307 average time 0.02890209437999147 iter num 50\n",
            "loss 2.5612118770368397 average time 0.026577782999978202 iter num 60\n",
            "loss 0.1824588980525732 average time 0.025148519699983548 iter num 70\n",
            "loss 1.9328307826071978 average time 0.02418028373749621 iter num 80\n",
            "loss 0.4258292756276205 average time 0.02335649798889992 iter num 90\n",
            "loss 1.4237445429898798 average time 0.022638435610006127 iter num 100\n",
            "loss 2.046161680482328 average time 0.08036305749992607 iter num 10\n",
            "loss 5.270909168757498 average time 0.04833541184993919 iter num 20\n",
            "loss 5.315074813552201 average time 0.037095338333286536 iter num 30\n",
            "loss 1.7081585247069597 average time 0.03216412109995872 iter num 40\n",
            "loss 2.1037558326497674 average time 0.028640657179948903 iter num 50\n",
            "loss 1.1512298078741878 average time 0.02650803161662528 iter num 60\n",
            "loss 1.4567020116373897 average time 0.025060333028561997 iter num 70\n",
            "loss 1.4366493269335479 average time 0.023889387475003333 iter num 80\n",
            "loss 2.129978674929589 average time 0.022939123422232418 iter num 90\n",
            "loss 0.47970141167752445 average time 0.022184259180012305 iter num 100\n",
            "loss 0.8514680666849017 average time 0.08203476720000254 iter num 10\n",
            "loss 2.8388749342411757 average time 0.048835171050041024 iter num 20\n",
            "loss 5.464768037199974 average time 0.03791324673335718 iter num 30\n",
            "loss 1.6021751798689365 average time 0.032315886900073566 iter num 40\n",
            "loss 0.5024024721933529 average time 0.02891698390005331 iter num 50\n",
            "loss 0.2975638199131936 average time 0.026588378216714167 iter num 60\n",
            "loss 0.46018449211260304 average time 0.025130279814311506 iter num 70\n",
            "loss 0.6876639963593334 average time 0.02405197933751424 iter num 80\n",
            "loss 1.2206730752950534 average time 0.02316298310000396 iter num 90\n",
            "loss 0.1800902646209579 average time 0.022483888820006542 iter num 100\n",
            "loss 0.23961089027579874 average time 0.07987888490006298 iter num 10\n",
            "loss 0.5101414717501029 average time 0.04780807024999376 iter num 20\n",
            "loss 1.4436113997362554 average time 0.037597946433318916 iter num 30\n",
            "loss 1.2662369408644736 average time 0.03214821422498062 iter num 40\n",
            "loss 1.3828277587890625 average time 0.02888983759998155 iter num 50\n",
            "loss 0.7758173160254955 average time 0.026633606583300207 iter num 60\n",
            "loss 0.19397997675696388 average time 0.02497372359999385 iter num 70\n",
            "loss 0.17438736904296093 average time 0.02383057541250082 iter num 80\n",
            "loss 0.1743198481563013 average time 0.023066223533310726 iter num 90\n",
            "loss 0.6586407107533887 average time 0.022489567200000237 iter num 100\n",
            "loss 0.49161797505803406 average time 0.08050881090002804 iter num 10\n",
            "loss 0.18051121514872648 average time 0.047844241150050947 iter num 20\n",
            "loss 0.2718815812841058 average time 0.037411257533343206 iter num 30\n",
            "loss 1.1491563054732978 average time 0.03199031847493643 iter num 40\n",
            "loss 0.7975156768225133 average time 0.02871028405996185 iter num 50\n",
            "loss 2.338211052119732 average time 0.026621779699962645 iter num 60\n",
            "loss 0.34297296224394813 average time 0.02531922708568735 iter num 70\n",
            "loss 0.18701724911807105 average time 0.024335780787498606 iter num 80\n",
            "loss 0.39845952414907515 average time 0.023593144411117668 iter num 90\n",
            "loss 0.5748964758822694 average time 0.022827042560002155 iter num 100\n",
            "loss 1.7272995319217443 average time 0.07648932250021971 iter num 10\n",
            "loss 1.314133987762034 average time 0.04687857230010195 iter num 20\n",
            "loss 0.7051891589071602 average time 0.036421494166734195 iter num 30\n",
            "loss 1.1363661178620532 average time 0.03130725870009883 iter num 40\n",
            "loss 0.678517171763815 average time 0.028505281020061377 iter num 50\n",
            "loss 0.5903756391489878 average time 0.02653279615002854 iter num 60\n",
            "loss 0.7725381874479353 average time 0.02495470068572883 iter num 70\n",
            "loss 1.5129614621400833 average time 0.02381051318752725 iter num 80\n",
            "loss 0.9058487194124609 average time 0.022826670866682736 iter num 90\n",
            "loss 0.4164565325481817 average time 0.02212508264002281 iter num 100\n",
            "loss 1.091083831852302 average time 0.07833876520007835 iter num 10\n",
            "loss 2.288206305820495 average time 0.047192771800064294 iter num 20\n",
            "loss 7.350884843617678 average time 0.03641767590003534 iter num 30\n",
            "loss 10.252178180962801 average time 0.031122256150069916 iter num 40\n",
            "loss 7.426957017742097 average time 0.02773045728004945 iter num 50\n",
            "loss 3.3881986746564507 average time 0.02567871898334791 iter num 60\n",
            "loss 3.0095945112407207 average time 0.0241979185571576 iter num 70\n",
            "loss 0.7727844058535993 average time 0.023174738187503863 iter num 80\n",
            "loss 1.6568823775742203 average time 0.022632261744436416 iter num 90\n",
            "loss 1.0954297613352537 average time 0.021946118219993878 iter num 100\n",
            "loss 1.439415500499308 average time 0.07792829420004636 iter num 10\n",
            "loss 1.023102959152311 average time 0.046670676850044404 iter num 20\n",
            "loss 4.863985814154148 average time 0.03606367743338221 iter num 30\n",
            "loss 0.8566623728256673 average time 0.031131154625018097 iter num 40\n",
            "loss 12.479700380936265 average time 0.027846458060048464 iter num 50\n",
            "loss 17.05300062894821 average time 0.02576305600005071 iter num 60\n",
            "loss 5.7091639610007405 average time 0.024368639185753896 iter num 70\n",
            "loss 1.4187587657943368 average time 0.023319567537578224 iter num 80\n",
            "loss 0.980952027020976 average time 0.022492696033390935 iter num 90\n",
            "loss 2.1259811182972044 average time 0.02177803728004619 iter num 100\n",
            "loss 19.72666010260582 average time 0.07905998389996967 iter num 10\n",
            "loss 2.9017357155680656 average time 0.047155498449956215 iter num 20\n",
            "loss 27.768556028604507 average time 0.037242982166662844 iter num 30\n",
            "loss 14.296916779130697 average time 0.03156305999993947 iter num 40\n",
            "loss 20.51163697615266 average time 0.028469186139973318 iter num 50\n",
            "loss 9.138183668255806 average time 0.026522964449941355 iter num 60\n",
            "loss 1.864411897258833 average time 0.024827784957103305 iter num 70\n",
            "loss 2.245839568786323 average time 0.023704534137471 iter num 80\n",
            "loss 2.1666279644705355 average time 0.022743768822187524 iter num 90\n",
            "loss 2.1199724869802594 average time 0.022039205839955684 iter num 100\n",
            "loss 2.8645701240748167 average time 0.08095846779988278 iter num 10\n",
            "loss 8.565110038034618 average time 0.048084703949962206 iter num 20\n",
            "loss 5.111950449645519 average time 0.037157361066662516 iter num 30\n",
            "loss 2.936100645456463 average time 0.0319617470500134 iter num 40\n",
            "loss 3.1852370011620224 average time 0.028605851719985368 iter num 50\n",
            "loss 0.8701150363776833 average time 0.026436942800000907 iter num 60\n",
            "loss 1.759166771080345 average time 0.024831248228552535 iter num 70\n",
            "loss 1.3112051237840205 average time 0.023671688224987976 iter num 80\n",
            "loss 0.7385920616798103 average time 0.022755781211081842 iter num 90\n",
            "loss 1.7105325241573155 average time 0.02194644307997805 iter num 100\n",
            "loss 1.1475829523988068 average time 0.0768437930998516 iter num 10\n",
            "loss 1.777456927811727 average time 0.04661338849996355 iter num 20\n",
            "loss 1.0734630632214248 average time 0.03640739026656471 iter num 30\n",
            "loss 0.279979249171447 average time 0.03126739814993016 iter num 40\n",
            "loss 1.7881106759887189 average time 0.02817613025998071 iter num 50\n",
            "loss 0.5829742440255359 average time 0.026013631883339865 iter num 60\n",
            "loss 0.9817294630920514 average time 0.024476815014272037 iter num 70\n",
            "loss 1.8563566845841706 average time 0.023352449887488545 iter num 80\n",
            "loss 0.7935528992675245 average time 0.02245763712221055 iter num 90\n",
            "loss 2.934748772531748 average time 0.021843241809992833 iter num 100\n",
            "loss 1.3962792581878603 average time 0.08040314289992238 iter num 10\n",
            "loss 0.9195120219374076 average time 0.04801437174992316 iter num 20\n",
            "loss 1.9143402460031211 average time 0.03713336523326992 iter num 30\n",
            "loss 2.4658965412527323 average time 0.03175609472493761 iter num 40\n",
            "loss 0.27136411517858505 average time 0.028468548559976624 iter num 50\n",
            "loss 1.168852104456164 average time 0.026446052383334973 iter num 60\n",
            "loss 1.3910063717048615 average time 0.024969586499979154 iter num 70\n",
            "loss 0.6619764462811872 average time 0.023677386112467502 iter num 80\n",
            "loss 1.6223806596826762 average time 0.02290184267772525 iter num 90\n",
            "loss 0.5527897155843675 average time 0.022203715219939114 iter num 100\n",
            "loss 0.3722279507201165 average time 0.08145900849985992 iter num 10\n",
            "loss 0.8156751573551446 average time 0.04853045314985138 iter num 20\n",
            "loss 1.672945509199053 average time 0.03770696839995556 iter num 30\n",
            "loss 1.4838305651210248 average time 0.03223436347498136 iter num 40\n",
            "loss 1.2562339543364942 average time 0.02876094313996873 iter num 50\n",
            "loss 0.7036221359157935 average time 0.026583587199941878 iter num 60\n",
            "loss 1.6460921324323863 average time 0.025039295628526557 iter num 70\n",
            "loss 1.9862872431986034 average time 0.02386490829998138 iter num 80\n",
            "loss 2.4277533520944417 average time 0.02291288993333688 iter num 90\n",
            "loss 0.8448988955933601 average time 0.022176297830010298 iter num 100\n",
            "loss 1.4342313806992024 average time 0.08011011269991286 iter num 10\n",
            "loss 1.800259342417121 average time 0.04801342034993468 iter num 20\n",
            "loss 1.03504178696312 average time 0.037451231499926504 iter num 30\n",
            "loss 1.2029924255330116 average time 0.032221673349954474 iter num 40\n",
            "loss 0.5055971996625885 average time 0.029111530680002034 iter num 50\n",
            "loss 0.5721529669244774 average time 0.026744874700019256 iter num 60\n",
            "loss 0.42976258555427194 average time 0.02517087121428371 iter num 70\n",
            "loss 0.5147781121195294 average time 0.023818589799998336 iter num 80\n",
            "loss 1.1147956683998927 average time 0.022931265355550245 iter num 90\n",
            "loss 0.5791465446236543 average time 0.022287779579974087 iter num 100\n",
            "loss 1.4684782945550978 average time 0.07758655729985549 iter num 10\n",
            "loss 0.41258696001023054 average time 0.04638459834986861 iter num 20\n",
            "loss 0.6938932347111404 average time 0.03614741213329277 iter num 30\n",
            "loss 0.4447476749191992 average time 0.03120607042494612 iter num 40\n",
            "loss 8.954262011684477 average time 0.0280973993799671 iter num 50\n",
            "loss 1.1207976058358327 average time 0.02579339653329953 iter num 60\n",
            "loss 1.3612592010758817 average time 0.02431475717142218 iter num 70\n",
            "loss 0.33452921343268827 average time 0.023313174800000523 iter num 80\n",
            "loss 0.6275176565395668 average time 0.02249984801111269 iter num 90\n",
            "loss 1.2991484254598618 average time 0.02175054302000717 iter num 100\n",
            "loss 5.385551485233009 average time 0.07828756869994322 iter num 10\n",
            "loss 0.9191879507852718 average time 0.0468828832500094 iter num 20\n",
            "loss 1.5109821106307209 average time 0.035962219433319356 iter num 30\n",
            "loss 1.1583951709326357 average time 0.03078659307500402 iter num 40\n",
            "loss 2.2607232676818967 average time 0.02820357734000936 iter num 50\n",
            "loss 0.7434459985233843 average time 0.026076516116654604 iter num 60\n",
            "loss 1.388062519254163 average time 0.02451831558568561 iter num 70\n",
            "loss 0.401744109694846 average time 0.023428840849976495 iter num 80\n",
            "loss 0.1737688398861792 average time 0.022676114744434824 iter num 90\n",
            "loss 0.46766534069320187 average time 0.02196658328997728 iter num 100\n",
            "loss 0.9231162403011695 average time 0.07686465409997253 iter num 10\n",
            "loss 0.5503204738488421 average time 0.046319030549966556 iter num 20\n",
            "loss 0.9225262328982353 average time 0.035981888633280806 iter num 30\n",
            "loss 0.6539007881656289 average time 0.030615133099922788 iter num 40\n",
            "loss 1.3170173042453825 average time 0.027702466199934862 iter num 50\n",
            "loss 1.060606591636315 average time 0.02545875186660851 iter num 60\n",
            "loss 0.8764266385696828 average time 0.02409114758564621 iter num 70\n",
            "loss 0.7203487621154636 average time 0.02300430848746373 iter num 80\n",
            "loss 1.1955174704780802 average time 0.022208961811065818 iter num 90\n",
            "loss 1.7894647317007184 average time 0.0215173257299557 iter num 100\n",
            "loss 0.3965378346038051 average time 0.07810375129975 iter num 10\n",
            "loss 0.1721008084132336 average time 0.04637721094986773 iter num 20\n",
            "loss 0.7588752487208694 average time 0.03557066603316343 iter num 30\n",
            "loss 2.7802385739050806 average time 0.030729275899898312 iter num 40\n",
            "loss 3.0107313068583608 average time 0.027422573619915055 iter num 50\n",
            "loss 1.9225932192057371 average time 0.025362859766619294 iter num 60\n",
            "loss 0.5547386535909027 average time 0.023915729828513577 iter num 70\n",
            "loss 1.7190317157655954 average time 0.022784204587446767 iter num 80\n",
            "loss 2.0052751642651856 average time 0.021964868188853064 iter num 90\n",
            "loss 0.6280128582147881 average time 0.02136850488995151 iter num 100\n",
            "loss 2.2451230324804783 average time 0.07916501890003928 iter num 10\n",
            "loss 0.4098891804460436 average time 0.04684268360006172 iter num 20\n",
            "loss 1.3125130499247462 average time 0.03609691483340308 iter num 30\n",
            "loss 0.290695606963709 average time 0.030555111225066867 iter num 40\n",
            "loss 0.5079999755253084 average time 0.027483190020084293 iter num 50\n",
            "loss 2.142222656402737 average time 0.025560687833376505 iter num 60\n",
            "loss 0.6707111606374383 average time 0.02404592024287402 iter num 70\n",
            "loss 0.7021245983196422 average time 0.02291791398752139 iter num 80\n",
            "loss 0.344642176060006 average time 0.0219647221222456 iter num 90\n",
            "loss 0.4938807978760451 average time 0.021357511860023805 iter num 100\n",
            "loss 0.4522404560702853 average time 0.07895904140013954 iter num 10\n",
            "loss 0.35574135836213827 average time 0.04683775095013516 iter num 20\n",
            "loss 1.600706164026633 average time 0.03674663573347061 iter num 30\n",
            "loss 1.2300038360990584 average time 0.03148749122508434 iter num 40\n",
            "loss 0.6248041609069332 average time 0.028285899620059354 iter num 50\n",
            "loss 0.36918958358000964 average time 0.02620812220006883 iter num 60\n",
            "loss 0.8785506361164153 average time 0.02451749707148078 iter num 70\n",
            "loss 3.228389541618526 average time 0.02324057690001382 iter num 80\n",
            "loss 0.32091840694192797 average time 0.022345176377792896 iter num 90\n",
            "loss 0.5397054701461457 average time 0.021560835720038085 iter num 100\n",
            "loss 1.112001045839861 average time 0.07662656460006474 iter num 10\n",
            "loss 3.4772357321344316 average time 0.04625582595008382 iter num 20\n",
            "loss 1.9942631479352713 average time 0.03582758396675369 iter num 30\n",
            "loss 2.241591428173706 average time 0.030380621550057184 iter num 40\n",
            "loss 1.4543371798936278 average time 0.027361624460063468 iter num 50\n",
            "loss 0.6269272125791758 average time 0.025235424716690127 iter num 60\n",
            "loss 1.3703134027309716 average time 0.02380605185715987 iter num 70\n",
            "loss 0.5145148315932602 average time 0.022695644037526108 iter num 80\n",
            "loss 0.3147169991279952 average time 0.02183971948889949 iter num 90\n",
            "loss 1.3021111954003572 average time 0.021119938390002063 iter num 100\n",
            "loss 3.7356247776187956 average time 0.0792188410999188 iter num 10\n",
            "loss 0.8745082595851272 average time 0.04703941814991595 iter num 20\n",
            "loss 8.071911288425326 average time 0.036768231433325124 iter num 30\n",
            "loss 2.5595008628442883 average time 0.03173578989999441 iter num 40\n",
            "loss 18.66005128249526 average time 0.02873494485997071 iter num 50\n",
            "loss 3.465251938905567 average time 0.026627191083283226 iter num 60\n",
            "loss 1.6342921298928559 average time 0.025072754371376505 iter num 70\n",
            "loss 1.861507334979251 average time 0.023706622574991343 iter num 80\n",
            "loss 1.5626370441168547 average time 0.022730702922227567 iter num 90\n",
            "loss 12.139759492129087 average time 0.021875225180010602 iter num 100\n",
            "loss 4.897357430309057 average time 0.07541702440003065 iter num 10\n",
            "loss 3.2171624479815364 average time 0.044910589349956356 iter num 20\n",
            "loss 1.3793486868962646 average time 0.03458610096658958 iter num 30\n",
            "loss 2.6965804863721132 average time 0.029421242324929153 iter num 40\n",
            "loss 3.627273836173117 average time 0.02668286959995385 iter num 50\n",
            "loss 1.6065812087617815 average time 0.024925653866618328 iter num 60\n",
            "loss 5.249782698228955 average time 0.023418720528531722 iter num 70\n",
            "loss 1.5692056331317872 average time 0.022404664137457075 iter num 80\n",
            "loss 1.3315484102349728 average time 0.02160920085549757 iter num 90\n",
            "loss 1.0868844401556998 average time 0.02085027372994773 iter num 100\n",
            "loss 0.3412423757254146 average time 0.07655731839995497 iter num 10\n",
            "loss 1.6059023619163781 average time 0.04574934144993677 iter num 20\n",
            "loss 1.4481443213298917 average time 0.03534301973337885 iter num 30\n",
            "loss 1.7403345555067062 average time 0.030296784674965237 iter num 40\n",
            "loss 0.5767688708147034 average time 0.02724428055993485 iter num 50\n",
            "loss 0.6529837992275134 average time 0.025208790099956482 iter num 60\n",
            "loss 1.3004164793528616 average time 0.023980819471385726 iter num 70\n",
            "loss 1.3184960698708892 average time 0.022958479074964087 iter num 80\n",
            "loss 0.648030691081658 average time 0.02220434245550172 iter num 90\n",
            "loss 1.0809880041051656 average time 0.02136393055994631 iter num 100\n",
            "loss 2.3199847782962024 average time 0.07956001029988329 iter num 10\n",
            "loss 4.728302010335028 average time 0.04743584164998538 iter num 20\n",
            "loss 1.5409763727802783 average time 0.03642427409998466 iter num 30\n",
            "loss 0.6058705184841529 average time 0.031404300699978197 iter num 40\n",
            "loss 0.4588054434861988 average time 0.028046486539951728 iter num 50\n",
            "loss 0.49333011702401564 average time 0.025832511666628002 iter num 60\n",
            "loss 0.8287125820061192 average time 0.024537024142838555 iter num 70\n",
            "loss 0.4387610897538252 average time 0.023538234574971284 iter num 80\n",
            "loss 1.5441338473465294 average time 0.022623420444415388 iter num 90\n",
            "loss 0.6563076749444008 average time 0.021919148499973742 iter num 100\n",
            "loss 0.4790386446984485 average time 0.07756723960010277 iter num 10\n",
            "loss 0.5029443855164573 average time 0.04715198610010703 iter num 20\n",
            "loss 1.9412237452343106 average time 0.03620548200008974 iter num 30\n",
            "loss 55.72555586695671 average time 0.03094504015009534 iter num 40\n",
            "loss 11.90580427646637 average time 0.027729691740078125 iter num 50\n",
            "loss 9.491267846897244 average time 0.02556836390005325 iter num 60\n",
            "loss 4.210827173665166 average time 0.02386280738577885 iter num 70\n",
            "loss 1.6944319941103458 average time 0.022633538412571853 iter num 80\n",
            "loss 0.6617431063205004 average time 0.021924424477836307 iter num 90\n",
            "loss 1.4182852464728057 average time 0.0211997396800416 iter num 100\n",
            "loss 4.248819896019995 average time 0.07695108439993419 iter num 10\n",
            "loss 5.015601054765284 average time 0.04652066314979493 iter num 20\n",
            "loss 6.603968795388937 average time 0.035982068999874176 iter num 30\n",
            "loss 1.3837347796652466 average time 0.030480520424885072 iter num 40\n",
            "loss 1.5722282114438713 average time 0.027503031899905182 iter num 50\n",
            "loss 2.1241436479613185 average time 0.025408850499934486 iter num 60\n",
            "loss 2.5067059323191643 average time 0.023825205742754665 iter num 70\n",
            "loss 0.932537077460438 average time 0.022631605412402677 iter num 80\n",
            "loss 0.5514912481885403 average time 0.021741792366598626 iter num 90\n",
            "loss 0.39685248339083046 average time 0.020952733589938363 iter num 100\n",
            "loss 1.3446752564050257 average time 0.07671111759991618 iter num 10\n",
            "loss 0.7497682963730767 average time 0.04620182769999701 iter num 20\n",
            "loss 0.5308020263328217 average time 0.03606956403333849 iter num 30\n",
            "loss 1.2136913574067876 average time 0.030919596325065867 iter num 40\n",
            "loss 17.64443120919168 average time 0.027931198760034023 iter num 50\n",
            "loss 3.707192954607308 average time 0.025910644783334647 iter num 60\n",
            "loss 1.756426936481148 average time 0.024259884671443743 iter num 70\n",
            "loss 1.1749574332498014 average time 0.02306104474998847 iter num 80\n",
            "loss 5.181441083550453 average time 0.022209566888856596 iter num 90\n",
            "loss 4.246222670190036 average time 0.021495239159976337 iter num 100\n",
            "loss 7.388161029666662 average time 0.07802010159985003 iter num 10\n",
            "loss 3.2750581158325076 average time 0.045926183800065704 iter num 20\n",
            "loss 2.289505355292931 average time 0.03553669630003545 iter num 30\n",
            "loss 1.7065934662241489 average time 0.030276558100013062 iter num 40\n",
            "loss 1.1595236719585955 average time 0.027285236440020524 iter num 50\n",
            "loss 5.66103495657444 average time 0.02517748238333297 iter num 60\n",
            "loss 1.3031993876211345 average time 0.023691636657128715 iter num 70\n",
            "loss 1.0883218055823818 average time 0.0229437941249671 iter num 80\n",
            "loss 1.844278594944626 average time 0.02195343251109484 iter num 90\n",
            "loss 1.2939123553223908 average time 0.021249583459984935 iter num 100\n",
            "loss 5.233781994320452 average time 0.07971313509997344 iter num 10\n",
            "loss 1.9792368402704597 average time 0.04719181959999332 iter num 20\n",
            "loss 1.6537214105483145 average time 0.036443815366662115 iter num 30\n",
            "loss 2.934116928372532 average time 0.03114843349997045 iter num 40\n",
            "loss 2.2167008137330413 average time 0.02769154558000082 iter num 50\n",
            "loss 0.45551048970082775 average time 0.02551278200003253 iter num 60\n",
            "loss 2.0605108875315636 average time 0.023786205985769422 iter num 70\n",
            "loss 2.8443080373108387 average time 0.02286079901255107 iter num 80\n",
            "loss 0.34341363061685115 average time 0.022071285111148125 iter num 90\n",
            "loss 0.1715461621643044 average time 0.021257643860026293 iter num 100\n",
            "loss 0.7643697608727962 average time 0.0806249097001455 iter num 10\n",
            "loss 0.6014815880917013 average time 0.04778840385015428 iter num 20\n",
            "loss 2.017742081079632 average time 0.03709013943343962 iter num 30\n",
            "loss 1.0509804997127503 average time 0.03218602020010621 iter num 40\n",
            "loss 0.7067630940582603 average time 0.028755649200102196 iter num 50\n",
            "loss 2.1377035591285676 average time 0.026483133016730182 iter num 60\n",
            "loss 2.2791455558035523 average time 0.02484250032860343 iter num 70\n",
            "loss 0.9281554957851768 average time 0.02344465252504051 iter num 80\n",
            "loss 1.0070107236970216 average time 0.022478637488913794 iter num 90\n",
            "loss 3.186399699188769 average time 0.02168542165002691 iter num 100\n",
            "loss 2.872040495276451 average time 0.07416937209991374 iter num 10\n",
            "loss 1.1383421224309132 average time 0.04420444924990079 iter num 20\n",
            "loss 0.8415395132033154 average time 0.034587843799878705 iter num 30\n",
            "loss 0.5529600093723275 average time 0.029596638149882892 iter num 40\n",
            "loss 0.9006504842545837 average time 0.02700214337990474 iter num 50\n",
            "loss 1.28799001686275 average time 0.025106232849899848 iter num 60\n",
            "loss 1.0758457210613415 average time 0.0237339999856366 iter num 70\n",
            "loss 0.4459116098587401 average time 0.022665837087424735 iter num 80\n",
            "loss 0.6908203067723662 average time 0.02178981664436732 iter num 90\n",
            "loss 1.8012608052231371 average time 0.021272858419952172 iter num 100\n",
            "loss 0.2199598020524718 average time 0.07793404859994553 iter num 10\n",
            "loss 0.3972895137849264 average time 0.046389097099972784 iter num 20\n",
            "loss 0.8799984789220616 average time 0.035995799000011174 iter num 30\n",
            "loss 0.36548328353092074 average time 0.031024579974996414 iter num 40\n",
            "loss 0.7938253838801757 average time 0.02788565317998291 iter num 50\n",
            "loss 0.6912098615430295 average time 0.025632973266647242 iter num 60\n",
            "loss 0.4882345820078626 average time 0.0239977871285581 iter num 70\n",
            "loss 1.4425365952774882 average time 0.022899688487484582 iter num 80\n",
            "loss 0.37448186049005017 average time 0.021928321855527125 iter num 90\n",
            "loss 0.8848455763654783 average time 0.021313897889986038 iter num 100\n",
            "loss 2.4903242592699826 average time 0.07849376299982395 iter num 10\n",
            "loss 0.8211687236325815 average time 0.046842160849928406 iter num 20\n",
            "loss 0.5421516834758222 average time 0.0361641214000277 iter num 30\n",
            "loss 1.3517106708604842 average time 0.031064727925058832 iter num 40\n",
            "loss 0.7373373227892444 average time 0.027656514340033026 iter num 50\n",
            "loss 0.24640929041197523 average time 0.025385014800046218 iter num 60\n",
            "loss 0.5781104846391827 average time 0.02392667265716487 iter num 70\n",
            "loss 1.2245196558069438 average time 0.022793667225028003 iter num 80\n",
            "loss 1.0920299973804504 average time 0.02187238306668304 iter num 90\n",
            "loss 0.9663582022767514 average time 0.021110972459991897 iter num 100\n",
            "loss 1.4528974134009331 average time 0.07569406619986693 iter num 10\n",
            "loss 0.8047545270528644 average time 0.044973067950013504 iter num 20\n",
            "loss 1.0635668877512217 average time 0.03467178363334824 iter num 30\n",
            "loss 0.7793866097927094 average time 0.029623021074985444 iter num 40\n",
            "loss 0.8199941657949239 average time 0.02713872537999123 iter num 50\n",
            "loss 1.7078682139981538 average time 0.02507929333329836 iter num 60\n",
            "loss 0.19098810298601165 average time 0.023685277085665542 iter num 70\n",
            "loss 0.39448139432352036 average time 0.022890300737458347 iter num 80\n",
            "loss 0.7805851055309176 average time 0.021947353533283198 iter num 90\n",
            "loss 0.3365905649843626 average time 0.021154680979961996 iter num 100\n",
            "loss 1.6999352374114096 average time 0.07616354040010265 iter num 10\n",
            "loss 1.871504500741139 average time 0.04573384645004808 iter num 20\n",
            "loss 0.5748822513851337 average time 0.03547819326671136 iter num 30\n",
            "loss 0.6833103543613106 average time 0.030213155925025603 iter num 40\n",
            "loss 0.42808012949535623 average time 0.027291858820026393 iter num 50\n",
            "loss 1.7285240755882114 average time 0.025209150533373758 iter num 60\n",
            "loss 2.651477698236704 average time 0.0237498427857385 iter num 70\n",
            "loss 1.9025390793103725 average time 0.022656248737519036 iter num 80\n",
            "loss 2.2003089543431997 average time 0.021699645400015774 iter num 90\n",
            "loss 0.23910133677418344 average time 0.021044304260021816 iter num 100\n",
            "loss 3.176633035764098 average time 0.07659854560006352 iter num 10\n",
            "loss 1.7004203982651234 average time 0.045809302099996785 iter num 20\n",
            "loss 1.2145173241151497 average time 0.03546910389995901 iter num 30\n",
            "loss 0.6941660831216723 average time 0.030537307099962163 iter num 40\n",
            "loss 1.439123589079827 average time 0.02752548897997258 iter num 50\n",
            "loss 1.186006047646515 average time 0.025741985516651765 iter num 60\n",
            "loss 0.7248434121720493 average time 0.024169131214239314 iter num 70\n",
            "loss 1.5143168275244534 average time 0.023151572862457215 iter num 80\n",
            "loss 0.5262582271825522 average time 0.022305372544421213 iter num 90\n",
            "loss 0.6885863695060834 average time 0.02168279851997795 iter num 100\n",
            "loss 0.9528859663987532 average time 0.07581524710012673 iter num 10\n",
            "loss 0.6027814379194751 average time 0.04521662180004569 iter num 20\n",
            "loss 1.9455401343293488 average time 0.03519552160002301 iter num 30\n",
            "loss 0.6641162326559424 average time 0.0301679515000842 iter num 40\n",
            "loss 0.322587184200529 average time 0.027270214220061463 iter num 50\n",
            "loss 0.3858417403534986 average time 0.025272494133362973 iter num 60\n",
            "loss 0.48676614824216813 average time 0.023680008242912925 iter num 70\n",
            "loss 0.50564922275953 average time 0.022741095312551352 iter num 80\n",
            "loss 0.34053857234539464 average time 0.02201539093335264 iter num 90\n",
            "loss 0.706605424056761 average time 0.021401321500025005 iter num 100\n",
            "loss 1.1318176257191226 average time 0.0809716777000176 iter num 10\n",
            "loss 0.541096342203673 average time 0.04819914435011015 iter num 20\n",
            "loss 1.9158818759024143 average time 0.036883633266643304 iter num 30\n",
            "loss 1.313912944169715 average time 0.0312608641499537 iter num 40\n",
            "loss 1.2568834063131362 average time 0.027911890979921736 iter num 50\n",
            "loss 0.6490643136203289 average time 0.025662266683275446 iter num 60\n",
            "loss 1.1505813017720357 average time 0.024297403299936248 iter num 70\n",
            "loss 1.2597547902259976 average time 0.023053057662468745 iter num 80\n",
            "loss 1.0953690798487514 average time 0.022332497655517928 iter num 90\n",
            "loss 0.5707003219868056 average time 0.0216276159699828 iter num 100\n",
            "loss 0.8868253644322976 average time 0.07804416190001576 iter num 10\n",
            "loss 0.2467878584866412 average time 0.04668929479998951 iter num 20\n",
            "loss 0.32971591281238943 average time 0.03584151609999632 iter num 30\n",
            "loss 1.245947933057323 average time 0.031030629200017756 iter num 40\n",
            "loss 0.5938423419138417 average time 0.027643475200002286 iter num 50\n",
            "loss 0.7015443406999111 average time 0.025501095700004348 iter num 60\n",
            "loss 0.8020242967177182 average time 0.02399804761425912 iter num 70\n",
            "loss 0.567538445466198 average time 0.022838343399985205 iter num 80\n",
            "loss 0.7032350549707189 average time 0.02196650306663691 iter num 90\n",
            "loss 0.558407227799762 average time 0.021516871209951206 iter num 100\n",
            "loss 0.25745128368726 average time 0.07763888699992094 iter num 10\n",
            "loss 0.7534210453741252 average time 0.04630795469988698 iter num 20\n",
            "loss 0.1937910019478295 average time 0.03581416049995217 iter num 30\n",
            "loss 0.5264518040348776 average time 0.03078698074991735 iter num 40\n",
            "loss 0.877900529303588 average time 0.02747729647993765 iter num 50\n",
            "loss 1.4293307322077453 average time 0.025361950033266113 iter num 60\n",
            "loss 1.2915159459225833 average time 0.024004813099976933 iter num 70\n",
            "loss 0.6377389945555478 average time 0.022869255762475404 iter num 80\n",
            "loss 0.9745037095854059 average time 0.022078160499960277 iter num 90\n",
            "loss 0.6158278847578913 average time 0.021382099699967513 iter num 100\n",
            "loss 1.0635936632752419 average time 0.07797347840005386 iter num 10\n",
            "loss 0.9294070332543924 average time 0.0462728192000668 iter num 20\n",
            "loss 2.26401025429368 average time 0.036132483699990794 iter num 30\n",
            "loss 0.41468956624157727 average time 0.030831325774988726 iter num 40\n",
            "loss 0.7595638453494757 average time 0.0278303058399797 iter num 50\n",
            "loss 0.7853165152482688 average time 0.02571093589993628 iter num 60\n",
            "loss 0.3730184835148975 average time 0.024128483957078322 iter num 70\n",
            "loss 0.5459901876747608 average time 0.022911824187451656 iter num 80\n",
            "loss 0.19897557649528608 average time 0.022062990299976565 iter num 90\n",
            "loss 2.36041028983891 average time 0.021330942539962053 iter num 100\n",
            "loss 1.0553557513048872 average time 0.07707780620003177 iter num 10\n",
            "loss 1.2363994028419256 average time 0.0465990390499428 iter num 20\n",
            "loss 1.166982838185504 average time 0.036250941033298054 iter num 30\n",
            "loss 1.4356143947225064 average time 0.03077348849990358 iter num 40\n",
            "loss 1.709355419734493 average time 0.027570429619900097 iter num 50\n",
            "loss 2.064096333924681 average time 0.025664284116601266 iter num 60\n",
            "loss 0.895363264135085 average time 0.023965980799883775 iter num 70\n",
            "loss 0.9153485007118434 average time 0.022774351662417303 iter num 80\n",
            "loss 0.5010852328268811 average time 0.021907617555482123 iter num 90\n",
            "loss 0.21404675862868316 average time 0.021374173429931035 iter num 100\n",
            "loss 1.0024475341197103 average time 0.07951604579993728 iter num 10\n",
            "loss 2.990118518937379 average time 0.04673539575005634 iter num 20\n",
            "loss 11.375178582966328 average time 0.03601571996665977 iter num 30\n",
            "loss 4.786633362527937 average time 0.031045051749924824 iter num 40\n",
            "loss 0.9705216507427394 average time 0.02761498884006869 iter num 50\n",
            "loss 0.3691388701554388 average time 0.02547555013334204 iter num 60\n",
            "loss 0.4877337778452784 average time 0.023946892871416433 iter num 70\n",
            "loss 1.027634643833153 average time 0.02280040603748148 iter num 80\n",
            "loss 0.7549321162514389 average time 0.021966000922172196 iter num 90\n",
            "loss 0.8456951036350802 average time 0.021280824429977654 iter num 100\n",
            "loss 1.254841627087444 average time 0.08069965790018614 iter num 10\n",
            "loss 0.3041834497707896 average time 0.04793239115006145 iter num 20\n",
            "loss 0.3076685607084073 average time 0.036805523466743276 iter num 30\n",
            "loss 0.15550323951174505 average time 0.031658581300052904 iter num 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-86a3ace7f0ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0mmodel_save_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'jax_european_test_3.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m           \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_PATHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m           \u001b[0mEuropean_Call_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptionvalueavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m           \u001b[0mgooptionvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptionvalueavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m           \u001b[0mDeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgooptionvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36moptionvalueavg\u001b[0;34m(key, initial_stocks, numsteps, drift, r, cov, K, T, keys)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moptionvalueavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m###################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices)\u001b[0m\n\u001b[1;32m   5653\u001b[0m   \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_index_for_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5654\u001b[0m   return _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[0;32m-> 5655\u001b[0;31m                  unique_indices)\n\u001b[0m\u001b[1;32m   5656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5657\u001b[0m \u001b[0;31m# TODO(phawkins): re-enable jit after fixing excessive recompilation for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices)\u001b[0m\n\u001b[1;32m   5661\u001b[0m             unique_indices):\n\u001b[1;32m   5662\u001b[0m   \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_merge_static_and_dynamic_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5663\u001b[0;31m   \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_index_to_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shared with _scatter_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5664\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_index_to_gather\u001b[0;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[1;32m   5852\u001b[0m         \u001b[0;31m# XLA gives error when indexing into an axis of size 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5853\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"index is out of bounds for axis {x_axis} with size 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5854\u001b[0;31m       \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnormalize_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5855\u001b[0m       \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_element_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5856\u001b[0m       \u001b[0mgather_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgather_indices_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_normalize_index\u001b[0;34m(index, axis_size)\u001b[0m\n\u001b[1;32m   5437\u001b[0m     \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_constant_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5438\u001b[0m     \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_size_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5439\u001b[0;31m     index)\n\u001b[0m\u001b[1;32m   5440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5441\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_wraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_along_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_doc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(pred, on_true, on_false)\u001b[0m\n\u001b[1;32m    841\u001b[0m   \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m   \"\"\"\n\u001b[0;32m--> 843\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mselect_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_false\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m def slice(operand: Array, start_indices: Sequence[int],\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         args, used_axis_names(self, params) if self._dispatch_on_params else None)\n\u001b[1;32m    266\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    274\u001b[0m   \u001b[0;34m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m   \u001b[0mcompiled_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxla_primitive_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0munsafe_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled_primitive\u001b[0;34m(prim, compiled, result_handler, *args)\u001b[0m\n\u001b[1;32m    390\u001b[0m   \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m   \u001b[0minput_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_put\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m   \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba159341-83b3-4a61-dfdc-a613e4338ea6"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 0.8, 0.8, 0.25, 0.05, 0.05]*3]).cuda() # T, K, S, sigma, mu, r\n",
        "print('price: ' + str(model(inputs.float())))\n",
        "\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient[0][[2,8,14]]\n",
        "\n",
        "# price, delta1, delta2, delta3\n",
        "# should be around (0.067710705, 0.22125466 , 0.22136934 , 0.22104672)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: tensor([[0.1501]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1927, 0.1926, 0.1862], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IluHtDoa35-f",
        "outputId": "29e8830b-59c3-46b2-db56-2b0e4935eff7"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 0.8, 0.8, 0.25, 0.05, 0.05]*3]).cuda() # T, K, S, sigma, mu, r\n",
        "print('price: ' + str(model(inputs.float())))\n",
        "\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient[0][[2,8,14]]\n",
        "\n",
        "# price, delta1, delta2, delta3\n",
        "# should be around (0.067710705, 0.22125466 , 0.22136934 , 0.22104672)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: tensor([[0.1501]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.1927, 0.1926, 0.1862], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_2AXrPt7bNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e191ca4-a67e-4d72-ce47-aad3cfbfcec5"
      },
      "source": [
        "numstocks = 3\n",
        "numsteps = 50\n",
        "numpaths = 100000\n",
        "\n",
        "rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.05]*numstocks)\n",
        "r = drift\n",
        "cov = jnp.identity(numstocks)*0.25*0.25\n",
        "initial_stocks = jnp.array([0.8]*numstocks) # must be float\n",
        "T = 10.0\n",
        "K = 10\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "\n",
        "# delta test\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.202843e-05\n",
            "[7.8077363e-05 1.6362128e-04 8.8285895e-05]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwApH0GT9bBK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "2fceb140-e645-491f-a304-7e4a05acb916"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 0.8, S, 0.25, 0.05, 0.05] + ([1, 0.8, 0.8, 0.25, 0.05, 0.05]*2)]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "prices = np.arange(0, 1, 0.01)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc8fa082750>]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}