{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generating Test",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Pui/Generating_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuPE3AQX2BH1",
        "outputId": "59adfca7-11ad-4dff-ddbd-fe534fc52953"
      },
      "source": [
        "S_range = np.linspace(0.75, 1.25, 10)\n",
        "K_range = np.linspace(0.75, 1.25, 10)\n",
        "Sigma_range = np.linspace(0.15, 0.45, 5)\n",
        "r_range = np.linspace(0.01, 0.04, 3)\n",
        "\n",
        "print(S_range)\n",
        "print(K_range)\n",
        "print(Sigma_range)\n",
        "print(r_range)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.75       0.80555556 0.86111111 0.91666667 0.97222222 1.02777778\n",
            " 1.08333333 1.13888889 1.19444444 1.25      ]\n",
            "[0.75       0.80555556 0.86111111 0.91666667 0.97222222 1.02777778\n",
            " 1.08333333 1.13888889 1.19444444 1.25      ]\n",
            "[0.15  0.225 0.3   0.375 0.45 ]\n",
            "[0.01  0.025 0.04 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4HV-G44th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e2a3222-d056-4cba-fa0a-a005e6518ac2"
      },
      "source": [
        "%%writefile cupy_dataset.py\n",
        "import cupy\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "import pandas as pd\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "    return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "S_range = np.linspace(0.75, 1.25, 10)\n",
        "K_range = np.linspace(0.75, 1.25, 10)\n",
        "Sigma_range = np.linspace(0.15, 0.45, 5)\n",
        "r_range = np.linspace(0.01, 0.04, 3)\n",
        "\n",
        "call = []\n",
        "for i in S_range:\n",
        "  for j in K_range:\n",
        "    for l in r_range:\n",
        "      for k in Sigma_range:\n",
        "        call.append([1,j,i,k,l,l,bs_call(i,j,1,l,k),bs_delta(i,j,1,l,k)]) #T, K, S, sigma, mu, r\n",
        "Thedataset = pd.DataFrame(call)\n",
        "\n",
        "Thedataset_X = Thedataset.iloc[:,:6]\n",
        "Thedataset_Y = Thedataset.iloc[:,6:]\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len, number_path, batch, seed, stocks):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 50\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = 1.0 # assume T = 1, use float here\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        self.X = cupy.array(Thedataset_X)\n",
        "        self.Y = cupy.array(Thedataset_Y)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(self.X.toDlpack()), from_dlpack(self.Y.toDlpack()))\n",
        "\n",
        "\n",
        "# ds = OptionDataSet(max_len = 1, number_path = 10000, batch = 2, seed = np.random.randint(10000), stocks=1) # for testing purpose, use constant seed. When training, change to random seed\n",
        "# for i in ds:\n",
        "#     print(i[0])\n",
        "#     print(i[0].shape)\n",
        "#     print(i[1])\n",
        "#     print(i[1].shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cupy_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6JO9OBHdvv",
        "outputId": "dda36129-4865-43c1-fadd-634b87acfa8a"
      },
      "source": [
        "%%writefile model.py\n",
        "# version 1,2\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*1, 32) # remember to change this!\n",
        "        self.fc2 = nn.Linear(32, 64)\n",
        "        self.fc3 = nn.Linear(64, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 32)\n",
        "        self.fc6 = nn.Linear(32, 1) # 1 outputs: price\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1.0, 0.5, 0.5, 0.3, 0.03, 0.03]*1)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = (x - torch.tensor([0.0, 0.75, 0.75, 0.15, 0.01, 0.01]*1).cuda()) / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlXD80xPNVc6",
        "outputId": "6f48d9a1-9ee2-4e62-8e97-b40f56144512"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 31.7 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3CyULkENYKb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f416cb73-79d6-491d-88b3-0362f17819ff"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 100000, batch = 1, seed = np.random.randint(10000), stocks = 1) # must have random seed. It doesn't matter how many batch here (not taken into function). Use max_len to adjust\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    # print(x)\n",
        "    # print(x.shape)\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    # print(y.shape)\n",
        "    y_pred = model(x.float())\n",
        "    # print(y_pred)\n",
        "    # print(y_pred.shape)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x.float()\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "    # print(y_pred)\n",
        "    # print(y_pred.shape)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.21275691130556876 average time 2.2172917150000018 iter num 20\n",
            "loss 0.19914288638351194 average time 2.201579961425 iter num 40\n",
            "loss 0.1891768526916255 average time 2.2067520843499997 iter num 60\n",
            "loss 0.1845969282499282 average time 2.2135725168500002 iter num 80\n",
            "loss 0.1835804659955946 average time 2.20936135983 iter num 100\n",
            "loss 0.1626686034980522 average time 2.194595416750002 iter num 20\n",
            "loss 0.14173157708948125 average time 2.1875014336750014 iter num 40\n",
            "loss 0.12629605435207958 average time 2.1778576933166667 iter num 60\n",
            "loss 0.11884121547550335 average time 2.174891702862498 iter num 80\n",
            "loss 0.11724398775250039 average time 2.1838199030399967 iter num 100\n",
            "loss 0.0867865462919209 average time 2.2039234362499824 iter num 20\n",
            "loss 0.06303299545399357 average time 2.188037299874992 iter num 40\n",
            "loss 0.0520055679951355 average time 2.1531721496166596 iter num 60\n",
            "loss 0.04857875479207383 average time 2.133798158374995 iter num 80\n",
            "loss 0.04799106253964681 average time 2.136486375010002 iter num 100\n",
            "loss 0.04134920201486148 average time 2.148515379299994 iter num 20\n",
            "loss 0.04026455349348455 average time 2.1531598104500036 iter num 40\n",
            "loss 0.04007437924614477 average time 2.1576751908833347 iter num 60\n",
            "loss 0.03998482296250874 average time 2.1584929838250018 iter num 80\n",
            "loss 0.03996508516828881 average time 2.162706484820004 iter num 100\n",
            "loss 0.039586298532994425 average time 2.1826127079500166 iter num 20\n",
            "loss 0.039251047639339634 average time 2.190900372025001 iter num 40\n",
            "loss 0.03902777037293753 average time 2.179171103566665 iter num 60\n",
            "loss 0.03892548139142364 average time 2.170668382462496 iter num 80\n",
            "loss 0.03890377434461703 average time 2.1759037768599967 iter num 100\n",
            "loss 0.03849062308690485 average time 2.1494969631499656 iter num 20\n",
            "loss 0.038129445738332365 average time 2.146531211524973 iter num 40\n",
            "loss 0.03789328764743161 average time 2.145909154349977 iter num 60\n",
            "loss 0.037785898873442005 average time 2.1486024619874855 iter num 80\n",
            "loss 0.03776320356260651 average time 2.1456281037399867 iter num 100\n",
            "loss 0.03733194895179423 average time 2.183903956999984 iter num 20\n",
            "loss 0.03695308282934558 average time 2.1627465186249935 iter num 40\n",
            "loss 0.036704452624391246 average time 2.165915685283331 iter num 60\n",
            "loss 0.03659135490246899 average time 2.1689677959124993 iter num 80\n",
            "loss 0.0365674586632728 average time 2.1692343496099964 iter num 100\n",
            "loss 0.036113952899438403 average time 2.14952699024999 iter num 20\n",
            "loss 0.03571540284734945 average time 2.1743467316999956 iter num 40\n",
            "loss 0.035453337990587454 average time 2.1705881720333235 iter num 60\n",
            "loss 0.0353340123887186 average time 2.165254012262494 iter num 80\n",
            "loss 0.035308825220198854 average time 2.1735328096799957 iter num 100\n",
            "loss 0.03483059793230972 average time 2.1341836911000085 iter num 20\n",
            "loss 0.03440897735296805 average time 2.1368552663250115 iter num 40\n",
            "loss 0.03413110655413652 average time 2.1397434474166706 iter num 60\n",
            "loss 0.03400433167214624 average time 2.1461993128500128 iter num 80\n",
            "loss 0.033977576640107664 average time 2.1495727834499987 iter num 100\n",
            "loss 0.03346923006846701 average time 2.156467420350009 iter num 20\n",
            "loss 0.033019679372925145 average time 2.187387437874963 iter num 40\n",
            "loss 0.03272258786731802 average time 2.1759244179666593 iter num 60\n",
            "loss 0.03258686255609328 average time 2.1756789780375017 iter num 80\n",
            "loss 0.032558198795107775 average time 2.179083152339999 iter num 100\n",
            "loss 0.03201136976940405 average time 2.2232812611500776 iter num 20\n",
            "loss 0.03152315732981303 average time 2.1766304430750667 iter num 40\n",
            "loss 0.03119811312685664 average time 2.168024542366705 iter num 60\n",
            "loss 0.0310488024229687 average time 2.1635737924250407 iter num 80\n",
            "loss 0.031017218116744443 average time 2.1686658413900295 iter num 100\n",
            "loss 0.030412525889139827 average time 2.170575298299923 iter num 20\n",
            "loss 0.029866267808387702 average time 2.183550799474972 iter num 40\n",
            "loss 0.02949824825525999 average time 2.1827747792999994 iter num 60\n",
            "loss 0.02932789275138378 average time 2.173357563299993 iter num 80\n",
            "loss 0.02929172883404612 average time 2.1737451693899903 iter num 100\n",
            "loss 0.028596334933849676 average time 2.133771961499997 iter num 20\n",
            "loss 0.027961889519394295 average time 2.1559662595000533 iter num 40\n",
            "loss 0.02753178541641343 average time 2.1534992510666977 iter num 60\n",
            "loss 0.027332741564708263 average time 2.150606194450006 iter num 80\n",
            "loss 0.027290526453992416 average time 2.144421900980005 iter num 100\n",
            "loss 0.026481848540997034 average time 2.129792220449963 iter num 20\n",
            "loss 0.025752960281348474 average time 2.1138450896999643 iter num 40\n",
            "loss 0.025267208061766203 average time 2.12322973603331 iter num 60\n",
            "loss 0.0250454236245745 average time 2.1256054285874826 iter num 80\n",
            "loss 0.024998738605773695 average time 2.12467514966997 iter num 100\n",
            "loss 0.02411429302452711 average time 2.1537012820499286 iter num 20\n",
            "loss 0.02333275851896803 average time 2.1554735285499875 iter num 40\n",
            "loss 0.022817285034997917 average time 2.1400358659166687 iter num 60\n",
            "loss 0.022582463260055058 average time 2.134099027725 iter num 80\n",
            "loss 0.022533092530530912 average time 2.1401358572300158 iter num 100\n",
            "loss 0.02159804325087369 average time 2.163301113750026 iter num 20\n",
            "loss 0.020766092329717285 average time 2.1397981307750342 iter num 40\n",
            "loss 0.020214362800471224 average time 2.138299727683375 iter num 60\n",
            "loss 0.019962381836580362 average time 2.1333138582250397 iter num 80\n",
            "loss 0.019909332547567108 average time 2.1366792474400382 iter num 100\n",
            "loss 0.018905429912161008 average time 2.180989513450072 iter num 20\n",
            "loss 0.01801621273267564 average time 2.1593907156500336 iter num 40\n",
            "loss 0.017431420946092218 average time 2.1588584619333613 iter num 60\n",
            "loss 0.017166539095418484 average time 2.153148363887527 iter num 80\n",
            "loss 0.017111020647340377 average time 2.1508298864300333 iter num 100\n",
            "loss 0.016067938880498428 average time 2.140500744750034 iter num 20\n",
            "loss 0.015155811552487495 average time 2.1287430080000265 iter num 40\n",
            "loss 0.014562920362173604 average time 2.130840647800013 iter num 60\n",
            "loss 0.014296320897593001 average time 2.126399831325017 iter num 80\n",
            "loss 0.01424066454691965 average time 2.127207788680012 iter num 100\n",
            "loss 0.013204280664431321 average time 2.1474526868499653 iter num 20\n",
            "loss 0.012315862272839827 average time 2.1426085659250473 iter num 40\n",
            "loss 0.011750690886950925 average time 2.1430313616167043 iter num 60\n",
            "loss 0.011500743965604743 average time 2.135374009350039 iter num 80\n",
            "loss 0.011448983007978685 average time 2.132498604170041 iter num 100\n",
            "loss 0.010502686407547345 average time 2.1606097852499717 iter num 20\n",
            "loss 0.009728895115230042 average time 2.166934381499959 iter num 40\n",
            "loss 0.00926057882117397 average time 2.1592757866499594 iter num 60\n",
            "loss 0.009060641293926714 average time 2.162012240687477 iter num 80\n",
            "loss 0.009019898447236838 average time 2.1665927228899817 iter num 100\n",
            "loss 0.008299358375734629 average time 2.1351841206500466 iter num 20\n",
            "loss 0.007753492547292281 average time 2.151148170474926 iter num 40\n",
            "loss 0.0074448706533511225 average time 2.1651445016165782 iter num 60\n",
            "loss 0.0073181446113924535 average time 2.1776100007499055 iter num 80\n",
            "loss 0.007292696511481966 average time 2.177269400059913 iter num 100\n",
            "loss 0.006852255540853036 average time 2.159088328650114 iter num 20\n",
            "loss 0.006529293296124209 average time 2.191780852450006 iter num 40\n",
            "loss 0.006346847510422958 average time 2.1772854718000265 iter num 60\n",
            "loss 0.0062707248380727805 average time 2.17294671352505 iter num 80\n",
            "loss 0.006255257980126758 average time 2.1801286950100165 iter num 100\n",
            "loss 0.005978650277770557 average time 2.1454410870500853 iter num 20\n",
            "loss 0.005758193110333486 average time 2.1821845707250986 iter num 40\n",
            "loss 0.005623584583993389 average time 2.174696719783378 iter num 60\n",
            "loss 0.005564862345307069 average time 2.16914315935004 iter num 80\n",
            "loss 0.00555271710722543 average time 2.168764626500042 iter num 100\n",
            "loss 0.005330112548823415 average time 2.154422758950068 iter num 20\n",
            "loss 0.005145802321220888 average time 2.1475720295750533 iter num 40\n",
            "loss 0.005030294877813355 average time 2.158201944250019 iter num 60\n",
            "loss 0.0049791236829741 average time 2.160695621387538 iter num 80\n",
            "loss 0.004968491125570212 average time 2.163753454460011 iter num 100\n",
            "loss 0.004771039482034367 average time 2.163380750600072 iter num 20\n",
            "loss 0.0046062146436476915 average time 2.1813316568501477 iter num 40\n",
            "loss 0.0045033700859184655 average time 2.1786208550667805 iter num 60\n",
            "loss 0.004458119832233613 average time 2.1629501125626236 iter num 80\n",
            "loss 0.00444873971557145 average time 2.1701168110601063 iter num 100\n",
            "loss 0.00427610504971877 average time 2.153660684100032 iter num 20\n",
            "loss 0.004127671521684848 average time 2.1749156373000007 iter num 40\n",
            "loss 0.004034391438857016 average time 2.1812392130499876 iter num 60\n",
            "loss 0.003993313902647274 average time 2.1754923118499505 iter num 80\n",
            "loss 0.003984803919136782 average time 2.167232159369951 iter num 100\n",
            "loss 0.0038283324502938806 average time 2.151052285099786 iter num 20\n",
            "loss 0.0036968430307482425 average time 2.148292153399916 iter num 40\n",
            "loss 0.0036134323730698994 average time 2.1455231766666203 iter num 60\n",
            "loss 0.0035762537626162173 average time 2.16620822430001 iter num 80\n",
            "loss 0.0035685194368509465 average time 2.1767111947100055 iter num 100\n",
            "loss 0.0034248329171219873 average time 2.1590544220499397 iter num 20\n",
            "loss 0.003303490688504437 average time 2.1524973948749904 iter num 40\n",
            "loss 0.003226914978188427 average time 2.164557352033368 iter num 60\n",
            "loss 0.0031930911753523107 average time 2.169482512099978 iter num 80\n",
            "loss 0.003186062936534016 average time 2.1664939183099796 iter num 100\n",
            "loss 0.0030561720480429184 average time 2.163973015649981 iter num 20\n",
            "loss 0.002946071249191493 average time 2.1643247632500104 iter num 40\n",
            "loss 0.002875868707435956 average time 2.1698976438833597 iter num 60\n",
            "loss 0.0028446923963144056 average time 2.169380177750054 iter num 80\n",
            "loss 0.002838213192692756 average time 2.166004493710034 iter num 100\n",
            "loss 0.002718670402755426 average time 2.139186626100036 iter num 20\n",
            "loss 0.002616562064788744 average time 2.1374126331250407 iter num 40\n",
            "loss 0.0025511443911650352 average time 2.1474825350500395 iter num 60\n",
            "loss 0.0025220665543215785 average time 2.147083547475006 iter num 80\n",
            "loss 0.00251601006395076 average time 2.150172997740019 iter num 100\n",
            "loss 0.00240420826127824 average time 2.169858302500006 iter num 20\n",
            "loss 0.002308997353169479 average time 2.178368339499957 iter num 40\n",
            "loss 0.002248041145617644 average time 2.1638961414333 iter num 60\n",
            "loss 0.0022207604123338966 average time 2.16036578423749 iter num 80\n",
            "loss 0.0022150681555824577 average time 2.160410569409996 iter num 100\n",
            "loss 0.002109407538378103 average time 2.1569738781498926 iter num 20\n",
            "loss 0.0020194555174617543 average time 2.169591688224932 iter num 40\n",
            "loss 0.0019622106225627924 average time 2.163408032283299 iter num 60\n",
            "loss 0.0019366932708031143 average time 2.1628902615875063 iter num 80\n",
            "loss 0.0019313627947402246 average time 2.16481139550001 iter num 100\n",
            "loss 0.0018322074811396912 average time 2.1469196974998797 iter num 20\n",
            "loss 0.0017475623465269153 average time 2.1484416860499778 iter num 40\n",
            "loss 0.0016935032803329468 average time 2.1433573305666718 iter num 60\n",
            "loss 0.001669404066021662 average time 2.146345044887505 iter num 80\n",
            "loss 0.001664371512854654 average time 2.1406995438799914 iter num 100\n",
            "loss 0.0015710408618032359 average time 2.130302407499994 iter num 20\n",
            "loss 0.0014918119376217433 average time 2.113757397399945 iter num 40\n",
            "loss 0.0014415090166880467 average time 2.115041312899954 iter num 60\n",
            "loss 0.0014191893384121604 average time 2.133182161649927 iter num 80\n",
            "loss 0.0014145524691863561 average time 2.139572730029922 iter num 100\n",
            "loss 0.0013285420996336456 average time 2.1487749815499226 iter num 20\n",
            "loss 0.0012558729617087065 average time 2.156046116949915 iter num 40\n",
            "loss 0.0012098560019835436 average time 2.1442631917832538 iter num 60\n",
            "loss 0.0011895102152598947 average time 2.1401186745249445 iter num 80\n",
            "loss 0.0011852887760685398 average time 2.1392724340299445 iter num 100\n",
            "loss 0.001107300864154146 average time 2.1529856642500818 iter num 20\n",
            "loss 0.0010420013553479805 average time 2.1713295354000364 iter num 40\n",
            "loss 0.0010009385927367644 average time 2.159666770249972 iter num 60\n",
            "loss 0.0009828654487087684 average time 2.1519608593749466 iter num 80\n",
            "loss 0.0009791156964753245 average time 2.15033390259995 iter num 100\n",
            "loss 0.0009105843064464984 average time 2.1551744353999767 iter num 20\n",
            "loss 0.0008541696591824435 average time 2.1393095447250063 iter num 40\n",
            "loss 0.0008192858086050557 average time 2.1468894629166395 iter num 60\n",
            "loss 0.0008041195861729217 average time 2.14888637143747 iter num 80\n",
            "loss 0.0008009927865741439 average time 2.1488469548799913 iter num 100\n",
            "loss 0.0007441483322558483 average time 2.1410528399500435 iter num 20\n",
            "loss 0.0006978419519333564 average time 2.154972892750061 iter num 40\n",
            "loss 0.0006695852254479279 average time 2.1496282919834053 iter num 60\n",
            "loss 0.0006573825703226974 average time 2.1527352766250147 iter num 80\n",
            "loss 0.0006548732208114742 average time 2.149759811060021 iter num 100\n",
            "loss 0.0006095863480257466 average time 2.1541973938498815 iter num 20\n",
            "loss 0.0005734288467445075 average time 2.1346613523248834 iter num 40\n",
            "loss 0.0005516628727813144 average time 2.1395115516833356 iter num 60\n",
            "loss 0.000542291103607107 average time 2.1375796274625145 iter num 80\n",
            "loss 0.0005403706723843493 average time 2.136786409740034 iter num 100\n",
            "loss 0.0005059809887713855 average time 2.1535975816002066 iter num 20\n",
            "loss 0.00047923566518180504 average time 2.151731264250111 iter num 40\n",
            "loss 0.0004634964054037417 average time 2.1570117110667524 iter num 60\n",
            "loss 0.00045682573467852614 average time 2.175951214012457 iter num 80\n",
            "loss 0.0004554625734696231 average time 2.176416005149913 iter num 100\n",
            "loss 0.00043112744344766195 average time 2.1795640502501556 iter num 20\n",
            "loss 0.0004122273425871705 average time 2.150796643125068 iter num 40\n",
            "loss 0.0004011655915004259 average time 2.143816652966689 iter num 60\n",
            "loss 0.0003965149104015843 average time 2.1545796034000206 iter num 80\n",
            "loss 0.00039556517622396447 average time 2.153861559630004 iter num 100\n",
            "loss 0.00037870447740184304 average time 2.2051531833001716 iter num 20\n",
            "loss 0.00036577441926471325 average time 2.193153956175047 iter num 40\n",
            "loss 0.00035823658627489127 average time 2.1728937527666554 iter num 60\n",
            "loss 0.0003550513233847761 average time 2.180227208775045 iter num 80\n",
            "loss 0.0003544014092982138 average time 2.173492403470027 iter num 100\n",
            "loss 0.0003429761851319561 average time 2.1475851246499587 iter num 20\n",
            "loss 0.00033430526497004424 average time 2.164209378525038 iter num 40\n",
            "loss 0.0003292365544736486 average time 2.17248793664988 iter num 60\n",
            "loss 0.0003270894348178094 average time 2.180121975649945 iter num 80\n",
            "loss 0.0003266517840606835 average time 2.178866337429954 iter num 100\n",
            "loss 0.0003188381969377603 average time 2.1638591832997918 iter num 20\n",
            "loss 0.00031286426946676714 average time 2.1557102575498446 iter num 40\n",
            "loss 0.00030938213719941353 average time 2.1559870863499477 iter num 60\n",
            "loss 0.0003078925714247985 average time 2.1630215181999572 iter num 80\n",
            "loss 0.00030758850654042074 average time 2.165178087249915 iter num 100\n",
            "loss 0.00030323070110661865 average time 2.133860889549942 iter num 20\n",
            "loss 0.00029818293795295285 average time 2.166473594449917 iter num 40\n",
            "loss 0.0002956661977770268 average time 2.154694104333248 iter num 60\n",
            "loss 0.0002945824469312041 average time 2.1624368419624487 iter num 80\n",
            "loss 0.00029435315398780533 average time 2.164639682639936 iter num 100\n",
            "loss 0.00029044752452098014 average time 2.1585139768997577 iter num 20\n",
            "loss 0.0002872959895897718 average time 2.159896434424945 iter num 40\n",
            "loss 0.0002853411321958185 average time 2.153678897883401 iter num 60\n",
            "loss 0.0002844872543905218 average time 2.1594857578500752 iter num 80\n",
            "loss 0.00028431073826990926 average time 2.160361690440059 iter num 100\n",
            "loss 0.0002812072514947444 average time 2.1725204919497627 iter num 20\n",
            "loss 0.00027838843269611816 average time 2.178733237124834 iter num 40\n",
            "loss 0.00027674431832688627 average time 2.1826250368665567 iter num 60\n",
            "loss 0.00027599929512709125 average time 2.1857512997499726 iter num 80\n",
            "loss 0.00027584506997878247 average time 2.1800596622899864 iter num 100\n",
            "loss 0.0002727664031253485 average time 2.180848069499734 iter num 20\n",
            "loss 0.00027122986742714563 average time 2.1780354621249445 iter num 40\n",
            "loss 0.00026948967788807427 average time 2.167610423949918 iter num 60\n",
            "loss 0.0002689263098084445 average time 2.1687480724624266 iter num 80\n",
            "loss 0.00026881723868548487 average time 2.163061639729967 iter num 100\n",
            "loss 0.00026646780778857024 average time 2.1574979133499257 iter num 20\n",
            "loss 0.0002644475138875583 average time 2.172976887449977 iter num 40\n",
            "loss 0.0002631559024356011 average time 2.156616129149976 iter num 60\n",
            "loss 0.00026257749700638565 average time 2.1565740912125646 iter num 80\n",
            "loss 0.00026245656046936167 average time 2.1562213308200624 iter num 100\n",
            "loss 0.0002601983007004121 average time 2.1556289863498934 iter num 20\n",
            "loss 0.00025825563007049923 average time 2.1379157543749896 iter num 40\n",
            "loss 0.0002570012796596273 average time 2.1500672525000484 iter num 60\n",
            "loss 0.00025643713884053915 average time 2.1580320554876153 iter num 80\n",
            "loss 0.00025631917242719033 average time 2.1650460440201096 iter num 100\n",
            "loss 0.0002541147917899189 average time 2.165837317450132 iter num 20\n",
            "loss 0.0002522167560035161 average time 2.1886411581499035 iter num 40\n",
            "loss 0.00025098878845704515 average time 2.1900869297498504 iter num 60\n",
            "loss 0.0002504338679617176 average time 2.1822379068498776 iter num 80\n",
            "loss 0.0002503175984182038 average time 2.182452914919959 iter num 100\n",
            "loss 0.0002481435935809558 average time 2.145433668049827 iter num 20\n",
            "loss 0.00024625593640009155 average time 2.182690776624986 iter num 40\n",
            "loss 0.0002450406429754581 average time 2.179423339433227 iter num 60\n",
            "loss 0.0002444945536166813 average time 2.175638515524929 iter num 80\n",
            "loss 0.00024438046451284143 average time 2.1720314698099537 iter num 100\n",
            "loss 0.00024198945389011965 average time 2.1659415694502058 iter num 20\n",
            "loss 0.0002403458575203648 average time 2.1671523580250325 iter num 40\n",
            "loss 0.00023924008549938214 average time 2.1672748712833405 iter num 60\n",
            "loss 0.0002386922245290233 average time 2.172796341837511 iter num 80\n",
            "loss 0.0002385895122848684 average time 2.1649743429399133 iter num 100\n",
            "loss 0.00023985035581540687 average time 2.147110907249771 iter num 20\n",
            "loss 0.00023528203909210994 average time 2.152867355474973 iter num 40\n",
            "loss 0.0002347015141950986 average time 2.159675798683293 iter num 60\n",
            "loss 0.00023405173941596746 average time 2.164413544575018 iter num 80\n",
            "loss 0.00023400677726209923 average time 2.1737179244699654 iter num 100\n",
            "loss 0.00023254687079944973 average time 2.141170348849937 iter num 20\n",
            "loss 0.00023121196719626426 average time 2.145372663074977 iter num 40\n",
            "loss 0.0002304044412296807 average time 2.156911852299951 iter num 60\n",
            "loss 0.00023002956435765328 average time 2.1667730234499913 iter num 80\n",
            "loss 0.00022995214875453157 average time 2.1723057646800044 iter num 100\n",
            "loss 0.0002285020012292133 average time 2.1703723744499257 iter num 20\n",
            "loss 0.0002272447601622405 average time 2.179854145849822 iter num 40\n",
            "loss 0.00022643051942830523 average time 2.1688596587165194 iter num 60\n",
            "loss 0.0002260652254486035 average time 2.182428589237361 iter num 80\n",
            "loss 0.00022598875230659608 average time 2.177138144299879 iter num 100\n",
            "loss 0.0002245586829979813 average time 2.157371055800104 iter num 20\n",
            "loss 0.00022331999798002865 average time 2.173367498750076 iter num 40\n",
            "loss 0.00022251724526969703 average time 2.163433284816741 iter num 60\n",
            "loss 0.00022215563283158312 average time 2.159213038987491 iter num 80\n",
            "loss 0.0002220799504924874 average time 2.157670457029981 iter num 100\n",
            "loss 0.0002206615043528651 average time 2.1156989630499994 iter num 20\n",
            "loss 0.000219436105190107 average time 2.1009052264248567 iter num 40\n",
            "loss 0.00021864608165817647 average time 2.1196776318332318 iter num 60\n",
            "loss 0.00021829081608088657 average time 2.127558753074959 iter num 80\n",
            "loss 0.00021821648333063008 average time 2.1348686456699397 iter num 100\n",
            "loss 0.00021682103922620832 average time 2.168061844699878 iter num 20\n",
            "loss 0.00021561138074134442 average time 2.1656236939751126 iter num 40\n",
            "loss 0.0002148282590185485 average time 2.161818710850033 iter num 60\n",
            "loss 0.00021447570258543235 average time 2.1510622345249883 iter num 80\n",
            "loss 0.00021440237209718275 average time 2.142382085539939 iter num 100\n",
            "loss 0.0002130207062353791 average time 2.1545132092501262 iter num 20\n",
            "loss 0.00021181958401487574 average time 2.164344802325104 iter num 40\n",
            "loss 0.00021104192936648576 average time 2.153692644883419 iter num 60\n",
            "loss 0.00021069256036708607 average time 2.1611103858375373 iter num 80\n",
            "loss 0.0002106193077444405 average time 2.1572782934800125 iter num 100\n",
            "loss 0.00020925181625492935 average time 2.1611777731499386 iter num 20\n",
            "loss 0.0002080691705572855 average time 2.1938833875500223 iter num 40\n",
            "loss 0.00020730364798516253 average time 2.1738228325833613 iter num 60\n",
            "loss 0.00020696003836445995 average time 2.1683638351000356 iter num 80\n",
            "loss 0.00020688782648773911 average time 2.169223022770002 iter num 100\n",
            "loss 0.00020556565347033245 average time 2.1231685947504046 iter num 20\n",
            "loss 0.00020437233949719644 average time 2.136112849450092 iter num 40\n",
            "loss 0.00020362684673691503 average time 2.1404768234167024 iter num 60\n",
            "loss 0.0002032884120060839 average time 2.158043715599979 iter num 80\n",
            "loss 0.00020321751433301352 average time 2.155558721129946 iter num 100\n",
            "loss 0.00020917811035741718 average time 2.1677330242998325 iter num 20\n",
            "loss 0.00020136208725428067 average time 2.179216873699943 iter num 40\n",
            "loss 0.00020032904529538787 average time 2.185363018433236 iter num 60\n",
            "loss 0.0001999479908540976 average time 2.188204698149934 iter num 80\n",
            "loss 0.00019985340567296972 average time 2.18245998245995 iter num 100\n",
            "loss 0.00019861081100060573 average time 2.1420514266500503 iter num 20\n",
            "loss 0.00019765388326269256 average time 2.1403133554751093 iter num 40\n",
            "loss 0.0001970181741942254 average time 2.1495174519667066 iter num 60\n",
            "loss 0.00019673180057907556 average time 2.1500447937000446 iter num 80\n",
            "loss 0.00019667097250350172 average time 2.1518412236400764 iter num 100\n",
            "loss 0.00019554093091377973 average time 2.205997983949783 iter num 20\n",
            "loss 0.00019452443335393982 average time 2.1869278738748106 iter num 40\n",
            "loss 0.0001938896943875527 average time 2.18077237903323 iter num 60\n",
            "loss 0.00019359870747625766 average time 2.1809698141249783 iter num 80\n",
            "loss 0.00019353778605168926 average time 2.178131224539975 iter num 100\n",
            "loss 0.00019436500411694143 average time 2.142852072849928 iter num 20\n",
            "loss 0.00019129910592700366 average time 2.165834823249952 iter num 40\n",
            "loss 0.00019086874483171057 average time 2.1765017620000737 iter num 60\n",
            "loss 0.0001905134042538406 average time 2.1681099940750754 iter num 80\n",
            "loss 0.00019046163510434992 average time 2.1641003769300915 iter num 100\n",
            "loss 0.0001908318054662081 average time 2.16223250790008 iter num 20\n",
            "loss 0.00018856179306969947 average time 2.147363051750017 iter num 40\n",
            "loss 0.00018847860446518267 average time 2.1526822481833734 iter num 60\n",
            "loss 0.00018798226247159004 average time 2.151309839912551 iter num 80\n",
            "loss 0.0001879318706741175 average time 2.1575301881000812 iter num 100\n",
            "loss 0.00018698446985784603 average time 2.14365978984988 iter num 20\n",
            "loss 0.00018620248383459845 average time 2.164140094674849 iter num 40\n",
            "loss 0.00018570755600573802 average time 2.163305416649958 iter num 60\n",
            "loss 0.00018548496003375472 average time 2.1608294689875036 iter num 80\n",
            "loss 0.00018543840572098663 average time 2.1557465275599497 iter num 100\n",
            "loss 0.00018456931241753963 average time 2.1510556748499767 iter num 20\n",
            "loss 0.0001838160740677498 average time 2.139996192650051 iter num 40\n",
            "loss 0.0001833288528327283 average time 2.145557785116701 iter num 60\n",
            "loss 0.00018310987274106102 average time 2.1384719773500365 iter num 80\n",
            "loss 0.00018306440094062888 average time 2.1396780270300586 iter num 100\n",
            "loss 0.0001822058140344354 average time 2.1667626276997907 iter num 20\n",
            "loss 0.00018146048709219778 average time 2.159998763299973 iter num 40\n",
            "loss 0.00018097677549218526 average time 2.1586627947832917 iter num 60\n",
            "loss 0.0001807588172804787 average time 2.160666988900016 iter num 80\n",
            "loss 0.0001807131907878365 average time 2.157868817550043 iter num 100\n",
            "loss 0.0001798576358024351 average time 2.210149158200238 iter num 20\n",
            "loss 0.00017911328322677345 average time 2.1806837915502 iter num 40\n",
            "loss 0.0001786279017662511 average time 2.1729755324168156 iter num 60\n",
            "loss 0.0001784083593079324 average time 2.174326476125157 iter num 80\n",
            "loss 0.0001783625445603062 average time 2.1814994582901273 iter num 100\n",
            "loss 0.00017749794897341928 average time 2.198794338350035 iter num 20\n",
            "loss 0.0001767467773640765 average time 2.1978864048750895 iter num 40\n",
            "loss 0.00017625802537120513 average time 2.188922219650097 iter num 60\n",
            "loss 0.0001760374497555339 average time 2.184373377025145 iter num 80\n",
            "loss 0.00017599103671864358 average time 2.1766986119801732 iter num 100\n",
            "loss 0.00017512014828940348 average time 2.1534979000500245 iter num 20\n",
            "loss 0.00017436329681698055 average time 2.1632753120999495 iter num 40\n",
            "loss 0.0001738683680864038 average time 2.163387324349939 iter num 60\n",
            "loss 0.0001736447444162467 average time 2.1625846685624537 iter num 80\n",
            "loss 0.00017359810261562838 average time 2.166072205079981 iter num 100\n",
            "loss 0.00017286570459307973 average time 2.173561631049961 iter num 20\n",
            "loss 0.00017196859230229916 average time 2.175651501375069 iter num 40\n",
            "loss 0.0001714443341847232 average time 2.167592990650034 iter num 60\n",
            "loss 0.00017122143788660804 average time 2.163463363087499 iter num 80\n",
            "loss 0.00017117442107136816 average time 2.16309301583 iter num 100\n",
            "loss 0.00017398417458000097 average time 2.1605865169001843 iter num 20\n",
            "loss 0.00016986354131472205 average time 2.1765880673501217 iter num 40\n",
            "loss 0.0001694104460495595 average time 2.171881201300069 iter num 60\n",
            "loss 0.0001693630466581477 average time 2.1740499254624863 iter num 80\n",
            "loss 0.0001692939982637254 average time 2.167023918919986 iter num 100\n",
            "loss 0.00016843439063975833 average time 2.135381987150231 iter num 20\n",
            "loss 0.00016784844086416712 average time 2.144564714499984 iter num 40\n",
            "loss 0.000167421358772574 average time 2.151913754649983 iter num 60\n",
            "loss 0.00016724765066461044 average time 2.151757085100121 iter num 80\n",
            "loss 0.00016720981581145634 average time 2.157924459590049 iter num 100\n",
            "loss 0.00016651350903895638 average time 2.206643285050268 iter num 20\n",
            "loss 0.00016591685938143966 average time 2.2068378164502973 iter num 40\n",
            "loss 0.00016553312803411078 average time 2.191504027300228 iter num 60\n",
            "loss 0.0001653604785455189 average time 2.1903706354001313 iter num 80\n",
            "loss 0.00016532482482674004 average time 2.1842976975301642 iter num 100\n",
            "loss 0.0001646483120111565 average time 2.144039296099436 iter num 20\n",
            "loss 0.00016406168659068566 average time 2.1537324159500715 iter num 40\n",
            "loss 0.00016367991851535355 average time 2.145534914800252 iter num 60\n",
            "loss 0.00016350765662702618 average time 2.154689036725222 iter num 80\n",
            "loss 0.0001634717241429781 average time 2.1460599867301426 iter num 100\n",
            "loss 0.00016279073013867598 average time 2.1343250767997235 iter num 20\n",
            "loss 0.00016219537137138266 average time 2.127572830000008 iter num 40\n",
            "loss 0.00016180702639728275 average time 2.122155187116611 iter num 60\n",
            "loss 0.00016163074512841278 average time 2.1225684874374564 iter num 80\n",
            "loss 0.00016159447523098915 average time 2.1291770413300037 iter num 100\n",
            "loss 0.0001608968606022173 average time 2.1431832223004674 iter num 20\n",
            "loss 0.00016028799291387943 average time 2.1681887327004006 iter num 40\n",
            "loss 0.00015988890886111659 average time 2.1756472894668453 iter num 60\n",
            "loss 0.00015970827805597646 average time 2.1665660150750683 iter num 80\n",
            "loss 0.00015967069990662747 average time 2.158564004349937 iter num 100\n",
            "loss 0.00015895476729164707 average time 2.1479320352000286 iter num 20\n",
            "loss 0.00015832521050505207 average time 2.176760555374949 iter num 40\n",
            "loss 0.00015791232927542522 average time 2.1797782096498244 iter num 60\n",
            "loss 0.00015772597821697088 average time 2.185810032424797 iter num 80\n",
            "loss 0.00015768708485857776 average time 2.1752145541398202 iter num 100\n",
            "loss 0.0001569495915648941 average time 2.1210866061501292 iter num 20\n",
            "loss 0.00015630477211452248 average time 2.1286113018750257 iter num 40\n",
            "loss 0.00015588276168140483 average time 2.145894685283444 iter num 60\n",
            "loss 0.00015569134557500905 average time 2.146046592524999 iter num 80\n",
            "loss 0.00015565125392768024 average time 2.147199948910129 iter num 100\n",
            "loss 0.0001549276249507624 average time 2.1158617785496974 iter num 20\n",
            "loss 0.0001542268708788123 average time 2.131510689624702 iter num 40\n",
            "loss 0.00015379889607570674 average time 2.1255249152498434 iter num 60\n",
            "loss 0.00015360070384434679 average time 2.1324338280375286 iter num 80\n",
            "loss 0.00015355973192647478 average time 2.1332866296699287 iter num 100\n",
            "loss 0.000152893988921242 average time 2.1454676629502503 iter num 20\n",
            "loss 0.00015315245999454404 average time 2.143711525325125 iter num 40\n",
            "loss 0.00015204818526859268 average time 2.1516099688167136 iter num 60\n",
            "loss 0.0001517774349884026 average time 2.146838176587471 iter num 80\n",
            "loss 0.00015174403991253103 average time 2.1439753170197946 iter num 100\n",
            "loss 0.00015098866601218132 average time 2.153222388250106 iter num 20\n",
            "loss 0.00015037264853863161 average time 2.1356205376250728 iter num 40\n",
            "loss 0.0001499832207016275 average time 2.143800950950026 iter num 60\n",
            "loss 0.00014980946611711543 average time 2.1406260009125164 iter num 80\n",
            "loss 0.00014977308336807792 average time 2.142533017460155 iter num 100\n",
            "loss 0.00014909236380459742 average time 2.135780959249678 iter num 20\n",
            "loss 0.0001485016743890215 average time 2.1431775096749335 iter num 40\n",
            "loss 0.00014811811863209198 average time 2.1603486544165813 iter num 60\n",
            "loss 0.00014794508089516662 average time 2.1607302215501023 iter num 80\n",
            "loss 0.0001479089083567094 average time 2.1565766340100527 iter num 100\n",
            "loss 0.00014722689685406888 average time 2.1585131874497163 iter num 20\n",
            "loss 0.00014662915776629022 average time 2.144603043549705 iter num 40\n",
            "loss 0.00014623888995083376 average time 2.1416398638663545 iter num 60\n",
            "loss 0.00014606209686962254 average time 2.1313661974247227 iter num 80\n",
            "loss 0.0001460251238901426 average time 2.1349373388798267 iter num 100\n",
            "loss 0.00014532578442140703 average time 2.1639818170006038 iter num 20\n",
            "loss 0.00014471257628387974 average time 2.1639218778506804 iter num 40\n",
            "loss 0.00014430999088267365 average time 2.1575638273005096 iter num 60\n",
            "loss 0.00014412743932965672 average time 2.1565085219629054 iter num 80\n",
            "loss 0.00014408914371750932 average time 2.1593329388303757 iter num 100\n",
            "loss 0.00014343230417326267 average time 2.1618224231504426 iter num 20\n",
            "loss 0.00014274748481217487 average time 2.168536577325085 iter num 40\n",
            "loss 0.0001423192396751839 average time 2.1819987139831936 iter num 60\n",
            "loss 0.0001421337615475822 average time 2.177693762337367 iter num 80\n",
            "loss 0.00014209409737325613 average time 2.173710853529956 iter num 100\n",
            "loss 0.00014269395297497668 average time 2.200712651049616 iter num 20\n",
            "loss 0.00014157949065146108 average time 2.1807290268497126 iter num 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-4197a39c0ae8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-4197a39c0ae8>\u001b[0m in \u001b[0;36mtrain_update\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_order_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompute_deltas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# print(y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-4197a39c0ae8>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_order_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompute_deltas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;31m# print(y_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-4197a39c0ae8>\u001b[0m in \u001b[0;36mcompute_deltas\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m       \u001b[0mfirst_order_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_order_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# normalize the parameter to range [0-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_fEzULvKwR-"
      },
      "source": [
        "# 20:32\n",
        "# 1:56"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b3be0cc-7ec7-4b6f-f8b8-dc8109dcbf5e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_BS_oneDS_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a71c75ef-e2f8-4da6-9f24-8839d3bfcd05"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2848927e-6eae-4dfa-90d5-e2db657ce19f"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_BS_oneDS_2.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "329a236f-a629-4ec8-d2b0-6eb57ebc596e"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=6, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc5): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc6): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5239e77f-519d-46b0-db4f-fac43c63ea4c"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 100000, batch = 1, seed = np.random.randint(10000), stocks = 1) # must have random seed. It doesn't matter how many batch here (not taken into function). Use max_len to adjust\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x.float())\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x.float()\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 50)\n",
        "\n",
        "model_save_name = 'jax_european_1stock_BS_oneDS_2.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.00014343598652116147 average time 2.1517012593494655 iter num 20\n",
            "loss 0.00014397651055074426 average time 2.1567439403997923 iter num 40\n",
            "loss 0.00014147028012654844 average time 2.159693487033231 iter num 60\n",
            "loss 0.00014155845974380953 average time 2.1718470632125446 iter num 80\n",
            "loss 0.00014153674193813793 average time 2.1683865032501126 iter num 100\n",
            "loss 0.0001411492403129057 average time 2.179297355850031 iter num 20\n",
            "loss 0.000140663668273772 average time 2.152569434875022 iter num 40\n",
            "loss 0.00014044119848717816 average time 2.152489299066595 iter num 60\n",
            "loss 0.0001403293634534273 average time 2.1646394438875176 iter num 80\n",
            "loss 0.000140309619323086 average time 2.165091931220086 iter num 100\n",
            "loss 0.00013987734443052124 average time 2.213684456700139 iter num 20\n",
            "loss 0.00013952138761062083 average time 2.1948286310753247 iter num 40\n",
            "loss 0.0001393020191195068 average time 2.1939285673835913 iter num 60\n",
            "loss 0.000139204043281672 average time 2.183612899875243 iter num 80\n",
            "loss 0.00013918452617803616 average time 2.182504193890127 iter num 100\n",
            "loss 0.00013879738101308306 average time 2.178213723549379 iter num 20\n",
            "loss 0.00013847229104200592 average time 2.180704508899635 iter num 40\n",
            "loss 0.00013826713083919245 average time 2.1916701098665725 iter num 60\n",
            "loss 0.00013817505290161395 average time 2.206166658187476 iter num 80\n",
            "loss 0.00013815651465593436 average time 2.2115470672899393 iter num 100\n",
            "loss 0.00013778998156412472 average time 2.1924424455492044 iter num 20\n",
            "loss 0.00013747385544062772 average time 2.1803667434746785 iter num 40\n",
            "loss 0.0001372695553453941 average time 2.1793076862997625 iter num 60\n",
            "loss 0.00013717705467859175 average time 2.1775685617872567 iter num 80\n",
            "loss 0.0001371579290981371 average time 2.183366190309789 iter num 100\n",
            "loss 0.00013678586720251474 average time 2.1633561918006308 iter num 20\n",
            "loss 0.00013646036029202186 average time 2.188063856075405 iter num 40\n",
            "loss 0.00013624754104785293 average time 2.18947039306701 iter num 60\n",
            "loss 0.0001361514306034835 average time 2.1855772624502605 iter num 80\n",
            "loss 0.0001361311784003808 average time 2.183439059600241 iter num 100\n",
            "loss 0.00013574055783461842 average time 2.1814414125496113 iter num 20\n",
            "loss 0.0001353955908093481 average time 2.1767075078499145 iter num 40\n",
            "loss 0.0001351685999609814 average time 2.177639197716538 iter num 60\n",
            "loss 0.00013506425287228022 average time 2.1709037739999077 iter num 80\n",
            "loss 0.00013504247175974765 average time 2.1686507857499238 iter num 100\n",
            "loss 0.00013462236811654193 average time 2.2109480021996206 iter num 20\n",
            "loss 0.00013425090443828892 average time 2.1822483351998017 iter num 40\n",
            "loss 0.00013400423533879697 average time 2.1818844794330894 iter num 60\n",
            "loss 0.0001338917816348149 average time 2.1947026712247406 iter num 80\n",
            "loss 0.00013386825770529212 average time 2.189605169759816 iter num 100\n",
            "loss 0.00013341596967962927 average time 2.160711644849653 iter num 20\n",
            "loss 0.00013301470500338985 average time 2.1813428280746847 iter num 40\n",
            "loss 0.00013274948716039206 average time 2.1821620527998675 iter num 60\n",
            "loss 0.00013262796110717184 average time 2.1767392148375166 iter num 80\n",
            "loss 0.00013260262308018876 average time 2.17039011871002 iter num 100\n",
            "loss 0.00013211547215824567 average time 2.197317028499492 iter num 20\n",
            "loss 0.00013168324958502962 average time 2.1931260327998645 iter num 40\n",
            "loss 0.0001313976040008451 average time 2.189696597199812 iter num 60\n",
            "loss 0.0001312675190233479 average time 2.1884824241624754 iter num 80\n",
            "loss 0.00013124029534235238 average time 2.187809863199909 iter num 100\n",
            "loss 0.00013071962806765963 average time 2.1624425745996634 iter num 20\n",
            "loss 0.00013026006336133594 average time 2.1540028003999394 iter num 40\n",
            "loss 0.00012995664394329265 average time 2.164042209083406 iter num 60\n",
            "loss 0.00012981837432333022 average time 2.161928118500009 iter num 80\n",
            "loss 0.00012978937317874352 average time 2.164272690740072 iter num 100\n",
            "loss 0.00012923533730186618 average time 2.1435802711494034 iter num 20\n",
            "loss 0.0001287456354633257 average time 2.1460261404744414 iter num 40\n",
            "loss 0.00012842215180430244 average time 2.143058068516378 iter num 60\n",
            "loss 0.0001282747247496648 average time 2.1500164329248945 iter num 80\n",
            "loss 0.00012824366619939082 average time 2.1522703634499702 iter num 100\n",
            "loss 0.00012765425791500738 average time 2.1806470040002752 iter num 20\n",
            "loss 0.00012713039792302633 average time 2.183349476625426 iter num 40\n",
            "loss 0.00012678379179132047 average time 2.1887571489172237 iter num 60\n",
            "loss 0.0001266259681228827 average time 2.1775860014129194 iter num 80\n",
            "loss 0.0001265929481511665 average time 2.1763978252904055 iter num 100\n",
            "loss 0.00012596577325773192 average time 2.207674596499783 iter num 20\n",
            "loss 0.00012541253958797547 average time 2.184721330674711 iter num 40\n",
            "loss 0.00012504931085268597 average time 2.1873881067664116 iter num 60\n",
            "loss 0.00012488418949472887 average time 2.1909523315999193 iter num 80\n",
            "loss 0.00012484946651942718 average time 2.1954068950499277 iter num 100\n",
            "loss 0.00012419377182156975 average time 2.179868367099698 iter num 20\n",
            "loss 0.0001236180788537236 average time 2.1627558664747992 iter num 40\n",
            "loss 0.00012324062627342339 average time 2.1688687900665777 iter num 60\n",
            "loss 0.00012306873412618153 average time 2.1797459169873035 iter num 80\n",
            "loss 0.00012303271748292008 average time 2.1750388323799053 iter num 100\n",
            "loss 0.00012235119973046243 average time 2.2079779152501944 iter num 20\n",
            "loss 0.00012175021860964982 average time 2.202958141374802 iter num 40\n",
            "loss 0.00012135538154059674 average time 2.194557685599951 iter num 60\n",
            "loss 0.00012117594173013316 average time 2.1793168878998133 iter num 80\n",
            "loss 0.0001211382088642925 average time 2.1809541419199014 iter num 100\n",
            "loss 0.00012042665512750155 average time 2.163195443149925 iter num 20\n",
            "loss 0.00011980035362799974 average time 2.163751364249856 iter num 40\n",
            "loss 0.0001193913350057867 average time 2.1679931643498396 iter num 60\n",
            "loss 0.00011920573534308404 average time 2.1659759302123347 iter num 80\n",
            "loss 0.00011916673995034002 average time 2.1637897559598422 iter num 100\n",
            "loss 0.00011843145223763523 average time 2.173149598499731 iter num 20\n",
            "loss 0.00011779066923523965 average time 2.17552469939983 iter num 40\n",
            "loss 0.00011737283515072588 average time 2.1763733239166565 iter num 60\n",
            "loss 0.00011718355099514493 average time 2.1762770449874553 iter num 80\n",
            "loss 0.00011714404517117536 average time 2.172792345279995 iter num 100\n",
            "loss 0.00011639452956716547 average time 2.1375757486499425 iter num 20\n",
            "loss 0.00011573256991897957 average time 2.146739753699785 iter num 40\n",
            "loss 0.00011529647484444835 average time 2.148220169333096 iter num 60\n",
            "loss 0.0001150991288457603 average time 2.143504346249847 iter num 80\n",
            "loss 0.00011505762493667062 average time 2.1429587122598606 iter num 100\n",
            "loss 0.00011422319113539648 average time 2.156830160050049 iter num 20\n",
            "loss 0.00011360648508474826 average time 2.162886086524941 iter num 40\n",
            "loss 0.00011314876460036419 average time 2.173001006616626 iter num 60\n",
            "loss 0.00011294895868669148 average time 2.1676222138748926 iter num 80\n",
            "loss 0.00011290574787957838 average time 2.1719738484800475 iter num 100\n",
            "loss 0.00012549098935848752 average time 2.1836131891997868 iter num 20\n",
            "loss 0.00011328958380498505 average time 2.187889281400112 iter num 40\n",
            "loss 0.00011120434565730066 average time 2.1771045230333885 iter num 60\n",
            "loss 0.00011118776994596228 average time 2.1871684404125973 iter num 80\n",
            "loss 0.00011113637869494327 average time 2.1813144964400637 iter num 100\n",
            "loss 0.00011044981147157751 average time 2.1759543850501357 iter num 20\n",
            "loss 0.00010992444830681936 average time 2.192403730050137 iter num 40\n",
            "loss 0.00010959680135712435 average time 2.18929228156685 iter num 60\n",
            "loss 0.0001094516835603212 average time 2.183617274012704 iter num 80\n",
            "loss 0.00010942138370417513 average time 2.1782537607101404 iter num 100\n",
            "loss 0.00010885399291577294 average time 2.1718562597505295 iter num 20\n",
            "loss 0.00010836321339540327 average time 2.1780691828003 iter num 40\n",
            "loss 0.0001080450813846393 average time 2.1904317686336072 iter num 60\n",
            "loss 0.00010790117518102097 average time 2.1885396742627563 iter num 80\n",
            "loss 0.00010787107224224653 average time 2.1895967885402934 iter num 100\n",
            "loss 0.00010730099397401818 average time 2.1853585766002652 iter num 20\n",
            "loss 0.00010680522715585903 average time 2.189976996625046 iter num 40\n",
            "loss 0.00010648168793015014 average time 2.2082791709666103 iter num 60\n",
            "loss 0.00010633556281817849 average time 2.2015699930750543 iter num 80\n",
            "loss 0.00010630467173827666 average time 2.194765105500046 iter num 100\n",
            "loss 0.00010572577464675528 average time 2.1543394334501498 iter num 20\n",
            "loss 0.00010522238447244421 average time 2.166956436700093 iter num 40\n",
            "loss 0.0001048931298575391 average time 2.1742653134834353 iter num 60\n",
            "loss 0.00010474423354242556 average time 2.1790516682750423 iter num 80\n",
            "loss 0.00010471307893588467 average time 2.1816682072701585 iter num 100\n",
            "loss 0.00010412505699106873 average time 2.2026678504997106 iter num 20\n",
            "loss 0.00010362118000735534 average time 2.2117799640000158 iter num 40\n",
            "loss 0.0001032885521521999 average time 2.1992571426667684 iter num 60\n",
            "loss 0.00010313873163934027 average time 2.1918771296875095 iter num 80\n",
            "loss 0.00010310767611333958 average time 2.1896590098199886 iter num 100\n",
            "loss 0.00010245320731821093 average time 2.2205128953499296 iter num 20\n",
            "loss 0.00010185600397519566 average time 2.2155995160252133 iter num 40\n",
            "loss 0.00010173575079592397 average time 2.1986683232335054 iter num 60\n",
            "loss 0.0001015445298785576 average time 2.198140230025092 iter num 80\n",
            "loss 0.00010150744390097138 average time 2.1990204620300573 iter num 100\n",
            "loss 0.00010420655332686576 average time 2.2064441168504345 iter num 20\n",
            "loss 0.00010118107043438301 average time 2.2067332128001 iter num 40\n",
            "loss 0.00010065045216718769 average time 2.2018662289334316 iter num 60\n",
            "loss 0.00010039116185401976 average time 2.207663272887703 iter num 80\n",
            "loss 0.00010039221740223876 average time 2.2089066555100363 iter num 100\n",
            "loss 9.977776893367504e-05 average time 2.1965285834008683 iter num 20\n",
            "loss 9.939753320737624e-05 average time 2.1827491886751886 iter num 40\n",
            "loss 9.915589235336604e-05 average time 2.1972863045499857 iter num 60\n",
            "loss 9.905252612018915e-05 average time 2.1972988857250586 iter num 80\n",
            "loss 9.903063596644057e-05 average time 2.2027757708799616 iter num 100\n",
            "loss 9.863083489516293e-05 average time 2.2296618048998424 iter num 20\n",
            "loss 9.828821394962828e-05 average time 2.224676789949899 iter num 40\n",
            "loss 9.806789806424357e-05 average time 2.2269066646500506 iter num 60\n",
            "loss 9.796894405812201e-05 average time 2.222414688262552 iter num 80\n",
            "loss 9.794859044882146e-05 average time 2.217616269940081 iter num 100\n",
            "loss 9.756323672315253e-05 average time 2.1900998117997004 iter num 20\n",
            "loss 9.722796820621551e-05 average time 2.2030692045247635 iter num 40\n",
            "loss 9.700941826951479e-05 average time 2.2098429475498658 iter num 60\n",
            "loss 9.691054798749608e-05 average time 2.2089378649123317 iter num 80\n",
            "loss 9.689001127037789e-05 average time 2.2051126683198525 iter num 100\n",
            "loss 9.649894254039551e-05 average time 2.179223914400063 iter num 20\n",
            "loss 9.615812998371002e-05 average time 2.1870632302499873 iter num 40\n",
            "loss 9.593610065531551e-05 average time 2.197755259733155 iter num 60\n",
            "loss 9.583619205362015e-05 average time 2.202236088387326 iter num 80\n",
            "loss 9.581550834132986e-05 average time 2.205396353529795 iter num 100\n",
            "loss 9.542421231446306e-05 average time 2.203310556150245 iter num 20\n",
            "loss 9.508574534098449e-05 average time 2.208830656400187 iter num 40\n",
            "loss 9.486638975926793e-05 average time 2.20527179873352 iter num 60\n",
            "loss 9.476722220176401e-05 average time 2.206643810237574 iter num 80\n",
            "loss 9.474668273633528e-05 average time 2.205420781020002 iter num 100\n",
            "loss 9.435347501923694e-05 average time 2.1996441174003847 iter num 20\n",
            "loss 9.400526112556012e-05 average time 2.2233205622749663 iter num 40\n",
            "loss 9.377729014278424e-05 average time 2.2089616253665856 iter num 60\n",
            "loss 9.367478106439828e-05 average time 2.2120331787624763 iter num 80\n",
            "loss 9.365337896185268e-05 average time 2.211012490170142 iter num 100\n",
            "loss 9.324834581321567e-05 average time 2.230961303850381 iter num 20\n",
            "loss 9.28939710306848e-05 average time 2.220976024175161 iter num 40\n",
            "loss 9.266571673491694e-05 average time 2.2181774218668577 iter num 60\n",
            "loss 9.256328294750554e-05 average time 2.22062290376266 iter num 80\n",
            "loss 9.25417749349702e-05 average time 2.2257040159800816 iter num 100\n",
            "loss 9.212750592148889e-05 average time 2.1873832024502917 iter num 20\n",
            "loss 9.179010056143769e-05 average time 2.1959595862249444 iter num 40\n",
            "loss 9.156245205842248e-05 average time 2.206985890566648 iter num 60\n",
            "loss 9.146114804467748e-05 average time 2.204155683025192 iter num 80\n",
            "loss 9.144032292448089e-05 average time 2.2056960643401906 iter num 100\n",
            "loss 9.644594440181802e-05 average time 2.2098937654502153 iter num 20\n",
            "loss 9.065153836469905e-05 average time 2.2163280567500805 iter num 40\n",
            "loss 9.04367149687696e-05 average time 2.207650179266784 iter num 60\n",
            "loss 9.037530806885674e-05 average time 2.2092483015875586 iter num 80\n",
            "loss 9.038169146323486e-05 average time 2.2101758933499878 iter num 100\n",
            "loss 9.001642497166134e-05 average time 2.2093863192500067 iter num 20\n",
            "loss 8.968606415237586e-05 average time 2.240841891975015 iter num 40\n",
            "loss 8.948720618959652e-05 average time 2.245119379616881 iter num 60\n",
            "loss 8.94010094449171e-05 average time 2.2403947544501532 iter num 80\n",
            "loss 8.938329979051097e-05 average time 2.2299703647302156 iter num 100\n",
            "loss 8.904644978072733e-05 average time 2.201104370300345 iter num 20\n",
            "loss 8.875015618845536e-05 average time 2.207446273450023 iter num 40\n",
            "loss 8.856005009593973e-05 average time 2.203810303016568 iter num 60\n",
            "loss 8.847315301819363e-05 average time 2.199928442274904 iter num 80\n",
            "loss 8.845514107227775e-05 average time 2.2089954393398874 iter num 100\n",
            "loss 9.147602962514934e-05 average time 2.2516201874002943 iter num 20\n",
            "loss 8.798261326720629e-05 average time 2.2295102670252165 iter num 40\n",
            "loss 8.7762047231039e-05 average time 2.2318585700167506 iter num 60\n",
            "loss 8.757339258400748e-05 average time 2.222396865012615 iter num 80\n",
            "loss 8.754068244102523e-05 average time 2.213674762460105 iter num 100\n",
            "loss 8.712337784314662e-05 average time 2.2263254379500723 iter num 20\n",
            "loss 8.697492203932291e-05 average time 2.223812440324764 iter num 40\n",
            "loss 8.673142705601674e-05 average time 2.214200506699611 iter num 60\n",
            "loss 8.664866241797324e-05 average time 2.217621494987179 iter num 80\n",
            "loss 8.66345616458223e-05 average time 2.215683029649699 iter num 100\n",
            "loss 8.653131320165915e-05 average time 2.1989182470497326 iter num 20\n",
            "loss 8.605840484971383e-05 average time 2.2032879050750127 iter num 40\n",
            "loss 8.584662797739734e-05 average time 2.203173375900042 iter num 60\n",
            "loss 8.577181284938512e-05 average time 2.2138191054249092 iter num 80\n",
            "loss 8.57555504825212e-05 average time 2.21012336361975 iter num 100\n",
            "loss 8.52270669536495e-05 average time 2.1950956439002764 iter num 20\n",
            "loss 8.584211830390555e-05 average time 2.2126905294251626 iter num 40\n",
            "loss 8.537908259837322e-05 average time 2.218438195133361 iter num 60\n",
            "loss 8.533529795102165e-05 average time 2.2274905502625186 iter num 80\n",
            "loss 8.530502530743776e-05 average time 2.223544159479934 iter num 100\n",
            "loss 8.492529395927941e-05 average time 2.208958036000149 iter num 20\n",
            "loss 8.462194965331065e-05 average time 2.2043048909499703 iter num 40\n",
            "loss 8.44916477332117e-05 average time 2.2105561902499176 iter num 60\n",
            "loss 8.443753690458872e-05 average time 2.209710501062318 iter num 80\n",
            "loss 8.442632505123435e-05 average time 2.218135692889773 iter num 100\n",
            "loss 8.421405012982456e-05 average time 2.2100355956497877 iter num 20\n",
            "loss 8.40366837208966e-05 average time 2.208310026174877 iter num 40\n",
            "loss 8.392111552943873e-05 average time 2.2285806758500257 iter num 60\n",
            "loss 8.38690454724782e-05 average time 2.225519938175057 iter num 80\n",
            "loss 8.385835530656096e-05 average time 2.23139464510994 iter num 100\n",
            "loss 8.365358678177636e-05 average time 2.2096249343496313 iter num 20\n",
            "loss 8.347723265367585e-05 average time 2.205567690949647 iter num 40\n",
            "loss 8.336348100590908e-05 average time 2.199378107766461 iter num 60\n",
            "loss 8.33126934505195e-05 average time 2.200581629649696 iter num 80\n",
            "loss 8.330224010993876e-05 average time 2.2038344772598064 iter num 100\n",
            "loss 8.310380165101217e-05 average time 2.2338161094003226 iter num 20\n",
            "loss 8.293204700043436e-05 average time 2.222920413650081 iter num 40\n",
            "loss 8.282113406410258e-05 average time 2.218211543399957 iter num 60\n",
            "loss 8.277040207607755e-05 average time 2.2216088167249834 iter num 80\n",
            "loss 8.275999558006049e-05 average time 2.221691192610015 iter num 100\n",
            "loss 8.256008780854232e-05 average time 2.1934050791003754 iter num 20\n",
            "loss 8.238488398272917e-05 average time 2.2020442743754756 iter num 40\n",
            "loss 8.227205878817432e-05 average time 2.193477341000228 iter num 60\n",
            "loss 8.222083294035893e-05 average time 2.1985474605875424 iter num 80\n",
            "loss 8.221035318720553e-05 average time 2.2011795260200233 iter num 100\n",
            "loss 8.200832807582163e-05 average time 2.2441340650497295 iter num 20\n",
            "loss 8.183553217869868e-05 average time 2.220541124674855 iter num 40\n",
            "loss 8.172409852673071e-05 average time 2.2143758301834775 iter num 60\n",
            "loss 8.167427623522758e-05 average time 2.2097697066001274 iter num 80\n",
            "loss 8.166418004475697e-05 average time 2.211352989030056 iter num 100\n",
            "loss 8.147008463391717e-05 average time 2.2127292446002684 iter num 20\n",
            "loss 8.130446874564925e-05 average time 2.213189624475217 iter num 40\n",
            "loss 8.11956938212906e-05 average time 2.2223979394501536 iter num 60\n",
            "loss 8.114636816129057e-05 average time 2.2138444136001 iter num 80\n",
            "loss 8.113646210587726e-05 average time 2.2126638411100794 iter num 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQs-OZHGEwac"
      },
      "source": [
        "# 2:09\n",
        "# 5:11"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1793c131-3d8b-4633-debd-9f06465b4525"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 1, 1, 0.25, 0.02, 0.02]]).cuda() # T, K, S, sigma, mu, r\n",
        "print('price: ' + str(model(inputs.float())))\n",
        "\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient[0][[2]]\n",
        "\n",
        "# price, delta\n",
        "# should be around (0.10870558, 0.581213937)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: tensor([[0.1082]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5812], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqpasxVi0hx3",
        "outputId": "370e734d-5b18-4196-a0e1-b782d467d85f"
      },
      "source": [
        "import cupy\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "import pandas as pd\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "    return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "print(bs_call(1,1,1,0.02,0.25))\n",
        "print(bs_delta(1,1,1,0.02,0.25))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10870558490557591\n",
            "0.5812139374874482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lovJwXo3-YEu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "0483254a-48c4-423d-81c1-b20af42dacd2"
      },
      "source": [
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "\n",
        "def compute_price(S):\n",
        "    inputs = torch.tensor([[1, 1, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_prices = []\n",
        "BS_call_prices = []\n",
        "for p in prices:\n",
        "    model_call_prices.append(compute_price(p).item())\n",
        "    BS_call_prices.append(bs_call(p, 1, 1, 0.02, 0.25))\n",
        "\n",
        "#plt.plot(prices, model_call_prices, label = \"model_call_prices\")\n",
        "#plt.plot(prices, BS_call_prices, label = \"BS_call_prices\")\n",
        "plt.plot(prices, np.array(model_call_prices)-np.array(BS_call_prices), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwApH0GT9bBK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "6a3266f0-a868-43d4-c593-b9232f145f5d"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 1, 1, 0.02, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHgD1NjP7DOW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "a5befa7c-80ac-4c69-d2a9-7ae60c6a69a8"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 0.75, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 0.75, 1, 0.02, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD5CAYAAAA3Os7hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3RU1drH8e9OD6SSAiGhhBKaoUkR6SBIUREsV1BB8Kr3tV6xXLAiongVO1hQERWUKogUQZpIuxKUlkBCCAFSSO89M/v940SMEEiAJDOZPJ+1ZjFzzsnMc5LwY7PP3vsorTVCCCHqPjtLFyCEEKJ6SKALIYSNkEAXQggbIYEuhBA2QgJdCCFshAS6EELYCIfKDlBKLQBuApK11tdUsF8B7wOjgHzgPq3175W9r6+vr27ZsuVlFyyEEPXZ/v37U7XWfhXtqzTQgYXAXODri+wfCbQte/QGPi7785JatmxJWFhYFT5eCCHEn5RSpy62r9IuF631DiD9EoeMAb7Whr2Al1Iq4PLLFEIIcTWqow89EDhT7nVc2TYhhBC1qFYviiqlHlRKhSmlwlJSUmrzo4UQwuZVpQ+9MvFAs3Kvg8q2XUBrPR+YD9CjR48LFpEpKSkhLi6OwsLCaihLWDsXFxeCgoJwdHS0dClC2ITqCPQ1wKNKqSUYF0OztNaJV/JGcXFxuLu707JlS4zBM8JWaa1JS0sjLi6O4OBgS5cjhE2oyrDF74BBgK9SKg54GXAE0Fp/AqzHGLIYjTFscfKVFlNYWChhXk8opfDx8UG63oSoPpUGutZ6fCX7NfBIdRUkYV5/yM9aiOpVHV0uQgghzqc1FGZCXirkpZR7pELb4RDYvdo/UgK9Bv05ecrX1/eqjqmqhQsXEhYWxty5c5kxYwZubm48/fTTlX5dbGwsN910E0eOHKnSMQcOHCAhIYFRo0Zddc1C1DmlxZB7FnLKPXKTyh7Jxp95KcZzc0nF79HQTwJdWIcDBw4QFhYmgS6sjsmsyS0sJaughKyCErILS8gtKiWvqJTcskdeUSl5RSYKik0UlBiPwhLjtSrKppEpBV9zGj7mVHzNafiaU/HVafiY0/DR6Xjp7As/Fzuy7LzItPMmy86bTPuOZDfoS7a9N7kO3uTae5Pn6E2egzeFjt7c6dWS/jVw/hLo54mNjWXEiBFcd9117N69m549ezJ58mRefvllkpOTWbx4MW3atGHKlCnExMTQoEED5s+fT+fOnUlLS2P8+PHEx8fTp08fyt/eb9GiRXzwwQcUFxfTu3dvPvroI+zt7Sut5+uvv2bOnDkopejcuTPffPMNP/74I7NmzaK4uBgfHx8WL15M48aNL+s89+/fz5QpUwAYPnz4ue0mk4lp06axfft2ioqKeOSRR3jooYfO7S8uLuall16ioKCAnTt3Mn36dIKDg3niiScoLCzE1dWVL7/8knbt2hEeHs7kyZMpLi7GbDazcuVK2rZte1l1CpFbVEpSdiFJ2YWk5BSRmltMam4RqTlFpOUZz9PziskqMML74nfV1PiRRQv7FFo7ptHcPp0glUYTlUpjcwr+5mQa6PwLvirLvhEZDn5kOTUlziGUDHsfMu19yLDzId2+EenKmxw7D8zYY9YarUGjMZvBpDUms8Zk0phKyp7rfDLzL9Jyv0pWG+iv/BhORMKF/xJejY5NPXj55k6VHhcdHc3y5ctZsGABPXv25Ntvv2Xnzp2sWbOG119/nWbNmtGtWzdWr17N1q1bmThxIgcOHOCVV16hX79+vPTSS6xbt44vvvgCgKNHj7J06VJ27dqFo6MjDz/8MIsXL2bixImXrCM8PJxZs2axe/dufH19SU83VmDo168fe/fuRSnF559/zptvvsnbb799Wd+LyZMnM3fuXAYMGMAzzzxzbvsXX3yBp6cn+/bto6ioiL59+zJ8+PBzFzCdnJyYOXPmua4dgOzsbH799VccHBzYvHkzzz33HCtXruSTTz7hiSee4O6776a4uBiTyXRZNQrbprUmu6CUhKwCErMKiM8sJDGzgITMApKyi0jKKSQpq5C84gt/bxztFT4NnfF1d8KnoTNt/NzwcHXEx8lEIEk0Lo3HtzgBz8I4GhYk4Jx7BsecOFRpuTkuJsDVGzyDwLMjeA43nnsElv3ZFNya4OnghGftfVuuitUGuiUFBwcTGhoKQKdOnRg6dChKKUJDQ4mNjeXUqVOsXLkSgCFDhpCWlkZ2djY7duzg+++/B2D06NF4e3sDsGXLFvbv30/Pnj0BKCgowN/fv9I6tm7dyh133HGuf71Ro0aAMV7/H//4B4mJiRQXF1/2OO7MzEwyMzMZMGAAAPfeey8bNmwAYNOmTRw6dIgVK1YAkJWVxfHjxwkJCbno+2VlZTFp0iSOHz+OUoqSEqP10adPH1577TXi4uIYN26ctM7rofS8YmLT8ojPKCAuo4D4zHziMwqIzywgPqPggrB2sFM09nAhwNOFDk08GBjiRxMPFxp7uODv4Yy/uzO+LhrPgjhU+glIOwRp0ZAWA3EnIee8KTAunuDVApp0gPYjjOfeLcCrOXg2A2e3Wvxu1DyrDfSqtKRrirOz87nndnZ2517b2dlRWlp62TMbtdZMmjSJ2bNnV0t9jz32GFOnTuWWW25h+/btzJgxo1reF4xaP/zwQ2688ca/bY+Njb3o17z44osMHjyYVatWERsby6BBgwCYMGECvXv3Zt26dYwaNYpPP/2UIUOGVFutwjqUmszEpuUTnZzDiZQ8YlLyOJmaS0xq3gVdC14NHAn0cqWlT0P6tvEl0MuVAE9XArxcCPRyxdfNGXu7suGseWmQGgkpv0FSFByJhLTjkHkGKNev4tYYGrWC1kPAOxgalT28g6FBo9r7RlgBqw10a9a/f38WL17Miy++yPbt2/H19cXDw4MBAwbw7bff8sILL7BhwwYyMjIAGDp0KGPGjOHJJ5/E39+f9PR0cnJyaNGixSU/Z8iQIYwdO5apU6fi4+NDeno6jRo1Iisri8BAY/2zr7766rLr9/LywsvLi507d9KvXz8WL158bt+NN97Ixx9/zJAhQ3B0dCQqKurcZ/3J3d2dnJycc6/L17Nw4cJz22NiYmjVqhWPP/44p0+f5tChQxLodZjWmoSsQiLPZhN5NpeopByOnc3hRHIuxSbzueMaezjTyteNUaEBtPJtSLBvQ4K8GxDo7YqbcwWRU5AByccgMhySjxqPlGOQn/bXMQ6u4NsWgnpB17vBpw34tIZGrcHFoxbOvm6QQL8CM2bMYMqUKXTu3JkGDRqcC9WXX36Z8ePH06lTJ66//nqaN28OQMeOHZk1axbDhw/HbDbj6OjIvHnzKg30Tp068fzzzzNw4EDs7e3p1q0bCxcuZMaMGdxxxx14e3szZMgQTp48ednn8OWXXzJlyhSUUn+7KPrPf/6T2NhYunfvjtYaPz8/Vq9e/bevHTx4MG+88QZdu3Zl+vTpPPvss0yaNIlZs2YxevToc8ctW7aMb775BkdHR5o0acJzzz132XUKy0jPK+bY2WyizuYQmZRD5NkcopJyyS0qPXdMgKcLIY3dGdDWl5DG7oQ0difYr2HFoQ1gNkFKJJw9/Ncj+SjkJPx1jLMH+HeA9jeBXzvwbWcEuWczsJMbrFVG6YtfEq5RPXr00Off4OLo0aN06NDBIvUIy5CfuWWZzZrT6flEJGYTkZBNRGI24QlZJGUXnTvGq4Ej7Rq7066J+7ngbtfYHc8Gl+h6LC2CpHBI+APOHjLCOykCSguM/XaO4NceGncyAvzPPz0CQWYQX5JSar/WukdF+6SFLkQ9UVxqJioph4gEI7TDE7I5mph97sKkvZ2irb8bfVv70iHAg/YBRnD7uTtfepkGU0lZeP9uBHjCAaPl/eekGhcvaBIKPaYYfzYJBd8QcHCqhbOuXyTQrUBaWhpDhw69YPuWLVvw8fG5qvd+5JFH2LVr19+2PfHEE0yefMVrqIk6IDO/mIjEbI4m5nC0rPV9PDmHEpPxP/IGTvZ0DPDg9muD6NTUk45NPWjj74aLYyVzI7SGrDiID4O4skfiAfhzOKCLFzTtCtc/CgFdjedeLaTVXUsk0K2Aj48PBw4cqJH3njdvXo28r7AuZ9LzWX84kd9OpnM0MZuErL/GW/u6OdEhwIMBIa3o1NSDTk09aOnTEDu7KoSsqRSSDsPpvcbjzP/+Ghpo7wwBXYyWd+C1xsO7pYS3BUmgC1FHxWXks+HwWdYeTuTgmUwA2vi70TO4ER0CPMoe7vi7u1T9TUsKIW4fxO6E03uMFnhJnrHPsxm06AvNekPQtdA4VLpNrIwEuhB1SHZhCd/vj+OHgwn8cdoI8dBAT6aNbM/o0ACaNWpweW9YPsBjdxrPTUWAgibXQNcJ0Pw64+EZVP0nJKqVBLoQdcCJlFy+3h3Liv1x5BWb6BjgwbMj2jE6NIAWPg2r/kZmEyQehJjtELMNTv/PCHBlB006Q68HoGV/I8BdvWrsfETNkEAXwkqZzZpfjqewcFcsv0Sl4GRvx81dmnLf9S0JDbqM1UUyz8CJLXBiG5z8xZjIA9D4Guj5TwgeIAFuIyTQz2Nvb09oaChaa+zt7Zk7dy7XX389+fn5PPDAAxw6dAitNV5eXvz000+4uV39WhCyjrkoL7eolJX74/hqdywxqXn4uzszdVgI43s1x8/dufI3KC2GM3vh+CY4vhlSjhrb3ZtCu1HQapDxcKt8PSFRt0ign8fV1fXciJONGzcyffp0fvnlF95//30aN27M4cOHAYiMjKxzd6uXdcytW2xqHl/tiWV5WBy5RaV0bebF+3d1ZeQ1ATg5VDJLMjcFon4yHjG/QHGOMXmnxfXQ7R5oc4Mx81JGoNg0CfRLyM7OPrdiYmJi4t+m6rdr1+6SXyvrmIuq0Frz6/FUFu6OZVtkMg52itGhAdzXN5iuzSrpAkmNhsh1cGy9MZwQbcy0DL3NuMVZ8ABwdq+V8xDWwXoDfcM0Y7pwdWoSCiPfuOQhBQUFdO3alcLCQhITE9m6dSsAU6ZMYfjw4axYsYKhQ4cyadKki4acrGMuqmJ3dCpvbozkwJlMfN2ceGxIW+7p3Rx/j4sMM9TauKAZ8QMcWwupUcb2Jp1h0DSjO6VJqLTC6zHrDXQLKd/lsmfPHiZOnMiRI0fo2rUrMTExbNq0ic2bN9OzZ0/27NlT4Tokso65uJSDZzJ5a2MkO6NTCfB0Yfa4UMZ1D8TZoYJZmlob0+kjVhtBnhELyh5a9oOeD0C7keDVrNbPQVgn6w30SlrStaFPnz6kpqaSkpKCv78/bm5ujBs3jnHjxmFnZ8f69esva2EpWce8fjuelMOcTZFsDE+iUUMnXhjdgXuua3HhdHutjQWtDq8wgjzzNNg5QPBA6P+UsRJhPVvnW1SN9Qa6FTh27BgmkwkfHx927dpFx44d8fb2pri4mIiIiHMBeD5Zx1yUl5hVwDubolj5exwNnBx48oYQ7u8ffOEys+kn4cgKOLTcuLGDnYMxGmXAs9B+tIS4qJQE+nn+7EMHo9X71VdfYW9vz4kTJ/i///s/tNaYzWZGjx7NbbfdVuF7yDrmAiCroISPt5/gy10n0Rqm9A3m4cFtaNSw3HT5/HQ4shIOLYO434xtzfvA6Heg01gJcXFZZD10YVG2+DMvKjXxzZ5TzN0WTVZBCbd2DWTqsJC/puWbSuHEVjiwCCI3gKkY/DtC6B0Qertxv0shLkLWQxeiFpjMmjUH43l7UxRxGQX0b+vLtJHt6dS0bFZn6nH4YxEcWmqsWNjAB3rcD93uNkanCHGVJNCvgqxjLsDomtsYnsQ7P0cSlZRLp6YezB4XSv+2fsadew4th7AFcHq3MUKl7TAY+SaEjJDVCkW1kkC/CrKOef2mtWZndCpzNkZyMC6LVr4NmTuhG6OuCcAuIwY2fQAHFhs3O/YOhhtmQJfx4N7E0qULG2V1ga61vvTtroTNsNT1m+qw/1Q6b22MZG9MOoFerrx5e2fGdWmCQ/RPsOgLYyVDZQ/tRxk3gAgeJDc5FjXOqgLdxcWFtLQ0fHx8JNRtnNaatLQ0XFwu4+YLVuB4Ug5vbozk54gkfN2cmHFzR8Z38cT54CKY+xlknQaPIBj8grGGikeApUsW9YhVBXpQUBBxcXGkpKRYuhRRC1xcXAgKqhs3TTibVci7P0exfP8ZGjg58PTwEO5vX4Lr7x/C+99BSb5xN58bXzOm4Ntb1V8tUU9Y1W+do6PjZU+HF6ImZRWU8MkvJ1iw8yRmrbmvT0ueaHMWz9+nwY7Nxn01Q++A3g9BQGdLlyvqOasKdCGsRYnJzOK9p3hvy3Ey80sY26Uxz7eKwffgo/D779DQ3+hWufY+cPOzdLlCABLoQlxge2Qys9YdJTo5l4Gt3Hm91XECI16AyBho1Bpues8YreJYt/r/he2TQBeizImUXGatjWBbZArtGyk29jpAyImFqJ3J0LQ73Pm1sTCWXQWrIgphBSTQRb2XnlfM3K3RfL0nFh/HYpZ2DKPX2W9Rh9Kg1WDov8BYrlZGXgkrJ4Eu6q2k7ELm74jh2/+dxrE0h4+a7+WGrJXYxWRAm2Ew8D/QrKelyxSiyqoU6EqpEcD7gD3wudb6jfP2twAWAH5AOnCP1jqummsVolqcTsvnkx0nWBEWh7Mu4O3AXdyYtRz7pCxjOv7AZyHwWkuXKcRlqzTQlVL2wDxgGBAH7FNKrdFaR5Q7bA7wtdb6K6XUEGA2cG9NFCzElTqVlsd7m4+z5mACLqqUt1uEMSpjMfYpqRAy0riNW9Ouli5TiCtWlRZ6LyBaax0DoJRaAowBygd6R2Bq2fNtwN8X4hbCgkxmzYKdJ5mzKRJHZea9kHBGpX2FfUIctOwPQ1+WrhVhE6oS6IHAmXKv44De5x1zEBiH0S0zFnBXSvlordOqpUohrlBUUg7PrDjEwTMZPNM8modKF+EQe9wYtXLrXOOOQHKxU9iI6roo+jQwVyl1H7ADiAcuuFW8UupB4EGA5s1lEX9Rc0pMZj7ZfoIPth6nl/Mp9gcuxyd5P/i2g38sMoYfSpALG1OVQI8Hyt9WPKhs2zla6wSMFjpKKTfgNq115vlvpLWeD8wH445FV1izEJd0OC6LZ1ceIisxhm/91tAzZzMU+sFN70K3ibLOirBZVfnN3ge0VUoFYwT5XcCE8gcopXyBdK21GZiOMeJFiFqVmFXAWxsj+fmP40x1Xc/EBuuwL1DQbyr0exJcPCxdohA1qtJA11qXKqUeBTZiDFtcoLUOV0rNBMK01muAQcBspZTG6HJ5pAZrFuJvcotK+WT7CT7/NZpb2MketyW4laRD6J0w9CXwalb5mwhhA6r0f0+t9Xpg/XnbXir3fAWwonpLE+LSSk1mluw7w3ubo/DPi2K957e0KjwC/j1g1AoZSy7qHelMFHXSnhNpvPTDEZKTz/JmozUMN61H2TWCMfOgywS5O5ColyTQRZ2SmlvE6+uOsuqPMzzkvpupHt/iWJCN6vkADJ4Ort6WLlEIi5FAF3WC2az59rfTvPnTMQJLTvGr3zcE5RyC5tfDqLegyTWWLlEIi5NAF1bvSHwWz68+wrEzybzu+zPj8pehSt1gzEfQdYKMJxeijAS6sFoFxSbe2xzFZ7/GcEOD4yzy+RL33Fhj9MqNr8udgoQ4jwS6sEp7Y9KYtvIQ6WkpLA1YTc+MdeDYAu75HtoMtXR5QlglCXRhVXIKS3hjwzEW/+80d3pG8Kr3ZzhnpkLfJ2DgNHBqYOkShbBaEujCamw7lsxzqw6Tn53O6sBVdE1bB34d4J4lENjd0uUJYfUk0IXF5RSW8MqPEazYH8f4RlG80uhTnNKTjCn7g6aBg7OlSxSiTpBAFxa1NyaNp5YdJCcrjTXNf6Rz8g/GiojjF0OQzPQU4nJIoAuLKCwx8famSD7feZJRnqd5x2cezinx0PffMGg6OLpYukQh6hwJdFHrwhOymLr0INFJmXzRYiuDk79CuTSDyT9B8/PvnSKEqCoJdFFrSk1m5v8aw7s/R9HJNZ3fA+fjmXQQuoyHkW/K8rZCXCUJdFErTqbm8dSyA/x+OoOZLQ5yb/o8VJ4D3L4ArrnN0uUJYRMk0EWN0lqzaO8pXl9/DC/7Ana2XkpQ/AZo0Q/GfQqeQZYuUQibIYEuakxiVgHPrjjEr8dTubdlFi8XvolDwmkY8qJxByE7e0uXKIRNkUAX1U5rzao/4nl5TTgms5ll10bQ89hbqAY+cN9aaHG9pUsUwiZJoItqdTarkOdXHWbLsWT6N3PiE69FNAxfA21ugLGfQkNfS5cohM2SQBfVQmvN8v1xvLo2ghKTmXcH2nHr8f+gomNh6MvG+HK5i5AQNUoCXVy1hMwCpn9/mF+iUujVshHzronEb/t/jLsHSReLELVGAl1cMa01S/ad4bV1RzGZNTNvCuHerE9Rmz+Dlv3h9i9lzXIhapEEurgisal5TP/+MHti0riuVSPmjAggaPO/4PQeuO4RGDYT7OXXS4jaJH/jxGUpNZn5YudJ3vk5Cid7O14fG8pdAWexWz4CCjJh3OfQ+Q5LlylEvSSBLqosPCGLaSsPczg+i2EdG/PqmGtocvw7WPgMeDSFf/4MTUItXaYQ9ZYEuqhUYYmJD7Yc59MdMXg3cGTehO6M6uSL2vgc/DYfWg+F2z6HBo0sXaoQ9ZoEurik3dGpPLfqMLFp+dx+bRAvjO6Al8qHb++EE1uhz6NGf7nM+hTC4iTQRYUy8op5bf1RVuyPo4VPAxbd35t+bX0h7QR8dxekx8AtH0L3iZYuVQhRRgJd/I3Wmh8OJDBzbQTZBSU8PKg1jw9ti4ujPcTuhKX3GAdO/AFa9rNssUKIv5FAF+ecSc/n+dVH2BGVQpdmXrwxLpQOAWVrlP/+Nax9Ehq1gvFLwKe1ZYsVQlxAAl1gNmu+2XuK//50DAW8cksn7rmuBfZ2Csxm2DoTdr4LrYcYk4VcvSxdshCiAhLo9dzJ1DyeXXGQfbEZDAjxY/a4UAK9XI2dpUXwwyNweDlcOxlGzZHJQkJYMfnbWU+ZzJoFO08yZ1Mkzg52vHV7Z26/NgillHFAQabRXx77Kwx9CfpNhT/3CSGskgR6PRSdnMNTyw9x8EwmN3RozGtjr6Gxh8tfB2TFweI7IDXKWPK2y12WK1YIUWUS6PXM+sOJPL38IM4Odrx/V1du6dL0r1Y5QFI4LLodinLg7hXQerDlihVCXBYJ9HrCZNa8vSmSj7afoFtzLz6559q/t8oBTv4KSyaAU0OYskGm8QtRx0ig1wNZ+SU8vuQPfolKYXyv5sy4pSPODufN7Dy2DpZPhkbBRsvcq5llihVCXDEJdBt37Gw2D369n8SsAl4fG8qE3s0vPOjAd8ZolqZdjTCXNVmEqJOqdE8wpdQIpVSkUipaKTWtgv3NlVLblFJ/KKUOKaVGVX+p4nKtO5TIuI92U1hiYsmDfSoO870fw+p/GbM+J66RMBeiDqu0ha6UsgfmAcOAOGCfUmqN1jqi3GEvAMu01h8rpToC64GWNVCvqAKtNR9ujeadn6O4toU3H9/dHf/z+8u1hu2z4Zf/Qoeb4bYvwMHZMgULIapFVbpcegHRWusYAKXUEmAMUD7QNVA2RxxPIKE6ixRVV1RqYtrKw6z6I55x3QOZPS70wv5ysxl+mga/fQrd7oGb3pcJQ0LYgKr8LQ4EzpR7HQf0Pu+YGcAmpdRjQEPghmqpTlyW9LxiHvomjH2xGTw9PIRHBrf5+5BEAFMprHkUDn5nLH07fJZMGBLCRlSpD70KxgMLtdZBwCjgG6XUBe+tlHpQKRWmlApLSUmppo8WANHJudw6bxcH47KYO6Ebjw5pW0GYl8CqB40wH/yChLkQNqYqgR4PlB/DFlS2rbz7gWUAWus9gAvge/4baa3na617aK17+PnJ3eCry67oVMZ9tIv84lKWPHgdN3VueuFBpcWwYgocWWnckGLgMxLmQtiYqgT6PqCtUipYKeUE3AWsOe+Y08BQAKVUB4xAlyZ4LVi27wyTFvxGE08XVj3cl+7NvS88qLQIlk+Co2tgxBvQ94naL1QIUeMq7UPXWpcqpR4FNgL2wAKtdbhSaiYQprVeAzwFfKaUehLjAul9Wmtdk4XXd2azZk7ZzM/+bX2Zd3d3PFwcLzywpACW3gvRPxurJfZ6oPaLFULUiioNbdBar8cYilh+20vlnkcAfau3NHExhSUmnl5+kLWHEhnfqxkzx1yDo30F/9kqzocl4yHmF7j5A7h2Uu0XK4SoNTJWrY5Jyy3iwW/2s/9UBtNHtufBAa0uvPgJRph/eyec2gW3fgRdJ9R+sUKIWiWBXoecSMll8pf7SMou5KO7uzMqNKDiA0sKjJb5qV3G8red76zdQoUQFiGBXkdEns3hzk/34GCn+O7B6yq++AnGBdCl9xjdLLd+JGEuRD0igV4HaK155cdw7BSsergvzX0aVHxgaTEsmwTRm40+c+lmEaJeqa6JRaIGbT2WzO4TaTwxtO3Fw9xUAiunQNQGYzSLXAAVot6RQLdyJSYzr68/Sivfhtx9XYuKDzKbYNVDcPRHuHG2DE0Uop6SQLdyS347zYmUPKaNbF/x0ESz2VjL/M8ZoH0erv0ihRBWQQLdimUXlvDu5uP0Dm7EsI6NLzxAa9jwzF9rs8gMUCHqNQl0K/bRthOk5xXzwuiOFY813zoL9n1uBPnAZ2q/QCGEVZFAt1Jn0vNZsOsk47oHEhrkeeEBuz+EX+dA90lwwyu1X6AQwupIoFuptzZGYqfgmRvbXbjz929g0wvQaSzc9K6smiiEACTQrdKBM5msOZjAA/1bEeDp+vedET/Aj49Dmxtg7Hyws6/4TYQQ9Y4EupXRWjNrbQS+bs48NLD133ee2Aor/wlBveDOr8HByTJFCiGskgS6lfnpyFnCTmXw1PAQ3JzLTeSNC4Mld4NvO5iwFJwaWq5IIYRVkkC3IsWlZt746RjtGrtzZ49yN4lKjTZWTnRrDPd+D65elitSCGG1JNCtyNd7YjmVls9zoztgb1d2oTM3GRaNAxTcsxLc/C1ZohDCisniXFYiM7+YD7dGMyDEj4EhZVxGiZMAABB3SURBVPdbLcqBxbdDXgrctxZ8Wl/6TYQQ9ZoEupX4YEs0OYUlPDeqvbHBVGKsnHj2CIxfAoHXWrZAIYTVk0C3ArGpeXyzN5Y7ezSjfRMPY0r/msfhxBa45UMIGW7pEoUQdYD0oVuB//50DEd7O6YODzE2bHsNDn4Lg56D7hMtW5wQos6QQLewfbHpbDhyln8NbI2/uwuEfQk73jKm9A981tLlCSHqEAl0CzKbNbPWHaWxhzMP9G9l3Glo3VPQdjiMfkem9AshLosEugX9eCiBg2cyeXp4O1wzImH5ZPDvCLcvAHu5vCGEuDwS6BZSWGLizZ8i6RjgwW0hTvDtP8CxAUxYAs7uli5PCFEHSTPQQhbujiU+s4C3bw3Bbul4yE+FyevBM8jSpQkh6igJdAtIySli7tZobmjny3WHnof43+Efi6BpN0uXJoSow6TLxQLe3hRJYYmJt3zWQMRqGP4qdLjJ0mUJIeo4aaHXsiPxWSwNO8P77cLx/n0uXHsf9HnU0mUJIWyAtNBrkdaaV9dGMMg1hptPvwmtBsGoOTI8UQhRLaSFXot+OnKWMyej2OLxDsqtGdyxEOwdLV2WEMJGSAu9lhSWmJiz7gBfN3wPF0qMBbdcvS1dlhDChkgLvZZ88WsM/857j9b2J1H/WAp+Fdz8WQghroK00GtBcnYhJdvncLP9XtQNL0PIjZYuSQhhgyTQa8Ha5V/wuFpKbshY6PtvS5cjhLBREug1LPLwb9x5eiZJDdvhdsfHMqJFCFFjJNBrkM7PwGP1RAqVC+73LQNHV0uXJISwYRLoNcVsJumrifiUJvNHnw9x829h6YqEEDZOAr2GFG+dTZOkHSxwe5Chw262dDlCiHqgSoGulBqhlIpUSkUrpaZVsP9dpdSBskeUUiqz+kutQyJ/wmnnm6wwDaD3nc9iZyf95kKImlfpOHSllD0wDxgGxAH7lFJrtNYRfx6jtX6y3PGPAfV32cC0E5hWPsAx3ZL917zI7S0aWboiIUQ9UZUWei8gWmsdo7UuBpYAYy5x/Hjgu+oors4pzkMvvYeCUs1TPM3UUV0sXZEQoh6pSqAHAmfKvY4r23YBpVQLIBjYevWl1TFaw49PQPJRHi58mDuG9cPP3dnSVQkh6pHqvih6F7BCa22qaKdS6kGlVJhSKiwlJaWaP9rC/vcJHF7OZw7jSfTty8Q+MqpFCFG7qhLo8UCzcq+DyrZV5C4u0d2itZ6vte6hte7h5+dX9Sqt3em9sOkFTjQayOzcUbxySycc7WUAkRCidlUldfYBbZVSwUopJ4zQXnP+QUqp9oA3sKd6S7RyeamwfDIl7kHcmTyJUaGBXN/G19JVCSHqoUoDXWtdCjwKbASOAsu01uFKqZlKqVvKHXoXsERrrWumVCtkNsP3D0J+Gm+6TydPNeC50R0sXZUQop6q0vK5Wuv1wPrztr103usZ1VdWHbHzbTixheM9X+WzX915algbAr1ker8QwjJkPfQrdXIHbHsdU6fbeSD8Glr6KB4Y0MrSVQkh6jG5cnclcpJgxf3g04b5no8Tm17AzDHX4OJob+nKhBD1mAT65TKbYOX9UJRDwvBPeHdHAqM7BzAgxIZG7Qgh6iTpcrlc22dD7K/oMR/x3C4TjnaKF0d3tHRVQgghLfTLEr0FdsyBbvew0XEI2yNTeHJYCE08XSxdmRBCSKBXWU4SrHoI/NqTN3Q2r/wYQfsm7tx3fUtLVyaEEIB0uVSN2WyEeVEuTPqRD3bEk5hVyNwJ3XCQGaFCCCshaVQVuz+AmG0wYjaR5iC+2HmSf/RoxrWyNK4QwopIoFcmLgy2vgodb0V3n8SLq4/g7uLAtJHtLV2ZEEL8jQT6pRRmwYop4N4Ubn6fFb/H81tsOtNGtse7oZOlqxNCiL+RQL8YrWHtk5AVB7d/QarJldfWH6VHC2/uuLZZ5V8vhBC1TAL9Yv5YBEdWwuDnoFkvZq2NIK+olNnjQuUeoUIIqySBXpGUSNjwLAQPgH5P8ktUCqsPJPDwoDa0bexu6eqEEKJCEujnKy0y1mlxdIWx88kv1Ty/6jCt/Bry8ODWlq5OCCEuSsahn2/rq5B0GMYvAY8A3l0XQVxGAcse6oOzgyy+JYSwXtJCLy/mF9g9F66dDO1GciQ+iy92nmR8r+b0CpYx50II6yaB/qf8dFj1L/BpDTe+RqnJzLTvD+Hj5ixjzoUQdYJ0ucBfQxTzkmH8ZnBqyJc7YjgSn828Cd3xdHW0dIVCCFEpaaEDHFwCEauNIYpNu3EmPZ93fo7ihg7+jAptYunqhBCiSiTQM2Jh/TPQoi/0/Tdaa55bdRg7BTPHXINSMuZcCFE31O9AN5XC9w+CsoOxn4CdPUv3neHX46lMG9mepnLDZyFEHVK/+9B3vgNn/gfjPgev5iRmFfDauqNc16oRd/duYenqhBDistTfFnr87/DLf+Ga26HzHWitmf79YUrNmv/e1lmm9wsh6pz6GeglBcYQxYb+MHoOACv2x7E9MoVnR7SjhU9DCxcohBCXr352uWydBamRcM/34OpNUnYhr66NoGdLbyb1aWnp6oQQ4orUvxZ67E7YMw963A9thhqjWr4/TFGpmTdv7yJdLUKIOqt+BXpRDqz+P/BuCcNfBWD1gXi2HEvmmRvbEewrXS1CiLqrfnW5bHzOuGHF5J/AqSHJOYXMWBNB9+ZeTO4bbOnqhBDiqtSfFnrURvj9a7j+cWjeG4CXVodTUGLizdu7YC9dLUKIOq5+BHp+Oqx5DPw7GdP7gS1Hk/gp/CxPDG1LG383CxcohBBXr350uaybaoT6PSvBwZmCYhMvrwmnjb8bD/RvZenqhBCiWth+Cz18lfEYNA2ahALw0fZo4jIKeHXMNTg52P63QAhRP9h2muWlwrqnoGk36PtvAE6k5PLpLzGM7RZIn9Y+Fi5QCCGqj20H+rqnjKGKt34M9g5orXn5h3CcHe2YPkpuWiGEsC22G+jhq4w1zgdNA/8OAPx4KJGd0ak8c2M7/N1dLFygEEJUL9sM9LxUWPc0BHSF658AILuwhFfXRhAa6CkrKQohbJJtjnJZ/wwUZsGkH8HeOMV3f44iNbeIzyf2kDHnQgibZHst9IgfIPx7GPQfaNwRgPCELL7aHcvdvZvTpZmXhQsUQoiaUaVAV0qNUEpFKqWilVLTLnLMnUqpCKVUuFLq2+ots4ry0mDtVAjocm5Ui9mseWH1EbwbOPHMcLkQKoSwXZV2uSil7IF5wDAgDtinlFqjtY4od0xbYDrQV2udoZTyr6mCL2nDn10ta8DeEYAl+87wx+lM3r6jC54NHC1SlhBC1IaqtNB7AdFa6xitdTGwBBhz3jEPAPO01hkAWuvk6i2zCo6uhSMrYeB/oHEnAFJzi3hjg3FLuXHdA2u9JCGEqE1VCfRA4Ey513Fl28oLAUKUUruUUnuVUiMqeiOl1INKqTClVFhKSsqVVVyRggxjen/jUOj373ObX193lIISE7NuDUUpuRAqhLBt1XVR1AFoCwwCxgOfKaUuuPqotZ6vte6hte7h5+dXTR8NbHrRGKo4Zu65rpbdJ1L5/o94/jWwtSy+JYSoF6oS6PFAs3Kvg8q2lRcHrNFal2itTwJRGAFf82K2wx/fwPWPQdOuABSVmnhh9RGaN2rAI4Pb1EoZQghhaVUJ9H1AW6VUsFLKCbgLWHPeMasxWucopXwxumBiqrHOihXnwY9PQKPWxozQMvN/iSEmJY+ZYzrh4mhf42UIIYQ1qDTQtdalwKPARuAosExrHa6UmqmUuqXssI1AmlIqAtgGPKO1Tqupos/Z9jpkxMItH4KjKwCxqXl8uC2a0Z0DGNTOMoNthBDCEqo0U1RrvR5Yf962l8o918DUskftiAuDvR9BjynQsu+fdfDiD0dwsrfjpZs61lopQghhDermTNHSYvjhUXAPgBteObd53eFEfj2eytPDQ2jsIYtvCSHql7q5lsvOdyDlKExYBi4egLH41swfjcW37u3T0rL1CSGEBdS9QE8+CjvmQOgdEHLjuc3/3XDMWHxrkiy+JYSon+pel8uJreDiCSPeOLdpX2w6i/93msl9g+kcJItvCSHqp7rXQu/zCHSdAK7egDHmfNrKQwR6uTJ1WIiFixNCCMupe4EO58IcYN62E5xIyWPh5J40dK6bpyOEENWh7nW5lBOVlMPH26O5tWtTGXMuhKj36mygm82aaSsP4ebswIsy5lwIIepuoC/63yl+P53Jizd1xMfN2dLlCCGExdXJQE/ILOC/G47Rv60vY7vJOudCCAF1MNC11rz0wxFMWvOarHMuhBDn1LlAX3/4LJuPJvPUsHY092lg6XKEEMJq1LlAd3NxYFjHxkzu29LSpQghhFWpcwO3B4b4MTCkGu92JIQQNqLOtdCFEEJUTAJdCCFshAS6EELYCAl0IYSwERLoQghhIyTQhRDCRkigCyGEjZBAF0IIG6G01pb5YKVSgFMW+fCr4wukWroIC6iv5w3199zlvK1TC611hbMrLRbodZVSKkxr3cPSddS2+nreUH/PXc677pEuFyGEsBES6EIIYSMk0C/ffEsXYCH19byh/p67nHcdI33oQghhI6SFLoQQNkIC/SKUUiOUUpFKqWil1LQK9jdXSm1TSv2hlDqklBpliTqrWxXOu4VSakvZOW9XSgVZos7qppRaoJRKVkoduch+pZT6oOz7ckgp1b22a6wJVTjv9kqpPUqpIqXU07VdX02pwnnfXfZzPqyU2q2U6lLbNV4JCfQKKKXsgXnASKAjMF4p1fG8w14AlmmtuwF3AR/VbpXVr4rnPQf4WmvdGZgJzK7dKmvMQmDEJfaPBNqWPR4EPq6FmmrDQi593unA4xg/d1uykEuf90lgoNY6FHiVOtKvLoFesV5AtNY6RmtdDCwBxpx3jAY8yp57Agm1WF9Nqcp5dwS2lj3fVsH+OklrvQMjvC5mDMY/ZFprvRfwUkoF1E51Naey89ZaJ2ut9wEltVdVzavCee/WWmeUvdwL1In/iUqgVywQOFPudVzZtvJmAPcopeKA9cBjtVNajarKeR8ExpU9Hwu4K6V8aqE2S6vK90bYpvuBDZYuoiok0K/ceGCh1joIGAV8o5SqD9/Pp4GBSqk/gIFAPGCybElC1Ayl1GCMQP+PpWupijp3k+haEg80K/c6qGxbefdT1gentd6jlHLBWAMiuVYqrBmVnrfWOoGyFrpSyg24TWudWWsVWk5VfieEDVFKdQY+B0ZqrdMsXU9V1IcW5ZXYB7RVSgUrpZwwLnquOe+Y08BQAKVUB8AFSKnVKqtfpeetlPIt9z+R6cCCWq7RUtYAE8tGu1wHZGmtEy1dlKgZSqnmwPfAvVrrKEvXU1XSQq+A1rpUKfUosBGwBxZorcOVUjOBMK31GuAp4DOl1JMYF0jv03V8llYVz3sQMFsppYEdwCMWK7gaKaW+wzg337LrIi8DjgBa608wrpOMAqKBfGCyZSqtXpWdt1KqCRCGMQDArJT6N9BRa51toZKrRRV+3i8BPsBHSimA0rqwYJfMFBVCCBshXS5CCGEjJNCFEMJGSKALIYSNkEAXQggbIYEuhBA2QgJdCCFshAS6EELYCAl0IYSwEf8PmNj10/ae+YcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7MfujMQ7oij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "cd48a21c-8690-4fdc-c054-89e1f8f1ae7a"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1.25, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 1.25, 1, 0.02, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}