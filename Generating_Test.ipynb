{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generating Test",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Judy/Generating_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e86Pm8rKt3yf"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuPE3AQX2BH1",
        "outputId": "ee6ecd70-d4ac-4712-9ab5-7547a286b89c"
      },
      "source": [
        "S_range = np.linspace(0.75, 1.25, 5)\n",
        "K_range = np.linspace(0.75, 1.25, 5)\n",
        "Sigma_range = np.linspace(0.15, 0.45, 3)\n",
        "r_range = np.linspace(0.01, 0.04, 2)\n",
        "\n",
        "print(S_range)\n",
        "print(K_range)\n",
        "print(Sigma_range)\n",
        "print(r_range)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.75  0.875 1.    1.125 1.25 ]\n",
            "[0.75  0.875 1.    1.125 1.25 ]\n",
            "[0.15 0.3  0.45]\n",
            "[0.01 0.04]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4HV-G44th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c9f168e-ab68-42ce-ff73-7da930e07a4f"
      },
      "source": [
        "%%writefile cupy_dataset.py\n",
        "import cupy\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "import pandas as pd\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "    return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "S_range = np.linspace(0.75, 1.25, 5)\n",
        "K_range = np.linspace(0.75, 1.25, 5)\n",
        "Sigma_range = np.linspace(0.15, 0.45, 3)\n",
        "r_range = np.linspace(0.01, 0.04, 2)\n",
        "\n",
        "call = []\n",
        "for i in S_range:\n",
        "  for j in K_range:\n",
        "    for l in r_range:\n",
        "      for k in Sigma_range:\n",
        "        call.append([1,j,i,k,l,l,bs_call(i,j,1,l,k),bs_delta(i,j,1,l,k)]) #T, K, S, sigma, mu, r\n",
        "Thedataset = pd.DataFrame(call)\n",
        "\n",
        "Thedataset_X = Thedataset.iloc[:,:6]\n",
        "Thedataset_Y = Thedataset.iloc[:,6:]\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len, number_path, batch, seed, stocks):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 50\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = 1.0 # assume T = 1, use float here\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        self.X = cupy.array(Thedataset_X)\n",
        "        self.Y = cupy.array(Thedataset_Y)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(self.X.toDlpack()), from_dlpack(self.Y.toDlpack()))\n",
        "\n",
        "\n",
        "# ds = OptionDataSet(max_len = 1, number_path = 10000, batch = 2, seed = np.random.randint(10000), stocks=1) # for testing purpose, use constant seed. When training, change to random seed\n",
        "# for i in ds:\n",
        "#     print(i[0])\n",
        "#     print(i[0].shape)\n",
        "#     print(i[1])\n",
        "#     print(i[1].shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cupy_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6JO9OBHdvv",
        "outputId": "bbf33bcd-fbf4-4203-988e-b83b010ea4e0"
      },
      "source": [
        "%%writefile model.py\n",
        "# version 1,2\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*1, 32) # remember to change this!\n",
        "        self.fc2 = nn.Linear(32, 64)\n",
        "        self.fc3 = nn.Linear(64, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 32)\n",
        "        self.fc6 = nn.Linear(32, 1) # 1 outputs: price\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1.0, 0.5, 0.5, 0.3, 0.03, 0.03]*1)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = (x - torch.tensor([0.0, 0.75, 0.75, 0.15, 0.01, 0.01]*1).cuda()) / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlXD80xPNVc6",
        "outputId": "69701623-e8f2-4cce-c5bf-ca8a3bf51ed9"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3CyULkENYKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b277167d-cb65-4f09-920e-cb2030aa2503"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 100000, batch = 1, seed = np.random.randint(10000), stocks = 1) # must have random seed. It doesn't matter how many batch here (not taken into function). Use max_len to adjust\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    # print(x)\n",
        "    # print(x.shape)\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    # print(y.shape)\n",
        "    y_pred = model(x.float())\n",
        "    # print(y_pred)\n",
        "    # print(y_pred.shape)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x.float()\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "    # print(y_pred)\n",
        "    # print(y_pred.shape)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.1888860525436098 average time 0.14984231329999886 iter num 20\n",
            "loss 0.1690811336374387 average time 0.1459700626250026 iter num 40\n",
            "loss 0.1536369712296809 average time 0.14475045841666656 iter num 60\n",
            "loss 0.1455405835980438 average time 0.14530027696249945 iter num 80\n",
            "loss 0.14372804828038266 average time 0.14475901188000137 iter num 100\n",
            "loss 0.10662811339287236 average time 0.14235618540000133 iter num 20\n",
            "loss 0.07440038968807451 average time 0.14295278689999974 iter num 40\n",
            "loss 0.059077172243148963 average time 0.14299817124999947 iter num 60\n",
            "loss 0.05465071148316707 average time 0.1429774612999985 iter num 80\n",
            "loss 0.05393771563482347 average time 0.14342250069999693 iter num 100\n",
            "loss 0.04740896252152207 average time 0.1477658823000013 iter num 20\n",
            "loss 0.046747206299596014 average time 0.14544273640000113 iter num 40\n",
            "loss 0.04620156178972212 average time 0.14491158003333263 iter num 60\n",
            "loss 0.045954737852790965 average time 0.144361768549998 iter num 80\n",
            "loss 0.04590441385109942 average time 0.14546625729999732 iter num 100\n",
            "loss 0.044979348214723394 average time 0.1440805644500017 iter num 20\n",
            "loss 0.044200126260709995 average time 0.14442022710000088 iter num 40\n",
            "loss 0.043690688259359185 average time 0.1444649297833346 iter num 60\n",
            "loss 0.04345704583974128 average time 0.14456676546249908 iter num 80\n",
            "loss 0.04340729554172902 average time 0.1442720532499993 iter num 100\n",
            "loss 0.04245611998347828 average time 0.14523504985000385 iter num 20\n",
            "loss 0.04162161103271871 average time 0.14630430982500114 iter num 40\n",
            "loss 0.04107269428561517 average time 0.14591226460000162 iter num 60\n",
            "loss 0.04082281643154084 average time 0.14567518688750028 iter num 80\n",
            "loss 0.04076992103462514 average time 0.14583422510999866 iter num 100\n",
            "loss 0.03976392766960764 average time 0.1438215787000047 iter num 20\n",
            "loss 0.0388762202534406 average time 0.14624679442500224 iter num 40\n",
            "loss 0.03829258915280447 average time 0.14570039649999936 iter num 60\n",
            "loss 0.03802744605631173 average time 0.14492327848749795 iter num 80\n",
            "loss 0.037971361575183694 average time 0.14471138605000136 iter num 100\n",
            "loss 0.03690315894092695 average time 0.14360578475000524 iter num 20\n",
            "loss 0.03596316754915925 average time 0.1448246632000007 iter num 40\n",
            "loss 0.03534464602900493 average time 0.14428755656666586 iter num 60\n",
            "loss 0.03506214030089112 average time 0.14410255717499892 iter num 80\n",
            "loss 0.03500235403529399 average time 0.14424357208000005 iter num 100\n",
            "loss 0.0338660843279932 average time 0.14447232895000753 iter num 20\n",
            "loss 0.03285984002897008 average time 0.14602475084999753 iter num 40\n",
            "loss 0.03219436391073185 average time 0.145736968483331 iter num 60\n",
            "loss 0.031890170034833895 average time 0.1451278134624964 iter num 80\n",
            "loss 0.0318258169809618 average time 0.14476396970999644 iter num 100\n",
            "loss 0.030601080876814166 average time 0.14340120050000849 iter num 20\n",
            "loss 0.029510121094879584 average time 0.14292420777500753 iter num 40\n",
            "loss 0.028783857629536138 average time 0.14290848238333637 iter num 60\n",
            "loss 0.028450729214761047 average time 0.14289424045000204 iter num 80\n",
            "loss 0.02838026722097706 average time 0.1429050414000028 iter num 100\n",
            "loss 0.027037543130009684 average time 0.14606350879999752 iter num 20\n",
            "loss 0.025835147168892725 average time 0.14551915017499936 iter num 40\n",
            "loss 0.025032726236395263 average time 0.14499846721666643 iter num 60\n",
            "loss 0.024665251520679707 average time 0.1447155030000012 iter num 80\n",
            "loss 0.02458770114550658 average time 0.14535158471000215 iter num 100\n",
            "loss 0.02311203365843622 average time 0.1499182667500037 iter num 20\n",
            "loss 0.0217930067014556 average time 0.15050627455000126 iter num 40\n",
            "loss 0.02091851347044268 average time 0.15022449363333312 iter num 60\n",
            "loss 0.02051965575403696 average time 0.15004142066249884 iter num 80\n",
            "loss 0.020435742534828053 average time 0.1499639555799996 iter num 100\n",
            "loss 0.01884956848433311 average time 0.14895440210000288 iter num 20\n",
            "loss 0.01745539334487308 average time 0.1485324633250059 iter num 40\n",
            "loss 0.016547522548927943 average time 0.14628901483334478 iter num 60\n",
            "loss 0.016139923476451757 average time 0.1464739097625099 iter num 80\n",
            "loss 0.016054898715877352 average time 0.14664781145000916 iter num 100\n",
            "loss 0.014475822178669504 average time 0.14679190780003068 iter num 20\n",
            "loss 0.013141443683358265 average time 0.145809174775016 iter num 40\n",
            "loss 0.012310201684500168 average time 0.14534949638334257 iter num 60\n",
            "loss 0.011948179775620984 average time 0.1448728542500035 iter num 80\n",
            "loss 0.011873748944509344 average time 0.14436260233000553 iter num 100\n",
            "loss 0.010532155513541853 average time 0.14203329769998732 iter num 20\n",
            "loss 0.009474716304185405 average time 0.14241749902499237 iter num 40\n",
            "loss 0.008857757050367988 average time 0.14216640423332857 iter num 60\n",
            "loss 0.0086007218407257 average time 0.14201356293749826 iter num 80\n",
            "loss 0.008548871001960515 average time 0.14244104943000138 iter num 100\n",
            "loss 0.007645916759917073 average time 0.14372242705001667 iter num 20\n",
            "loss 0.006986503732038747 average time 0.14371515545000477 iter num 40\n",
            "loss 0.006624984948751933 average time 0.14333302776666984 iter num 60\n",
            "loss 0.006479086053000938 average time 0.14291519293750526 iter num 80\n",
            "loss 0.006449998925436665 average time 0.14256910619000565 iter num 100\n",
            "loss 0.005950720610198378 average time 0.14532172254999978 iter num 20\n",
            "loss 0.005591625009815083 average time 0.1435091545249975 iter num 40\n",
            "loss 0.00539218914101335 average time 0.14353653651666415 iter num 60\n",
            "loss 0.005310108670880357 average time 0.14327798617499496 iter num 80\n",
            "loss 0.005293585374316332 average time 0.14302445004999867 iter num 100\n",
            "loss 0.004999115634689196 average time 0.14242751670000758 iter num 20\n",
            "loss 0.004770987581822885 average time 0.14225482635001468 iter num 40\n",
            "loss 0.004635058749684572 average time 0.14224523053334792 iter num 60\n",
            "loss 0.004576787577960147 average time 0.1433390317875066 iter num 80\n",
            "loss 0.004564819049459524 average time 0.14342638873000282 iter num 100\n",
            "loss 0.004344740276837649 average time 0.1418085754999879 iter num 20\n",
            "loss 0.004161974739624052 average time 0.1417473650999881 iter num 40\n",
            "loss 0.004047835273858601 average time 0.14188390931665823 iter num 60\n",
            "loss 0.003997649769743561 average time 0.14216077189999368 iter num 80\n",
            "loss 0.003987254495773404 average time 0.1421528553499968 iter num 100\n",
            "loss 0.0037943596506781634 average time 0.1421750047000046 iter num 20\n",
            "loss 0.003634576337730419 average time 0.14322895175000952 iter num 40\n",
            "loss 0.003535618886365021 average time 0.1425501031000086 iter num 60\n",
            "loss 0.00349222422572534 average time 0.1424991786625071 iter num 80\n",
            "loss 0.003483240145618797 average time 0.1428618847600046 iter num 100\n",
            "loss 0.0033201426902508056 average time 0.1412916770499976 iter num 20\n",
            "loss 0.003185967467602657 average time 0.14221930534999389 iter num 40\n",
            "loss 0.003102662643655639 average time 0.14187996353333385 iter num 60\n",
            "loss 0.003066404043367935 average time 0.14205609218750226 iter num 80\n",
            "loss 0.0030588931409480193 average time 0.1422975112500012 iter num 100\n",
            "loss 0.0029217858974277507 average time 0.14212541485000543 iter num 20\n",
            "loss 0.002807268634966487 average time 0.1420784695750001 iter num 40\n",
            "loss 0.0027339637517863457 average time 0.14237865975000166 iter num 60\n",
            "loss 0.0027014523618045447 average time 0.14212469115000204 iter num 80\n",
            "loss 0.002694635680552755 average time 0.14214966185000208 iter num 100\n",
            "loss 0.0025687507280105245 average time 0.14249361534999708 iter num 20\n",
            "loss 0.0024636018072696757 average time 0.14493523982499426 iter num 40\n",
            "loss 0.0023969305513895085 average time 0.14382256838333282 iter num 60\n",
            "loss 0.002367272876702652 average time 0.1433518152625041 iter num 80\n",
            "loss 0.0023610763041550156 average time 0.14311213521000582 iter num 100\n",
            "loss 0.0022444915029167013 average time 0.14068084879999673 iter num 20\n",
            "loss 0.002147784512119633 average time 0.14133177947499292 iter num 40\n",
            "loss 0.0020860471476077252 average time 0.1416324593499932 iter num 60\n",
            "loss 0.0020586764703473537 average time 0.14138471337499398 iter num 80\n",
            "loss 0.0020529895897856373 average time 0.1416600692599957 iter num 100\n",
            "loss 0.001952920372429778 average time 0.1422731173000102 iter num 20\n",
            "loss 0.0018707355335279017 average time 0.14312346910000145 iter num 40\n",
            "loss 0.0018194715503636596 average time 0.14418758583333896 iter num 60\n",
            "loss 0.0017967286997303059 average time 0.14557504663750792 iter num 80\n",
            "loss 0.001792010443898986 average time 0.14532626410000715 iter num 100\n",
            "loss 0.0017055395442640887 average time 0.1431964536500061 iter num 20\n",
            "loss 0.0016326069722078264 average time 0.14216460065000264 iter num 40\n",
            "loss 0.0015865660934317298 average time 0.14255526246666553 iter num 60\n",
            "loss 0.0015662550937623194 average time 0.1424611433499976 iter num 80\n",
            "loss 0.0015620304131413797 average time 0.14251374887999418 iter num 100\n",
            "loss 0.0014842741806835138 average time 0.1411547495999912 iter num 20\n",
            "loss 0.0014194245807348789 average time 0.14114052409999828 iter num 40\n",
            "loss 0.0013788108456839776 average time 0.14183898256666605 iter num 60\n",
            "loss 0.0013609095418432012 average time 0.14165197620000214 iter num 80\n",
            "loss 0.0013572015741531807 average time 0.14244989763000035 iter num 100\n",
            "loss 0.001289956449824594 average time 0.14162736650000057 iter num 20\n",
            "loss 0.0012356839822653639 average time 0.14274713457500354 iter num 40\n",
            "loss 0.001202193576011314 average time 0.14237533870000144 iter num 60\n",
            "loss 0.0011875787988794612 average time 0.14221599433750215 iter num 80\n",
            "loss 0.001184572496810728 average time 0.1422891172900006 iter num 100\n",
            "loss 0.0011319799615106775 average time 0.14327584474999072 iter num 20\n",
            "loss 0.001089950450156355 average time 0.14240268817499385 iter num 40\n",
            "loss 0.0010639396851982112 average time 0.14173648528332972 iter num 60\n",
            "loss 0.0010525772751140167 average time 0.14314454972499674 iter num 80\n",
            "loss 0.0010502282156001816 average time 0.1428158320199975 iter num 100\n",
            "loss 0.0010068830434356317 average time 0.14563759520000302 iter num 20\n",
            "loss 0.0009707553400822442 average time 0.145270155875005 iter num 40\n",
            "loss 0.0009483081691376399 average time 0.1441437095166729 iter num 60\n",
            "loss 0.0009384641537704777 average time 0.14350436406250963 iter num 80\n",
            "loss 0.0009364265667324353 average time 0.143437215510005 iter num 100\n",
            "loss 0.0009010338562956498 average time 0.14340411250000215 iter num 20\n",
            "loss 0.0008701852121759846 average time 0.14276702950000128 iter num 40\n",
            "loss 0.0008521714815259256 average time 0.14305922513333183 iter num 60\n",
            "loss 0.000844321180215217 average time 0.14255161811249906 iter num 80\n",
            "loss 0.0008427143056268666 average time 0.14263960659999952 iter num 100\n",
            "loss 0.0008197042786635692 average time 0.14057414749999567 iter num 20\n",
            "loss 0.0007966453319531844 average time 0.1409026661500093 iter num 40\n",
            "loss 0.0007838156772073615 average time 0.1422954170500077 iter num 60\n",
            "loss 0.0007783890827675904 average time 0.1423771133375027 iter num 80\n",
            "loss 0.0007772702293864211 average time 0.14252141245000075 iter num 100\n",
            "loss 0.0007568412275930267 average time 0.14174625210000613 iter num 20\n",
            "loss 0.0007400478316708377 average time 0.1424202517000026 iter num 40\n",
            "loss 0.0007295220286377337 average time 0.14197300558333267 iter num 60\n",
            "loss 0.000724890220323315 average time 0.1428115794624972 iter num 80\n",
            "loss 0.0007239316423738456 average time 0.1438227736299973 iter num 100\n",
            "loss 0.000706254426616949 average time 0.14471607365000522 iter num 20\n",
            "loss 0.0006916343786065915 average time 0.14593218537500546 iter num 40\n",
            "loss 0.0006825914199686331 average time 0.14562856146667022 iter num 60\n",
            "loss 0.0006786505013716724 average time 0.14506697303750116 iter num 80\n",
            "loss 0.0006778350451901816 average time 0.14517516185000431 iter num 100\n",
            "loss 0.0006630752823968852 average time 0.1424001930999907 iter num 20\n",
            "loss 0.0006509528988856973 average time 0.14265546057499706 iter num 40\n",
            "loss 0.0006434759780157653 average time 0.1424505409666684 iter num 60\n",
            "loss 0.0006402102215599208 average time 0.14292640196250517 iter num 80\n",
            "loss 0.0006395360096058657 average time 0.1425780298000086 iter num 100\n",
            "loss 0.0006273042715477793 average time 0.14193296145002138 iter num 20\n",
            "loss 0.0006173185364037881 average time 0.14212552020001112 iter num 40\n",
            "loss 0.0006111409444310993 average time 0.14216453678334537 iter num 60\n",
            "loss 0.0006084213437985783 average time 0.14244662562500993 iter num 80\n",
            "loss 0.0006078606958745873 average time 0.1421859178300076 iter num 100\n",
            "loss 0.0005991472020437195 average time 0.1462486342499915 iter num 20\n",
            "loss 0.000595005461519238 average time 0.14474156207499506 iter num 40\n",
            "loss 0.0005893299405148253 average time 0.14426445259999052 iter num 60\n",
            "loss 0.0005875742710350036 average time 0.1435035245999913 iter num 80\n",
            "loss 0.0005871793786492338 average time 0.14300712493999185 iter num 100\n",
            "loss 0.0005806948657094175 average time 0.14171228295001584 iter num 20\n",
            "loss 0.0005752996518804796 average time 0.1417424918250049 iter num 40\n",
            "loss 0.0005719466383407829 average time 0.1415392443666633 iter num 60\n",
            "loss 0.0005704752095139602 average time 0.14168381301249725 iter num 80\n",
            "loss 0.0005701688305662096 average time 0.14187532998000052 iter num 100\n",
            "loss 0.0005645574392975784 average time 0.1426326472000028 iter num 20\n",
            "loss 0.0005598797583351506 average time 0.1415916986999946 iter num 40\n",
            "loss 0.0005569543247764662 average time 0.14292540924999458 iter num 60\n",
            "loss 0.000555657810408337 average time 0.14296370548749734 iter num 80\n",
            "loss 0.000555388239673015 average time 0.14277652199000046 iter num 100\n",
            "loss 0.0005503236234779757 average time 0.14233007655000166 iter num 20\n",
            "loss 0.0005460218464724977 average time 0.14207884352499606 iter num 40\n",
            "loss 0.000543241689934277 average time 0.14168955914999135 iter num 60\n",
            "loss 0.0005420034488296963 average time 0.14124302743749553 iter num 80\n",
            "loss 0.0005417461815933518 average time 0.14120666766000112 iter num 100\n",
            "loss 0.0005370026014218643 average time 0.14197238009999183 iter num 20\n",
            "loss 0.0005330055712819031 average time 0.14161377252499677 iter num 40\n",
            "loss 0.0005304712577215602 average time 0.14238257120000336 iter num 60\n",
            "loss 0.000529339294600051 average time 0.14262345876250038 iter num 80\n",
            "loss 0.0005291029967904097 average time 0.14231004108999515 iter num 100\n",
            "loss 0.0005246939777929399 average time 0.14150211584999967 iter num 20\n",
            "loss 0.0005209778335175874 average time 0.14230118657499133 iter num 40\n",
            "loss 0.0005186129803423902 average time 0.1423875370333216 iter num 60\n",
            "loss 0.0005175604983393465 average time 0.14234154139999333 iter num 80\n",
            "loss 0.0005173416398073862 average time 0.14236744338999188 iter num 100\n",
            "loss 0.000513318387142874 average time 0.14041000285000677 iter num 20\n",
            "loss 0.0005099195693652173 average time 0.14134703834999982 iter num 40\n",
            "loss 0.0005077542631682715 average time 0.14126837648333132 iter num 60\n",
            "loss 0.0005067884052834743 average time 0.14130935627499924 iter num 80\n",
            "loss 0.000506586681179286 average time 0.1414126979100024 iter num 100\n",
            "loss 0.0005028402678086719 average time 0.14397161615001436 iter num 20\n",
            "loss 0.0004996406336406273 average time 0.1426560086749987 iter num 40\n",
            "loss 0.0004975664788022928 average time 0.1414999139166639 iter num 60\n",
            "loss 0.00049663858510907 average time 0.14151258418749676 iter num 80\n",
            "loss 0.0004964443095859007 average time 0.1413192250899965 iter num 100\n",
            "loss 0.0004928468784193702 average time 0.1404572474499844 iter num 20\n",
            "loss 0.0004897731667086141 average time 0.14079138309998881 iter num 40\n",
            "loss 0.0004877923630899032 average time 0.14119270398332825 iter num 60\n",
            "loss 0.0004869035287035652 average time 0.14146968658749728 iter num 80\n",
            "loss 0.00048671810669809087 average time 0.1415631915999984 iter num 100\n",
            "loss 0.00048371890941044187 average time 0.14155975649999847 iter num 20\n",
            "loss 0.00048017194033170903 average time 0.14111014864999163 iter num 40\n",
            "loss 0.0004783309249682007 average time 0.1424891422166638 iter num 60\n",
            "loss 0.00047746977626963777 average time 0.14271225079999966 iter num 80\n",
            "loss 0.00047728624768982926 average time 0.14332446573999733 iter num 100\n",
            "loss 0.00048339135375444984 average time 0.1415927199000066 iter num 20\n",
            "loss 0.0004712260252695453 average time 0.14082141077499558 iter num 40\n",
            "loss 0.00046786319181680496 average time 0.14098129588332994 iter num 60\n",
            "loss 0.000467192460943202 average time 0.14117355807499904 iter num 80\n",
            "loss 0.0004670646284087727 average time 0.14118190752999793 iter num 100\n",
            "loss 0.0004648375504604841 average time 0.1425020617499854 iter num 20\n",
            "loss 0.00046286162111362555 average time 0.14206888377498786 iter num 40\n",
            "loss 0.0004615497343163061 average time 0.14240447974999407 iter num 60\n",
            "loss 0.0004609543990888268 average time 0.14258104533749502 iter num 80\n",
            "loss 0.0004608293880088103 average time 0.1425547924699981 iter num 100\n",
            "loss 0.000458488554439526 average time 0.14131786875001354 iter num 20\n",
            "loss 0.0004564488733665858 average time 0.14119678295000995 iter num 40\n",
            "loss 0.0004551191336779786 average time 0.14121990383332939 iter num 60\n",
            "loss 0.00045451867501603596 average time 0.1411385807500068 iter num 80\n",
            "loss 0.0004543925931785973 average time 0.14117942659000846 iter num 100\n",
            "loss 0.0004520272777864932 average time 0.14175199884997483 iter num 20\n",
            "loss 0.0004499431205558564 average time 0.14091738964997375 iter num 40\n",
            "loss 0.000448582506154613 average time 0.14106464746663125 iter num 60\n",
            "loss 0.00044796657086912535 average time 0.14136980811247213 iter num 80\n",
            "loss 0.00044783732531322317 average time 0.14103836399997818 iter num 100\n",
            "loss 0.00044540389075619263 average time 0.14657388849997233 iter num 20\n",
            "loss 0.0004432721551420974 average time 0.14445705949999024 iter num 40\n",
            "loss 0.0004418750494769352 average time 0.14367685183333379 iter num 60\n",
            "loss 0.000441241964451038 average time 0.14294959412500247 iter num 80\n",
            "loss 0.00044110879619538464 average time 0.14269702501000212 iter num 100\n",
            "loss 0.00043860885715863845 average time 0.13918863194998038 iter num 20\n",
            "loss 0.00043641969178696415 average time 0.14051916994999375 iter num 40\n",
            "loss 0.0004349870797945069 average time 0.1406212653666633 iter num 60\n",
            "loss 0.000434338625138564 average time 0.14106757929998537 iter num 80\n",
            "loss 0.00043420312756857325 average time 0.141433393519992 iter num 100\n",
            "loss 0.00043164651633665203 average time 0.14142432215001008 iter num 20\n",
            "loss 0.00042939455816550583 average time 0.1415547163000042 iter num 40\n",
            "loss 0.00042792069538459944 average time 0.14224733758334196 iter num 60\n",
            "loss 0.00042725246518164286 average time 0.14215419276250998 iter num 80\n",
            "loss 0.00042711210447649256 average time 0.1419093412000143 iter num 100\n",
            "loss 0.0004244727321786453 average time 0.1420282479999969 iter num 20\n",
            "loss 0.00042216856841386415 average time 0.1415791283500198 iter num 40\n",
            "loss 0.0004206702898246006 average time 0.14130049411668325 iter num 60\n",
            "loss 0.00041999233616699355 average time 0.14112246512501087 iter num 80\n",
            "loss 0.0004198497733358174 average time 0.14106641800000716 iter num 100\n",
            "loss 0.0004171698365677211 average time 0.1411243495000008 iter num 20\n",
            "loss 0.00041483533194325387 average time 0.14069243010001173 iter num 40\n",
            "loss 0.0004132947505628272 average time 0.14249227778334064 iter num 60\n",
            "loss 0.00041259351941260857 average time 0.14378797673750227 iter num 80\n",
            "loss 0.0004124465635576853 average time 0.14419469402999538 iter num 100\n",
            "loss 0.00041695741195735893 average time 0.1453040668000085 iter num 20\n",
            "loss 0.00040686505726598066 average time 0.14496255262499744 iter num 40\n",
            "loss 0.00040533024811739834 average time 0.14419472106667777 iter num 60\n",
            "loss 0.0004045649836218126 average time 0.14339667571250914 iter num 80\n",
            "loss 0.00040441731679236183 average time 0.1429925101700087 iter num 100\n",
            "loss 0.0004024043666167025 average time 0.14066506824997305 iter num 20\n",
            "loss 0.0003991683682162848 average time 0.1407105824499979 iter num 40\n",
            "loss 0.0003978218995669398 average time 0.1404807026666731 iter num 60\n",
            "loss 0.00039719608279096446 average time 0.14084946196250314 iter num 80\n",
            "loss 0.00039705202458868006 average time 0.14084222028000112 iter num 100\n",
            "loss 0.0003947280433260296 average time 0.14510807365002165 iter num 20\n",
            "loss 0.0003920693715057731 average time 0.14333972927501576 iter num 40\n",
            "loss 0.0003906709918168044 average time 0.1439895799666753 iter num 60\n",
            "loss 0.0003900145912000077 average time 0.1429574767499986 iter num 80\n",
            "loss 0.0003898695168130879 average time 0.14255472766999902 iter num 100\n",
            "loss 0.000387654546130721 average time 0.1397558534000268 iter num 20\n",
            "loss 0.0003843480885381856 average time 0.1418669758750184 iter num 40\n",
            "loss 0.00038290166355746765 average time 0.14158265468335002 iter num 60\n",
            "loss 0.00038232617917880645 average time 0.14161133090000533 iter num 80\n",
            "loss 0.00038219234477592163 average time 0.14189907205000962 iter num 100\n",
            "loss 0.00038056654718275146 average time 0.1398591139000132 iter num 20\n",
            "loss 0.0003773126227041129 average time 0.14190232832501692 iter num 40\n",
            "loss 0.0003758468271487976 average time 0.14285397161667485 iter num 60\n",
            "loss 0.00037522318205649184 average time 0.1424414061249962 iter num 80\n",
            "loss 0.00037509160878067385 average time 0.14210191104999012 iter num 100\n",
            "loss 0.00037244204079093526 average time 0.13964433954998867 iter num 20\n",
            "loss 0.0003698536115255814 average time 0.14052207707497927 iter num 40\n",
            "loss 0.00036848483992131737 average time 0.14052744288331573 iter num 60\n",
            "loss 0.00036789115432861035 average time 0.14056812063748225 iter num 80\n",
            "loss 0.0003677508128236466 average time 0.14076432782998835 iter num 100\n",
            "loss 0.0003682340006045326 average time 0.1412979433000146 iter num 20\n",
            "loss 0.0003627982260379362 average time 0.14061799645000406 iter num 40\n",
            "loss 0.00036119159712429545 average time 0.14098585475001452 iter num 60\n",
            "loss 0.0003605265109733688 average time 0.14186130805002223 iter num 80\n",
            "loss 0.00036039056384738044 average time 0.14179129012001568 iter num 100\n",
            "loss 0.00035796727954041897 average time 0.14110341955001787 iter num 20\n",
            "loss 0.0003558946260120396 average time 0.14081799149999483 iter num 40\n",
            "loss 0.00035451799443592086 average time 0.1414519932166665 iter num 60\n",
            "loss 0.0003538878687749592 average time 0.14146119371250448 iter num 80\n",
            "loss 0.0003537553371446536 average time 0.1414435917899982 iter num 100\n",
            "loss 0.00035212476478688355 average time 0.1415195497500008 iter num 20\n",
            "loss 0.00034900966765095135 average time 0.14217205115000411 iter num 40\n",
            "loss 0.00034763298408337534 average time 0.14108048589999952 iter num 60\n",
            "loss 0.0003469654183283245 average time 0.14066039951250672 iter num 80\n",
            "loss 0.00034683363239769644 average time 0.14095177439000736 iter num 100\n",
            "loss 0.00036604427252001414 average time 0.14330574350003644 iter num 20\n",
            "loss 0.00033927670161550377 average time 0.142186604300025 iter num 40\n",
            "loss 0.0003383359849715168 average time 0.1423926557500143 iter num 60\n",
            "loss 0.0003375572772301292 average time 0.1420273983625094 iter num 80\n",
            "loss 0.0003374764633905019 average time 0.14172020734000626 iter num 100\n",
            "loss 0.0003357584408978844 average time 0.14119493344996953 iter num 20\n",
            "loss 0.0003341743544120256 average time 0.1409454663249619 iter num 40\n",
            "loss 0.0003331327118547805 average time 0.14101130229997427 iter num 60\n",
            "loss 0.0003326585470103086 average time 0.1408008389374885 iter num 80\n",
            "loss 0.0003325582087831178 average time 0.14066202965998856 iter num 100\n",
            "loss 0.00033065197035248896 average time 0.14144250340004874 iter num 20\n",
            "loss 0.00032895282162139514 average time 0.1423444235750253 iter num 40\n",
            "loss 0.0003278292708362008 average time 0.14227124608334332 iter num 60\n",
            "loss 0.0003273167590156246 average time 0.14251641689999986 iter num 80\n",
            "loss 0.0003272085836677952 average time 0.1430026097399923 iter num 100\n",
            "loss 0.0003251673613946472 average time 0.1395462580499725 iter num 20\n",
            "loss 0.0003233669552075095 average time 0.14024002624998957 iter num 40\n",
            "loss 0.0003221818841163921 average time 0.14060835448332984 iter num 60\n",
            "loss 0.00032164147494948095 average time 0.14064769327500243 iter num 80\n",
            "loss 0.00032152803521327366 average time 0.14036506890000283 iter num 100\n",
            "loss 0.0003193805179612452 average time 0.14093264864998217 iter num 20\n",
            "loss 0.00031748878291797074 average time 0.14108061972500535 iter num 40\n",
            "loss 0.00031624578151781383 average time 0.14061468466667293 iter num 60\n",
            "loss 0.00031568276024986395 average time 0.1417149108625125 iter num 80\n",
            "loss 0.0003155648393810711 average time 0.1426802597500091 iter num 100\n",
            "loss 0.00031333916487699296 average time 0.14109506600004806 iter num 20\n",
            "loss 0.0003113855029673464 average time 0.14114187370002468 iter num 40\n",
            "loss 0.0003101038963050548 average time 0.14075859516668743 iter num 60\n",
            "loss 0.0003095231669534722 average time 0.14091162661252382 iter num 80\n",
            "loss 0.0003094016291231844 average time 0.14112548193002566 iter num 100\n",
            "loss 0.000307106280163181 average time 0.14177717219999977 iter num 20\n",
            "loss 0.00030509784213088905 average time 0.14249199280000086 iter num 40\n",
            "loss 0.0003037816031459348 average time 0.14231839375000088 iter num 60\n",
            "loss 0.00030318610266740284 average time 0.14176874262499553 iter num 80\n",
            "loss 0.00030306091994080183 average time 0.14178783010999496 iter num 100\n",
            "loss 0.00030070321678215845 average time 0.14484227699998656 iter num 20\n",
            "loss 0.00029864404385352285 average time 0.14294257477499742 iter num 40\n",
            "loss 0.0002972933831630416 average time 0.1423985136666526 iter num 60\n",
            "loss 0.0002966824550172574 average time 0.14259599847498236 iter num 80\n",
            "loss 0.00029655427332654774 average time 0.14219889982998893 iter num 100\n",
            "loss 0.0002960866466147105 average time 0.1415513138999927 iter num 20\n",
            "loss 0.0002918029837918614 average time 0.1407240868749909 iter num 40\n",
            "loss 0.00029041273857681823 average time 0.14126425374999296 iter num 60\n",
            "loss 0.0002898646448349381 average time 0.141172748449992 iter num 80\n",
            "loss 0.0002897246985019051 average time 0.1410555804400019 iter num 100\n",
            "loss 0.0002868772742943728 average time 0.14069003340000563 iter num 20\n",
            "loss 0.0002848093311306501 average time 0.14186199657499401 iter num 40\n",
            "loss 0.00028205985205062784 average time 0.14207528966665753 iter num 60\n",
            "loss 0.00028171250765794865 average time 0.14207515764998674 iter num 80\n",
            "loss 0.0002816007772919711 average time 0.14206440876998613 iter num 100\n",
            "loss 0.00027997598227555724 average time 0.1414867354500302 iter num 20\n",
            "loss 0.00027857791158640663 average time 0.14085489597499645 iter num 40\n",
            "loss 0.00027765245005225813 average time 0.14166204691666734 iter num 60\n",
            "loss 0.00027721883648463706 average time 0.14157146326250541 iter num 80\n",
            "loss 0.000277127211698658 average time 0.1412186158800091 iter num 100\n",
            "loss 0.000275400565216755 average time 0.14178829125000902 iter num 20\n",
            "loss 0.0002738646128920581 average time 0.1417837085249971 iter num 40\n",
            "loss 0.00027284752465819433 average time 0.14168814038331826 iter num 60\n",
            "loss 0.0002723844478570636 average time 0.14230696091249512 iter num 80\n",
            "loss 0.00027228734964415224 average time 0.1419161970899995 iter num 100\n",
            "loss 0.00027044204532944806 average time 0.1449947625500272 iter num 20\n",
            "loss 0.0002688030166944024 average time 0.14397514800000977 iter num 40\n",
            "loss 0.0002677279441591485 average time 0.1441593518833353 iter num 60\n",
            "loss 0.00026724129858721467 average time 0.14466136941249771 iter num 80\n",
            "loss 0.00026713858729041735 average time 0.14512828356 iter num 100\n",
            "loss 0.00026520805881862625 average time 0.1431529712000156 iter num 20\n",
            "loss 0.0002635115319542974 average time 0.1432301633500117 iter num 40\n",
            "loss 0.000262398789637188 average time 0.1425168227833448 iter num 60\n",
            "loss 0.0002618933130815959 average time 0.14202917787500838 iter num 80\n",
            "loss 0.0002617878869979038 average time 0.14181051748000528 iter num 100\n",
            "loss 0.0002597882123204867 average time 0.14199026259999528 iter num 20\n",
            "loss 0.00025803619550447107 average time 0.14216293700000052 iter num 40\n",
            "loss 0.00025688943585268825 average time 0.14194064389999614 iter num 60\n",
            "loss 0.0002563693494909721 average time 0.14205876251249663 iter num 80\n",
            "loss 0.0002562608418850464 average time 0.1417705425500003 iter num 100\n",
            "loss 0.00025420542183506343 average time 0.14079303125000706 iter num 20\n",
            "loss 0.0002524064597139158 average time 0.14182699605000834 iter num 40\n",
            "loss 0.0002512323524527409 average time 0.14164823783333227 iter num 60\n",
            "loss 0.0002507007348799397 average time 0.14180062040000507 iter num 80\n",
            "loss 0.00025058978647902514 average time 0.14186759359001372 iter num 100\n",
            "loss 0.0002484783849115469 average time 0.1409914354499847 iter num 20\n",
            "loss 0.0002466467711106065 average time 0.14248726390000002 iter num 40\n",
            "loss 0.0002454371687504779 average time 0.14270303353334082 iter num 60\n",
            "loss 0.0002448901879272592 average time 0.1425868601500099 iter num 80\n",
            "loss 0.0002447755852884404 average time 0.14232001339000816 iter num 100\n",
            "loss 0.00026341001146515164 average time 0.14301410395000858 iter num 20\n",
            "loss 0.0002398657593780894 average time 0.14221811085000696 iter num 40\n",
            "loss 0.00023859606749527772 average time 0.14237600080000068 iter num 60\n",
            "loss 0.00023801552943049245 average time 0.14218451453749878 iter num 80\n",
            "loss 0.00023794056995263475 average time 0.14207194887999777 iter num 100\n",
            "loss 0.00023641329651798054 average time 0.14186118259998465 iter num 20\n",
            "loss 0.00023507405004630596 average time 0.14210633710000592 iter num 40\n",
            "loss 0.0002341950299502869 average time 0.14251831638332912 iter num 60\n",
            "loss 0.00023378924037635522 average time 0.14305655122501265 iter num 80\n",
            "loss 0.00023370383512996096 average time 0.14319568137000716 iter num 100\n",
            "loss 0.0002320753046408245 average time 0.14756259799997906 iter num 20\n",
            "loss 0.00023062879403383077 average time 0.14699452592499823 iter num 40\n",
            "loss 0.00022967513383027595 average time 0.1466602348999989 iter num 60\n",
            "loss 0.0002292413090139185 average time 0.1461557832750003 iter num 80\n",
            "loss 0.00022915075745002226 average time 0.14568042317000163 iter num 100\n",
            "loss 0.00022742398385558165 average time 0.14523272844999155 iter num 20\n",
            "loss 0.00022590440256935906 average time 0.14565309762500078 iter num 40\n",
            "loss 0.0002249072273810751 average time 0.1456338179333367 iter num 60\n",
            "loss 0.0002244571956273076 average time 0.14507126071250126 iter num 80\n",
            "loss 0.00022436332153777302 average time 0.14477438887000063 iter num 100\n",
            "loss 0.00022258870110674408 average time 0.1414591455999698 iter num 20\n",
            "loss 0.00022103237709799806 average time 0.14163082064999913 iter num 40\n",
            "loss 0.00022000946254999864 average time 0.14178872386666702 iter num 60\n",
            "loss 0.0002195481042765269 average time 0.14174249434999808 iter num 80\n",
            "loss 0.0002194516315311774 average time 0.1421999069599974 iter num 100\n",
            "loss 0.0002176764653720154 average time 0.14163580064996495 iter num 20\n",
            "loss 0.00021604217497313868 average time 0.14090783904998147 iter num 40\n",
            "loss 0.00021500562489078698 average time 0.14081865128330642 iter num 60\n",
            "loss 0.0002145355379891618 average time 0.14131397376248458 iter num 80\n",
            "loss 0.00021443800317957524 average time 0.14215547415999027 iter num 100\n",
            "loss 0.00021564454720416213 average time 0.14545546319999403 iter num 20\n",
            "loss 0.00021082387429248212 average time 0.1452213620249722 iter num 40\n",
            "loss 0.0002098006996684914 average time 0.14430890271663657 iter num 60\n",
            "loss 0.00020926298274022445 average time 0.14394328059998146 iter num 80\n",
            "loss 0.00020918049275495736 average time 0.14388457154998605 iter num 100\n",
            "loss 0.0002077794384897151 average time 0.14137810659999558 iter num 20\n",
            "loss 0.00020590972462478143 average time 0.1416293112000176 iter num 40\n",
            "loss 0.0002044038114899382 average time 0.1419898725500199 iter num 60\n",
            "loss 0.00020412355883602944 average time 0.14166634970002007 iter num 80\n",
            "loss 0.00020406926375633614 average time 0.1417900511000198 iter num 100\n",
            "loss 0.0002028933829127916 average time 0.14292954004999955 iter num 20\n",
            "loss 0.00020186042314629981 average time 0.1431766380249769 iter num 40\n",
            "loss 0.0002011487388606739 average time 0.14355464423330583 iter num 60\n",
            "loss 0.00020082286595335356 average time 0.14399841672498326 iter num 80\n",
            "loss 0.00020075447521695198 average time 0.1436883727899908 iter num 100\n",
            "loss 0.00019944658099850274 average time 0.14155377429997315 iter num 20\n",
            "loss 0.00019828412918442592 average time 0.14115412892498397 iter num 40\n",
            "loss 0.0001975136934165757 average time 0.14128896623333276 iter num 60\n",
            "loss 0.00019716261135508458 average time 0.14120387406250642 iter num 80\n",
            "loss 0.00019708835267832426 average time 0.14158192933000463 iter num 100\n",
            "loss 0.00019569095632596665 average time 0.14387715119999028 iter num 20\n",
            "loss 0.00019446868120240996 average time 0.14346044114998335 iter num 40\n",
            "loss 0.0001936687538996902 average time 0.14319672333331634 iter num 60\n",
            "loss 0.00019330618516872383 average time 0.14365095404998557 iter num 80\n",
            "loss 0.00019323071377863366 average time 0.14441416098998616 iter num 100\n",
            "loss 0.00019180015726657284 average time 0.14468124764999857 iter num 20\n",
            "loss 0.0001905486468734546 average time 0.14452098735000618 iter num 40\n",
            "loss 0.00018973284685198854 average time 0.14432724983333856 iter num 60\n",
            "loss 0.00018936492924266683 average time 0.1442079690999975 iter num 80\n",
            "loss 0.0001892878424724515 average time 0.1441176234699992 iter num 100\n",
            "loss 0.0001878301338293441 average time 0.14143144405004476 iter num 20\n",
            "loss 0.00018656656382206417 average time 0.14145838007501652 iter num 40\n",
            "loss 0.00018573923852574463 average time 0.14224824331667682 iter num 60\n",
            "loss 0.00018536708625661164 average time 0.14243063028750386 iter num 80\n",
            "loss 0.00018528874785639937 average time 0.1426957596900047 iter num 100\n",
            "loss 0.00019657752103737817 average time 0.1445989551000025 iter num 20\n",
            "loss 0.00018257300889552486 average time 0.14487999187499553 iter num 40\n",
            "loss 0.0001812397627757036 average time 0.14478150906666087 iter num 60\n",
            "loss 0.0001809517570967558 average time 0.14456926413749613 iter num 80\n",
            "loss 0.0001809174406218157 average time 0.14395001838999177 iter num 100\n",
            "loss 0.00017999579798517283 average time 0.1416700486000309 iter num 20\n",
            "loss 0.00017906688506363699 average time 0.14280699312500927 iter num 40\n",
            "loss 0.00017849275569988061 average time 0.14345802934999863 iter num 60\n",
            "loss 0.00017821873952167248 average time 0.1432352071624962 iter num 80\n",
            "loss 0.00017816162034037258 average time 0.14298498491999453 iter num 100\n",
            "loss 0.00017706826003555906 average time 0.1441983985500201 iter num 20\n",
            "loss 0.0001760936259828722 average time 0.14379549710000675 iter num 40\n",
            "loss 0.0001754442848162812 average time 0.14415485355001087 iter num 60\n",
            "loss 0.00017514857562585866 average time 0.14369425605000288 iter num 80\n",
            "loss 0.0001750868920408482 average time 0.1436382655899979 iter num 100\n",
            "loss 0.00017391548431298063 average time 0.14207544084999882 iter num 20\n",
            "loss 0.00017288492081719479 average time 0.14137263205001888 iter num 40\n",
            "loss 0.00017221275743674913 average time 0.14209180645001046 iter num 60\n",
            "loss 0.00017190906245023428 average time 0.1425017660500032 iter num 80\n",
            "loss 0.00017184572424815817 average time 0.1424620872200103 iter num 100\n",
            "loss 0.00017064887258882351 average time 0.14854533125001126 iter num 20\n",
            "loss 0.00016960408163986342 average time 0.14913243090002198 iter num 40\n",
            "loss 0.00016892326563144948 average time 0.14882173660001097 iter num 60\n",
            "loss 0.0001686171813169704 average time 0.14927304114999346 iter num 80\n",
            "loss 0.0001685531071518034 average time 0.14916890290999846 iter num 100\n",
            "loss 0.0001674361241590347 average time 0.1432296392499552 iter num 20\n",
            "loss 0.0001662779581634263 average time 0.14326564374997589 iter num 40\n",
            "loss 0.00016562025727738402 average time 0.14271954569998116 iter num 60\n",
            "loss 0.00016530392362366176 average time 0.14283289749998004 iter num 80\n",
            "loss 0.0001652423633316133 average time 0.1428205182799843 iter num 100\n",
            "loss 0.00018110579532345448 average time 0.1414964307999867 iter num 20\n",
            "loss 0.00016580296856515863 average time 0.14398096472498878 iter num 40\n",
            "loss 0.00016236005293060005 average time 0.14376841098334125 iter num 60\n",
            "loss 0.0001621580284793076 average time 0.14337764117500457 iter num 80\n",
            "loss 0.00016211301768767608 average time 0.14335743088000755 iter num 100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 10000\n",
              "\tepoch: 100\n",
              "\tepoch_length: 100\n",
              "\tmax_epochs: 100\n",
              "\toutput: 0.00016211301768767608\n",
              "\tbatch: <class 'tuple'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: <class 'cupy_dataset.OptionDataSet'>\n",
              "\tseed: <class 'NoneType'>\n",
              "\ttimes: <class 'dict'>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_fEzULvKwR-"
      },
      "source": [
        "# 24 min\n",
        "# 1:56"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "339d9fd7-dbe8-4a6a-88f9-7ea1b43f1bdb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_BS_oneDS_B_2.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Judy/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f32d1c7-403f-48b9-9a0c-22997231c429"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca70003-dc51-4d45-ecd9-90991f905a0c"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_BS_oneDS_B_6.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Judy/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a752ed0e-9408-4640-ad1f-3fc4bd0eb301"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=6, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc5): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc6): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a52f4c-ebd3-4db2-9868-b82b6a813d17"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 100000, batch = 1, seed = np.random.randint(10000), stocks = 1) # must have random seed. It doesn't matter how many batch here (not taken into function). Use max_len to adjust\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x.float())\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x.float()\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)\n",
        "\n",
        "model_save_name = 'jax_european_1stock_BS_oneDS_B_7.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Judy/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 5.089649058945988e-05 average time 0.14395556939989546 iter num 20\n",
            "loss 3.0281707120389736e-05 average time 0.14316866077479062 iter num 40\n",
            "loss 2.9135098413079425e-05 average time 0.14315565326651267 iter num 60\n",
            "loss 2.871898692564535e-05 average time 0.1440042419623296 iter num 80\n",
            "loss 2.8740685668104955e-05 average time 0.14378307752986075 iter num 100\n",
            "loss 2.8801316367004816e-05 average time 0.14243249014998582 iter num 20\n",
            "loss 2.877877977498489e-05 average time 0.1420774683498621 iter num 40\n",
            "loss 2.8777268003263403e-05 average time 0.14213459753327698 iter num 60\n",
            "loss 2.8775618764351495e-05 average time 0.1420316450874907 iter num 80\n",
            "loss 2.8775010853030647e-05 average time 0.1421386085699487 iter num 100\n",
            "loss 2.8768520923490792e-05 average time 0.14143410564993247 iter num 20\n",
            "loss 2.8760742568248382e-05 average time 0.14165876110014325 iter num 40\n",
            "loss 2.8753888713944257e-05 average time 0.14122020158344337 iter num 60\n",
            "loss 2.8750528926645322e-05 average time 0.14124647971257218 iter num 80\n",
            "loss 2.874978559284374e-05 average time 0.14190205703000175 iter num 100\n",
            "loss 2.8735053778699442e-05 average time 0.13986503870009984 iter num 20\n",
            "loss 2.8721373941597622e-05 average time 0.14133720095005628 iter num 40\n",
            "loss 2.8712022568272245e-05 average time 0.14198961178338626 iter num 60\n",
            "loss 2.870777243881728e-05 average time 0.14192588673749923 iter num 80\n",
            "loss 2.8706959812749823e-05 average time 0.1419292502499775 iter num 100\n",
            "loss 2.8688635624141093e-05 average time 0.1410152625498995 iter num 20\n",
            "loss 2.8671742324368977e-05 average time 0.14119523424988073 iter num 40\n",
            "loss 2.8660691111763636e-05 average time 0.1412087200666671 iter num 60\n",
            "loss 2.8655507475331295e-05 average time 0.14164982447489366 iter num 80\n",
            "loss 2.865463626658509e-05 average time 0.1415263211499041 iter num 100\n",
            "loss 2.8633644484996805e-05 average time 0.14304369034989578 iter num 20\n",
            "loss 2.8614962803732124e-05 average time 0.14387282887500988 iter num 40\n",
            "loss 2.860244489197888e-05 average time 0.143114499100011 iter num 60\n",
            "loss 2.8597011105710712e-05 average time 0.14281031269999858 iter num 80\n",
            "loss 2.8595970291086626e-05 average time 0.1423601538099865 iter num 100\n",
            "loss 2.8573458542269936e-05 average time 0.14166001634994246 iter num 20\n",
            "loss 2.855348535624156e-05 average time 0.14158354175010573 iter num 40\n",
            "loss 2.8540252384171445e-05 average time 0.14150710176675904 iter num 60\n",
            "loss 2.8534456295346835e-05 average time 0.14155979150011716 iter num 80\n",
            "loss 2.8533501926547057e-05 average time 0.14166635579005743 iter num 100\n",
            "loss 2.8508889447587402e-05 average time 0.14101427304949538 iter num 20\n",
            "loss 2.8489565014709154e-05 average time 0.14019880624987308 iter num 40\n",
            "loss 2.8475726910621693e-05 average time 0.1414908498665985 iter num 60\n",
            "loss 2.8469728572574583e-05 average time 0.14187246058743314 iter num 80\n",
            "loss 2.8468531979912073e-05 average time 0.1418138928899316 iter num 100\n",
            "loss 3.078596086250222e-05 average time 0.14170666625013836 iter num 20\n",
            "loss 2.8629998220165682e-05 average time 0.141606527049953 iter num 40\n",
            "loss 2.8689635326270426e-05 average time 0.14135261585003414 iter num 60\n",
            "loss 2.862111205338629e-05 average time 0.14102342055002737 iter num 80\n",
            "loss 2.8613103961664522e-05 average time 0.1411761388999912 iter num 100\n",
            "loss 2.8565407149874693e-05 average time 0.1411826679499427 iter num 20\n",
            "loss 2.8523068186913077e-05 average time 0.14282577032486188 iter num 40\n",
            "loss 2.8499874794084105e-05 average time 0.14248539519994666 iter num 60\n",
            "loss 2.8491704988107668e-05 average time 0.1421957759625002 iter num 80\n",
            "loss 2.849031615936641e-05 average time 0.14268255677001435 iter num 100\n",
            "loss 2.8508752603431638e-05 average time 0.14148029309999402 iter num 20\n",
            "loss 2.843581202600769e-05 average time 0.14223709395000697 iter num 40\n",
            "loss 2.842080626303068e-05 average time 0.14154649301663086 iter num 60\n",
            "loss 2.841250063838028e-05 average time 0.14182922753748245 iter num 80\n",
            "loss 2.8411330476110964e-05 average time 0.14165508435999072 iter num 100\n",
            "loss 2.9231248226425243e-05 average time 0.14230975854989084 iter num 20\n",
            "loss 3.068246260717839e-05 average time 0.14228395285003897 iter num 40\n",
            "loss 2.975460635174193e-05 average time 0.14172922001668364 iter num 60\n",
            "loss 2.954818094496822e-05 average time 0.14139030922503934 iter num 80\n",
            "loss 2.9537666953772377e-05 average time 0.14158296539004367 iter num 100\n",
            "loss 2.9280361142192178e-05 average time 0.14999103589998414 iter num 20\n",
            "loss 2.9157800899621114e-05 average time 0.14672394820004228 iter num 40\n",
            "loss 2.9090958001035025e-05 average time 0.14539748130012717 iter num 60\n",
            "loss 2.906631953048344e-05 average time 0.14527823738753795 iter num 80\n",
            "loss 2.9061923165646237e-05 average time 0.14523537978004242 iter num 100\n",
            "loss 2.8982073858162534e-05 average time 0.1449973842500185 iter num 20\n",
            "loss 2.8921007262183317e-05 average time 0.1448588265750459 iter num 40\n",
            "loss 2.888513576192962e-05 average time 0.1445138217833725 iter num 60\n",
            "loss 2.886929725444044e-05 average time 0.14439137386252696 iter num 80\n",
            "loss 2.8866428400107294e-05 average time 0.14402296785005092 iter num 100\n",
            "loss 2.880596803266375e-05 average time 0.14188977659996455 iter num 20\n",
            "loss 2.8755471676569705e-05 average time 0.14118577617496159 iter num 40\n",
            "loss 2.872361683456609e-05 average time 0.14221726796664977 iter num 60\n",
            "loss 2.870931418580031e-05 average time 0.1427670470249268 iter num 80\n",
            "loss 2.8706816657443895e-05 average time 0.14277377386997614 iter num 100\n",
            "loss 2.8651850689025442e-05 average time 0.14251138000017818 iter num 20\n",
            "loss 2.8605132282353763e-05 average time 0.14222572297508124 iter num 40\n",
            "loss 2.8575501925420304e-05 average time 0.1421386369166915 iter num 60\n",
            "loss 2.856247755079429e-05 average time 0.14228046796256422 iter num 80\n",
            "loss 2.8559964385878357e-05 average time 0.14277978905005512 iter num 100\n",
            "loss 2.8509303863138828e-05 average time 0.14186258154986717 iter num 20\n",
            "loss 2.84664500909369e-05 average time 0.14161091882492655 iter num 40\n",
            "loss 2.8439195921527503e-05 average time 0.14279278893327502 iter num 60\n",
            "loss 2.842732662479078e-05 average time 0.14242789069999162 iter num 80\n",
            "loss 2.8425136576757363e-05 average time 0.14290408931998172 iter num 100\n",
            "loss 2.8378984680199342e-05 average time 0.14168114240010254 iter num 20\n",
            "loss 2.8340116011862192e-05 average time 0.14194538927499706 iter num 40\n",
            "loss 2.8315602747264476e-05 average time 0.14232568831657771 iter num 60\n",
            "loss 2.830469049072845e-05 average time 0.14271087848742353 iter num 80\n",
            "loss 2.8302718841105616e-05 average time 0.14282721862997277 iter num 100\n",
            "loss 2.826091422243764e-05 average time 0.14088674724989686 iter num 20\n",
            "loss 2.822575269553966e-05 average time 0.14272106544990493 iter num 40\n",
            "loss 2.8203239971248203e-05 average time 0.1427716115831572 iter num 60\n",
            "loss 2.8193397029739837e-05 average time 0.14284554103739994 iter num 80\n",
            "loss 2.8191611375663882e-05 average time 0.14262200913992273 iter num 100\n",
            "loss 2.8145137385711662e-05 average time 0.1451737922000575 iter num 20\n",
            "loss 2.811881914863543e-05 average time 0.14407354474988096 iter num 40\n",
            "loss 2.8101330303854672e-05 average time 0.14290820648329827 iter num 60\n",
            "loss 2.8091703406234036e-05 average time 0.1424616634374388 iter num 80\n",
            "loss 2.8090049305720755e-05 average time 0.14299523257994223 iter num 100\n",
            "loss 3.916784733147621e-05 average time 0.14354457180024838 iter num 20\n",
            "loss 3.1623744889090803e-05 average time 0.14295546960006505 iter num 40\n",
            "loss 3.0572291198528545e-05 average time 0.1422714177000974 iter num 60\n",
            "loss 3.0218386481240038e-05 average time 0.14225287855003899 iter num 80\n",
            "loss 3.0192344014552517e-05 average time 0.1420002379800826 iter num 100\n",
            "loss 2.968685273213235e-05 average time 0.1416126589002488 iter num 20\n",
            "loss 2.9421016718490086e-05 average time 0.1411351287501475 iter num 40\n",
            "loss 2.9314897108784114e-05 average time 0.1420938386167715 iter num 60\n",
            "loss 2.927435701328269e-05 average time 0.14223938126258417 iter num 80\n",
            "loss 2.9267086504735876e-05 average time 0.14250408445001084 iter num 100\n",
            "loss 2.9137811797851135e-05 average time 0.14309537235003517 iter num 20\n",
            "loss 2.9042060792315874e-05 average time 0.14349571530010508 iter num 40\n",
            "loss 2.898568082799715e-05 average time 0.14250527115003328 iter num 60\n",
            "loss 2.896126659341582e-05 average time 0.14190092593753434 iter num 80\n",
            "loss 2.8956570327576387e-05 average time 0.14174747729004594 iter num 100\n",
            "loss 2.886469466172866e-05 average time 0.14000050189997637 iter num 20\n",
            "loss 2.878801478811183e-05 average time 0.142823787099951 iter num 40\n",
            "loss 2.8738050235935605e-05 average time 0.14243811216674657 iter num 60\n",
            "loss 2.871641268415143e-05 average time 0.14287348087502777 iter num 80\n",
            "loss 2.8712092545387646e-05 average time 0.14265703049000877 iter num 100\n",
            "loss 2.8626751755299822e-05 average time 0.1408157412503897 iter num 20\n",
            "loss 2.8555925033236493e-05 average time 0.14127688205026062 iter num 40\n",
            "loss 2.8511814075494355e-05 average time 0.14195431053346208 iter num 60\n",
            "loss 2.8492518450003646e-05 average time 0.14188363377506902 iter num 80\n",
            "loss 2.8488635885590933e-05 average time 0.14137088797002434 iter num 100\n",
            "loss 2.841522660201925e-05 average time 0.14240657345026192 iter num 20\n",
            "loss 2.8354211442928938e-05 average time 0.14091619077512405 iter num 40\n",
            "loss 2.8316343505516188e-05 average time 0.1409460083167081 iter num 60\n",
            "loss 2.8299888880340594e-05 average time 0.14140626540001905 iter num 80\n",
            "loss 2.829671604005272e-05 average time 0.14142737483998644 iter num 100\n",
            "loss 2.8233863919810932e-05 average time 0.14514277845028117 iter num 20\n",
            "loss 2.818181855191874e-05 average time 0.14361535382518015 iter num 40\n",
            "loss 2.8149593238717984e-05 average time 0.14305232260009385 iter num 60\n",
            "loss 2.8135368287257056e-05 average time 0.14297070206262105 iter num 80\n",
            "loss 2.8132575609610314e-05 average time 0.1426143973400758 iter num 100\n",
            "loss 2.8078383682421183e-05 average time 0.14104573220010935 iter num 20\n",
            "loss 2.8033223571680633e-05 average time 0.141173483799912 iter num 40\n",
            "loss 2.8005086549988094e-05 average time 0.14147484738332422 iter num 60\n",
            "loss 2.799271551711284e-05 average time 0.1414247367499229 iter num 80\n",
            "loss 2.7990500977858584e-05 average time 0.14119871083998078 iter num 100\n",
            "loss 2.7943143230290157e-05 average time 0.14130669059977663 iter num 20\n",
            "loss 2.7903503535170777e-05 average time 0.14083121392486647 iter num 40\n",
            "loss 2.787870665795986e-05 average time 0.14172486129985676 iter num 60\n",
            "loss 2.786769934808621e-05 average time 0.14186399296243052 iter num 80\n",
            "loss 2.7865762520313023e-05 average time 0.14181985820996487 iter num 100\n",
            "loss 2.7824040325039393e-05 average time 0.14028384900029778 iter num 20\n",
            "loss 2.7788665930338378e-05 average time 0.14115506802531855 iter num 40\n",
            "loss 2.7766395813726818e-05 average time 0.14136325438357744 iter num 60\n",
            "loss 2.7756761608224844e-05 average time 0.14129825218774386 iter num 80\n",
            "loss 2.7754859189590177e-05 average time 0.1410648433701499 iter num 100\n",
            "loss 2.780548220240616e-05 average time 0.1396964374001982 iter num 20\n",
            "loss 2.7700900685884293e-05 average time 0.14050549957514705 iter num 40\n",
            "loss 2.7672258445824822e-05 average time 0.14033755161678224 iter num 60\n",
            "loss 2.766351378125863e-05 average time 0.14163520736258306 iter num 80\n",
            "loss 2.7660958586299265e-05 average time 0.1415158216901 iter num 100\n",
            "loss 4.110111540032478e-05 average time 0.1422521685499305 iter num 20\n",
            "loss 3.433153611724785e-05 average time 0.1426126643999396 iter num 40\n",
            "loss 3.133198893600288e-05 average time 0.14296396139992187 iter num 60\n",
            "loss 3.084349101885257e-05 average time 0.14242626012494383 iter num 80\n",
            "loss 3.076556394968252e-05 average time 0.14223418707990276 iter num 100\n",
            "loss 2.998252792960862e-05 average time 0.1435754892499972 iter num 20\n",
            "loss 2.958231474958645e-05 average time 0.14266187037483177 iter num 40\n",
            "loss 2.9425756534618192e-05 average time 0.14230263638334387 iter num 60\n",
            "loss 2.936819245063496e-05 average time 0.14200871671250753 iter num 80\n",
            "loss 2.9357828048513214e-05 average time 0.14224037359002978 iter num 100\n",
            "loss 2.9176410907910467e-05 average time 0.15014504615010082 iter num 20\n",
            "loss 2.9046542272374644e-05 average time 0.1461662418250853 iter num 40\n",
            "loss 2.897264033413989e-05 average time 0.14482094786681046 iter num 60\n",
            "loss 2.8941296911440773e-05 average time 0.14413566710004488 iter num 80\n",
            "loss 2.8935153370866337e-05 average time 0.14398846809001042 iter num 100\n",
            "loss 2.881894807451138e-05 average time 0.14185450369996033 iter num 20\n",
            "loss 2.8724800129727395e-05 average time 0.1425869251250333 iter num 40\n",
            "loss 2.8667333158367473e-05 average time 0.14377425846657085 iter num 60\n",
            "loss 2.864262811354686e-05 average time 0.1440568382874062 iter num 80\n",
            "loss 2.8637816234293446e-05 average time 0.14452086065992262 iter num 100\n",
            "loss 2.8539143376395143e-05 average time 0.14430183815011333 iter num 20\n",
            "loss 2.8457554386743274e-05 average time 0.1451752679000947 iter num 40\n",
            "loss 2.84072593336818e-05 average time 0.1442734009500479 iter num 60\n",
            "loss 2.8385228430900386e-05 average time 0.14409888547506852 iter num 80\n",
            "loss 2.838103008528867e-05 average time 0.14329291185005785 iter num 100\n",
            "loss 2.8297221690318945e-05 average time 0.14169332094979836 iter num 20\n",
            "loss 2.8225108115019675e-05 average time 0.1408405681498607 iter num 40\n",
            "loss 2.8180443178901795e-05 average time 0.14142051336648365 iter num 60\n",
            "loss 2.8161233826047324e-05 average time 0.14133203064986902 iter num 80\n",
            "loss 2.8157520466148496e-05 average time 0.14173733692989118 iter num 100\n",
            "loss 2.8084401025819066e-05 average time 0.14417085134991794 iter num 20\n",
            "loss 2.802402050751436e-05 average time 0.14289819449991228 iter num 40\n",
            "loss 2.7986476778678952e-05 average time 0.1432217013166337 iter num 60\n",
            "loss 2.797031405883079e-05 average time 0.14381429309994473 iter num 80\n",
            "loss 2.796703700803489e-05 average time 0.14342129097996803 iter num 100\n",
            "loss 2.790505654421664e-05 average time 0.14105389060014203 iter num 20\n",
            "loss 2.7851841787003128e-05 average time 0.1411234267251075 iter num 40\n",
            "loss 2.7818368928966085e-05 average time 0.1418597043666826 iter num 60\n",
            "loss 2.7803858445645733e-05 average time 0.14189515130001382 iter num 80\n",
            "loss 2.7801154839192514e-05 average time 0.1417340672499813 iter num 100\n",
            "loss 2.7745727544446966e-05 average time 0.14139032665007106 iter num 20\n",
            "loss 2.769956519141244e-05 average time 0.1419376299749274 iter num 40\n",
            "loss 2.7670584215102518e-05 average time 0.1420339927499602 iter num 60\n",
            "loss 2.7657841901704252e-05 average time 0.14188949085007607 iter num 80\n",
            "loss 2.765559189920245e-05 average time 0.1417030531700584 iter num 100\n",
            "loss 2.7607017400781918e-05 average time 0.14535062550003203 iter num 20\n",
            "loss 2.7566590189450727e-05 average time 0.1440220579999277 iter num 40\n",
            "loss 2.754117212770791e-05 average time 0.14361055788319088 iter num 60\n",
            "loss 2.7530055639384368e-05 average time 0.1427952729248318 iter num 80\n",
            "loss 2.7528023218795482e-05 average time 0.1423399154098115 iter num 100\n",
            "loss 2.7485469119774906e-05 average time 0.14156881674989563 iter num 20\n",
            "loss 2.7449738940211745e-05 average time 0.1422249732250293 iter num 40\n",
            "loss 2.7427249409990426e-05 average time 0.14183348648330138 iter num 60\n",
            "loss 2.7417345777595154e-05 average time 0.14154670083746623 iter num 80\n",
            "loss 2.7415398989970753e-05 average time 0.141629282360027 iter num 100\n",
            "loss 2.7423214777274096e-05 average time 0.14164808980003726 iter num 20\n",
            "loss 2.7355210600096364e-05 average time 0.14402705095003512 iter num 40\n",
            "loss 2.73246408317531e-05 average time 0.14317159476668168 iter num 60\n",
            "loss 2.7317621774928192e-05 average time 0.14233890901246013 iter num 80\n",
            "loss 2.7315558906826384e-05 average time 0.14220606144992418 iter num 100\n",
            "loss 3.97764863172099e-05 average time 0.14159473479985535 iter num 20\n",
            "loss 3.1309048830392584e-05 average time 0.14181068169996253 iter num 40\n",
            "loss 3.024983856064022e-05 average time 0.1418808633999409 iter num 60\n",
            "loss 2.9844386673664924e-05 average time 0.14212979247495242 iter num 80\n",
            "loss 2.9800982234586526e-05 average time 0.14208146760996898 iter num 100\n",
            "loss 2.914321663390755e-05 average time 0.14121871300012573 iter num 20\n",
            "loss 2.8805910493435695e-05 average time 0.1412516367749504 iter num 40\n",
            "loss 2.867419770743573e-05 average time 0.14167985581661924 iter num 60\n",
            "loss 2.8629001992635095e-05 average time 0.14271631442497892 iter num 80\n",
            "loss 2.862030604292767e-05 average time 0.14260436599997775 iter num 100\n",
            "loss 2.8469484742426915e-05 average time 0.13984307360024104 iter num 20\n",
            "loss 2.8354414734571067e-05 average time 0.1401303458751954 iter num 40\n",
            "loss 2.8286124634550256e-05 average time 0.14180681348349633 iter num 60\n",
            "loss 2.8257158424461975e-05 average time 0.14227061846258948 iter num 80\n",
            "loss 2.8251431832963384e-05 average time 0.14228710986004445 iter num 100\n",
            "loss 2.8143550082022062e-05 average time 0.14255847334998178 iter num 20\n",
            "loss 2.8056931142084648e-05 average time 0.14268258550009705 iter num 40\n",
            "loss 2.8004408917575333e-05 average time 0.1423614088333731 iter num 60\n",
            "loss 2.7981646718287946e-05 average time 0.14264951443758492 iter num 80\n",
            "loss 2.7977160847214705e-05 average time 0.14263793132004138 iter num 100\n",
            "loss 2.7891819478121318e-05 average time 0.14418801895008074 iter num 20\n",
            "loss 2.782151486219812e-05 average time 0.14280391087513636 iter num 40\n",
            "loss 2.777438868613329e-05 average time 0.14241901886674288 iter num 60\n",
            "loss 2.7753552058172295e-05 average time 0.14239386433757772 iter num 80\n",
            "loss 2.7749623978618705e-05 average time 0.14228828983003042 iter num 100\n",
            "loss 2.767055996214026e-05 average time 0.14190050715014876 iter num 20\n",
            "loss 2.7605799479813448e-05 average time 0.14299650222515084 iter num 40\n",
            "loss 2.7566281347706065e-05 average time 0.14261508616676413 iter num 60\n",
            "loss 2.754913345832493e-05 average time 0.14207865301254968 iter num 80\n",
            "loss 2.754590340028038e-05 average time 0.14172271017001548 iter num 100\n",
            "loss 2.7481213705945267e-05 average time 0.1415237127499495 iter num 20\n",
            "loss 2.7427631854494196e-05 average time 0.14344405934998578 iter num 40\n",
            "loss 2.7394822295475545e-05 average time 0.1429882557000989 iter num 60\n",
            "loss 2.7380429981755004e-05 average time 0.14345488652506902 iter num 80\n",
            "loss 2.7377666408332094e-05 average time 0.14341377376005768 iter num 100\n",
            "loss 2.7323517388760696e-05 average time 0.14187785110007098 iter num 20\n",
            "loss 2.7278629569136758e-05 average time 0.14283723662510966 iter num 40\n",
            "loss 2.7250877151926093e-05 average time 0.14270588291677389 iter num 60\n",
            "loss 2.723868307188917e-05 average time 0.14254313372507568 iter num 80\n",
            "loss 2.7236409873127722e-05 average time 0.14230367465010205 iter num 100\n",
            "loss 2.7190376159315765e-05 average time 0.14437273090006783 iter num 20\n",
            "loss 2.7151969895344436e-05 average time 0.14328641504998813 iter num 40\n",
            "loss 2.712803099949969e-05 average time 0.14295511181665763 iter num 60\n",
            "loss 2.7117725519033467e-05 average time 0.14378834588749215 iter num 80\n",
            "loss 2.7115721025375924e-05 average time 0.14360934919001012 iter num 100\n",
            "loss 2.7068084094374092e-05 average time 0.14496520274979047 iter num 20\n",
            "loss 2.7043438578166407e-05 average time 0.14320425967498523 iter num 40\n",
            "loss 2.702028062547966e-05 average time 0.14285488905000723 iter num 60\n",
            "loss 2.7011005625169234e-05 average time 0.1422802539375425 iter num 80\n",
            "loss 2.7009224483038788e-05 average time 0.14243442452003363 iter num 100\n",
            "loss 3.13826437394254e-05 average time 0.14176117879997036 iter num 20\n",
            "loss 2.8124317317754274e-05 average time 0.1412647044998721 iter num 40\n",
            "loss 2.738741535945563e-05 average time 0.14130856949980927 iter num 60\n",
            "loss 2.7301214628239936e-05 average time 0.141205977287359 iter num 80\n",
            "loss 2.7291961849118758e-05 average time 0.14175813603980714 iter num 100\n",
            "loss 2.726351105112391e-05 average time 0.14803773990015542 iter num 20\n",
            "loss 2.7118227020897036e-05 average time 0.14493911767499412 iter num 40\n",
            "loss 2.7103047804051243e-05 average time 0.14379536553327246 iter num 60\n",
            "loss 2.7091751445353237e-05 average time 0.1433700107000277 iter num 80\n",
            "loss 2.7088152597151175e-05 average time 0.1429477931999827 iter num 100\n",
            "loss 3.141833682806767e-05 average time 0.14122600024993517 iter num 20\n",
            "loss 2.7681170171708496e-05 average time 0.1406438186248579 iter num 40\n",
            "loss 2.7502403758979608e-05 average time 0.141285190899877 iter num 60\n",
            "loss 2.748446016872101e-05 average time 0.14137574843744005 iter num 80\n",
            "loss 2.7482817528602424e-05 average time 0.141351534099922 iter num 100\n",
            "loss 2.7336437807928512e-05 average time 0.14406635380009902 iter num 20\n",
            "loss 2.725856762794143e-05 average time 0.146307862499998 iter num 40\n",
            "loss 2.7219773220266336e-05 average time 0.1459662341333266 iter num 60\n",
            "loss 2.7202120930694876e-05 average time 0.14607066021246737 iter num 80\n",
            "loss 2.7198892619586552e-05 average time 0.14561973067997314 iter num 100\n",
            "loss 2.713044951581449e-05 average time 0.14281059834975168 iter num 20\n",
            "loss 2.707289124801053e-05 average time 0.14302575639976567 iter num 40\n",
            "loss 2.7037349511970004e-05 average time 0.14241403654981089 iter num 60\n",
            "loss 2.702201766844451e-05 average time 0.14245590702482785 iter num 80\n",
            "loss 2.7019157232098045e-05 average time 0.1421744139198927 iter num 100\n",
            "loss 2.6965313880479307e-05 average time 0.14431137104975278 iter num 20\n",
            "loss 2.6914090653497215e-05 average time 0.143505943999844 iter num 40\n",
            "loss 2.6885903318014083e-05 average time 0.14388365418332494 iter num 60\n",
            "loss 2.687320260201056e-05 average time 0.1438567950750212 iter num 80\n",
            "loss 2.6871062188693462e-05 average time 0.14347560619999059 iter num 100\n",
            "loss 2.6851276424197684e-05 average time 0.1430530567500682 iter num 20\n",
            "loss 2.6782096359019432e-05 average time 0.14263427952496385 iter num 40\n",
            "loss 2.675857866222505e-05 average time 0.14224155351669954 iter num 60\n",
            "loss 2.6745404293418322e-05 average time 0.1425716668750283 iter num 80\n",
            "loss 2.674343864673459e-05 average time 0.14223565807007618 iter num 100\n",
            "loss 6.083617988821211e-05 average time 0.14282603364990792 iter num 20\n",
            "loss 3.825448019465555e-05 average time 0.14288351015015904 iter num 40\n",
            "loss 3.0480896288433323e-05 average time 0.1431938442502542 iter num 60\n",
            "loss 3.0183824025319366e-05 average time 0.14300534340025023 iter num 80\n",
            "loss 3.0126317138029033e-05 average time 0.143765173630145 iter num 100\n",
            "loss 2.9258230213022185e-05 average time 0.14398772725053277 iter num 20\n",
            "loss 2.877899868738894e-05 average time 0.1434159306752008 iter num 40\n",
            "loss 2.8587480361537947e-05 average time 0.14310694873353594 iter num 60\n",
            "loss 2.851779618077208e-05 average time 0.14238453291268344 iter num 80\n",
            "loss 2.8505287564804213e-05 average time 0.14249037230016257 iter num 100\n",
            "loss 2.8298978122313215e-05 average time 0.14249770120040922 iter num 20\n",
            "loss 2.8156582199807586e-05 average time 0.1430994517999352 iter num 40\n",
            "loss 2.807780698572955e-05 average time 0.14237755334985802 iter num 60\n",
            "loss 2.8044713876775914e-05 average time 0.1423456176250056 iter num 80\n",
            "loss 2.8038178214750044e-05 average time 0.1417865642300603 iter num 100\n",
            "loss 2.791900698713227e-05 average time 0.1422920223498295 iter num 20\n",
            "loss 2.782381450724534e-05 average time 0.14193577554970033 iter num 40\n",
            "loss 2.776602670920317e-05 average time 0.1423542680998556 iter num 60\n",
            "loss 2.7740919573946282e-05 average time 0.1422991046999414 iter num 80\n",
            "loss 2.773585215139367e-05 average time 0.14247105203005048 iter num 100\n",
            "loss 2.7641458346493984e-05 average time 0.14249295244972018 iter num 20\n",
            "loss 2.756384275702959e-05 average time 0.14201549524977963 iter num 40\n",
            "loss 2.7516007415602443e-05 average time 0.14249108329962232 iter num 60\n",
            "loss 2.749514330710627e-05 average time 0.1428876530247635 iter num 80\n",
            "loss 2.7490971566415088e-05 average time 0.14282419358976767 iter num 100\n",
            "loss 2.741198422332079e-05 average time 0.14322893144981208 iter num 20\n",
            "loss 2.734679606475577e-05 average time 0.1427705777000483 iter num 40\n",
            "loss 2.7306319879163535e-05 average time 0.14324958691668144 iter num 60\n",
            "loss 2.7288683344515844e-05 average time 0.14306883737503995 iter num 80\n",
            "loss 2.728529331771205e-05 average time 0.14283325002990752 iter num 100\n",
            "loss 2.7218242465650486e-05 average time 0.14244897490007133 iter num 20\n",
            "loss 2.716263243992272e-05 average time 0.14258231472495025 iter num 40\n",
            "loss 2.7126390709529018e-05 average time 0.1437125350498415 iter num 60\n",
            "loss 2.7110524804321904e-05 average time 0.14326982086245152 iter num 80\n",
            "loss 2.7107546656381816e-05 average time 0.1434997656199266 iter num 100\n",
            "loss 2.7047644132805458e-05 average time 0.14240551944985783 iter num 20\n",
            "loss 2.6997864437853038e-05 average time 0.1424123136248454 iter num 40\n",
            "loss 2.6967034885317282e-05 average time 0.14307989485005237 iter num 60\n",
            "loss 2.6953560800025905e-05 average time 0.14287421825001728 iter num 80\n",
            "loss 2.695101816402632e-05 average time 0.14310076822002885 iter num 100\n",
            "loss 2.6900202141502955e-05 average time 0.14316979615014133 iter num 20\n",
            "loss 2.6857410146710205e-05 average time 0.1442219178000414 iter num 40\n",
            "loss 2.6830937602872477e-05 average time 0.1434444934499576 iter num 60\n",
            "loss 2.6819537761245624e-05 average time 0.14311914662489472 iter num 80\n",
            "loss 2.681741963630957e-05 average time 0.14353671670985932 iter num 100\n",
            "loss 2.677376660552446e-05 average time 0.14239134109993756 iter num 20\n",
            "loss 2.673766700267288e-05 average time 0.14274704982517505 iter num 40\n",
            "loss 2.6715260299262414e-05 average time 0.14279708985013712 iter num 60\n",
            "loss 2.6705505202938107e-05 average time 0.14265293132493753 iter num 80\n",
            "loss 2.670362190655871e-05 average time 0.1426034369098852 iter num 100\n",
            "loss 2.6666187725033494e-05 average time 0.14393598710012157 iter num 20\n",
            "loss 2.663477809718275e-05 average time 0.14291487000000416 iter num 40\n",
            "loss 2.6614021278849488e-05 average time 0.14257187501661975 iter num 60\n",
            "loss 2.660477954646561e-05 average time 0.1430105633623043 iter num 80\n",
            "loss 2.6603119991401342e-05 average time 0.1428090879897354 iter num 100\n",
            "loss 2.656895596286943e-05 average time 0.14542150885026786 iter num 20\n",
            "loss 2.653638328771731e-05 average time 0.1436943590251758 iter num 40\n",
            "loss 2.6516681133877492e-05 average time 0.14294842371673439 iter num 60\n",
            "loss 2.650788934623242e-05 average time 0.14302677027499158 iter num 80\n",
            "loss 2.6506239944738855e-05 average time 0.14267115518996434 iter num 100\n",
            "loss 2.685473749028626e-05 average time 0.14200182524964475 iter num 20\n",
            "loss 2.6529654594037513e-05 average time 0.1422278248249313 iter num 40\n",
            "loss 2.6529159331235545e-05 average time 0.14360710873321902 iter num 60\n",
            "loss 2.6502674787787555e-05 average time 0.14359853548735374 iter num 80\n",
            "loss 2.6498680443199506e-05 average time 0.14324784923981496 iter num 100\n",
            "loss 3.287597934043184e-05 average time 0.14249972950019582 iter num 20\n",
            "loss 2.925610382165249e-05 average time 0.14227964980027535 iter num 40\n",
            "loss 2.8718827070975897e-05 average time 0.14223706126673885 iter num 60\n",
            "loss 2.8505213986665802e-05 average time 0.14195092160007333 iter num 80\n",
            "loss 2.8473335058808786e-05 average time 0.14161923300005583 iter num 100\n",
            "loss 2.7905061813969858e-05 average time 0.1418705617001251 iter num 20\n",
            "loss 2.7660126133491302e-05 average time 0.14116805502508215 iter num 40\n",
            "loss 2.7563520721282774e-05 average time 0.14176596549993217 iter num 60\n",
            "loss 2.7528334116916596e-05 average time 0.14273214918748636 iter num 80\n",
            "loss 2.7521638772955344e-05 average time 0.14279695511999307 iter num 100\n",
            "loss 2.7399594403110648e-05 average time 0.14766055704949393 iter num 20\n",
            "loss 2.7303759617868697e-05 average time 0.1451425258494055 iter num 40\n",
            "loss 2.7246009634741934e-05 average time 0.14395666879960725 iter num 60\n",
            "loss 2.722129870463695e-05 average time 0.14346900226219078 iter num 80\n",
            "loss 2.7216490211901208e-05 average time 0.14347334567970393 iter num 100\n",
            "loss 2.712486057978604e-05 average time 0.14077424240058461 iter num 20\n",
            "loss 2.7050288057948903e-05 average time 0.14132516927520555 iter num 40\n",
            "loss 2.700460869590978e-05 average time 0.14142634920026467 iter num 60\n",
            "loss 2.6983954784782075e-05 average time 0.1424584029502057 iter num 80\n",
            "loss 2.6980103027564967e-05 average time 0.14320511630012334 iter num 100\n",
            "loss 2.690376575320116e-05 average time 0.14585691840002254 iter num 20\n",
            "loss 2.6841623993072087e-05 average time 0.14423175407491726 iter num 40\n",
            "loss 2.6803974164173676e-05 average time 0.1438730847666496 iter num 60\n",
            "loss 2.6787661408843858e-05 average time 0.14377223085002697 iter num 80\n",
            "loss 2.67845395062365e-05 average time 0.1442647403499359 iter num 100\n",
            "loss 2.6723530177660615e-05 average time 0.1453407850001895 iter num 20\n",
            "loss 2.6673536974895206e-05 average time 0.14598968925001826 iter num 40\n",
            "loss 2.6642916132681466e-05 average time 0.14565816826664862 iter num 60\n",
            "loss 2.6629511429678143e-05 average time 0.14485577161253788 iter num 80\n",
            "loss 2.662700147585342e-05 average time 0.14448907951995352 iter num 100\n",
            "loss 2.657689677707926e-05 average time 0.14350755855011813 iter num 20\n",
            "loss 2.653321693862818e-05 average time 0.14413726622524337 iter num 40\n",
            "loss 2.6506311670049998e-05 average time 0.14436014883364504 iter num 60\n",
            "loss 2.649451090441218e-05 average time 0.14362718030024552 iter num 80\n",
            "loss 2.649229063914226e-05 average time 0.1432676186302342 iter num 100\n",
            "loss 2.644801773088766e-05 average time 0.1421219565499996 iter num 20\n",
            "loss 2.641074194322875e-05 average time 0.1415318191748156 iter num 40\n",
            "loss 2.6387633266778856e-05 average time 0.1415952251663839 iter num 60\n",
            "loss 2.6377592802991982e-05 average time 0.1417166211748281 iter num 80\n",
            "loss 2.6375714157037354e-05 average time 0.14190220155993302 iter num 100\n",
            "loss 2.6337610878485785e-05 average time 0.1440350357002899 iter num 20\n",
            "loss 2.630591180212667e-05 average time 0.14221043890020155 iter num 40\n",
            "loss 2.6286163218507586e-05 average time 0.14230275155023264 iter num 60\n",
            "loss 2.62775530777893e-05 average time 0.14299337510010446 iter num 80\n",
            "loss 2.627588656562799e-05 average time 0.14298683659013478 iter num 100\n",
            "loss 2.6243013273461102e-05 average time 0.14263054250022833 iter num 20\n",
            "loss 2.621505162291458e-05 average time 0.1428400371501084 iter num 40\n",
            "loss 2.6197705596457405e-05 average time 0.14232026641669412 iter num 60\n",
            "loss 2.6189956023903098e-05 average time 0.1417397783249271 iter num 80\n",
            "loss 2.6188490904952926e-05 average time 0.1415520785599074 iter num 100\n",
            "loss 2.7095317805267065e-05 average time 0.14121063999991748 iter num 20\n",
            "loss 2.6427707503415875e-05 average time 0.14221924947514708 iter num 40\n",
            "loss 2.6192844089694384e-05 average time 0.142125707716635 iter num 60\n",
            "loss 2.6207072395938702e-05 average time 0.14232165452490336 iter num 80\n",
            "loss 2.6202118718014183e-05 average time 0.14254818273988348 iter num 100\n",
            "loss 2.8312238257017888e-05 average time 0.14437557389992434 iter num 20\n",
            "loss 3.2787992267697014e-05 average time 0.14247567235015596 iter num 40\n",
            "loss 2.9228197087939104e-05 average time 0.1420944103833487 iter num 60\n",
            "loss 2.856402021120933e-05 average time 0.1421783185874574 iter num 80\n",
            "loss 2.84984687100943e-05 average time 0.14212009853989002 iter num 100\n",
            "loss 2.7826126601873944e-05 average time 0.14258398634992772 iter num 20\n",
            "loss 2.7502196976792403e-05 average time 0.14221784647506866 iter num 40\n",
            "loss 2.738362030241996e-05 average time 0.14162476186666026 iter num 60\n",
            "loss 2.7339515989707908e-05 average time 0.14168680736243006 iter num 80\n",
            "loss 2.7331191950817684e-05 average time 0.14163399926997955 iter num 100\n",
            "loss 2.7187294254084697e-05 average time 0.14380281919984556 iter num 20\n",
            "loss 2.708103095781143e-05 average time 0.1453345485497266 iter num 40\n",
            "loss 2.7018065253060403e-05 average time 0.14431423544974678 iter num 60\n",
            "loss 2.6991246880608326e-05 average time 0.14409855844978664 iter num 80\n",
            "loss 2.6985887018112142e-05 average time 0.14383167963987945 iter num 100\n",
            "loss 2.688590580344785e-05 average time 0.14175274379995245 iter num 20\n",
            "loss 2.6805794299714172e-05 average time 0.14116474537495377 iter num 40\n",
            "loss 2.6757209377787333e-05 average time 0.14236136910003552 iter num 60\n",
            "loss 2.6736532285022885e-05 average time 0.14173087443750773 iter num 80\n",
            "loss 2.673233684252189e-05 average time 0.14207512282999232 iter num 100\n",
            "loss 2.6654371244176635e-05 average time 0.1427425783003855 iter num 20\n",
            "loss 2.659089818749507e-05 average time 0.1431525878253524 iter num 40\n",
            "loss 2.655246712223743e-05 average time 0.1423123120670425 iter num 60\n",
            "loss 2.653549656291756e-05 average time 0.14305606503771742 iter num 80\n",
            "loss 2.6532068356804967e-05 average time 0.14295736954019958 iter num 100\n",
            "loss 2.6465579942657436e-05 average time 0.1422395271001733 iter num 20\n",
            "loss 2.641144049454601e-05 average time 0.1423780615748001 iter num 40\n",
            "loss 2.6378408567562002e-05 average time 0.14220042840018626 iter num 60\n",
            "loss 2.6364290123511004e-05 average time 0.14225840952512953 iter num 80\n",
            "loss 2.6361634184541372e-05 average time 0.1424389686300856 iter num 100\n",
            "loss 2.630413653693932e-05 average time 0.14208556119974675 iter num 20\n",
            "loss 2.6256728080532947e-05 average time 0.1419799683249039 iter num 40\n",
            "loss 2.6227467813185554e-05 average time 0.1416784492999189 iter num 60\n",
            "loss 2.6214962031306573e-05 average time 0.14161401279998245 iter num 80\n",
            "loss 2.621266760945491e-05 average time 0.14196376563988453 iter num 100\n",
            "loss 2.61651537806989e-05 average time 0.14238963480020175 iter num 20\n",
            "loss 2.612640734388816e-05 average time 0.14199045799996385 iter num 40\n",
            "loss 2.6102377973716177e-05 average time 0.14207082969999948 iter num 60\n",
            "loss 2.6091892364663555e-05 average time 0.1429716751748856 iter num 80\n",
            "loss 2.609002007436668e-05 average time 0.14295256119989064 iter num 100\n",
            "loss 2.6050479772731976e-05 average time 0.14073551265009882 iter num 20\n",
            "loss 2.601708538074305e-05 average time 0.14193496465004501 iter num 40\n",
            "loss 2.599667055930118e-05 average time 0.14180891951679467 iter num 60\n",
            "loss 2.5987708742161748e-05 average time 0.14215321427518574 iter num 80\n",
            "loss 2.5986143172632893e-05 average time 0.1416603414301062 iter num 100\n",
            "loss 2.5945897693059183e-05 average time 0.14090564594935132 iter num 20\n",
            "loss 2.592270109623124e-05 average time 0.1434347828497266 iter num 40\n",
            "loss 2.5906142054608953e-05 average time 0.1435104039665627 iter num 60\n",
            "loss 2.5898261136381787e-05 average time 0.14324461456230891 iter num 80\n",
            "loss 2.5896730226705947e-05 average time 0.14309398526984296 iter num 100\n",
            "loss 3.778796315630469e-05 average time 0.13990555140026117 iter num 20\n",
            "loss 2.7712453387068382e-05 average time 0.14064925735019643 iter num 40\n",
            "loss 2.6794639428479937e-05 average time 0.14099285010003465 iter num 60\n",
            "loss 2.6657697413532522e-05 average time 0.14139379335006197 iter num 80\n",
            "loss 2.6631625736278605e-05 average time 0.14128815219999524 iter num 100\n",
            "loss 2.641176735165402e-05 average time 0.14225484915023118 iter num 20\n",
            "loss 2.631040921657067e-05 average time 0.14243018477491204 iter num 40\n",
            "loss 2.627296056390065e-05 average time 0.1422021936999954 iter num 60\n",
            "loss 2.6260956914396852e-05 average time 0.14252569650002442 iter num 80\n",
            "loss 2.6258440228788412e-05 average time 0.14259063186000276 iter num 100\n",
            "loss 2.62040937475311e-05 average time 0.1497006493000299 iter num 20\n",
            "loss 2.615324747456836e-05 average time 0.14609095767491453 iter num 40\n",
            "loss 2.612119233202224e-05 average time 0.14440103221659228 iter num 60\n",
            "loss 2.6107254805327482e-05 average time 0.14360622771255294 iter num 80\n",
            "loss 2.6104675401588206e-05 average time 0.1429988368200793 iter num 100\n",
            "loss 2.6052092094818578e-05 average time 0.14279930545017122 iter num 20\n",
            "loss 2.600867586463555e-05 average time 0.14199640947508668 iter num 40\n",
            "loss 2.598173670811528e-05 average time 0.1421123245168322 iter num 60\n",
            "loss 2.597009144371466e-05 average time 0.14188145931266263 iter num 80\n",
            "loss 2.5967901874365266e-05 average time 0.14288567534018512 iter num 100\n",
            "loss 2.5923210111834536e-05 average time 0.1430159810006444 iter num 20\n",
            "loss 2.5886280255417288e-05 average time 0.1423294046502633 iter num 40\n",
            "loss 2.5863319376898767e-05 average time 0.14249926658346038 iter num 60\n",
            "loss 2.5853348681931155e-05 average time 0.14251275308747607 iter num 80\n",
            "loss 2.585147312542234e-05 average time 0.14255135997995239 iter num 100\n",
            "loss 2.589584412006869e-05 average time 0.13990678364971246 iter num 20\n",
            "loss 2.5790500761948152e-05 average time 0.1404018282000834 iter num 40\n",
            "loss 2.5764774209511583e-05 average time 0.14101127390016094 iter num 60\n",
            "loss 2.575669228783406e-05 average time 0.14236484965026647 iter num 80\n",
            "loss 2.5755359195624616e-05 average time 0.14255052126023657 iter num 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQs-OZHGEwac"
      },
      "source": [
        "# 23 + 23 + 23 + 23 + 16 + 23 + (23)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36cba7cc-2196-4e65-d6c0-cc124b307ca6"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 1, 1, 0.25, 0.02, 0.02]]).cuda() # T, K, S, sigma, mu, r\n",
        "print('price: ' + str(model(inputs.float())))\n",
        "\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient[0][[2]]\n",
        "\n",
        "# price, delta\n",
        "# should be around (0.10870558, 0.581213937)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: tensor([[0.1049]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5880], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqpasxVi0hx3",
        "outputId": "88a80a87-0f60-4895-a76b-e208c67f4a5c"
      },
      "source": [
        "import cupy\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "import pandas as pd\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "    return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "print(bs_call(1,1,1,0.02,0.25))\n",
        "print(bs_delta(1,1,1,0.02,0.25))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10870558490557591\n",
            "0.5812139374874482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lovJwXo3-YEu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "2a436cac-ffb8-4a1b-b8a2-c07258283fb3"
      },
      "source": [
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "\n",
        "def compute_price(S):\n",
        "    inputs = torch.tensor([[1, 1, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_prices = []\n",
        "BS_call_prices = []\n",
        "for p in prices:\n",
        "    model_call_prices.append(compute_price(p).item())\n",
        "    BS_call_prices.append(bs_call(p, 1, 1, 0.02, 0.25))\n",
        "\n",
        "#plt.plot(prices, model_call_prices, label = \"model_call_prices\")\n",
        "#plt.plot(prices, BS_call_prices, label = \"BS_call_prices\")\n",
        "plt.plot(prices, np.array(model_call_prices)-np.array(BS_call_prices), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwApH0GT9bBK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "8713a026-d6f1-4d89-fe4b-424cf5efd117"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 1, 1, 0.02, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHgD1NjP7DOW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "cb99f3f5-0062-499d-b3d3-b1baa4b2eb75"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 0.75, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 0.75, 1, 0.02, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7MfujMQ7oij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3b02899e-bbde-4066-d966-3ecaf42df335"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1.25, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 1.25, 1, 0.02, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}