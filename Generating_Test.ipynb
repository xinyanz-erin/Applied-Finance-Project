{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generating Test",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Judy/Generating_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e86Pm8rKt3yf"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuPE3AQX2BH1",
        "outputId": "ee6ecd70-d4ac-4712-9ab5-7547a286b89c"
      },
      "source": [
        "S_range = np.linspace(0.75, 1.25, 5)\n",
        "K_range = np.linspace(0.75, 1.25, 5)\n",
        "Sigma_range = np.linspace(0.15, 0.45, 3)\n",
        "r_range = np.linspace(0.01, 0.04, 2)\n",
        "\n",
        "print(S_range)\n",
        "print(K_range)\n",
        "print(Sigma_range)\n",
        "print(r_range)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.75  0.875 1.    1.125 1.25 ]\n",
            "[0.75  0.875 1.    1.125 1.25 ]\n",
            "[0.15 0.3  0.45]\n",
            "[0.01 0.04]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4HV-G44th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c9f168e-ab68-42ce-ff73-7da930e07a4f"
      },
      "source": [
        "%%writefile cupy_dataset.py\n",
        "import cupy\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "import pandas as pd\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "    return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "S_range = np.linspace(0.75, 1.25, 5)\n",
        "K_range = np.linspace(0.75, 1.25, 5)\n",
        "Sigma_range = np.linspace(0.15, 0.45, 3)\n",
        "r_range = np.linspace(0.01, 0.04, 2)\n",
        "\n",
        "call = []\n",
        "for i in S_range:\n",
        "  for j in K_range:\n",
        "    for l in r_range:\n",
        "      for k in Sigma_range:\n",
        "        call.append([1,j,i,k,l,l,bs_call(i,j,1,l,k),bs_delta(i,j,1,l,k)]) #T, K, S, sigma, mu, r\n",
        "Thedataset = pd.DataFrame(call)\n",
        "\n",
        "Thedataset_X = Thedataset.iloc[:,:6]\n",
        "Thedataset_Y = Thedataset.iloc[:,6:]\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len, number_path, batch, seed, stocks):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 50\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = 1.0 # assume T = 1, use float here\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        self.X = cupy.array(Thedataset_X)\n",
        "        self.Y = cupy.array(Thedataset_Y)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(self.X.toDlpack()), from_dlpack(self.Y.toDlpack()))\n",
        "\n",
        "\n",
        "# ds = OptionDataSet(max_len = 1, number_path = 10000, batch = 2, seed = np.random.randint(10000), stocks=1) # for testing purpose, use constant seed. When training, change to random seed\n",
        "# for i in ds:\n",
        "#     print(i[0])\n",
        "#     print(i[0].shape)\n",
        "#     print(i[1])\n",
        "#     print(i[1].shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cupy_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6JO9OBHdvv",
        "outputId": "bbf33bcd-fbf4-4203-988e-b83b010ea4e0"
      },
      "source": [
        "%%writefile model.py\n",
        "# version 1,2\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*1, 32) # remember to change this!\n",
        "        self.fc2 = nn.Linear(32, 64)\n",
        "        self.fc3 = nn.Linear(64, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 32)\n",
        "        self.fc6 = nn.Linear(32, 1) # 1 outputs: price\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1.0, 0.5, 0.5, 0.3, 0.03, 0.03]*1)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = (x - torch.tensor([0.0, 0.75, 0.75, 0.15, 0.01, 0.01]*1).cuda()) / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlXD80xPNVc6",
        "outputId": "69701623-e8f2-4cce-c5bf-ca8a3bf51ed9"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 34.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 18.8 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 10.8 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 11.7 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 9.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3CyULkENYKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b277167d-cb65-4f09-920e-cb2030aa2503"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 100000, batch = 1, seed = np.random.randint(10000), stocks = 1) # must have random seed. It doesn't matter how many batch here (not taken into function). Use max_len to adjust\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    # print(x)\n",
        "    # print(x.shape)\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    # print(y.shape)\n",
        "    y_pred = model(x.float())\n",
        "    # print(y_pred)\n",
        "    # print(y_pred.shape)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x.float()\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "    # print(y_pred)\n",
        "    # print(y_pred.shape)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.1888860525436098 average time 0.14984231329999886 iter num 20\n",
            "loss 0.1690811336374387 average time 0.1459700626250026 iter num 40\n",
            "loss 0.1536369712296809 average time 0.14475045841666656 iter num 60\n",
            "loss 0.1455405835980438 average time 0.14530027696249945 iter num 80\n",
            "loss 0.14372804828038266 average time 0.14475901188000137 iter num 100\n",
            "loss 0.10662811339287236 average time 0.14235618540000133 iter num 20\n",
            "loss 0.07440038968807451 average time 0.14295278689999974 iter num 40\n",
            "loss 0.059077172243148963 average time 0.14299817124999947 iter num 60\n",
            "loss 0.05465071148316707 average time 0.1429774612999985 iter num 80\n",
            "loss 0.05393771563482347 average time 0.14342250069999693 iter num 100\n",
            "loss 0.04740896252152207 average time 0.1477658823000013 iter num 20\n",
            "loss 0.046747206299596014 average time 0.14544273640000113 iter num 40\n",
            "loss 0.04620156178972212 average time 0.14491158003333263 iter num 60\n",
            "loss 0.045954737852790965 average time 0.144361768549998 iter num 80\n",
            "loss 0.04590441385109942 average time 0.14546625729999732 iter num 100\n",
            "loss 0.044979348214723394 average time 0.1440805644500017 iter num 20\n",
            "loss 0.044200126260709995 average time 0.14442022710000088 iter num 40\n",
            "loss 0.043690688259359185 average time 0.1444649297833346 iter num 60\n",
            "loss 0.04345704583974128 average time 0.14456676546249908 iter num 80\n",
            "loss 0.04340729554172902 average time 0.1442720532499993 iter num 100\n",
            "loss 0.04245611998347828 average time 0.14523504985000385 iter num 20\n",
            "loss 0.04162161103271871 average time 0.14630430982500114 iter num 40\n",
            "loss 0.04107269428561517 average time 0.14591226460000162 iter num 60\n",
            "loss 0.04082281643154084 average time 0.14567518688750028 iter num 80\n",
            "loss 0.04076992103462514 average time 0.14583422510999866 iter num 100\n",
            "loss 0.03976392766960764 average time 0.1438215787000047 iter num 20\n",
            "loss 0.0388762202534406 average time 0.14624679442500224 iter num 40\n",
            "loss 0.03829258915280447 average time 0.14570039649999936 iter num 60\n",
            "loss 0.03802744605631173 average time 0.14492327848749795 iter num 80\n",
            "loss 0.037971361575183694 average time 0.14471138605000136 iter num 100\n",
            "loss 0.03690315894092695 average time 0.14360578475000524 iter num 20\n",
            "loss 0.03596316754915925 average time 0.1448246632000007 iter num 40\n",
            "loss 0.03534464602900493 average time 0.14428755656666586 iter num 60\n",
            "loss 0.03506214030089112 average time 0.14410255717499892 iter num 80\n",
            "loss 0.03500235403529399 average time 0.14424357208000005 iter num 100\n",
            "loss 0.0338660843279932 average time 0.14447232895000753 iter num 20\n",
            "loss 0.03285984002897008 average time 0.14602475084999753 iter num 40\n",
            "loss 0.03219436391073185 average time 0.145736968483331 iter num 60\n",
            "loss 0.031890170034833895 average time 0.1451278134624964 iter num 80\n",
            "loss 0.0318258169809618 average time 0.14476396970999644 iter num 100\n",
            "loss 0.030601080876814166 average time 0.14340120050000849 iter num 20\n",
            "loss 0.029510121094879584 average time 0.14292420777500753 iter num 40\n",
            "loss 0.028783857629536138 average time 0.14290848238333637 iter num 60\n",
            "loss 0.028450729214761047 average time 0.14289424045000204 iter num 80\n",
            "loss 0.02838026722097706 average time 0.1429050414000028 iter num 100\n",
            "loss 0.027037543130009684 average time 0.14606350879999752 iter num 20\n",
            "loss 0.025835147168892725 average time 0.14551915017499936 iter num 40\n",
            "loss 0.025032726236395263 average time 0.14499846721666643 iter num 60\n",
            "loss 0.024665251520679707 average time 0.1447155030000012 iter num 80\n",
            "loss 0.02458770114550658 average time 0.14535158471000215 iter num 100\n",
            "loss 0.02311203365843622 average time 0.1499182667500037 iter num 20\n",
            "loss 0.0217930067014556 average time 0.15050627455000126 iter num 40\n",
            "loss 0.02091851347044268 average time 0.15022449363333312 iter num 60\n",
            "loss 0.02051965575403696 average time 0.15004142066249884 iter num 80\n",
            "loss 0.020435742534828053 average time 0.1499639555799996 iter num 100\n",
            "loss 0.01884956848433311 average time 0.14895440210000288 iter num 20\n",
            "loss 0.01745539334487308 average time 0.1485324633250059 iter num 40\n",
            "loss 0.016547522548927943 average time 0.14628901483334478 iter num 60\n",
            "loss 0.016139923476451757 average time 0.1464739097625099 iter num 80\n",
            "loss 0.016054898715877352 average time 0.14664781145000916 iter num 100\n",
            "loss 0.014475822178669504 average time 0.14679190780003068 iter num 20\n",
            "loss 0.013141443683358265 average time 0.145809174775016 iter num 40\n",
            "loss 0.012310201684500168 average time 0.14534949638334257 iter num 60\n",
            "loss 0.011948179775620984 average time 0.1448728542500035 iter num 80\n",
            "loss 0.011873748944509344 average time 0.14436260233000553 iter num 100\n",
            "loss 0.010532155513541853 average time 0.14203329769998732 iter num 20\n",
            "loss 0.009474716304185405 average time 0.14241749902499237 iter num 40\n",
            "loss 0.008857757050367988 average time 0.14216640423332857 iter num 60\n",
            "loss 0.0086007218407257 average time 0.14201356293749826 iter num 80\n",
            "loss 0.008548871001960515 average time 0.14244104943000138 iter num 100\n",
            "loss 0.007645916759917073 average time 0.14372242705001667 iter num 20\n",
            "loss 0.006986503732038747 average time 0.14371515545000477 iter num 40\n",
            "loss 0.006624984948751933 average time 0.14333302776666984 iter num 60\n",
            "loss 0.006479086053000938 average time 0.14291519293750526 iter num 80\n",
            "loss 0.006449998925436665 average time 0.14256910619000565 iter num 100\n",
            "loss 0.005950720610198378 average time 0.14532172254999978 iter num 20\n",
            "loss 0.005591625009815083 average time 0.1435091545249975 iter num 40\n",
            "loss 0.00539218914101335 average time 0.14353653651666415 iter num 60\n",
            "loss 0.005310108670880357 average time 0.14327798617499496 iter num 80\n",
            "loss 0.005293585374316332 average time 0.14302445004999867 iter num 100\n",
            "loss 0.004999115634689196 average time 0.14242751670000758 iter num 20\n",
            "loss 0.004770987581822885 average time 0.14225482635001468 iter num 40\n",
            "loss 0.004635058749684572 average time 0.14224523053334792 iter num 60\n",
            "loss 0.004576787577960147 average time 0.1433390317875066 iter num 80\n",
            "loss 0.004564819049459524 average time 0.14342638873000282 iter num 100\n",
            "loss 0.004344740276837649 average time 0.1418085754999879 iter num 20\n",
            "loss 0.004161974739624052 average time 0.1417473650999881 iter num 40\n",
            "loss 0.004047835273858601 average time 0.14188390931665823 iter num 60\n",
            "loss 0.003997649769743561 average time 0.14216077189999368 iter num 80\n",
            "loss 0.003987254495773404 average time 0.1421528553499968 iter num 100\n",
            "loss 0.0037943596506781634 average time 0.1421750047000046 iter num 20\n",
            "loss 0.003634576337730419 average time 0.14322895175000952 iter num 40\n",
            "loss 0.003535618886365021 average time 0.1425501031000086 iter num 60\n",
            "loss 0.00349222422572534 average time 0.1424991786625071 iter num 80\n",
            "loss 0.003483240145618797 average time 0.1428618847600046 iter num 100\n",
            "loss 0.0033201426902508056 average time 0.1412916770499976 iter num 20\n",
            "loss 0.003185967467602657 average time 0.14221930534999389 iter num 40\n",
            "loss 0.003102662643655639 average time 0.14187996353333385 iter num 60\n",
            "loss 0.003066404043367935 average time 0.14205609218750226 iter num 80\n",
            "loss 0.0030588931409480193 average time 0.1422975112500012 iter num 100\n",
            "loss 0.0029217858974277507 average time 0.14212541485000543 iter num 20\n",
            "loss 0.002807268634966487 average time 0.1420784695750001 iter num 40\n",
            "loss 0.0027339637517863457 average time 0.14237865975000166 iter num 60\n",
            "loss 0.0027014523618045447 average time 0.14212469115000204 iter num 80\n",
            "loss 0.002694635680552755 average time 0.14214966185000208 iter num 100\n",
            "loss 0.0025687507280105245 average time 0.14249361534999708 iter num 20\n",
            "loss 0.0024636018072696757 average time 0.14493523982499426 iter num 40\n",
            "loss 0.0023969305513895085 average time 0.14382256838333282 iter num 60\n",
            "loss 0.002367272876702652 average time 0.1433518152625041 iter num 80\n",
            "loss 0.0023610763041550156 average time 0.14311213521000582 iter num 100\n",
            "loss 0.0022444915029167013 average time 0.14068084879999673 iter num 20\n",
            "loss 0.002147784512119633 average time 0.14133177947499292 iter num 40\n",
            "loss 0.0020860471476077252 average time 0.1416324593499932 iter num 60\n",
            "loss 0.0020586764703473537 average time 0.14138471337499398 iter num 80\n",
            "loss 0.0020529895897856373 average time 0.1416600692599957 iter num 100\n",
            "loss 0.001952920372429778 average time 0.1422731173000102 iter num 20\n",
            "loss 0.0018707355335279017 average time 0.14312346910000145 iter num 40\n",
            "loss 0.0018194715503636596 average time 0.14418758583333896 iter num 60\n",
            "loss 0.0017967286997303059 average time 0.14557504663750792 iter num 80\n",
            "loss 0.001792010443898986 average time 0.14532626410000715 iter num 100\n",
            "loss 0.0017055395442640887 average time 0.1431964536500061 iter num 20\n",
            "loss 0.0016326069722078264 average time 0.14216460065000264 iter num 40\n",
            "loss 0.0015865660934317298 average time 0.14255526246666553 iter num 60\n",
            "loss 0.0015662550937623194 average time 0.1424611433499976 iter num 80\n",
            "loss 0.0015620304131413797 average time 0.14251374887999418 iter num 100\n",
            "loss 0.0014842741806835138 average time 0.1411547495999912 iter num 20\n",
            "loss 0.0014194245807348789 average time 0.14114052409999828 iter num 40\n",
            "loss 0.0013788108456839776 average time 0.14183898256666605 iter num 60\n",
            "loss 0.0013609095418432012 average time 0.14165197620000214 iter num 80\n",
            "loss 0.0013572015741531807 average time 0.14244989763000035 iter num 100\n",
            "loss 0.001289956449824594 average time 0.14162736650000057 iter num 20\n",
            "loss 0.0012356839822653639 average time 0.14274713457500354 iter num 40\n",
            "loss 0.001202193576011314 average time 0.14237533870000144 iter num 60\n",
            "loss 0.0011875787988794612 average time 0.14221599433750215 iter num 80\n",
            "loss 0.001184572496810728 average time 0.1422891172900006 iter num 100\n",
            "loss 0.0011319799615106775 average time 0.14327584474999072 iter num 20\n",
            "loss 0.001089950450156355 average time 0.14240268817499385 iter num 40\n",
            "loss 0.0010639396851982112 average time 0.14173648528332972 iter num 60\n",
            "loss 0.0010525772751140167 average time 0.14314454972499674 iter num 80\n",
            "loss 0.0010502282156001816 average time 0.1428158320199975 iter num 100\n",
            "loss 0.0010068830434356317 average time 0.14563759520000302 iter num 20\n",
            "loss 0.0009707553400822442 average time 0.145270155875005 iter num 40\n",
            "loss 0.0009483081691376399 average time 0.1441437095166729 iter num 60\n",
            "loss 0.0009384641537704777 average time 0.14350436406250963 iter num 80\n",
            "loss 0.0009364265667324353 average time 0.143437215510005 iter num 100\n",
            "loss 0.0009010338562956498 average time 0.14340411250000215 iter num 20\n",
            "loss 0.0008701852121759846 average time 0.14276702950000128 iter num 40\n",
            "loss 0.0008521714815259256 average time 0.14305922513333183 iter num 60\n",
            "loss 0.000844321180215217 average time 0.14255161811249906 iter num 80\n",
            "loss 0.0008427143056268666 average time 0.14263960659999952 iter num 100\n",
            "loss 0.0008197042786635692 average time 0.14057414749999567 iter num 20\n",
            "loss 0.0007966453319531844 average time 0.1409026661500093 iter num 40\n",
            "loss 0.0007838156772073615 average time 0.1422954170500077 iter num 60\n",
            "loss 0.0007783890827675904 average time 0.1423771133375027 iter num 80\n",
            "loss 0.0007772702293864211 average time 0.14252141245000075 iter num 100\n",
            "loss 0.0007568412275930267 average time 0.14174625210000613 iter num 20\n",
            "loss 0.0007400478316708377 average time 0.1424202517000026 iter num 40\n",
            "loss 0.0007295220286377337 average time 0.14197300558333267 iter num 60\n",
            "loss 0.000724890220323315 average time 0.1428115794624972 iter num 80\n",
            "loss 0.0007239316423738456 average time 0.1438227736299973 iter num 100\n",
            "loss 0.000706254426616949 average time 0.14471607365000522 iter num 20\n",
            "loss 0.0006916343786065915 average time 0.14593218537500546 iter num 40\n",
            "loss 0.0006825914199686331 average time 0.14562856146667022 iter num 60\n",
            "loss 0.0006786505013716724 average time 0.14506697303750116 iter num 80\n",
            "loss 0.0006778350451901816 average time 0.14517516185000431 iter num 100\n",
            "loss 0.0006630752823968852 average time 0.1424001930999907 iter num 20\n",
            "loss 0.0006509528988856973 average time 0.14265546057499706 iter num 40\n",
            "loss 0.0006434759780157653 average time 0.1424505409666684 iter num 60\n",
            "loss 0.0006402102215599208 average time 0.14292640196250517 iter num 80\n",
            "loss 0.0006395360096058657 average time 0.1425780298000086 iter num 100\n",
            "loss 0.0006273042715477793 average time 0.14193296145002138 iter num 20\n",
            "loss 0.0006173185364037881 average time 0.14212552020001112 iter num 40\n",
            "loss 0.0006111409444310993 average time 0.14216453678334537 iter num 60\n",
            "loss 0.0006084213437985783 average time 0.14244662562500993 iter num 80\n",
            "loss 0.0006078606958745873 average time 0.1421859178300076 iter num 100\n",
            "loss 0.0005991472020437195 average time 0.1462486342499915 iter num 20\n",
            "loss 0.000595005461519238 average time 0.14474156207499506 iter num 40\n",
            "loss 0.0005893299405148253 average time 0.14426445259999052 iter num 60\n",
            "loss 0.0005875742710350036 average time 0.1435035245999913 iter num 80\n",
            "loss 0.0005871793786492338 average time 0.14300712493999185 iter num 100\n",
            "loss 0.0005806948657094175 average time 0.14171228295001584 iter num 20\n",
            "loss 0.0005752996518804796 average time 0.1417424918250049 iter num 40\n",
            "loss 0.0005719466383407829 average time 0.1415392443666633 iter num 60\n",
            "loss 0.0005704752095139602 average time 0.14168381301249725 iter num 80\n",
            "loss 0.0005701688305662096 average time 0.14187532998000052 iter num 100\n",
            "loss 0.0005645574392975784 average time 0.1426326472000028 iter num 20\n",
            "loss 0.0005598797583351506 average time 0.1415916986999946 iter num 40\n",
            "loss 0.0005569543247764662 average time 0.14292540924999458 iter num 60\n",
            "loss 0.000555657810408337 average time 0.14296370548749734 iter num 80\n",
            "loss 0.000555388239673015 average time 0.14277652199000046 iter num 100\n",
            "loss 0.0005503236234779757 average time 0.14233007655000166 iter num 20\n",
            "loss 0.0005460218464724977 average time 0.14207884352499606 iter num 40\n",
            "loss 0.000543241689934277 average time 0.14168955914999135 iter num 60\n",
            "loss 0.0005420034488296963 average time 0.14124302743749553 iter num 80\n",
            "loss 0.0005417461815933518 average time 0.14120666766000112 iter num 100\n",
            "loss 0.0005370026014218643 average time 0.14197238009999183 iter num 20\n",
            "loss 0.0005330055712819031 average time 0.14161377252499677 iter num 40\n",
            "loss 0.0005304712577215602 average time 0.14238257120000336 iter num 60\n",
            "loss 0.000529339294600051 average time 0.14262345876250038 iter num 80\n",
            "loss 0.0005291029967904097 average time 0.14231004108999515 iter num 100\n",
            "loss 0.0005246939777929399 average time 0.14150211584999967 iter num 20\n",
            "loss 0.0005209778335175874 average time 0.14230118657499133 iter num 40\n",
            "loss 0.0005186129803423902 average time 0.1423875370333216 iter num 60\n",
            "loss 0.0005175604983393465 average time 0.14234154139999333 iter num 80\n",
            "loss 0.0005173416398073862 average time 0.14236744338999188 iter num 100\n",
            "loss 0.000513318387142874 average time 0.14041000285000677 iter num 20\n",
            "loss 0.0005099195693652173 average time 0.14134703834999982 iter num 40\n",
            "loss 0.0005077542631682715 average time 0.14126837648333132 iter num 60\n",
            "loss 0.0005067884052834743 average time 0.14130935627499924 iter num 80\n",
            "loss 0.000506586681179286 average time 0.1414126979100024 iter num 100\n",
            "loss 0.0005028402678086719 average time 0.14397161615001436 iter num 20\n",
            "loss 0.0004996406336406273 average time 0.1426560086749987 iter num 40\n",
            "loss 0.0004975664788022928 average time 0.1414999139166639 iter num 60\n",
            "loss 0.00049663858510907 average time 0.14151258418749676 iter num 80\n",
            "loss 0.0004964443095859007 average time 0.1413192250899965 iter num 100\n",
            "loss 0.0004928468784193702 average time 0.1404572474499844 iter num 20\n",
            "loss 0.0004897731667086141 average time 0.14079138309998881 iter num 40\n",
            "loss 0.0004877923630899032 average time 0.14119270398332825 iter num 60\n",
            "loss 0.0004869035287035652 average time 0.14146968658749728 iter num 80\n",
            "loss 0.00048671810669809087 average time 0.1415631915999984 iter num 100\n",
            "loss 0.00048371890941044187 average time 0.14155975649999847 iter num 20\n",
            "loss 0.00048017194033170903 average time 0.14111014864999163 iter num 40\n",
            "loss 0.0004783309249682007 average time 0.1424891422166638 iter num 60\n",
            "loss 0.00047746977626963777 average time 0.14271225079999966 iter num 80\n",
            "loss 0.00047728624768982926 average time 0.14332446573999733 iter num 100\n",
            "loss 0.00048339135375444984 average time 0.1415927199000066 iter num 20\n",
            "loss 0.0004712260252695453 average time 0.14082141077499558 iter num 40\n",
            "loss 0.00046786319181680496 average time 0.14098129588332994 iter num 60\n",
            "loss 0.000467192460943202 average time 0.14117355807499904 iter num 80\n",
            "loss 0.0004670646284087727 average time 0.14118190752999793 iter num 100\n",
            "loss 0.0004648375504604841 average time 0.1425020617499854 iter num 20\n",
            "loss 0.00046286162111362555 average time 0.14206888377498786 iter num 40\n",
            "loss 0.0004615497343163061 average time 0.14240447974999407 iter num 60\n",
            "loss 0.0004609543990888268 average time 0.14258104533749502 iter num 80\n",
            "loss 0.0004608293880088103 average time 0.1425547924699981 iter num 100\n",
            "loss 0.000458488554439526 average time 0.14131786875001354 iter num 20\n",
            "loss 0.0004564488733665858 average time 0.14119678295000995 iter num 40\n",
            "loss 0.0004551191336779786 average time 0.14121990383332939 iter num 60\n",
            "loss 0.00045451867501603596 average time 0.1411385807500068 iter num 80\n",
            "loss 0.0004543925931785973 average time 0.14117942659000846 iter num 100\n",
            "loss 0.0004520272777864932 average time 0.14175199884997483 iter num 20\n",
            "loss 0.0004499431205558564 average time 0.14091738964997375 iter num 40\n",
            "loss 0.000448582506154613 average time 0.14106464746663125 iter num 60\n",
            "loss 0.00044796657086912535 average time 0.14136980811247213 iter num 80\n",
            "loss 0.00044783732531322317 average time 0.14103836399997818 iter num 100\n",
            "loss 0.00044540389075619263 average time 0.14657388849997233 iter num 20\n",
            "loss 0.0004432721551420974 average time 0.14445705949999024 iter num 40\n",
            "loss 0.0004418750494769352 average time 0.14367685183333379 iter num 60\n",
            "loss 0.000441241964451038 average time 0.14294959412500247 iter num 80\n",
            "loss 0.00044110879619538464 average time 0.14269702501000212 iter num 100\n",
            "loss 0.00043860885715863845 average time 0.13918863194998038 iter num 20\n",
            "loss 0.00043641969178696415 average time 0.14051916994999375 iter num 40\n",
            "loss 0.0004349870797945069 average time 0.1406212653666633 iter num 60\n",
            "loss 0.000434338625138564 average time 0.14106757929998537 iter num 80\n",
            "loss 0.00043420312756857325 average time 0.141433393519992 iter num 100\n",
            "loss 0.00043164651633665203 average time 0.14142432215001008 iter num 20\n",
            "loss 0.00042939455816550583 average time 0.1415547163000042 iter num 40\n",
            "loss 0.00042792069538459944 average time 0.14224733758334196 iter num 60\n",
            "loss 0.00042725246518164286 average time 0.14215419276250998 iter num 80\n",
            "loss 0.00042711210447649256 average time 0.1419093412000143 iter num 100\n",
            "loss 0.0004244727321786453 average time 0.1420282479999969 iter num 20\n",
            "loss 0.00042216856841386415 average time 0.1415791283500198 iter num 40\n",
            "loss 0.0004206702898246006 average time 0.14130049411668325 iter num 60\n",
            "loss 0.00041999233616699355 average time 0.14112246512501087 iter num 80\n",
            "loss 0.0004198497733358174 average time 0.14106641800000716 iter num 100\n",
            "loss 0.0004171698365677211 average time 0.1411243495000008 iter num 20\n",
            "loss 0.00041483533194325387 average time 0.14069243010001173 iter num 40\n",
            "loss 0.0004132947505628272 average time 0.14249227778334064 iter num 60\n",
            "loss 0.00041259351941260857 average time 0.14378797673750227 iter num 80\n",
            "loss 0.0004124465635576853 average time 0.14419469402999538 iter num 100\n",
            "loss 0.00041695741195735893 average time 0.1453040668000085 iter num 20\n",
            "loss 0.00040686505726598066 average time 0.14496255262499744 iter num 40\n",
            "loss 0.00040533024811739834 average time 0.14419472106667777 iter num 60\n",
            "loss 0.0004045649836218126 average time 0.14339667571250914 iter num 80\n",
            "loss 0.00040441731679236183 average time 0.1429925101700087 iter num 100\n",
            "loss 0.0004024043666167025 average time 0.14066506824997305 iter num 20\n",
            "loss 0.0003991683682162848 average time 0.1407105824499979 iter num 40\n",
            "loss 0.0003978218995669398 average time 0.1404807026666731 iter num 60\n",
            "loss 0.00039719608279096446 average time 0.14084946196250314 iter num 80\n",
            "loss 0.00039705202458868006 average time 0.14084222028000112 iter num 100\n",
            "loss 0.0003947280433260296 average time 0.14510807365002165 iter num 20\n",
            "loss 0.0003920693715057731 average time 0.14333972927501576 iter num 40\n",
            "loss 0.0003906709918168044 average time 0.1439895799666753 iter num 60\n",
            "loss 0.0003900145912000077 average time 0.1429574767499986 iter num 80\n",
            "loss 0.0003898695168130879 average time 0.14255472766999902 iter num 100\n",
            "loss 0.000387654546130721 average time 0.1397558534000268 iter num 20\n",
            "loss 0.0003843480885381856 average time 0.1418669758750184 iter num 40\n",
            "loss 0.00038290166355746765 average time 0.14158265468335002 iter num 60\n",
            "loss 0.00038232617917880645 average time 0.14161133090000533 iter num 80\n",
            "loss 0.00038219234477592163 average time 0.14189907205000962 iter num 100\n",
            "loss 0.00038056654718275146 average time 0.1398591139000132 iter num 20\n",
            "loss 0.0003773126227041129 average time 0.14190232832501692 iter num 40\n",
            "loss 0.0003758468271487976 average time 0.14285397161667485 iter num 60\n",
            "loss 0.00037522318205649184 average time 0.1424414061249962 iter num 80\n",
            "loss 0.00037509160878067385 average time 0.14210191104999012 iter num 100\n",
            "loss 0.00037244204079093526 average time 0.13964433954998867 iter num 20\n",
            "loss 0.0003698536115255814 average time 0.14052207707497927 iter num 40\n",
            "loss 0.00036848483992131737 average time 0.14052744288331573 iter num 60\n",
            "loss 0.00036789115432861035 average time 0.14056812063748225 iter num 80\n",
            "loss 0.0003677508128236466 average time 0.14076432782998835 iter num 100\n",
            "loss 0.0003682340006045326 average time 0.1412979433000146 iter num 20\n",
            "loss 0.0003627982260379362 average time 0.14061799645000406 iter num 40\n",
            "loss 0.00036119159712429545 average time 0.14098585475001452 iter num 60\n",
            "loss 0.0003605265109733688 average time 0.14186130805002223 iter num 80\n",
            "loss 0.00036039056384738044 average time 0.14179129012001568 iter num 100\n",
            "loss 0.00035796727954041897 average time 0.14110341955001787 iter num 20\n",
            "loss 0.0003558946260120396 average time 0.14081799149999483 iter num 40\n",
            "loss 0.00035451799443592086 average time 0.1414519932166665 iter num 60\n",
            "loss 0.0003538878687749592 average time 0.14146119371250448 iter num 80\n",
            "loss 0.0003537553371446536 average time 0.1414435917899982 iter num 100\n",
            "loss 0.00035212476478688355 average time 0.1415195497500008 iter num 20\n",
            "loss 0.00034900966765095135 average time 0.14217205115000411 iter num 40\n",
            "loss 0.00034763298408337534 average time 0.14108048589999952 iter num 60\n",
            "loss 0.0003469654183283245 average time 0.14066039951250672 iter num 80\n",
            "loss 0.00034683363239769644 average time 0.14095177439000736 iter num 100\n",
            "loss 0.00036604427252001414 average time 0.14330574350003644 iter num 20\n",
            "loss 0.00033927670161550377 average time 0.142186604300025 iter num 40\n",
            "loss 0.0003383359849715168 average time 0.1423926557500143 iter num 60\n",
            "loss 0.0003375572772301292 average time 0.1420273983625094 iter num 80\n",
            "loss 0.0003374764633905019 average time 0.14172020734000626 iter num 100\n",
            "loss 0.0003357584408978844 average time 0.14119493344996953 iter num 20\n",
            "loss 0.0003341743544120256 average time 0.1409454663249619 iter num 40\n",
            "loss 0.0003331327118547805 average time 0.14101130229997427 iter num 60\n",
            "loss 0.0003326585470103086 average time 0.1408008389374885 iter num 80\n",
            "loss 0.0003325582087831178 average time 0.14066202965998856 iter num 100\n",
            "loss 0.00033065197035248896 average time 0.14144250340004874 iter num 20\n",
            "loss 0.00032895282162139514 average time 0.1423444235750253 iter num 40\n",
            "loss 0.0003278292708362008 average time 0.14227124608334332 iter num 60\n",
            "loss 0.0003273167590156246 average time 0.14251641689999986 iter num 80\n",
            "loss 0.0003272085836677952 average time 0.1430026097399923 iter num 100\n",
            "loss 0.0003251673613946472 average time 0.1395462580499725 iter num 20\n",
            "loss 0.0003233669552075095 average time 0.14024002624998957 iter num 40\n",
            "loss 0.0003221818841163921 average time 0.14060835448332984 iter num 60\n",
            "loss 0.00032164147494948095 average time 0.14064769327500243 iter num 80\n",
            "loss 0.00032152803521327366 average time 0.14036506890000283 iter num 100\n",
            "loss 0.0003193805179612452 average time 0.14093264864998217 iter num 20\n",
            "loss 0.00031748878291797074 average time 0.14108061972500535 iter num 40\n",
            "loss 0.00031624578151781383 average time 0.14061468466667293 iter num 60\n",
            "loss 0.00031568276024986395 average time 0.1417149108625125 iter num 80\n",
            "loss 0.0003155648393810711 average time 0.1426802597500091 iter num 100\n",
            "loss 0.00031333916487699296 average time 0.14109506600004806 iter num 20\n",
            "loss 0.0003113855029673464 average time 0.14114187370002468 iter num 40\n",
            "loss 0.0003101038963050548 average time 0.14075859516668743 iter num 60\n",
            "loss 0.0003095231669534722 average time 0.14091162661252382 iter num 80\n",
            "loss 0.0003094016291231844 average time 0.14112548193002566 iter num 100\n",
            "loss 0.000307106280163181 average time 0.14177717219999977 iter num 20\n",
            "loss 0.00030509784213088905 average time 0.14249199280000086 iter num 40\n",
            "loss 0.0003037816031459348 average time 0.14231839375000088 iter num 60\n",
            "loss 0.00030318610266740284 average time 0.14176874262499553 iter num 80\n",
            "loss 0.00030306091994080183 average time 0.14178783010999496 iter num 100\n",
            "loss 0.00030070321678215845 average time 0.14484227699998656 iter num 20\n",
            "loss 0.00029864404385352285 average time 0.14294257477499742 iter num 40\n",
            "loss 0.0002972933831630416 average time 0.1423985136666526 iter num 60\n",
            "loss 0.0002966824550172574 average time 0.14259599847498236 iter num 80\n",
            "loss 0.00029655427332654774 average time 0.14219889982998893 iter num 100\n",
            "loss 0.0002960866466147105 average time 0.1415513138999927 iter num 20\n",
            "loss 0.0002918029837918614 average time 0.1407240868749909 iter num 40\n",
            "loss 0.00029041273857681823 average time 0.14126425374999296 iter num 60\n",
            "loss 0.0002898646448349381 average time 0.141172748449992 iter num 80\n",
            "loss 0.0002897246985019051 average time 0.1410555804400019 iter num 100\n",
            "loss 0.0002868772742943728 average time 0.14069003340000563 iter num 20\n",
            "loss 0.0002848093311306501 average time 0.14186199657499401 iter num 40\n",
            "loss 0.00028205985205062784 average time 0.14207528966665753 iter num 60\n",
            "loss 0.00028171250765794865 average time 0.14207515764998674 iter num 80\n",
            "loss 0.0002816007772919711 average time 0.14206440876998613 iter num 100\n",
            "loss 0.00027997598227555724 average time 0.1414867354500302 iter num 20\n",
            "loss 0.00027857791158640663 average time 0.14085489597499645 iter num 40\n",
            "loss 0.00027765245005225813 average time 0.14166204691666734 iter num 60\n",
            "loss 0.00027721883648463706 average time 0.14157146326250541 iter num 80\n",
            "loss 0.000277127211698658 average time 0.1412186158800091 iter num 100\n",
            "loss 0.000275400565216755 average time 0.14178829125000902 iter num 20\n",
            "loss 0.0002738646128920581 average time 0.1417837085249971 iter num 40\n",
            "loss 0.00027284752465819433 average time 0.14168814038331826 iter num 60\n",
            "loss 0.0002723844478570636 average time 0.14230696091249512 iter num 80\n",
            "loss 0.00027228734964415224 average time 0.1419161970899995 iter num 100\n",
            "loss 0.00027044204532944806 average time 0.1449947625500272 iter num 20\n",
            "loss 0.0002688030166944024 average time 0.14397514800000977 iter num 40\n",
            "loss 0.0002677279441591485 average time 0.1441593518833353 iter num 60\n",
            "loss 0.00026724129858721467 average time 0.14466136941249771 iter num 80\n",
            "loss 0.00026713858729041735 average time 0.14512828356 iter num 100\n",
            "loss 0.00026520805881862625 average time 0.1431529712000156 iter num 20\n",
            "loss 0.0002635115319542974 average time 0.1432301633500117 iter num 40\n",
            "loss 0.000262398789637188 average time 0.1425168227833448 iter num 60\n",
            "loss 0.0002618933130815959 average time 0.14202917787500838 iter num 80\n",
            "loss 0.0002617878869979038 average time 0.14181051748000528 iter num 100\n",
            "loss 0.0002597882123204867 average time 0.14199026259999528 iter num 20\n",
            "loss 0.00025803619550447107 average time 0.14216293700000052 iter num 40\n",
            "loss 0.00025688943585268825 average time 0.14194064389999614 iter num 60\n",
            "loss 0.0002563693494909721 average time 0.14205876251249663 iter num 80\n",
            "loss 0.0002562608418850464 average time 0.1417705425500003 iter num 100\n",
            "loss 0.00025420542183506343 average time 0.14079303125000706 iter num 20\n",
            "loss 0.0002524064597139158 average time 0.14182699605000834 iter num 40\n",
            "loss 0.0002512323524527409 average time 0.14164823783333227 iter num 60\n",
            "loss 0.0002507007348799397 average time 0.14180062040000507 iter num 80\n",
            "loss 0.00025058978647902514 average time 0.14186759359001372 iter num 100\n",
            "loss 0.0002484783849115469 average time 0.1409914354499847 iter num 20\n",
            "loss 0.0002466467711106065 average time 0.14248726390000002 iter num 40\n",
            "loss 0.0002454371687504779 average time 0.14270303353334082 iter num 60\n",
            "loss 0.0002448901879272592 average time 0.1425868601500099 iter num 80\n",
            "loss 0.0002447755852884404 average time 0.14232001339000816 iter num 100\n",
            "loss 0.00026341001146515164 average time 0.14301410395000858 iter num 20\n",
            "loss 0.0002398657593780894 average time 0.14221811085000696 iter num 40\n",
            "loss 0.00023859606749527772 average time 0.14237600080000068 iter num 60\n",
            "loss 0.00023801552943049245 average time 0.14218451453749878 iter num 80\n",
            "loss 0.00023794056995263475 average time 0.14207194887999777 iter num 100\n",
            "loss 0.00023641329651798054 average time 0.14186118259998465 iter num 20\n",
            "loss 0.00023507405004630596 average time 0.14210633710000592 iter num 40\n",
            "loss 0.0002341950299502869 average time 0.14251831638332912 iter num 60\n",
            "loss 0.00023378924037635522 average time 0.14305655122501265 iter num 80\n",
            "loss 0.00023370383512996096 average time 0.14319568137000716 iter num 100\n",
            "loss 0.0002320753046408245 average time 0.14756259799997906 iter num 20\n",
            "loss 0.00023062879403383077 average time 0.14699452592499823 iter num 40\n",
            "loss 0.00022967513383027595 average time 0.1466602348999989 iter num 60\n",
            "loss 0.0002292413090139185 average time 0.1461557832750003 iter num 80\n",
            "loss 0.00022915075745002226 average time 0.14568042317000163 iter num 100\n",
            "loss 0.00022742398385558165 average time 0.14523272844999155 iter num 20\n",
            "loss 0.00022590440256935906 average time 0.14565309762500078 iter num 40\n",
            "loss 0.0002249072273810751 average time 0.1456338179333367 iter num 60\n",
            "loss 0.0002244571956273076 average time 0.14507126071250126 iter num 80\n",
            "loss 0.00022436332153777302 average time 0.14477438887000063 iter num 100\n",
            "loss 0.00022258870110674408 average time 0.1414591455999698 iter num 20\n",
            "loss 0.00022103237709799806 average time 0.14163082064999913 iter num 40\n",
            "loss 0.00022000946254999864 average time 0.14178872386666702 iter num 60\n",
            "loss 0.0002195481042765269 average time 0.14174249434999808 iter num 80\n",
            "loss 0.0002194516315311774 average time 0.1421999069599974 iter num 100\n",
            "loss 0.0002176764653720154 average time 0.14163580064996495 iter num 20\n",
            "loss 0.00021604217497313868 average time 0.14090783904998147 iter num 40\n",
            "loss 0.00021500562489078698 average time 0.14081865128330642 iter num 60\n",
            "loss 0.0002145355379891618 average time 0.14131397376248458 iter num 80\n",
            "loss 0.00021443800317957524 average time 0.14215547415999027 iter num 100\n",
            "loss 0.00021564454720416213 average time 0.14545546319999403 iter num 20\n",
            "loss 0.00021082387429248212 average time 0.1452213620249722 iter num 40\n",
            "loss 0.0002098006996684914 average time 0.14430890271663657 iter num 60\n",
            "loss 0.00020926298274022445 average time 0.14394328059998146 iter num 80\n",
            "loss 0.00020918049275495736 average time 0.14388457154998605 iter num 100\n",
            "loss 0.0002077794384897151 average time 0.14137810659999558 iter num 20\n",
            "loss 0.00020590972462478143 average time 0.1416293112000176 iter num 40\n",
            "loss 0.0002044038114899382 average time 0.1419898725500199 iter num 60\n",
            "loss 0.00020412355883602944 average time 0.14166634970002007 iter num 80\n",
            "loss 0.00020406926375633614 average time 0.1417900511000198 iter num 100\n",
            "loss 0.0002028933829127916 average time 0.14292954004999955 iter num 20\n",
            "loss 0.00020186042314629981 average time 0.1431766380249769 iter num 40\n",
            "loss 0.0002011487388606739 average time 0.14355464423330583 iter num 60\n",
            "loss 0.00020082286595335356 average time 0.14399841672498326 iter num 80\n",
            "loss 0.00020075447521695198 average time 0.1436883727899908 iter num 100\n",
            "loss 0.00019944658099850274 average time 0.14155377429997315 iter num 20\n",
            "loss 0.00019828412918442592 average time 0.14115412892498397 iter num 40\n",
            "loss 0.0001975136934165757 average time 0.14128896623333276 iter num 60\n",
            "loss 0.00019716261135508458 average time 0.14120387406250642 iter num 80\n",
            "loss 0.00019708835267832426 average time 0.14158192933000463 iter num 100\n",
            "loss 0.00019569095632596665 average time 0.14387715119999028 iter num 20\n",
            "loss 0.00019446868120240996 average time 0.14346044114998335 iter num 40\n",
            "loss 0.0001936687538996902 average time 0.14319672333331634 iter num 60\n",
            "loss 0.00019330618516872383 average time 0.14365095404998557 iter num 80\n",
            "loss 0.00019323071377863366 average time 0.14441416098998616 iter num 100\n",
            "loss 0.00019180015726657284 average time 0.14468124764999857 iter num 20\n",
            "loss 0.0001905486468734546 average time 0.14452098735000618 iter num 40\n",
            "loss 0.00018973284685198854 average time 0.14432724983333856 iter num 60\n",
            "loss 0.00018936492924266683 average time 0.1442079690999975 iter num 80\n",
            "loss 0.0001892878424724515 average time 0.1441176234699992 iter num 100\n",
            "loss 0.0001878301338293441 average time 0.14143144405004476 iter num 20\n",
            "loss 0.00018656656382206417 average time 0.14145838007501652 iter num 40\n",
            "loss 0.00018573923852574463 average time 0.14224824331667682 iter num 60\n",
            "loss 0.00018536708625661164 average time 0.14243063028750386 iter num 80\n",
            "loss 0.00018528874785639937 average time 0.1426957596900047 iter num 100\n",
            "loss 0.00019657752103737817 average time 0.1445989551000025 iter num 20\n",
            "loss 0.00018257300889552486 average time 0.14487999187499553 iter num 40\n",
            "loss 0.0001812397627757036 average time 0.14478150906666087 iter num 60\n",
            "loss 0.0001809517570967558 average time 0.14456926413749613 iter num 80\n",
            "loss 0.0001809174406218157 average time 0.14395001838999177 iter num 100\n",
            "loss 0.00017999579798517283 average time 0.1416700486000309 iter num 20\n",
            "loss 0.00017906688506363699 average time 0.14280699312500927 iter num 40\n",
            "loss 0.00017849275569988061 average time 0.14345802934999863 iter num 60\n",
            "loss 0.00017821873952167248 average time 0.1432352071624962 iter num 80\n",
            "loss 0.00017816162034037258 average time 0.14298498491999453 iter num 100\n",
            "loss 0.00017706826003555906 average time 0.1441983985500201 iter num 20\n",
            "loss 0.0001760936259828722 average time 0.14379549710000675 iter num 40\n",
            "loss 0.0001754442848162812 average time 0.14415485355001087 iter num 60\n",
            "loss 0.00017514857562585866 average time 0.14369425605000288 iter num 80\n",
            "loss 0.0001750868920408482 average time 0.1436382655899979 iter num 100\n",
            "loss 0.00017391548431298063 average time 0.14207544084999882 iter num 20\n",
            "loss 0.00017288492081719479 average time 0.14137263205001888 iter num 40\n",
            "loss 0.00017221275743674913 average time 0.14209180645001046 iter num 60\n",
            "loss 0.00017190906245023428 average time 0.1425017660500032 iter num 80\n",
            "loss 0.00017184572424815817 average time 0.1424620872200103 iter num 100\n",
            "loss 0.00017064887258882351 average time 0.14854533125001126 iter num 20\n",
            "loss 0.00016960408163986342 average time 0.14913243090002198 iter num 40\n",
            "loss 0.00016892326563144948 average time 0.14882173660001097 iter num 60\n",
            "loss 0.0001686171813169704 average time 0.14927304114999346 iter num 80\n",
            "loss 0.0001685531071518034 average time 0.14916890290999846 iter num 100\n",
            "loss 0.0001674361241590347 average time 0.1432296392499552 iter num 20\n",
            "loss 0.0001662779581634263 average time 0.14326564374997589 iter num 40\n",
            "loss 0.00016562025727738402 average time 0.14271954569998116 iter num 60\n",
            "loss 0.00016530392362366176 average time 0.14283289749998004 iter num 80\n",
            "loss 0.0001652423633316133 average time 0.1428205182799843 iter num 100\n",
            "loss 0.00018110579532345448 average time 0.1414964307999867 iter num 20\n",
            "loss 0.00016580296856515863 average time 0.14398096472498878 iter num 40\n",
            "loss 0.00016236005293060005 average time 0.14376841098334125 iter num 60\n",
            "loss 0.0001621580284793076 average time 0.14337764117500457 iter num 80\n",
            "loss 0.00016211301768767608 average time 0.14335743088000755 iter num 100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 10000\n",
              "\tepoch: 100\n",
              "\tepoch_length: 100\n",
              "\tmax_epochs: 100\n",
              "\toutput: 0.00016211301768767608\n",
              "\tbatch: <class 'tuple'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: <class 'cupy_dataset.OptionDataSet'>\n",
              "\tseed: <class 'NoneType'>\n",
              "\ttimes: <class 'dict'>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_fEzULvKwR-"
      },
      "source": [
        "# 24 min\n",
        "# 1:56"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "339d9fd7-dbe8-4a6a-88f9-7ea1b43f1bdb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_BS_oneDS_B_2.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Judy/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f32d1c7-403f-48b9-9a0c-22997231c429"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2587bd1-cd1e-4eef-c8ac-f1d74f401495"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_BS_oneDS_B_4.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Judy/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce540da0-e8ca-44e0-db1a-1221eed7d1e2"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=6, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc5): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc6): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16f82621-1454-442b-9bd4-ea9a715cd603"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 100000, batch = 1, seed = np.random.randint(10000), stocks = 1) # must have random seed. It doesn't matter how many batch here (not taken into function). Use max_len to adjust\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x.float())\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x.float()\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)\n",
        "\n",
        "model_save_name = 'jax_european_1stock_BS_oneDS_B_5.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Judy/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 5.435535113619418e-05 average time 0.1419892256503772 iter num 20\n",
            "loss 4.099025823275669e-05 average time 0.14231175755007824 iter num 40\n",
            "loss 3.902043300293578e-05 average time 0.14227442241666116 iter num 60\n",
            "loss 3.876869905255983e-05 average time 0.14208765872501772 iter num 80\n",
            "loss 3.873391049869462e-05 average time 0.14201787957996204 iter num 100\n",
            "loss 3.8784495010045615e-05 average time 0.13958369980009594 iter num 20\n",
            "loss 3.877928823083008e-05 average time 0.14042099957496249 iter num 40\n",
            "loss 3.8743590034331355e-05 average time 0.14089129898332733 iter num 60\n",
            "loss 3.873535456645141e-05 average time 0.1414306787000214 iter num 80\n",
            "loss 3.873300102271983e-05 average time 0.14130365539995182 iter num 100\n",
            "loss 3.8692869595892387e-05 average time 0.14133790214982583 iter num 20\n",
            "loss 3.866097128315035e-05 average time 0.14351824614996075 iter num 40\n",
            "loss 3.86399370463758e-05 average time 0.1449485299332082 iter num 60\n",
            "loss 3.862986344666455e-05 average time 0.14499816276234015 iter num 80\n",
            "loss 3.862819744033403e-05 average time 0.14505494632987392 iter num 100\n",
            "loss 3.8587175023866475e-05 average time 0.14374076369995237 iter num 20\n",
            "loss 3.855135502344825e-05 average time 0.14309832889980498 iter num 40\n",
            "loss 3.852752965264372e-05 average time 0.14257033753319776 iter num 60\n",
            "loss 3.851703066659831e-05 average time 0.1423803096748543 iter num 80\n",
            "loss 3.851519174135221e-05 average time 0.14249402865987576 iter num 100\n",
            "loss 3.8471759350650696e-05 average time 0.14097677454974472 iter num 20\n",
            "loss 3.843422718796536e-05 average time 0.14305103799974858 iter num 40\n",
            "loss 3.8410130996264305e-05 average time 0.14291511643323246 iter num 60\n",
            "loss 3.839947258583936e-05 average time 0.14289569311245032 iter num 80\n",
            "loss 3.8397465465582946e-05 average time 0.14255488002996572 iter num 100\n",
            "loss 3.835360995575237e-05 average time 0.14207948814982957 iter num 20\n",
            "loss 3.831586148696628e-05 average time 0.14225043512478805 iter num 40\n",
            "loss 3.829152322712751e-05 average time 0.14173857558319772 iter num 60\n",
            "loss 3.828051872079555e-05 average time 0.141664667412374 iter num 80\n",
            "loss 3.827847115221973e-05 average time 0.1416273736698349 iter num 100\n",
            "loss 3.823493062917004e-05 average time 0.14236398769990047 iter num 20\n",
            "loss 3.8197060587035545e-05 average time 0.14106151169980877 iter num 40\n",
            "loss 3.817254183343304e-05 average time 0.14096537051652072 iter num 60\n",
            "loss 3.8161643926604816e-05 average time 0.14217717291237478 iter num 80\n",
            "loss 3.81596760118603e-05 average time 0.142093456139919 iter num 100\n",
            "loss 3.8115780788911515e-05 average time 0.1401566755001113 iter num 20\n",
            "loss 3.807745539887768e-05 average time 0.14065314572499119 iter num 40\n",
            "loss 3.805255774219485e-05 average time 0.14090033290000673 iter num 60\n",
            "loss 3.8041481769001826e-05 average time 0.14066176483752316 iter num 80\n",
            "loss 3.803936089571425e-05 average time 0.14080959206001353 iter num 100\n",
            "loss 3.799494067537809e-05 average time 0.14188716295002451 iter num 20\n",
            "loss 3.795598746250052e-05 average time 0.1417805370500446 iter num 40\n",
            "loss 3.793078236471967e-05 average time 0.14176835301677784 iter num 60\n",
            "loss 3.7919613973520876e-05 average time 0.14188047983759589 iter num 80\n",
            "loss 3.791753392262074e-05 average time 0.1426995531400462 iter num 100\n",
            "loss 3.787240428127342e-05 average time 0.141623794899715 iter num 20\n",
            "loss 3.7832911493985954e-05 average time 0.14112330079979074 iter num 40\n",
            "loss 3.780742133273476e-05 average time 0.14067974181646908 iter num 60\n",
            "loss 3.779596504241944e-05 average time 0.14114965198732535 iter num 80\n",
            "loss 3.7793735000790586e-05 average time 0.14102028833987787 iter num 100\n",
            "loss 3.7747894215485306e-05 average time 0.1412134808500923 iter num 20\n",
            "loss 3.770810779009724e-05 average time 0.14120985917506915 iter num 40\n",
            "loss 3.7682045342798305e-05 average time 0.14053241541669195 iter num 60\n",
            "loss 3.767056440119954e-05 average time 0.1402131438125025 iter num 80\n",
            "loss 3.7668242593732665e-05 average time 0.14070705297996028 iter num 100\n",
            "loss 3.7621821787096086e-05 average time 0.1476394968997738 iter num 20\n",
            "loss 3.758127616036935e-05 average time 0.14598149534999721 iter num 40\n",
            "loss 3.7554958430768235e-05 average time 0.1444051283833384 iter num 60\n",
            "loss 3.75431268975183e-05 average time 0.14328077251254853 iter num 80\n",
            "loss 3.754077147067676e-05 average time 0.14296810725005343 iter num 100\n",
            "loss 3.7493612770912294e-05 average time 0.1414281054003368 iter num 20\n",
            "loss 3.7452762053726715e-05 average time 0.14176372162528422 iter num 40\n",
            "loss 3.74259651101818e-05 average time 0.141875352283508 iter num 60\n",
            "loss 3.741401385537698e-05 average time 0.14180034587516274 iter num 80\n",
            "loss 3.741169620281301e-05 average time 0.14164234112007762 iter num 100\n",
            "loss 3.73637806793048e-05 average time 0.14078898100015066 iter num 20\n",
            "loss 3.7321921952157e-05 average time 0.1412905390251126 iter num 40\n",
            "loss 3.729467152503339e-05 average time 0.14180103643338954 iter num 60\n",
            "loss 3.72826137460337e-05 average time 0.1417296403125647 iter num 80\n",
            "loss 3.7280246918012955e-05 average time 0.14168214607014307 iter num 100\n",
            "loss 3.723190868972946e-05 average time 0.1418159949497749 iter num 20\n",
            "loss 3.718969226966671e-05 average time 0.1420120898249934 iter num 40\n",
            "loss 3.7161630770540114e-05 average time 0.1419590892499097 iter num 60\n",
            "loss 3.7149194473782014e-05 average time 0.14179887258742382 iter num 80\n",
            "loss 3.714660034039521e-05 average time 0.14165331462989342 iter num 100\n",
            "loss 3.7098533470063313e-05 average time 0.14417855335013882 iter num 20\n",
            "loss 3.7052364358436885e-05 average time 0.14273360205020252 iter num 40\n",
            "loss 3.7024133974867885e-05 average time 0.14264561925007607 iter num 60\n",
            "loss 3.7010926476758206e-05 average time 0.14237213130006693 iter num 80\n",
            "loss 3.700838103192707e-05 average time 0.14260261825005727 iter num 100\n",
            "loss 4.6960866711354586e-05 average time 0.14240750865001245 iter num 20\n",
            "loss 3.763662140699498e-05 average time 0.1424301836750601 iter num 40\n",
            "loss 3.74496179121926e-05 average time 0.14228088610000972 iter num 60\n",
            "loss 3.7424670300533035e-05 average time 0.14138557924998169 iter num 80\n",
            "loss 3.7422259147564175e-05 average time 0.14126589686004082 iter num 100\n",
            "loss 3.731765057043186e-05 average time 0.1412258137000208 iter num 20\n",
            "loss 3.724065365625665e-05 average time 0.14132260454998685 iter num 40\n",
            "loss 3.719302875137899e-05 average time 0.14106260404996646 iter num 60\n",
            "loss 3.717236211080988e-05 average time 0.14162391511245004 iter num 80\n",
            "loss 3.7167702596350604e-05 average time 0.141497925009935 iter num 100\n",
            "loss 3.709434646957697e-05 average time 0.14221915409998473 iter num 20\n",
            "loss 3.702194248555302e-05 average time 0.14410359634989617 iter num 40\n",
            "loss 3.698351587369706e-05 average time 0.1428330517166311 iter num 60\n",
            "loss 3.6964859900002725e-05 average time 0.14245981442500125 iter num 80\n",
            "loss 3.696123894484732e-05 average time 0.14206408419004218 iter num 100\n",
            "loss 4.157860274996794e-05 average time 0.14022617030004766 iter num 20\n",
            "loss 3.736852599909945e-05 average time 0.14152350175008904 iter num 40\n",
            "loss 3.7254270791558576e-05 average time 0.1412202332167908 iter num 60\n",
            "loss 3.722395673173816e-05 average time 0.14079382621257536 iter num 80\n",
            "loss 3.722278718991674e-05 average time 0.1411257887200918 iter num 100\n",
            "loss 3.710975895959163e-05 average time 0.1416307921501357 iter num 20\n",
            "loss 3.701971589895124e-05 average time 0.14201220097515943 iter num 40\n",
            "loss 3.696700645251093e-05 average time 0.14243087066676405 iter num 60\n",
            "loss 3.69443820707176e-05 average time 0.14299023618757473 iter num 80\n",
            "loss 3.6940021372447834e-05 average time 0.14276429028001075 iter num 100\n",
            "loss 3.7043263614541956e-05 average time 0.14221459810014495 iter num 20\n",
            "loss 3.682051921008353e-05 average time 0.14126560265008264 iter num 40\n",
            "loss 3.6760077703111375e-05 average time 0.14095046268342534 iter num 60\n",
            "loss 3.674434421267714e-05 average time 0.14074403251254353 iter num 80\n",
            "loss 3.673925624276358e-05 average time 0.1404843833300765 iter num 100\n",
            "loss 3.767173191274604e-05 average time 0.13957709219994285 iter num 20\n",
            "loss 3.904823990170593e-05 average time 0.1399997476250519 iter num 40\n",
            "loss 3.903575146000148e-05 average time 0.1408165999500549 iter num 60\n",
            "loss 3.880117266235214e-05 average time 0.14047011596255743 iter num 80\n",
            "loss 3.878201753820405e-05 average time 0.14115195087008034 iter num 100\n",
            "loss 3.840830619718052e-05 average time 0.13925144149989138 iter num 20\n",
            "loss 3.816219750002262e-05 average time 0.14040105189988025 iter num 40\n",
            "loss 3.803547784900207e-05 average time 0.14210580514991306 iter num 60\n",
            "loss 3.798323028061322e-05 average time 0.14195873243736515 iter num 80\n",
            "loss 3.797327774647408e-05 average time 0.14201813876989036 iter num 100\n",
            "loss 3.778719429786103e-05 average time 0.14289130735005529 iter num 20\n",
            "loss 3.764339596245696e-05 average time 0.14274999524996018 iter num 40\n",
            "loss 3.75590655188059e-05 average time 0.14310483585001446 iter num 60\n",
            "loss 3.752314777779121e-05 average time 0.14402275178752005 iter num 80\n",
            "loss 3.751605982846998e-05 average time 0.14400465821006947 iter num 100\n",
            "loss 3.7381529245789826e-05 average time 0.142254476099788 iter num 20\n",
            "loss 3.7271145782410926e-05 average time 0.1433365194248836 iter num 40\n",
            "loss 3.7202944621426755e-05 average time 0.14254643109989046 iter num 60\n",
            "loss 3.71735791233544e-05 average time 0.1428135702123882 iter num 80\n",
            "loss 3.7167595239910135e-05 average time 0.14252623455984575 iter num 100\n",
            "loss 3.7055380956968916e-05 average time 0.13971365730003527 iter num 20\n",
            "loss 3.696224184868556e-05 average time 0.14087574680002035 iter num 40\n",
            "loss 3.6904201185578645e-05 average time 0.14073198154992497 iter num 60\n",
            "loss 3.6878818143913845e-05 average time 0.1409652097999924 iter num 80\n",
            "loss 3.687391765896863e-05 average time 0.14090126387001875 iter num 100\n",
            "loss 3.677688518241559e-05 average time 0.14103118364982947 iter num 20\n",
            "loss 3.669560784762474e-05 average time 0.1410592206000274 iter num 40\n",
            "loss 3.6644418957062595e-05 average time 0.14183310166672528 iter num 60\n",
            "loss 3.6622144871502824e-05 average time 0.1421954223000057 iter num 80\n",
            "loss 3.6617634058536664e-05 average time 0.14192823693998435 iter num 100\n",
            "loss 3.6530915454802985e-05 average time 0.13963079499999367 iter num 20\n",
            "loss 3.645796071745724e-05 average time 0.13915547772489845 iter num 40\n",
            "loss 3.64123722311624e-05 average time 0.13920933509998576 iter num 60\n",
            "loss 3.639238642843888e-05 average time 0.13945407921246442 iter num 80\n",
            "loss 3.638849503484927e-05 average time 0.13952640506993702 iter num 100\n",
            "loss 3.631170971756653e-05 average time 0.14326062874970374 iter num 20\n",
            "loss 3.6246677282697446e-05 average time 0.14139049599984901 iter num 40\n",
            "loss 3.620551121034857e-05 average time 0.14094829353331687 iter num 60\n",
            "loss 3.618733668795913e-05 average time 0.14070827009991263 iter num 80\n",
            "loss 3.6183718247034164e-05 average time 0.14109022398992238 iter num 100\n",
            "loss 3.660986358605174e-05 average time 0.1400043637499948 iter num 20\n",
            "loss 3.6106812427745896e-05 average time 0.14031098777491025 iter num 40\n",
            "loss 3.605097406365685e-05 average time 0.14003581696667122 iter num 60\n",
            "loss 3.603386980340811e-05 average time 0.14017743071246969 iter num 80\n",
            "loss 3.6030715488288624e-05 average time 0.14033136106998426 iter num 100\n",
            "loss 4.9546985140398175e-05 average time 0.14025227665015336 iter num 20\n",
            "loss 4.0286421702035976e-05 average time 0.1401590631000545 iter num 40\n",
            "loss 3.9272210877474946e-05 average time 0.14037871846673322 iter num 60\n",
            "loss 3.890797470236399e-05 average time 0.1398787966000782 iter num 80\n",
            "loss 3.8873396080801355e-05 average time 0.13994673797005816 iter num 100\n",
            "loss 3.840693705795504e-05 average time 0.14227228969975841 iter num 20\n",
            "loss 3.807735001309119e-05 average time 0.14521668474981198 iter num 40\n",
            "loss 3.7918340276611425e-05 average time 0.1435945580165632 iter num 60\n",
            "loss 3.785688059810417e-05 average time 0.14270235337482973 iter num 80\n",
            "loss 3.7844511572050664e-05 average time 0.14229980252988753 iter num 100\n",
            "loss 3.762483336170557e-05 average time 0.1401817186997505 iter num 20\n",
            "loss 3.7455415711166337e-05 average time 0.1409608586749073 iter num 40\n",
            "loss 3.7356681828496494e-05 average time 0.14111224359994595 iter num 60\n",
            "loss 3.7314971603787736e-05 average time 0.1412954603498747 iter num 80\n",
            "loss 3.7306729389629835e-05 average time 0.14105775719988742 iter num 100\n",
            "loss 3.71513860606771e-05 average time 0.1402549803500733 iter num 20\n",
            "loss 3.702383122307468e-05 average time 0.1396661590999429 iter num 40\n",
            "loss 3.694581470557262e-05 average time 0.13999881594988134 iter num 60\n",
            "loss 3.691269069636611e-05 average time 0.1405718025999704 iter num 80\n",
            "loss 3.690605007158578e-05 average time 0.14010949281999274 iter num 100\n",
            "loss 3.678059518303559e-05 average time 0.14010946695016174 iter num 20\n",
            "loss 3.667682386782034e-05 average time 0.13908015840006555 iter num 40\n",
            "loss 3.661292965858905e-05 average time 0.13908211793344283 iter num 60\n",
            "loss 3.658518252420846e-05 average time 0.13938400268764325 iter num 80\n",
            "loss 3.657957903194815e-05 average time 0.1393418831000781 iter num 100\n",
            "loss 3.647335961822545e-05 average time 0.13857305864994487 iter num 20\n",
            "loss 3.638496867114921e-05 average time 0.1397469158248441 iter num 40\n",
            "loss 3.632975114627244e-05 average time 0.13981592398328455 iter num 60\n",
            "loss 3.630562560792294e-05 average time 0.13988386338739928 iter num 80\n",
            "loss 3.630098620206661e-05 average time 0.14048420341992823 iter num 100\n",
            "loss 3.6208521936844435e-05 average time 0.14129596095017405 iter num 20\n",
            "loss 3.613093557285179e-05 average time 0.14124683972499952 iter num 40\n",
            "loss 3.60822701728506e-05 average time 0.1403872979166408 iter num 60\n",
            "loss 3.606073226727015e-05 average time 0.1400404280125258 iter num 80\n",
            "loss 3.605650992418625e-05 average time 0.13996957546996783 iter num 100\n",
            "loss 3.5973682012551654e-05 average time 0.14062647460004882 iter num 20\n",
            "loss 3.590376331189464e-05 average time 0.14053665242499846 iter num 40\n",
            "loss 3.585951151511663e-05 average time 0.14042759848331723 iter num 60\n",
            "loss 3.58399920223263e-05 average time 0.14016819979997308 iter num 80\n",
            "loss 3.58361456106884e-05 average time 0.13987389676996828 iter num 100\n",
            "loss 3.576082237911344e-05 average time 0.1387190547497994 iter num 20\n",
            "loss 3.569650269055965e-05 average time 0.1407308257749719 iter num 40\n",
            "loss 3.565566283543128e-05 average time 0.14029878574992835 iter num 60\n",
            "loss 3.563763453128143e-05 average time 0.1402769548749802 iter num 80\n",
            "loss 3.563409087089403e-05 average time 0.14019922729998144 iter num 100\n",
            "loss 3.567381166535172e-05 average time 0.13862618880011723 iter num 20\n",
            "loss 3.5508716580488875e-05 average time 0.1384993860000577 iter num 40\n",
            "loss 3.5472685785783726e-05 average time 0.1394318551334436 iter num 60\n",
            "loss 3.545452930684713e-05 average time 0.1393412910250163 iter num 80\n",
            "loss 3.54512496315127e-05 average time 0.13962444464001236 iter num 100\n",
            "loss 4.995121312624493e-05 average time 0.14078101595005138 iter num 20\n",
            "loss 3.8849753545693624e-05 average time 0.1403024507000282 iter num 40\n",
            "loss 3.80020593845001e-05 average time 0.1399703704000179 iter num 60\n",
            "loss 3.779450168673114e-05 average time 0.14067642383747625 iter num 80\n",
            "loss 3.77778212195745e-05 average time 0.14085078082996916 iter num 100\n",
            "loss 3.733472636305968e-05 average time 0.14061156340021624 iter num 20\n",
            "loss 3.706442779314669e-05 average time 0.14008816017512798 iter num 40\n",
            "loss 3.692472934823555e-05 average time 0.1398023523834733 iter num 60\n",
            "loss 3.6870052939276367e-05 average time 0.13967360047506644 iter num 80\n",
            "loss 3.6859266391659356e-05 average time 0.14013446233997456 iter num 100\n",
            "loss 3.6663958666641606e-05 average time 0.14130245329997707 iter num 20\n",
            "loss 3.6515031530101574e-05 average time 0.1401612050750373 iter num 40\n",
            "loss 3.64270188839144e-05 average time 0.13983477541669345 iter num 60\n",
            "loss 3.6389714021131195e-05 average time 0.1396756111374998 iter num 80\n",
            "loss 3.6382209766075276e-05 average time 0.1398282365600062 iter num 100\n",
            "loss 3.624245278827022e-05 average time 0.14183319595013016 iter num 20\n",
            "loss 3.6127454288878144e-05 average time 0.14059337935000257 iter num 40\n",
            "loss 3.605683965020536e-05 average time 0.14027159685013732 iter num 60\n",
            "loss 3.6026549268464266e-05 average time 0.14013380875016992 iter num 80\n",
            "loss 3.6020506747613134e-05 average time 0.1407951593301732 iter num 100\n",
            "loss 3.590550035603644e-05 average time 0.1404397893497844 iter num 20\n",
            "loss 3.581030277819395e-05 average time 0.14044964212503147 iter num 40\n",
            "loss 3.575126049419253e-05 average time 0.1403216966167747 iter num 60\n",
            "loss 3.572563083314541e-05 average time 0.13998288638752002 iter num 80\n",
            "loss 3.572065232449348e-05 average time 0.13997643401997265 iter num 100\n",
            "loss 3.562259995679211e-05 average time 0.1406762402001732 iter num 20\n",
            "loss 3.554077222044254e-05 average time 0.1437810789501782 iter num 40\n",
            "loss 3.548894252481316e-05 average time 0.14387351993345873 iter num 60\n",
            "loss 3.546631076168434e-05 average time 0.14398489131256156 iter num 80\n",
            "loss 3.546196748877006e-05 average time 0.14337302729003568 iter num 100\n",
            "loss 3.537499786473209e-05 average time 0.14151794365006937 iter num 20\n",
            "loss 3.5302012799293514e-05 average time 0.14014610744998207 iter num 40\n",
            "loss 3.525628828105935e-05 average time 0.14025499941665961 iter num 60\n",
            "loss 3.523598519088493e-05 average time 0.13999042564998945 iter num 80\n",
            "loss 3.523206985618967e-05 average time 0.14065058692000093 iter num 100\n",
            "loss 3.5154174007709415e-05 average time 0.13842655889984598 iter num 20\n",
            "loss 3.508797804637964e-05 average time 0.13866830979986844 iter num 40\n",
            "loss 3.504634890389673e-05 average time 0.13925066003327327 iter num 60\n",
            "loss 3.5027769654811165e-05 average time 0.13997549326250008 iter num 80\n",
            "loss 3.502425356640182e-05 average time 0.14034135456004151 iter num 100\n",
            "loss 3.5061797665354316e-05 average time 0.1423548959000982 iter num 20\n",
            "loss 3.489905855690856e-05 average time 0.14101613562506826 iter num 40\n",
            "loss 3.486079906914096e-05 average time 0.14021902563332939 iter num 60\n",
            "loss 3.4843104225918205e-05 average time 0.14024464553740473 iter num 80\n",
            "loss 3.4839638407838065e-05 average time 0.14018746508987534 iter num 100\n",
            "loss 5.0858015748152335e-05 average time 0.14051906099975894 iter num 20\n",
            "loss 3.781876784453589e-05 average time 0.13959558017500057 iter num 40\n",
            "loss 3.75175144222417e-05 average time 0.13989887091662848 iter num 60\n",
            "loss 3.7157971063620495e-05 average time 0.13984118706243862 iter num 80\n",
            "loss 3.715354810022672e-05 average time 0.1396986502899199 iter num 100\n",
            "loss 3.677277982972413e-05 average time 0.14345974114994534 iter num 20\n",
            "loss 3.650807616263845e-05 average time 0.1412441417001446 iter num 40\n",
            "loss 3.6379667350216495e-05 average time 0.14078154225010925 iter num 60\n",
            "loss 3.632605851586442e-05 average time 0.14054684217514932 iter num 80\n",
            "loss 3.631584334957135e-05 average time 0.14046270939017633 iter num 100\n",
            "loss 3.6129915445589694e-05 average time 0.13901324605003537 iter num 20\n",
            "loss 3.598758794485945e-05 average time 0.13908568840001861 iter num 40\n",
            "loss 3.590427822653796e-05 average time 0.13911881603341195 iter num 60\n",
            "loss 3.5868901907437964e-05 average time 0.139364108812606 iter num 80\n",
            "loss 3.586205320207685e-05 average time 0.13941978406006456 iter num 100\n",
            "loss 3.572897845295582e-05 average time 0.13904397979977148 iter num 20\n",
            "loss 3.5619485977460706e-05 average time 0.13971082979992389 iter num 40\n",
            "loss 3.55519002285921e-05 average time 0.1411273911166063 iter num 60\n",
            "loss 3.552257126196026e-05 average time 0.14214563849998285 iter num 80\n",
            "loss 3.551693343047177e-05 average time 0.1416260434299693 iter num 100\n",
            "loss 3.540624610698533e-05 average time 0.13939390949981317 iter num 20\n",
            "loss 3.5314335640922825e-05 average time 0.1396723459248733 iter num 40\n",
            "loss 3.525716398124235e-05 average time 0.13955102739979944 iter num 60\n",
            "loss 3.523243125521994e-05 average time 0.13971391922489146 iter num 80\n",
            "loss 3.522754327530885e-05 average time 0.1396443900498707 iter num 100\n",
            "loss 3.5132412396317916e-05 average time 0.1398900475998744 iter num 20\n",
            "loss 3.5052831055019116e-05 average time 0.13996667152496228 iter num 40\n",
            "loss 3.500310128572337e-05 average time 0.13987057656665153 iter num 60\n",
            "loss 3.498138660376788e-05 average time 0.1405235005750228 iter num 80\n",
            "loss 3.4977127354564314e-05 average time 0.14140884060003373 iter num 100\n",
            "loss 3.48933439292954e-05 average time 0.1412181814000178 iter num 20\n",
            "loss 3.4823876470683325e-05 average time 0.13968880880011056 iter num 40\n",
            "loss 3.478211444876221e-05 average time 0.13977787355003482 iter num 60\n",
            "loss 3.476402780121135e-05 average time 0.13998416212507436 iter num 80\n",
            "loss 3.4760331588429734e-05 average time 0.13968688562006717 iter num 100\n",
            "loss 3.468949628346674e-05 average time 0.14144445734964392 iter num 20\n",
            "loss 3.4629940229717234e-05 average time 0.14052015862480402 iter num 40\n",
            "loss 3.459202048269438e-05 average time 0.14022256066655245 iter num 60\n",
            "loss 3.4575323857896325e-05 average time 0.14071528618742377 iter num 80\n",
            "loss 3.457208615570519e-05 average time 0.1404131491699627 iter num 100\n",
            "loss 3.462723163799725e-05 average time 0.14264001150058903 iter num 20\n",
            "loss 3.4459646843569745e-05 average time 0.1409958299502705 iter num 40\n",
            "loss 3.442315418978475e-05 average time 0.1410913634335581 iter num 60\n",
            "loss 3.4406768781607035e-05 average time 0.14069368202522128 iter num 80\n",
            "loss 3.440399225678113e-05 average time 0.1404688789901411 iter num 100\n",
            "loss 4.227908179719261e-05 average time 0.14127265275001263 iter num 20\n",
            "loss 3.703865848200181e-05 average time 0.1413276891750229 iter num 40\n",
            "loss 3.6993221862689546e-05 average time 0.14078840798335174 iter num 60\n",
            "loss 3.665830979125279e-05 average time 0.14050857042498138 iter num 80\n",
            "loss 3.664085118658153e-05 average time 0.14035690172999238 iter num 100\n",
            "loss 3.621277021832393e-05 average time 0.1385016375997111 iter num 20\n",
            "loss 3.594296348594922e-05 average time 0.14031348767489363 iter num 40\n",
            "loss 3.580619144280372e-05 average time 0.1412529760498425 iter num 60\n",
            "loss 3.5751137859637114e-05 average time 0.14087262098739756 iter num 80\n",
            "loss 3.5740783838334687e-05 average time 0.1406639776099837 iter num 100\n",
            "loss 3.555226928433859e-05 average time 0.13933081864997804 iter num 20\n",
            "loss 3.54073447968501e-05 average time 0.13925174697510556 iter num 40\n",
            "loss 3.5322183587259454e-05 average time 0.1395750513333951 iter num 60\n",
            "loss 3.528589525371495e-05 average time 0.13961676602498302 iter num 80\n",
            "loss 3.5278803188174495e-05 average time 0.1402306443099951 iter num 100\n",
            "loss 3.514342711814736e-05 average time 0.14047543235019475 iter num 20\n",
            "loss 3.5033605337810376e-05 average time 0.14056333402504606 iter num 40\n",
            "loss 3.496625937615722e-05 average time 0.14024829456663307 iter num 60\n",
            "loss 3.493723610463424e-05 average time 0.13979061683744476 iter num 80\n",
            "loss 3.4931612945029715e-05 average time 0.1402256243199372 iter num 100\n",
            "loss 3.482193903578453e-05 average time 0.14055093654988013 iter num 20\n",
            "loss 3.4736496834669544e-05 average time 0.1412247971999477 iter num 40\n",
            "loss 3.4683347986754483e-05 average time 0.14095374039986078 iter num 60\n",
            "loss 3.4660307866518307e-05 average time 0.14041464697497757 iter num 80\n",
            "loss 3.465576664081161e-05 average time 0.13988524019994655 iter num 100\n",
            "loss 3.4567800989223634e-05 average time 0.13880860800036315 iter num 20\n",
            "loss 3.449413288820572e-05 average time 0.13896725722520387 iter num 40\n",
            "loss 3.4448346646329405e-05 average time 0.13908267910016245 iter num 60\n",
            "loss 3.442817486278486e-05 average time 0.13889117691262526 iter num 80\n",
            "loss 3.4424361451014384e-05 average time 0.138938478050095 iter num 100\n",
            "loss 3.434726274005843e-05 average time 0.14029799174977597 iter num 20\n",
            "loss 3.428275010729221e-05 average time 0.1403375719999076 iter num 40\n",
            "loss 3.424221610005124e-05 average time 0.13986973261653474 iter num 60\n",
            "loss 3.422419015272785e-05 average time 0.13990615511252144 iter num 80\n",
            "loss 3.4220683337242e-05 average time 0.13986263101996882 iter num 100\n",
            "loss 3.415193346632487e-05 average time 0.14151456624986167 iter num 20\n",
            "loss 3.409294425240934e-05 average time 0.14155806584990388 iter num 40\n",
            "loss 3.405535329930076e-05 average time 0.1409838997165025 iter num 60\n",
            "loss 3.403884582226841e-05 average time 0.14075569298738627 iter num 80\n",
            "loss 3.403558437284694e-05 average time 0.14051588270989668 iter num 100\n",
            "loss 3.417637395569649e-05 average time 0.13968473670011008 iter num 20\n",
            "loss 3.393120077694669e-05 average time 0.13913703595017068 iter num 40\n",
            "loss 3.3896428984197844e-05 average time 0.14047836711688433 iter num 60\n",
            "loss 3.388024500230502e-05 average time 0.14027022551265417 iter num 80\n",
            "loss 3.3877204618421674e-05 average time 0.14041033372010134 iter num 100\n",
            "loss 3.8972231105302164e-05 average time 0.14026388245038107 iter num 20\n",
            "loss 3.7490533660705384e-05 average time 0.14167090335017746 iter num 40\n",
            "loss 3.6230526039535747e-05 average time 0.14219404558355866 iter num 60\n",
            "loss 3.6097975181854e-05 average time 0.1419372497751965 iter num 80\n",
            "loss 3.604821871504171e-05 average time 0.14222999757015714 iter num 100\n",
            "loss 3.562818599195314e-05 average time 0.1410390428000028 iter num 20\n",
            "loss 3.539264912953165e-05 average time 0.1409137125000143 iter num 40\n",
            "loss 3.5265817430159655e-05 average time 0.1405445606833382 iter num 60\n",
            "loss 3.5216672145431e-05 average time 0.14036076486254387 iter num 80\n",
            "loss 3.520670454342857e-05 average time 0.1402984878400457 iter num 100\n",
            "loss 3.503029994177956e-05 average time 0.14055890449981234 iter num 20\n",
            "loss 3.489384671754158e-05 average time 0.14035741217498982 iter num 40\n",
            "loss 3.481324263320808e-05 average time 0.14072814966669586 iter num 60\n",
            "loss 3.477882614502701e-05 average time 0.14031196104997434 iter num 80\n",
            "loss 3.477211190084347e-05 average time 0.14006626373997277 iter num 100\n",
            "loss 3.464936576772403e-05 average time 0.13921481289999066 iter num 20\n",
            "loss 3.4551548886062214e-05 average time 0.13932725322506484 iter num 40\n",
            "loss 3.4491422812946146e-05 average time 0.13958427363349984 iter num 60\n",
            "loss 3.446535097204557e-05 average time 0.13944783292508872 iter num 80\n",
            "loss 3.44601426915354e-05 average time 0.1396154355800172 iter num 100\n",
            "loss 3.436126821673916e-05 average time 0.14127896825020797 iter num 20\n",
            "loss 3.4279198932086754e-05 average time 0.1418588776750312 iter num 40\n",
            "loss 3.4228412715541394e-05 average time 0.14132969893331998 iter num 60\n",
            "loss 3.4206363512993636e-05 average time 0.1408197822374632 iter num 80\n",
            "loss 3.420201190898014e-05 average time 0.1406238062999546 iter num 100\n",
            "loss 3.411738359249161e-05 average time 0.13991028479986198 iter num 20\n",
            "loss 3.404675144002991e-05 average time 0.13997298344975206 iter num 40\n",
            "loss 3.4002574098391335e-05 average time 0.1394813520832334 iter num 60\n",
            "loss 3.3983292829963866e-05 average time 0.1395282775124315 iter num 80\n",
            "loss 3.397966287493693e-05 average time 0.13936150620989793 iter num 100\n",
            "loss 3.390542622166356e-05 average time 0.13986776870024187 iter num 20\n",
            "loss 3.384248592374924e-05 average time 0.13967996147516715 iter num 40\n",
            "loss 3.3802814436599324e-05 average time 0.1392226128167143 iter num 60\n",
            "loss 3.378535186112941e-05 average time 0.14025710046248605 iter num 80\n",
            "loss 3.378193087034963e-05 average time 0.14054369692003094 iter num 100\n",
            "loss 3.371537831056659e-05 average time 0.1436529163999694 iter num 20\n",
            "loss 3.365767077437459e-05 average time 0.14159858419993726 iter num 40\n",
            "loss 3.362162040748525e-05 average time 0.14093387781655717 iter num 60\n",
            "loss 3.360576348591621e-05 average time 0.14023676411241012 iter num 80\n",
            "loss 3.36026588038885e-05 average time 0.13995844994993603 iter num 100\n",
            "loss 3.3877862132074336e-05 average time 0.13933146079989456 iter num 20\n",
            "loss 3.355324919970847e-05 average time 0.13953746019997199 iter num 40\n",
            "loss 3.352340625026658e-05 average time 0.1396920712166017 iter num 60\n",
            "loss 3.349573650017241e-05 average time 0.13997217533744788 iter num 80\n",
            "loss 3.349330960016897e-05 average time 0.14015987453994966 iter num 100\n",
            "loss 4.201197420388163e-05 average time 0.14057894685020073 iter num 20\n",
            "loss 3.7740624323650145e-05 average time 0.1401017653749932 iter num 40\n",
            "loss 3.6870118426254234e-05 average time 0.14102176815003986 iter num 60\n",
            "loss 3.6700810296237014e-05 average time 0.14063987156250732 iter num 80\n",
            "loss 3.6636615414306266e-05 average time 0.1404337948599823 iter num 100\n",
            "loss 3.608442608582735e-05 average time 0.1389783256499868 iter num 20\n",
            "loss 3.569935155554282e-05 average time 0.139031251275037 iter num 40\n",
            "loss 3.5515671877080584e-05 average time 0.1393571761667469 iter num 60\n",
            "loss 3.5444754804472256e-05 average time 0.13949465970010805 iter num 80\n",
            "loss 3.5431079041928113e-05 average time 0.13966717733008407 iter num 100\n",
            "loss 3.519019414963566e-05 average time 0.14082718249983373 iter num 20\n",
            "loss 3.501098616571288e-05 average time 0.14240781944995434 iter num 40\n",
            "loss 3.4908546452261606e-05 average time 0.14184790259999622 iter num 60\n",
            "loss 3.486533100032194e-05 average time 0.1416300989624915 iter num 80\n",
            "loss 3.485680852359421e-05 average time 0.14114036889992349 iter num 100\n",
            "loss 3.4709790268464196e-05 average time 0.1394039560001147 iter num 20\n",
            "loss 3.459192130604737e-05 average time 0.13918098715002997 iter num 40\n",
            "loss 3.451977644928024e-05 average time 0.13949230435003604 iter num 60\n",
            "loss 3.448867561204763e-05 average time 0.13944122952502766 iter num 80\n",
            "loss 3.44825532762524e-05 average time 0.13933501472998613 iter num 100\n",
            "loss 3.436462142376482e-05 average time 0.13823642035004013 iter num 20\n",
            "loss 3.426772261125725e-05 average time 0.13871671115002754 iter num 40\n",
            "loss 3.420851952043533e-05 average time 0.1392016242332526 iter num 60\n",
            "loss 3.418279647099652e-05 average time 0.1401907630999176 iter num 80\n",
            "loss 3.417771347867401e-05 average time 0.14016248692989394 iter num 100\n",
            "loss 3.40793092735518e-05 average time 0.14001939994996065 iter num 20\n",
            "loss 3.399760466499843e-05 average time 0.14009182615004648 iter num 40\n",
            "loss 3.39470231080257e-05 average time 0.13968545443334127 iter num 60\n",
            "loss 3.392513630131784e-05 average time 0.13975221499999863 iter num 80\n",
            "loss 3.3920847081310525e-05 average time 0.13973625550999713 iter num 100\n",
            "loss 3.383602150983067e-05 average time 0.1403131619501437 iter num 20\n",
            "loss 3.376503580887181e-05 average time 0.14212254805024713 iter num 40\n",
            "loss 3.3720326903361405e-05 average time 0.14131873893350833 iter num 60\n",
            "loss 3.3700977423234864e-05 average time 0.14084226212507928 iter num 80\n",
            "loss 3.3696993135843695e-05 average time 0.14080552301002172 iter num 100\n",
            "loss 3.362204807781833e-05 average time 0.14201192279979297 iter num 20\n",
            "loss 3.3558396528184575e-05 average time 0.14099129572500715 iter num 40\n",
            "loss 3.3518234716647275e-05 average time 0.14059692806667953 iter num 60\n",
            "loss 3.350056500707199e-05 average time 0.14045584171258269 iter num 80\n",
            "loss 3.349716141012741e-05 average time 0.14047681046005892 iter num 100\n",
            "loss 3.342943066893435e-05 average time 0.13864223044993196 iter num 20\n",
            "loss 3.3371881752868606e-05 average time 0.13883532334998563 iter num 40\n",
            "loss 3.3335461562243116e-05 average time 0.13874424818335077 iter num 60\n",
            "loss 3.331949651265214e-05 average time 0.13849071429997367 iter num 80\n",
            "loss 3.331634072299732e-05 average time 0.13850627010000607 iter num 100\n",
            "loss 3.3254440456121036e-05 average time 0.13952236915001776 iter num 20\n",
            "loss 3.320190858126645e-05 average time 0.13914673872504862 iter num 40\n",
            "loss 3.3168354370866844e-05 average time 0.13998239998339462 iter num 60\n",
            "loss 3.315345332733111e-05 average time 0.1399096354250105 iter num 80\n",
            "loss 3.315050177526877e-05 average time 0.13958312291006222 iter num 100\n",
            "loss 3.312906688295979e-05 average time 0.13965829510025288 iter num 20\n",
            "loss 3.3045233810515273e-05 average time 0.1393315051251193 iter num 40\n",
            "loss 3.301391647720406e-05 average time 0.13942502073338497 iter num 60\n",
            "loss 3.299961653992977e-05 average time 0.13947899148759008 iter num 80\n",
            "loss 3.2996927558719185e-05 average time 0.13929025815006754 iter num 100\n",
            "loss 4.748518164040272e-05 average time 0.13893242394988192 iter num 20\n",
            "loss 3.5988961790086465e-05 average time 0.13903328214987595 iter num 40\n",
            "loss 3.5655356208599614e-05 average time 0.13929269836659539 iter num 60\n",
            "loss 3.5284477798884086e-05 average time 0.13952034397482294 iter num 80\n",
            "loss 3.525265312822938e-05 average time 0.13957750787989426 iter num 100\n",
            "loss 3.487788527857325e-05 average time 0.1401421425997796 iter num 20\n",
            "loss 3.4591484917093684e-05 average time 0.13949168177482535 iter num 40\n",
            "loss 3.446736583032344e-05 average time 0.13897158939989823 iter num 60\n",
            "loss 3.441714595821255e-05 average time 0.13918629173740554 iter num 80\n",
            "loss 3.440794038685053e-05 average time 0.13915092283985359 iter num 100\n",
            "loss 3.4242896502814796e-05 average time 0.13994417820022137 iter num 20\n",
            "loss 3.411692751571257e-05 average time 0.14169648690021858 iter num 40\n",
            "loss 3.404291437987914e-05 average time 0.14278005120013404 iter num 60\n",
            "loss 3.4011601486177045e-05 average time 0.14282778271265215 iter num 80\n",
            "loss 3.4005325920531934e-05 average time 0.14287056486009533 iter num 100\n",
            "loss 3.3885021383701584e-05 average time 0.14354531809976834 iter num 20\n",
            "loss 3.378639058474268e-05 average time 0.1428765286998896 iter num 40\n",
            "loss 3.372610039716305e-05 average time 0.142067933333207 iter num 60\n",
            "loss 3.370017280026241e-05 average time 0.1411887588374384 iter num 80\n",
            "loss 3.369497747026157e-05 average time 0.1412956624999788 iter num 100\n",
            "loss 3.359592329291972e-05 average time 0.1384494400499534 iter num 20\n",
            "loss 3.351319171472548e-05 average time 0.13885505032499168 iter num 40\n",
            "loss 3.346235280925271e-05 average time 0.1392767293000361 iter num 60\n",
            "loss 3.3440104842185326e-05 average time 0.13935707556249782 iter num 80\n",
            "loss 3.3435783942979306e-05 average time 0.13947124297999836 iter num 100\n",
            "loss 3.335064979620283e-05 average time 0.1390233435502523 iter num 20\n",
            "loss 3.327996284332587e-05 average time 0.14031167005005046 iter num 40\n",
            "loss 3.323559087859954e-05 average time 0.14173659935010316 iter num 60\n",
            "loss 3.321632736810867e-05 average time 0.14136146302505495 iter num 80\n",
            "loss 3.321249090353198e-05 average time 0.14099928277009893 iter num 100\n",
            "loss 3.313803126312687e-05 average time 0.13923052299996924 iter num 20\n",
            "loss 3.307514645994288e-05 average time 0.1390971760999946 iter num 40\n",
            "loss 3.3035772165207755e-05 average time 0.1390459752165043 iter num 60\n",
            "loss 3.301845828567244e-05 average time 0.13893213577487132 iter num 80\n",
            "loss 3.3014988918912606e-05 average time 0.13948245151990704 iter num 100\n",
            "loss 3.29487009529715e-05 average time 0.13999782889995913 iter num 20\n",
            "loss 3.2892758216377666e-05 average time 0.13981906624994736 iter num 40\n",
            "loss 3.285743752102786e-05 average time 0.13952840744987044 iter num 60\n",
            "loss 3.2841852476890707e-05 average time 0.13980590301239318 iter num 80\n",
            "loss 3.2838948902787976e-05 average time 0.13990558964986122 iter num 100\n",
            "loss 3.315940927727549e-05 average time 0.14189771100018334 iter num 20\n",
            "loss 3.276494790942925e-05 average time 0.14356342952501108 iter num 40\n",
            "loss 3.272259564649454e-05 average time 0.1430285269001009 iter num 60\n",
            "loss 3.270779042666191e-05 average time 0.14215817326262367 iter num 80\n",
            "loss 3.270524098130369e-05 average time 0.1414977262901448 iter num 100\n",
            "loss 4.16801308197137e-05 average time 0.13940696125000612 iter num 20\n",
            "loss 3.671704589480772e-05 average time 0.1391047862499363 iter num 40\n",
            "loss 3.552182796808685e-05 average time 0.13944990913323635 iter num 60\n",
            "loss 3.510375412759078e-05 average time 0.139530315937418 iter num 80\n",
            "loss 3.5089081134111144e-05 average time 0.13970503952996297 iter num 100\n",
            "loss 3.462437075243268e-05 average time 0.14239730265016987 iter num 20\n",
            "loss 3.437568281389593e-05 average time 0.14267018739997184 iter num 40\n",
            "loss 3.425390313634382e-05 average time 0.14201359186657403 iter num 60\n",
            "loss 3.420331504079048e-05 average time 0.14127713038737966 iter num 80\n",
            "loss 3.419310049041071e-05 average time 0.14105349631990977 iter num 100\n",
            "loss 3.400978739097828e-05 average time 0.1383542978499463 iter num 20\n",
            "loss 3.387147571721003e-05 average time 0.13947975612504707 iter num 40\n",
            "loss 3.3789896198860895e-05 average time 0.1395353901333692 iter num 60\n",
            "loss 3.375528101344078e-05 average time 0.1394484860625198 iter num 80\n",
            "loss 3.374848684872549e-05 average time 0.13921643385003335 iter num 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQs-OZHGEwac"
      },
      "source": [
        "# 23 + 23 + 23 + 23 + 16"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ccd471-5189-44f2-9018-d10767a92d2d"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 1, 1, 0.25, 0.02, 0.02]]).cuda() # T, K, S, sigma, mu, r\n",
        "print('price: ' + str(model(inputs.float())))\n",
        "\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient[0][[2]]\n",
        "\n",
        "# price, delta\n",
        "# should be around (0.10870558, 0.581213937)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: tensor([[0.1051]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5837], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqpasxVi0hx3",
        "outputId": "44930281-3485-45cb-db51-525265ce31c0"
      },
      "source": [
        "import cupy\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "import pandas as pd\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "    return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "print(bs_call(1,1,1,0.02,0.25))\n",
        "print(bs_delta(1,1,1,0.02,0.25))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10870558490557591\n",
            "0.5812139374874482\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lovJwXo3-YEu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "9355afee-a3e4-413a-a96f-2bee3b416aae"
      },
      "source": [
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "\n",
        "def compute_price(S):\n",
        "    inputs = torch.tensor([[1, 1, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_prices = []\n",
        "BS_call_prices = []\n",
        "for p in prices:\n",
        "    model_call_prices.append(compute_price(p).item())\n",
        "    BS_call_prices.append(bs_call(p, 1, 1, 0.02, 0.25))\n",
        "\n",
        "#plt.plot(prices, model_call_prices, label = \"model_call_prices\")\n",
        "#plt.plot(prices, BS_call_prices, label = \"BS_call_prices\")\n",
        "plt.plot(prices, np.array(model_call_prices)-np.array(BS_call_prices), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwApH0GT9bBK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "7a340b31-4f03-44c4-cada-a95008854720"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 1, 1, 0.02, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHgD1NjP7DOW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "fed26451-f839-4f9b-bb12-4eef5e41750d"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 0.75, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 0.75, 1, 0.02, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7MfujMQ7oij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "cd48a21c-8690-4fdc-c054-89e1f8f1ae7a"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1.25, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 1.25, 1, 0.02, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}