{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grid Test_Knock Out Call 3stocks_Old Method",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Erin/4min_Grid_Test_Knock_Out_Call_3stocks_Old_Method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPlLTzwwNfwg"
      },
      "source": [
        "nstock = 3"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYigDkiy0HU9"
      },
      "source": [
        "# import cupy\n",
        "# import jax\n",
        "# import jax.numpy as jnp\n",
        "# from jax import random\n",
        "# from jax import jit\n",
        "# import numpy as np\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# S_range = jnp.linspace(0.75, 1.25, 10)\n",
        "# K_range = jnp.linspace(0.75, 1.25, 8)\n",
        "# B_range = jnp.linspace(0.5, 1.0, 8) #in = (1.1, 1.6, 8)\n",
        "# sigma_range = jnp.linspace(0.15, 0.45, 4)\n",
        "# r_range = jnp.linspace(0.01, 0.04, 3)\n",
        "\n",
        "# print(S_range)\n",
        "# print(K_range)\n",
        "# print(B_range)\n",
        "# print(sigma_range)\n",
        "# print(r_range)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIQxpJqK6OZr"
      },
      "source": [
        "# import cupy\n",
        "# import jax\n",
        "# import jax.numpy as jnp\n",
        "# from jax import random\n",
        "# from jax import jit\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "#     stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "#     stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "#                             jax.ops.index[0],         # initialization of stock prices\n",
        "#                             initial_stocks)\n",
        "#     noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "#     sigma = jnp.diag(cov) ** 0.5\n",
        "#     dt = T / numsteps\n",
        "#     def time_step(t, val):\n",
        "#         dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "#         val = jax.ops.index_update(val,\n",
        "#                             jax.ops.index[t],\n",
        "#                             val[t-1] * dx)\n",
        "#         return val\n",
        "#     return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "# def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T): # down-and-out call\n",
        "#     return jnp.mean(jnp.maximum((1 - jnp.any(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2) < B, axis=1).astype(int))* \n",
        "#                                 (jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2))[:,-1]-K, 0) *\n",
        "#                     jnp.exp(-r[0] * T))\n",
        "\n",
        "# goptionvalueavg = jax.grad(optionvalueavg, argnums=1)\n",
        "\n",
        "# #################################################################### Adjust all parameters here (not inside class)\n",
        "# numstocks = nstock\n",
        "# numsteps = 50\n",
        "# numpaths = 2000000\n",
        "\n",
        "# rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "# rng, key = jax.random.split(rng)\n",
        "# keys = jax.random.split(key, numpaths)\n",
        "\n",
        "# S1_range = jnp.linspace(0.75, 1.25, 6)[2:4]\n",
        "# S2_range = jnp.linspace(0.75, 1.25, 6)\n",
        "# S3_range = jnp.linspace(0.75, 1.25, 6)\n",
        "# K_range = jnp.linspace(0.75, 1.25, 5)\n",
        "# B_range = jnp.linspace(0.5, 1.0, 6)\n",
        "# sigma_range = jnp.linspace(0.15, 0.45, 3)\n",
        "# r_range = jnp.linspace(0.01, 0.04, 3)\n",
        "# T = 1.0\n",
        "\n",
        "# fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "# batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "# ####################################################################\n",
        "\n",
        "# call = []\n",
        "# count = 0\n",
        "\n",
        "# # for S1 in S_range:\n",
        "# #   for K in K_range:\n",
        "# #     for B in B_range:\n",
        "# #       for r in r_range:\n",
        "# #         for sigma in sigma_range:    \n",
        "\n",
        "# #           initial_stocks = jnp.array([S]*numstocks) # must be float\n",
        "# #           r_tmp = jnp.array([r]*numstocks)\n",
        "# #           drift = r_tmp\n",
        "# #           cov = jnp.identity(numstocks)*sigma*sigma\n",
        "\n",
        "# #           Knock_Out_Call_price = optionvalueavg(key, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T)\n",
        "# #           Deltas = goptionvalueavg(keys, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T)\n",
        "# #           # call.append([T, K, B, S, sigma, r, r, Knock_Out_Call_price] + list(Deltas)) #T, K, B, S, sigma, mu, r, price, delta\n",
        "# #           call.append([T, K, S1, sigma, r, r,\n",
        "# #                          T, K, S2, sigma, r, r,\n",
        "# #                          T, K, S3, sigma, r, r, Knock_Out_Call_price] + list(Deltas))\n",
        "          \n",
        "# #           count += 1\n",
        "# #           print(count)\n",
        "\n",
        "# for S1 in S1_range:\n",
        "#   for S2 in S2_range:\n",
        "#     for S3 in S3_range:\n",
        "#       for K in K_range:\n",
        "#         for B in B_range:\n",
        "#           for r in r_range:\n",
        "#             for sigma in sigma_range:\n",
        "              \n",
        "#               initial_stocks = jnp.array([S1, S2, S3]) # must be float\n",
        "#               r_tmp = jnp.array([r]*numstocks)\n",
        "#               drift = r_tmp\n",
        "#               cov = jnp.identity(numstocks)*sigma*sigma\n",
        "              \n",
        "#               Knock_Out_Call_price = optionvalueavg(key, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T)\n",
        "#               Deltas = goptionvalueavg(keys, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T)\n",
        "#               call.append([T, K, B, S1, sigma, r, r,\n",
        "#                           T, K, B, S2, sigma, r, r,\n",
        "#                           T, K, B, S3, sigma, r, r, Knock_Out_Call_price] + list(Deltas)) #T, K, S, sigma, mu, r, price, delta\n",
        "                          \n",
        "#               count += 1\n",
        "#               print(count)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_OUtP8GUwj5"
      },
      "source": [
        "# Thedataset_3stock = pd.DataFrame(call)\n",
        "# Thedataset_3stock"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RsPX_tEBGFc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39591f2-fd29-4c5d-ddca-55d64f14f756"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv_WjCRV2OZK"
      },
      "source": [
        "# #save to csv\n",
        "# Thedataset_3stock.to_csv(f'/content/drive/MyDrive/AFP/Save_Models/Knock_Out_Call_{str(nstock)}stocks_Datset_part2.csv', index=False, header=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LtL32xSp7mw"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skGWSSsG8TGG"
      },
      "source": [
        "# read csv\n",
        "import pandas as pd\n",
        "\n",
        "Thedataset_3stock = pd.read_csv(f'/content/drive/MyDrive/AFP/Save_Models/Knock_Out_Call_{str(nstock)}stocks_Datset.csv', header=None)\n",
        "# Thedataset_3stock"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4HV-G44th"
      },
      "source": [
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "import torch\n",
        "torch.set_printoptions(precision=6)\n",
        "\n",
        "# Thedataset_X = Thedataset_3stock.iloc[:,:7]\n",
        "# Thedataset_Y = Thedataset_3stock.iloc[:,7:]\n",
        "Thedataset_X = Thedataset_3stock.iloc[:,:7*nstock]\n",
        "Thedataset_Y = Thedataset_3stock.iloc[:,7*nstock:]\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.X = cupy.array(Thedataset_X)\n",
        "        self.Y = cupy.array(Thedataset_Y)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(self.X.toDlpack()), from_dlpack(self.Y.toDlpack()))\n",
        "\n",
        "# print\n",
        "# ds = OptionDataSet(max_len = 1)\n",
        "# for i in ds:\n",
        "#     print(i[0])\n",
        "#     print(i[0].shape)\n",
        "#     print(i[1])\n",
        "#     print(i[1].shape)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN6JO9OBHdvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "508ee8d5-f96d-4187-8fb6-74adfb5f91fd"
      },
      "source": [
        "%%writefile model.py\n",
        "# version 1,2\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024, nstock = 1):\n",
        "        self.nstock = nstock\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(7*self.nstock, 64) # remember to change this!\n",
        "        self.fc2 = nn.Linear(64, 128)\n",
        "        self.fc3 = nn.Linear(128, 256)\n",
        "        self.fc4 = nn.Linear(256, 128)\n",
        "        self.fc5 = nn.Linear(128, 64)\n",
        "        self.fc6 = nn.Linear(64, nstock + 1) # outputs: prices, delta\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1.0, 0.5, 0.5, 0.5, 0.3, 0.03, 0.03] * self.nstock)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, B, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = (x - torch.tensor([0.0, 0.75, 0.5, 0.75, 0.15, 0.01, 0.01] * self.nstock).cuda()) / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlXD80xPNVc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cedb97e4-bf1d-4efc-b491-a9a665f89ddc"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.7/dist-packages (0.4.7)\n",
            "Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeLVZiiaDS4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62a149c2-5c1f-474f-ad12-b2fab245b414"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3CyULkENYKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c6952b4-858e-4301-8961-b06e47ae46de"
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net(nstock = nstock).cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100) # Use max_len to adjust\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    # print(x)\n",
        "    # print(x.shape)\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    # print(y.shape)\n",
        "    y_pred = model(x.float())\n",
        "    # print(y_pred)\n",
        "    # print(y_pred.shape)\n",
        "\n",
        "    # def compute_deltas(x):\n",
        "    #   inputs = x.float()\n",
        "    #   inputs.requires_grad = True\n",
        "    #   first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "    #   return first_order_gradient[0][[3]]  # Now index 3 is stock price, not 2\n",
        "\n",
        "    # deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    # y_pred = torch.cat((y_pred, deltas), 1)\n",
        "    # # print(y_pred)\n",
        "    # # print(y_pred.shape)\n",
        "\n",
        "    loss_weight = torch.tensor([1] * (nstock+1)).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)\n",
        "\n",
        "model_save_name = f'jax_knock_out_{str(nstock)}stocks_oldmethod_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.01224672574410706 average time 0.013402555700054108 iter num 20\n",
            "loss 0.009126863497373745 average time 0.013017256375030683 iter num 40\n",
            "loss 0.007128439253593152 average time 0.01285466865001581 iter num 60\n",
            "loss 0.006232940173446742 average time 0.01278237576251513 iter num 80\n",
            "loss 0.006053955598234374 average time 0.01277504470002441 iter num 100\n",
            "loss 0.003737655452817366 average time 0.01261908504998246 iter num 20\n",
            "loss 0.003077620475164287 average time 0.012637904099983643 iter num 40\n",
            "loss 0.002952841700973571 average time 0.012628574316659069 iter num 60\n",
            "loss 0.0029291216273295085 average time 0.012654615137500968 iter num 80\n",
            "loss 0.002925123533513152 average time 0.012648380730006466 iter num 100\n",
            "loss 0.002866913714641158 average time 0.012667869699953371 iter num 20\n",
            "loss 0.002827311498416252 average time 0.012674643724960789 iter num 40\n",
            "loss 0.002801992896041586 average time 0.01265406656665012 iter num 60\n",
            "loss 0.002790392425969882 average time 0.012654131624992715 iter num 80\n",
            "loss 0.0027879172490643256 average time 0.012654088879999107 iter num 100\n",
            "loss 0.0027401545357884846 average time 0.012630229749925092 iter num 20\n",
            "loss 0.0026969246358838407 average time 0.012602543299965418 iter num 40\n",
            "loss 0.002667518494240767 average time 0.012609296966638794 iter num 60\n",
            "loss 0.0026537848461946523 average time 0.012604186099980551 iter num 80\n",
            "loss 0.002650849449597863 average time 0.012608973609990243 iter num 100\n",
            "loss 0.00259369734099629 average time 0.012570879250006328 iter num 20\n",
            "loss 0.002540499362337802 average time 0.012605423475008593 iter num 40\n",
            "loss 0.0025036114546335333 average time 0.012602701850020518 iter num 60\n",
            "loss 0.0024862426558514756 average time 0.012617321362523626 iter num 80\n",
            "loss 0.0024825296122590735 average time 0.012606760210014728 iter num 100\n",
            "loss 0.0024099512513550093 average time 0.012561042349966555 iter num 20\n",
            "loss 0.0023414939245934674 average time 0.012601462274983533 iter num 40\n",
            "loss 0.0022937765236533915 average time 0.012632631983342435 iter num 60\n",
            "loss 0.002271347673240465 average time 0.01264629316252126 iter num 80\n",
            "loss 0.0022665717742345656 average time 0.012657625370006826 iter num 100\n",
            "loss 0.0021740583904874327 average time 0.012633189600046535 iter num 20\n",
            "loss 0.0020888819274574363 average time 0.012664938074999554 iter num 40\n",
            "loss 0.0020316990079338425 average time 0.012674329816695718 iter num 60\n",
            "loss 0.00200571147480325 average time 0.012667143275024273 iter num 80\n",
            "loss 0.0020002791307905292 average time 0.012677677400015455 iter num 100\n",
            "loss 0.0018996632683345733 average time 0.012627267650054818 iter num 20\n",
            "loss 0.001816466234958361 average time 0.01266227910005 iter num 40\n",
            "loss 0.0017660936028513112 average time 0.01266683956671386 iter num 60\n",
            "loss 0.0017445469369338008 average time 0.012674303637538742 iter num 80\n",
            "loss 0.0017401494163367614 average time 0.012671752200030823 iter num 100\n",
            "loss 0.0016617997720287955 average time 0.01258623990001979 iter num 20\n",
            "loss 0.0016000427985978507 average time 0.012608778750006877 iter num 40\n",
            "loss 0.0015626836007322244 average time 0.012616640966681796 iter num 60\n",
            "loss 0.0015464987835293385 average time 0.012619799550003563 iter num 80\n",
            "loss 0.0015431731161170035 average time 0.012637950299986187 iter num 100\n",
            "loss 0.00150144384439706 average time 0.012687076550014354 iter num 20\n",
            "loss 0.0014466955978118192 average time 0.01266780054999117 iter num 40\n",
            "loss 0.001420180807563871 average time 0.012657373183310483 iter num 60\n",
            "loss 0.0014089189005137023 average time 0.012673602774987103 iter num 80\n",
            "loss 0.0014065616416483056 average time 0.012677944249990105 iter num 100\n",
            "loss 0.0013627150640250262 average time 0.01269738865000818 iter num 20\n",
            "loss 0.001325020567518184 average time 0.012634889199989629 iter num 40\n",
            "loss 0.0013006305922969499 average time 0.01263960033334873 iter num 60\n",
            "loss 0.0012896234030226484 average time 0.012625333124992722 iter num 80\n",
            "loss 0.001287313011388084 average time 0.012620032079989869 iter num 100\n",
            "loss 0.0012437795305523655 average time 0.012608751949960606 iter num 20\n",
            "loss 0.001205629608967238 average time 0.012613410100004784 iter num 40\n",
            "loss 0.0011806166272726646 average time 0.012630322733336167 iter num 60\n",
            "loss 0.0011692711688302661 average time 0.012618840524993402 iter num 80\n",
            "loss 0.0011668876847418178 average time 0.012624475339994206 iter num 100\n",
            "loss 0.0011220523106009904 average time 0.012638869849956791 iter num 20\n",
            "loss 0.0010833476079848373 average time 0.012662043874968276 iter num 40\n",
            "loss 0.0010587315807957728 average time 0.012661744666661433 iter num 60\n",
            "loss 0.001047884163009243 average time 0.012642467837497406 iter num 80\n",
            "loss 0.0010456398992679558 average time 0.012633644589982396 iter num 100\n",
            "loss 0.00100499680498972 average time 0.012620920599965757 iter num 20\n",
            "loss 0.0009730659524267945 average time 0.01264366084996027 iter num 40\n",
            "loss 0.0009544807933454176 average time 0.012658103949979705 iter num 60\n",
            "loss 0.0009466858897513628 average time 0.012672199049973187 iter num 80\n",
            "loss 0.0009451019202947068 average time 0.012688730099980602 iter num 100\n",
            "loss 0.000927466566002336 average time 0.012662455200029399 iter num 20\n",
            "loss 0.0008995740268352995 average time 0.01263257909999993 iter num 40\n",
            "loss 0.0008854047091282708 average time 0.012594148949998878 iter num 60\n",
            "loss 0.000880269391741258 average time 0.012599954462496043 iter num 80\n",
            "loss 0.0008792042166866852 average time 0.012603915859999688 iter num 100\n",
            "loss 0.0008595141744489716 average time 0.012626851699974396 iter num 20\n",
            "loss 0.0008427590612723459 average time 0.012611289574999773 iter num 40\n",
            "loss 0.0008319336746852568 average time 0.012614067999993494 iter num 60\n",
            "loss 0.0008270388779939024 average time 0.012620665887487803 iter num 80\n",
            "loss 0.0008260101108912034 average time 0.012629203649989904 iter num 100\n",
            "loss 0.0008065321067551069 average time 0.012648341449903455 iter num 20\n",
            "loss 0.0007892094906093258 average time 0.012613453974961431 iter num 40\n",
            "loss 0.0007776378701096519 average time 0.012618532116615217 iter num 60\n",
            "loss 0.000772308855852657 average time 0.012623882124955799 iter num 80\n",
            "loss 0.0007711806367238577 average time 0.012623825669952566 iter num 100\n",
            "loss 0.00075582926149673 average time 0.012652768750035648 iter num 20\n",
            "loss 0.0007306926412052796 average time 0.012649012950032557 iter num 40\n",
            "loss 0.0007172881646106714 average time 0.012633668783352429 iter num 60\n",
            "loss 0.0007112171388682161 average time 0.012650686099999576 iter num 80\n",
            "loss 0.0007099337520046196 average time 0.012628327030001855 iter num 100\n",
            "loss 0.0006863517683670158 average time 0.012543962599966107 iter num 20\n",
            "loss 0.0006660605146020512 average time 0.012556057949984734 iter num 40\n",
            "loss 0.0006523803526267309 average time 0.012579710866672637 iter num 60\n",
            "loss 0.0006460770258323878 average time 0.012597851312517606 iter num 80\n",
            "loss 0.0006447410183656635 average time 0.012594087460010997 iter num 100\n",
            "loss 0.0006193746424452578 average time 0.012632175700014158 iter num 20\n",
            "loss 0.0005969187969500694 average time 0.012631093800030158 iter num 40\n",
            "loss 0.000582331653798955 average time 0.012648743766688616 iter num 60\n",
            "loss 0.0005758134953074503 average time 0.01265465635002556 iter num 80\n",
            "loss 0.0005744571107338605 average time 0.012657743370018579 iter num 100\n",
            "loss 0.0005495012746828155 average time 0.012698497700057487 iter num 20\n",
            "loss 0.0005290209285755356 average time 0.012693029025024316 iter num 40\n",
            "loss 0.0005166202908375307 average time 0.012691840300044532 iter num 60\n",
            "loss 0.0005113192182914333 average time 0.012683169975014152 iter num 80\n",
            "loss 0.0005102367513856113 average time 0.012677771630010284 iter num 100\n",
            "loss 0.0004910114256625242 average time 0.012703608500032715 iter num 20\n",
            "loss 0.0004762345093881926 average time 0.012686392750038068 iter num 40\n",
            "loss 0.0004676360537249642 average time 0.01265955853335375 iter num 60\n",
            "loss 0.00046400683916304004 average time 0.012643803250017526 iter num 80\n",
            "loss 0.0004632672765743978 average time 0.012645739670015246 iter num 100\n",
            "loss 0.0004520600390987326 average time 0.012695717399969908 iter num 20\n",
            "loss 0.00043994568272055025 average time 0.012700414599987653 iter num 40\n",
            "loss 0.0004335374745668733 average time 0.012670976666648433 iter num 60\n",
            "loss 0.0004308115068611969 average time 0.012688394374970357 iter num 80\n",
            "loss 0.00043025019159770544 average time 0.012680774749987904 iter num 100\n",
            "loss 0.00042701153467275554 average time 0.012714760800031399 iter num 20\n",
            "loss 0.00041954301366778476 average time 0.012727823399995942 iter num 40\n",
            "loss 0.0004111474774773459 average time 0.012692048616668217 iter num 60\n",
            "loss 0.0004091056390794813 average time 0.012679364749999422 iter num 80\n",
            "loss 0.000408712092035901 average time 0.012653106920015488 iter num 100\n",
            "loss 0.00040175487688841295 average time 0.01261629370007995 iter num 20\n",
            "loss 0.0003958014486926837 average time 0.012609090350053975 iter num 40\n",
            "loss 0.0003919798744372454 average time 0.012610766983372438 iter num 60\n",
            "loss 0.0003902681684130096 average time 0.012603568187535075 iter num 80\n",
            "loss 0.00038991051154002414 average time 0.012616954960030853 iter num 100\n",
            "loss 0.0003832297948345638 average time 0.012681048350077617 iter num 20\n",
            "loss 0.000377475248789801 average time 0.012684895375059568 iter num 40\n",
            "loss 0.00037376469052395004 average time 0.012675793850053196 iter num 60\n",
            "loss 0.00037209945762849454 average time 0.012657710850044168 iter num 80\n",
            "loss 0.0003717512483758606 average time 0.012654346350032028 iter num 100\n",
            "loss 0.0003652377368275343 average time 0.012650619899955019 iter num 20\n",
            "loss 0.0003596098802835609 average time 0.012639608675021919 iter num 40\n",
            "loss 0.00035597113114724477 average time 0.012636375150001792 iter num 60\n",
            "loss 0.00035433529193936873 average time 0.012641112574999624 iter num 80\n",
            "loss 0.00035399299097479226 average time 0.01263428820000172 iter num 100\n",
            "loss 0.0003475788008326412 average time 0.012674886900003911 iter num 20\n",
            "loss 0.00034201537842456267 average time 0.012648985875000563 iter num 40\n",
            "loss 0.00033840513632142893 average time 0.01264492923335941 iter num 60\n",
            "loss 0.00033677810782492334 average time 0.012663658875004558 iter num 80\n",
            "loss 0.0003364372977096139 average time 0.012667997930007004 iter num 100\n",
            "loss 0.00033003687050153015 average time 0.012703384600035861 iter num 20\n",
            "loss 0.0003244569740344811 average time 0.012697293925054965 iter num 40\n",
            "loss 0.0003208182387884914 average time 0.012692480716699114 iter num 60\n",
            "loss 0.0003191732128651531 average time 0.012690315162529942 iter num 80\n",
            "loss 0.0003188281181257013 average time 0.012674272870017376 iter num 100\n",
            "loss 0.00031232994876318344 average time 0.012651586350011712 iter num 20\n",
            "loss 0.00030663222181480246 average time 0.012634869049998087 iter num 40\n",
            "loss 0.00030289991628649007 average time 0.01262476854999477 iter num 60\n",
            "loss 0.00030120855055302143 average time 0.012634974499997042 iter num 80\n",
            "loss 0.00030085346295399655 average time 0.012631919519990334 iter num 100\n",
            "loss 0.00029415689846606463 average time 0.012674811700026111 iter num 20\n",
            "loss 0.0002882681590676672 average time 0.012746985875037354 iter num 40\n",
            "loss 0.0002844045524701466 average time 0.01278093510003752 iter num 60\n",
            "loss 0.00028265244038119786 average time 0.012765593387530316 iter num 80\n",
            "loss 0.00028228453481009833 average time 0.012735866010016252 iter num 100\n",
            "loss 0.0003122470279914038 average time 0.012650493499972982 iter num 20\n",
            "loss 0.00027079331439420015 average time 0.012623471550000431 iter num 40\n",
            "loss 0.0002673205581000044 average time 0.012621197366668942 iter num 60\n",
            "loss 0.0002657463485748275 average time 0.012635755825016304 iter num 80\n",
            "loss 0.00026543561258828035 average time 0.012639879900002598 iter num 100\n",
            "loss 0.00025956238342095196 average time 0.012699478600006841 iter num 20\n",
            "loss 0.00025439699174178987 average time 0.012698269799955142 iter num 40\n",
            "loss 0.00025100844323780626 average time 0.012684035549993193 iter num 60\n",
            "loss 0.00024947207231443833 average time 0.01266455240000255 iter num 80\n",
            "loss 0.0002491495276593501 average time 0.012645309560002715 iter num 100\n",
            "loss 0.0002430652181594552 average time 0.012644391899971196 iter num 20\n",
            "loss 0.00023771516574809954 average time 0.012621421124993048 iter num 40\n",
            "loss 0.0002342049416749872 average time 0.012645903899980718 iter num 60\n",
            "loss 0.00023261324336277232 average time 0.012651599574979855 iter num 80\n",
            "loss 0.0002322790479894818 average time 0.012655507479985317 iter num 100\n",
            "loss 0.0002259730330039741 average time 0.012666567700125596 iter num 20\n",
            "loss 0.00022042254346461734 average time 0.012682734450083898 iter num 40\n",
            "loss 0.00021677782663959694 average time 0.012670358000067002 iter num 60\n",
            "loss 0.00021512445565756297 average time 0.012663393925060972 iter num 80\n",
            "loss 0.00021477727226593937 average time 0.01264494209005079 iter num 100\n",
            "loss 0.000212838528399693 average time 0.012583227999994052 iter num 20\n",
            "loss 0.00020305302910722398 average time 0.012570272199991451 iter num 40\n",
            "loss 0.00019896213640891206 average time 0.012565940383342421 iter num 60\n",
            "loss 0.00019728247607934328 average time 0.012565047925005502 iter num 80\n",
            "loss 0.00019693284396433416 average time 0.012560651510007119 iter num 100\n",
            "loss 0.00019339386110203677 average time 0.012654068250026285 iter num 20\n",
            "loss 0.00019195820124468053 average time 0.012639800324984662 iter num 40\n",
            "loss 0.0001849515518942177 average time 0.012621432733340043 iter num 60\n",
            "loss 0.00018338170778590832 average time 0.012607419675026677 iter num 80\n",
            "loss 0.0001831089369015318 average time 0.012604733110024427 iter num 100\n",
            "loss 0.00017819719057087386 average time 0.012598769149963118 iter num 20\n",
            "loss 0.00017385754408127675 average time 0.012599176450009963 iter num 40\n",
            "loss 0.00017104184240655616 average time 0.012609173950014945 iter num 60\n",
            "loss 0.00016977204448604365 average time 0.012614958500012107 iter num 80\n",
            "loss 0.00016950599498130508 average time 0.012631528030005938 iter num 100\n",
            "loss 0.00016451266735881314 average time 0.012606821499934995 iter num 20\n",
            "loss 0.00016017172695180165 average time 0.01263000859994463 iter num 40\n",
            "loss 0.00015735757208175613 average time 0.012626589183317568 iter num 60\n",
            "loss 0.0001560923317743531 average time 0.012624919925002587 iter num 80\n",
            "loss 0.00015582778106354922 average time 0.012606170330004716 iter num 100\n",
            "loss 0.00015088107810437012 average time 0.012573677999967003 iter num 20\n",
            "loss 0.00014661584733899257 average time 0.012618132399995829 iter num 40\n",
            "loss 0.0001438694192695179 average time 0.012610991150017981 iter num 60\n",
            "loss 0.00014263969099225947 average time 0.012620491575012239 iter num 80\n",
            "loss 0.00014238300745541822 average time 0.012629066430017702 iter num 100\n",
            "loss 0.00013759967733808443 average time 0.012666721999994478 iter num 20\n",
            "loss 0.00013349974955388075 average time 0.012617920950003737 iter num 40\n",
            "loss 0.00013087289210660485 average time 0.01263638575001096 iter num 60\n",
            "loss 0.00012970026393944312 average time 0.012658387362506573 iter num 80\n",
            "loss 0.00012945583060025 average time 0.012670869630010202 iter num 100\n",
            "loss 0.00012491244077459388 average time 0.012660137249986292 iter num 20\n",
            "loss 0.00012103723974198009 average time 0.012678400550021252 iter num 40\n",
            "loss 0.00011856266207657684 average time 0.012671822766689426 iter num 60\n",
            "loss 0.00011745992219805082 average time 0.012660298975021078 iter num 80\n",
            "loss 0.0001172302213364365 average time 0.01265184127001703 iter num 100\n",
            "loss 0.00011296810656090855 average time 0.012634814400030336 iter num 20\n",
            "loss 0.00010934569719580185 average time 0.012653860400007488 iter num 40\n",
            "loss 0.00010704228538724237 average time 0.012661830983332342 iter num 60\n",
            "loss 0.00010601839911182323 average time 0.012653089512485848 iter num 80\n",
            "loss 0.00010580536200146404 average time 0.012640292519977265 iter num 100\n",
            "loss 0.00017183803695718666 average time 0.01260220854999261 iter num 20\n",
            "loss 0.00010576366328987598 average time 0.012627065999959086 iter num 40\n",
            "loss 9.850138630994565e-05 average time 0.012603168516625374 iter num 60\n",
            "loss 9.765142735662016e-05 average time 0.012600219862457606 iter num 80\n",
            "loss 9.747952569573245e-05 average time 0.012603720359970793 iter num 100\n",
            "loss 9.475580507283542e-05 average time 0.012640246749970174 iter num 20\n",
            "loss 9.240384869633404e-05 average time 0.012682684449976023 iter num 40\n",
            "loss 9.09164733263808e-05 average time 0.012686249516658183 iter num 60\n",
            "loss 9.025426312171107e-05 average time 0.012670331599997553 iter num 80\n",
            "loss 9.01163218970094e-05 average time 0.012656869400011601 iter num 100\n",
            "loss 8.755390784662788e-05 average time 0.012545348149933489 iter num 20\n",
            "loss 8.537049873655453e-05 average time 0.012624220599968794 iter num 40\n",
            "loss 8.397716852113719e-05 average time 0.012649607616655583 iter num 60\n",
            "loss 8.33563492195859e-05 average time 0.012653060287499329 iter num 80\n",
            "loss 8.322701346018862e-05 average time 0.012650983680009631 iter num 100\n",
            "loss 8.082405787629342e-05 average time 0.012616157549996388 iter num 20\n",
            "loss 7.877662577570014e-05 average time 0.012650741599986758 iter num 40\n",
            "loss 7.747055817266734e-05 average time 0.012635267249978217 iter num 60\n",
            "loss 7.688884086248287e-05 average time 0.012647253049976825 iter num 80\n",
            "loss 7.676767461569584e-05 average time 0.012667259999980161 iter num 100\n",
            "loss 7.451765923328384e-05 average time 0.01268346550004935 iter num 20\n",
            "loss 7.260249545888186e-05 average time 0.012662850375022572 iter num 40\n",
            "loss 7.138185496649905e-05 average time 0.01265338235003431 iter num 60\n",
            "loss 7.083853932901061e-05 average time 0.012657689387526715 iter num 80\n",
            "loss 7.072539019226353e-05 average time 0.012642399720029972 iter num 100\n",
            "loss 6.862576556817965e-05 average time 0.01263037575006365 iter num 20\n",
            "loss 6.684120988176436e-05 average time 0.012673232425072456 iter num 40\n",
            "loss 6.57056152472031e-05 average time 0.01267364583335772 iter num 60\n",
            "loss 6.520066398106396e-05 average time 0.012683243812512046 iter num 80\n",
            "loss 6.509555912032793e-05 average time 0.012677264180006205 iter num 100\n",
            "loss 6.427479153012857e-05 average time 0.012667792349998309 iter num 20\n",
            "loss 6.20402879906119e-05 average time 0.012665851824965556 iter num 40\n",
            "loss 6.06646976812432e-05 average time 0.012669745016637535 iter num 60\n",
            "loss 6.016575879574414e-05 average time 0.012649121937477048 iter num 80\n",
            "loss 6.006680219807998e-05 average time 0.012640440399959516 iter num 100\n",
            "loss 0.00014342020506790472 average time 0.012619561700034865 iter num 20\n",
            "loss 6.097146163337887e-05 average time 0.012607589299966549 iter num 40\n",
            "loss 5.764361535604858e-05 average time 0.01260704146664769 iter num 60\n",
            "loss 5.699783840546873e-05 average time 0.012595056299983299 iter num 80\n",
            "loss 5.689950441583976e-05 average time 0.012612864009975055 iter num 100\n",
            "loss 5.572355628707128e-05 average time 0.012675383999953738 iter num 20\n",
            "loss 5.4692045605193833e-05 average time 0.01265193167499774 iter num 40\n",
            "loss 5.404295179081424e-05 average time 0.01265023083331774 iter num 60\n",
            "loss 5.3754297823209834e-05 average time 0.012654800124977328 iter num 80\n",
            "loss 5.369408457438864e-05 average time 0.012655561079977815 iter num 100\n",
            "loss 5.2573712174409336e-05 average time 0.012605491250042178 iter num 20\n",
            "loss 5.1615372490301e-05 average time 0.012622108825019041 iter num 40\n",
            "loss 5.100178608129554e-05 average time 0.012631207916691286 iter num 60\n",
            "loss 5.072782373172941e-05 average time 0.012646055412523083 iter num 80\n",
            "loss 5.067067354596798e-05 average time 0.012651898539993454 iter num 100\n",
            "loss 4.9607258696082935e-05 average time 0.012571466650024376 iter num 20\n",
            "loss 4.869798646072456e-05 average time 0.012589522975008548 iter num 40\n",
            "loss 4.8116102563095215e-05 average time 0.012588502633358681 iter num 60\n",
            "loss 4.7856414034966865e-05 average time 0.012603042425030252 iter num 80\n",
            "loss 4.7802255124279295e-05 average time 0.012609487840004477 iter num 100\n",
            "loss 4.6794828971825604e-05 average time 0.012581394700009695 iter num 20\n",
            "loss 4.593414791722891e-05 average time 0.012604534274976232 iter num 40\n",
            "loss 4.538377499002e-05 average time 0.012611202783288415 iter num 60\n",
            "loss 4.5138267007021155e-05 average time 0.012612115299970129 iter num 80\n",
            "loss 4.508708252595729e-05 average time 0.012609390789971258 iter num 100\n",
            "loss 4.4135268338849835e-05 average time 0.012645512999961283 iter num 20\n",
            "loss 4.332289851900036e-05 average time 0.012643068274962843 iter num 40\n",
            "loss 4.280384680834093e-05 average time 0.012634517066643033 iter num 60\n",
            "loss 4.257243423987794e-05 average time 0.012641443099977324 iter num 80\n",
            "loss 4.252418450295626e-05 average time 0.01262612252998224 iter num 100\n",
            "loss 4.162746263624127e-05 average time 0.012703739100061284 iter num 20\n",
            "loss 4.086259278430868e-05 average time 0.012728402150059992 iter num 40\n",
            "loss 4.037416821958952e-05 average time 0.012721859333373687 iter num 60\n",
            "loss 4.015647568705019e-05 average time 0.0127233863000356 iter num 80\n",
            "loss 4.01111095767491e-05 average time 0.012703615740015266 iter num 100\n",
            "loss 3.926806208062623e-05 average time 0.012671617250020972 iter num 20\n",
            "loss 3.8549455811744726e-05 average time 0.012663729824998882 iter num 40\n",
            "loss 3.809084177393941e-05 average time 0.012663355433316308 iter num 60\n",
            "loss 3.788649934731589e-05 average time 0.012651036724997766 iter num 80\n",
            "loss 3.78439284081203e-05 average time 0.012659225870002046 iter num 100\n",
            "loss 4.016508039103661e-05 average time 0.012701689649998116 iter num 20\n",
            "loss 3.702447769915019e-05 average time 0.012684811700012233 iter num 40\n",
            "loss 3.602601592867388e-05 average time 0.012683361816652906 iter num 60\n",
            "loss 3.580207125558183e-05 average time 0.012699312512489768 iter num 80\n",
            "loss 3.576140605049982e-05 average time 0.012691340139977001 iter num 100\n",
            "loss 8.078731746585335e-05 average time 0.012615234550048626 iter num 20\n",
            "loss 4.22250218211953e-05 average time 0.01261633925003025 iter num 40\n",
            "loss 3.541144515283561e-05 average time 0.012661764083365295 iter num 60\n",
            "loss 3.468777293096243e-05 average time 0.012666135225032349 iter num 80\n",
            "loss 3.4621988340815126e-05 average time 0.012658936850011742 iter num 100\n",
            "loss 3.413838745080522e-05 average time 0.012619809300008455 iter num 20\n",
            "loss 3.37060110962845e-05 average time 0.012604843650024122 iter num 40\n",
            "loss 3.3441883398037535e-05 average time 0.012634783116671619 iter num 60\n",
            "loss 3.332441130759055e-05 average time 0.012639294649983413 iter num 80\n",
            "loss 3.329990377063432e-05 average time 0.012646884449973186 iter num 100\n",
            "loss 3.28433615548936e-05 average time 0.012677429199925427 iter num 20\n",
            "loss 3.2451810192563e-05 average time 0.012662605224988965 iter num 40\n",
            "loss 3.220031361155777e-05 average time 0.012651565766630787 iter num 60\n",
            "loss 3.2087765060927675e-05 average time 0.012643529712460123 iter num 80\n",
            "loss 3.2064254922949174e-05 average time 0.012631479539959401 iter num 100\n",
            "loss 3.162581914062011e-05 average time 0.012567308050006432 iter num 20\n",
            "loss 3.124910785203928e-05 average time 0.012617039074984859 iter num 40\n",
            "loss 3.1006945162564636e-05 average time 0.01262142575000477 iter num 60\n",
            "loss 3.0898545202719154e-05 average time 0.012618374350012118 iter num 80\n",
            "loss 3.087590293973983e-05 average time 0.012617156020005495 iter num 100\n",
            "loss 3.045353931068285e-05 average time 0.012596490049963905 iter num 20\n",
            "loss 3.0090607133762994e-05 average time 0.012627065874960408 iter num 40\n",
            "loss 2.9857303333931184e-05 average time 0.012671670733311657 iter num 60\n",
            "loss 2.975287306624029e-05 average time 0.012669729387494045 iter num 80\n",
            "loss 2.973105225230303e-05 average time 0.01266556674000185 iter num 100\n",
            "loss 2.9324221286615634e-05 average time 0.01266535969996312 iter num 20\n",
            "loss 2.8974682741999604e-05 average time 0.012643297650004114 iter num 40\n",
            "loss 2.8750002917618757e-05 average time 0.012651387116648038 iter num 60\n",
            "loss 2.8649436710646842e-05 average time 0.012649912962484678 iter num 80\n",
            "loss 2.8628446665080398e-05 average time 0.01265771307997511 iter num 100\n",
            "loss 2.8236750500114378e-05 average time 0.012585407349979505 iter num 20\n",
            "loss 2.790026939712531e-05 average time 0.012590465099992797 iter num 40\n",
            "loss 2.768404376916602e-05 average time 0.012605103900000358 iter num 60\n",
            "loss 2.7587272162316513e-05 average time 0.01261783699998773 iter num 80\n",
            "loss 2.7567066310387908e-05 average time 0.01261844157998894 iter num 100\n",
            "loss 2.7190174638603053e-05 average time 0.012665841299985913 iter num 20\n",
            "loss 2.6866481321719023e-05 average time 0.012595816174984975 iter num 40\n",
            "loss 2.6658468824541778e-05 average time 0.012615215699975124 iter num 60\n",
            "loss 2.65653793848175e-05 average time 0.012601112562492744 iter num 80\n",
            "loss 2.654594213623455e-05 average time 0.01259360241997456 iter num 100\n",
            "loss 2.6183396683632343e-05 average time 0.012575695100099437 iter num 20\n",
            "loss 2.5871976306809188e-05 average time 0.012612235550045625 iter num 40\n",
            "loss 2.5671831788992832e-05 average time 0.012608188450046024 iter num 60\n",
            "loss 2.5582246177139875e-05 average time 0.012600124300047356 iter num 80\n",
            "loss 2.5563547512199863e-05 average time 0.0126061861700191 iter num 100\n",
            "loss 2.527943201645136e-05 average time 0.012646995650061398 iter num 20\n",
            "loss 2.491765317381126e-05 average time 0.012633591800033627 iter num 40\n",
            "loss 2.4722390720740563e-05 average time 0.01264550663333921 iter num 60\n",
            "loss 2.4635950009819086e-05 average time 0.012645748312496607 iter num 80\n",
            "loss 2.4617929568429736e-05 average time 0.012647612189998653 iter num 100\n",
            "loss 0.00011995128239555843 average time 0.01262512245009475 iter num 20\n",
            "loss 3.471113771017935e-05 average time 0.012661620574999689 iter num 40\n",
            "loss 2.4875087106532885e-05 average time 0.012662566533322206 iter num 60\n",
            "loss 2.4162877759184635e-05 average time 0.012666952474990011 iter num 80\n",
            "loss 2.4135635510337895e-05 average time 0.012668472079990351 iter num 100\n",
            "loss 2.3913101723695178e-05 average time 0.012600042450003457 iter num 20\n",
            "loss 2.368547807523578e-05 average time 0.01260809610000706 iter num 40\n",
            "loss 2.355480553467902e-05 average time 0.01261888420002227 iter num 60\n",
            "loss 2.3498033417704873e-05 average time 0.012613152862508059 iter num 80\n",
            "loss 2.3486156776602468e-05 average time 0.012621172520020991 iter num 100\n",
            "loss 2.3264820087822964e-05 average time 0.01267911795002874 iter num 20\n",
            "loss 2.3073924265061636e-05 average time 0.012656587099991156 iter num 40\n",
            "loss 2.2950621590183414e-05 average time 0.012649912933337266 iter num 60\n",
            "loss 2.2895237261131715e-05 average time 0.012661268350001365 iter num 80\n",
            "loss 2.2883651929907334e-05 average time 0.012665095770003063 iter num 100\n",
            "loss 2.2666765283533243e-05 average time 0.012603378400012844 iter num 20\n",
            "loss 2.2478992774275623e-05 average time 0.012597788650020902 iter num 40\n",
            "loss 2.2357454780733135e-05 average time 0.0126189459167108 iter num 60\n",
            "loss 2.2302812137800685e-05 average time 0.012618465637535792 iter num 80\n",
            "loss 2.229138175090747e-05 average time 0.012618909450025058 iter num 100\n",
            "loss 2.2077206140623352e-05 average time 0.012696068000013837 iter num 20\n",
            "loss 2.189163410381094e-05 average time 0.012657506125015061 iter num 40\n",
            "loss 2.1771445267669963e-05 average time 0.012634625783365057 iter num 60\n",
            "loss 2.1717381338694402e-05 average time 0.012606210300032217 iter num 80\n",
            "loss 2.1706074538972998e-05 average time 0.012597412270019958 iter num 100\n",
            "loss 2.1494141073106492e-05 average time 0.012696397049990083 iter num 20\n",
            "loss 2.1310452879015462e-05 average time 0.012730156849988817 iter num 40\n",
            "loss 2.119145288303188e-05 average time 0.012708359749967712 iter num 60\n",
            "loss 2.113792694736637e-05 average time 0.012685235612480028 iter num 80\n",
            "loss 2.1126733537201196e-05 average time 0.012673476919999302 iter num 100\n",
            "loss 2.0916884952087373e-05 average time 0.012809990049959197 iter num 20\n",
            "loss 2.0734974354009478e-05 average time 0.012772080374975302 iter num 40\n",
            "loss 2.0617126070286103e-05 average time 0.012720694533322785 iter num 60\n",
            "loss 2.0564111840259698e-05 average time 0.012690979212487718 iter num 80\n",
            "loss 2.05530220181068e-05 average time 0.012685585879999052 iter num 100\n",
            "loss 2.034516423840249e-05 average time 0.012605977599946527 iter num 20\n",
            "loss 2.016498926993324e-05 average time 0.012631421499941098 iter num 40\n",
            "loss 2.0048275403145386e-05 average time 0.012636585266621599 iter num 60\n",
            "loss 1.9995769019700324e-05 average time 0.01262562969997134 iter num 80\n",
            "loss 1.998478189301295e-05 average time 0.012630373829988457 iter num 100\n",
            "loss 1.9778963317997087e-05 average time 0.012692920899985439 iter num 20\n",
            "loss 1.960056778880273e-05 average time 0.012739929600002142 iter num 40\n",
            "loss 1.948501421032441e-05 average time 0.0127307157833305 iter num 60\n",
            "loss 1.9433046328960838e-05 average time 0.012723140249994458 iter num 80\n",
            "loss 1.9422170299407187e-05 average time 0.01269830595998883 iter num 100\n",
            "loss 4.51989623467102e-05 average time 0.012614238199898865 iter num 20\n",
            "loss 2.1754876850472208e-05 average time 0.01260047722496438 iter num 40\n",
            "loss 1.9142296432692006e-05 average time 0.012594903366630206 iter num 60\n",
            "loss 1.894073541475186e-05 average time 0.012605776587474794 iter num 80\n",
            "loss 1.8930449047186008e-05 average time 0.012626306059964919 iter num 100\n",
            "loss 2.0138975437051026e-05 average time 0.012613251450034113 iter num 20\n",
            "loss 1.8770066612830555e-05 average time 0.012615543000038087 iter num 40\n",
            "loss 1.852709919724423e-05 average time 0.012603394616674753 iter num 60\n",
            "loss 1.8468094235145888e-05 average time 0.012610267375009698 iter num 80\n",
            "loss 1.8458749217716098e-05 average time 0.012607232740015207 iter num 100\n",
            "loss 1.847576219537793e-05 average time 0.012596583099980307 iter num 20\n",
            "loss 1.8209566601619353e-05 average time 0.012601788774952638 iter num 40\n",
            "loss 1.8041120521249494e-05 average time 0.012604366049974185 iter num 60\n",
            "loss 1.799593779917448e-05 average time 0.01260835694998832 iter num 80\n",
            "loss 1.798660882496579e-05 average time 0.012611092689999168 iter num 100\n",
            "loss 2.7452813700461385e-05 average time 0.012640434399986588 iter num 20\n",
            "loss 1.8782085567110544e-05 average time 0.012691904474991134 iter num 40\n",
            "loss 1.76529146256443e-05 average time 0.01268759856664777 iter num 60\n",
            "loss 1.761142491556418e-05 average time 0.012681683462471938 iter num 80\n",
            "loss 1.7599990198792958e-05 average time 0.012676016289983636 iter num 100\n",
            "loss 1.7473677908285083e-05 average time 0.012638617650054584 iter num 20\n",
            "loss 1.7313244624817488e-05 average time 0.012626557025043894 iter num 40\n",
            "loss 1.7223920194190497e-05 average time 0.012635994100029772 iter num 60\n",
            "loss 1.71848606240214e-05 average time 0.01263927536251117 iter num 80\n",
            "loss 1.7176712411680334e-05 average time 0.012633646660010527 iter num 100\n",
            "loss 1.702467959889676e-05 average time 0.012618070949997673 iter num 20\n",
            "loss 1.6891021255859182e-05 average time 0.012611994299993512 iter num 40\n",
            "loss 1.6804811369063377e-05 average time 0.012635112816694043 iter num 60\n",
            "loss 1.676597532822782e-05 average time 0.012633123737521146 iter num 80\n",
            "loss 1.6757847579358053e-05 average time 0.012624561640018328 iter num 100\n",
            "loss 1.8755702764019225e-05 average time 0.012674851250039865 iter num 20\n",
            "loss 1.6496206304112688e-05 average time 0.012655650899978355 iter num 40\n",
            "loss 1.639025012870896e-05 average time 0.012655239283321861 iter num 60\n",
            "loss 1.6351233353157255e-05 average time 0.012657455712491128 iter num 80\n",
            "loss 1.6343093026015042e-05 average time 0.01264519603998906 iter num 100\n",
            "loss 2.7637967272375328e-05 average time 0.012545269950055626 iter num 20\n",
            "loss 2.3105380761077642e-05 average time 0.0125566576000665 iter num 40\n",
            "loss 1.6574025745278767e-05 average time 0.012583167250022597 iter num 60\n",
            "loss 1.6253419157928278e-05 average time 0.012593972524996389 iter num 80\n",
            "loss 1.6240636146662173e-05 average time 0.01260845147000964 iter num 100\n",
            "loss 1.612383588689044e-05 average time 0.012622535200011952 iter num 20\n",
            "loss 1.600892502378771e-05 average time 0.012626459950001844 iter num 40\n",
            "loss 1.594592362319703e-05 average time 0.01263751771666648 iter num 60\n",
            "loss 1.591878221735307e-05 average time 0.01262855350000791 iter num 80\n",
            "loss 1.5913119321751852e-05 average time 0.01263032200001362 iter num 100\n",
            "loss 1.580763017022765e-05 average time 0.012663389500062294 iter num 20\n",
            "loss 1.5716686293370874e-05 average time 0.012657233075026397 iter num 40\n",
            "loss 1.5657852214931632e-05 average time 0.012663664400004866 iter num 60\n",
            "loss 1.563137985646075e-05 average time 0.012664270187485727 iter num 80\n",
            "loss 1.5625837420088094e-05 average time 0.012665090989999043 iter num 100\n",
            "loss 1.552184210637768e-05 average time 0.012662677400066968 iter num 20\n",
            "loss 1.5431396142760395e-05 average time 0.012614180549996945 iter num 40\n",
            "loss 1.5372585170902024e-05 average time 0.012604374716678043 iter num 60\n",
            "loss 1.5346061927957037e-05 average time 0.012605056537529436 iter num 80\n",
            "loss 1.534050869274335e-05 average time 0.012616210450023573 iter num 100\n",
            "loss 1.5236119477805527e-05 average time 0.01264720784995461 iter num 20\n",
            "loss 1.5145146380430836e-05 average time 0.012673901074970217 iter num 40\n",
            "loss 1.5085914618292815e-05 average time 0.012683355699967555 iter num 60\n",
            "loss 1.5059182023858295e-05 average time 0.012677536912462983 iter num 80\n",
            "loss 1.505358082696716e-05 average time 0.01267246990995318 iter num 100\n",
            "loss 1.494832180749755e-05 average time 0.012692559149991211 iter num 20\n",
            "loss 1.485653228882711e-05 average time 0.012646768524996332 iter num 40\n",
            "loss 1.479674134945321e-05 average time 0.012652827249985421 iter num 60\n",
            "loss 1.476975900718657e-05 average time 0.01264102749997278 iter num 80\n",
            "loss 1.4764105987155738e-05 average time 0.012629000319989245 iter num 100\n",
            "loss 1.4657825841557397e-05 average time 0.012609013399924152 iter num 20\n",
            "loss 1.456513405944957e-05 average time 0.012606088749964783 iter num 40\n",
            "loss 1.4504754338155063e-05 average time 0.012602111283331396 iter num 60\n",
            "loss 1.4477506192930032e-05 average time 0.012604564837499766 iter num 80\n",
            "loss 1.4471798345952718e-05 average time 0.012608832460000486 iter num 100\n",
            "loss 1.4364475150594699e-05 average time 0.012606746750020648 iter num 20\n",
            "loss 1.4270873880185422e-05 average time 0.012593471875004526 iter num 40\n",
            "loss 1.4209907904920753e-05 average time 0.01262909503334413 iter num 60\n",
            "loss 1.4182393113914018e-05 average time 0.012619589512513584 iter num 80\n",
            "loss 1.4176631346037281e-05 average time 0.012622916680011259 iter num 100\n",
            "loss 1.4068394836658914e-05 average time 0.012683740399961608 iter num 20\n",
            "loss 1.3973798386976612e-05 average time 0.01270443952498681 iter num 40\n",
            "loss 1.3912264252107546e-05 average time 0.012690935349996834 iter num 60\n",
            "loss 1.3884496298631736e-05 average time 0.012685653062510483 iter num 80\n",
            "loss 1.3878676690533613e-05 average time 0.012684521729997868 iter num 100\n",
            "loss 5.1615768042759586e-05 average time 0.01260615125008826 iter num 20\n",
            "loss 1.4211268825322388e-05 average time 0.012619673850065283 iter num 40\n",
            "loss 1.3830519544237037e-05 average time 0.012605327200041453 iter num 60\n",
            "loss 1.3636956211173474e-05 average time 0.012624691412531775 iter num 80\n",
            "loss 1.362722630821045e-05 average time 0.012636436950015196 iter num 100\n",
            "loss 1.3664756215539058e-05 average time 0.012609855499931655 iter num 20\n",
            "loss 1.3455463107922034e-05 average time 0.012629428174966506 iter num 40\n",
            "loss 1.3382301616721064e-05 average time 0.012646206199997323 iter num 60\n",
            "loss 1.3356607372032233e-05 average time 0.012645963524994386 iter num 80\n",
            "loss 1.3351207365026503e-05 average time 0.012639292869994278 iter num 100\n",
            "loss 4.135764628247399e-05 average time 0.012555790650048948 iter num 20\n",
            "loss 1.3403425603412207e-05 average time 0.01258287922502177 iter num 40\n",
            "loss 1.3181851163331496e-05 average time 0.012590739483357538 iter num 60\n",
            "loss 1.3114993643531025e-05 average time 0.012600217487522514 iter num 80\n",
            "loss 1.3106614758958867e-05 average time 0.01260250774002543 iter num 100\n",
            "loss 1.345210672925119e-05 average time 0.01255995679998705 iter num 20\n",
            "loss 1.2943627570897528e-05 average time 0.01257560654998997 iter num 40\n",
            "loss 1.287333651964448e-05 average time 0.012586098833329137 iter num 60\n",
            "loss 1.2848920184900341e-05 average time 0.01258700914999622 iter num 80\n",
            "loss 1.2843657395834081e-05 average time 0.012597442279998176 iter num 100\n",
            "loss 1.3710399469291842e-05 average time 0.012659280800039596 iter num 20\n",
            "loss 1.2718686310188296e-05 average time 0.012620850099995095 iter num 40\n",
            "loss 1.261109987744911e-05 average time 0.012608847299990582 iter num 60\n",
            "loss 1.2586072936331387e-05 average time 0.012614661287506124 iter num 80\n",
            "loss 1.2580651563600475e-05 average time 0.012620571840011507 iter num 100\n",
            "loss 0.0001224779509517098 average time 0.012591064999924129 iter num 20\n",
            "loss 2.2567114655520337e-05 average time 0.012608535349932027 iter num 40\n",
            "loss 1.2898043504547201e-05 average time 0.012626665449943175 iter num 60\n",
            "loss 1.2694802879393012e-05 average time 0.012635913574956702 iter num 80\n",
            "loss 1.2683641109986466e-05 average time 0.01265179161996457 iter num 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxMDB8zYo3G_"
      },
      "source": [
        "# 2min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "830df671-ae3b-46dd-fd7b-adfe241c33e7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = f'jax_knock_out_{str(nstock)}stocks_oldmethod_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce183ab0-88de-4101-99f1-470764f714d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65090dd0-5fab-4d64-f578-2d5694101f67"
      },
      "source": [
        "import torch\n",
        "model_save_name = f'jax_knock_out_{str(nstock)}stocks_oldmethod_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c52ef660-ceca-46ee-dce6-d3c245d72165"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net(nstock = nstock).cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=21, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (fc4): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc5): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc6): Linear(in_features=64, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moxMKMLEhJR7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a535006d-7302-486f-9ce7-6a5b7216f4dd"
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "#model = Net(nstock = nstock).cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3, eps=1e-4, amsgrad=True) # try using higher epsilon and amsgrad\n",
        "dataset = OptionDataSet(max_len = 100) # Use max_len to adjust\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x.float())\n",
        "\n",
        "    loss_weight = torch.tensor([1] * (nstock+1)).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)\n",
        "\n",
        "model_save_name = f'jax_knock_out_{str(nstock)}stocks_oldmethod_1_countinue.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 1.2756535125932428e-05 average time 0.013289664099875153 iter num 20\n",
            "loss 1.26399995867062e-05 average time 0.01304634952489323 iter num 40\n",
            "loss 1.2628776215454076e-05 average time 0.012994447549954203 iter num 60\n",
            "loss 1.2621122051964752e-05 average time 0.012920986474978236 iter num 80\n",
            "loss 1.261999394314996e-05 average time 0.012866819759947247 iter num 100\n",
            "loss 1.2598954754049982e-05 average time 0.012691140949937108 iter num 20\n",
            "loss 1.2581631534931349e-05 average time 0.012710275849963181 iter num 40\n",
            "loss 1.2570922482418698e-05 average time 0.012709633266604214 iter num 60\n",
            "loss 1.2566232378492254e-05 average time 0.012731959262441705 iter num 80\n",
            "loss 1.256528677392435e-05 average time 0.012749968029947923 iter num 100\n",
            "loss 1.2547580695540954e-05 average time 0.012626620650007681 iter num 20\n",
            "loss 1.2532822540756025e-05 average time 0.012671893400010958 iter num 40\n",
            "loss 1.2523562315248027e-05 average time 0.012670688533338156 iter num 60\n",
            "loss 1.2519478759212804e-05 average time 0.012692107250006756 iter num 80\n",
            "loss 1.2518654575434167e-05 average time 0.01269126312005028 iter num 100\n",
            "loss 1.2503121927773567e-05 average time 0.012675672199975452 iter num 20\n",
            "loss 1.2489997652705741e-05 average time 0.012671577299965976 iter num 40\n",
            "loss 1.248166230182377e-05 average time 0.012677942216608546 iter num 60\n",
            "loss 1.2477963143282691e-05 average time 0.01268186951244843 iter num 80\n",
            "loss 1.2477223572653454e-05 average time 0.01267810861993894 iter num 100\n",
            "loss 1.2463077098086385e-05 average time 0.012707872549935929 iter num 20\n",
            "loss 1.2451004201519415e-05 average time 0.012709715099958885 iter num 40\n",
            "loss 1.2443277477039293e-05 average time 0.012694433199931155 iter num 60\n",
            "loss 1.2439836645468888e-05 average time 0.01269570343745272 iter num 80\n",
            "loss 1.2439139548847955e-05 average time 0.01268963818993143 iter num 100\n",
            "loss 1.2425914272175417e-05 average time 0.012637940649938173 iter num 20\n",
            "loss 1.2414544117079464e-05 average time 0.012662422874973345 iter num 40\n",
            "loss 1.2407236584838436e-05 average time 0.012657415566642764 iter num 60\n",
            "loss 1.2403971345922487e-05 average time 0.012663149837442234 iter num 80\n",
            "loss 1.2403307832313181e-05 average time 0.012668170209944946 iter num 100\n",
            "loss 1.2390718142736004e-05 average time 0.012633933949973652 iter num 20\n",
            "loss 1.2379847887902461e-05 average time 0.012687350124997466 iter num 40\n",
            "loss 1.2372831126950323e-05 average time 0.012705701866661912 iter num 60\n",
            "loss 1.2369695068111892e-05 average time 0.012712775062470882 iter num 80\n",
            "loss 1.236906483289128e-05 average time 0.012719258999986778 iter num 100\n",
            "loss 1.2356931387461266e-05 average time 0.012772899900028278 iter num 20\n",
            "loss 1.234642821596627e-05 average time 0.012775176925038068 iter num 40\n",
            "loss 1.2339642853912445e-05 average time 0.012789897149999282 iter num 60\n",
            "loss 1.233659590363121e-05 average time 0.01278704014999903 iter num 80\n",
            "loss 1.2335983976303252e-05 average time 0.01279271656999299 iter num 100\n",
            "loss 1.2324208287015078e-05 average time 0.01287077679990034 iter num 20\n",
            "loss 1.231399983488578e-05 average time 0.0128221134499654 iter num 40\n",
            "loss 1.2307380787109427e-05 average time 0.012789755899954494 iter num 60\n",
            "loss 1.2304413773718121e-05 average time 0.012753017762463514 iter num 80\n",
            "loss 1.2303818678673189e-05 average time 0.012736346699985007 iter num 100\n",
            "loss 1.2292330189383834e-05 average time 0.012714373350036112 iter num 20\n",
            "loss 1.2282344749815194e-05 average time 0.012677831375026472 iter num 40\n",
            "loss 1.2275875005603095e-05 average time 0.012669742066721786 iter num 60\n",
            "loss 1.2272971655778532e-05 average time 0.012693055175054724 iter num 80\n",
            "loss 1.227238734612386e-05 average time 0.012704472180002995 iter num 100\n",
            "loss 1.2261133796562378e-05 average time 0.012712858500071889 iter num 20\n",
            "loss 1.2251343831000731e-05 average time 0.012668115200017382 iter num 40\n",
            "loss 1.2244992060795338e-05 average time 0.012680551650025034 iter num 60\n",
            "loss 1.2242142489538293e-05 average time 0.012697647812524337 iter num 80\n",
            "loss 1.2241564423489018e-05 average time 0.012706198839996432 iter num 100\n",
            "loss 1.2230510288118303e-05 average time 0.012745629699975326 iter num 20\n",
            "loss 1.2220888686821226e-05 average time 0.01276955032501519 iter num 40\n",
            "loss 1.2214644814035248e-05 average time 0.012735397550022754 iter num 60\n",
            "loss 1.2211833563251686e-05 average time 0.012736380025000927 iter num 80\n",
            "loss 1.2211270433959235e-05 average time 0.012732749279975905 iter num 100\n",
            "loss 1.220038499006315e-05 average time 0.012655058049995204 iter num 20\n",
            "loss 1.21909082639818e-05 average time 0.012678179800036559 iter num 40\n",
            "loss 1.218474795610812e-05 average time 0.012684638483369782 iter num 60\n",
            "loss 1.2181985342191536e-05 average time 0.01266977071254587 iter num 80\n",
            "loss 1.2181432913425984e-05 average time 0.01266869508003765 iter num 100\n",
            "loss 1.2170699258266941e-05 average time 0.012682179999956134 iter num 20\n",
            "loss 1.2161347817192068e-05 average time 0.012660440675017526 iter num 40\n",
            "loss 1.2155269317303769e-05 average time 0.01265950203334493 iter num 60\n",
            "loss 1.2152542175126519e-05 average time 0.012668852587501079 iter num 80\n",
            "loss 1.2151992140946326e-05 average time 0.012666636419971837 iter num 100\n",
            "loss 1.2141392422721754e-05 average time 0.01269397150003897 iter num 20\n",
            "loss 1.213216021908717e-05 average time 0.012670913325018773 iter num 40\n",
            "loss 1.2126153782474333e-05 average time 0.012670857400022821 iter num 60\n",
            "loss 1.2123455936299243e-05 average time 0.012675048899984631 iter num 80\n",
            "loss 1.212291629097776e-05 average time 0.01265811260999726 iter num 100\n",
            "loss 1.2112439267411884e-05 average time 0.012708574500038594 iter num 20\n",
            "loss 1.2103306130723396e-05 average time 0.01271654070005752 iter num 40\n",
            "loss 1.2097371376963293e-05 average time 0.012694532683387176 iter num 60\n",
            "loss 1.2094700884983663e-05 average time 0.012684557987540757 iter num 80\n",
            "loss 1.2094166883255109e-05 average time 0.012889530120028213 iter num 100\n",
            "loss 1.2083799407842566e-05 average time 0.012703051499875074 iter num 20\n",
            "loss 1.2074761355426834e-05 average time 0.012698215199861806 iter num 40\n",
            "loss 1.2068884008320024e-05 average time 0.012675877783234075 iter num 60\n",
            "loss 1.2066243218613838e-05 average time 0.012669959724939872 iter num 80\n",
            "loss 1.2065713977514078e-05 average time 0.012666080929939198 iter num 100\n",
            "loss 1.2055455330357063e-05 average time 0.01267916565016094 iter num 20\n",
            "loss 1.204649961346225e-05 average time 0.012678997025136595 iter num 40\n",
            "loss 1.2040684141480267e-05 average time 0.01267638005013699 iter num 60\n",
            "loss 1.2038064127724241e-05 average time 0.012662408200139908 iter num 80\n",
            "loss 1.2037536648188385e-05 average time 0.01265354208010649 iter num 100\n",
            "loss 1.202737091047599e-05 average time 0.012690464300112581 iter num 20\n",
            "loss 1.2018507000030382e-05 average time 0.012679698750048374 iter num 40\n",
            "loss 1.2012727955496758e-05 average time 0.012681313566690732 iter num 60\n",
            "loss 1.2010138506306527e-05 average time 0.012672829537507369 iter num 80\n",
            "loss 1.200961529173161e-05 average time 0.012662831790021301 iter num 100\n",
            "loss 1.1999541769374501e-05 average time 0.012633466699981 iter num 20\n",
            "loss 1.199074670209369e-05 average time 0.012660253525064035 iter num 40\n",
            "loss 1.198503055777699e-05 average time 0.012668655550078256 iter num 60\n",
            "loss 1.1982455106041616e-05 average time 0.012658508150059334 iter num 80\n",
            "loss 1.198193798077396e-05 average time 0.012668871330042748 iter num 100\n",
            "loss 1.1971939901127534e-05 average time 0.012732178549913441 iter num 20\n",
            "loss 1.1963221182697273e-05 average time 0.012738352275027865 iter num 40\n",
            "loss 1.1957545813030536e-05 average time 0.01276170383336345 iter num 60\n",
            "loss 1.195499875465095e-05 average time 0.01277577925005744 iter num 80\n",
            "loss 1.1954485009318085e-05 average time 0.012771255870029563 iter num 100\n",
            "loss 1.1944568766766669e-05 average time 0.01269233109992456 iter num 20\n",
            "loss 1.1935911732168865e-05 average time 0.012691577024861544 iter num 40\n",
            "loss 1.1930283596465824e-05 average time 0.01268212013324046 iter num 60\n",
            "loss 1.1927745041087797e-05 average time 0.012671203299919397 iter num 80\n",
            "loss 1.1927237744751458e-05 average time 0.012657673159919796 iter num 100\n",
            "loss 1.1917398547964536e-05 average time 0.012708225700089315 iter num 20\n",
            "loss 1.1908806635285019e-05 average time 0.01268926187510715 iter num 40\n",
            "loss 1.1903219815833954e-05 average time 0.012686823566734043 iter num 60\n",
            "loss 1.1900701559710168e-05 average time 0.01270441470003334 iter num 80\n",
            "loss 1.1900196453989472e-05 average time 0.012715589650024412 iter num 100\n",
            "loss 1.1890424043801998e-05 average time 0.012790130100074747 iter num 20\n",
            "loss 1.188189492940361e-05 average time 0.012766966150070402 iter num 40\n",
            "loss 1.1876337793447459e-05 average time 0.012741367666709873 iter num 60\n",
            "loss 1.187384748493749e-05 average time 0.012718105500027832 iter num 80\n",
            "loss 1.1873344366491023e-05 average time 0.012716736370011859 iter num 100\n",
            "loss 1.186364478867818e-05 average time 0.012750487400080602 iter num 20\n",
            "loss 1.1855169545351234e-05 average time 0.012735115450050216 iter num 40\n",
            "loss 1.184965992781452e-05 average time 0.012762800600042586 iter num 60\n",
            "loss 1.1847174260401573e-05 average time 0.012763022912542965 iter num 80\n",
            "loss 1.1846678161932773e-05 average time 0.012747318010042363 iter num 100\n",
            "loss 1.1837044791509086e-05 average time 0.012759682899923065 iter num 20\n",
            "loss 1.1828619194954207e-05 average time 0.012719437650025612 iter num 40\n",
            "loss 1.1823145194861486e-05 average time 0.012721420416710316 iter num 60\n",
            "loss 1.1820677495908945e-05 average time 0.012710839825001586 iter num 80\n",
            "loss 1.182018697633934e-05 average time 0.012706468839969603 iter num 100\n",
            "loss 1.1810610161700808e-05 average time 0.01269947530004174 iter num 20\n",
            "loss 1.1802249600163417e-05 average time 0.012703777799993076 iter num 40\n",
            "loss 1.1796803235680612e-05 average time 0.012710547733301306 iter num 60\n",
            "loss 1.1794352290530565e-05 average time 0.012703766874983558 iter num 80\n",
            "loss 1.1793858967973054e-05 average time 0.0127019382600065 iter num 100\n",
            "loss 1.1784344371353419e-05 average time 0.012643327599926124 iter num 20\n",
            "loss 1.1776031841952176e-05 average time 0.012663641524932245 iter num 40\n",
            "loss 1.1770625789866357e-05 average time 0.01267397543332057 iter num 60\n",
            "loss 1.176818412185394e-05 average time 0.012697817062496597 iter num 80\n",
            "loss 1.1767698763098227e-05 average time 0.012699721020017023 iter num 100\n",
            "loss 1.1758236431120573e-05 average time 0.012675921749996632 iter num 20\n",
            "loss 1.1749977573466442e-05 average time 0.012700124050047635 iter num 40\n",
            "loss 1.1744596037338102e-05 average time 0.012705798083394863 iter num 60\n",
            "loss 1.1742174592491027e-05 average time 0.012718906225063619 iter num 80\n",
            "loss 1.1741690016131328e-05 average time 0.0127155916900756 iter num 100\n",
            "loss 1.1732287725425264e-05 average time 0.012694120800006203 iter num 20\n",
            "loss 1.1724078526092965e-05 average time 0.012679162199970052 iter num 40\n",
            "loss 1.1718724777624595e-05 average time 0.012674585433311828 iter num 60\n",
            "loss 1.1716316889198436e-05 average time 0.012665695150008104 iter num 80\n",
            "loss 1.1715834052346513e-05 average time 0.012670133539977542 iter num 100\n",
            "loss 1.1706487263589655e-05 average time 0.012648031599974274 iter num 20\n",
            "loss 1.169832139052351e-05 average time 0.012670713974921454 iter num 40\n",
            "loss 1.169300291843444e-05 average time 0.012675667916634362 iter num 60\n",
            "loss 1.1690611548081996e-05 average time 0.0126699203874864 iter num 80\n",
            "loss 1.1690130413542834e-05 average time 0.012668696330019885 iter num 100\n",
            "loss 1.1680833137279635e-05 average time 0.012745583849982723 iter num 20\n",
            "loss 1.1672706411127523e-05 average time 0.012717006200000469 iter num 40\n",
            "loss 1.1667416640449175e-05 average time 0.012703006633349409 iter num 60\n",
            "loss 1.166504231035731e-05 average time 0.012698464312506985 iter num 80\n",
            "loss 1.1664567610868693e-05 average time 0.01270298231002016 iter num 100\n",
            "loss 1.1655317942154303e-05 average time 0.01268384969998806 iter num 20\n",
            "loss 1.1647238933258292e-05 average time 0.012676241799977107 iter num 40\n",
            "loss 1.1641977538514856e-05 average time 0.012690623383347581 iter num 60\n",
            "loss 1.163961321637149e-05 average time 0.012688804749973314 iter num 80\n",
            "loss 1.1639139665242541e-05 average time 0.012695945139957985 iter num 100\n",
            "loss 1.1629941626605766e-05 average time 0.012733166600082769 iter num 20\n",
            "loss 1.1621908337341781e-05 average time 0.01273842250002417 iter num 40\n",
            "loss 1.161667481435039e-05 average time 0.01273462558334965 iter num 60\n",
            "loss 1.1614325048634267e-05 average time 0.012717495550032255 iter num 80\n",
            "loss 1.1613853328812541e-05 average time 0.012719211240037111 iter num 100\n",
            "loss 1.1604700536461742e-05 average time 0.012720079299924691 iter num 20\n",
            "loss 1.1596713340201777e-05 average time 0.0127390534749793 iter num 40\n",
            "loss 1.159150658116242e-05 average time 0.012737334450018048 iter num 60\n",
            "loss 1.1589161162698076e-05 average time 0.01272421670003041 iter num 80\n",
            "loss 1.1588695440978745e-05 average time 0.012715825639988907 iter num 100\n",
            "loss 1.1579598071446903e-05 average time 0.012582845050110337 iter num 20\n",
            "loss 1.1571646453161351e-05 average time 0.012609066575123506 iter num 40\n",
            "loss 1.1566464434836447e-05 average time 0.01261997608336666 iter num 60\n",
            "loss 1.1564140030013877e-05 average time 0.01262574961252767 iter num 80\n",
            "loss 1.156367039787459e-05 average time 0.012635915550017671 iter num 100\n",
            "loss 1.155461540685542e-05 average time 0.012649777100068604 iter num 20\n",
            "loss 1.1546705558726374e-05 average time 0.012674830175069474 iter num 40\n",
            "loss 1.1541556986268387e-05 average time 0.012678258816686138 iter num 60\n",
            "loss 1.1539236317861854e-05 average time 0.012671371237536278 iter num 80\n",
            "loss 1.1538776132077976e-05 average time 0.012673052500022096 iter num 100\n",
            "loss 1.1529772192433274e-05 average time 0.012706472900072185 iter num 20\n",
            "loss 1.1521892791667793e-05 average time 0.012673616725010106 iter num 40\n",
            "loss 1.1516769051219291e-05 average time 0.012666803683381052 iter num 60\n",
            "loss 1.1514460205449673e-05 average time 0.012663094700042166 iter num 80\n",
            "loss 1.151400471525321e-05 average time 0.012672384950064952 iter num 100\n",
            "loss 1.1505038430940602e-05 average time 0.012752947049966679 iter num 20\n",
            "loss 1.149720920269884e-05 average time 0.012719499874992834 iter num 40\n",
            "loss 1.149210958136301e-05 average time 0.012725514283329176 iter num 60\n",
            "loss 1.1489812389070892e-05 average time 0.012719957650017478 iter num 80\n",
            "loss 1.1489354506237979e-05 average time 0.012717525960033527 iter num 100\n",
            "loss 1.1480434188208477e-05 average time 0.012717873899964616 iter num 20\n",
            "loss 1.1472639528700214e-05 average time 0.01268256385001223 iter num 40\n",
            "loss 1.1467570508402619e-05 average time 0.012686514300003181 iter num 60\n",
            "loss 1.1465287080144912e-05 average time 0.012675663912511936 iter num 80\n",
            "loss 1.1464827883513582e-05 average time 0.012666240780026783 iter num 100\n",
            "loss 1.1455951716831809e-05 average time 0.012670129100069972 iter num 20\n",
            "loss 1.144820236747294e-05 average time 0.01264976104996549 iter num 40\n",
            "loss 1.1443146502442954e-05 average time 0.012673674183270122 iter num 60\n",
            "loss 1.1440874186790561e-05 average time 0.012663645162467674 iter num 80\n",
            "loss 1.144041667175615e-05 average time 0.012658902699977262 iter num 100\n",
            "loss 1.1431587784939947e-05 average time 0.012730496349968234 iter num 20\n",
            "loss 1.1423875630792038e-05 average time 0.01273045347502375 iter num 40\n",
            "loss 1.1418841293177157e-05 average time 0.012732588133333896 iter num 60\n",
            "loss 1.1416582559478481e-05 average time 0.01272909627498393 iter num 80\n",
            "loss 1.1416125817785122e-05 average time 0.012719490609961213 iter num 100\n",
            "loss 1.140734192100984e-05 average time 0.012687196400020185 iter num 20\n",
            "loss 1.1399656914048417e-05 average time 0.012707289399963883 iter num 40\n",
            "loss 1.1394655104667744e-05 average time 0.01272461116662574 iter num 60\n",
            "loss 1.1392406481823565e-05 average time 0.012735869187463323 iter num 80\n",
            "loss 1.1391955617271404e-05 average time 0.012740339239971945 iter num 100\n",
            "loss 1.1383210602955013e-05 average time 0.012650653050013717 iter num 20\n",
            "loss 1.1375562389504336e-05 average time 0.0126610240750324 iter num 40\n",
            "loss 1.1370581883542133e-05 average time 0.01267419596668636 iter num 60\n",
            "loss 1.1368340969753398e-05 average time 0.012701893162511625 iter num 80\n",
            "loss 1.136789766309058e-05 average time 0.012688933440012989 iter num 100\n",
            "loss 1.1359183040693024e-05 average time 0.012678277199984222 iter num 20\n",
            "loss 1.1351576337593556e-05 average time 0.012671215549971748 iter num 40\n",
            "loss 1.134661611710435e-05 average time 0.012680695883333707 iter num 60\n",
            "loss 1.1344392636046055e-05 average time 0.012693386149976504 iter num 80\n",
            "loss 1.1343944233971807e-05 average time 0.012699796919978325 iter num 100\n",
            "loss 1.1335277953021607e-05 average time 0.0127411428499272 iter num 20\n",
            "loss 1.1327697971082054e-05 average time 0.012701229249955759 iter num 40\n",
            "loss 1.1322769560740193e-05 average time 0.012677316666637732 iter num 60\n",
            "loss 1.132055061777309e-05 average time 0.012687102162476548 iter num 80\n",
            "loss 1.1320103842670462e-05 average time 0.012695020289975219 iter num 100\n",
            "loss 1.1311476869425564e-05 average time 0.012745901600010257 iter num 20\n",
            "loss 1.1303936945345145e-05 average time 0.01278682422496331 iter num 40\n",
            "loss 1.12990209901109e-05 average time 0.012817399649945098 iter num 60\n",
            "loss 1.1296819578650089e-05 average time 0.0127931653749215 iter num 80\n",
            "loss 1.1296377000393606e-05 average time 0.012781643549915315 iter num 100\n",
            "loss 1.128778066718588e-05 average time 0.012790042549977444 iter num 20\n",
            "loss 1.1280277636057768e-05 average time 0.012815381100017476 iter num 40\n",
            "loss 1.1275390576803516e-05 average time 0.012813680299980963 iter num 60\n",
            "loss 1.1273186851597712e-05 average time 0.012813959149968922 iter num 80\n",
            "loss 1.1272751343017689e-05 average time 0.01281146843993156 iter num 100\n",
            "loss 1.1264198623677915e-05 average time 0.012778113700051108 iter num 20\n",
            "loss 1.1256724123668817e-05 average time 0.012776262549891726 iter num 40\n",
            "loss 1.1251853126602221e-05 average time 0.012755703333217147 iter num 60\n",
            "loss 1.1249668049721043e-05 average time 0.012781299749917707 iter num 80\n",
            "loss 1.1249232526964313e-05 average time 0.012785959719922175 iter num 100\n",
            "loss 1.1240715801068655e-05 average time 0.012776106799947229 iter num 20\n",
            "loss 1.1233278647830943e-05 average time 0.012783881650011607 iter num 40\n",
            "loss 1.1228430500045099e-05 average time 0.012775855783305208 iter num 60\n",
            "loss 1.1226247689203143e-05 average time 0.01278808543750074 iter num 80\n",
            "loss 1.122581751655581e-05 average time 0.012784485730016969 iter num 100\n",
            "loss 1.1217340159028313e-05 average time 0.012675945899991348 iter num 20\n",
            "loss 1.1209927882810182e-05 average time 0.012714444999937768 iter num 40\n",
            "loss 1.1205104729527919e-05 average time 0.012754797799955971 iter num 60\n",
            "loss 1.120293501037697e-05 average time 0.012751114812465403 iter num 80\n",
            "loss 1.12025039407483e-05 average time 0.012748661239966168 iter num 100\n",
            "loss 1.1194059787187431e-05 average time 0.012773766850159518 iter num 20\n",
            "loss 1.1186686494372781e-05 average time 0.012743154125087131 iter num 40\n",
            "loss 1.118188406928749e-05 average time 0.012728772433335204 iter num 60\n",
            "loss 1.117972368055019e-05 average time 0.01272079033750515 iter num 80\n",
            "loss 1.1179294819290907e-05 average time 0.012717400499996074 iter num 100\n",
            "loss 1.1170889991830446e-05 average time 0.012732011299976875 iter num 20\n",
            "loss 1.116354967322991e-05 average time 0.012737625875001869 iter num 40\n",
            "loss 1.1158765365019768e-05 average time 0.012718498300015806 iter num 60\n",
            "loss 1.1156610260890374e-05 average time 0.01271183513753158 iter num 80\n",
            "loss 1.1156182378194875e-05 average time 0.012704331450013342 iter num 100\n",
            "loss 1.1147812828934094e-05 average time 0.013003904700008206 iter num 20\n",
            "loss 1.1140504059675836e-05 average time 0.012855719849972047 iter num 40\n",
            "loss 1.1135740922274893e-05 average time 0.01281398216665366 iter num 60\n",
            "loss 1.1133599051917989e-05 average time 0.012785927100003392 iter num 80\n",
            "loss 1.1133171845974252e-05 average time 0.012787593450020722 iter num 100\n",
            "loss 1.1124839537708084e-05 average time 0.012797915100145473 iter num 20\n",
            "loss 1.1117560096336985e-05 average time 0.012788215174987272 iter num 40\n",
            "loss 1.1112816853696625e-05 average time 0.012770839799986788 iter num 60\n",
            "loss 1.111068978537068e-05 average time 0.0127539673624824 iter num 80\n",
            "loss 1.111026141403121e-05 average time 0.012747400930002185 iter num 100\n",
            "loss 1.1101963131675743e-05 average time 0.01272424135008805 iter num 20\n",
            "loss 1.1094716709236964e-05 average time 0.01272484600003736 iter num 40\n",
            "loss 1.1089998560481684e-05 average time 0.012701030716743843 iter num 60\n",
            "loss 1.1087873715538006e-05 average time 0.012704562600049485 iter num 80\n",
            "loss 1.108744782848983e-05 average time 0.012702238100046089 iter num 100\n",
            "loss 1.1079190463027555e-05 average time 0.012685495149980852 iter num 20\n",
            "loss 1.1071974887090994e-05 average time 0.012680988224951761 iter num 40\n",
            "loss 1.1067270324898153e-05 average time 0.012682345100013965 iter num 60\n",
            "loss 1.106515585793031e-05 average time 0.012691240824983652 iter num 80\n",
            "loss 1.1064730207258672e-05 average time 0.012678230189967507 iter num 100\n",
            "loss 1.1056508245841354e-05 average time 0.012712270499923762 iter num 20\n",
            "loss 1.104932054825654e-05 average time 0.012725633499985633 iter num 40\n",
            "loss 1.10446405759253e-05 average time 0.012721603616622208 iter num 60\n",
            "loss 1.1042530375524663e-05 average time 0.012721105187461034 iter num 80\n",
            "loss 1.1042110600814096e-05 average time 0.012741411329952825 iter num 100\n",
            "loss 1.1033925311670453e-05 average time 0.012769084899991867 iter num 20\n",
            "loss 1.102676365559379e-05 average time 0.01273988985003598 iter num 40\n",
            "loss 1.1022104222449427e-05 average time 0.012750779250063715 iter num 60\n",
            "loss 1.1020001957025983e-05 average time 0.012750665887551804 iter num 80\n",
            "loss 1.1019584160580636e-05 average time 0.012754875150048974 iter num 100\n",
            "loss 1.1011431798436623e-05 average time 0.012752517599938073 iter num 20\n",
            "loss 1.1004304059300673e-05 average time 0.012731770600021263 iter num 40\n",
            "loss 1.0999655998438653e-05 average time 0.012744270266678844 iter num 60\n",
            "loss 1.0997571851509227e-05 average time 0.012746587287495004 iter num 80\n",
            "loss 1.0997153414394114e-05 average time 0.012740234980010428 iter num 100\n",
            "loss 1.098902934116844e-05 average time 0.012719733399944744 iter num 20\n",
            "loss 1.0981935910392312e-05 average time 0.012661276024937251 iter num 40\n",
            "loss 1.09773124177705e-05 average time 0.012676615266642936 iter num 60\n",
            "loss 1.0975229856237633e-05 average time 0.0126958495624649 iter num 80\n",
            "loss 1.0974814733070231e-05 average time 0.01269023924000976 iter num 100\n",
            "loss 1.096672346629399e-05 average time 0.012784205049956653 iter num 20\n",
            "loss 1.0959655787374851e-05 average time 0.012721759899932295 iter num 40\n",
            "loss 1.0955051892669326e-05 average time 0.012721479433275817 iter num 60\n",
            "loss 1.095298193837122e-05 average time 0.012715386749925983 iter num 80\n",
            "loss 1.0952566776241174e-05 average time 0.012719115019954187 iter num 100\n",
            "loss 1.0944511378713818e-05 average time 0.012672165999993013 iter num 20\n",
            "loss 1.0937472853111511e-05 average time 0.012659463300042261 iter num 40\n",
            "loss 1.0932884213504717e-05 average time 0.012678228183358443 iter num 60\n",
            "loss 1.093082153368652e-05 average time 0.012689006687514848 iter num 80\n",
            "loss 1.0930411407699073e-05 average time 0.012697665939995204 iter num 100\n",
            "loss 1.0922387861962631e-05 average time 0.01277520285011633 iter num 20\n",
            "loss 1.0915374413183637e-05 average time 0.012732289725113333 iter num 40\n",
            "loss 1.0910805261525042e-05 average time 0.012784588400108987 iter num 60\n",
            "loss 1.0908750250127157e-05 average time 0.012772955425066356 iter num 80\n",
            "loss 1.0908342204072008e-05 average time 0.012764217650028513 iter num 100\n",
            "loss 1.090035283885086e-05 average time 0.012684643699958541 iter num 20\n",
            "loss 1.0893367271646884e-05 average time 0.012692364724989602 iter num 40\n",
            "loss 1.0888818088434128e-05 average time 0.012673908683321617 iter num 60\n",
            "loss 1.088677163843539e-05 average time 0.01266545517501072 iter num 80\n",
            "loss 1.0886369585721492e-05 average time 0.012667662770027163 iter num 100\n",
            "loss 1.0878405144713737e-05 average time 0.012770025349936986 iter num 20\n",
            "loss 1.0871450767966903e-05 average time 0.012752343299916901 iter num 40\n",
            "loss 1.0866918419405201e-05 average time 0.012740743449921866 iter num 60\n",
            "loss 1.0864883375633581e-05 average time 0.01272529063745651 iter num 80\n",
            "loss 1.086447323410176e-05 average time 0.012711926539968771 iter num 100\n",
            "loss 1.085654801865498e-05 average time 0.01267446165002184 iter num 20\n",
            "loss 1.0849618723323976e-05 average time 0.012701905799940506 iter num 40\n",
            "loss 1.0845102021778987e-05 average time 0.012708944116623874 iter num 60\n",
            "loss 1.0843073791821094e-05 average time 0.012693551074994503 iter num 80\n",
            "loss 1.0842667735100423e-05 average time 0.012700483269982214 iter num 100\n",
            "loss 1.0834779034513753e-05 average time 0.012686472949962991 iter num 20\n",
            "loss 1.0827871925464862e-05 average time 0.012676489424961801 iter num 40\n",
            "loss 1.0823376883906256e-05 average time 0.012676361816678158 iter num 60\n",
            "loss 1.0821355546825773e-05 average time 0.012667178074968888 iter num 80\n",
            "loss 1.0820952613768331e-05 average time 0.01266889826998522 iter num 100\n",
            "loss 1.0813087470923245e-05 average time 0.012690449599813292 iter num 20\n",
            "loss 1.0806214884002222e-05 average time 0.012691178999921249 iter num 40\n",
            "loss 1.080173517937952e-05 average time 0.012691080083277484 iter num 60\n",
            "loss 1.0799727942854049e-05 average time 0.012669117687448762 iter num 80\n",
            "loss 1.0799324701286572e-05 average time 0.012672755789972144 iter num 100\n",
            "loss 1.0791491166608411e-05 average time 0.012706870199917831 iter num 20\n",
            "loss 1.0784648588961142e-05 average time 0.012653034849950017 iter num 40\n",
            "loss 1.0780184844764104e-05 average time 0.012676128133337745 iter num 60\n",
            "loss 1.077817810188179e-05 average time 0.012690282550011034 iter num 80\n",
            "loss 1.0777778299176374e-05 average time 0.012700639960021362 iter num 100\n",
            "loss 1.0769973863699142e-05 average time 0.012710889400023007 iter num 20\n",
            "loss 1.0763157065420886e-05 average time 0.012740417975101082 iter num 40\n",
            "loss 1.0758710828848044e-05 average time 0.012765618916728273 iter num 60\n",
            "loss 1.0756713425700017e-05 average time 0.012731031775047086 iter num 80\n",
            "loss 1.075631764441025e-05 average time 0.012720000070048627 iter num 100\n",
            "loss 1.0748545642445505e-05 average time 0.012699885599977279 iter num 20\n",
            "loss 1.0741750874661965e-05 average time 0.01271099895000134 iter num 40\n",
            "loss 1.0737325706874105e-05 average time 0.012700962716674742 iter num 60\n",
            "loss 1.073533495667547e-05 average time 0.01268956817501703 iter num 80\n",
            "loss 1.0734940549581472e-05 average time 0.012695214839986875 iter num 100\n",
            "loss 1.0727193248391204e-05 average time 0.012823885100033294 iter num 20\n",
            "loss 1.0720429484985766e-05 average time 0.012745339775051434 iter num 40\n",
            "loss 1.0716020014966686e-05 average time 0.012757734316710411 iter num 60\n",
            "loss 1.0714033303248328e-05 average time 0.01273728420005682 iter num 80\n",
            "loss 1.0713643276885846e-05 average time 0.012738686290049372 iter num 100\n",
            "loss 1.0705935460334214e-05 average time 0.012677385099868843 iter num 20\n",
            "loss 1.069919472964563e-05 average time 0.012716269224961252 iter num 40\n",
            "loss 1.0694803426239128e-05 average time 0.012728716799983886 iter num 60\n",
            "loss 1.069282760856166e-05 average time 0.012728820574977817 iter num 80\n",
            "loss 1.0692431556522941e-05 average time 0.012726681320000353 iter num 100\n",
            "loss 1.0684749695732772e-05 average time 0.012674404850031351 iter num 20\n",
            "loss 1.0678031681252618e-05 average time 0.012714816374978 iter num 40\n",
            "loss 1.0673660603270658e-05 average time 0.012721677333365733 iter num 60\n",
            "loss 1.0671695586592022e-05 average time 0.012727154450010403 iter num 80\n",
            "loss 1.067130165810858e-05 average time 0.01272118184001556 iter num 100\n",
            "loss 1.0663645060154766e-05 average time 0.012703778649847664 iter num 20\n",
            "loss 1.0656959577584168e-05 average time 0.012731101449912786 iter num 40\n",
            "loss 1.0652602115977227e-05 average time 0.012721258249939638 iter num 60\n",
            "loss 1.0650641859783878e-05 average time 0.012722941412448563 iter num 80\n",
            "loss 1.0650249027636462e-05 average time 0.012728142309952091 iter num 100\n",
            "loss 1.064262182900434e-05 average time 0.012673638399974152 iter num 20\n",
            "loss 1.0635963268769226e-05 average time 0.012669491450014902 iter num 40\n",
            "loss 1.0631617752864286e-05 average time 0.012677276016696245 iter num 60\n",
            "loss 1.0629661496461092e-05 average time 0.012695028375048878 iter num 80\n",
            "loss 1.0629275947747164e-05 average time 0.012694334100033303 iter num 100\n",
            "loss 1.0621684231833963e-05 average time 0.012758540749928216 iter num 20\n",
            "loss 1.0615043389990195e-05 average time 0.012732307124952057 iter num 40\n",
            "loss 1.0610718419020549e-05 average time 0.012743131983249138 iter num 60\n",
            "loss 1.060877486402529e-05 average time 0.012756710849976116 iter num 80\n",
            "loss 1.0608389535224305e-05 average time 0.012747645350018502 iter num 100\n",
            "loss 1.0600816519893921e-05 average time 0.01277483230010148 iter num 20\n",
            "loss 1.059420548298755e-05 average time 0.012779326425038562 iter num 40\n",
            "loss 1.0589892338298918e-05 average time 0.012768931383379822 iter num 60\n",
            "loss 1.0587957287917937e-05 average time 0.012768628650030677 iter num 80\n",
            "loss 1.05875689595604e-05 average time 0.012764421470028537 iter num 100\n",
            "loss 1.0580037094756656e-05 average time 0.01270401029983077 iter num 20\n",
            "loss 1.0573446553922446e-05 average time 0.01274911109990171 iter num 40\n",
            "loss 1.0569149115366742e-05 average time 0.012732982066609111 iter num 60\n",
            "loss 1.0567224874692102e-05 average time 0.012739666362460867 iter num 80\n",
            "loss 1.0566833899890523e-05 average time 0.012738242839959639 iter num 100\n",
            "loss 1.055932870780034e-05 average time 0.012717863400030182 iter num 20\n",
            "loss 1.0552763964807629e-05 average time 0.01269761122498494 iter num 40\n",
            "loss 1.0548484096031036e-05 average time 0.012700895600088795 iter num 60\n",
            "loss 1.0546560944722245e-05 average time 0.012704264887588579 iter num 80\n",
            "loss 1.054618100732381e-05 average time 0.012705695560089224 iter num 100\n",
            "loss 1.0538697156212765e-05 average time 0.012698799550116746 iter num 20\n",
            "loss 1.053215813089885e-05 average time 0.01269211114997688 iter num 40\n",
            "loss 1.0527897108553786e-05 average time 0.012704660566608557 iter num 60\n",
            "loss 1.0525983654820937e-05 average time 0.012718173987434512 iter num 80\n",
            "loss 1.0525600704446497e-05 average time 0.01270494126993981 iter num 100\n",
            "loss 1.0518143535479011e-05 average time 0.0127279478499986 iter num 20\n",
            "loss 1.0511625192246546e-05 average time 0.012705204700046125 iter num 40\n",
            "loss 1.0507386461102748e-05 average time 0.012703693783335742 iter num 60\n",
            "loss 1.0505473391642223e-05 average time 0.012689079337519615 iter num 80\n",
            "loss 1.0505094183432309e-05 average time 0.01268093537999448 iter num 100\n",
            "loss 1.0497668870852437e-05 average time 0.012739564599951337 iter num 20\n",
            "loss 1.0491176366442695e-05 average time 0.012741178874966863 iter num 40\n",
            "loss 1.0486945635615773e-05 average time 0.012715190283279299 iter num 60\n",
            "loss 1.0485048007378953e-05 average time 0.012704240674963785 iter num 80\n",
            "loss 1.0484663579600619e-05 average time 0.01270637517997784 iter num 100\n",
            "loss 1.0477263901987717e-05 average time 0.012733264400139888 iter num 20\n",
            "loss 1.0470799598750928e-05 average time 0.012729167325073832 iter num 40\n",
            "loss 1.0466584579691265e-05 average time 0.012736804466734005 iter num 60\n",
            "loss 1.0464688701395182e-05 average time 0.012750577325061841 iter num 80\n",
            "loss 1.0464314646797917e-05 average time 0.012746472400094718 iter num 100\n",
            "loss 1.0456940175383495e-05 average time 0.012686215800113133 iter num 20\n",
            "loss 1.0450498424440775e-05 average time 0.012694609575100912 iter num 40\n",
            "loss 1.0446299260082347e-05 average time 0.01268215443342342 iter num 60\n",
            "loss 1.0444409374079837e-05 average time 0.01268921467507198 iter num 80\n",
            "loss 1.0444040243426034e-05 average time 0.012699318810091427 iter num 100\n",
            "loss 1.0436691513814321e-05 average time 0.012793713450037103 iter num 20\n",
            "loss 1.0430271198483263e-05 average time 0.01282365914996717 iter num 40\n",
            "loss 1.0426086637573748e-05 average time 0.012818056099937773 iter num 60\n",
            "loss 1.0424200398357905e-05 average time 0.012799692337500801 iter num 80\n",
            "loss 1.0423830224439318e-05 average time 0.012795479149981475 iter num 100\n",
            "loss 1.0416511141483043e-05 average time 0.012730328000088775 iter num 20\n",
            "loss 1.0410116643575306e-05 average time 0.012745956825006033 iter num 40\n",
            "loss 1.0405947547405505e-05 average time 0.012753048849981496 iter num 60\n",
            "loss 1.0404070978136335e-05 average time 0.012771006424986808 iter num 80\n",
            "loss 1.0403704752942174e-05 average time 0.012754593369991199 iter num 100\n",
            "loss 1.0396407285698855e-05 average time 0.01274158484993677 iter num 20\n",
            "loss 1.0390035305612675e-05 average time 0.012755362100028833 iter num 40\n",
            "loss 1.038588464733144e-05 average time 0.012753059866690819 iter num 60\n",
            "loss 1.0384015082157424e-05 average time 0.012756776725007057 iter num 80\n",
            "loss 1.0383641844035523e-05 average time 0.012749775220027005 iter num 100\n",
            "loss 1.0376379940078263e-05 average time 0.012675615800026208 iter num 20\n",
            "loss 1.0370028448691496e-05 average time 0.012679491500011863 iter num 40\n",
            "loss 1.0365889387880158e-05 average time 0.012703235383348025 iter num 60\n",
            "loss 1.036402967420081e-05 average time 0.012711726812483448 iter num 80\n",
            "loss 1.0363657774770001e-05 average time 0.012720399409981837 iter num 100\n",
            "loss 1.0356420692219132e-05 average time 0.012782272799995553 iter num 20\n",
            "loss 1.0350091276976761e-05 average time 0.01274331617498774 iter num 40\n",
            "loss 1.0345970530694898e-05 average time 0.012712153766627429 iter num 60\n",
            "loss 1.034411023323166e-05 average time 0.012691350699958548 iter num 80\n",
            "loss 1.0343744029815303e-05 average time 0.012674710059973221 iter num 100\n",
            "loss 1.0336531328711655e-05 average time 0.012699727200015332 iter num 20\n",
            "loss 1.0330226691026849e-05 average time 0.012681388124997283 iter num 40\n",
            "loss 1.0326121460951376e-05 average time 0.01267138289996789 iter num 60\n",
            "loss 1.0324266481318763e-05 average time 0.012659688387509504 iter num 80\n",
            "loss 1.0323906713936701e-05 average time 0.012669719600007739 iter num 100\n",
            "loss 1.0316719315750758e-05 average time 0.012701309299973217 iter num 20\n",
            "loss 1.0310433658495067e-05 average time 0.01273999605004974 iter num 40\n",
            "loss 1.0306336922529846e-05 average time 0.012722063716667738 iter num 60\n",
            "loss 1.0304498722112264e-05 average time 0.012716760149987748 iter num 80\n",
            "loss 1.0304133883394512e-05 average time 0.012719239390007716 iter num 100\n",
            "loss 1.0296970179643827e-05 average time 0.012724797649798347 iter num 20\n",
            "loss 1.0290716141387665e-05 average time 0.012725627299937514 iter num 40\n",
            "loss 1.0286634496553113e-05 average time 0.012702331416630842 iter num 60\n",
            "loss 1.0284795403234364e-05 average time 0.012696399737490083 iter num 80\n",
            "loss 1.0284433648134954e-05 average time 0.012695887649988436 iter num 100\n",
            "loss 1.0277299518514537e-05 average time 0.012773293649979678 iter num 20\n",
            "loss 1.0271057989834065e-05 average time 0.012778395899931638 iter num 40\n",
            "loss 1.0266992729132488e-05 average time 0.012755074733271006 iter num 60\n",
            "loss 1.0265164460168778e-05 average time 0.012746191687472219 iter num 80\n",
            "loss 1.0264801016331676e-05 average time 0.012743749479959661 iter num 100\n",
            "loss 1.025768801970382e-05 average time 0.012637780800059773 iter num 20\n",
            "loss 1.025147213637687e-05 average time 0.012655491900045491 iter num 40\n",
            "loss 1.0247421521889273e-05 average time 0.012654411333384512 iter num 60\n",
            "loss 1.024559938074772e-05 average time 0.01266118856257208 iter num 80\n",
            "loss 1.0245238439034914e-05 average time 0.012663991430054011 iter num 100\n",
            "loss 1.023815540479198e-05 average time 0.01275576800003364 iter num 20\n",
            "loss 1.023196436275695e-05 average time 0.012729025675002958 iter num 40\n",
            "loss 1.0227927060332927e-05 average time 0.012691821583302954 iter num 60\n",
            "loss 1.0226104481188771e-05 average time 0.012679806337519039 iter num 80\n",
            "loss 1.022574920586709e-05 average time 0.012677417670047361 iter num 100\n",
            "loss 1.0218688035701065e-05 average time 0.012684023500105468 iter num 20\n",
            "loss 1.021251204942704e-05 average time 0.012656788650065209 iter num 40\n",
            "loss 1.0208494311416174e-05 average time 0.012668708200059579 iter num 60\n",
            "loss 1.0206683184829943e-05 average time 0.012685528962538228 iter num 80\n",
            "loss 1.0206322850730765e-05 average time 0.012729623020004511 iter num 100\n",
            "loss 1.0199287670916864e-05 average time 0.012781234799922459 iter num 20\n",
            "loss 1.0193140319098294e-05 average time 0.012733999899910486 iter num 40\n",
            "loss 1.0189133972864744e-05 average time 0.012725541799939795 iter num 60\n",
            "loss 1.0187328884425943e-05 average time 0.012745312912431927 iter num 80\n",
            "loss 1.018696784543659e-05 average time 0.012754713009953775 iter num 100\n",
            "loss 1.0179953286496608e-05 average time 0.01274052464991655 iter num 20\n",
            "loss 1.0173826056209318e-05 average time 0.012742821674873995 iter num 40\n",
            "loss 1.0169837005680423e-05 average time 0.012745590783288208 iter num 60\n",
            "loss 1.0168040587561037e-05 average time 0.01272085508744567 iter num 80\n",
            "loss 1.0167681971019332e-05 average time 0.012724594109922691 iter num 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhxXce6KtOMc"
      },
      "source": [
        "# 2min8s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06f7e966-ed73-4b51-bf1b-159090e5568a"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 1, 0.8, 1, 0.25, 0.02, 0.02] * nstock]).cuda() # T, K, B, S, sigma, mu, r\n",
        "print('price: ' + str(model(inputs.float())))\n",
        "\n",
        "# price, delta\n",
        "# should be around (0.10632345, 0.5543747)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: tensor([[0.066172, 0.195474, 0.193930, 0.195925]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqpasxVi0hx3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a776682-c802-4600-cf2e-29ea60c42370"
      },
      "source": [
        "# Knock out call\n",
        "\n",
        "# now change code such that 'numsteps' does not represent year\n",
        "# make dt = year / numsteps\n",
        "# Add r, and notice that noise must have mean 0, not drift, or else it'll give large option prices\n",
        "# (done)\n",
        "# after making the changes, the values are still correct\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        #dx =  drift + noise[t,:] # no need to multiply by sigma here because noise generated by cov not corr\n",
        "        dx2 = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx2)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T): # down-and-out call\n",
        "    return jnp.mean(jnp.maximum((1 - jnp.any(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2) < B, axis=1).astype(int))* \n",
        "                                (jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2))[:,-1]-K, 0) *\n",
        "                    jnp.exp(-r[0] * T))\n",
        "    # must use '-1' not 'numsteps', or else grad will be 0\n",
        "\n",
        "numstocks = nstock\n",
        "numsteps = 50\n",
        "numpaths = 2000000\n",
        "\n",
        "rng = jax.random.PRNGKey(1)\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.02]*numstocks)\n",
        "r = drift # let r = drift to match B-S\n",
        "\n",
        "cov = jnp.identity(numstocks)*0.25*0.25\n",
        "initial_stocks = jnp.array([1.]*numstocks) # must be float\n",
        "\n",
        "T = 1.0\n",
        "K = 1.0\n",
        "B = 0.8 # if B is set to 0, equivalent to European call\n",
        "\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "\n",
        "keys = jax.random.split(key, numpaths)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T)) # here numsteps different from T\n",
        "\n",
        "# delta\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, B, T)) # here numsteps different from T"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0678582\n",
            "[0.19399585 0.19401251 0.19391604]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lovJwXo3-YEu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "1c8c1d13-c5da-4e76-d67b-fc081bd8cc30"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def compute_price(S):\n",
        "    inputs = torch.tensor([[1, 1, 0.8, S, 0.25, 0.02, 0.02] * nstock]).cuda()\n",
        "    return model(inputs.float())[0][0]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_prices = []\n",
        "correct_call_prices = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*numstocks) # must be float\n",
        "    model_call_prices.append(compute_price(p).item())\n",
        "    correct_call_prices.append(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T))\n",
        "\n",
        "#plt.plot(prices, model_call_prices, label = \"model_call_prices\")\n",
        "#plt.plot(prices, correct_call_prices, label = \"correct_call_prices\")\n",
        "plt.plot(prices, np.array(model_call_prices)-np.array(correct_call_prices), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwApH0GT9bBK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b4bb4e29-254f-4e7b-f7eb-ecf34a17f2fe"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, 0.8, S, 0.25, 0.02, 0.02] * nstock]).cuda()\n",
        "    return model(inputs.float())[0][1]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*nstock) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, 1.0, B, T)[0])\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"correct_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZiN9f/H8ef7nNmM3Zjsy8iQnRqSrZCtRCmhxVrqR9RXq0pJ+qb1W0lJ9i3ZGyEllCUyE9llGwwyzBgMs57z+f0x01xDgzPMzH3OmffjuuYy93a8bsvL7V4+txhjUEop5b1sVgdQSimVt7TolVLKy2nRK6WUl9OiV0opL6dFr5RSXs7H6gCXK126tKlatarVMZRSyqNERkaeNsYEZ7fM7Yq+atWqREREWB1DKaU8iogcvtIyPXWjlFJeToteKaW8nBa9Ukp5Obc7R5+d1NRUoqOjSUpKsjqKskBAQAAVK1bE19fX6ihKeSSPKPro6GiKFi1K1apVERGr46h8ZIwhNjaW6OhoQkJCrI6jlEfyiFM3SUlJBAUFackXQCJCUFCQ/m9OqRvgEUUPaMkXYPp7r9SN8YhTN0op5bWSzsLJnfD3drD7QVi/XP8ptOiVUio/GAPnjsPxLfD3Nvh7B5zcDvFHMlc5XbIBpbXovcM/T/+WLl36htZx1dSpU4mIiODzzz9n5MiRFClShBdeeOGa20VFRdG5c2d27Njh0jpbt27l+PHj3HPPPTecWSmPd/5keqlnfJnjW5ALMQA4sXHStyK7nZWJSLuDXc7K7HJW5SapzPd5EEWLXuWarVu3EhERoUWvCh5HGsTshKO/w9FNmKObkIwjdSc2on0qsSW1FpFpndjhDGEPVShbpBS3lCtKzTLF6Fm2KLXKFaVSycA8iedxRf/Wkp3sOn4uVz+zdvlivHlfnauuExUVRceOHWnatCkbNmygcePG9OvXjzfffJOYmBhmzZpF9erV6d+/PwcPHiQwMJAJEyZQv359YmNj6dWrF8eOHeOOO+4g6+sbZ86cyWeffUZKSgq33347X3zxBXa7/ZqZp0+fzocffoiIUL9+fWbMmMGSJUsYPXo0KSkpBAUFMWvWLMqUKZOjX4vIyEj69+8PQPv27TPnOxwOXnnlFdasWUNycjKDBw/mqaeeylyekpLCG2+8QWJiIuvWrWP48OGEhITw7LPPkpSURKFChZgyZQo1a9Zk586d9OvXj5SUFJxOJwsWLCA0NDRHOZWyVGoiRG+GqPU4D6+H6EhsaRcBiLUF8XtadSIcLdnqrM4hn2pUvSmY2uWLUad8cR4sV4waZYpSyO/af89zi8cVvZX279/PvHnzmDx5Mo0bN2b27NmsW7eO8PBw/vvf/1KpUiUaNWrE4sWLWbVqFb1792br1q289dZbtGjRgjfeeIOlS5cyadIkAHbv3s23337L+vXr8fX1ZdCgQcyaNYvevXtfNcfOnTsZPXo0GzZsoHTp0sTFxQHQokULNm7ciIgwceJE3n//fT766KMc7WO/fv34/PPPadWqFS+++GLm/EmTJlG8eHE2b95McnIyzZs3p3379pl3xPj5+TFq1KjMU0QA586dY+3atfj4+LBy5UpeffVVFixYwPjx43n22Wd59NFHSUlJweFw5CijUvkuNTH9SD1qHSkH1uJzIhK7MxUHNnabKmx2tOQPZyh7fGsTVCaE+pVK0qBCcR4pX4yqQYWx26y9c8zjiv5aR955KSQkhHr16gFQp04d2rZti4hQr149oqKiOHz4MAsWLACgTZs2xMbGcu7cOX799VcWLlwIwL333kvJkiUB+Pnnn4mMjKRx48YAJCYmctNNN10zx6pVq+jevXvm+ftSpUoB6Q+W9ejRgxMnTpCSkpLjB4zi4+OJj4+nVatWADz++OMsX74cgB9//JFt27Yxf/58AM6ePcu+ffuoUaPGFT/v7Nmz9OnTh3379iEipKamAnDHHXfwzjvvEB0dTbdu3fRoXrkfpxP+3kba/lVc3L2SwJOb8XGm4MTGbmdVNjnbEyl1SCzbhBpVKlC/YnH+U6E4VYMKY7O41LPjcUVvJX9//8zvbTZb5rTNZiMtLS3Hj+gbY+jTpw/vvvturuQbMmQIw4YNo0uXLqxZs4aRI0fmyudCetaxY8fSoUOHS+ZHRUVdcZsRI0bQunVrFi1aRFRUFHfddRcAjzzyCLfffjtLly7lnnvu4auvvqJNmza5llWp65IQw8VdP3B+xw8UPb6ewLR4fIDjzkqsc7Zlf+HboEozalWtwB2VS9CvbDH8fDzjUSTPSOkhWrZsyaxZswBYs2YNpUuXplixYrRq1YrZs2cDsHz5cs6cOQNA27ZtmT9/PjEx6Vfi4+LiOHz4ikNKZ2rTpg3z5s0jNjY2cztIP4KuUKECANOmTctx/hIlSlCiRAnWrVsHkLkvAB06dODLL7/MPCr/66+/uHDhwiXbFy1alPPnz2dOZ80zderUzPkHDx6kWrVqDB06lK5du7Jt27YcZ1XqhhlDQlQEB+a/wbEP7oAPQwlcNgQ5vJ4VyfX4pOjzfFJ/CVEPr6Try9MYM/xFxjzSnD7NqlK/YgmPKXlw8YheRDoCnwJ2YKIxZsxly58GBgMOIAEYaIzZlbFsODAgY9lQY8yK3IvvXkaOHEn//v2pX78+gYGBmWX75ptv0qtXL+rUqUOzZs2oXLkyALVr12b06NG0b98ep9OJr68v48aNo0qVKlf9eerUqcNrr73GnXfeid1up1GjRkydOpWRI0fSvXt3SpYsSZs2bTh06FCO92HKlCn0798fEbnkYuwTTzxBVFQUt956K8YYgoODWbx48SXbtm7dmjFjxtCwYUOGDx/OSy+9RJ8+fRg9ejT33ntv5npz585lxowZ+Pr6UrZsWV599dUc51TqeiQnJ3Jg0zJStn9Hpdh1BDljCTTCn6Y664r1Jq16e0LqNqVj5VL5erE0r0nWO0CyXUHEDvwFtAOigc1Ar3+KPGOdYsaYcxnfdwEGGWM6ikht4BugCVAeWAnUMMZc8epbWFiYufwNU7t376ZWrVrXsXvKW+ifAXU9jDEcPHGKQxuXEHhgKXUTfqOYXCTBBLA9IIyzldoQ1PBe6tUMJcDXs4tdRCKNMWHZLXPliL4JsN8YczDjw+YAXYHMov+n5DMUBv7516MrMMcYkwwcEpH9GZ/3W473QimlXJCc5mDTX8eJ/v07yhxZSlNHJDdLMucowoGgu5A6XQlt2pk7ChexOmq+caXoKwBHs0xHA7dfvpKIDAaGAX7AP1fWKgAbL9u2QjbbDgQGApmnNRTExsbStm3bf83/+eefCQoKuqHPHjx4MOvXr79k3rPPPku/frn/+LVSeS3uQgqrdx0n+o8VVDq+jLvZRCtJ5Jy9BMerdKX4rQ9yU722NLIXzHca5NpdN8aYccA4EXkEeB3ok4NtJwATIP3UTW5l8nRBQUFs3bo1Tz573LhxefK5SuWX2IRkfthxgp0Rawn9ewmd7RsJlrMk2QtzpkonApo+SrHqd1HMrjcXuvIrcAyolGW6Ysa8K5kDfHmd2yql1BXFX0xhxc6/WbNlD+WPLOEh2xoetR0hzdePC1XbYhr3IiC0A+V8A6yO6lZcKfrNQKiIhJBe0j2BR7KuICKhxph9GZP3Av98Hw7MFpGPSb8YGwr8nhvBlVIFQ6rDyeo9MczbfBjHvp950Laaz+x/4OuTRmJwA0yT5/Cp+yDFC5WwOqrbumbRG2PSROQZYAXpt1dONsbsFJFRQIQxJhx4RkTuBlKBM2SctslYby7pF27TgMFXu+NGKaX+sT/mPHMjovklcjvtk1bwtu8ayvqeJi2gFPaGA6HRYxQqY92T8p7EpZNXxphlwLLL5r2R5ftnr7LtO8A71xtQKVVwJKU6CN96nDm/H8b/2AZ6+6zkZVsEdl8HzmqtIawfPjU6gY+f1VE9iuc82lVAxcfH88UXX+TqZ44cOZIPP/wQgL59+2aOX3Mta9asoXPnzi6vs2bNGjZs2HBjYVWBEH3mIu8u303b/y5h9+L3+DR2IN/4vUOHwL+w3/F/MOQPbL0XQ+2uWvLXQS9H57G0tDR8fHyuOH0t/xT9oEGD8iJenlqzZg1FihShWbNmVkdRbsgYw28HY5m6Poq9u7fR12cFK31+pZDvRUz5xhA2Alud+8G3kNVRPZ7nFf3yV9LfrZibytaDTmOuudrlY8C//fbb9O/fn9OnTxMcHMyUKVOoXLkyffv2JSAggC1bttC8eXPi4uIumR48eDCDBw/m1KlTBAYG8vXXX3PLLbdw8uRJnn76aQ4ePAjAl19+yWeffcaBAwdo2LAh7dq144MPPsg223vvvcfMmTOx2Wx06tSJMWPG8PXXXzNhwgRSUlKoXr06M2bMIDAwZy82+OGHH3juuecIDAykRYsWmfMvXLjAkCFD2LFjB6mpqYwcOZKuXbtmLo+KimL8+PHY7XZmzpzJ2LFjiY+Pz3a8/F9++YVnn00/+yci/PrrrxQtWjRHOZXnSHU4+X7bcb5ac4DiMZt5yv8HWvtHgM2O1OkGTZ9GKtxmdUyv4nlFb5HsxoDv06dP5tfkyZMZOnRo5vgv0dHRbNiwAbvdTt++fS+Zbtu2LePHjyc0NJRNmzYxaNAgVq1axdChQ7nzzjtZtGgRDoeDhIQExowZk/mavitZvnw53333HZs2bSIwMDBzkLNu3brx5JNPAvD6668zadIkhgwZ4vI+JyUl8eSTT7Jq1SqqV69Ojx49Mpe98847tGnThsmTJxMfH0+TJk24++67M5dXrVqVp59++pLXFp45cybb8fI//PBDxo0bR/PmzUlISCAgQG+N80ZJqQ7mRRzl61/2Uffcr4wNWEqo/wFMoVJI2PPQ+AkoVs7qmF7J84rehSPvvJDdGPC//fZb5jjzjz/+OC+99FLm+t27d7/kTVH/TCckJLBhwwa6d++euSw5OTnz55g+fToAdrud4sWLZ450eTUrV66kX79+mUfr/4xPv2PHDl5//XXi4+NJSEj41xDD17Jnzx5CQkIyx4t/7LHHmDBhApA+Pn14eHjmuf6kpCSOHDlyxc+CK4+X37x5c4YNG8ajjz5Kt27dqFixYo5yKvd2LimVmRsPM23tPlomrWZ2wFIq+kVjSlaHZp8i9Xvo6Zk85nlF7yEKFy6c7bTT6aREiRJ59sRrVn379mXx4sU0aNCAqVOnsmbNmlz7bGMMCxYsoGbNmpfMP3ny5BW3udJ4+a+88gr33nsvy5Yto3nz5qxYsYJbbrkl17IqayQkpzF53SGmr91Dp9SVLA1YRmnfGExwPWg5GqnVBWyePZCYp9C7blyU3RjwzZo1Y86cOUD62O0tW7a85ucUK1aMkJAQ5s2bB6QX5p9//gmkj0//5ZfpDxU7HA7Onj37rzHes9OuXTumTJnCxYsXM7MBnD9/nnLlypGamnrJ2PKuuuWWW4iKiuLAgQMAfPPNN5nLOnTowNixYzPff7tly5Z/bX+18emzjpd/4MAB6tWrx8svv0zjxo3Zs2dPjrMq95GU6mDi2oO0e+8Hzq76hJ/tQ3jbdyqly4fAI/OQp9ZCnQe05PORFr2Lso4B36BBA4YNG8bYsWOZMmVK5su5P/30U5c+a9asWUyaNIkGDRpQp04dvvvuOwA+/fRTVq9eTb169bjtttvYtWsXQUFBNG/enLp1617yDtesOnbsSJcuXQgLC6Nhw4aZp1Pefvttbr/9dpo3b35dR8gBAQFMmDCBe++9l1tvvfWS1xyOGDGC1NRU6tevT506dRgxYsS/tr/vvvtYtGgRDRs2ZO3atZnj5d92222Zp8AAPvnkE+rWrUv9+vXx9fWlU6dOOc6qrJfqcDJ70xHavf8Th3/4lKUylBG+MyleuR70XQr9V0CN9iDu96o9b3fN8ejzm45Hr7KjfwbclzGGZdv/5qMfdnD72eUM8w8n2HkKKjeDNq9B1RbX/hB1w250PHqllMrWjmNneTt8B2WPfs+sgAWU8z2JKRcGbSZAtdZ69O4mtOg9yPbt23n88ccvmefv78+mTZtu+LMfeOCBf7168L333svxnTqqYDh1PpkPV+zl6B8/MNLvG2r5HcTcVB/afI6EttOCdzMeU/TGGKSA/+GpV69ent2ts2jRojz53NzgbqcXC7LkNAdT1kexfNVqnjUzaeO3BWexinD310jdh8Cml/3ckUcUfUBAALGxsQQFBRX4si9ojDHExsbqQ1RuYMOB03y84Fe6nZvOIp9fMP5F4M5R2Jo8BTr+u1vziKKvWLEi0dHRnDp1yuooygIBAQH6EJWF4i6kMGbJn5TaPpHpvosJ8HNga/I0tHoRAktZHU+5wCOK3tfXN/MpSqVU/jDGsDAymnVLp/OccxpVfE/iqHEPtg6jIehmq+OpHPCIoldK5a9Dpy/w5bwldD7+Of+zbye5VCh0Ho/95jZWR1PXQYteKZXJ4TTM/GUbsvq//Nf2Iw7/wjjbjsG/yRNg97U6nrpOWvRKKQAOnUpg4cxxPBb/BcG2syTXf5xCHUZC4SCro6kbpEWvVAHndBoWrFxHmfWv8bz8SXyJWkj3hRSqqGPCewsteqUKsMMxZ9gwYyQPnJsFNh/O3fk2JVoOArtWgzfR302lCiCn0/DDiiXU2DicXhJNdLl2VOj1KQHFK1gdTeUBLXqlCphjMaf5c9oLdExYTJxPMHGdZ1CxURerY6k85NLzyiLSUUT2ish+EXklm+XDRGSXiGwTkZ9FpEqWZQ4R2ZrxFZ6b4ZVSrjPGsGr5fJzjmnHPhUXsr/IwQS9GUkpL3utd84heROzAOKAdEA1sFpFwY8yuLKttAcKMMRdF5P+A94F/XjCaaIxpmMu5lVI5EHPqFDunPUubhKWc8ClPTNcF1Kh/97U3VF7BlSP6JsB+Y8xBY0wKMAfomnUFY8xqY8zFjMmNgD6vrpQbMMawfsU8HONup9X5Zeys0psyL0Vwk5Z8geLKOfoKwNEs09HA7VdZfwCwPMt0gIhEAGnAGGPM4ss3EJGBwECAypUruxBJKXUtcfFn+XPqc7SOX0i0vRInH5hGnbrXft2l8j65ejFWRB4DwoA7s8yuYow5JiLVgFUist0YcyDrdsaYCcAESH/DVG5mUqog+n39zwT/NITWHGNbhV7U6f0xdv9Aq2Mpi7hS9MeASlmmK2bMu4SI3A28BtxpjEn+Z74x5ljGjwdFZA3QCDhw+fZKqRt3/mIiG6a+TpuTU4i3leDwPbOp3/heq2Mpi7lS9JuBUBEJIb3gewKPZF1BRBoBXwEdjTExWeaXBC4aY5JFpDTQnPQLtUqpXLb1zz+wf/c0HZx72VW6PTf3HU9wUR2+QLlQ9MaYNBF5BlgB2IHJxpidIjIKiDDGhAMfAEWAeRkvBjlijOkC1AK+EhEn6Rd+x1x2t45S6gYlp6bx4zef0vrA+xixc/DOz6jduo/VsZQbEXd7TVtYWJiJiIiwOoZSHmH/kWMcnfF/tE79hYOFG1K273QCg6tce0PldUQk0hgTlt0yfTJWKQ/kdBqWLVtMg80v0lJi2V/3P1TvNgJsdqujKTekRa+Uh/n7TALrpgzn/rMzOeN7E+e7f0/1ms2tjqXcmBa9Uh7k18htBC4ZyEPs5lCFzlTt/QUSUNzqWMrNadEr5QGS0xzM/XYmHf96naKSTMzdnxLSoq/VsZSH0KJXys0dOnWe9ZNf5tGLs4ktVAVbn9ncVK6O1bGUB9GiV8qNLd+0g6LLBvGY/MnxKvdR/tHx4F/E6ljKw2jRK+WGElMcTJozh24HXqe0nCe+7QeUb/EkpD+nolSOaNEr5WaiTiXw/eTRPHVxAhcCymJ7fCElKjayOpbyYFr0SrmRldsOk7BwKM+whtMV7qL049OgUAmrYykPp0WvlBtIcziZ8P2vNI/8D3fbDnK2yTBKdxwBNpdeAqfUVWnRK2Wx0wnJjJ86hf87NZrCPg5SHpxF8TqdrY6lvIgWvVIW2nI4jl+mj+KVtGlcLFqFgL7zoHSo1bGUl9GiV8oi8zbuw3fZf3jOtpZzIR0p1vNrCChmdSzlhbTolcpnKWlO/rfoFzpsf56GtgMkNn+ZYm1f0fPxKs9o0SuVj2LOJ/HxlG/4T+xISvok43hwBoXqdLE6lvJyWvRK5ZMtR86weNrHvJX2JY7CN+HXZxmU0aEMVN7TolcqH8zbHEV8+Ou8ZV/ChfJ3UPixWVBYX/On8ocWvVJ5yOE0fPR9JI02v0h3+x8kNexH4fs+ALuv1dFUAaJFr1QeOZeUysgZPzLg6HBq2Y/i6Pg+AU2fsjqWKoC06JXKA4djL/Du5G8ZmTCKUr4p2HrOg9C7rY6lCigteqVy2YYDp5k78yv+Zz7FViQIv95L9aKrspRLN+6KSEcR2Ssi+0XklWyWDxORXSKyTUR+FpEqWZb1EZF9GV99cjO8Uu7mm02HWT1lJB+bD7DdVAv/p9doySvLXbPoRcQOjAM6AbWBXiJS+7LVtgBhxpj6wHzg/YxtSwFvArcDTYA3RaRk7sVXyj04nYYxS7eTuuR5XvOZgaNmZ/yfWA5Fy1gdTSmXjuibAPuNMQeNMSnAHKBr1hWMMauNMRczJjcCFTO+7wD8ZIyJM8acAX4COuZOdKXcQ2KKg//MXE/YxiH09vkJ5x1D8e0xHfwCrY6mFODaOfoKwNEs09GkH6FfyQBg+VW2rZCTgEq5s5jzSbw49SeePzWCuvbDmHs/xtZ4gNWxlLpErl6MFZHHgDDgzhxuNxAYCFC5cuXcjKRUnvnr5HlGTlrIB8lvU9Y3AdvD30BN/Q+rcj+unLo5BlTKMl0xY94lRORu4DWgizEmOSfbGmMmGGPCjDFhwcHBrmZXyjLr9p3m3S8mMj5lODcFgr3/Mi155bZcKfrNQKiIhIiIH9ATCM+6gog0Ar4iveRjsixaAbQXkZIZF2HbZ8xTymN9t/UY86f9j69kNIVKlcd34M9Q4VarYyl1Rdc8dWOMSRORZ0gvaDsw2RizU0RGARHGmHDgA6AIME/S31J/xBjTxRgTJyJvk/6PBcAoY0xcnuyJUvlg0rpDnFj+AZ/4ziKtUjN8HpkNhfRGMuXexBhjdYZLhIWFmYiICKtjKHUJYwzvLd9N6Q2jeMJnOY5aXbE/+DX4+FsdTSkARCTSGBOW3TJ9Mlapa0h1OHl9fiTNdrxBV58NOJsMxN7xPX1RiPIYWvRKXUViioPnZ67lkUOv0sK+E9N2JLYWz0H6KUqlPIIWvVJXcDYxlWGTVjAs5lVq+RyDruORhr2sjqVUjmnRK5WNuAspvDxhISPjR1DONwFbz2919EnlsbTolbpMzLkk3vxqNu8mjKRYgA2f3t9DhdusjqXUddOiVyqLY/GJfDh+Ah8kvotvkZL49QuH0qFWx1LqhmjRK5XhcOwFJoz/hPdSP8ZRshr+/b+DYuWtjqXUDdOiVwrYH3OeeePf5m3nBBLL3ErhPvMhsJTVsZTKFVr0qsDbdewsaya+xHAzh4TKbSny2EwdYlh5FS16VaDtiD7DnxMHMYhlnK/5IEUf/grsvlbHUipXadGrAmtL1CmOTB3Ao/zC+YZPULTLB/q0q/JKWvSqQIrcf4L4GY/TVTZztumLFO/wmj7tqryWFr0qcH7fexjn7EdoKzs4e9doit81xOpISuUpLXpVoGzcsY9C83pQVw5xruNYijftbXUkpfKcFr0qMDZs2U7pxT2pKie5cP8UijW83+pISuULLXpVIKz9fTNVlj5CaTlPUo+5FKvVxupISuUbLXrl9dasW8stPz1OYVsqzse+o9jNt1sdSal8pUWvvNqqVT/S4Jf+2O0+2Pouo3DlBlZHUirf6U3Dymv99MNiwn7pjdOnEP4DV2jJqwJLi155pZ/CZ9Pitye54BtE0UErKVS2ptWRlLKMFr3yOj8u+JpWkUM47V+JUs+sJCCoitWRlLKUFr3yGsYYls/6hDbbXuJYoRqUHboS/xLlrI6llOVcKnoR6Sgie0Vkv4i8ks3yViLyh4ikichDly1ziMjWjK/w3AquVFbGGH6Y9i4d/hrJoSINqfLcj/gW0WGGlQIX7roRETswDmgHRAObRSTcGLMry2pHgL7AC9l8RKIxpmEuZFUqW06nYcXEV+l0/Av2Fm9G6DMLsfkVsjqWUm7DldsrmwD7jTEHAURkDtAVyCx6Y0xUxjJnHmRU6orS0hz8PH4YnU5PZVepttQa9A3i4291LKXciiunbioAR7NMR2fMc1WAiESIyEYRyfaZcxEZmLFOxKlTp3Lw0aogS0l18MvnT9Hh9FR2lrmPWoPnaskrlY38eGCqijHmmIhUA1aJyHZjzIGsKxhjJgATAMLCwkw+ZFIeLikllY2f9aFtwlJ2VuxJnf5f6ljySl2BK38zjgGVskxXzJjnEmPMsYwfDwJrgEY5yKfUv5y/mMjv/3uYuxKWsiNkAHUGjNeSV+oqXPnbsRkIFZEQEfEDegIu3T0jIiVFxD/j+9JAc7Kc21cqp+LOJbDtkwdplbiKXbWepW6fj/WFIUpdwzWL3hiTBjwDrAB2A3ONMTtFZJSIdAEQkcYiEg10B74SkZ0Zm9cCIkTkT2A1MOayu3WUctnfsWfY91lXmqes56+Gr1K7xyirIynlEcQY9zolHhYWZiIiIqyOodzMkRMxnPr6ARo5dnKo6Whu7vSM1ZGUcisiEmmMCctumY5eqdzevsPRJE7tRgOzj6N3fczNrftbHUkpj6JFr9za9n0Hsc/qRi2OEtNhPFXu6GF1JKU8jha9clt/7NxD0bkPUlliOHPfVMrfdp/VkZTySFr0yi1t3PInZRc/TBmJ58KDs7mpXjurIynlsbToldv5ZeNmqi3vRSm5QHKveZSq2crqSEp5NC165VZ++nUtdX/uTRFbKubx7yhRrYnVkZTyeFr0ym0sXfkTt6/tj6/dhr3fMgIr1bc6klJeQYteuYXFy5Zy56aBGJ8AAp5cin/ZW6yOpJTX0AFClOUWhS+kzaYBOH0LU+Tpn7TklcplWvTKUgsXfEP7yKdJ8itF8UEr8QuuZnUkpbyOFr2yhDGGBXOncc+2IZz3L0epwSvxKVXZ6lhKeSUtepXvjIfbucUAABD+SURBVDEs+uZrOu8cRmyhqgQPWYlPifJWx1LKa2nRq3xljGHRzLHct/cVYgqHUm7IT9iLBlsdSymvpnfdqHzjdBoWT/2QroffIbpIfSoPWYIEFLc6llJeT4te5QuH0/D91yPpduITDhULo+oz3yH+RayOpVSBoEWv8lxamoMfxr9E19MT2V+qFTf/31zEt5DVsZQqMLToVZ5KSXWwetwgOsfPYe9N91Dzqelg97U6llIFiha9yjNJKan8NrYvHc5/z64K3ak9YIK+xFspC2jRqzyRmJjEH2N70friKnaEDKBu74/0Jd5KWUSLXuW6hAsJ7P7sIZon/8a2W56jfs+3rI6kVIGmRa9y1blzZzg09n4ap25lW4MR1H/gBasjKVXgadGrXHM29iQnvuxCndS/+LPJ+zS49ymrIymlcPHJWBHpKCJ7RWS/iLySzfJWIvKHiKSJyEOXLesjIvsyvvrkVnDlXuJOHiFuXHuqpe5nV8uxWvJKuZFrHtGLiB0YB7QDooHNIhJujNmVZbUjQF/ghcu2LQW8CYQBBojM2PZM7sRX7uB09D6SJt9HGUcce9tOon6r+62OpJTKwpUj+ibAfmPMQWNMCjAH6Jp1BWNMlDFmG+C8bNsOwE/GmLiMcv8J6JgLuZWbOHlwO45JHSnqOMfBe2ZRT0teKbfjStFXAI5mmY7OmOcKl7YVkYEiEiEiEadOnXLxo5XVTuzZhN/0e/BxpnLs/rnUvb2d1ZGUUtlwi6dXjDETjDFhxpiw4GAdydATRG9dSdE595OIH6ceXkztRi2sjqSUugJXiv4YUCnLdMWMea64kW2Vmzq8cRGlF/fiFCVJfGwZt9S51epISqmrcKXoNwOhIhIiIn5ATyDcxc9fAbQXkZIiUhJonzFPeahDq6dS/ocBHJJK2Ab8wM3Va1odSSl1DdcsemNMGvAM6QW9G5hrjNkpIqNEpAuAiDQWkWigO/CViOzM2DYOeJv0fyw2A6My5ikPdGDZp1RZ8xw7bbdQ7KnlVKmkr/5TyhOIMcbqDJcICwszERERVsdQWRnDwYVvUW37//jNpwk3/99cbgoqaXUqpVQWIhJpjAnLbpk+Gauuzunk4OznqLZ/Gqv9WtPwmVmULFbY6lRKqRzQoldX5kjl8OS+VDv2Pd8HdqXVkK8pVsjf6lRKqRzSolfZS7lA9ISHqXJ6HXOL96PzoA8I9NcXhijlibTo1b9djOPv8V0pd3Y704OH0ePp1/H3sVudSil1nbTo1SXM2Whix3em5MWjTK34Fr37D8HX7hbP1SmlrpMWvcrkjPmLcxM74598juk3f0z/x3pjt+lboZTydFr0CgDHkd9JmvYQqWmG+bW/5ImH70f01X9KeQUtekXanuU4v+3DKUcJfg4bz4D7WmvJK+VFtOgLuNSI6di+f5Y9zipsaTmBAe2aWB1JKZXLtOgLKmNIXfMhvr+M5ldHPaLbf0WflnWsTqWUygNa9AWR00HK9y/h98dEFjuak3bf5zzSpJrVqZRSeUSLvqBJTSJl/kD89n7HRMe9lHnwfe5vWNHqVEqpPKRFX5AkniFlVi/8on/jXcfjhPUaQbvaZaxOpZTKY1r0BcXZaFKnPQBxB3neOZT7ew+lZai+zUupgkCLviA4uZO06d1IvnCOobzK4AH9uK1KKatTKaXyiRa9tzu0Fsc3jxCX4sNQ+yhGDHiYOuWLW51KKZWPtOi92Y6FOBc+RZQzmBf83uCjJztTLbiI1amUUvlMR6vyRsbAuk9gfj/+cFTjP4Xf4/NBXbXklSqg9Ije2zjSYPmLEDGZpY6mjC/1IpOfaElwUX1hiFIFlRa9N0lOwMzvj+xbwfi0+/i10iBm9m5M8UL6whClCjItem9x/m/M7IcxJ7bzemp/ztftzZTu9fWFIUop187Ri0hHEdkrIvtF5JVslvuLyLcZyzeJSNWM+VVFJFFEtmZ8jc/d+AqAmN04v25L8t976Z/yPEVbPMUnPRpqySulABeO6EXEDowD2gHRwGYRCTfG7Mqy2gDgjDGmuoj0BN4DemQsO2CMaZjLudU/Dv6C89vHiE+10zt5BA/f15ned1S1OpVSyo24ckTfBNhvjDlojEkB5gBdL1unKzAt4/v5QFvRAc3z3tbZmJndOJxaggdTRvHMIw9pySul/sWVoq8AHM0yHZ0xL9t1jDFpwFkgKGNZiIhsEZFfRKRldj+BiAwUkQgRiTh16lSOdqBAMgZWvwuL/49Nzlr04W0+fLIzHeuWtTqZUsoN5fXF2BNAZWNMrIjcBiwWkTrGmHNZVzLGTAAmAISFhZk8zuTZ0lIgfAhsm8N8551MLD6UmX2bUTko0OpkSik35UrRHwMqZZmumDEvu3WiRcQHKA7EGmMMkAxgjIkUkQNADSDiRoMXSIlnMN8+jkSt5cPU7vwZ8gTfPnqb3j6plLoqV07dbAZCRSRERPyAnkD4ZeuEA30yvn8IWGWMMSISnHExFxGpBoQCB3MnegFzJgrnxPY4on7juZRBxIU9y+R+TbTklVLXdM0jemNMmog8A6wA7MBkY8xOERkFRBhjwoFJwAwR2Q/Ekf6PAUArYJSIpAJO4GljTFxe7IhXi47AMbsHiYmJPJHyCnd3epABLUL0Bd5KKZdI+tkV9xEWFmYiIvTMTqZd3+Fc8CTHHSV4yvkyz/XsrC8LUUr9i4hEGmPCslumT8a6K2Ngw1jMT2/wpwnlNf/hfNC3rQ4xrJTKMS16d+RIwyx7AYmcwlJHU6aVeZmpfZpxU9EAq5MppTyQFr27STqHc24fbAdXMS6tC7trPcuMhxsR4KvDGSilro8WvTuJP0razIeR03t4OfVJyt41kLF3h+pFV6XUDdGidxfHIkmd2YOkxAsMcQznge6P0rXh5Q8gK6VUzmnRu4Nd4aQteJKTaUV50e9dhj9xP/UrlrA6lVLKS2jRW8kYHOs+wf7zSLY5q/NFmdF81ruNvg1KKZWrtOit4kgl+bvn8N82kyWOpmy99b982aURvnZ9ja9SKndp0VvhYhwJMx+lyPENfOF4gNJd3mJE4ypWp1JKeSkt+nyW9vduEqZ2JzDxBG/5PEOX/i/QqHJJq2MppbyYFn0+Oh6xhOJLB5Lq9GFs5f8xtGdPShb2szqWUsrLadHnA6fDyeZv3yFs70fsl8oc7TiJ5+9obHUspVQBoUWfx6JPx/PX5Kdoc/EHIgObU3nADGqWDrr2hkoplUu06PNIYoqD2T/9RoPfn6eN7GHnzU9y66PvITYdykAplb+06HOZMYal20+waslsXkv5hMK2VGI7fEGdpo9aHU0pVUBp0eeiHcfOMjp8O62OfcXHPuFcKFmTgEdnEhBcw+poSqkCTIs+FxyNu8jYVftYG/knX/iPo5HPHpy39qFwp/fAt5DV8ZRSBZwW/Q04eCqBL9YcYNGWY7SxbeXnwuMpZEuDzhOx1e9udTyllAK06K/L3r/PM271fr7fdpyaPn+zNHgxt5z9FYLqQvepUDrU6ohKKZVJi95Fxhg2HYpjyvpDrNh5kop+F5hXeQW3xixCEgOh7RvQdJCeqlFKuR0t+ms4ezGVhVuimbXpCPtjEggOcDKjxm+0+Hs6EnMRbusLdw2HIsFWR1VKqWxp0WfDGMO26LPM3HiYJduOk5Tq4MGypxhbdwc1Ty7DduQ41OgE7d6C4JpWx1VKqatyqehFpCPwKWAHJhpjxly23B+YDtwGxAI9jDFRGcuGAwMABzDUGLMi19Lnsr9Onuf7bSdYuu04h06dp7nffiaW2UWTpPX4xR+Ds3YIaQndvoKQVlbHVUopl1yz6EXEDowD2gHRwGYRCTfG7Mqy2gDgjDGmuoj0BN4DeohIbaAnUAcoD6wUkRrGGEdu78j12n8shg0Rkezbsx2/c4epYjvJR4FnqFnsIIVS4uCMP9zcBmq9BjU7QWApqyMrpVSOuHJE3wTYb4w5CCAic4CuQNai7wqMzPh+PvC5pL/RuiswxxiTDBwSkf0Zn/db7sTPIukshA8B4wSnM/1H4wTjSP8xLQVSL+JMuUhyYgJpyRexpSVSnUSq//MZvuD0K4qtZAgEt00v9tD24F801+MqpVR+caXoKwBHs0xHA7dfaR1jTJqInAWCMuZvvGzbf73xWkQGAgMBKleu7Gr2SzkdcGoviO2SLyM2LqYa4lNsxCTZOZlYjAumNKkSQInixSlTpizVatSlePkaUDIEW2ApELm+DEop5Ybc4mKsMWYCMAEgLCzMXNeHBJaCwZs4l5TKliPxREbFEXH4DFuPxnMxJf1M0S1li3Jng2BahgYTVrUkAb46wJhSyvu5UvTHgEpZpitmzMtunWgR8QGKk35R1pVtc8WJs4n0m7KZvSfPYwzYBGqVK0b32ypyW9VSNA0pxU3FAvLip1ZKKbfmStFvBkJFJIT0ku4JPHLZOuFAH9LPvT8ErDLGGBEJB2aLyMekX4wNBX7PrfBZBRfxp3yJQnSsW5awKqVoWLkERfzd4j8sSillqWs2YcY592eAFaTfXjnZGLNTREYBEcaYcGASMCPjYmsc6f8YkLHeXNIv3KYBg/Pqjhsfu43JffWtTUopdTkx5vpOieeVsLAwExERYXUMpZTyKCISaYwJy26ZLb/DKKWUyl9a9Eop5eW06JVSystp0SullJfToldKKS+nRa+UUl5Oi14ppbyc291HLyKngMNW57hOpYHTVoewgO53waL77Z6qGGOyfdWd2xW9JxORiCs9sODNdL8LFt1vz6OnbpRSystp0SullJfTos9dE6wOYBHd74JF99vD6Dl6pZTycnpEr5RSXk6LXimlvJwWfQ6JSEcR2Ssi+0XklWyWVxaR1SKyRUS2icg9VuTMCy7sexUR+Tljv9eISEUrcuYmEZksIjEisuMKy0VEPsv4NdkmIrfmd8a84MJ+3yIiv4lIsoi8kN/58ooL+/1oxu/zdhHZICIN8jvj9dCizwERsQPjgE5AbaCXiNS+bLXXgbnGmEakv2nri/xNmTdc3PcPgenGmPrAKODd/E2ZJ6YCHa+yvBPpr8gMBQYCX+ZDpvwwlavvdxwwlPTfc28ylavv9yHgTmNMPeBtPOQCrRZ9zjQB9htjDhpjUoA5QNfL1jFAsYzviwPH8zFfXnJl32sDqzK+X53Nco9jjPmV9FK7kq6k/+NmjDEbgRIiUi5/0uWda+23MSbGGLMZSM2/VHnPhf3eYIw5kzG5EfCI/7Vq0edMBeBolunojHlZjQQeE5FoYBkwJH+i5TlX9v1PoFvG9w8ARUUkKB+yWcmVXxflnQYAy60O4Qot+tzXC5hqjKkI3EP6S9MLyq/zC8CdIrIFuBM4BuTJy+CVspKItCa96F+2OosrfKwO4GGOAZWyTFfMmJfVADLO8RljfhORANIHQ4rJl4R555r7bow5TsYRvYgUAR40xsTnW0JruPJnQnkREakPTAQ6GWNirc7jioJypJlbNgOhIhIiIn6kX2wNv2ydI0BbABGpBQQAp/I1Zd645r6LSOks/3sZDkzO54xWCAd6Z9x90xQ4a4w5YXUolTdEpDKwEHjcGPOX1XlcpUf0OWCMSRORZ4AVgB2YbIzZKSKjgAhjTDjwPPC1iPyH9AuzfY0XPH7s4r7fBbwrIgb4FRhsWeBcIiLfkL5fpTOuu7wJ+AIYY8aTfh3mHmA/cBHoZ03S3HWt/RaRskAE6TceOEXkOaC2MeacRZFzhQu/328AQcAXIgKQ5gkjWuoQCEop5eX01I1SSnk5LXqllPJyWvRKKeXltOiVUsrLadErpZSX06JXSikvp0WvlFJe7v8BGucpYbQliFkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHgD1NjP7DOW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "599656a5-3d2e-47ce-d6cb-d9e8a3837ba4"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 0.775, 0.8, S, 0.25, 0.02, 0.02] * nstock]).cuda()\n",
        "    return model(inputs.float())[0][1]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*nstock) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, 0.775, B, T)[0])\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"correct_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7MfujMQ7oij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "b17fed30-ac96-4fbf-b758-78dba3743d56"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1.225, 0.8, S, 0.25, 0.02, 0.02] * nstock]).cuda()\n",
        "    return model(inputs.float())[0][1]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*nstock) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, 1.225, B, T)[0])\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"correct_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "P0bCg1oIqSFj",
        "outputId": "2baf497c-9ed2-49a2-dc02-676d7f639f89"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, 0.8, S, 0.25, 0.02, 0.02] + [1, 1, 0.8, 1.225, 0.25, 0.02, 0.02] + [1, 1, 0.8, 0.775, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())[0][1]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p, 1.225, 0.775]) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, 1.0, B, T)[0])\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"correct_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3jCj1iMqfW4"
      },
      "source": [
        ""
      ],
      "execution_count": 36,
      "outputs": []
    }
  ]
}