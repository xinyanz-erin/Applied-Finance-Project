{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "European_Call_jax.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Pui/European_Call_jax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1TgzBZmOpEc",
        "cellView": "form",
        "collapsed": true,
        "outputId": "be5cd50d-5abb-4175-a219-69417c6d0689"
      },
      "source": [
        "#@title\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "from jax import device_put\n",
        "\n",
        "def test():\n",
        "  paths=100000\n",
        "  steps=252\n",
        "  stocks=3\n",
        "  key = random.PRNGKey(10)\n",
        "  x = random.normal(key, (paths,steps,stocks))\n",
        "  s0=random.randint(key,(stocks,1),50,100)*1.\n",
        "  s=s0\n",
        "  s = device_put(s)\n",
        "  for i in range(steps):\n",
        "    for j in range(stocks):\n",
        "      s+=x[:,i,j]\n",
        "  return(s0,s)\n",
        "\n",
        "a,b=test()\n",
        "\n",
        "print(a,np.mean(b,axis=1))\n",
        "\n",
        "jtest=jit(test)\n",
        "\n",
        "c,d=jtest()\n",
        "\n",
        "print(c,np.mean(d,axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[86.]\n",
            " [56.]\n",
            " [71.]] [85.99678  55.996777 70.99677 ]\n",
            "[[86.]\n",
            " [56.]\n",
            " [71.]] [85.99678  55.996777 70.99677 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZWaZ_PdRZs1",
        "cellView": "form",
        "collapsed": true,
        "outputId": "cc269f2c-282b-4d02-936d-3245b3ddd45b"
      },
      "source": [
        "#@title\n",
        "paths=10\n",
        "steps=5\n",
        "stocks=3\n",
        "key = random.PRNGKey(10)\n",
        "x = random.normal(key, (paths,steps,stocks))\n",
        "s0=random.randint(key,(stocks,1),50,100)*1.\n",
        "s=s0\n",
        "s = device_put(s)\n",
        "print(s)\n",
        "print(x[:,1,1])\n",
        "print(s+x[:,1,1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[86.]\n",
            " [56.]\n",
            " [71.]]\n",
            "[-0.32907748 -0.3529078  -0.5357338  -2.402825   -1.3187171  -0.4300647\n",
            " -0.42437345  0.22680947  0.3185347  -0.9541187 ]\n",
            "[[85.67092  85.647095 85.464264 83.597176 84.68128  85.56994  85.57563\n",
            "  86.22681  86.318535 85.04588 ]\n",
            " [55.67092  55.64709  55.464268 53.597176 54.681282 55.569935 55.575626\n",
            "  56.22681  56.318535 55.045883]\n",
            " [70.67092  70.647095 70.464264 68.597176 69.68128  70.56994  70.57563\n",
            "  71.22681  71.318535 70.04588 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM9Sjorq3aPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "outputId": "f2a537d1-0d3f-465f-e8b9-5b23939cd88b"
      },
      "source": [
        "#@title\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "\n",
        "def simple_process(key, initial_values, numsteps, drift, cov):\n",
        "    stocks_init = jnp.zeros((numsteps + 1,initial_values.shape[0]))\n",
        "    stocks_init=jax.ops.index_update(stocks_init,  # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],\n",
        "                            initial_values)\n",
        "    noise = jax.random.multivariate_normal(key, drift, cov, (numsteps,))\n",
        "    #return(noise)\n",
        "    def time_step(t, val):\n",
        "        dx =  drift+noise[t,:]\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] + dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "# def fori_loop(lower, upper, body_fun, init_val): # upper is exclusive\n",
        "#   val = init_val\n",
        "#   for i in range(lower, upper):\n",
        "#     val = body_fun(i, val)\n",
        "#   return val\n",
        "\n",
        "numsteps=5\n",
        "key = random.PRNGKey(10)\n",
        "drift=jnp.array([0.0]*3)\n",
        "cov=np.random.random((3,3))\n",
        "cov=np.matmul(cov,cov.T)\n",
        "initial_values=jnp.array([100.]*3)\n",
        "fast_simple = jax.jit(simple_process, static_argnums=2)\n",
        "init_stocks=jnp.array([100.]*3)\n",
        "fast_simple(key,init_stocks,numsteps,drift,cov)\n",
        "# Batch OU sample via vmap\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None)) \n",
        "# An integer or None indicates which array axis to map over for all arguments (with None indicating not to map any axis)\n",
        "\n",
        "%timeit fast_simple(key, init_stocks, 12, drift, cov)\n",
        "\n",
        "numsamples=100000 # num of paths\n",
        "keys = jax.random.split(key, numsamples)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None))\n",
        "%timeit batch_simple(keys, init_stocks, 12, drift, cov)\n",
        "\n",
        "batch_simple(keys, init_stocks, numsteps, drift, cov).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 27769.64 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 16.1 Âµs per loop\n",
            "1 loop, best of 5: 177 ms per loop\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 5, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKLz8BeVe5TQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "collapsed": true,
        "outputId": "92debbf8-323a-4172-9b26-f37891c40cf8"
      },
      "source": [
        "#@title\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, sigma, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init=jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],       # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key, drift, cov, (numsteps,))\n",
        "    dt = jnp.array(T[0]/numsteps)\n",
        "    def time_step(t, val):\n",
        "        dx =  drift * dt * val[t-1,:] + sigma * val[t-1,:] * jnp.sqrt(dt) * noise[t,:]\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] + dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "# def fori_loop(lower, upper, body_fun, init_val): # upper is exclusive\n",
        "#   val = init_val\n",
        "#   for i in range(lower, upper):\n",
        "#     val = body_fun(i, val)\n",
        "#   return val\n",
        "\n",
        "np.random.seed(0)\n",
        "key = random.PRNGKey(0)\n",
        "initial_stocks=jnp.array([100.]*3)\n",
        "numsteps=10\n",
        "drift=jnp.array([0]*3)\n",
        "# cov=np.random.random((3,3))\n",
        "# cov=np.matmul(cov,cov.T)\n",
        "corr = jnp.diag(jnp.array([1]*3))\n",
        "sigma = jnp.array([0.3]*3)\n",
        "cov = (jnp.diag(sigma)).dot(corr).dot(jnp.diag(sigma))\n",
        "#sigma = jnp.array(np.random.random(3))\n",
        "#r = jnp.array([np.random.random(1)]*3)\n",
        "T = jnp.array([1.]*3)\n",
        "\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "fast_simple(key, initial_stocks, numsteps, drift, cov, sigma, T)\n",
        "\n",
        "# numsamples=100000 # num of paths\n",
        "# keys = jax.random.split(key, numsamples)\n",
        "\n",
        "# batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None, None))\n",
        "# %timeit batch_simple(keys, initial_stocks, numsteps, drift, cov, sigma, T)\n",
        "# batch_simple(keys, initial_stocks, numsteps, drift, cov, sigma, T).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([[104.03143 , 103.00068 , 102.59222 ],\n",
              "             [102.768456, 105.89164 , 100.96432 ],\n",
              "             [102.81328 ,  99.627396, 102.55864 ],\n",
              "             [105.48844 , 101.25624 , 104.66836 ],\n",
              "             [105.8519  , 100.323296, 109.50462 ],\n",
              "             [106.59    ,  96.38026 , 107.60002 ],\n",
              "             [107.01583 ,  98.68716 , 104.24871 ],\n",
              "             [103.734055,  95.48625 , 102.4883  ],\n",
              "             [103.274185,  94.44483 ,  99.23759 ],\n",
              "             [102.81635 ,  93.41477 ,  96.08998 ]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7KFGhPVWJu9",
        "cellView": "form",
        "collapsed": true,
        "outputId": "d09cf7ac-aac3-4f78-a535-1ad4809939a8"
      },
      "source": [
        "#@title\n",
        "key = random.PRNGKey(10)\n",
        "initial_values=jnp.array([100.]*3)\n",
        "numsteps=5\n",
        "drift=jnp.array([0.0]*3)\n",
        "cov=np.random.random((3,3))\n",
        "cov=np.matmul(cov, cov.T)\n",
        "\n",
        "print(key)\n",
        "print(initial_values)\n",
        "print(numsteps)\n",
        "print(drift)\n",
        "print(cov)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 0 10]\n",
            "[100. 100. 100.]\n",
            "5\n",
            "[0. 0. 0.]\n",
            "[[0.74040995 0.50528954 0.38358708]\n",
            " [0.50528954 0.69334581 0.33222558]\n",
            " [0.38358708 0.33222558 0.21827158]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5F1U2n21WuDC",
        "cellView": "form",
        "collapsed": true,
        "outputId": "1b5b7145-262b-4ccf-8675-6cfc98cb63ae"
      },
      "source": [
        "#@title\n",
        "stocks_init = jnp.zeros((numsteps + 1, initial_values.shape[0]))\n",
        "print(stocks_init)\n",
        "stocks_init=jax.ops.index_update(stocks_init,\n",
        "                        jax.ops.index[0],\n",
        "                        initial_values)\n",
        "print(stocks_init)\n",
        "noise = jax.random.multivariate_normal(key, drift, cov, (numsteps,))\n",
        "print(noise)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]\n",
            " [0. 0. 0.]]\n",
            "[[100. 100. 100.]\n",
            " [  0.   0.   0.]\n",
            " [  0.   0.   0.]\n",
            " [  0.   0.   0.]\n",
            " [  0.   0.   0.]\n",
            " [  0.   0.   0.]]\n",
            "[[-0.05614188 -0.93355596 -0.05524409]\n",
            " [ 0.70478475 -0.20070948  0.15282556]\n",
            " [ 0.11612918 -0.04694405 -0.03823702]\n",
            " [ 0.42249295 -0.36928132 -0.06133213]\n",
            " [-0.24204297 -0.2061234  -0.13489908]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUAoeddX9Kr0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95c54348-56c0-4091-f05c-6e204d267dfa"
      },
      "source": [
        "!curl https://colab.chainer.org/install |sh -\n",
        "import cupy"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1580  100  1580    0     0   8186      0 --:--:-- --:--:-- --:--:--  8144\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "\u001b[K     |ââââââââââââââââââââââââââââââââ| 58.9 MB 30 kB/s \n",
            "\u001b[K     |ââââââââââââââââââââââââââââââââ| 1.0 MB 68.7 MB/s \n",
            "\u001b[?25h  Building wheel for chainer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "+ set +ex\n",
            "Installation succeeded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1crQ3-JCs9Q1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88d62f85-2d05-4204-c8cc-4a4745dc6868"
      },
      "source": [
        "# import jax\n",
        "# import jax.numpy as jnp\n",
        "# from jax import random\n",
        "# from jax import jit\n",
        "# import numpy as np\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "#     stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "#     stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "#                             jax.ops.index[0],         # initialization of stock prices\n",
        "#                             initial_stocks)\n",
        "#     noise = jax.random.multivariate_normal(key, jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps,))\n",
        "#     dt = jnp.array(T[0]/numsteps)\n",
        "#     def time_step(t, val):\n",
        "#         dx =  drift * dt * val[t-1,:] + val[t-1,:] * jnp.sqrt(dt) * noise[t,:] # no need to multiply by sigma here because noise generated by cov not corr\n",
        "#         val = jax.ops.index_update(val,\n",
        "#                             jax.ops.index[t],\n",
        "#                             val[t-1] + dx)\n",
        "#         return val\n",
        "#     return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "# # def fori_loop(lower, upper, body_fun, init_val): # upper is exclusive\n",
        "# #   val = init_val\n",
        "# #   for i in range(lower, upper):\n",
        "# #     val = body_fun(i, val)\n",
        "# #   return val\n",
        "\n",
        "# numstocks = 3\n",
        "\n",
        "# #np.random.seed(15)\n",
        "# key = random.PRNGKey(10)\n",
        "# initial_stocks = jnp.array(np.random.random(numstocks) * 200)\n",
        "# numsteps = 100\n",
        "# # drift=jnp.array([0.05] * numstocks) \n",
        "# # cov=np.random.random((3,3))\n",
        "# # cov=np.matmul(cov,cov.T)\n",
        "# corr = jnp.diag(jnp.array([1]*numstocks)) # assume no correlation between stocks here\n",
        "# sigma = jnp.array(np.random.random(numstocks) * 0.4)\n",
        "# cov = (jnp.diag(sigma)).dot(corr).dot(jnp.diag(sigma))\n",
        "# r = jnp.repeat(jnp.array(np.random.random(1) * 0.1), numstocks)\n",
        "# drift = r # To match BS, use drift = r\n",
        "# T = jnp.array([1.] * numstocks)\n",
        "\n",
        "# fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "# fast_simple(key, initial_stocks, numsteps, drift, cov, T)\n",
        "\n",
        "# numsamples = 100000 # num of paths\n",
        "# keys = jax.random.split(key, numsamples)\n",
        "\n",
        "# batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "# %timeit batch_simple(keys, initial_stocks, numsteps, drift, cov, T)\n",
        "# out = batch_simple(keys, initial_stocks, numsteps, drift, cov, T)\n",
        "\n",
        "# K = np.random.random(1) * 200\n",
        "# European_Call_price = np.mean(np.maximum((np.mean(out[:,numsteps,:], axis=1)) - K, 0) * jnp.exp(-r[0] * T[0]))\n",
        "\n",
        "# paras = (T, jnp.repeat(jnp.array(K), numstocks), initial_stocks, sigma, drift, r)\n",
        "# paras = np.column_stack(paras).reshape(1,-1)[0]\n",
        "\n",
        "# print(from_dlpack(cupy.array(paras).toDlpack()))\n",
        "# print(European_Call_price)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The slowest run took 187.96 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 2.32 ms per loop\n",
            "tensor([1.0000e+00, 5.8479e+01, 1.2630e+02, 1.3925e-02, 9.5619e-03, 9.5619e-03,\n",
            "        1.0000e+00, 5.8479e+01, 1.8647e+02, 3.9301e-01, 9.5619e-03, 9.5619e-03,\n",
            "        1.0000e+00, 5.8479e+01, 7.6436e+01, 1.8355e-01, 9.5619e-03, 9.5619e-03],\n",
            "       device='cuda:0')\n",
            "71.90888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCQv7CplV44K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3895a6-f40f-461b-d6b0-233475bd8554"
      },
      "source": [
        "# import jax\n",
        "# import jax.numpy as jnp\n",
        "# from jax import random\n",
        "# from jax import jit\n",
        "# import numpy as np\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "#     stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "#     stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "#                             jax.ops.index[0],         # initialization of stock prices\n",
        "#                             initial_stocks)\n",
        "#     noise = jax.random.multivariate_normal(key, jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps,))\n",
        "#     dt = jnp.array(T[0]/numsteps)\n",
        "#     def time_step(t, val):\n",
        "#         dx =  drift * dt * val[t-1,:] + val[t-1,:] * jnp.sqrt(dt) * noise[t,:] # no need to multiply by sigma here because noise generated by cov not corr\n",
        "#         val = jax.ops.index_update(val,\n",
        "#                             jax.ops.index[t],\n",
        "#                             val[t-1] + dx)\n",
        "#         return val\n",
        "#     return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "# rng = jax.random.PRNGKey(1)\n",
        "# rng, key = jax.random.split(rng)\n",
        "# numsteps = 100\n",
        "\n",
        "# r = jnp.repeat(jnp.array(np.random.random(1) * 0.1), numstocks)\n",
        "# drift = r # To match BS, use drift = r\n",
        "\n",
        "# corr = jnp.diag(jnp.array([1]*numstocks)) # assume no correlation between stocks here\n",
        "# sigma = jnp.array(np.random.random(numstocks) * 0.4)\n",
        "# cov = (jnp.diag(sigma)).dot(corr).dot(jnp.diag(sigma))\n",
        "\n",
        "# initial_stocks = jnp.array(np.random.random(numstocks) * 200)\n",
        "\n",
        "# T = jnp.array([1.] * numstocks)\n",
        "\n",
        "# fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "# numsamples = 100000 # num of paths\n",
        "# keys = jax.random.split(key, numsamples)\n",
        "# batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "# K = np.random.random(1) * 200\n",
        "# #jnp.mean(jnp.maximum((jnp.mean((batch_simple(keys, initial_stocks, numsteps, drift, cov, T))[:,numsteps,:], axis=1)) - K, 0) * jnp.exp(-r[0] * T[0]))\n",
        "\n",
        "# def optionvalue(key, initial_stocks, numsteps, drift, r, cov, T, K):\n",
        "#   return jnp.mean(jnp.maximum((jnp.mean((batch_simple(keys, initial_stocks, numsteps, drift, cov, T))[:,numsteps,:], axis=1)) - K, 0) * jnp.exp(-r[0] * T[0]))\n",
        "\n",
        "# gooptionvalue = jax.grad(optionvalue, argnums = 1)\n",
        "\n",
        "# #gooptionvalue(keys, initial_stocks, numsteps, drift, r, cov, T, K)\n",
        "\n",
        "# paras = (T, jnp.repeat(jnp.array(K), numstocks), initial_stocks, sigma, drift, r)\n",
        "# paras = np.column_stack(paras).reshape(1,-1)[0]\n",
        "\n",
        "# print(from_dlpack(cupy.array(paras).toDlpack()))\n",
        "# print(optionvalue(key, initial_stocks, numsteps, drift, r, cov, T, K))\n",
        "\n",
        "# # # def fori_loop(lower, upper, body_fun, init_val): # upper is exclusive\n",
        "# # #   val = init_val\n",
        "# # #   for i in range(lower, upper):\n",
        "# # #     val = body_fun(i, val)\n",
        "# # #   return val\n",
        "\n",
        "# # numstocks = 3\n",
        "\n",
        "# # #np.random.seed(15)\n",
        "# # key = random.PRNGKey(10)\n",
        "# # initial_stocks = jnp.array(np.random.random(numstocks) * 200)\n",
        "# # numsteps = 100\n",
        "# # # drift=jnp.array([0.05] * numstocks) \n",
        "# # # cov=np.random.random((3,3))\n",
        "# # # cov=np.matmul(cov,cov.T)\n",
        "# # corr = jnp.diag(jnp.array([1]*numstocks)) # assume no correlation between stocks here\n",
        "# # sigma = jnp.array(np.random.random(numstocks) * 0.4)\n",
        "# # cov = (jnp.diag(sigma)).dot(corr).dot(jnp.diag(sigma))\n",
        "# # r = jnp.repeat(jnp.array(np.random.random(1) * 0.1), numstocks)\n",
        "# # drift = r # To match BS, use drift = r\n",
        "# # T = jnp.array([1.] * numstocks)\n",
        "\n",
        "# # fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "# # fast_simple(key, initial_stocks, numsteps, drift, cov, T)\n",
        "\n",
        "# # numsamples = 100000 # num of paths\n",
        "# # keys = jax.random.split(key, numsamples)\n",
        "\n",
        "# # batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "# # #%timeit batch_simple(keys, initial_stocks, numsteps, drift, cov, T)\n",
        "# # #out = batch_simple(keys, initial_stocks, numsteps, drift, cov, T)\n",
        "\n",
        "# # K = np.random.random(1) * 200\n",
        "\n",
        "# # def optionvalue(keys, initial_stocks, numsteps, drift, cov, T, K):\n",
        "# #   return jnp.mean(jnp.maximum((jnp.mean((batch_simple(keys, initial_stocks, numsteps, drift, cov, T))[:,numsteps,:], axis=1)) - K, 0) * jnp.exp(-r[0] * T[0]))\n",
        "\n",
        "# # gooptionvalue = jax.grad(optionvalue, argnums = 1)\n",
        "\n",
        "# # gooptionvalue(keys, initial_stocks, numsteps, drift, cov, T, K)\n",
        "\n",
        "# # #European_Call_price = np.mean(np.maximum((np.mean(out[:,numsteps,:], axis=1)) - K, 0) * jnp.exp(-r[0] * T[0]))\n",
        "\n",
        "# # # paras = (T, jnp.repeat(jnp.array(K), numstocks), initial_stocks, sigma, drift, r)\n",
        "# # # paras = np.column_stack(paras).reshape(1,-1)[0]\n",
        "\n",
        "# # # print(from_dlpack(cupy.array(paras).toDlpack()))\n",
        "# # # print(European_Call_price)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([0., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OUt9yONbxp0"
      },
      "source": [
        "# Peter's code\n",
        "\n",
        "def simple_process(key, initial_stocks, numsteps, drift, cov):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key, drift, cov, (numsteps+1,))\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    def time_step(t, val):\n",
        "        dx =  drift + noise[t,:] # no need to multiply by sigma here because noise generated by cov not corr\n",
        "        dx2 = jnp.exp((drift - sigma ** 2. / 2.) + noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx2)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalue(key, initial_stocks, numsteps, drift, cov, strike):\n",
        "  return jnp.mean((jnp.maximum(batch_simple(keys, initial_stocks, numsteps, drift, cov)[:,-1,:]-strike,0))) # this is assuming 1 stock for testing price (didn't take avg)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, cov, strike):\n",
        "  return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov)[:,-1,:], axis=1)-strike,0))) # this is assuming 3 stocks in basket"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXOYzdQvR_PB",
        "outputId": "c4b0199d-6fe3-4630-e44b-7bb5b78443b8"
      },
      "source": [
        "# Peter's code\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "numstocks = 3\n",
        "\n",
        "rng = jax.random.PRNGKey(1)\n",
        "rng, key = jax.random.split(rng)\n",
        "#numsteps = 10\n",
        "drift = jnp.array([0.0]*numstocks)\n",
        "\n",
        "cov = jnp.identity(numstocks)*.25*.25\n",
        "initial_stocks = jnp.array([100.]*numstocks)\n",
        "\n",
        "K = 110.0\n",
        "\n",
        "fast_simple = jax.jit(simple_process, static_argnums=2)\n",
        "#fast_simple(key, initial_stocks, numsteps, drift, cov)\n",
        "\n",
        "keys = jax.random.split(key, 1000000)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None))\n",
        "\n",
        "print(initial_stocks) #S = 100\n",
        "print(K) #K = 110\n",
        "print(cov) #sigma = 0.25\n",
        "print(drift) #drift = 0\n",
        "\n",
        "#################################################################################### values for checking\n",
        "#S, K, r, sigma, T\n",
        "# 100, 110, 0, 0.25, 1\n",
        "# 1 stock price should be around 6.1904\n",
        "# 3 stock price should be around 2.3767\n",
        "# delta should be around (0.39888 / numstocks)\n",
        "####################################################################################\n",
        "\n",
        "# option price\n",
        "# 1 stock\n",
        "print(optionvalue(key, initial_stocks, 1, drift, cov, K)) # numsteps here = years = 1\n",
        "# 3 stocks basket\n",
        "print(optionvalueavg(key, initial_stocks, 1, drift, cov, K)) # numsteps here = years = 1\n",
        "\n",
        "# delta test\n",
        "gooptionvalue = jax.grad(optionvalue,argnums=1)\n",
        "gooptionvalue(keys, initial_stocks, 1, drift, cov, K) # numsteps here = years = 1"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100. 100. 100.]\n",
            "110.0\n",
            "[[0.0625 0.     0.    ]\n",
            " [0.     0.0625 0.    ]\n",
            " [0.     0.     0.0625]]\n",
            "[0. 0. 0.]\n",
            "6.1957526\n",
            "2.3685584\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([0.13313732, 0.13304196, 0.13283278], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWYfON_marpj",
        "outputId": "49719971-6482-4c97-a34f-5d7657f9d4e4"
      },
      "source": [
        "# now change code such that 'numsteps' does not represent year\n",
        "# make dt = year / numsteps\n",
        "# (done)\n",
        "# after making the changes, the values are still correct\n",
        "\n",
        "def simple_process(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key, drift, cov, (numsteps+1,))\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        #dx =  drift + noise[t,:] # no need to multiply by sigma here because noise generated by cov not corr\n",
        "        dx2 = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx2)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalue(key, initial_stocks, numsteps, drift, cov, strike, T):\n",
        "  return jnp.mean((jnp.maximum(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:]-strike,0))) # this is assuming 1 stock for testing price (didn't take avg)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, cov, strike, T):\n",
        "  return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-strike,0))) # this is assuming 3 stocks in basket\n",
        "\n",
        "numstocks = 3\n",
        "\n",
        "rng = jax.random.PRNGKey(1)\n",
        "rng, key = jax.random.split(rng)\n",
        "numsteps = 50\n",
        "drift = jnp.array([0.0]*numstocks)\n",
        "\n",
        "cov = jnp.identity(numstocks)*.25*.25\n",
        "initial_stocks = jnp.array([100.]*numstocks)\n",
        "\n",
        "T = 1.0\n",
        "K = 110.0\n",
        "\n",
        "fast_simple = jax.jit(simple_process, static_argnums=2)\n",
        "#fast_simple(key, initial_stocks, numsteps, drift, cov)\n",
        "\n",
        "keys = jax.random.split(key, 1000000)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "print(initial_stocks) #S = 100\n",
        "print(K) #K = 110\n",
        "print(cov) #sigma = 0.25\n",
        "print(drift) #drift = 0\n",
        "\n",
        "#################################################################################### values for checking\n",
        "#S, K, r, sigma, T\n",
        "# 100, 110, 0, 0.25, 1\n",
        "# 1 stock price should be around 6.1904\n",
        "# 3 stock price should be around 2.3767\n",
        "# delta should be around (0.39888 / numstocks)\n",
        "####################################################################################\n",
        "\n",
        "# option price\n",
        "# 1 stock\n",
        "print(optionvalue(key, initial_stocks, numsteps, drift, cov, 110, T)) # numsteps here = 50, but T = year = 1\n",
        "# 3 stocks basket\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, cov, 110, T)) # numsteps here = 50, but T = year = 1\n",
        "\n",
        "# delta test\n",
        "gooptionvalue = jax.grad(optionvalue,argnums=1)\n",
        "gooptionvalue(keys, initial_stocks, numsteps, drift, cov, 110, T) # numsteps here = 50, but T = year = 1"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[100. 100. 100.]\n",
            "110.0\n",
            "[[0.0625 0.     0.    ]\n",
            " [0.     0.0625 0.    ]\n",
            " [0.     0.     0.0625]]\n",
            "[0. 0. 0.]\n",
            "6.189104\n",
            "2.3675647\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DeviceArray([0.13300765, 0.1338707 , 0.13241932], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxFUnc_iBVcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aa461d4-8ec1-4080-ceed-cba17b33adb5"
      },
      "source": [
        "################################# TEST ########################################\n",
        "%%writefile cupy_dataset.py\n",
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key, jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps,))\n",
        "    dt = jnp.array(T[0]/numsteps)\n",
        "    def time_step(t, val):\n",
        "        dx =  drift * dt * val[t-1,:] + val[t-1,:] * jnp.sqrt(dt) * noise[t,:] # no need to multiply by sigma here because noise generated by cov not corr\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] + dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "\n",
        "class NumbaOptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len=10, number_path = 1000, batch=2, seed=15, stocks=3):  # 3 stocks\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 365\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = 1\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros((self.N_BATCH, 1 + self.N_STOCKS * 2), dtype=cupy.float32) # output: price, delta1, delta2, delta3, gamma1, gamma2, gamma3\n",
        "        X = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "\n",
        "        for op in range(self.N_BATCH):\n",
        "          \n",
        "          key = random.PRNGKey(self.seed)\n",
        "          initial_stocks = jnp.array(np.random.random(self.N_STOCKS) * 200)\n",
        "          # cov=np.random.random((3,3))\n",
        "          # cov=np.matmul(cov,cov.T)\n",
        "          corr = jnp.diag(jnp.array([1]*self.N_STOCKS)) # assume no correlation between stocks here\n",
        "          sigma = jnp.array(np.random.random(self.N_STOCKS) * 0.4)\n",
        "          cov = (jnp.diag(sigma)).dot(corr).dot(jnp.diag(sigma))\n",
        "          r = jnp.repeat(jnp.array(np.random.random(1) * 0.1), self.N_STOCKS)\n",
        "          drift = r # To match BS, use drift = r\n",
        "          T = jnp.array([self.T] * self.N_STOCKS)\n",
        "          K = np.random.random(1) * 200\n",
        "\n",
        "          fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "          fast_simple(key, initial_stocks, self.N_STEPS, drift, cov, T)\n",
        "\n",
        "          numsamples = self.N_PATHS # num of paths\n",
        "          keys = jax.random.split(key, numsamples)\n",
        "\n",
        "          batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "          out = batch_simple(keys, initial_stocks, self.N_STEPS, drift, cov, T)\n",
        "\n",
        "          European_Call_price = np.mean(np.maximum((np.mean(out[:,self.N_STEPS,:], axis=1)) - K, 0) * jnp.exp(-r[0] * T[0]))\n",
        "          Y[op, 0] = European_Call_price\n",
        "          Y[op, 1:7] = cupy.array(np.arange(1, 7, 1), dtype=cupy.float32) # test: assume some number for greeks\n",
        "\n",
        "          paras = (T, jnp.repeat(jnp.array(K), self.N_STOCKS), initial_stocks, sigma, drift, r)\n",
        "          paras = np.column_stack(paras).reshape(1,-1)[0]\n",
        "          X[op,] = cupy.array(paras)\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "# ds = NumbaOptionDataSet(2, number_path = 10000, batch = 2, seed = 15, stocks=3)\n",
        "# for i in ds:\n",
        "#     print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cupy_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6JO9OBHdvv",
        "outputId": "cdf2ad85-2850-44bc-b88f-7e06865493ce"
      },
      "source": [
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*3, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 7) # 7 outputs: price, delta1, delta2, delta3, gamma1, gamma2, gamma3\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1, 200.0, 200.0, 0.4, 0.1, 0.1]*3)) # don't use numpy here - will give error later\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlXD80xPNVc6",
        "outputId": "9c08465e-e800-49b6-8901-0f063ac681e8"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.7/dist-packages (0.4.6)\n",
            "Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "S3CyULkENYKb",
        "outputId": "bb712633-830c-489a-dc16-55e398f11684"
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import NumbaOptionDataSet\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = NumbaOptionDataSet(max_len = 100, number_path = 1024, batch = 32, stocks = 3)\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    #print(y)\n",
        "    y_pred = model(x)\n",
        "    #print(y_pred)\n",
        "    loss = loss_fn(y_pred[:,:], y[:,:]) # compute MSE between the 2 arrays\n",
        "    #print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 170.97227478027344 average time 0.2868524645999514 iter num 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-26b84b662747>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    799\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m           \u001b[0;31m# cov=np.random.random((3,3))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m           \u001b[0;31m# cov=np.matmul(cov,cov.T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m           \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STOCKS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# assume no correlation between stocks here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m           \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STOCKS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m           \u001b[0mcov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mdiag\u001b[0;34m(v, k)\u001b[0m\n\u001b[1;32m   3950\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0m_abs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3951\u001b[0m     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3952\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3953\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3954\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdiagonal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36mzeros_like\u001b[0;34m(a, dtype, shape)\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3134\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3135\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mfull_like\u001b[0;34m(x, fill_value, dtype, shape)\u001b[0m\n\u001b[1;32m   1891\u001b[0m   \u001b[0mweak_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_weakly_typed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m   \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1893\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_convert_element_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_convert_element_type\u001b[0;34m(operand, new_dtype, weak_type)\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m     return convert_element_type_p.bind(operand, new_dtype=new_dtype,\n\u001b[0;32m--> 459\u001b[0;31m                                        weak_type=new_weak_type)\n\u001b[0m\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbitcast_convert_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperand\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    263\u001b[0m         args, used_axis_names(self, params) if self._dispatch_on_params else None)\n\u001b[1;32m    264\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    272\u001b[0m   \u001b[0;34m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m   \u001b[0mcompiled_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxla_primitive_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0munsafe_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled_primitive\u001b[0;34m(prim, compiled, result_handler, *args)\u001b[0m\n\u001b[1;32m    388\u001b[0m   \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m   \u001b[0minput_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_put\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m   \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c05fb9d-09d8-4fb5-af64-b8b7e9dc53fe"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'Sobolev_test_2.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "613a702e-2e6e-42f1-aab8-da92d1bb5303"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8dc1776-0f54-4b67-eb1b-e34c2ba665e3"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'Sobolev_test_2.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef9d942b-6a8e-4696-87fa-13e72c957350"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=18, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc5): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc6): Linear(in_features=1024, out_features=7, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ca1047-1388-4a8a-e04a-920390a8aaca"
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import NumbaOptionDataSet\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "#dataset = NumbaOptionDataSet(max_len = 100, number_path = 1024, batch = 32, stocks = 3)\n",
        "dataset = NumbaOptionDataSet(max_len = 100, number_path = 10000, batch = 8, stocks = 3)\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    #print(y)\n",
        "    y_pred = model(x)\n",
        "    #print(y_pred)\n",
        "    loss = loss_fn(y_pred[:,:], y[:,:]) # compute MSE between the 2 arrays\n",
        "    #print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 50)\n",
        "\n",
        "model_save_name = 'Sobolev_test_3.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 1.029026985168457 average time 0.0340081225999711 iter num 20\n",
            "loss 0.617005467414856 average time 0.018951306099870634 iter num 40\n",
            "loss 0.03694123774766922 average time 0.013974828499885916 iter num 60\n",
            "loss 0.021337922662496567 average time 0.011435932699873775 iter num 80\n",
            "loss 0.09433745592832565 average time 0.009915153309921152 iter num 100\n",
            "loss 0.11723805218935013 average time 0.0183694542000012 iter num 20\n",
            "loss 0.01526159979403019 average time 0.01111411579995547 iter num 40\n",
            "loss 0.1372022032737732 average time 0.008679239499845911 iter num 60\n",
            "loss 0.009897846728563309 average time 0.00744770511232673 iter num 80\n",
            "loss 0.02277585119009018 average time 0.006720673529907799 iter num 100\n",
            "loss 0.176094189286232 average time 0.018482654399849707 iter num 20\n",
            "loss 0.7619354724884033 average time 0.011126924624977618 iter num 40\n",
            "loss 0.016424519941210747 average time 0.008681149066675668 iter num 60\n",
            "loss 0.07612674683332443 average time 0.007461873924989959 iter num 80\n",
            "loss 0.17612077295780182 average time 0.006743284780022805 iter num 100\n",
            "loss 0.07285795360803604 average time 0.01913797165025244 iter num 20\n",
            "loss 0.31574195623397827 average time 0.011501843375208409 iter num 40\n",
            "loss 0.22184062004089355 average time 0.008981664616809819 iter num 60\n",
            "loss 0.09382329136133194 average time 0.007669310950086583 iter num 80\n",
            "loss 0.030084067955613136 average time 0.006873544570098602 iter num 100\n",
            "loss 0.23569482564926147 average time 0.018495464500028903 iter num 20\n",
            "loss 0.17928428947925568 average time 0.011058487500076809 iter num 40\n",
            "loss 0.03594185784459114 average time 0.00859476865010341 iter num 60\n",
            "loss 0.2106533944606781 average time 0.007351223575028598 iter num 80\n",
            "loss 0.03527126461267471 average time 0.006621893960036687 iter num 100\n",
            "loss 0.051669761538505554 average time 0.018363753049925435 iter num 20\n",
            "loss 0.05015193670988083 average time 0.011047666124977696 iter num 40\n",
            "loss 0.19285403192043304 average time 0.008659290299995822 iter num 60\n",
            "loss 0.3058931529521942 average time 0.00749733971247224 iter num 80\n",
            "loss 0.025059062987565994 average time 0.0067500392899819414 iter num 100\n",
            "loss 0.050493452697992325 average time 0.019302934400093362 iter num 20\n",
            "loss 0.038786426186561584 average time 0.011552211725029338 iter num 40\n",
            "loss 0.007763484958559275 average time 0.008966385433420024 iter num 60\n",
            "loss 0.13111799955368042 average time 0.0076440793000756456 iter num 80\n",
            "loss 0.16317343711853027 average time 0.006845633240045572 iter num 100\n",
            "loss 5.263354778289795 average time 0.01852836035004657 iter num 20\n",
            "loss 0.1232566386461258 average time 0.011106684524884258 iter num 40\n",
            "loss 0.2529465854167938 average time 0.008646461266622888 iter num 60\n",
            "loss 0.029247263446450233 average time 0.007417609949970938 iter num 80\n",
            "loss 0.11600920557975769 average time 0.006653678630009381 iter num 100\n",
            "loss 0.15117716789245605 average time 0.018183959650104952 iter num 20\n",
            "loss 0.3993252217769623 average time 0.010925416725194736 iter num 40\n",
            "loss 0.014664767310023308 average time 0.008573970183442725 iter num 60\n",
            "loss 0.045852091163396835 average time 0.007339357275054681 iter num 80\n",
            "loss 0.03962501510977745 average time 0.006589585390047432 iter num 100\n",
            "loss 0.8198221921920776 average time 0.018660157350132066 iter num 20\n",
            "loss 0.07394543290138245 average time 0.011197566899954835 iter num 40\n",
            "loss 0.2116485983133316 average time 0.008672925150009784 iter num 60\n",
            "loss 0.09257777780294418 average time 0.00741514358751374 iter num 80\n",
            "loss 0.09817323833703995 average time 0.006650265140051488 iter num 100\n",
            "loss 0.04933295398950577 average time 0.019343931999992493 iter num 20\n",
            "loss 0.017714133486151695 average time 0.011571555174896275 iter num 40\n",
            "loss 0.2578217685222626 average time 0.008913081633302984 iter num 60\n",
            "loss 0.12312507629394531 average time 0.007608295699992595 iter num 80\n",
            "loss 0.03024757094681263 average time 0.00681794791997163 iter num 100\n",
            "loss 0.06693051755428314 average time 0.018454385149925655 iter num 20\n",
            "loss 0.732535183429718 average time 0.011110534674890005 iter num 40\n",
            "loss 0.21512112021446228 average time 0.008590181666568242 iter num 60\n",
            "loss 0.0750415176153183 average time 0.007362877199898321 iter num 80\n",
            "loss 0.08634065836668015 average time 0.006601261339910707 iter num 100\n",
            "loss 0.28695955872535706 average time 0.018310746899715014 iter num 20\n",
            "loss 0.19417177140712738 average time 0.010922975949733882 iter num 40\n",
            "loss 0.19032829999923706 average time 0.008480063116500484 iter num 60\n",
            "loss 0.09884647279977798 average time 0.007268730462396888 iter num 80\n",
            "loss 0.13063876330852509 average time 0.006545470239962015 iter num 100\n",
            "loss 0.04802323505282402 average time 0.01902177874962945 iter num 20\n",
            "loss 0.11973200738430023 average time 0.011300568749902595 iter num 40\n",
            "loss 0.19098211824893951 average time 0.00882670145007675 iter num 60\n",
            "loss 0.10967302322387695 average time 0.007519747912556341 iter num 80\n",
            "loss 0.03440920263528824 average time 0.006751355310043437 iter num 100\n",
            "loss 0.31206196546554565 average time 0.018933622449640097 iter num 20\n",
            "loss 2.1219377517700195 average time 0.011306437024813931 iter num 40\n",
            "loss 0.7964522838592529 average time 0.008802394299891603 iter num 60\n",
            "loss 0.33631643652915955 average time 0.007496677387439377 iter num 80\n",
            "loss 0.10052261501550674 average time 0.006727758729994093 iter num 100\n",
            "loss 1.4340656995773315 average time 0.018676348149892875 iter num 20\n",
            "loss 0.5694433450698853 average time 0.011156338974979007 iter num 40\n",
            "loss 0.07274973392486572 average time 0.008663742850027726 iter num 60\n",
            "loss 0.03339308500289917 average time 0.0074275458875035835 iter num 80\n",
            "loss 0.015212670899927616 average time 0.0066714107199732095 iter num 100\n",
            "loss 0.18612153828144073 average time 0.018534424700010276 iter num 20\n",
            "loss 0.3481162488460541 average time 0.011052329050016851 iter num 40\n",
            "loss 0.1890137791633606 average time 0.00867512725008055 iter num 60\n",
            "loss 0.17924466729164124 average time 0.007388756637556071 iter num 80\n",
            "loss 0.06559775769710541 average time 0.006621526390081272 iter num 100\n",
            "loss 0.34453094005584717 average time 0.018250014299974283 iter num 20\n",
            "loss 0.30187103152275085 average time 0.01098802852479821 iter num 40\n",
            "loss 0.06827791035175323 average time 0.008587995566570802 iter num 60\n",
            "loss 0.0811426043510437 average time 0.007387100362461751 iter num 80\n",
            "loss 0.11006683111190796 average time 0.006639080709937843 iter num 100\n",
            "loss 0.08216547966003418 average time 0.01831480590026331 iter num 20\n",
            "loss 0.7681877017021179 average time 0.011021059125096145 iter num 40\n",
            "loss 0.3248593807220459 average time 0.008534464283457055 iter num 60\n",
            "loss 0.12011946737766266 average time 0.007311719287599772 iter num 80\n",
            "loss 0.049394529312849045 average time 0.006568638670069049 iter num 100\n",
            "loss 0.23727528750896454 average time 0.018416009049542482 iter num 20\n",
            "loss 0.2695482671260834 average time 0.01099829349996071 iter num 40\n",
            "loss 0.2528647780418396 average time 0.008558258983309011 iter num 60\n",
            "loss 0.051315054297447205 average time 0.007310622699947089 iter num 80\n",
            "loss 0.12619906663894653 average time 0.006565447689954453 iter num 100\n",
            "loss 0.2896241843700409 average time 0.018281470500005524 iter num 20\n",
            "loss 0.058612219989299774 average time 0.010987916399972163 iter num 40\n",
            "loss 0.029875054955482483 average time 0.008545030016739475 iter num 60\n",
            "loss 0.02426311932504177 average time 0.007317499950067941 iter num 80\n",
            "loss 0.041583351790905 average time 0.006567413279990433 iter num 100\n",
            "loss 0.1548672616481781 average time 0.01852963325009114 iter num 20\n",
            "loss 0.6267627477645874 average time 0.011109572225086595 iter num 40\n",
            "loss 0.5728351473808289 average time 0.008653221700114955 iter num 60\n",
            "loss 0.0533800944685936 average time 0.007432846712640639 iter num 80\n",
            "loss 0.12511257827281952 average time 0.0066525877201456755 iter num 100\n",
            "loss 0.2454756796360016 average time 0.018478513050376934 iter num 20\n",
            "loss 0.1089206114411354 average time 0.011090115000251899 iter num 40\n",
            "loss 0.07945262640714645 average time 0.00859436918344727 iter num 60\n",
            "loss 0.16585344076156616 average time 0.007355546437611338 iter num 80\n",
            "loss 0.15714044868946075 average time 0.006621635890078323 iter num 100\n",
            "loss 0.5424817800521851 average time 0.0191776425000171 iter num 20\n",
            "loss 0.15451405942440033 average time 0.011416815150096227 iter num 40\n",
            "loss 0.17216487228870392 average time 0.00883438758343497 iter num 60\n",
            "loss 0.1447705775499344 average time 0.007507871125130805 iter num 80\n",
            "loss 0.026883665472269058 average time 0.006760174580067542 iter num 100\n",
            "loss 0.5446352958679199 average time 0.019972658900042007 iter num 20\n",
            "loss 0.2371034324169159 average time 0.011789003600006254 iter num 40\n",
            "loss 0.45010581612586975 average time 0.009042648883284226 iter num 60\n",
            "loss 0.24682733416557312 average time 0.0076772175624910234 iter num 80\n",
            "loss 0.11796966940164566 average time 0.006840660710022348 iter num 100\n",
            "loss 0.07325491309165955 average time 0.031392839299951444 iter num 20\n",
            "loss 0.15193960070610046 average time 0.0175149762001638 iter num 40\n",
            "loss 0.14460928738117218 average time 0.012880004516773624 iter num 60\n",
            "loss 0.0589282363653183 average time 0.010576445462629636 iter num 80\n",
            "loss 0.025128738954663277 average time 0.009234439480133005 iter num 100\n",
            "loss 0.3757663667201996 average time 0.018713398900035826 iter num 20\n",
            "loss 0.5194064974784851 average time 0.011688560150059858 iter num 40\n",
            "loss 0.19061799347400665 average time 0.009062341916705918 iter num 60\n",
            "loss 0.14505591988563538 average time 0.007745271362500717 iter num 80\n",
            "loss 0.1079569086432457 average time 0.006963444979992346 iter num 100\n",
            "loss 0.12001897394657135 average time 0.019068066450381595 iter num 20\n",
            "loss 0.01720508188009262 average time 0.011378680400321172 iter num 40\n",
            "loss 0.10829202830791473 average time 0.008803786616863363 iter num 60\n",
            "loss 0.07405781745910645 average time 0.007497369950147004 iter num 80\n",
            "loss 0.12687690556049347 average time 0.006729968250147067 iter num 100\n",
            "loss 0.17228911817073822 average time 0.01889337489983518 iter num 20\n",
            "loss 0.08693119883537292 average time 0.011373639149951487 iter num 40\n",
            "loss 0.09883496165275574 average time 0.008859636083313187 iter num 60\n",
            "loss 0.04444693401455879 average time 0.007603588125061833 iter num 80\n",
            "loss 0.026035748422145844 average time 0.0068453760900411 iter num 100\n",
            "loss 0.5289120674133301 average time 0.019170302500242542 iter num 20\n",
            "loss 0.08364789932966232 average time 0.011503417049925701 iter num 40\n",
            "loss 0.09153459966182709 average time 0.008934789416677328 iter num 60\n",
            "loss 0.16846957802772522 average time 0.00764270652500727 iter num 80\n",
            "loss 0.09572213143110275 average time 0.006867312680005852 iter num 100\n",
            "loss 0.21325156092643738 average time 0.01851150594993669 iter num 20\n",
            "loss 0.6387319564819336 average time 0.011177369224833455 iter num 40\n",
            "loss 0.6105710864067078 average time 0.008739573766555016 iter num 60\n",
            "loss 0.2043374925851822 average time 0.007504031687403767 iter num 80\n",
            "loss 0.14201855659484863 average time 0.006767363719900459 iter num 100\n",
            "loss 6.9377760887146 average time 0.019140262300061293 iter num 20\n",
            "loss 6.385639667510986 average time 0.011552714424988153 iter num 40\n",
            "loss 3.367457151412964 average time 0.008970773316741542 iter num 60\n",
            "loss 0.48963242769241333 average time 0.007700156837540817 iter num 80\n",
            "loss 0.17405541241168976 average time 0.006921650980057165 iter num 100\n",
            "loss 0.04300476983189583 average time 0.01991262054980325 iter num 20\n",
            "loss 0.03148622065782547 average time 0.011887244699892108 iter num 40\n",
            "loss 0.1312597393989563 average time 0.009192914183343722 iter num 60\n",
            "loss 0.08136742562055588 average time 0.00784484226251152 iter num 80\n",
            "loss 0.03927911818027496 average time 0.007040463280009135 iter num 100\n",
            "loss 0.23972168564796448 average time 0.018684232650048215 iter num 20\n",
            "loss 0.3111225366592407 average time 0.011270559425065585 iter num 40\n",
            "loss 0.0540802963078022 average time 0.008837222716708008 iter num 60\n",
            "loss 0.02423376962542534 average time 0.007563862900019558 iter num 80\n",
            "loss 0.28696417808532715 average time 0.0068060571899877685 iter num 100\n",
            "loss 0.0754755288362503 average time 0.019312748800166445 iter num 20\n",
            "loss 0.07640735805034637 average time 0.011601988650090789 iter num 40\n",
            "loss 0.07431939989328384 average time 0.008993121900039114 iter num 60\n",
            "loss 0.013795454055070877 average time 0.007687825875063936 iter num 80\n",
            "loss 0.02254750020802021 average time 0.00690666685004544 iter num 100\n",
            "loss 0.179475337266922 average time 0.019289797549936337 iter num 20\n",
            "loss 0.509458065032959 average time 0.011438061550052225 iter num 40\n",
            "loss 0.2619682550430298 average time 0.008844033183443874 iter num 60\n",
            "loss 0.20494705438613892 average time 0.007569154412544776 iter num 80\n",
            "loss 0.014541986398398876 average time 0.006758945990040957 iter num 100\n",
            "loss 0.08083616197109222 average time 0.01872047040023972 iter num 20\n",
            "loss 0.2783210277557373 average time 0.011262231800037626 iter num 40\n",
            "loss 0.17241045832633972 average time 0.00879235419994681 iter num 60\n",
            "loss 0.0705413669347763 average time 0.007562348974988709 iter num 80\n",
            "loss 0.051872096955776215 average time 0.0068015583399756 iter num 100\n",
            "loss 0.11057326197624207 average time 0.018652494699836097 iter num 20\n",
            "loss 0.05735247582197189 average time 0.01113254247502482 iter num 40\n",
            "loss 0.12390603870153427 average time 0.00859795338328695 iter num 60\n",
            "loss 0.022420581430196762 average time 0.007350239724928542 iter num 80\n",
            "loss 0.009250734932720661 average time 0.0065940417898855234 iter num 100\n",
            "loss 0.03161395713686943 average time 0.018158050550300685 iter num 20\n",
            "loss 0.15550577640533447 average time 0.010874103550077053 iter num 40\n",
            "loss 0.07665322721004486 average time 0.008468384950022785 iter num 60\n",
            "loss 0.16059204936027527 average time 0.007236295337497723 iter num 80\n",
            "loss 0.16537222266197205 average time 0.006497287470010633 iter num 100\n",
            "loss 0.05912007763981819 average time 0.01845241060009357 iter num 20\n",
            "loss 0.36845168471336365 average time 0.011054399524937253 iter num 40\n",
            "loss 0.23829416930675507 average time 0.008561748866547229 iter num 60\n",
            "loss 0.061866771429777145 average time 0.007326470062457702 iter num 80\n",
            "loss 0.017453037202358246 average time 0.006589050049969955 iter num 100\n",
            "loss 0.023313043639063835 average time 0.018009692950272438 iter num 20\n",
            "loss 0.1268545687198639 average time 0.010962928300114073 iter num 40\n",
            "loss 0.05125473067164421 average time 0.008510217533421382 iter num 60\n",
            "loss 0.039802271872758865 average time 0.007340536325114044 iter num 80\n",
            "loss 0.11143134534358978 average time 0.006571389390046534 iter num 100\n",
            "loss 0.2418496012687683 average time 0.01784625845002665 iter num 20\n",
            "loss 0.09215004742145538 average time 0.010677384299879123 iter num 40\n",
            "loss 0.043461691588163376 average time 0.008357926050030074 iter num 60\n",
            "loss 0.027098074555397034 average time 0.007170206362548015 iter num 80\n",
            "loss 0.0704638883471489 average time 0.006446692180070386 iter num 100\n",
            "loss 0.054895371198654175 average time 0.018548232449757052 iter num 20\n",
            "loss 0.07716357707977295 average time 0.011192906575024609 iter num 40\n",
            "loss 0.08350833505392075 average time 0.00871422378331772 iter num 60\n",
            "loss 0.10712950676679611 average time 0.0075004028999956064 iter num 80\n",
            "loss 0.03246910497546196 average time 0.0067665936900630184 iter num 100\n",
            "loss 1.3754613399505615 average time 0.01943630130008387 iter num 20\n",
            "loss 1.1568489074707031 average time 0.01152677602494805 iter num 40\n",
            "loss 0.2804810702800751 average time 0.00888307768324618 iter num 60\n",
            "loss 0.11961428821086884 average time 0.007544727724939549 iter num 80\n",
            "loss 0.06841382384300232 average time 0.006753681629925267 iter num 100\n",
            "loss 0.026679430156946182 average time 0.018472024299899203 iter num 20\n",
            "loss 0.08504362404346466 average time 0.011020032799888214 iter num 40\n",
            "loss 0.15486162900924683 average time 0.00855172613337345 iter num 60\n",
            "loss 0.010367577895522118 average time 0.007368506212560533 iter num 80\n",
            "loss 0.020587895065546036 average time 0.006608283780042257 iter num 100\n",
            "loss 0.524247407913208 average time 0.01808256620015527 iter num 20\n",
            "loss 0.22756080329418182 average time 0.0108504198251012 iter num 40\n",
            "loss 0.08229942619800568 average time 0.00839883821672629 iter num 60\n",
            "loss 0.08713608235120773 average time 0.007182618412548436 iter num 80\n",
            "loss 0.028058495372533798 average time 0.0064626070799931766 iter num 100\n",
            "loss 0.04008333384990692 average time 0.018308999849887188 iter num 20\n",
            "loss 0.059152938425540924 average time 0.011038912574895221 iter num 40\n",
            "loss 0.024085674434900284 average time 0.008655529199889619 iter num 60\n",
            "loss 0.012430834583938122 average time 0.007456603324999378 iter num 80\n",
            "loss 0.048957426100969315 average time 0.0067071657700398645 iter num 100\n",
            "loss 0.3304767310619354 average time 0.018334908800170524 iter num 20\n",
            "loss 0.10971783101558685 average time 0.010970101374959995 iter num 40\n",
            "loss 0.016432328149676323 average time 0.008521460633316262 iter num 60\n",
            "loss 0.027684830129146576 average time 0.007276386237481347 iter num 80\n",
            "loss 0.18305261433124542 average time 0.0065518219899604446 iter num 100\n",
            "loss 0.02578648179769516 average time 0.018170010600078966 iter num 20\n",
            "loss 0.06801874935626984 average time 0.01086079035012517 iter num 40\n",
            "loss 0.038871437311172485 average time 0.00844673443340677 iter num 60\n",
            "loss 0.017485935240983963 average time 0.007243573850064422 iter num 80\n",
            "loss 0.06352108716964722 average time 0.006506381520030118 iter num 100\n",
            "loss 0.150056391954422 average time 0.01837347784994563 iter num 20\n",
            "loss 0.04378188028931618 average time 0.011124972275092659 iter num 40\n",
            "loss 0.16515791416168213 average time 0.008712055366716716 iter num 60\n",
            "loss 0.020304540172219276 average time 0.007505777837491223 iter num 80\n",
            "loss 0.013837449252605438 average time 0.006761438599969551 iter num 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "**Results**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1be6e54f-fb58-4c19-b4c4-25062f60543a"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 110.0, 110.0, 0.35, 0.05, 0.05]*3]).cuda()\n",
        "model(inputs.float())\n",
        "\n",
        "# should be around (12, 1, 2, 3, 4, 5, 6)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11.7784,  0.9815,  2.0024,  2.9885,  4.0015,  4.9788,  5.9587]],\n",
              "       device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}