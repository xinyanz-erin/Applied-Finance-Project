{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Generating Test",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Pui/Generating_Test_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4HV-G44th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27a23e19-5ab5-40b4-8864-4c029ad05b3b"
      },
      "source": [
        "%%writefile cupy_dataset.py\n",
        "import cupy\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "import pandas as pd\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "    return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "S_range = np.array(list(range(75,130,5)))/100 #11\n",
        "K_range = np.array(list(range(75,130,5)))/100 #11\n",
        "Sigma_range = np.array(list(range(15,51,6)))/10 #6\n",
        "r_range = np.array(list(range(1,5,1)))/100 #4\n",
        "\n",
        "call = []\n",
        "for i in S_range:\n",
        "  for j in K_range:\n",
        "    for l in r_range:\n",
        "      for k in Sigma_range:\n",
        "        call.append([1,j,i,k,l,l,bs_call(i,j,1,l,k),bs_delta(i,j,1,l,k)]) #T, K, S, sigma, mu, r\n",
        "Thedataset = pd.DataFrame(call)\n",
        "\n",
        "Thedataset_X = Thedataset.iloc[:,:6]\n",
        "Thedataset_Y = Thedataset.iloc[:,6:]\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len, number_path, batch, seed, stocks):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 50\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = 1.0 # assume T = 1, use float here\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "\n",
        "        self.X = cupy.array(Thedataset_X)\n",
        "        self.Y = cupy.array(Thedataset_Y)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(self.X.toDlpack()), from_dlpack(self.Y.toDlpack()))\n",
        "        \n",
        "\n",
        "# ds = OptionDataSet(max_len = 1, number_path = 10000, batch = 2, seed = np.random.randint(10000), stocks=1) # for testing purpose, use constant seed. When training, change to random seed\n",
        "# for i in ds:\n",
        "#     print(i[0])\n",
        "#     print(i[0].shape)\n",
        "#     print(i[1])\n",
        "#     print(i[1].shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cupy_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6JO9OBHdvv",
        "outputId": "2e754e59-4095-4667-e070-dd68473c5aa5"
      },
      "source": [
        "%%writefile model.py\n",
        "# version 1,2\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*1, 32) # remember to change this!\n",
        "        self.fc2 = nn.Linear(32, 64)\n",
        "        self.fc3 = nn.Linear(64, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 32)\n",
        "        self.fc6 = nn.Linear(32, 1) # 1 outputs: price\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1.0, 0.5, 0.5, 0.3, 0.35, 0.35]*1)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = (x - torch.tensor([0.0, 0.75, 0.75, 0.15, 0.25, 0.25]*1).cuda()) / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlXD80xPNVc6",
        "outputId": "e1473777-cf43-41f8-e2cc-f156088be487"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 27.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3CyULkENYKb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2608ddc8-03f7-4b0a-d523-46378a9e0303"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 100000, batch = 1, seed = np.random.randint(10000), stocks = 1) # must have random seed. It doesn't matter how many batch here (not taken into function). Use max_len to adjust\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    # print(x)\n",
        "    # print(x.shape)\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    # print(y.shape)\n",
        "    y_pred = model(x.float())\n",
        "    # print(y_pred)\n",
        "    # print(y_pred.shape)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x.float()\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "    # print(y_pred)\n",
        "    # print(y_pred.shape)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.5205378060295073 average time 2.7728453462000004 iter num 20\n",
            "loss 0.4457372294417444 average time 2.7754852194250135 iter num 40\n",
            "loss 0.43255834120334924 average time 2.7671659053000135 iter num 60\n",
            "loss 0.4311324044729085 average time 2.7650501001750074 iter num 80\n",
            "loss 0.43091838690998374 average time 2.761024590160005 iter num 100\n",
            "loss 0.4268761703041968 average time 2.7573281675999852 iter num 20\n",
            "loss 0.4231403158139091 average time 2.767156413149988 iter num 40\n",
            "loss 0.420506241297659 average time 2.7697389343166567 iter num 60\n",
            "loss 0.41923669128007857 average time 2.766563219424995 iter num 80\n",
            "loss 0.41895805423489346 average time 2.767092271229998 iter num 100\n",
            "loss 0.41338933322642946 average time 2.742701227849989 iter num 20\n",
            "loss 0.4081835688996192 average time 2.746757589724973 iter num 40\n",
            "loss 0.40455871457349285 average time 2.7479539853833104 iter num 60\n",
            "loss 0.40283704219470895 average time 2.749029902974988 iter num 80\n",
            "loss 0.40246417148813235 average time 2.7491025957899886 iter num 100\n",
            "loss 0.3950784761956834 average time 2.7351754850000476 iter num 20\n",
            "loss 0.38809927011125805 average time 2.7458535339250263 iter num 40\n",
            "loss 0.3831936217753985 average time 2.7456165918500117 iter num 60\n",
            "loss 0.38085634094259785 average time 2.747891821137517 iter num 80\n",
            "loss 0.38035196603132837 average time 2.747637299450014 iter num 100\n",
            "loss 0.37034066655243536 average time 2.735040430549975 iter num 20\n",
            "loss 0.360678320191904 average time 2.7383621576499935 iter num 40\n",
            "loss 0.35376262966304695 average time 2.7414791336333297 iter num 60\n",
            "loss 0.35043844670341223 average time 2.743262168187502 iter num 80\n",
            "loss 0.34972106510177914 average time 2.7490488016399923 iter num 100\n",
            "loss 0.33539843356985627 average time 2.7514282606000053 iter num 20\n",
            "loss 0.3212540024290369 average time 2.752798062075004 iter num 40\n",
            "loss 0.31095128498001506 average time 2.750439996566672 iter num 60\n",
            "loss 0.30596327260733347 average time 2.749947036625008 iter num 80\n",
            "loss 0.3048871926080925 average time 2.754767009550021 iter num 100\n",
            "loss 0.28333902688056073 average time 2.7491076064499564 iter num 20\n",
            "loss 0.26184535644357937 average time 2.7560551100499766 iter num 40\n",
            "loss 0.24616312529064502 average time 2.7568153715333135 iter num 60\n",
            "loss 0.23860183107635102 average time 2.7603812237749823 iter num 80\n",
            "loss 0.2369784711603126 average time 2.756854613989972 iter num 100\n",
            "loss 0.20489601574885521 average time 2.7875488512499715 iter num 20\n",
            "loss 0.17405043955818203 average time 2.765525127700016 iter num 40\n",
            "loss 0.1527649023761261 average time 2.7711111065666727 iter num 60\n",
            "loss 0.14300354395849568 average time 2.7731467291249827 iter num 80\n",
            "loss 0.14096467990001832 average time 2.7693533971499935 iter num 100\n",
            "loss 0.10337823580691655 average time 2.7661289578000834 iter num 20\n",
            "loss 0.07330952800956814 average time 2.787900894225038 iter num 40\n",
            "loss 0.05656969466823034 average time 2.784066567066702 iter num 60\n",
            "loss 0.0500496145455806 average time 2.7798375195000347 iter num 80\n",
            "loss 0.04878691117146214 average time 2.776154945110029 iter num 100\n",
            "loss 0.029120918309072083 average time 2.754846922600018 iter num 20\n",
            "loss 0.018897864408872467 average time 2.7730407499500074 iter num 40\n",
            "loss 0.015256996995591366 average time 2.7798498957333475 iter num 60\n",
            "loss 0.014192647537427315 average time 2.7800639106500116 iter num 80\n",
            "loss 0.014009053667560648 average time 2.7795384943600037 iter num 100\n",
            "loss 0.011601274213816792 average time 2.764974038249966 iter num 20\n",
            "loss 0.010715842733781658 average time 2.7632854844749772 iter num 40\n",
            "loss 0.010437769391756512 average time 2.772355214833298 iter num 60\n",
            "loss 0.010347962558219417 average time 2.77266550654997 iter num 80\n",
            "loss 0.01033104846696167 average time 2.7701335655899766 iter num 100\n",
            "loss 0.010052069788681037 average time 2.760437412050055 iter num 20\n",
            "loss 0.009851531961459154 average time 2.7558292652500085 iter num 40\n",
            "loss 0.009731285760450395 average time 2.7706960863166916 iter num 60\n",
            "loss 0.009678403022819254 average time 2.772245396362513 iter num 80\n",
            "loss 0.00966740158573276 average time 2.770791916090002 iter num 100\n",
            "loss 0.009462356480376313 average time 2.7741143949500384 iter num 20\n",
            "loss 0.009286445244133917 average time 2.767420078925022 iter num 40\n",
            "loss 0.009172690098741153 average time 2.7687704110000064 iter num 60\n",
            "loss 0.009121509267612264 average time 2.7743928099000015 iter num 80\n",
            "loss 0.009110779069261134 average time 2.7705552958099906 iter num 100\n",
            "loss 0.008909653734242455 average time 2.759648981300006 iter num 20\n",
            "loss 0.008734856469688426 average time 2.761322274975032 iter num 40\n",
            "loss 0.008621034967255355 average time 2.7576978712500324 iter num 60\n",
            "loss 0.008569674811307892 average time 2.761263997812523 iter num 80\n",
            "loss 0.00855890528226827 average time 2.765428132399993 iter num 100\n",
            "loss 0.008356507463724948 average time 2.763239320400089 iter num 20\n",
            "loss 0.008180307288018347 average time 2.7591714716250406 iter num 40\n",
            "loss 0.008065480805948539 average time 2.755854350650058 iter num 60\n",
            "loss 0.008013633733245921 average time 2.7553553545500336 iter num 80\n",
            "loss 0.00800276699640015 average time 2.7625589169400246 iter num 100\n",
            "loss 0.007798516537103462 average time 2.758731134100208 iter num 20\n",
            "loss 0.00762055010666671 average time 2.7602255944751732 iter num 40\n",
            "loss 0.007505102827886811 average time 2.755637015616806 iter num 60\n",
            "loss 0.007453126934916696 average time 2.7575124674500784 iter num 80\n",
            "loss 0.007442253437689896 average time 2.756738882290065 iter num 100\n",
            "loss 0.007238075120724619 average time 2.7604677625000478 iter num 20\n",
            "loss 0.00706096401797675 average time 2.7507669314000394 iter num 40\n",
            "loss 0.006946534683255772 average time 2.752273947566694 iter num 60\n",
            "loss 0.006895173810182653 average time 2.7538267241125483 iter num 80\n",
            "loss 0.006884434098122487 average time 2.7616594998500568 iter num 100\n",
            "loss 0.006683302338548713 average time 2.772119526249935 iter num 20\n",
            "loss 0.006509764219488465 average time 2.773288234224947 iter num 40\n",
            "loss 0.006398252523542193 average time 2.7695734601999904 iter num 60\n",
            "loss 0.006348410608638517 average time 2.7630397015499852 iter num 80\n",
            "loss 0.0063380039129085 average time 2.7622085505400262 iter num 100\n",
            "loss 0.006143908770185876 average time 2.7485796234999724 iter num 20\n",
            "loss 0.00597808102630501 average time 2.765853865725012 iter num 40\n",
            "loss 0.005872250778314404 average time 2.773770305766614 iter num 60\n",
            "loss 0.005825120814185103 average time 2.7695833960249727 iter num 80\n",
            "loss 0.005815299818170467 average time 2.766890219419993 iter num 100\n",
            "loss 0.005632626588851425 average time 2.7631250182999794 iter num 20\n",
            "loss 0.0054769431751223565 average time 2.758276054499947 iter num 40\n",
            "loss 0.005377929258316709 average time 2.7724523650999346 iter num 60\n",
            "loss 0.00533394446117264 average time 2.767758991162475 iter num 80\n",
            "loss 0.005324796220974491 average time 2.7673974967699815 iter num 100\n",
            "loss 0.005155030172969723 average time 2.7503312294499667 iter num 20\n",
            "loss 0.00501106734538732 average time 2.7543778726250365 iter num 40\n",
            "loss 0.004919752380402843 average time 2.762396334933343 iter num 60\n",
            "loss 0.00487925986757631 average time 2.7618733554249957 iter num 80\n",
            "loss 0.004870843147184537 average time 2.765039725029983 iter num 100\n",
            "loss 0.0047147193038273635 average time 2.7652070105499207 iter num 20\n",
            "loss 0.004582390245817527 average time 2.761704923699972 iter num 40\n",
            "loss 0.0044985962061394776 average time 2.763128239249939 iter num 60\n",
            "loss 0.004461433247341897 average time 2.770131962637447 iter num 80\n",
            "loss 0.004453709907680126 average time 2.7721045657999275 iter num 100\n",
            "loss 0.004310091304139677 average time 2.7628784630499923 iter num 20\n",
            "loss 0.004188111250299378 average time 2.7701676240999404 iter num 40\n",
            "loss 0.004110799055537966 average time 2.7709049158999277 iter num 60\n",
            "loss 0.004076535052649625 average time 2.7680681826999374 iter num 80\n",
            "loss 0.004069413050252868 average time 2.7695973631099697 iter num 100\n",
            "loss 0.0039374397062085864 average time 2.783504564049963 iter num 20\n",
            "loss 0.00382596345980279 average time 2.7795691973999963 iter num 40\n",
            "loss 0.003755410664584826 average time 2.774953209799984 iter num 60\n",
            "loss 0.0037240952884181914 average time 2.7712698894500134 iter num 80\n",
            "loss 0.0037175795688199104 average time 2.7774068170099873 iter num 100\n",
            "loss 0.003596802691617635 average time 2.771661874600068 iter num 20\n",
            "loss 0.003494528841419036 average time 2.768053040825021 iter num 40\n",
            "loss 0.0034296430946525133 average time 2.7637499230333256 iter num 60\n",
            "loss 0.0034008434535462467 average time 2.7656893422250506 iter num 80\n",
            "loss 0.0033948500255541482 average time 2.7650439299400387 iter num 100\n",
            "loss 0.003283754638468322 average time 2.7904066874499223 iter num 20\n",
            "loss 0.0031894487831452146 average time 2.7770549085749736 iter num 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e89e047e891b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-e89e047e891b>\u001b[0m in \u001b[0;36mtrain_update\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_order_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompute_deltas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-e89e047e891b>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_order_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompute_deltas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-e89e047e891b>\u001b[0m in \u001b[0;36mcompute_deltas\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     37\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m       \u001b[0mfirst_order_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_order_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    234\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    235\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         inputs, allow_unused, accumulate_grad=False)\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_fEzULvKwR-"
      },
      "source": [
        "# 19:09\n",
        "# 21:15"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c556bfc-c38e-4997-9ba6-167cfd5c0904"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_BS_oneDS_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52221ecb-bb7c-4807-9543-2356a80ed5cc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecf489d3-7379-4a24-cbd8-605d66966582"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_BS_oneDS_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d156d47a-eb4d-4014-cab1-108660bed8ab"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=6, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc5): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc6): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3af9c8a8-0bf9-4a23-e3c0-bd985ff62ec1"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 100000, batch = 1, seed = np.random.randint(10000), stocks = 1) # must have random seed. It doesn't matter how many batch here (not taken into function). Use max_len to adjust\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x.float())\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x.float()\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)\n",
        "\n",
        "model_save_name = 'jax_european_1stock_BS_oneDS_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.002996461522678711 average time 2.7785745786000917 iter num 20\n",
            "loss 0.0029259253164437477 average time 2.7863694280750453 iter num 40\n",
            "loss 0.0029008435581087343 average time 2.782608152316728 iter num 60\n",
            "loss 0.0028721104830474724 average time 2.776712601587542 iter num 80\n",
            "loss 0.002867241652109009 average time 2.7756212748000415 iter num 100\n",
            "loss 0.0027621943465336585 average time 2.773356518400033 iter num 20\n",
            "loss 0.0026725858968926924 average time 2.773428758825071 iter num 40\n",
            "loss 0.002614074782741791 average time 2.787418052483387 iter num 60\n",
            "loss 0.0025876138524985976 average time 2.7838354677625374 iter num 80\n",
            "loss 0.0025818943376997154 average time 2.7822042977100407 iter num 100\n",
            "loss 0.002474391868844893 average time 2.7688389461500265 iter num 20\n",
            "loss 0.0023854020720735386 average time 2.7646866657500366 iter num 40\n",
            "loss 0.0023298429878681084 average time 2.7636857984666525 iter num 60\n",
            "loss 0.0023051595904011487 average time 2.7688621169749807 iter num 80\n",
            "loss 0.0022999580263141366 average time 2.7682876610699987 iter num 100\n",
            "loss 0.002203339107416297 average time 2.776378016849867 iter num 20\n",
            "loss 0.0021240336081191882 average time 2.7744447507249332 iter num 40\n",
            "loss 0.0020746839303002976 average time 2.765154986316611 iter num 60\n",
            "loss 0.00205283499449756 average time 2.774881165012471 iter num 80\n",
            "loss 0.002048249554780231 average time 2.7726136219799993 iter num 100\n",
            "loss 0.001963262541832901 average time 2.783505933500146 iter num 20\n",
            "loss 0.0018928880820489186 average time 2.7803463623000426 iter num 40\n",
            "loss 0.0018487235897627391 average time 2.7765945009499773 iter num 60\n",
            "loss 0.001829101204729205 average time 2.777453700487513 iter num 80\n",
            "loss 0.0018249854388870611 average time 2.780188821510001 iter num 100\n",
            "loss 0.001748446402543239 average time 2.7726573922500393 iter num 20\n",
            "loss 0.0016842133206626273 average time 2.7755427743750714 iter num 40\n",
            "loss 0.0016435277656835024 average time 2.7710622763500394 iter num 60\n",
            "loss 0.0016253839200163008 average time 2.773359630475079 iter num 80\n",
            "loss 0.0016215805118393472 average time 2.7817328766100764 iter num 100\n",
            "loss 0.0015507134243277715 average time 2.7608906423000916 iter num 20\n",
            "loss 0.0014909373984910855 average time 2.759223555049948 iter num 40\n",
            "loss 0.0014529732530898887 average time 2.764851273783309 iter num 60\n",
            "loss 0.0014360530490177723 average time 2.760698527712452 iter num 80\n",
            "loss 0.0014325119872177737 average time 2.7587365912499626 iter num 100\n",
            "loss 0.001366522081095798 average time 2.7836167995496908 iter num 20\n",
            "loss 0.0013108411036373206 average time 2.7664261315246677 iter num 40\n",
            "loss 0.0012755775851496798 average time 2.7643760250830383 iter num 60\n",
            "loss 0.0012599060859966901 average time 2.7611623625498396 iter num 80\n",
            "loss 0.001256634616400289 average time 2.762387193069935 iter num 100\n",
            "loss 0.0011958783452621468 average time 2.759357649300182 iter num 20\n",
            "loss 0.001144885712765723 average time 2.767796757550059 iter num 40\n",
            "loss 0.001112806741911669 average time 2.7625855941667394 iter num 60\n",
            "loss 0.0010986152761366527 average time 2.7650077481625432 iter num 80\n",
            "loss 0.0010956608489200148 average time 2.7751380879599674 iter num 100\n",
            "loss 0.00104098077185173 average time 2.78781512020023 iter num 20\n",
            "loss 0.000995341029055758 average time 2.777663944450114 iter num 40\n",
            "loss 0.0009667917113759997 average time 2.7708446296834457 iter num 60\n",
            "loss 0.0009542181529385088 average time 2.7668798352625346 iter num 80\n",
            "loss 0.0009516059273824499 average time 2.762460779680041 iter num 100\n",
            "loss 0.000903407971855661 average time 2.7743747546500344 iter num 20\n",
            "loss 0.0008633000094052119 average time 2.772975570650078 iter num 40\n",
            "loss 0.0008382707378339659 average time 2.769174545350173 iter num 60\n",
            "loss 0.0008272613242027423 average time 2.768813562762648 iter num 80\n",
            "loss 0.0008249758492300031 average time 2.7665791300301863 iter num 100\n",
            "loss 0.0007828238723840281 average time 2.769483164149915 iter num 20\n",
            "loss 0.0007478440509738996 average time 2.7621101932249985 iter num 40\n",
            "loss 0.0007260804634708506 average time 2.7730242615499567 iter num 60\n",
            "loss 0.0007165318848448256 average time 2.7726214200874666 iter num 80\n",
            "loss 0.0007145529397020213 average time 2.770576298600008 iter num 100\n",
            "loss 0.0006781182662637771 average time 2.7557747995499993 iter num 20\n",
            "loss 0.0006480079481540054 average time 2.7636122602498743 iter num 40\n",
            "loss 0.0006292739168165208 average time 2.760113825716568 iter num 60\n",
            "loss 0.0006210635233632833 average time 2.7702457639749354 iter num 80\n",
            "loss 0.0006193638170833856 average time 2.771466144709939 iter num 100\n",
            "loss 0.0005960645983387822 average time 2.776575165900249 iter num 20\n",
            "loss 0.000572316935475412 average time 2.79044385897505 iter num 40\n",
            "loss 0.0005645721051644938 average time 2.795541057066718 iter num 60\n",
            "loss 0.0005592968836643202 average time 2.7905359179750575 iter num 80\n",
            "loss 0.0005580277972140564 average time 2.789808800530045 iter num 100\n",
            "loss 0.000537562543485908 average time 2.771210268549839 iter num 20\n",
            "loss 0.0005206416484639375 average time 2.771754617774968 iter num 40\n",
            "loss 0.0005097674537022813 average time 2.7682540067832635 iter num 60\n",
            "loss 0.0005049679022596659 average time 2.76840080596246 iter num 80\n",
            "loss 0.0005039706754749163 average time 2.7703005669499543 iter num 100\n",
            "loss 0.0004854501157308227 average time 2.7542898774000606 iter num 20\n",
            "loss 0.00046983041701015944 average time 2.75828326272499 iter num 40\n",
            "loss 0.0004599725235087892 average time 2.765513482000036 iter num 60\n",
            "loss 0.0004556080456892496 average time 2.7604804915499925 iter num 80\n",
            "loss 0.0004547002571553775 average time 2.7575721742899986 iter num 100\n",
            "loss 0.0004378968949274379 average time 2.7688676770500935 iter num 20\n",
            "loss 0.00042374142739073906 average time 2.7681535271750364 iter num 40\n",
            "loss 0.00041482720391397765 average time 2.763518248800028 iter num 60\n",
            "loss 0.0004108832750342039 average time 2.762279724562518 iter num 80\n",
            "loss 0.00041006395657186746 average time 2.7614640283700282 iter num 100\n",
            "loss 0.00039846845905803894 average time 2.780252413549988 iter num 20\n",
            "loss 0.00038480114004831457 average time 2.7738468762499906 iter num 40\n",
            "loss 0.0003754083253949686 average time 2.766807941616662 iter num 60\n",
            "loss 0.000372388720383212 average time 2.7682179319125453 iter num 80\n",
            "loss 0.00037171347059445964 average time 2.7662311312100427 iter num 100\n",
            "loss 0.0003817464532848615 average time 2.7507313430997784 iter num 20\n",
            "loss 0.0003659117178125214 average time 2.7754433422749116 iter num 40\n",
            "loss 0.00035198823274165247 average time 2.7720887975166684 iter num 60\n",
            "loss 0.00035109371994864315 average time 2.7753864368749417 iter num 80\n",
            "loss 0.0003503985564942695 average time 2.779403266439931 iter num 100\n",
            "loss 0.00034122119370158847 average time 2.7732474566002567 iter num 20\n",
            "loss 0.00033332354744323696 average time 2.7824133832252302 iter num 40\n",
            "loss 0.0003283101684402147 average time 2.7984637378501853 iter num 60\n",
            "loss 0.00032609341642052627 average time 2.797414213787647 iter num 80\n",
            "loss 0.00032562492711509975 average time 2.7910017409301147 iter num 100\n",
            "loss 0.0003169906981660709 average time 2.7687730556000134 iter num 20\n",
            "loss 0.00030964105556472837 average time 2.768071994600132 iter num 40\n",
            "loss 0.00030496797348049826 average time 2.776243874533338 iter num 60\n",
            "loss 0.0003028895334608815 average time 2.772064276737569 iter num 80\n",
            "loss 0.000302457241166197 average time 2.7672302688700436 iter num 100\n",
            "loss 0.0002944157991918971 average time 2.763476530000207 iter num 20\n",
            "loss 0.0002875923136428241 average time 2.766242381950042 iter num 40\n",
            "loss 0.0002832603739010485 average time 2.7606520954332763 iter num 60\n",
            "loss 0.00028133789496672274 average time 2.7779628306000177 iter num 80\n",
            "loss 0.0002809382261539805 average time 2.7823476648500582 iter num 100\n",
            "loss 0.0002735245472538798 average time 2.7655890107497725 iter num 20\n",
            "loss 0.0002672435182200291 average time 2.7732451861748815 iter num 40\n",
            "loss 0.00026325889822074414 average time 2.7688799111998983 iter num 60\n",
            "loss 0.0002614913806974683 average time 2.775029739474894 iter num 80\n",
            "loss 0.00026112405313753284 average time 2.7741460477999316 iter num 100\n",
            "loss 0.00025431310468048427 average time 2.78342004540018 iter num 20\n",
            "loss 0.00024855043977266576 average time 2.7692775370001073 iter num 40\n",
            "loss 0.0002449047627725892 average time 2.7606786991834875 iter num 60\n",
            "loss 0.0002432892456057189 average time 2.762914843550175 iter num 80\n",
            "loss 0.00024295380157959173 average time 2.7741197500001 iter num 100\n",
            "loss 0.00023700813144458824 average time 2.809464020700125 iter num 20\n",
            "loss 0.00023160578256643875 average time 2.8231039253249945 iter num 40\n",
            "loss 0.000228290059294627 average time 2.814892420633411 iter num 60\n",
            "loss 0.00022689937543711702 average time 2.805625023600078 iter num 80\n",
            "loss 0.00022658124410958655 average time 2.8049590277100287 iter num 100\n",
            "loss 0.0003052727486615544 average time 2.8195968445498694 iter num 20\n",
            "loss 0.0002246836471723246 average time 2.807658701624723 iter num 40\n",
            "loss 0.00022022449452345348 average time 2.7992465349997775 iter num 60\n",
            "loss 0.0002191274368108507 average time 2.7949399614622736 iter num 80\n",
            "loss 0.00021904429213553486 average time 2.7880411206997997 iter num 100\n",
            "loss 0.0002152564650952024 average time 2.7855332785000426 iter num 20\n",
            "loss 0.00021197969310374313 average time 2.7718715834500927 iter num 40\n",
            "loss 0.0002098709628867929 average time 2.764031044583438 iter num 60\n",
            "loss 0.0002089411466424755 average time 2.7625986574126045 iter num 80\n",
            "loss 0.0002087458043182391 average time 2.7655178917200827 iter num 100\n",
            "loss 0.00020512859836089114 average time 2.7488649540501684 iter num 20\n",
            "loss 0.0002020549614794676 average time 2.7774737692001508 iter num 40\n",
            "loss 0.00020010200404316241 average time 2.7809616947666957 iter num 60\n",
            "loss 0.00019923400007543994 average time 2.7755265650250065 iter num 80\n",
            "loss 0.00019905370333283024 average time 2.772956736700071 iter num 100\n",
            "loss 0.00019569151236023506 average time 2.7594825412495085 iter num 20\n",
            "loss 0.0001928324604412108 average time 2.7731503644246915 iter num 40\n",
            "loss 0.0001910126959290591 average time 2.765200054249787 iter num 60\n",
            "loss 0.00019020353149300608 average time 2.764730955362279 iter num 80\n",
            "loss 0.0001900357293090849 average time 2.767496571639804 iter num 100\n",
            "loss 0.00018690873426764303 average time 2.8023716962500655 iter num 20\n",
            "loss 0.00018425540226388982 average time 2.805322284199974 iter num 40\n",
            "loss 0.00018256958337707516 average time 2.80429308215001 iter num 60\n",
            "loss 0.00018182021901055155 average time 2.795456829599948 iter num 80\n",
            "loss 0.0001816648218186642 average time 2.791043100090028 iter num 100\n",
            "loss 0.0001787702824624655 average time 2.7636823309502687 iter num 20\n",
            "loss 0.000176316265143703 average time 2.7626522384753116 iter num 40\n",
            "loss 0.00017475789135848384 average time 2.7681884795669855 iter num 60\n",
            "loss 0.00017406546678038599 average time 2.768757508075146 iter num 80\n",
            "loss 0.00017392190192182035 average time 2.767903143400163 iter num 100\n",
            "loss 0.00017122759172733267 average time 2.7627592218500467 iter num 20\n",
            "loss 0.00016899097981174703 average time 2.7628162440499637 iter num 40\n",
            "loss 0.00016754715557191742 average time 2.7616679700833022 iter num 60\n",
            "loss 0.00016691437420250218 average time 2.7653233997375084 iter num 80\n",
            "loss 0.00016678176635290677 average time 2.7656496262300605 iter num 100\n",
            "loss 0.00021509182480626186 average time 2.7807120329498503 iter num 20\n",
            "loss 0.00016561820626133595 average time 2.7723302941998553 iter num 40\n",
            "loss 0.00016410578657411268 average time 2.7701972327334565 iter num 60\n",
            "loss 0.000164626175724532 average time 2.7715489209376303 iter num 80\n",
            "loss 0.00016455736149144321 average time 2.779116421210056 iter num 100\n",
            "loss 0.0001627854766914952 average time 2.782560750600351 iter num 20\n",
            "loss 0.0001611801320181953 average time 2.782091342675085 iter num 40\n",
            "loss 0.00016013291580776903 average time 2.784606570850277 iter num 60\n",
            "loss 0.00015968703668373834 average time 2.788731609962633 iter num 80\n",
            "loss 0.0001595912526603654 average time 2.797367203569993 iter num 100\n",
            "loss 0.00015783713102317451 average time 2.7818397205996006 iter num 20\n",
            "loss 0.00015633855247631595 average time 2.774374725974576 iter num 40\n",
            "loss 0.00015537854430033662 average time 2.7828035296496334 iter num 60\n",
            "loss 0.0001549493850771453 average time 2.7850215098872466 iter num 80\n",
            "loss 0.00015486089028562337 average time 2.785411275789775 iter num 100\n",
            "loss 0.00015319328563771154 average time 2.8193534802005162 iter num 20\n",
            "loss 0.00015176559209530285 average time 2.795652419650196 iter num 40\n",
            "loss 0.0001508511085643624 average time 2.7886039153168896 iter num 60\n",
            "loss 0.0001504428926583331 average time 2.784891543300091 iter num 80\n",
            "loss 0.00015035823437048652 average time 2.7833857554500354 iter num 100\n",
            "loss 0.0001487702736984194 average time 2.7967219432501222 iter num 20\n",
            "loss 0.0001474093744789664 average time 2.7840997759001764 iter num 40\n",
            "loss 0.00014653714397879335 average time 2.779636419916824 iter num 60\n",
            "loss 0.00014614702421888185 average time 2.773222720550211 iter num 80\n",
            "loss 0.000146066129180128 average time 2.7695838056501816 iter num 100\n",
            "loss 0.0001445485937738655 average time 2.7790889863001214 iter num 20\n",
            "loss 0.00014324605852337089 average time 2.7857522307500404 iter num 40\n",
            "loss 0.00014241009077231549 average time 2.7757029449666635 iter num 60\n",
            "loss 0.00014203591461625913 average time 2.7751353267249668 iter num 80\n",
            "loss 0.00014195821012417546 average time 2.773104473750063 iter num 100\n",
            "loss 0.00014091963347593543 average time 2.736618646850002 iter num 20\n",
            "loss 0.0001392662046935376 average time 2.7515363931748653 iter num 40\n",
            "loss 0.00013846300832364436 average time 2.7557862242498836 iter num 60\n",
            "loss 0.0001381115333598986 average time 2.7542233375624163 iter num 80\n",
            "loss 0.00013803590074499536 average time 2.758642232679813 iter num 100\n",
            "loss 0.00017339318182904153 average time 2.775313036950865 iter num 20\n",
            "loss 0.00014904026385767564 average time 2.765493416200388 iter num 40\n",
            "loss 0.0001390649952915738 average time 2.768474587183664 iter num 60\n",
            "loss 0.00014018080565938285 average time 2.7691631431626775 iter num 80\n",
            "loss 0.00014009654029688466 average time 2.7709049329001574 iter num 100\n",
            "loss 0.00013923568639438735 average time 2.7603964246001853 iter num 20\n",
            "loss 0.00013824640244929903 average time 2.7599121503751123 iter num 40\n",
            "loss 0.0001375996995308592 average time 2.7609417414834145 iter num 60\n",
            "loss 0.00013736331310902392 average time 2.766806918975135 iter num 80\n",
            "loss 0.0001373077700590472 average time 2.7659369056001015 iter num 100\n",
            "loss 0.0001362880392780138 average time 2.768181201549851 iter num 20\n",
            "loss 0.0001354092894236263 average time 2.783874380875113 iter num 40\n",
            "loss 0.00013484356580053893 average time 2.7866970576331975 iter num 60\n",
            "loss 0.00013459111836036075 average time 2.7928367155500835 iter num 80\n",
            "loss 0.0001345388042196924 average time 2.788145166710092 iter num 100\n",
            "loss 0.00013355050536249777 average time 2.7744565526496445 iter num 20\n",
            "loss 0.00013269941566295193 average time 2.7720611035749245 iter num 40\n",
            "loss 0.0001321506230868538 average time 2.7645117294999486 iter num 60\n",
            "loss 0.00013190462737769316 average time 2.7629610168874024 iter num 80\n",
            "loss 0.00013185376553551624 average time 2.771964488429985 iter num 100\n",
            "loss 0.0001308910451183908 average time 2.763451767049446 iter num 20\n",
            "loss 0.00013005937221920066 average time 2.7718977182245 iter num 40\n",
            "loss 0.00012952171596444914 average time 2.7811450621660696 iter num 60\n",
            "loss 0.00012928072486873894 average time 2.782543192837056 iter num 80\n",
            "loss 0.00012923102703284503 average time 2.785341260309542 iter num 100\n",
            "loss 0.00012828887958745295 average time 2.813161081150247 iter num 20\n",
            "loss 0.00012747369652531764 average time 2.8029540207251555 iter num 40\n",
            "loss 0.0001269470742709609 average time 2.8031970415335308 iter num 60\n",
            "loss 0.0001267108999511971 average time 2.801908062462735 iter num 80\n",
            "loss 0.00012666207934019572 average time 2.8014205734401547 iter num 100\n",
            "loss 0.00012573599829032085 average time 2.815847732599832 iter num 20\n",
            "loss 0.00012493529897363565 average time 2.8119000291500016 iter num 40\n",
            "loss 0.00012441778213287665 average time 2.8051476728665876 iter num 60\n",
            "loss 0.00012418550554907262 average time 2.8010778056749133 iter num 80\n",
            "loss 0.00012413738651899795 average time 2.8030098308598097 iter num 100\n",
            "loss 0.00012322565180787455 average time 2.7992902242001945 iter num 20\n",
            "loss 0.00012243580153608826 average time 2.80718469070016 iter num 40\n",
            "loss 0.00012192530120685004 average time 2.800834423900293 iter num 60\n",
            "loss 0.00012169608639160824 average time 2.800654941937637 iter num 80\n",
            "loss 0.0001216484439386112 average time 2.805104970470129 iter num 100\n",
            "loss 0.00012074834545256535 average time 2.775646688149936 iter num 20\n",
            "loss 0.00011996900025315026 average time 2.804866364324971 iter num 40\n",
            "loss 0.00011946464544390509 average time 2.8140009718001844 iter num 60\n",
            "loss 0.00011923757844363381 average time 2.805540920337626 iter num 80\n",
            "loss 0.00011919076904529239 average time 2.8114694414101176 iter num 100\n",
            "loss 0.00011829302936605843 average time 2.8098948252996707 iter num 20\n",
            "loss 0.00011754880375522009 average time 2.8065555418748773 iter num 40\n",
            "loss 0.0001170309613545259 average time 2.806308195266623 iter num 60\n",
            "loss 0.00011681051407542389 average time 2.805780646149924 iter num 80\n",
            "loss 0.00011676393245034469 average time 2.804445895349927 iter num 100\n",
            "loss 0.00017394713783849185 average time 2.8017150915002276 iter num 20\n",
            "loss 0.00012314040713679294 average time 2.7975308877252245 iter num 40\n",
            "loss 0.00011665800517845443 average time 2.7987928292335105 iter num 60\n",
            "loss 0.00011764396250266212 average time 2.7997316942626638 iter num 80\n",
            "loss 0.0001174543138552948 average time 2.80246880711009 iter num 100\n",
            "loss 0.00011684146418396851 average time 2.8123934930999894 iter num 20\n",
            "loss 0.00011617392537542782 average time 2.7999064700999043 iter num 40\n",
            "loss 0.00011570559310046385 average time 2.7961241995166954 iter num 60\n",
            "loss 0.0001155192912664564 average time 2.7988068887875217 iter num 80\n",
            "loss 0.00011547957081302411 average time 2.79575081570998 iter num 100\n",
            "loss 0.00011475901027328613 average time 2.7927483997003946 iter num 20\n",
            "loss 0.00011413708490266161 average time 2.7818363020252037 iter num 40\n",
            "loss 0.00011373475925041615 average time 2.7811879077498816 iter num 60\n",
            "loss 0.00011355378705101261 average time 2.790060990874963 iter num 80\n",
            "loss 0.00011351667262819118 average time 2.7896651813598874 iter num 100\n",
            "loss 0.00011280526227472288 average time 2.79082470070025 iter num 20\n",
            "loss 0.00011218724799331814 average time 2.781385977775153 iter num 40\n",
            "loss 0.00011178717469565355 average time 2.7808737004834256 iter num 60\n",
            "loss 0.00011160692340801313 average time 2.7828922972249983 iter num 80\n",
            "loss 0.00011156975866327236 average time 2.787740856820128 iter num 100\n",
            "loss 0.00011086219018506493 average time 2.783372741900166 iter num 20\n",
            "loss 0.00011024731196745617 average time 2.7812416563250735 iter num 40\n",
            "loss 0.00010984932729240832 average time 2.785873916233504 iter num 60\n",
            "loss 0.00010966988207197126 average time 2.7880526380376067 iter num 80\n",
            "loss 0.0001096329639654239 average time 2.791737551760016 iter num 100\n",
            "loss 0.00010892786651025573 average time 2.7662638433997926 iter num 20\n",
            "loss 0.00010831382760963975 average time 2.7821479935999376 iter num 40\n",
            "loss 0.00010791509239121398 average time 2.782699321316492 iter num 60\n",
            "loss 0.00010773568401829215 average time 2.7813890733747484 iter num 80\n",
            "loss 0.00010769876474512328 average time 2.7810450558797313 iter num 100\n",
            "loss 0.00010720321938503075 average time 2.805253953149804 iter num 20\n",
            "loss 0.00010644325349585842 average time 2.7927017866750248 iter num 40\n",
            "loss 0.00010598817423965122 average time 2.7839023789833544 iter num 60\n",
            "loss 0.00010582506963331287 average time 2.7852140789625537 iter num 80\n",
            "loss 0.00010578483736824153 average time 2.784433661210096 iter num 100\n",
            "loss 0.00017784779347021647 average time 2.795123765050266 iter num 20\n",
            "loss 0.00011125386464211499 average time 2.797958251075033 iter num 40\n",
            "loss 0.00010693962294446024 average time 2.7934266793166898 iter num 60\n",
            "loss 0.00010778278207511839 average time 2.791420758562572 iter num 80\n",
            "loss 0.00010756397338883076 average time 2.790471017100099 iter num 100\n",
            "loss 0.00010712271021744957 average time 2.7989199083993297 iter num 20\n",
            "loss 0.00010660921970110919 average time 2.802502527199704 iter num 40\n",
            "loss 0.00010623976372985125 average time 2.793242438566631 iter num 60\n",
            "loss 0.0001060901134644337 average time 2.7939249437374203 iter num 80\n",
            "loss 0.0001060585596346766 average time 2.795499133319936 iter num 100\n",
            "loss 0.00010549022964309623 average time 2.7839469002996338 iter num 20\n",
            "loss 0.00010500235954586989 average time 2.7843974423747566 iter num 40\n",
            "loss 0.00010468725646572082 average time 2.8045389221664663 iter num 60\n",
            "loss 0.00010454557377374314 average time 2.7998077802872556 iter num 80\n",
            "loss 0.00010451652997139292 average time 2.7993820173599304 iter num 100\n",
            "loss 0.00010395954242128475 average time 2.7979491537002104 iter num 20\n",
            "loss 0.0001034738442619928 average time 2.7964140103998942 iter num 40\n",
            "loss 0.00010315885887650258 average time 2.804298552633251 iter num 60\n",
            "loss 0.0001030171439562071 average time 2.8018812391249868 iter num 80\n",
            "loss 0.00010298773135333764 average time 2.8008729339200364 iter num 100\n",
            "loss 0.00010242734636061094 average time 2.786789147849595 iter num 20\n",
            "loss 0.00010194028782294491 average time 2.7857873115247456 iter num 40\n",
            "loss 0.00010162281831772537 average time 2.7883909221499077 iter num 60\n",
            "loss 0.00010148025552111364 average time 2.789538194462466 iter num 80\n",
            "loss 0.0001014506116293999 average time 2.792094219109931 iter num 100\n",
            "loss 0.00010088890049219845 average time 2.780101916550484 iter num 20\n",
            "loss 0.00010039815865448519 average time 2.781231013575416 iter num 40\n",
            "loss 0.00010007914685112179 average time 2.7837469781337254 iter num 60\n",
            "loss 9.993569367453846e-05 average time 2.7879132946502976 iter num 80\n",
            "loss 9.990576988089113e-05 average time 2.787506828350197 iter num 100\n",
            "loss 9.933727596858791e-05 average time 2.7787582661998385 iter num 20\n",
            "loss 9.884349355841419e-05 average time 2.787252176725269 iter num 40\n",
            "loss 9.852133816781865e-05 average time 2.793759270950128 iter num 60\n",
            "loss 9.83766032254368e-05 average time 2.7947251327876073 iter num 80\n",
            "loss 9.834644423424001e-05 average time 2.802445353180046 iter num 100\n",
            "loss 9.774171563794655e-05 average time 2.7963181776996864 iter num 20\n",
            "loss 9.729398605498462e-05 average time 2.7866229812999337 iter num 40\n",
            "loss 9.695346794369777e-05 average time 2.782459831450069 iter num 60\n",
            "loss 9.680721126202482e-05 average time 2.7855779408251236 iter num 80\n",
            "loss 9.677761165211834e-05 average time 2.7864127337201716 iter num 100\n",
            "loss 0.00010739326970680446 average time 2.800866394699915 iter num 20\n",
            "loss 0.00010040046524411273 average time 2.7891943480999544 iter num 40\n",
            "loss 9.66555603796927e-05 average time 2.790989620766656 iter num 60\n",
            "loss 9.707230587862758e-05 average time 2.7953023981125624 iter num 80\n",
            "loss 9.695019630209331e-05 average time 2.7951566071201523 iter num 100\n",
            "loss 9.647827088056454e-05 average time 2.8195647613496475 iter num 20\n",
            "loss 9.604770312292238e-05 average time 2.808435726624521 iter num 40\n",
            "loss 9.576079327852771e-05 average time 2.8012052009829254 iter num 60\n",
            "loss 9.562700554122186e-05 average time 2.79798201699964 iter num 80\n",
            "loss 9.560050869752248e-05 average time 2.7937417675498 iter num 100\n",
            "loss 9.50874467249182e-05 average time 2.817196026199963 iter num 20\n",
            "loss 9.464246412710523e-05 average time 2.81806101602524 iter num 40\n",
            "loss 9.435333091110883e-05 average time 2.808622414583624 iter num 60\n",
            "loss 9.422261794592407e-05 average time 2.8006516387626563 iter num 80\n",
            "loss 9.419555224377273e-05 average time 2.799119910440095 iter num 100\n",
            "loss 9.368617355812647e-05 average time 2.786981920800463 iter num 20\n",
            "loss 9.323001646109567e-05 average time 2.7958166675999565 iter num 40\n",
            "loss 9.293862614179977e-05 average time 2.7953725683500426 iter num 60\n",
            "loss 9.280683576751264e-05 average time 2.793800638062612 iter num 80\n",
            "loss 9.277887376462288e-05 average time 2.7904325736901594 iter num 100\n",
            "loss 9.983549630643617e-05 average time 2.7859617332003834 iter num 20\n",
            "loss 9.281978629378322e-05 average time 2.785412919925238 iter num 40\n",
            "loss 9.170880271214768e-05 average time 2.7925840034001643 iter num 60\n",
            "loss 9.163223429132768e-05 average time 2.791952373100048 iter num 80\n",
            "loss 9.16018841061469e-05 average time 2.794182614790043 iter num 100\n",
            "loss 0.00010348365326304011 average time 2.7815479857497847 iter num 20\n",
            "loss 9.625845632798892e-05 average time 2.7759754588749272 iter num 40\n",
            "loss 9.410561668111361e-05 average time 2.7835569928334736 iter num 60\n",
            "loss 9.317193096186881e-05 average time 2.7814786544249728 iter num 80\n",
            "loss 9.322206738512646e-05 average time 2.7828344902398383 iter num 100\n",
            "loss 9.295814551572581e-05 average time 2.798559424999803 iter num 20\n",
            "loss 9.258552995531464e-05 average time 2.797118218624837 iter num 40\n",
            "loss 9.232128213453897e-05 average time 2.797525086050094 iter num 60\n",
            "loss 9.222427652729572e-05 average time 2.7992603889876135 iter num 80\n",
            "loss 9.219899701653571e-05 average time 2.7971932277501765 iter num 100\n",
            "loss 9.175442084063093e-05 average time 2.7797177772994472 iter num 20\n",
            "loss 9.137194652694573e-05 average time 2.7892986739246224 iter num 40\n",
            "loss 9.112333489230807e-05 average time 2.7919726618831193 iter num 60\n",
            "loss 9.101106859724774e-05 average time 2.794170958024915 iter num 80\n",
            "loss 9.098777587511475e-05 average time 2.790494992450076 iter num 100\n",
            "loss 9.054431489733692e-05 average time 2.774197991199435 iter num 20\n",
            "loss 9.015657009476566e-05 average time 2.781532918224639 iter num 40\n",
            "loss 8.990356509889262e-05 average time 2.7838873700998494 iter num 60\n",
            "loss 8.978896480333605e-05 average time 2.7824443273874295 iter num 80\n",
            "loss 8.976510598813231e-05 average time 2.7915190552298736 iter num 100\n",
            "loss 8.93153038555572e-05 average time 2.7891309807000653 iter num 20\n",
            "loss 8.892069526752198e-05 average time 2.788589911775034 iter num 40\n",
            "loss 8.866374453070968e-05 average time 2.790871462716738 iter num 60\n",
            "loss 8.854777795323291e-05 average time 2.7932241043251453 iter num 80\n",
            "loss 8.852348210879979e-05 average time 2.800275772850073 iter num 100\n",
            "loss 8.806521002422817e-05 average time 2.803686263650525 iter num 20\n",
            "loss 8.766555671035793e-05 average time 2.8049151058500685 iter num 40\n",
            "loss 8.740426441597295e-05 average time 2.807659191499988 iter num 60\n",
            "loss 8.728616433484576e-05 average time 2.807187792862578 iter num 80\n",
            "loss 8.72614226910571e-05 average time 2.8091080601100837 iter num 100\n",
            "loss 8.678332403522286e-05 average time 2.82679509469981 iter num 20\n",
            "loss 8.638897912343211e-05 average time 2.81543829259972 iter num 40\n",
            "loss 8.612241379147302e-05 average time 2.8122117118498258 iter num 60\n",
            "loss 8.599960168039313e-05 average time 2.8086192593123087 iter num 80\n",
            "loss 8.597479252735978e-05 average time 2.808502950689872 iter num 100\n",
            "loss 9.821131190289689e-05 average time 2.811788897350925 iter num 20\n",
            "loss 8.568132040625815e-05 average time 2.804843992975657 iter num 40\n",
            "loss 8.529820881861464e-05 average time 2.79811545490035 iter num 60\n",
            "loss 8.505662243786542e-05 average time 2.7962441655002293 iter num 80\n",
            "loss 8.502654638175079e-05 average time 2.7904793615701418 iter num 100\n",
            "loss 9.01512840611997e-05 average time 2.7727796054501597 iter num 20\n",
            "loss 8.8284215801115e-05 average time 2.7903918702002555 iter num 40\n",
            "loss 8.787092867888723e-05 average time 2.7921468079002807 iter num 60\n",
            "loss 8.656152852492765e-05 average time 2.799621556287684 iter num 80\n",
            "loss 8.667453398742232e-05 average time 2.799350436810237 iter num 100\n",
            "loss 8.640586211282733e-05 average time 2.7939624000997356 iter num 20\n",
            "loss 8.605541476525796e-05 average time 2.7885709864001003 iter num 40\n",
            "loss 8.580863789838922e-05 average time 2.7962472294667653 iter num 60\n",
            "loss 8.571815357944074e-05 average time 2.798211163912447 iter num 80\n",
            "loss 8.569572112970726e-05 average time 2.793023268029901 iter num 100\n",
            "loss 8.530781292612563e-05 average time 2.8015421350000906 iter num 20\n",
            "loss 8.497054135452106e-05 average time 2.795683059275234 iter num 40\n",
            "loss 8.475220571870633e-05 average time 2.8055786248666967 iter num 60\n",
            "loss 8.46529846968354e-05 average time 2.8021330188126283 iter num 80\n",
            "loss 8.463267816098806e-05 average time 2.801316288120033 iter num 100\n",
            "loss 8.424215215613742e-05 average time 2.7991472070496455 iter num 20\n",
            "loss 8.390138676409938e-05 average time 2.802270008749656 iter num 40\n",
            "loss 8.367759398273974e-05 average time 2.8017834721331383 iter num 60\n",
            "loss 8.357676896160674e-05 average time 2.805668364474877 iter num 80\n",
            "loss 8.35555931025962e-05 average time 2.8054893677699875 iter num 100\n",
            "loss 8.315631843684764e-05 average time 2.8232883512506306 iter num 20\n",
            "loss 8.280345688661689e-05 average time 2.8148483963248507 iter num 40\n",
            "loss 8.257342401519916e-05 average time 2.8056516250000643 iter num 60\n",
            "loss 8.246929935617854e-05 average time 2.8147448452750723 iter num 80\n",
            "loss 8.244739491641475e-05 average time 2.8121288583601562 iter num 100\n",
            "loss 8.203376332739407e-05 average time 2.788348653399953 iter num 20\n",
            "loss 8.167251589968399e-05 average time 2.7874593965249006 iter num 40\n",
            "loss 8.143593166041514e-05 average time 2.785434826266646 iter num 60\n",
            "loss 8.132887048318169e-05 average time 2.782092633837647 iter num 80\n",
            "loss 8.130622084005204e-05 average time 2.7842247648800185 iter num 100\n",
            "loss 8.083972357197521e-05 average time 2.780044736550008 iter num 20\n",
            "loss 8.05345221170317e-05 average time 2.773362692450064 iter num 40\n",
            "loss 8.026885140404842e-05 average time 2.768489353000162 iter num 60\n",
            "loss 8.015906125775338e-05 average time 2.7669254275876938 iter num 80\n",
            "loss 8.013739449110636e-05 average time 2.7730849112501166 iter num 100\n",
            "loss 9.591440398164022e-05 average time 2.7704058533499847 iter num 20\n",
            "loss 8.406577878802432e-05 average time 2.77129535465001 iter num 40\n",
            "loss 8.112254254140467e-05 average time 2.773140860316683 iter num 60\n",
            "loss 8.067035982314543e-05 average time 2.774654556512496 iter num 80\n",
            "loss 8.069120514707567e-05 average time 2.7758564695299355 iter num 100\n",
            "loss 8.05984623756354e-05 average time 2.804456522700093 iter num 20\n",
            "loss 8.013639730947748e-05 average time 2.7918205815250987 iter num 40\n",
            "loss 7.990238614121137e-05 average time 2.791598147766854 iter num 60\n",
            "loss 7.980207060056926e-05 average time 2.7847936970126286 iter num 80\n",
            "loss 7.97828222728094e-05 average time 2.780898242820149 iter num 100\n",
            "loss 7.940500677877936e-05 average time 2.808180499950322 iter num 20\n",
            "loss 7.907478773175878e-05 average time 2.8005139199501174 iter num 40\n",
            "loss 7.885813200302019e-05 average time 2.793018541816855 iter num 60\n",
            "loss 7.875989792993548e-05 average time 2.7880929146500875 iter num 80\n",
            "loss 7.873950882212161e-05 average time 2.7873573344399483 iter num 100\n",
            "loss 7.835206573479346e-05 average time 2.777714923100575 iter num 20\n",
            "loss 7.801344421130713e-05 average time 2.790343636225316 iter num 40\n",
            "loss 7.779175666566232e-05 average time 2.792443079583427 iter num 60\n",
            "loss 7.769100628485894e-05 average time 2.801200716662561 iter num 80\n",
            "loss 7.766997373889147e-05 average time 2.80099045773004 iter num 100\n",
            "loss 7.722645609893006e-05 average time 2.7765097671994226 iter num 20\n",
            "loss 7.695481675952714e-05 average time 2.7862498402247184 iter num 40\n",
            "loss 7.669625890716262e-05 average time 2.7844506779498865 iter num 60\n",
            "loss 7.659405953930508e-05 average time 2.7828059576374016 iter num 80\n",
            "loss 7.657434080673285e-05 average time 2.778318468419893 iter num 100\n",
            "loss 0.0001282116895699725 average time 2.770077466450857 iter num 20\n",
            "loss 8.137364929735073e-05 average time 2.77087217490016 iter num 40\n",
            "loss 7.841810544759934e-05 average time 2.784580529116708 iter num 60\n",
            "loss 7.743472247529663e-05 average time 2.7878248850374803 iter num 80\n",
            "loss 7.739800336789641e-05 average time 2.7823435678900568 iter num 100\n",
            "loss 7.721435714799963e-05 average time 2.767115527450187 iter num 20\n",
            "loss 7.688914843770275e-05 average time 2.768378080350067 iter num 40\n",
            "loss 7.666550175045531e-05 average time 2.763540649050083 iter num 60\n",
            "loss 7.657953447723545e-05 average time 2.7721786885501842 iter num 80\n",
            "loss 7.656168106609018e-05 average time 2.770520127120144 iter num 100\n",
            "loss 7.621662015885191e-05 average time 2.761935529800394 iter num 20\n",
            "loss 7.591050682317128e-05 average time 2.7673096290000103 iter num 40\n",
            "loss 7.571127707470603e-05 average time 2.765959993216529 iter num 60\n",
            "loss 7.562061983156034e-05 average time 2.7720590529872426 iter num 80\n",
            "loss 7.560227406149576e-05 average time 2.7699014980095673 iter num 100\n",
            "loss 7.524651081711619e-05 average time 2.769679066649405 iter num 20\n",
            "loss 7.493289671504229e-05 average time 2.7607690349750555 iter num 40\n",
            "loss 7.47273017893506e-05 average time 2.763732026066767 iter num 60\n",
            "loss 7.463414901593458e-05 average time 2.763199463262663 iter num 80\n",
            "loss 7.46150333268198e-05 average time 2.7654848272301025 iter num 100\n",
            "loss 7.425290970870628e-05 average time 2.747436720299811 iter num 20\n",
            "loss 7.392106075511535e-05 average time 2.7619294969503243 iter num 40\n",
            "loss 7.370977023574156e-05 average time 2.762691901816773 iter num 60\n",
            "loss 7.361354095669277e-05 average time 2.7639599011125937 iter num 80\n",
            "loss 7.359359965553085e-05 average time 2.766591540409863 iter num 100\n",
            "loss 8.097984248605683e-05 average time 2.7939173693514023 iter num 20\n",
            "loss 7.40906003226536e-05 average time 2.782396909700947 iter num 40\n",
            "loss 7.297479427760844e-05 average time 2.779501769917018 iter num 60\n",
            "loss 7.27803400141005e-05 average time 2.780513350138153 iter num 80\n",
            "loss 7.279842171858178e-05 average time 2.7763107808706993 iter num 100\n",
            "loss 8.192783350036836e-05 average time 2.7839593804004834 iter num 20\n",
            "loss 7.81703938796347e-05 average time 2.7795553449499493 iter num 40\n",
            "loss 7.432015766447352e-05 average time 2.776721056033421 iter num 60\n",
            "loss 7.357627231435096e-05 average time 2.7782906984126385 iter num 80\n",
            "loss 7.370274795640475e-05 average time 2.77942416942009 iter num 100\n",
            "loss 7.350445949961913e-05 average time 2.8289956318003533 iter num 20\n",
            "loss 7.321868130591232e-05 average time 2.8329059703499295 iter num 40\n",
            "loss 7.299528494892715e-05 average time 2.817032647149851 iter num 60\n",
            "loss 7.29085457237172e-05 average time 2.803809526274745 iter num 80\n",
            "loss 7.289083637282961e-05 average time 2.7997113710597477 iter num 100\n",
            "loss 7.256591626640877e-05 average time 2.770444958850567 iter num 20\n",
            "loss 7.228270605484169e-05 average time 2.7882916843502246 iter num 40\n",
            "loss 7.209609047722553e-05 average time 2.779451574300159 iter num 60\n",
            "loss 7.201126312017993e-05 average time 2.7810500218126437 iter num 80\n",
            "loss 7.199388196177773e-05 average time 2.778939118360213 iter num 100\n",
            "loss 7.166018667909398e-05 average time 2.7874971497985825 iter num 20\n",
            "loss 7.136532399083232e-05 average time 2.782998870899246 iter num 40\n",
            "loss 7.117217160782213e-05 average time 2.789643103382817 iter num 60\n",
            "loss 7.108437249552607e-05 average time 2.788707114349563 iter num 80\n",
            "loss 7.106635678091921e-05 average time 2.7923845007298222 iter num 100\n",
            "loss 7.07254803827485e-05 average time 2.78438603329887 iter num 20\n",
            "loss 7.041624004684716e-05 average time 2.7844401023747194 iter num 40\n",
            "loss 7.021678784934964e-05 average time 2.792729339849757 iter num 60\n",
            "loss 7.012665755999326e-05 average time 2.784358748474915 iter num 80\n",
            "loss 7.010797436786418e-05 average time 2.783765831040146 iter num 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQs-OZHGEwac"
      },
      "source": [
        "# 21:17\n",
        "# 5:01"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38c314c5-7d6b-4033-c644-10f79a4f8a9a"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 1, 1, 0.25, 0.3, 0.3]]).cuda() # T, K, S, sigma, mu, r\n",
        "print('price: ' + str(model(inputs.float())))\n",
        "\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient[0][[2]]\n",
        "\n",
        "# price, delta\n",
        "# should be around (0.27130044, 0.90763223)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: tensor([[0.1397]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6531], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lovJwXo3-YEu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "3a334678-8d88-4900-b601-1a4e95da4fb1"
      },
      "source": [
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "\n",
        "def compute_price(S):\n",
        "    inputs = torch.tensor([[1, 1, S, 0.25, 0.3, 0.3]]).cuda()\n",
        "    return model(inputs.float())\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_prices = []\n",
        "BS_call_prices = []\n",
        "for p in prices:\n",
        "    model_call_prices.append(compute_price(p).item())\n",
        "    BS_call_prices.append(bs_call(p, 1, 1, 0.3, 0.25))\n",
        "\n",
        "#plt.plot(prices, model_call_prices, label = \"model_call_prices\")\n",
        "#plt.plot(prices, BS_call_prices, label = \"BS_call_prices\")\n",
        "plt.plot(prices, np.array(model_call_prices)-np.array(BS_call_prices), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD6CAYAAACs/ECRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXgV5f3+8fcnC2Hfw07YkX09IksCWEBkEUQUC4KoIIsIuFaoltb219ZqawtaQKAouKGIyo4LRdnBsO+EXfawg+zk+f2RQ7+UBpJ4kkySc7+u61xnZs4zZz4TonfmmZlnzDmHiIgErxCvCxAREW8pCEREgpyCQEQkyCkIRESCnIJARCTIKQhERIJcwEFgZoXN7Bszi/O/F7pFu97+NnFm1vuG5d3NbIOZrTezeWZWNNCaREQk5SzQ+wjM7HXghHPuNTMbBhRyzr10U5vCQCzgAxywCmgInAUOAjWcc8f833XeOfe7222zaNGirnz58gHVLSISbFatWnXMORd58/KwNPjuzkBL//Qk4DvgpZvatAW+cc6dADCzb4B7gc8AA/KY2XEgP7AjuQ2WL1+e2NjYNChdRCR4mNnepJanRRAUd84d8k8fBoon0aY08OMN8/uB0s65K2Y2ENgA/ATEAYPSoCYREUmhFJ0jMLNvzWxjEq/ON7Zzif1MKe5rMrNwYCBQHygFrAeG36JtPzOLNbPY+Pj4lG5CRESSkaIjAudc61t9ZmZHzKykc+6QmZUEjibR7AD/130EUIbELqR6/u/f6f+uT4Fht6hhHDAOwOfzaYAkEZE0khZdQzOA3sBr/vfpSbT5CvjTDVcU3UPiX/45gRpmFumciwfaAFvSoCYRySSuXLnC/v37uXjxotelBI2cOXNSpkwZwsPDU9Q+LYLgNeBTM+sD7AW6AZiZDxjgnOvrnDthZn8AfvCv8/sbThy/Ciw0syv+9R9Lg5pEJJPYv38/+fLlo3z58piZ1+Vke845jh8/zv79+6lQoUKK1gk4CJxzx4FWSSyPBfreMD8RmJhEu7HA2EDrEJHM6eLFiwqBDGRmFClShNScS9WdxSKS7hQCGSu1P++06BrKMj5fvZ8TP12mRsn8VCuZn8J5cnhdkoiI54IqCGavP8T8rf93UVOxfBFUK5mf6iXyUaNUfhpEFaJMoVz660UkmwkNDaV27dpcuXKFsLAwHn30UZ599llCQkKIjY1l8uTJjBo1ikuXLtGhQweOHTvG8OHDKVWqFAMGDCA8PJxly5aRK1cur3clXQRVEPzrsTuJP3uJbYfPsvXwGbYcSnx/d8lxLl9LABLDoWG5QjQsV4gG5QpRs1R+IsJCPa5cRAKRK1cu1q5dC8DRo0fp0aMHZ86c4dVXX8Xn8+Hz+QBYs2YNwH/aDhgwgOHDh9OzZ88Ubcc5h3OOkJAs1ut+vfCs9GrYsKFLS1euXnObDpx2k5ftcc9MWeNi/vJvV+6lWa7cS7Nc1ZfnuJ4Tlrt3vt/hthw67RISEtJ02yLZ3ebNm70uweXJk+e/5nfu3OkKFy7sEhIS3IIFC1yHDh3ckSNHXKVKlVz+/Pld3bp13dixY12hQoVc+fLlXY8ePZxzzr3++uvO5/O52rVruxEjRjjnnNu9e7erWrWq69Wrl6tRo4bbs2fPLdtVq1bN9e3b19WoUcO1adPGnT9/3jnnXFxcnGvVqpWrU6eOq1+/vtuxY8ctt3fu3DnXvn17V6dOHVezZk03ZcqUJPc5qZ87EOuS+H9qUB0R3EpYaAg1SuWnRqn89GpcDoCjZy6yet9JVuw+weK4Y/xpzlb+NGcrkfkiiKlSlOZVImlRNZJCOs8gkmKvztzE5oNn0vQ7a5TKz2/vq5mqdSpWrMi1a9c4evSGruJixZgwYQJ//etfmTVrFgDLli2jY8eOPPjgg3z99dfExcWxcuVKnHN06tSJhQsXEhUVRVxcHJMmTaJx48bJtvv4448ZP3483bp1Y9q0afTs2ZNHHnmEYcOG0aVLFy5evEhCQsItvyc+Pp5SpUoxe/ZsAE6fPh3wz1BBcAvF8ufk3lolubdWSQAOnb7AorhjLIo7xoKtR/l89QFCQ4zGFQvTtmYJ7qlRghIFcnpctYikl6+//pqvv/6a+vXrA3Du3Dni4uKIioqiXLlyNG7cONl2FSpUoF69egA0bNiQPXv2cPbsWQ4cOECXLl2AxJvBbvc9MTExPP/887z00kt07NiRmJiYgPdNQZBCJQvkopuvLN18ZUlIcGw4cJqvNx9m3sbDjJi+iRHTN1E/qiBta5agQ+2SlC2c2+uSRTKd1P7lnl527dpFaGgoxYoVY8uWlA1m4Jxj+PDh9O/f/7+W79mzhzx58qSoXURExH/mQ0NDuXDhQqq3B7B69WrmzJnDK6+8QqtWrRgxYkSK9uFWstgZjcwhJMSoW7YgL7atxvznW/Ltc815se0dXEtwvDZ3KzGvL+DBMUv5cMVeTp2/7HW5InKD+Ph4BgwYwNNPP52qKwTbtm3LxIkTOXfuHAAHDhz4r66l1La7Ll++fJQpU4Yvv/wSgEuXLnH+/Plbfs/BgwfJnTs3PXv25MUXX2T16tUp3odb0RFBGqhcLB+Vi+Vj0N2V2X/yPDPWHeSL1Qd4+YuN/G7GJu6+oxhd6pfmF9WL6QokEQ9cuHCBevXq/efy0V69evHcc8+l6jvuuecetmzZQpMmTQDImzcvH3zwAaGhoT+r3Y3ef/99+vfvz4gRIwgPD2fq1Km3/J4dO3bw4osvEhISQnh4OGPGjEnVfiQl4CeUecHn87nM/mAa5xybDp7hyzUHmL7uIPFnL1EwdzhdG5She6MoKhfL63WJIhliy5YtVK9e3esygk5SP3czW+Wc893cVkcE6cTMqFW6ALVKF2BYu2os2XmcT3/4kUlL9/Cvxbu5q0JhetwVxb21SugoQUQ8pSDIAGGhIbSomni5afzZS0xd9SNTVv7I0ClrKZwnBw81LEPPxuV0gllEPKEgyGCR+SJ4qmVlBjSvxOIdx/h45T4mLN7N+EW7uLdWCfpEV6BBVCENcyHZinNOv9MZKLVd/goCj4SEGM2rRtK8aiQHT11g0rI9fLxiH3M2HKZumQI8EV2B9rVLEh6qC7ska8uZMyfHjx+nSJEiCoMM4PzPI7h+P0JK6GRxJnL+8lWmrdrPu0v2sOvYT5TIn5O+MRXo3iiKPBHKbMma9ISyjHerJ5Td6mSxgiATSkhwfLf9KOMW7mL5rhMUyh3O480q0LtJeQrkTtmj50REbqYgyKJW7T3JmO928O2Wo+TJEUrPJuXoE12BYvk0nIWIpI6CIIvbcugMY77byaz1BwkLDaFHoyiealmJYvkVCCKSMgqCbGLPsZ8Y891OPlu9n7AQo1fjcgxoWYmieSOSX1lEgpqCIJvZe/wnRs3fwRdr9pMzPJTeTcvTL6aihsUWkVtSEGRTO+PPMfLbOGauP0ieHGH0ia7Ak80rkldXGYnITRQE2dy2w2f5x7fbmbvxMEXz5mBIqyp0bxSl+xBE5D9uFQT6v0Q2cUeJfIzp2ZAvnmpKxci8jJi+iTZvfs/s9YdSfZehiAQXBUE2Uz+qEJ/0a8zEx3zkCAth0EeruX/0UlbsOu51aSKSSSkIsiEz4xfVijN3aHNe71qHI6cv8vC45Qx4fxX7jp/3ujwRyWQUBNlYaIjR7c6yLHihJc+1qcr32+Np/eb3/GXeVs5duup1eSKSSSgIgkCuHKEMaVWFBS+0pGPdkoz5bict3/iOT3/4kWsJOn8gEuwCCgIzK2xm35hZnP+90C3azTOzU2Y266blFcxshZntMLNPzEwXwaejEgVy8ma3enw5qBlRhXPxq2nr6fT2YlbtPeF1aSLioUCPCIYB851zVYD5/vmkvAH0SmL5X4C/O+cqAyeBPgHWIylQr2xBpg1syshf1uP4uct0HbOMF6au49i5S16XJiIeCDQIOgOT/NOTgPuTauScmw+cvXGZJQ5M/gvgs+TWl7RnZnSuV5r5z7dgQItKTF97gLv/+h3vLdnN1WsJXpcnIhko0CAo7pw75J8+DBRPxbpFgFPOuetnLfcDpQOsR1IpT0QYw9pVY+7Q5tQrW5DfzdzMfW8vIXaPuotEgkWyQWBm35rZxiRenW9s5xLvWkq3M49m1s/MYs0sNj4+Pr02E7QqF8vL5CcaMeaRBpw+f5kHxy7jxanrOPnTZa9LE5F0luyANM651rf6zMyOmFlJ59whMysJHE3Fto8DBc0szH9UUAY4cJs6xgHjIHGIiVRsR1LIzGhXuyQt7ohk1PwdTFi0i/lbj/Lr9tXp2qC0HjMokk0F2jU0A+jtn+4NTE/piv4jiAXAgz9nfUk/uXMkdhfNGhJNhaJ5eGHqOrqPX87O+HNelyYi6SCgQefMrAjwKRAF7AW6OedOmJkPGOCc6+tvtwioBuQl8Uigj3PuKzOrCEwBCgNrgJ7OuWQvXdGgcxknIcEx5YcfeW3uFi5eSWBAy0o81bISOcNDvS5NRFJJo49KQOLPXuL/zd7M9LUHqRiZh790rcOd5Qt7XZaIpIJGH5WAROaLYOQv6zP5iUZcvprAQ2OX8ZsvN3L24hWvSxORACkIJFWaV43kq2ea83iz8nywYi/3/H0h/956xOuyRCQACgJJtTwRYfz2vppMG9iUfDnDeOK9WIZOWcNx3ZkskiUpCORnaxBViFmDY3imdRXmbDhEm78vZNb6g16XJSKppCCQgOQIC+GZ1lWZPSSGsoVy8fRHa3jqw1Uat0gkC1EQSJqoWjwf0wY25aV7q/Ht5qO0efN7Zq47qMdkimQBCgJJM2GhIQxsWYnZQ6KJKpKHwR+vYeAHq4k/q6MDkcxMQSBprkrxfEwb0IRh7arx721Huefv3zN7/aHkVxQRTygIJF2EhYYwoEUl5gyJJqpwbgZ9tJohH6/h1HkNYieS2SgIJF1VLpZ47uC5NlWZs+EQ9/x9IQu2pWZsQhFJbwoCSXdhoSEMaVWFLwc1o2DucB5/9weGf76ec5euJr+yiKQ7BYFkmFqlCzBzcDT9W1Rkyg8/0m7kQlbu1gNwRLymIJAMFREWyvB21ZnavwmG8fC4Zfxl3lYuX9XjMUW8oiAQT/jKF2bO0Bge9pVlzHc76TJ6CXFHzia/ooikOQWBeCZvRBivda3DuF4NOXT6Ih3fWsy7S3aTkKCb0EQykoJAPHdPzRJ89UxzmlUuyqszN9P73ZUcPn3R67JEgoaCQDKFyHwR/Ku3jz91qU3snpPcO3IhX2067HVZIkFBQSCZhpnR464oZg2Jpmyh3PR/fxXDP9/A+cu6zFQkPSkIJNOpFJmXaQObMqBFJab8sI+Oby1m44HTXpclkm0pCCRTyhEWwrB21fiw712cv3SNLqOXMPb7nTqRLJIOFASSqTWtVJR5z8TQunpxXpu7lV4TV3DkjE4ki6QlBYFkegVz52D0Iw34S9farN57inYjFzF/i56TLJJWFASSJZgZD98ZxczB0ZTIn5M+k2L53YxNXLxyzevSRLI8BYFkKZWL5eWLQU15olkF3lu6hy6jl7LjqO5IFgmEgkCynIiwUEbcV4OJj/k4cibxjuQpK/fpsZgiP5OCQLKsX1QrzryhMfjKFWbY5xsY/PEazly84nVZIlmOgkCytGL5czL5iUa82PYO5m48TMdRi1n34ymvyxLJUhQEkuWFhBiD7q7Mp/0bcy3B0XXMUsYv3KV7DkRSKKAgMLPCZvaNmcX53wvdot08MztlZrNuWv6hmW0zs41mNtHMwgOpR4Jbw3KFmT0kmlbVi/HHOVvoM+kHjp+75HVZIpleoEcEw4D5zrkqwHz/fFLeAHolsfxDoBpQG8gF9A2wHglyBXPnYGzPhvy+c02W7DhO+1GLWL7ruNdliWRqgQZBZ2CSf3oScH9SjZxz84H/ucbPOTfH+QErgTIB1iOCmfFok/J8MagpeXKE0WP8ckbNj+OauopEkhRoEBR3zh3yTx8Giv+cL/F3CfUC5gVYj8h/1CxVgBmDo+lUtxRvfrOdRyeu4OhZDU8hcrNkg8DMvvX34d/86nxjO/9f9T/3T67RwELn3KLb1NHPzGLNLDY+Pv5nbkaCTd6IMP7+cD1e71qHVXtP0n7kYhbHHfO6LJFMJdkgcM61ds7VSuI1HThiZiUB/O9HU1uAmf0WiASeS6aOcc45n3POFxkZmdrNSBAzM7rdWZbpg6IpmDucXhNX8Levt3H1WoLXpYlkCoF2Dc0AevunewPTU7OymfUF2gLdnXP6r1LS1R0l8jHj6WY82KAMb/17B49M0EimIhB4ELwGtDGzOKC1fx4z85nZhOuNzGwRMBVoZWb7zayt/6OxJJ5XWGZma81sRID1iNxW7hxhvPFQXf72UF3W7z9N+5GLWLhdXY0S3Cwrjs/i8/lcbGys12VIFhd35CyDPlpN3NFzPH13ZYa2qkJYqO6xlOzLzFY553w3L9dvvQStKsXzMX1QNA81VFeRBDcFgQS1XDlCef3B/+4qWhSnriIJLgoCEaBrwzLMeLoZRfLm4NGJK3nzm+26AU2ChoJAxK9K8Xx8OagZD9Qvw6j5cfT6l25Ak+CgIBC5Qe4cYfytW11ef7AOq/edpMOoxSzdqRvQJHtTEIgkoZsv8Qa0fDnD6DlhBW/Nj9Ow1pJtKQhEbuGOEvmY+XQ099Utxd++2c5j72lYa8meFAQit5EnIox/PFyPP3WpzfJdx+kwajGxe054XZZImlIQiCTDzOhxVxRfPNWUnOEhPDxuOe98v1NdRZJtKAhEUuj6sNZtaxbnz3O30u/9WE6dv+x1WSIBUxCIpEL+nOH8s0cDXu1Uk++3x9Nh1GLW/njK67JEAqIgEEklM6N30/J8NqApAA+NXcq7S3aTFcftEgEFgcjPVrdsQeYMiaFF1WK8OnMzT324mjMXr3hdlkiqKQhEAlAgdzjjH23Iy+2r8/XmI9z31mI2HjjtdVkiqaIgEAmQmfFk84p80q8xl64k8MCYpXy0Yp+6iiTLUBCIpBFf+cLMHhJN44pF+PUXG3jmk7X8dOmq12WJJEtBIJKGiuSN4L3H7uT5NlWZue4gnd5ezLbDZ70uS+S2FAQiaSwkxBjcqgof9LmL0xeu0vmfi/ls1X6vyxK5JQWBSDppWrkoc4ZGU69sQV6Yuo5ffbaOC5eveV2WyP9QEIiko2L5cvJh38YM/kVlpq7aT5fRS9gZf87rskT+i4JAJJ2FhhjP33MH7z3eiKNnL9HprcXMWHfQ67JE/kNBIJJBWlSNZPaQaKqVzM+Qj9fwypcbuHhFXUXiPQWBSAYqWSAXU/o1pn/zinywfB9dxyxl7/GfvC5LgpyCQCSDhYeGMLx9dSY86mP/yQt0HLWYeRsPeV2WBDEFgYhHWtcozqzB0VSMzMOAD1bz6sxNXL6a4HVZEoQUBCIeKls4N1MHNOWxpuV5d8keHnpnGT+eOO91WRJkFAQiHssRFsLvOtVk9CMN2HX0HB1GLeKbzUe8LkuCiIJAJJNoX7sks4ZEE1UkN09OjuWPszdz5Zq6iiT9BRQEZlbYzL4xszj/e6FbtJtnZqfMbNYtPh9lZrrLRoJeuSJ5+GxAU3o1Lsf4Rbt5+J1lHDx1weuyJJsL9IhgGDDfOVcFmO+fT8obQK+kPjAzH5BkgIgEo5zhofzh/lq81b0+24+co/2oRSzYetTrsiQbCzQIOgOT/NOTgPuTauScmw/8zxCMZhZKYkj8KsA6RLKd++qWYubgaEoVyMXj7/3Aa3O3qqtI0kWgQVDcOXf9AujDQPFUrv80MOOG7xCRG1QomofPn2rKI3dFMfb7nXQft1xdRZLmkg0CM/vWzDYm8ep8YzuX+DimFD+SycxKAQ8Bb6WwfT8zizWz2Pj4+JRuRiTLyxkeyh+71GZU9/psOXSGDuoqkjSWbBA451o752ol8ZoOHDGzkgD+99T8dtYHKgM7zGwPkNvMdtymjnHOOZ9zzhcZGZmKzYhkD53qlmLWkBhKqKtI0ligXUMzgN7+6d7A9JSu6Jyb7Zwr4Zwr75wrD5x3zlUOsB6RbK1C0Tx8oa4iSWOBBsFrQBsziwNa++cxM5+ZTbjeyMwWAVOBVma238zaBrhdkaB1c1dR+1GLmL9FN6DJz2eJXftZi8/nc7GxsV6XIeK53cd+YtCHq9l86Ax9oyvwq3urkSNM94lK0sxslXPOd/Ny/caIZGHXryp6tEk5JizeTTeNVSQ/g4JAJIvLGR7K7zvXYvQjDdjpH6to3sbDXpclWYiCQCSbaF+7JLOHxFC+aB4GfLCK307fqCegSYooCESykagiuflsQFP6RFdg0rK9PDB6KbviNYyX3J6CQCSbyREWwm861uBfvX0cPH2Bjm8t5os1+70uSzIxBYFINtWqenHmDo2hVqkCPPvJOl6Yuo7zl696XZZkQgoCkWysZIFcfPTkXQz5RWWmrd7PfW8tZsuhM16XJZmMgkAkmwsLDeG5e+7gwz53cebiVTr/cwmTl+0hK95DJOlDQSASJJpWLsrcoTE0rVSEEdM30f/9VZw6f9nrsiQTUBCIBJGieSOY2PtOXulQnQXbjtJu5CJW7j7hdVniMQWBSJAJCTH6xlTk84HNiAgL4ZfjlvGPb7dzLUFdRcFKQSASpGqXKcCsITHcX680//g2ju7jNZJpsFIQiASxvBFhvPlwPd7sVpdNB07TbqSGpwhGCgIR4YEGZZg1JIaowrkZ8MEqXv5ig4anCCIKAhEBEkcynTawKf2bV+TDFfvo9PZith0+63VZkgEUBCLyHznCQhjevjqTn2jEiZ+ucN/bi3XPQRBQEIjI/2heNZJ5z/zfPQdPTl7FiZ90z0F2pSAQkSRdv+fgNx1rsHB7PO1GLmTpzmNelyXpQEEgIrcUEmL0ia7A5081JU9EGI9MWMHr87Zy5VqC16VJGlIQiEiyapUuwKzB0TzsK8vo73by4Nhl7D3+k9dlSRpREIhIiuTOEcZrXesw+pEG7I4/R4dRes5BdqEgEJFUaV+7JHOfaU6Nkvl59pN1PPvJWs5evOJ1WRIABYGIpFrpgonPOXi2dVWmrz1Ah1GLWbPvpNdlyc+kIBCRnyUsNIShravwaf8mXEtwPDR2Gf9csEOD12VBCgIRCYivfGHmDI2hba0SvPHVNnpOWMHh0xe9LktSQUEgIgErkCuct7vX5/UH67D2x1PcO3IhX2/S4HVZhYJARNKEmdHNV5ZZQ6IpUygX/d5fxStfavC6rEBBICJpqlJkXqYNbMqTMRX4YLkGr8sKAgoCMytsZt+YWZz/vdAt2s0zs1NmNuum5WZmfzSz7Wa2xcyGBFKPiGQOEWGhvNyhBpM0eF2WEOgRwTBgvnOuCjDfP5+UN4BeSSx/DCgLVHPOVQemBFiPiGQiLapGMndoDE0qJg5e1+/9VZzU4HWZTqBB0BmY5J+eBNyfVCPn3HwgqWPDgcDvnXMJ/nZHA6xHRDKZyHwRvPvYnbzSoTrfbTtKu5GLWL7ruNdlyQ0CDYLizrlD/unDQPFUrl8JeNjMYs1srplVCbAeEcmEQkKMvjEV+eKpZuTOEUr38ct58+ttXNXgdZlCskFgZt+a2cYkXp1vbOcSO/9S2wEYAVx0zvmA8cDE29TRzx8YsfHx8ancjIhkBrVKF2Dm4GgebFCGUf/ewcPjlrP/5Hmvywp6FsjJGzPbBrR0zh0ys5LAd865O27RtiXwgnOu4w3LtgLtnHO7zcyAU865Aslt1+fzudjY2J9dt4h4b8a6g7z8+QYweO2BOnSoU9LrkrI9M1vl/8P7vwTaNTQD6O2f7g1MT+X6XwJ3+6dbANsDrEdEsohOdUsxZ2gMlYvlZdBHqxk2bT3nL1/1uqygFGgQvAa0MbM4oLV/HjPzmdmE643MbBEwFWhlZvvNrO0N63c1sw3An4G+AdYjIllI2cK5+bR/E55qWYlPYn/kvrcWs/ngGa/LCjoBdQ15RV1DItnPkh3HePaTtZy6cIWX21fn0SblSOwxlrSSXl1DIiJpolnloswdGkOzSkX47YxNPDk5lhO65yBDKAhEJNMokjeCiY/dyW861uD77fG0G7mQZTt1z0F6UxCISKZiZvSJruC/5yCMHhN0z0F6UxCISKZ0/Z6DB+on3nPwy3HLOXDqgtdlZUsKAhHJtPJGhPG3bnX5x8P12HLoDO3+sZB5Gw8lv6KkioJARDK9++uXZvaQGMoXzcOAD1bz8hd6zkFaUhCISJZQvmgePhvQlH7NK/Lhin10fnsJ24/oOQdpQUEgIllGjrAQft2+Ou89fifHzl2i09uL+WjFPj3nIEAKAhHJclreUYy5Q2PwlSvMr7/YwNMfreH0hStel5VlKQhEJEsqlj8nk59oxEv3VuOrTYdpP3IRq/ae9LqsLElBICJZVkiIMbBlJT4d0AQz6PbOMkZ/t4OEBHUVpYaCQESyvAZRhZg9JIZ7a5bg9XnbeHTiSo6eveh1WVmGgkBEsoUCucJ5u0d9/vxAbX7Yc4L2Ixfx/XY9xColFAQikm2YGd0bRTFzcDSF8+Sg98SV/HnOFi5f1fAUt6MgEJFsp2rxfMx4OppH7orinYW7eOidZew7rkdi3oqCQESypZzhofyxS21GP9KAXfHn6DBqETPXHfS6rExJQSAi2Vr72iWZMySGysXzMvjjNQz/fD0XLmt4ihspCEQk27v+SMyBLSvx8cof6fT2YrYd1vAU1ykIRCQohIeG8NK91Zj8RCNOnr+s4SluoCAQkaDSvGokc4bG0KiChqe4TkEgIkGnWL6cTHq8Eb+69w7mbTpMh1GLWLMveIenUBCISFAKCTGealmZT/s3wTl4aOwy3vl+Z1AOT6EgEJGg1rBcIeYMiaF19eL8ee5WHn/vB46du+R1WRlKQSAiQa9A7nDG9GzAH+6vxbJdx2k3chFLdhzzuqwMoyAQESFxeIpejcvx5VPNyJczjJ7/WsFfv9rG1WvZf3gKBYGIyA1qlMrPrMHRdG1QhrcX7KD7+OUcPHXB67LSlYJAROQmuXOE8deH6vKPh+ux+eAZ2o1cxDebj3hdVrpREIiI3ML99Usza0gMZQvn4snJsfxuxiYuXc1+w1MEFLOvonAAAAeASURBVARmVtjMvjGzOP97oVu0m2dmp8xs1k3LW5nZajNba2aLzaxyIPWIiKS1CkXzMG1gU55oVoH3lu7hgdFL2X3sJ6/LSlOBHhEMA+Y756oA8/3zSXkD6JXE8jHAI865esBHwCsB1iMikuYiwkIZcV8NJjzq48CpC3QctYgv1uz3uqw0E2gQdAYm+acnAfcn1cg5Nx9IaoQnB+T3TxcANEasiGRarWsUZ+7QGGqWKsCzn6zjhanrOH/5qtdlBSwswPWLO+cO+acPA8VTuX5fYI6ZXQDOAI0DrEdEJF2VLJCLj568i1Hz43hrwQ5W7zvJP3s0oHrJ/MmvnEkle0RgZt+a2cYkXp1vbOcSh/BL7b3ZzwLtnXNlgHeBN29TRz8zizWz2Ph4PYdURLwTFhrCc/fcwYd97+Lcxat0/ucS3l++N8uOZJpsEDjnWjvnaiXxmg4cMbOSAP73oyndsJlFAnWdcyv8iz4Bmt6mjnHOOZ9zzhcZGZnSzYiIpJumlYoyZ2gMTSoW4TdfbuSpD1dz+nzWG8k00HMEM4De/unewPRUrHsSKGBmVf3zbYAtAdYjIpKhiuaN4N3H7uTX7avxzeYjtB+1iFV7s9ZIpoEGwWtAGzOLA1r75zEzn5lNuN7IzBYBU4FWZrbfzNo6564CTwLTzGwdiVcVvRhgPSIiGS4kxOjXvBJTBzTBDLq9s4wx32WdkUwtK/Zp+Xw+Fxsb63UZIiL/4/SFK/z68w3M3nCImCpFebNbPSLzRXhdFgBmtso557t5ue4sFhFJQwVyhfN2j/r8qUttVu4+QbuRi1gcl7lHMlUQiIikMTOjx11RTH+6GQVzh9NrYuYeyVRBICKSTqqVyM+Mp5vRrWFZ3l6wg1+Oy5wjmSoIRETSUe4cYfzlwTqM/GU9thzKnCOZKghERDJA53qlmZ1JRzJVEIiIZJDy/pFMH29WnveW7qHrmMwxkqmCQEQkA0WEhfLb+2oy/lEfP55IHMl0+toDntakIBAR8UAb/0im1UvmZ+iUtbz02XouXPamq0hBICLikVIFczGlX2Oevrsyn676kU5vL2b7kaRG7E9fCgIREQ+FhYbwQts7eP+Juzh5/gqd3l7MlJX7MnQkUwWBiEgmEF2lKHOHxnBn+cIM+3wDQ6as5ezFjBnJVEEgIpJJROaLYNLjjXix7R3M2XCIjm8tZsP+0+m+XQWBiEgmEhJiDLq7MlP6Neby1QQeGLOEd5fsTteuIgWBiEgmdGf5wswZEkOLqpG8OnMz/d9fxanzl9NlWwoCEZFMqlCeHIx/1MdvOtZgwbajdBiVPlcVKQhERDIxM6NPdAWmDWxKpWJ5KVkgZ5pvIyzNv1FERNJcnTIFmfxEo3T5bh0RiIgEOQWBiEiQUxCIiAQ5BYGISJBTEIiIBDkFgYhIkFMQiIgEOQWBiEiQs4wc8zqtmFk8sNfrOn6GosAxr4vwgPY7uATrfkPm3/dyzrnImxdmySDIqsws1jnn87qOjKb9Di7But+QdfddXUMiIkFOQSAiEuQUBBlrnNcFeET7HVyCdb8hi+67zhGIiAQ5HRGIiAQ5BUE6MLN7zWybme0ws2FJfB5lZgvMbI2ZrTez9l7UmdZSsN/lzGy+f5+/M7MyXtSZ1sxsopkdNbONt/jczGyU/+ey3swaZHSN6SEF+13NzJaZ2SUzeyGj60svKdjvR/z/zhvMbKmZ1c3oGlNLQZDGzCwU+CfQDqgBdDezGjc1ewX41DlXH/glMDpjq0x7KdzvvwKTnXN1gN8Df87YKtPNe8C9t/m8HVDF/+oHjMmAmjLCe9x+v08AQ0j8d89O3uP2+70baOGcqw38gSxw3kBBkPYaATucc7ucc5eBKUDnm9o4IL9/ugBwMAPrSy8p2e8awL/90wuS+DxLcs4tJPF/erfSmcQAdM655UBBMyuZMdWln+T22zl31Dn3A3Al46pKfynY76XOuZP+2eVApj/yVRCkvdLAjzfM7/cvu9HvgJ5mth+YAwzOmNLSVUr2ex3wgH+6C5DPzIpkQG1eS8nPRrKnPsBcr4tIjoLAG92B95xzZYD2wPtmFgz/Fi8ALcxsDdACOABc87YkkfRhZneTGAQveV1LcvTw+rR3ACh7w3wZ/7Ib9cHfx+icW2ZmOUkco+RohlSYPpLdb+fcQfxHBGaWF+jqnDuVYRV6JyW/E5KNmFkdYALQzjl33Ot6khMMf4VmtB+AKmZWwcxykHgyeMZNbfYBrQDMrDqQE4jP0CrTXrL7bWZFbzjyGQ5MzOAavTIDeNR/9VBj4LRz7pDXRUn6MLMo4HOgl3Nuu9f1pISOCNKYc+6qmT0NfAWEAhOdc5vM7PdArHNuBvA8MN7MniXxxPFjLovf2ZfC/W4J/NnMHLAQGORZwWnIzD4mcd+K+s/7/BYIB3DOjSXxPFB7YAdwHnjcm0rTVnL7bWYlgFgSL4xIMLNngBrOuTMelZwmUvDvPQIoAow2M4CrmX0gOt1ZLCIS5NQ1JCIS5BQEIiJBTkEgIhLkFAQiIkFOQSAiEuQUBCIiQU5BICIS5BQEIiJB7v8D/X0RGjhqZLkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwApH0GT9bBK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "23b6de0d-40e2-4dc1-a2b5-0c5960d7ce05"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, S, 0.25, 0.3, 0.3]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 1, 1, 0.3, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHgD1NjP7DOW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "332c3d48-7960-4fb9-f4c2-19a8951b4598"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 0.75, S, 0.25, 0.3, 0.3]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 0.75, 1, 0.3, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7MfujMQ7oij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "cd07c82a-d678-42cb-c17c-7669082b7669"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1.25, S, 0.25, 0.3, 0.3]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 1.25, 1, 0.3, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}