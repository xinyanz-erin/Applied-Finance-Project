{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "European_Call_jax.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Lilian/European_Call_jax_v5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1RYKgBifCYw"
      },
      "source": [
        "# Test (Skip this if not trying to test, to make sure that functions are defined correctly in cells below without running this cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWYfON_marpj",
        "outputId": "49f9dd38-660e-4110-b885-6050e61b59bb"
      },
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T):\n",
        "  return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
        "\n",
        "numstocks = 3\n",
        "numsteps = 50\n",
        "numpaths = 100000\n",
        "\n",
        "rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.]*numstocks)\n",
        "r = drift\n",
        "cov = jnp.identity(numstocks)*0.25*0.25\n",
        "initial_stocks = jnp.array([100.]*numstocks) # must be float\n",
        "T = 1.0\n",
        "K = 110.0\n",
        "\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "keys = jax.random.split(key, numpaths)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "%timeit optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T)\n",
        "\n",
        "# delta test\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "%timeit goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3851213\n",
            "100 loops, best of 5: 5.32 ms per loop\n",
            "[0.09405017 0.09377991 0.09379512]\n",
            "10 loops, best of 5: 45.1 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxFUnc_iBVcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83b35e3-907e-4707-e34f-2a1b99656e16"
      },
      "source": [
        "%%writefile cupy_dataset.py\n",
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T, keys): # need to pass 'keys'\n",
        "    return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
        "\n",
        "###################################################################################################\n",
        "# these 2 functions must be defined outside class in order to be used in 'optionvalueavg' function\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "###################################################################################################\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len, number_path, batch, seed, stocks):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 50\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = 1.0 # assume T = 1, use float here\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros((self.N_BATCH, 1 + self.N_STOCKS), dtype=cupy.float32) # output: price, delta1, delta2, delta3\n",
        "        X = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "\n",
        "        for op in range(self.N_BATCH):\n",
        "          \n",
        "          rng = jax.random.PRNGKey(self.seed)\n",
        "          rng, key = jax.random.split(rng)\n",
        "\n",
        "          ################################################################################################### generate random input numbers\n",
        "\n",
        "          initial_stocks = jnp.array(np.random.random(self.N_STOCKS) * 1.0)\n",
        "\n",
        "          corr = jnp.diag(jnp.array([1]*self.N_STOCKS)) # assume no correlation between stocks here\n",
        "          sigma = jnp.array(np.random.random(self.N_STOCKS) * 0.3)\n",
        "          cov = (jnp.diag(sigma)).dot(corr).dot(jnp.diag(sigma))\n",
        "\n",
        "          r = jnp.repeat(jnp.array(np.random.random(1) * 0.1), self.N_STOCKS)\n",
        "          drift = jnp.array(np.random.random(self.N_STOCKS) * 0.1)\n",
        "\n",
        "          T = self.T\n",
        "          K = np.random.random(1) * 1.0\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### apply functions to compute price and deltas\n",
        "          \n",
        "          keys = jax.random.split(key, self.N_PATHS)\n",
        "\n",
        "          European_Call_price = optionvalueavg(key, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "          gooptionvalue = jax.grad(optionvalueavg, argnums=1)\n",
        "          Deltas = gooptionvalue(keys, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### store input and output numbers in X and Y\n",
        "\n",
        "          Y[op, 0] = European_Call_price\n",
        "          Y[op, 1:4] = cupy.array(Deltas, dtype=cupy.float32)\n",
        "\n",
        "          # T, K, S, sigma, mu, r\n",
        "          paras = (jnp.repeat(jnp.array(T), self.N_STOCKS), jnp.repeat(jnp.array(K), self.N_STOCKS), initial_stocks, sigma, drift, r)\n",
        "          paras = np.column_stack(paras).reshape(1,-1)[0]\n",
        "          X[op,] = cupy.array(paras)\n",
        "\n",
        "          ###################################################################################################\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "# ds = OptionDataSet(max_len = 2, number_path = 10000, batch = 2, seed = 15, stocks=3) # for testing purpose, use constant seed. When training, change to random seed\n",
        "# for i in ds:\n",
        "#     print(i)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cupy_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6JO9OBHdvv",
        "outputId": "4ca0ab5e-c89d-4108-dda4-8c0d9cf9aa94"
      },
      "source": [
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*3, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, hidden)\n",
        "        self.fc7 = nn.Linear(hidden, hidden)\n",
        "        self.fc8 = nn.Linear(hidden, hidden)\n",
        "        self.fc9 = nn.Linear(hidden, 1) # 4 outputs: price, delta1, delta2, delta3\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1, 1.0, 1.0, 0.3, 0.1, 0.1]*3)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        x = F.elu(self.fc6(x))\n",
        "        x = F.elu(self.fc7(x))\n",
        "        x = F.elu(self.fc8(x))\n",
        "        return self.fc9(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlXD80xPNVc6",
        "outputId": "dada7f99-b0e0-4ef9-ab3b-b9935e8b4280"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 28.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 32.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 38.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 30.4 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 18.3 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 15.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQol7RECI7gw",
        "outputId": "f63da630-08f7-4a77-8484-63bcef355af8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        }
      },
      "source": [
        "from ignite.engine import Engine, Events\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-28e1edfc6445>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/distributed/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomp_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/distributed/auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: module functions cannot set METH_CLASS or METH_STATIC"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "S3CyULkENYKb",
        "outputId": "30765afc-e59d-48a7-e235-b334e461a96e"
      },
      "source": [
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 1024, batch = 32, seed = np.random.randint(10000), stocks = 3) # must have random seed\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    # print(x)\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    y_pred = model(x)\n",
        "    # print(y_pred)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2,8,14]]\n",
        "\n",
        "    # print(torch.unbind(x))\n",
        "    # print([compute_deltas(x) for x in torch.unbind(x)])\n",
        "    # print(torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0))\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "    # print(y_pred)\n",
        "\n",
        "    loss_weight = 1/(y.mean(axis=0)**2)\n",
        "    # print(y.mean(axis=0))\n",
        "    # print((y.mean(axis=0)**2))\n",
        "    # print(1/(y.mean(axis=0)**2))\n",
        "    \n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    # print(loss_weight)\n",
        "    # print(loss_weight_normalized)\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean() # compute weighted MSE between the 2 arrays\n",
        "    # print((y_pred - y) ** 2)\n",
        "    # print((y_pred - y) ** 2 * loss_weight_normalized)\n",
        "    # print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output * 10000, 'average time', timer.value(), 'iter num', iter) # print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-c8c30e4018d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# loss will converge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMSELoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/distributed/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomp_models\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxla\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlauncher\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/distributed/auto.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtyping\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOptimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mUSE_GLOBAL_DEPS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0m_load_global_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa: F403\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;31m# Appease the type checker; ordinarily this binding is inserted by the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: module functions cannot set METH_CLASS or METH_STATIC"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a40050a-cd45-4d56-b0a2-dc7b4237eec2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_test_3.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Lilian/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c128eb8f-e347-4bf0-bc7c-9233ccdcb1d0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d191550b-01ad-4c51-ae6b-74c764bb64d1"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_test_4.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Lilian/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30978467-0bab-45b4-f921-6d0c85de0ea3"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=18, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc5): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc6): Linear(in_features=1024, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3b39835-19bf-4d40-84df-6f4f140ad607"
      },
      "source": [
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "#dataset = OptionDataSet(max_len = 100, number_path = 1024, batch = 32, seed = np.random.randint(10000), stocks = 3) # must have random seed\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 100000, batch = 8, seed = np.random.randint(10000), stocks = 3) # must have random seed\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    \n",
        "    y_pred = model(x)\n",
        "    \n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2,8,14]]\n",
        "\n",
        "    # print(torch.unbind(x))\n",
        "    # print([compute_deltas(x) for x in torch.unbind(x)])\n",
        "    # print(torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0))\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    error = (y_pred - y)/y\n",
        "    error = error[abs(error) != float(\"Inf\")].mean()\n",
        "    print('error', error)\n",
        "\n",
        "\n",
        "    loss_weight = 1/(y.mean(axis=0)**2)\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean() # compute weighted MSE between the 2 arrays\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 10\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output * 10000, 'average time', timer.value(), 'iter num', iter) # print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 50)\n",
        "\n",
        "# model_save_name = 'jax_european_test_3.pth'\n",
        "# path = F\"/content/drive/MyDrive/AFP Project/Lilian/{model_save_name}\" \n",
        "# torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "error tensor(0.3386, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.2135, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0037, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-748.1926, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(219.5309, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(3.7461, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-127.6580, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-1414.2839, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-3.2178, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.1370, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 1.1413099127821624 average time 0.1737452590999055 iter num 10\n",
            "error tensor(67.5247, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(1090.2649, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-12.3441, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-505.9640, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-118.1467, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-1.1451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-296.5696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(5693.0127, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(1587.8082, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(21.6944, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.30090495783952065 average time 0.09879784119996202 iter num 20\n",
            "error tensor(3.0779, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(18483.0332, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(3.1952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-2.8268, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0252, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-83.3324, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-281.4715, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.4337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(22.2437, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.11154785170219839 average time 0.073477441466639 iter num 30\n",
            "error tensor(1.0950, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(3.3373, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0379, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(69.4862, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(66.7573, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-1.1254, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-4.4392, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(1.9970, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-60.4857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0109, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.9751407924341038 average time 0.06079207199996972 iter num 40\n",
            "error tensor(-945.6541, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-2.5031, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.2294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-3.3468, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(2.1672, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.2625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0396, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(62.7958, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0248, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(172.3886, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 3.5028447746299207 average time 0.053463448019983845 iter num 50\n",
            "error tensor(4.0473, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(23183.4355, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-16.5942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.2200, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-275.7495, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-9.3963, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.9398, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-6294.8799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-223.0677, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.3332092455821112 average time 0.04840394808331894 iter num 60\n",
            "error tensor(-2.0790, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(13.3271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-1.0059, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.2857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-224.7225, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0676, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-4.0549, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-1.0321, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(26.4161, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.3891, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.48986537876771763 average time 0.044728670957147186 iter num 70\n",
            "error tensor(0.0378, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.5728, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-3.1165, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0152, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-1.0629, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-3.2279, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-8.6591, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-22.9132, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(17.5021, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.1426, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.3078107692999765 average time 0.04190516488751541 iter num 80\n",
            "error tensor(-0.0044, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0660, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(490.8815, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0696, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(53.3476, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-13.7693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0240, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(6.0251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(4.4902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.3666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.07121037469914882 average time 0.0397626040889059 iter num 90\n",
            "error tensor(0.1978, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-268.1203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(1.9100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-71.5855, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-295.4438, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-6.9164, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.4182, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(1.5816, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.5267, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.9348, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.6526515790028498 average time 0.037994880270016435 iter num 100\n",
            "error tensor(0.9800, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-57.5314, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-9.7088, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-2972.9548, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.7726, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-327.5245, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0045, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.4201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-109.6172, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.1451, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.25745561288204044 average time 0.1634554188000493 iter num 10\n",
            "error tensor(51.4139, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-14.9118, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-37.2935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-3.4596, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(5.5538, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(65.5843, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(5.0707, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(431.4372, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(7.4002, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(4.5836, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 1.1007038847310469 average time 0.09289540125007534 iter num 20\n",
            "error tensor(0.1984, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(946.5854, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(66.7693, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-186.1680, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-59.4497, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-1.3404, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-2.5882, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-1252.4271, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0297, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(1691.8123, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.516105501446873 average time 0.06913877446671297 iter num 30\n",
            "error tensor(38.0730, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(4.8285, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0029, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(50.7203, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(64.8865, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.1847, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(2.3208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-7.7764, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0091, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-8.0436, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.07616129096277291 average time 0.05763088350001908 iter num 40\n",
            "error tensor(-112.4136, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.7623, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.2907, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.1631, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0375, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-13.4251, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0301, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-30.8163, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.9563, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0053, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.3038943941646721 average time 0.05051315854002496 iter num 50\n",
            "error tensor(-3.6935, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(21.3050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0638, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-190.5442, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.1391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(1.3942, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.1759, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.7390, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-4.2806, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(141.3323, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.08445953426416963 average time 0.04594017313336281 iter num 60\n",
            "error tensor(0.0192, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-1.1987, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.4519, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(2.9552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-7.7687, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.9294, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.5561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0121, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-22.9799, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(1.1482, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.23516939108958468 average time 0.04262241408574222 iter num 70\n",
            "error tensor(18.4452, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-42.4095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(13.9204, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0201, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-9.5543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(22.7663, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-217.8385, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0050, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-645.4666, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0337, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.13571218005381525 average time 0.04003161475002344 iter num 80\n",
            "error tensor(-2.0983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.1653, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.5391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(257.4189, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(1.4156, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(2.8904, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0317, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-43.4787, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-113.7304, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0076, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.09230157957063057 average time 0.03801689048890593 iter num 90\n",
            "error tensor(9.2421, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.1745, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-2.0931, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.9187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-6.7374, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0215, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0122, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.1889, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.4412, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-50.9342, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.2113749724230729 average time 0.03649525633001758 iter num 100\n",
            "error tensor(19.9264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-33.4039, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0552, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.8003, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-14.9757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.2089, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0969, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-1.5991, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-240.4391, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0658, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.9889318607747555 average time 0.1618179417999727 iter num 10\n",
            "error tensor(-0.0042, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0543, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(4.5095, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.3100, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0255, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(59.2960, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-37.6523, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-6.9131, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.3264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-10.3435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.35529443266568705 average time 0.09226199965000888 iter num 20\n",
            "error tensor(0.2881, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(12.9936, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.2018, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(12.8208, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0361, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(1.2274, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.8578, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.6069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-93.4798, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-9.5586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.47682107833679765 average time 0.06879468010001802 iter num 30\n",
            "error tensor(1169.5435, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(3.4710, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-5.0357, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(23.6741, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-480.6625, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-637.4567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0180, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-1.8028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0277, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(2.0841, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 2.155312104150653 average time 0.057083881824996754 iter num 40\n",
            "error tensor(0.3813, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-2.6144, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(40.3400, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.1339, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-10.3219, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0902, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(1.1952, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-19.1643, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(69.5771, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.0102, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.13923153346695472 average time 0.050002854580006896 iter num 50\n",
            "error tensor(-115.1678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-65.5077, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-17.7264, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.9199, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(258.0617, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.1124, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-1.0678, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-3.3561, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-5126.9609, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(1.0262, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 1.7850814037956297 average time 0.045346785683341294 iter num 60\n",
            "error tensor(-347.8956, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-62.0466, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.3405, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-10.7757, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-2.0705, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.0187, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-2.6983, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-32.8465, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.2567, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.1073, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 1.2368753959890455 average time 0.04200145657144146 iter num 70\n",
            "error tensor(0.8720, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-5.7217, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-13.2586, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-1.2485, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-152.2097, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.1096, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-0.1069, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(0.6553, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(4.4560, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(1.1992, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "loss 0.3602642027544789 average time 0.0395277366000073 iter num 80\n",
            "error tensor(0.1028, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(21.4857, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(73.1289, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(1.0752, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-35.1504, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-24.6496, device='cuda:0', grad_fn=<MeanBackward0>)\n",
            "error tensor(-4.3194, device='cuda:0', grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-2fe2019f18a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;31m# model_save_name = 'jax_european_test_3.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m           \u001b[0;31m################################################################################################### store input and output numbers in X and Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m           \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEuropean_Call_price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m           \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDeltas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.__setitem__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_routines_indexing.pyx\u001b[0m in \u001b[0;36mcupy._core._routines_indexing._ndarray_setitem\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_routines_indexing.pyx\u001b[0m in \u001b[0;36mcupy._core._routines_indexing._scatter_op\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.fill\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_forward_method\u001b[0;34m(attrname, self, fun, *args)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_forward_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0m_forward_to_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_forward_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtxsoZ9U9M8T"
      },
      "source": [
        "model_save_name = 'jax_european_test_4.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Lilian/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59845557-cdf1-4da6-a5ff-66d6ff0d0a42"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 0.8, 0.8, 0.25, 0.05, 0.05]*3]).cuda() # T, K, S, sigma, mu, r\n",
        "print('price: ' + str(model(inputs.float())))\n",
        "\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient[0][[2,8,14]]\n",
        "\n",
        "# price, delta1, delta2, delta3\n",
        "# should be around (0.067710705, 0.22125466 , 0.22136934 , 0.22104672)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: tensor([[0.0543]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.2059, 0.2070, 0.2101], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_2AXrPt7bNj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "outputId": "b0ac9fe7-78f0-4eda-ebaa-f733da7ee1bd"
      },
      "source": [
        "numstocks = 3\n",
        "numsteps = 50\n",
        "numpaths = 100000\n",
        "\n",
        "rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.05]*numstocks)\n",
        "r = drift\n",
        "cov = jnp.identity(numstocks)*0.25*0.25\n",
        "initial_stocks = jnp.array([0.8]*numstocks) # must be float\n",
        "T = 1.0\n",
        "K = 0.8\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "\n",
        "# delta test\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-3c93a19c8c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnumpaths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mrng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPRNGKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'jax' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwApH0GT9bBK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "de67e820-8158-4a63-8381-ec56620ccca7"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 0.8, S, 0.25, 0.05, 0.05] + ([1, 0.8, 0.8, 0.25, 0.05, 0.05]*2)]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "prices = np.arange(0, 1, 0.01)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3ae5ca9350>]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}