{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "European_Call.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NwN6aLFDnwiy",
        "TY_9g3tbdLiY",
        "u2_89jOknwjH",
        "rXT4Bg0wdL7l"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Erin/European_Call.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCR6hhw5Xq_R"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSxOZk3ls2XQ",
        "outputId": "ae953038-8668-4c1f-b0b6-81929d452dc7"
      },
      "source": [
        "!curl https://colab.chainer.org/install |sh -\n",
        "import cupy"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1580  100  1580    0     0   7900      0 --:--:-- --:--:-- --:--:--  7900\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "+ set +ex\n",
            "Installation succeeded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwN6aLFDnwiy"
      },
      "source": [
        "### Deep Learning Barrier Option\n",
        "\n",
        "We used Numba and CuPy in the previous notebook to run Monte Carlo simulation to determine the price of the Asian Barrier option. A Monte Carlo simulation needs millions of paths to get an accurate answer which is computationally intensive. [Ryan et al (2018)](https://arxiv.org/abs/1809.02233) showed that a deep learning model can be trained to value derivatives. The deep learning model is accurate and very fast, capable of producing valuations a million times faster than traditional models. In the this notebook, we will use a fully connected network to learn the pricing mode of the Asian Barrier option. Monte Carlo simulation is used as pricing ground truth for the training. We use the same Asian Barrier Option model as last notebook with parameters listed as following:\n",
        "\n",
        "```\n",
        "T - Maturity (yrs.)\n",
        "S - Spot (usd)\n",
        "K - Strike (usd)\n",
        "sigma - Volatility (per.)\n",
        "r - Risk Free Rate (per.)\n",
        "mu - Stock Drift Rate (per.)\n",
        "B - Barrier (usd)\n",
        "```\n",
        "\n",
        "### Batched Data generation\n",
        "\n",
        "The dataset is an important part of the Deep learning training. We will modify the previous single Asian Barrier Option pricing code to handle a batch of Barrier Option pricing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHYrh4iYfP-n",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "###Test: Judy's new X code\n",
        "#N_STOCKS = 3"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy7qGwT0jv4A",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#X = cupy.array([])\n",
        "#for i in range(0,N_STOCKS):\n",
        "  #X =  cupy.concatenate((X,cupy.array([1,1]), cupy.random.rand(3),cupy.array([1])))\n",
        "#X = X.reshape(N_STOCKS,6)\n",
        "#X"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OHtAXC8hVae",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#X = X * ((cupy.array([200.0, 0, 200.0, 0.4, 0.2, 0.2] * N_STOCKS, dtype = cupy.float32)).reshape(N_STOCKS, 6))\n",
        "#X"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY_9g3tbdLiY"
      },
      "source": [
        "### Train(Erin Version)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBxT9Eida-c_"
      },
      "source": [
        "# ################################# TEST ########################################\n",
        "# %%writefile cupy_dataset.py\n",
        "\n",
        "# import numba\n",
        "# from numba import cuda\n",
        "# import random\n",
        "# import cupy\n",
        "# import numpy as np\n",
        "# import math\n",
        "# import time\n",
        "# import torch\n",
        "# cupy.cuda.set_allocator(None)\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# @cuda.jit\n",
        "# def batch_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_BATCH):\n",
        "#     # ii - overall thread index\n",
        "#     ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "#     stride = cuda.gridDim.x * cuda.blockDim.x\n",
        "#     tmp3 = math.sqrt(T/N_STEPS)\n",
        "#     for i in range(ii, N_PATHS * N_BATCH, stride):\n",
        "#         batch_id = i // N_PATHS\n",
        "#         path_id = i % N_PATHS\n",
        "#         tmp1 = mu[batch_id]*T/N_STEPS\n",
        "#         tmp2 = math.exp(-r[batch_id]*T)\n",
        "#         running_average = 0.0\n",
        "#         s_curr = S0[batch_id]\n",
        "#         for n in range(N_STEPS):\n",
        "#             s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH] # stock price\n",
        "#             running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average) # average of the path\n",
        "#             if i==0 and batch_id == 2:\n",
        "#                 print(s_curr)\n",
        "#             if running_average <= B[batch_id]: # if reach barrier, drop out the path\n",
        "#                 break\n",
        "#         payoff = running_average - K[batch_id] if running_average > K[batch_id] else 0\n",
        "#         d_s[i] = tmp2 * payoff\n",
        "\n",
        "# class NumbaOptionDataSet(object):\n",
        "    \n",
        "#     def __init__(self, max_len=10, number_path = 1000, batch=2, threads=512, seed=15, stocks=3):  # 3 stocks\n",
        "#         self.num = 0\n",
        "#         self.max_length = max_len\n",
        "#         self.N_PATHS = number_path\n",
        "#         self.N_STEPS = 365\n",
        "#         self.N_BATCH = batch\n",
        "#         self.N_STOCKS = stocks\n",
        "#         self.T = np.float32(1.0)\n",
        "#         self.output = cupy.zeros(self.N_STOCKS*self.N_PATHS, dtype=cupy.float32) \n",
        "#         self.number_of_blocks = (self.N_PATHS * self.N_STOCKS - 1) // threads + 1\n",
        "#         self.number_of_threads = threads\n",
        "#         cupy.random.seed(seed)\n",
        "        \n",
        "#     def __len__(self):\n",
        "#         return self.max_length\n",
        "        \n",
        "#     def __iter__(self):\n",
        "#         self.num = 0\n",
        "#         return self\n",
        "    \n",
        "#     def __next__(self):\n",
        "#         if self.num > self.max_length:\n",
        "#             raise StopIteration\n",
        "        \n",
        "#         Y = cupy.zeros(self.N_BATCH, dtype=cupy.float32)\n",
        "#         paras = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "#         for op in range(self.N_BATCH):\n",
        "          \n",
        "#           X = cupy.array([])\n",
        "#           K_rand = cupy.random.rand(1)[0]\n",
        "#           B_rand = cupy.random.rand(1)[0]\n",
        "#           r_rand = cupy.random.rand(1)[0]\n",
        "#           for i in range(0,self.N_STOCKS):\n",
        "#             X =  cupy.concatenate((X,cupy.array([K_rand,B_rand]), cupy.random.rand(3),cupy.array([r_rand]))) #[K,B,S0,sigma,mu,r], K B r are shared\n",
        "#           X = X.reshape(self.N_STOCKS,6)\n",
        "#           X = X * ((cupy.array([200.0, 0.1, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6))\n",
        "#           #X = cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)\n",
        "#           #X = 0.9 + cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)*0.1\n",
        "#           # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "#           #X = (X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6)\n",
        "\n",
        "#           # make sure the Barrier is smaller than the Strike price\n",
        "#           # X[:, 1] = X[:, 0] * X[:, 1]\n",
        "#           for i in range(self.N_STOCKS):\n",
        "#             paras[op,i*6:(i+1)*6] = X[i,:]\n",
        "\n",
        "#           stocks_randoms_mean = cupy.zeros(self.N_STOCKS, dtype = cupy.float32)\n",
        "#           rho = cupy.random.normal(0, 1, self.N_STOCKS, dtype = cupy.float32)\n",
        "\n",
        "#           #stocks_randoms_cov = cupy.ones((self.N_STOCKS, self.N_STOCKS), dtype = cupy.float32)\n",
        "#           #cupy.fill_diagonal(stocks_randoms_cov, rho)\n",
        "\n",
        "#           #stocks_randoms_cov = (-0.99 + cupy.random.rand(self.N_STOCKS*self.N_STOCKS, dtype=cupy.float32)*2*0.99).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "#           stocks_randoms_cov = cupy.array([1] * self.N_STOCKS*self.N_STOCKS, dtype = cupy.float32).reshape(self.N_STOCKS,self.N_STOCKS)  #Covariance\n",
        "#           cupy.fill_diagonal(stocks_randoms_cov, 1)\n",
        "\n",
        "#           num_of_randoms_each_stock = self.N_PATHS * self.N_STEPS\n",
        "#           randoms_gpu = cupy.random.multivariate_normal(stocks_randoms_mean, stocks_randoms_cov,\n",
        "#                                                         num_of_randoms_each_stock, dtype=cupy.float32)\n",
        "#           b1_r = randoms_gpu[:,0]\n",
        "#           b2_r = randoms_gpu[:,1]\n",
        "#           randoms = cupy.zeros(self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "#           interval = int((self.N_PATHS * self.N_STEPS * self.N_STOCKS) / self.N_PATHS)\n",
        "#           for i in range(interval):\n",
        "#             if i % 2 == 0:\n",
        "#                 ind = int(i/2)\n",
        "#                 randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b1_r[ind:(ind+self.N_PATHS)]\n",
        "#             else:\n",
        "#                 ind = int(i//2)\n",
        "#                 randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b2_r[ind:(ind+self.N_PATHS)]\n",
        "\n",
        "#           randoms = cupy.random.normal(0, 1, self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "#           batch_barrier_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, self.T, X[:, 0], \n",
        "#                                 X[:, 1], X[:, 2], X[:, 3], X[:, 4], X[:, 5], randoms, self.N_STEPS, self.N_PATHS, self.N_STOCKS)\n",
        "          \n",
        "#           o = self.output.reshape(self.N_STOCKS, self.N_PATHS)\n",
        "#           Y[op] = o.mean(axis = 0).mean()\n",
        "\n",
        "#         self.num += 1\n",
        "#         return (from_dlpack(paras.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "\n",
        "# # ds = NumbaOptionDataSet(10, number_path=100000, batch=3, seed=random.randint(0,100), stocks=5)\n",
        "# # for i in ds:\n",
        "# #     print(i[0])\n",
        "# ################################# TEST ########################################"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6dZnWTTfbf1"
      },
      "source": [
        "### Train (European Call option)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeREuPw0fguQ",
        "outputId": "0d98163f-bc4d-4a22-8b3a-fd351f084bce"
      },
      "source": [
        "################################# TEST ########################################\n",
        "%%writefile cupy_dataset.py\n",
        "\n",
        "import numba\n",
        "from numba import cuda\n",
        "import random\n",
        "import cupy\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "cupy.cuda.set_allocator(None)\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "@cuda.jit\n",
        "def European_call_option(d_s, T, K, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_BATCH):\n",
        "    # ii - overall thread index\n",
        "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
        "    #tmp3 = math.sqrt(T/N_STEPS)\n",
        "    for i in range(ii, N_PATHS * N_BATCH, stride):\n",
        "        batch_id = i // N_PATHS\n",
        "        path_id = i % N_PATHS\n",
        "        h = T[batch_id] / N_STEPS\n",
        "        tmp1 = mu[batch_id]*T[batch_id]/N_STEPS \n",
        "        tmp2 = math.exp(-r[batch_id]*T[batch_id]) # discount\n",
        "        tmp3 = math.sqrt(T[batch_id]/N_STEPS)\n",
        "        #running_average = 0.0\n",
        "        s_curr = S0[batch_id]\n",
        "        for n in range(N_STEPS):\n",
        "          #s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH] # stock price\n",
        "          s_curr = s_curr * math.exp((r[batch_id] - (1/2)*sigma[batch_id]**2)*h + sigma[batch_id] * tmp3 * d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH])\n",
        "          #running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average) # average of the path\n",
        "          #if i==0 and batch_id == 2:\n",
        "          #    print(s_curr)\n",
        "          #if running_average <= B[batch_id]: # if reach barrier, drop out the path\n",
        "          #    break\n",
        "        #payoff = running_average - K[batch_id] if running_average > K[batch_id] else 0\n",
        "        payoff = s_curr - K[batch_id] if s_curr > K[batch_id] else 0\n",
        "        d_s[i] = tmp2 * payoff\n",
        "\n",
        "class NumbaOptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len=10, number_path = 1000, batch=2, threads=512, seed=15, stocks=3):  # 3 stocks\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        #self.N_STEPS = 365\n",
        "        self.N_STEPS = 10000\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        #self.T = np.float32(1.0)\n",
        "        self.output = cupy.zeros(self.N_STOCKS*self.N_PATHS, dtype=cupy.float32) \n",
        "        self.number_of_blocks = (self.N_PATHS * self.N_STOCKS - 1) // threads + 1\n",
        "        self.number_of_threads = threads\n",
        "        cupy.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num > self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros(self.N_BATCH, dtype=cupy.float32)\n",
        "        paras = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "        #paras = cupy.zeros((self.N_BATCH, self.N_STOCKS * 5), dtype = cupy.float32)\n",
        "\n",
        "        for op in range(self.N_BATCH):\n",
        "          \n",
        "          X = cupy.array([])\n",
        "          #T_rand = cupy.random.rand(1)[0]\n",
        "          #K_rand = cupy.random.rand(1)[0]\n",
        "          #B_rand = cupy.random.rand(1)[0]\n",
        "          #r_rand = cupy.random.rand(1)[0]\n",
        "          for i in range(0, self.N_STOCKS):\n",
        "            #X =  cupy.concatenate((X, cupy.array([K_rand,B_rand]), cupy.random.rand(3), cupy.array([r_rand]))) #[K,B,S0,sigma,mu,r], K B r are shared\n",
        "            X = cupy.concatenate((X, cupy.random.rand(6))) #[T, K, S0, sigma, mu, r]\n",
        "          \n",
        "          X = X.reshape(self.N_STOCKS, 6)\n",
        "          #X = X * ((cupy.array([200.0, 0.1, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6))\n",
        "          #[T, K, S0, sigma, mu, r]\n",
        "          X = X * ((cupy.array([3, 200.0, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6))\n",
        "          #X = cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)\n",
        "          #X = 0.9 + cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)*0.1\n",
        "          # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "          #X = (X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6)\n",
        "\n",
        "          # make sure the Barrier is smaller than the Strike price\n",
        "          # X[:, 1] = X[:, 0] * X[:, 1]\n",
        "          for i in range(self.N_STOCKS):\n",
        "            paras[op,i*6:(i+1)*6] = X[i,:]\n",
        "            #paras[op, i*5:(i+1)*5] = X[i,:]\n",
        "\n",
        "          stocks_randoms_mean = cupy.zeros(self.N_STOCKS, dtype = cupy.float32)\n",
        "          rho = cupy.random.normal(0, 1, self.N_STOCKS, dtype = cupy.float32)\n",
        "\n",
        "          #stocks_randoms_cov = cupy.ones((self.N_STOCKS, self.N_STOCKS), dtype = cupy.float32)\n",
        "          #cupy.fill_diagonal(stocks_randoms_cov, rho)\n",
        "\n",
        "          #stocks_randoms_cov = (-0.99 + cupy.random.rand(self.N_STOCKS*self.N_STOCKS, dtype=cupy.float32)*2*0.99).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "          if self.N_STOCKS != 1:\n",
        "            stocks_randoms_cov = cupy.array([1] * self.N_STOCKS*self.N_STOCKS, dtype = cupy.float32).reshape(self.N_STOCKS,self.N_STOCKS)  #Covariance\n",
        "            cupy.fill_diagonal(stocks_randoms_cov, 1)\n",
        "\n",
        "            num_of_randoms_each_stock = self.N_PATHS * self.N_STEPS\n",
        "            randoms_gpu = cupy.random.multivariate_normal(stocks_randoms_mean, stocks_randoms_cov,\n",
        "                                                          num_of_randoms_each_stock, dtype=cupy.float32)\n",
        "            b1_r = randoms_gpu[:,0]\n",
        "            b2_r = randoms_gpu[:,1]\n",
        "            randoms = cupy.zeros(self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "            interval = int((self.N_PATHS * self.N_STEPS * self.N_STOCKS) / self.N_PATHS)\n",
        "            for i in range(interval):\n",
        "              if i % 2 == 0:\n",
        "                  ind = int(i/2)\n",
        "                  randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b1_r[ind:(ind+self.N_PATHS)]\n",
        "              else:\n",
        "                  ind = int(i//2)\n",
        "                  randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b2_r[ind:(ind+self.N_PATHS)]\n",
        "          if self.N_STOCKS == 1:\n",
        "            randoms = cupy.random.normal(0, 1, self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "          \n",
        "          European_call_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, X[:, 0], \n",
        "                                X[:, 1], X[:, 2], X[:, 3], X[:, 4], X[:, 5], randoms, self.N_STEPS, self.N_PATHS, self.N_STOCKS)\n",
        "          \n",
        "          o = self.output.reshape(self.N_STOCKS, self.N_PATHS)\n",
        "          Y[op] = o.mean(axis = 0).mean()\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(paras.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "\n",
        "# ds = NumbaOptionDataSet(2, number_path = 100000, batch = 1, seed = random.randint(0,100), stocks=1)\n",
        "# for i in ds:\n",
        "#     print(i)\n",
        "################################# TEST ########################################"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting cupy_dataset.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2_89jOknwjH"
      },
      "source": [
        "### Model\n",
        "To map the option parameters to price, we use 6 layers of fully connected neural network with hidden dimension 512 as inspired by [this paper](https://arxiv.org/abs/1809.02233). Writing this DL price model into a file `model.py`:-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMHqzJycx8XH"
      },
      "source": [
        "### Modified Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTn7iJQryAIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62cb897b-ff46-49be-87c9-6077873a9d5b"
      },
      "source": [
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# class Net(nn.Module):\n",
        "\n",
        "#     def __init__(self, hidden=1024):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.fc1 = nn.Linear(18, hidden) # remember to change this!\n",
        "#         self.fc2 = nn.Linear(hidden, hidden)\n",
        "#         self.fc3 = nn.Linear(hidden, hidden)\n",
        "#         self.fc4 = nn.Linear(hidden, hidden)\n",
        "#         self.fc5 = nn.Linear(hidden, hidden)\n",
        "#         self.fc6 = nn.Linear(hidden, 1)\n",
        "#         self.register_buffer('norm',\n",
        "#                              torch.tensor([200.0, 0.1, 200.0, 0.4, 0.2, 0.2]*3)) # don't use numpy here - will give error later\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 1)\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([3, 200.0, 200.0, 0.4, 0.2, 0.2]*1)) # don't use numpy here - will give error later\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting model.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSPRFqyznwjI"
      },
      "source": [
        "As we know the random parameters' scaling factors, the input parameters are first scaled back to a range of (0-1) by dividing them by (200.0, 198.0, 200.0, 0.4, 0.2, 0.2). Then they are projected 5 times to the hidden dimension of 512 after the `ELu` activation function. `ELu` is chosen because we need to compute the second order differentiation of the parameters. If use ReLu, the second order differentiation will always be zero. The last layer is a linear layer that maps the hidden dimension to the predicted option price. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM8J2liPnwjJ"
      },
      "source": [
        "For training, we use [Ignite](https://github.com/pytorch/ignite) which is a high-level library to train neural networks in PyTorch. We use `MSELoss` as the loss function, `Adam` as the optimizer and `CosineAnnealingScheduler` as the learning rate scheduler. The following code is feeding the random option data to the pricing model to train it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yACi4ge13_rd"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TyZT8_AH35M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f63553a-ba5b-46b6-b537-992daa8a6f98"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.7/dist-packages (0.4.6)\n",
            "Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Ej82G8nwjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93336eb-8323-4a9a-b556-caf5695c850d"
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import NumbaOptionDataSet\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "# dataset = NumbaOptionDataSet(max_len = 10000, number_path = 1024, batch = 4800)\n",
        "# dataset = NumbaOptionDataSet(max_len = 100, number_path = 1024, batch = 32, stocks = 3)\n",
        "dataset = NumbaOptionDataSet(max_len = 1000, number_path = 1024, batch = 1, stocks = 1)\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred[:,0], y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs=1000)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "loss 0.00018270665896125138 average time 0.0033298876503977228 iter num 20\n",
            "loss 1.6410932540893555 average time 0.003245481500243841 iter num 40\n",
            "loss 0.08091861754655838 average time 0.003091919616811841 iter num 60\n",
            "loss 1.7769250869750977 average time 0.0030069116625554672 iter num 80\n",
            "loss 18.064380645751953 average time 0.00292766490003487 iter num 100\n",
            "loss 0.33621886372566223 average time 0.0028453532749911875 iter num 120\n",
            "loss 10.64925765991211 average time 0.0028041339999487847 iter num 140\n",
            "loss 0.39108288288116455 average time 0.0027497959936908954 iter num 160\n",
            "loss 0.23227928578853607 average time 0.0027880430777157826 iter num 180\n",
            "loss 0.222361221909523 average time 0.002747642434951558 iter num 200\n",
            "loss 0.008906755596399307 average time 0.0027207582908390163 iter num 220\n",
            "loss 0.39332377910614014 average time 0.0027249719666012123 iter num 240\n",
            "loss 0.006806368473917246 average time 0.002715405396107739 iter num 260\n",
            "loss 0.13378207385540009 average time 0.0027241177428030433 iter num 280\n",
            "loss 17.303726196289062 average time 0.0027579850466342274 iter num 300\n",
            "loss 0.13468627631664276 average time 0.002754728365601977 iter num 320\n",
            "loss 33.92490005493164 average time 0.0027570324293853497 iter num 340\n",
            "loss 30.222007751464844 average time 0.0027505669333095285 iter num 360\n",
            "loss 0.008484193123877048 average time 0.002745931089458808 iter num 380\n",
            "loss 0.2273445725440979 average time 0.002744664617489434 iter num 400\n",
            "loss 0.0004354859993327409 average time 0.0027436223809542883 iter num 420\n",
            "loss 3.0300357341766357 average time 0.002745865552267126 iter num 440\n",
            "loss 1.7219854593276978 average time 0.0027334831043370525 iter num 460\n",
            "loss 3.512078285217285 average time 0.0027186930583146325 iter num 480\n",
            "loss 2.9995014667510986 average time 0.0027132668559897866 iter num 500\n",
            "loss 0.19467930495738983 average time 0.002714957082683283 iter num 520\n",
            "loss 3.1180529594421387 average time 0.0027183286981400873 iter num 540\n",
            "loss 1.478135585784912 average time 0.0027207766142769937 iter num 560\n",
            "loss 19.64167022705078 average time 0.0027325351258570725 iter num 580\n",
            "loss 2.786811113357544 average time 0.002731470398327171 iter num 600\n",
            "loss 0.03478885814547539 average time 0.00272656527901833 iter num 620\n",
            "loss 442.4209899902344 average time 0.002715372049979692 iter num 640\n",
            "loss 0.2077806442975998 average time 0.0027041140575502966 iter num 660\n",
            "loss 0.18233393132686615 average time 0.00270138682056527 iter num 680\n",
            "loss 14.396683692932129 average time 0.002691323729977739 iter num 700\n",
            "loss 7.726611614227295 average time 0.002698429022201607 iter num 720\n",
            "loss 2.504150629043579 average time 0.0026870028891681687 iter num 740\n",
            "loss 0.06670212745666504 average time 0.0026835116197186214 iter num 760\n",
            "loss 0.17196153104305267 average time 0.00268528256279891 iter num 780\n",
            "loss 3.765826841117814e-05 average time 0.0026869601137263998 iter num 800\n",
            "loss 0.11840546876192093 average time 0.0026895624963178375 iter num 820\n",
            "loss 1.941399335861206 average time 0.0026896431118811526 iter num 840\n",
            "loss 1.5896785259246826 average time 0.0026962934127643464 iter num 860\n",
            "loss 0.09533217549324036 average time 0.0026999987079307174 iter num 880\n",
            "loss 609.5879516601562 average time 0.0027007152666475224 iter num 900\n",
            "loss 171.36997985839844 average time 0.0027011889347625623 iter num 920\n",
            "loss 20.33564567565918 average time 0.002692479580824472 iter num 940\n",
            "loss 0.3804367482662201 average time 0.0026891811385098665 iter num 960\n",
            "loss 0.437282919883728 average time 0.002687039340782242 iter num 980\n",
            "loss 1.5021216869354248 average time 0.0026881992029648247 iter num 1000\n",
            "loss 1.5564024448394775 average time 0.003390266349833837 iter num 20\n",
            "loss 2.738335132598877 average time 0.0029182091749134997 iter num 40\n",
            "loss 0.037686433643102646 average time 0.002883845866623839 iter num 60\n",
            "loss 2.0198848247528076 average time 0.0028467937499726758 iter num 80\n",
            "loss 4.326296329498291 average time 0.002875043469994125 iter num 100\n",
            "loss 5.1684064865112305 average time 0.0028540393583474117 iter num 120\n",
            "loss 0.031251415610313416 average time 0.0028405733785543167 iter num 140\n",
            "loss 18.688642501831055 average time 0.002814963706225626 iter num 160\n",
            "loss 0.02000349573791027 average time 0.0027951890666574604 iter num 180\n",
            "loss 1.1164389848709106 average time 0.0028157525699771214 iter num 200\n",
            "loss 0.7290825247764587 average time 0.0028387309727060544 iter num 220\n",
            "loss 0.44675320386886597 average time 0.002841179366646429 iter num 240\n",
            "loss 0.3844696283340454 average time 0.002830874484600197 iter num 260\n",
            "loss 16.02943229675293 average time 0.0028169005250025035 iter num 280\n",
            "loss 12.70505428314209 average time 0.002807284216669359 iter num 300\n",
            "loss 4.073392868041992 average time 0.0027911615343953144 iter num 320\n",
            "loss 0.9481688737869263 average time 0.002779459344144604 iter num 340\n",
            "loss 3.081770420074463 average time 0.002785245494477648 iter num 360\n",
            "loss 2.8062710762023926 average time 0.002783692228977567 iter num 380\n",
            "loss 0.30364757776260376 average time 0.002771427830034554 iter num 400\n",
            "loss 0.3617042005062103 average time 0.0027645371333641206 iter num 420\n",
            "loss 301.7851257324219 average time 0.0027663703500241934 iter num 440\n",
            "loss 1.2500008344650269 average time 0.0027636710282738773 iter num 460\n",
            "loss 0.019696060568094254 average time 0.0027774913083514247 iter num 480\n",
            "loss 0.41196590662002563 average time 0.00277903365401653 iter num 500\n",
            "loss 0.6975930333137512 average time 0.002774423548089544 iter num 520\n",
            "loss 1.3616926670074463 average time 0.0027756880722369748 iter num 540\n",
            "loss 2.4199600219726562 average time 0.0027765171357227053 iter num 560\n",
            "loss 0.23947027325630188 average time 0.0027732356069150384 iter num 580\n",
            "loss 0.014836040325462818 average time 0.0027695913950113514 iter num 600\n",
            "loss 0.03924787417054176 average time 0.0027763412758113485 iter num 620\n",
            "loss 19.4422607421875 average time 0.00278890557657121 iter num 640\n",
            "loss 2.844773054122925 average time 0.002784443327282409 iter num 660\n",
            "loss 12.37775707244873 average time 0.0027820625397132117 iter num 680\n",
            "loss 100.85325622558594 average time 0.002780143465721007 iter num 700\n",
            "loss 68.20217895507812 average time 0.0027759007486186722 iter num 720\n",
            "loss 21.770954132080078 average time 0.0027832465864948233 iter num 740\n",
            "loss 1.0663739442825317 average time 0.0027795435618564192 iter num 760\n",
            "loss 3.488604784011841 average time 0.0027715531166811556 iter num 780\n",
            "loss 2.599846124649048 average time 0.002772297153760519 iter num 800\n",
            "loss 0.7313858866691589 average time 0.0027768746012265095 iter num 820\n",
            "loss 2.925114631652832 average time 0.002780506120245177 iter num 840\n",
            "loss 1.041716456413269 average time 0.0027737224627978935 iter num 860\n",
            "loss 15.976693153381348 average time 0.0027784240306842054 iter num 880\n",
            "loss 25.838441848754883 average time 0.0027789038177838342 iter num 900\n",
            "loss 0.17121435701847076 average time 0.0027768203521863263 iter num 920\n",
            "loss 0.08079729229211807 average time 0.002775452978732303 iter num 940\n",
            "loss 7.565647602081299 average time 0.002774702832298696 iter num 960\n",
            "loss 15.31988525390625 average time 0.0027793716673507017 iter num 980\n",
            "loss 122.6396713256836 average time 0.002775065297004403 iter num 1000\n",
            "loss 14.870817184448242 average time 0.003390024700001959 iter num 20\n",
            "loss 3.8474020957946777 average time 0.0030219828249300916 iter num 40\n",
            "loss 0.17155517637729645 average time 0.002903446066708663 iter num 60\n",
            "loss 33.257301330566406 average time 0.0028226902750247973 iter num 80\n",
            "loss 4.313684940338135 average time 0.002791260339981818 iter num 100\n",
            "loss 9.498916625976562 average time 0.0028325188249709752 iter num 120\n",
            "loss 15.254289627075195 average time 0.0028488631714156196 iter num 140\n",
            "loss 2.2292428016662598 average time 0.00285380268122708 iter num 160\n",
            "loss 77.96798706054688 average time 0.002840749799977655 iter num 180\n",
            "loss 4.374917030334473 average time 0.0028618314400046074 iter num 200\n",
            "loss 0.7314776182174683 average time 0.002856554272735097 iter num 220\n",
            "loss 1.6517688035964966 average time 0.0028428299958629093 iter num 240\n",
            "loss 0.0018422077409923077 average time 0.002835413023093189 iter num 260\n",
            "loss 0.31883561611175537 average time 0.0028319746928575896 iter num 280\n",
            "loss 6.978098826948553e-05 average time 0.002848443196653534 iter num 300\n",
            "loss 3.7491774559020996 average time 0.0028370211468711657 iter num 320\n",
            "loss 0.0809837356209755 average time 0.002833594502959279 iter num 340\n",
            "loss 11.790692329406738 average time 0.002835339338915017 iter num 360\n",
            "loss 0.9069350361824036 average time 0.0028263298342512586 iter num 380\n",
            "loss 0.3529905080795288 average time 0.002825192255040747 iter num 400\n",
            "loss 51.112701416015625 average time 0.0028314733881156175 iter num 420\n",
            "loss 4.776681900024414 average time 0.0028406225750214533 iter num 440\n",
            "loss 1.3949856758117676 average time 0.0028548631369710127 iter num 460\n",
            "loss 1.0078918933868408 average time 0.00284588545000967 iter num 480\n",
            "loss 1.2746188640594482 average time 0.002853424967997853 iter num 500\n",
            "loss 48.24298095703125 average time 0.002848103211538098 iter num 520\n",
            "loss 0.25860241055488586 average time 0.0028425856555494883 iter num 540\n",
            "loss 0.02760300226509571 average time 0.0028467278249893623 iter num 560\n",
            "loss 8.373806953430176 average time 0.0028496022327497736 iter num 580\n",
            "loss 0.036066144704818726 average time 0.0028505612616572763 iter num 600\n",
            "loss 1.149888515472412 average time 0.002841009625790907 iter num 620\n",
            "loss 2.733543634414673 average time 0.0028379980296676876 iter num 640\n",
            "loss 80.65443420410156 average time 0.0028476230363373885 iter num 660\n",
            "loss 12.303854942321777 average time 0.0028363444735024293 iter num 680\n",
            "loss 11.73961067199707 average time 0.002832340697116576 iter num 700\n",
            "loss 0.4562373161315918 average time 0.002825983626363874 iter num 720\n",
            "loss 0.017002342268824577 average time 0.0028173036553812993 iter num 740\n",
            "loss 0.04018536955118179 average time 0.002813745814443648 iter num 760\n",
            "loss 9.453213691711426 average time 0.0028169504794604084 iter num 780\n",
            "loss 0.9555229544639587 average time 0.002821836867474303 iter num 800\n",
            "loss 28.576786041259766 average time 0.002817265203627424 iter num 820\n",
            "loss 4.560091018676758 average time 0.002817391902347784 iter num 840\n",
            "loss 0.9697903990745544 average time 0.0028140469220636795 iter num 860\n",
            "loss 0.07313776761293411 average time 0.0028074599101997094 iter num 880\n",
            "loss 0.19240719079971313 average time 0.0028058790366412723 iter num 900\n",
            "loss 4.460185527801514 average time 0.002804162568453767 iter num 920\n",
            "loss 0.21943360567092896 average time 0.0028046471404040664 iter num 940\n",
            "loss 0.004168355837464333 average time 0.0028030151343557464 iter num 960\n",
            "loss 7.470507621765137 average time 0.0028003522856959867 iter num 980\n",
            "loss 1.1871109008789062 average time 0.002803853948980759 iter num 1000\n",
            "loss 1.4827120304107666 average time 0.0031733057000565166 iter num 20\n",
            "loss 0.27799084782600403 average time 0.00276854455009925 iter num 40\n",
            "loss 0.9971334338188171 average time 0.0028360284501104615 iter num 60\n",
            "loss 31.828184127807617 average time 0.0027308871376135356 iter num 80\n",
            "loss 3.4255154132843018 average time 0.002737985310068325 iter num 100\n",
            "loss 2.0506033897399902 average time 0.002682938025054682 iter num 120\n",
            "loss 54.213417053222656 average time 0.0026966860214867796 iter num 140\n",
            "loss 10.254633903503418 average time 0.0027000290562909867 iter num 160\n",
            "loss 17.331363677978516 average time 0.0027178508500178902 iter num 180\n",
            "loss 20.31851577758789 average time 0.002724856239992732 iter num 200\n",
            "loss 7.727478504180908 average time 0.002721421768191331 iter num 220\n",
            "loss 0.15283049643039703 average time 0.0027306088125290747 iter num 240\n",
            "loss 3.124480724334717 average time 0.002724882626933742 iter num 260\n",
            "loss 0.23190346360206604 average time 0.0027185342500030984 iter num 280\n",
            "loss 0.765498161315918 average time 0.0027100370199999208 iter num 300\n",
            "loss 12.15605354309082 average time 0.0026922679406311545 iter num 320\n",
            "loss 10.937101364135742 average time 0.0026894926529487696 iter num 340\n",
            "loss 21.470163345336914 average time 0.002688276230567984 iter num 360\n",
            "loss 1.5277763605117798 average time 0.0026859394605372997 iter num 380\n",
            "loss 9.381990432739258 average time 0.002694974527512386 iter num 400\n",
            "loss 79.80146026611328 average time 0.0027002111000088225 iter num 420\n",
            "loss 44.64085388183594 average time 0.0027008733772783504 iter num 440\n",
            "loss 40.350341796875 average time 0.0026975055282728927 iter num 460\n",
            "loss 16.98102378845215 average time 0.0026868515625096735 iter num 480\n",
            "loss 13.59128475189209 average time 0.002688532900003338 iter num 500\n",
            "loss 0.06338032335042953 average time 0.002690427342297251 iter num 520\n",
            "loss 1.3752690553665161 average time 0.0026796912333305013 iter num 540\n",
            "loss 0.05158497393131256 average time 0.0026899614249974286 iter num 560\n",
            "loss 0.42379677295684814 average time 0.0026919965482789096 iter num 580\n",
            "loss 9.430520057678223 average time 0.0026810866733376314 iter num 600\n",
            "loss 1.395706057548523 average time 0.0026722154967765456 iter num 620\n",
            "loss 4.7416300773620605 average time 0.0026746400953101103 iter num 640\n",
            "loss 0.06950676441192627 average time 0.0026752665636388083 iter num 660\n",
            "loss 17.380231857299805 average time 0.0026771607661778356 iter num 680\n",
            "loss 16.34349822998047 average time 0.002690051007146914 iter num 700\n",
            "loss 30.564517974853516 average time 0.0026890482666683765 iter num 720\n",
            "loss 0.039436206221580505 average time 0.002688354174330704 iter num 740\n",
            "loss 17.247028350830078 average time 0.0026860625223769983 iter num 760\n",
            "loss 1.0203701257705688 average time 0.0026849140859084375 iter num 780\n",
            "loss 1.5188261270523071 average time 0.0026873279262599682 iter num 800\n",
            "loss 0.3563499450683594 average time 0.0026879119487980127 iter num 820\n",
            "loss 178.430908203125 average time 0.0026851620833483704 iter num 840\n",
            "loss 2.5478756427764893 average time 0.0026783613395521167 iter num 860\n",
            "loss 49.60577392578125 average time 0.002676661350016151 iter num 880\n",
            "loss 0.010704990476369858 average time 0.002674412992237194 iter num 900\n",
            "loss 0.3144266605377197 average time 0.0026709165119684812 iter num 920\n",
            "loss 0.01577562466263771 average time 0.002681758104264442 iter num 940\n",
            "loss 0.0076400646939873695 average time 0.0026845412208407046 iter num 960\n",
            "loss 0.785772979259491 average time 0.0026822123867383868 iter num 980\n",
            "loss 28.109121322631836 average time 0.002680860360002043 iter num 1000\n",
            "loss 19.970544815063477 average time 0.0033441055998082447 iter num 20\n",
            "loss 0.6725374460220337 average time 0.002971862249842161 iter num 40\n",
            "loss 9.432652473449707 average time 0.002899293583201749 iter num 60\n",
            "loss 0.5190941095352173 average time 0.0029049003873524272 iter num 80\n",
            "loss 7.526037216186523 average time 0.002876462639942474 iter num 100\n",
            "loss 0.4536331593990326 average time 0.0028434682499209885 iter num 120\n",
            "loss 0.01125477533787489 average time 0.0028181697427628804 iter num 140\n",
            "loss 16.842409133911133 average time 0.0028116839686504135 iter num 160\n",
            "loss 0.7584189176559448 average time 0.0027963593165521968 iter num 180\n",
            "loss 138.0718231201172 average time 0.002777636044902465 iter num 200\n",
            "loss 50.382789611816406 average time 0.002815226013543989 iter num 220\n",
            "loss 7.118546009063721 average time 0.0028040636040941535 iter num 240\n",
            "loss 0.31301647424697876 average time 0.002788358173018843 iter num 260\n",
            "loss 19.062599182128906 average time 0.0027874586070863318 iter num 280\n",
            "loss 371.2080993652344 average time 0.002788088119935613 iter num 300\n",
            "loss 3.6700925827026367 average time 0.0028078913749482125 iter num 320\n",
            "loss 0.2916504442691803 average time 0.0028025411675919125 iter num 340\n",
            "loss 8.533074378967285 average time 0.0028010192860518954 iter num 360\n",
            "loss 4.077859401702881 average time 0.002777456571000489 iter num 380\n",
            "loss 11.97043228149414 average time 0.0027649247424642452 iter num 400\n",
            "loss 21.4679012298584 average time 0.002758219854725515 iter num 420\n",
            "loss 0.14022599160671234 average time 0.002787254895416812 iter num 440\n",
            "loss 11.068596839904785 average time 0.0027847022151826937 iter num 460\n",
            "loss 5.240715503692627 average time 0.0027837785208059056 iter num 480\n",
            "loss 23.86029624938965 average time 0.002780180653960997 iter num 500\n",
            "loss 0.10694801807403564 average time 0.0027732577576513834 iter num 520\n",
            "loss 0.0645613968372345 average time 0.0027658949258862037 iter num 540\n",
            "loss 0.45000985264778137 average time 0.0027624978035354227 iter num 560\n",
            "loss 4.67663049697876 average time 0.002775336553406368 iter num 580\n",
            "loss 101.64950561523438 average time 0.0027772339349485266 iter num 600\n",
            "loss 0.06864067167043686 average time 0.002775696845116815 iter num 620\n",
            "loss 30.037378311157227 average time 0.0027737063780818973 iter num 640\n",
            "loss 7.809370994567871 average time 0.0027756860484397764 iter num 660\n",
            "loss 5.044217586517334 average time 0.002772191451431889 iter num 680\n",
            "loss 0.5988060235977173 average time 0.0027704166399650735 iter num 700\n",
            "loss 0.05602601543068886 average time 0.00276199327080475 iter num 720\n",
            "loss 0.008679384365677834 average time 0.0027603348215888145 iter num 740\n",
            "loss 0.598181962966919 average time 0.0027578122618060184 iter num 760\n",
            "loss 0.317525714635849 average time 0.0027490733384277124 iter num 780\n",
            "loss 1.2012007236480713 average time 0.0027482803262182643 iter num 800\n",
            "loss 0.20448996126651764 average time 0.0027384941377665488 iter num 820\n",
            "loss 0.1307676136493683 average time 0.0027301923868630444 iter num 840\n",
            "loss 27.111108779907227 average time 0.0027243264185609554 iter num 860\n",
            "loss 3.1305389404296875 average time 0.0027221095670008503 iter num 880\n",
            "loss 0.39799800515174866 average time 0.0027196689332938855 iter num 900\n",
            "loss 106.86724853515625 average time 0.002712985178224066 iter num 920\n",
            "loss 0.09588456153869629 average time 0.0027128748606028625 iter num 940\n",
            "loss 0.08773131668567657 average time 0.0027149411999630503 iter num 960\n",
            "loss 0.8739030361175537 average time 0.0027129017162818 iter num 980\n",
            "loss 31.496036529541016 average time 0.0027162930649592453 iter num 1000\n",
            "loss 0.0009239575592800975 average time 0.0035108044999105914 iter num 20\n",
            "loss 0.002281929599121213 average time 0.003114605475093413 iter num 40\n",
            "loss 25.164453506469727 average time 0.0029829182166395186 iter num 60\n",
            "loss 1.4410878419876099 average time 0.0029369567750109128 iter num 80\n",
            "loss 0.7120428085327148 average time 0.0028985990000728636 iter num 100\n",
            "loss 0.06614804267883301 average time 0.0028454472833648954 iter num 120\n",
            "loss 78.41851806640625 average time 0.002844188592903915 iter num 140\n",
            "loss 3.170548439025879 average time 0.002818304743777844 iter num 160\n",
            "loss 10.572867393493652 average time 0.0028023413166617197 iter num 180\n",
            "loss 1.514360785484314 average time 0.0027927276599712058 iter num 200\n",
            "loss 1.058685064315796 average time 0.0027856223363332076 iter num 220\n",
            "loss 0.08762814104557037 average time 0.002775982374987507 iter num 240\n",
            "loss 2.2630650997161865 average time 0.002794745823072075 iter num 260\n",
            "loss 0.033092908561229706 average time 0.002812869196428177 iter num 280\n",
            "loss 8.285158157348633 average time 0.00281191365000268 iter num 300\n",
            "loss 0.4461682438850403 average time 0.00280550074374446 iter num 320\n",
            "loss 39.8494873046875 average time 0.002797699729420428 iter num 340\n",
            "loss 27.691837310791016 average time 0.0028040130055564483 iter num 360\n",
            "loss 1.0563293471932411e-05 average time 0.0028000979763275705 iter num 380\n",
            "loss 3.967883825302124 average time 0.002810349330011377 iter num 400\n",
            "loss 5.345063209533691 average time 0.0028055923214413358 iter num 420\n",
            "loss 13.623635292053223 average time 0.002801432627298213 iter num 440\n",
            "loss 2.8667426109313965 average time 0.0028027958043861396 iter num 460\n",
            "loss 42.68174743652344 average time 0.00279755995419085 iter num 480\n",
            "loss 0.7800366282463074 average time 0.0027901405580269055 iter num 500\n",
            "loss 9.825187683105469 average time 0.002785936092319529 iter num 520\n",
            "loss 2.1188511848449707 average time 0.0027897304851985947 iter num 540\n",
            "loss 0.6638447046279907 average time 0.0027966634553714745 iter num 560\n",
            "loss 0.33908018469810486 average time 0.0028060207603630262 iter num 580\n",
            "loss 5.254592418670654 average time 0.0027974293700117414 iter num 600\n",
            "loss 0.013057462871074677 average time 0.0027986075451765153 iter num 620\n",
            "loss 0.03092779964208603 average time 0.002783129245329974 iter num 640\n",
            "loss 13.001385688781738 average time 0.0027817243469860733 iter num 660\n",
            "loss 4.908473491668701 average time 0.0027936557853054716 iter num 680\n",
            "loss 12.96696662902832 average time 0.0027955434442914597 iter num 700\n",
            "loss 22.22878074645996 average time 0.0027909753055610055 iter num 720\n",
            "loss 39.49829864501953 average time 0.002787393037849413 iter num 740\n",
            "loss 2.9875288009643555 average time 0.002785016661855958 iter num 760\n",
            "loss 2.4143495559692383 average time 0.0027868370833437858 iter num 780\n",
            "loss 1.2583783864974976 average time 0.0027839553812646044 iter num 800\n",
            "loss 1.477013349533081 average time 0.0027867128341512865 iter num 820\n",
            "loss 0.6499062180519104 average time 0.0027881532761901847 iter num 840\n",
            "loss 0.20985327661037445 average time 0.0027858273418555762 iter num 860\n",
            "loss 0.07796413451433182 average time 0.0027802754568132183 iter num 880\n",
            "loss 8.518505096435547 average time 0.0027794579655488227 iter num 900\n",
            "loss 1.0230191946029663 average time 0.0027689264923854194 iter num 920\n",
            "loss 1.0131042003631592 average time 0.002766310740422496 iter num 940\n",
            "loss 288.20574951171875 average time 0.00276246478020236 iter num 960\n",
            "loss 0.009053793735802174 average time 0.002761494456116248 iter num 980\n",
            "loss 0.0001024223311105743 average time 0.002761501656994369 iter num 1000\n",
            "loss 33.36166000366211 average time 0.0030767203002142196 iter num 20\n",
            "loss 0.027220267802476883 average time 0.0028002188500522605 iter num 40\n",
            "loss 0.14533297717571259 average time 0.002739616783370972 iter num 60\n",
            "loss 0.5131799578666687 average time 0.0028589543250291173 iter num 80\n",
            "loss 0.03751194849610329 average time 0.002788403790000302 iter num 100\n",
            "loss 12.238787651062012 average time 0.0027596766416384828 iter num 120\n",
            "loss 10.521354675292969 average time 0.0027189692784954137 iter num 140\n",
            "loss 0.00021684053353965282 average time 0.0026908677686719785 iter num 160\n",
            "loss 17.9566593170166 average time 0.002710912049921414 iter num 180\n",
            "loss 1.2126500606536865 average time 0.002706466039926454 iter num 200\n",
            "loss 0.22288495302200317 average time 0.002756089095410888 iter num 220\n",
            "loss 3.3032684326171875 average time 0.0027826022582909597 iter num 240\n",
            "loss 19.2747745513916 average time 0.0028181655422765918 iter num 260\n",
            "loss 2.1411972045898438 average time 0.0028081980892693537 iter num 280\n",
            "loss 6.887821674346924 average time 0.0028199235333098236 iter num 300\n",
            "loss 44.21724319458008 average time 0.0028276404093446673 iter num 320\n",
            "loss 4.626936435699463 average time 0.0028574246323307094 iter num 340\n",
            "loss 4.241106986999512 average time 0.0028514173805332475 iter num 360\n",
            "loss 6.288492202758789 average time 0.0028513211184010862 iter num 380\n",
            "loss 50.82434844970703 average time 0.002838566142486343 iter num 400\n",
            "loss 0.8179201483726501 average time 0.002830919433316532 iter num 420\n",
            "loss 2.2864010334014893 average time 0.002812810006802961 iter num 440\n",
            "loss 3.133387804031372 average time 0.0028189861565094715 iter num 460\n",
            "loss 93.72382354736328 average time 0.0028217009020750083 iter num 480\n",
            "loss 0.6826828718185425 average time 0.0028188421839950026 iter num 500\n",
            "loss 0.8619089126586914 average time 0.002833112711529723 iter num 520\n",
            "loss 0.03598102182149887 average time 0.0028296324888692145 iter num 540\n",
            "loss 0.2631538510322571 average time 0.002826503705335069 iter num 560\n",
            "loss 0.20400379598140717 average time 0.0028245701378966323 iter num 580\n",
            "loss 7.71185827255249 average time 0.0028188945616329873 iter num 600\n",
            "loss 0.16001342236995697 average time 0.0028184987031929796 iter num 620\n",
            "loss 2.1682052612304688 average time 0.002817811757776667 iter num 640\n",
            "loss 1.2709465026855469 average time 0.0028172197984614204 iter num 660\n",
            "loss 2.5103118419647217 average time 0.002811668120570817 iter num 680\n",
            "loss 1.163851022720337 average time 0.0028109229328453825 iter num 700\n",
            "loss 0.9986729025840759 average time 0.002806573472207674 iter num 720\n",
            "loss 0.09090224653482437 average time 0.0028075680986394463 iter num 740\n",
            "loss 14.285161018371582 average time 0.0028138945263052797 iter num 760\n",
            "loss 10.178038597106934 average time 0.002829659741014322 iter num 780\n",
            "loss 6.510806083679199 average time 0.002834869554992565 iter num 800\n",
            "loss 0.4792671799659729 average time 0.00283665408535343 iter num 820\n",
            "loss 14.72220230102539 average time 0.0028341706261774866 iter num 840\n",
            "loss 65.56808471679688 average time 0.0028314479406807824 iter num 860\n",
            "loss 3.9260802268981934 average time 0.0028304721068004505 iter num 880\n",
            "loss 0.08644267916679382 average time 0.002838268144421616 iter num 900\n",
            "loss 1.6989660263061523 average time 0.002835789810848402 iter num 920\n",
            "loss 3.5963058471679688 average time 0.0028365509138080945 iter num 940\n",
            "loss 4.39414644241333 average time 0.002838943188515941 iter num 960\n",
            "loss 2.8373558961902745e-05 average time 0.0028324835214093304 iter num 980\n",
            "loss 0.15014685690402985 average time 0.0028303143109824304 iter num 1000\n",
            "loss 1.703802466392517 average time 0.0034532765998847026 iter num 20\n",
            "loss 5.197336673736572 average time 0.003187752424946666 iter num 40\n",
            "loss 7.631347179412842 average time 0.0030298700832342242 iter num 60\n",
            "loss 0.35786816477775574 average time 0.0029576390124248066 iter num 80\n",
            "loss 2.304994821548462 average time 0.0029463628399207663 iter num 100\n",
            "loss 1.5265942811965942 average time 0.0028895367332552268 iter num 120\n",
            "loss 0.9417178630828857 average time 0.002865724421384844 iter num 140\n",
            "loss 0.3283092677593231 average time 0.002835446549943299 iter num 160\n",
            "loss 14.599014282226562 average time 0.0028610462388617935 iter num 180\n",
            "loss 2.0411550998687744 average time 0.002876962444952369 iter num 200\n",
            "loss 5.172543048858643 average time 0.002884630640850942 iter num 220\n",
            "loss 74.13631439208984 average time 0.0028696226666094543 iter num 240\n",
            "loss 109.30865478515625 average time 0.0028521997076355688 iter num 260\n",
            "loss 0.15436027944087982 average time 0.0028356105142328097 iter num 280\n",
            "loss 0.01169462502002716 average time 0.002822781869957301 iter num 300\n",
            "loss 1.4861990213394165 average time 0.002814429340583047 iter num 320\n",
            "loss 3.209240198135376 average time 0.0028019325675974387 iter num 340\n",
            "loss 18.088132858276367 average time 0.0027951549138429577 iter num 360\n",
            "loss 0.37641340494155884 average time 0.002787346694683373 iter num 380\n",
            "loss 7.011230945587158 average time 0.002783572619946426 iter num 400\n",
            "loss 0.6940545439720154 average time 0.0027805291832789535 iter num 420\n",
            "loss 8.382137298583984 average time 0.0027742616204084864 iter num 440\n",
            "loss 5.259035110473633 average time 0.002770261062995933 iter num 460\n",
            "loss 27.837474822998047 average time 0.0027709299791316274 iter num 480\n",
            "loss 1.0082184076309204 average time 0.0027685563899613043 iter num 500\n",
            "loss 3.618055582046509 average time 0.002773921113419839 iter num 520\n",
            "loss 0.8458262085914612 average time 0.002781419101817543 iter num 540\n",
            "loss 13.854875564575195 average time 0.002776950512462203 iter num 560\n",
            "loss 0.6628034710884094 average time 0.002770170456858915 iter num 580\n",
            "loss 1.8305023908615112 average time 0.002769036146637518 iter num 600\n",
            "loss 0.42013484239578247 average time 0.0027702947193281417 iter num 620\n",
            "loss 2.2713823318481445 average time 0.0027694717499713306 iter num 640\n",
            "loss 2.907395601272583 average time 0.002777756784824746 iter num 660\n",
            "loss 0.024806633591651917 average time 0.0027781222485052295 iter num 680\n",
            "loss 25.399667739868164 average time 0.002775645187126169 iter num 700\n",
            "loss 15.341901779174805 average time 0.002775037859694546 iter num 720\n",
            "loss 0.03460056334733963 average time 0.0027723938918579488 iter num 740\n",
            "loss 1.9546886682510376 average time 0.0027744123341730494 iter num 760\n",
            "loss 12.409773826599121 average time 0.002775010375607496 iter num 780\n",
            "loss 16.1782283782959 average time 0.002771964383719023 iter num 800\n",
            "loss 0.006812351755797863 average time 0.0027720676609444524 iter num 820\n",
            "loss 0.8006366491317749 average time 0.002768444489257014 iter num 840\n",
            "loss 3.5599684715270996 average time 0.0027670440418321876 iter num 860\n",
            "loss 3.2196907997131348 average time 0.002765713345425783 iter num 880\n",
            "loss 0.0020472307223826647 average time 0.002769825275534256 iter num 900\n",
            "loss 0.12600131332874298 average time 0.002772312878238628 iter num 920\n",
            "loss 0.44060835242271423 average time 0.0027737141574262036 iter num 940\n",
            "loss 0.0496770516037941 average time 0.002771739565613037 iter num 960\n",
            "loss 0.5190941095352173 average time 0.002772931284682866 iter num 980\n",
            "loss 0.17747996747493744 average time 0.002772010768991095 iter num 1000\n",
            "loss 0.10726694017648697 average time 0.003585751800073922 iter num 20\n",
            "loss 2.590217113494873 average time 0.003388038325101661 iter num 40\n",
            "loss 5.996766567230225 average time 0.0031779559000521354 iter num 60\n",
            "loss 1.3014343976974487 average time 0.0030628313999613967 iter num 80\n",
            "loss 2.9683988094329834 average time 0.0029970451899862384 iter num 100\n",
            "loss 7.911840915679932 average time 0.0029242778832970846 iter num 120\n",
            "loss 0.17611649632453918 average time 0.002883856999947706 iter num 140\n",
            "loss 1.2157315015792847 average time 0.0028845555187217544 iter num 160\n",
            "loss 9.301145553588867 average time 0.0028981435444115455 iter num 180\n",
            "loss 9.60327434539795 average time 0.0028819941099845893 iter num 200\n",
            "loss 45.03181838989258 average time 0.0029114590318137993 iter num 220\n",
            "loss 11.616654396057129 average time 0.002900660395835075 iter num 240\n",
            "loss 0.1810179501771927 average time 0.002862831042295091 iter num 260\n",
            "loss 0.6605669856071472 average time 0.0028572141142701314 iter num 280\n",
            "loss 16.598201751708984 average time 0.0028470270266613322 iter num 300\n",
            "loss 9.303309440612793 average time 0.0028163830406242596 iter num 320\n",
            "loss 13.535384178161621 average time 0.0028098838647030574 iter num 340\n",
            "loss 0.8217039704322815 average time 0.0028075128111191183 iter num 360\n",
            "loss 0.370789498090744 average time 0.0027865259868504882 iter num 380\n",
            "loss 0.4995749890804291 average time 0.0027643927700091806 iter num 400\n",
            "loss 1.0093908309936523 average time 0.0027553224214205414 iter num 420\n",
            "loss 0.1316581815481186 average time 0.0027436800068037634 iter num 440\n",
            "loss 0.0458109974861145 average time 0.0027295722065030967 iter num 460\n",
            "loss 3.3632030487060547 average time 0.0027509198937271623 iter num 480\n",
            "loss 0.057134829461574554 average time 0.002755720055985876 iter num 500\n",
            "loss 52.35759735107422 average time 0.0027542256403788857 iter num 520\n",
            "loss 2.6643080711364746 average time 0.002753611977772784 iter num 540\n",
            "loss 0.2538575232028961 average time 0.002748092317847295 iter num 560\n",
            "loss 0.14544349908828735 average time 0.002761859999981394 iter num 580\n",
            "loss 1.6364834308624268 average time 0.002764746821640074 iter num 600\n",
            "loss 0.011619750410318375 average time 0.0027579328935350912 iter num 620\n",
            "loss 6.618945121765137 average time 0.0027546949984241565 iter num 640\n",
            "loss 0.4183367192745209 average time 0.0027501879166596734 iter num 660\n",
            "loss 30.17745018005371 average time 0.0027507931558749775 iter num 680\n",
            "loss 0.07065800577402115 average time 0.002751849487137536 iter num 700\n",
            "loss 0.2350258231163025 average time 0.002754137544441922 iter num 720\n",
            "loss 1.3233985900878906 average time 0.002753811450008003 iter num 740\n",
            "loss 2.760781764984131 average time 0.0027498088658112945 iter num 760\n",
            "loss 0.5337183475494385 average time 0.002746212196176109 iter num 780\n",
            "loss 559.057373046875 average time 0.002744241203765796 iter num 800\n",
            "loss 0.3453485667705536 average time 0.002744588200017106 iter num 820\n",
            "loss 67.33733367919922 average time 0.0027413154119195885 iter num 840\n",
            "loss 0.05477439612150192 average time 0.002751180710488687 iter num 860\n",
            "loss 45.74436569213867 average time 0.0027505391147955873 iter num 880\n",
            "loss 0.8595448136329651 average time 0.002755885634465408 iter num 900\n",
            "loss 1.5351229906082153 average time 0.0027544719163297092 iter num 920\n",
            "loss 0.028342297300696373 average time 0.0027664633234285537 iter num 940\n",
            "loss 141.1481170654297 average time 0.0027674270041927683 iter num 960\n",
            "loss 2.150546073913574 average time 0.0027640516214497827 iter num 980\n",
            "loss 31.97435188293457 average time 0.002774263168021207 iter num 1000\n",
            "loss 0.7296875715255737 average time 0.0036047384499397596 iter num 20\n",
            "loss 0.012664275243878365 average time 0.0031864877248608536 iter num 40\n",
            "loss 2.038207530975342 average time 0.0030737738497919054 iter num 60\n",
            "loss 7.821016311645508 average time 0.0029629153247924477 iter num 80\n",
            "loss 2.5104939937591553 average time 0.0029103708597904188 iter num 100\n",
            "loss 10.78589916229248 average time 0.0028648119748443906 iter num 120\n",
            "loss 1.559606909751892 average time 0.0028440247498760333 iter num 140\n",
            "loss 0.059056125581264496 average time 0.0028364935874037656 iter num 160\n",
            "loss 29.81433868408203 average time 0.0028229570888066114 iter num 180\n",
            "loss 40.02788543701172 average time 0.0027929034799126385 iter num 200\n",
            "loss 9.735511779785156 average time 0.0027771532635432034 iter num 220\n",
            "loss 1.4627410173416138 average time 0.0027662677874256284 iter num 240\n",
            "loss 13.575777053833008 average time 0.002786740811454645 iter num 260\n",
            "loss 71.20376586914062 average time 0.002777196792794712 iter num 280\n",
            "loss 0.020334742963314056 average time 0.0027706945499752084 iter num 300\n",
            "loss 5.596290588378906 average time 0.0027760652343545187 iter num 320\n",
            "loss 7.254924297332764 average time 0.0027722247470431767 iter num 340\n",
            "loss 1.5962053537368774 average time 0.0027791263221944164 iter num 360\n",
            "loss 0.45952653884887695 average time 0.0027709043052326658 iter num 380\n",
            "loss 1.113677740097046 average time 0.0027569901899869363 iter num 400\n",
            "loss 10.412872314453125 average time 0.00275075823093998 iter num 420\n",
            "loss 0.15639927983283997 average time 0.0027482785158926245 iter num 440\n",
            "loss 0.634553849697113 average time 0.0027773736804113506 iter num 460\n",
            "loss 0.26309025287628174 average time 0.002784566362474076 iter num 480\n",
            "loss 47.6170768737793 average time 0.0027739922839718927 iter num 500\n",
            "loss 2.4950318336486816 average time 0.0027721238865069608 iter num 520\n",
            "loss 0.02812834642827511 average time 0.002778544229598386 iter num 540\n",
            "loss 5.621581554412842 average time 0.0027752412838838478 iter num 560\n",
            "loss 5.425211429595947 average time 0.0027725193292726233 iter num 580\n",
            "loss 13.893012046813965 average time 0.002771519718295773 iter num 600\n",
            "loss 24.336959838867188 average time 0.002767427809642193 iter num 620\n",
            "loss 47.753318786621094 average time 0.0027643084359056046 iter num 640\n",
            "loss 0.2090170681476593 average time 0.002763808442388395 iter num 660\n",
            "loss 0.018861593678593636 average time 0.002763615836722559 iter num 680\n",
            "loss 26.302783966064453 average time 0.002760657247100815 iter num 700\n",
            "loss 1.4555065631866455 average time 0.002759015611069218 iter num 720\n",
            "loss 0.20174264907836914 average time 0.0027674058607772166 iter num 740\n",
            "loss 1.3128628730773926 average time 0.002767633334183541 iter num 760\n",
            "loss 10.255464553833008 average time 0.0027728308345920083 iter num 780\n",
            "loss 3.7062389850616455 average time 0.002773967052480657 iter num 800\n",
            "loss 15.681109428405762 average time 0.0027747962719287186 iter num 820\n",
            "loss 1.1209882497787476 average time 0.0027806199356897802 iter num 840\n",
            "loss 0.02725914493203163 average time 0.002781308088355598 iter num 860\n",
            "loss 1.3831075429916382 average time 0.0027848579488487634 iter num 880\n",
            "loss 8.348326683044434 average time 0.002789953582212345 iter num 900\n",
            "loss 69.83311462402344 average time 0.0027861292597702665 iter num 920\n",
            "loss 2.8642354011535645 average time 0.0027793650553034474 iter num 940\n",
            "loss 0.3001914918422699 average time 0.002778531898942068 iter num 960\n",
            "loss 0.02412688173353672 average time 0.0027771026387644992 iter num 980\n",
            "loss 78.19409942626953 average time 0.0027838978749878153 iter num 1000\n",
            "loss 44.83951950073242 average time 0.003496881600040069 iter num 20\n",
            "loss 0.3660024404525757 average time 0.0030768489250476705 iter num 40\n",
            "loss 10.013198852539062 average time 0.002940133800075273 iter num 60\n",
            "loss 3.323878288269043 average time 0.0028857602375410353 iter num 80\n",
            "loss 3.91939377784729 average time 0.002843054340028175 iter num 100\n",
            "loss 63.646484375 average time 0.0028983450166682207 iter num 120\n",
            "loss 0.06578846275806427 average time 0.0029010436500227243 iter num 140\n",
            "loss 18.667869567871094 average time 0.0028647885000509634 iter num 160\n",
            "loss 162.97598266601562 average time 0.0028414064778088588 iter num 180\n",
            "loss 12.988734245300293 average time 0.0028196804800245446 iter num 200\n",
            "loss 0.01807374693453312 average time 0.002865858904550061 iter num 220\n",
            "loss 21.222501754760742 average time 0.0028494768874907095 iter num 240\n",
            "loss 5.143692493438721 average time 0.0028428199692475922 iter num 260\n",
            "loss 656.1507568359375 average time 0.002842732675026127 iter num 280\n",
            "loss 0.1833590269088745 average time 0.0028295311033495335 iter num 300\n",
            "loss 5.272305965423584 average time 0.00281498124064683 iter num 320\n",
            "loss 87.5988998413086 average time 0.002809200188264239 iter num 340\n",
            "loss 15.411818504333496 average time 0.0028022920083609886 iter num 360\n",
            "loss 0.5092732310295105 average time 0.0028328819000164097 iter num 380\n",
            "loss 1.032610297203064 average time 0.0028276704775089456 iter num 400\n",
            "loss 0.32980164885520935 average time 0.002843893930968902 iter num 420\n",
            "loss 31.13182258605957 average time 0.0028371143091052626 iter num 440\n",
            "loss 0.9720757603645325 average time 0.0028291906673985068 iter num 460\n",
            "loss 0.011629330925643444 average time 0.002821807425023811 iter num 480\n",
            "loss 0.5806465148925781 average time 0.0028045564320345875 iter num 500\n",
            "loss 0.0034155487082898617 average time 0.0027973258904169665 iter num 520\n",
            "loss 64.06459045410156 average time 0.002793527114839957 iter num 540\n",
            "loss 0.12734712660312653 average time 0.002787138878605739 iter num 560\n",
            "loss 12.518389701843262 average time 0.002781553358658255 iter num 580\n",
            "loss 132.343017578125 average time 0.002782550078360752 iter num 600\n",
            "loss 2.270972728729248 average time 0.0027775029790591947 iter num 620\n",
            "loss 1.0213708877563477 average time 0.002775782439087493 iter num 640\n",
            "loss 0.6991680264472961 average time 0.002774075187908514 iter num 660\n",
            "loss 11.179835319519043 average time 0.0027830474397326135 iter num 680\n",
            "loss 15.959498405456543 average time 0.002776021948596151 iter num 700\n",
            "loss 109.16767883300781 average time 0.002770182988908548 iter num 720\n",
            "loss 0.04830484464764595 average time 0.0027681453405543955 iter num 740\n",
            "loss 0.5735630989074707 average time 0.0027653244855436673 iter num 760\n",
            "loss 0.2514299750328064 average time 0.0027635010961673217 iter num 780\n",
            "loss 0.44740840792655945 average time 0.002760949098758374 iter num 800\n",
            "loss 1.0524250268936157 average time 0.002763397935375063 iter num 820\n",
            "loss 3.3118433952331543 average time 0.0027682388392934495 iter num 840\n",
            "loss 0.22792698442935944 average time 0.002758307750012369 iter num 860\n",
            "loss 0.23281943798065186 average time 0.0027514724295563363 iter num 880\n",
            "loss 2.6141788959503174 average time 0.00275390344778417 iter num 900\n",
            "loss 0.7919732928276062 average time 0.002749611866313543 iter num 920\n",
            "loss 0.4785808026790619 average time 0.0027433809766041527 iter num 940\n",
            "loss 0.0653313472867012 average time 0.0027397938177197525 iter num 960\n",
            "loss 0.023854635655879974 average time 0.002736990725522019 iter num 980\n",
            "loss 0.7371753454208374 average time 0.0027440406840050853 iter num 1000\n",
            "loss 7.239807605743408 average time 0.0033637080500739103 iter num 20\n",
            "loss 25.851512908935547 average time 0.0030306327001198953 iter num 40\n",
            "loss 0.016096580773591995 average time 0.002828991083454942 iter num 60\n",
            "loss 13.543356895446777 average time 0.002820034875071542 iter num 80\n",
            "loss 0.11463607847690582 average time 0.00278036397006872 iter num 100\n",
            "loss 1.6384164094924927 average time 0.0027606266083542628 iter num 120\n",
            "loss 7.787341117858887 average time 0.002756839592893812 iter num 140\n",
            "loss 41.49839782714844 average time 0.002783158350052872 iter num 160\n",
            "loss 1.0330864191055298 average time 0.0027721319500516174 iter num 180\n",
            "loss 3.324796438217163 average time 0.0027694519150281848 iter num 200\n",
            "loss 15.695070266723633 average time 0.0027534003181988904 iter num 220\n",
            "loss 500.7027587890625 average time 0.0027375474833585636 iter num 240\n",
            "loss 155.2555694580078 average time 0.0027064304307924223 iter num 260\n",
            "loss 0.6568007469177246 average time 0.002709596917910468 iter num 280\n",
            "loss 3.9592337608337402 average time 0.00268756233338839 iter num 300\n",
            "loss 6.323896884918213 average time 0.002682754703181445 iter num 320\n",
            "loss 0.27268847823143005 average time 0.002686268223592111 iter num 340\n",
            "loss 0.3908750116825104 average time 0.00268992487228085 iter num 360\n",
            "loss 0.002732844091951847 average time 0.002699278571114854 iter num 380\n",
            "loss 0.6756848096847534 average time 0.0026978662725741743 iter num 400\n",
            "loss 0.40499311685562134 average time 0.0026956194072097006 iter num 420\n",
            "loss 23.730974197387695 average time 0.0026973117659632737 iter num 440\n",
            "loss 0.08448255807161331 average time 0.0027054440348405003 iter num 460\n",
            "loss 44.272151947021484 average time 0.0027047162729862367 iter num 480\n",
            "loss 2.730605363845825 average time 0.0027033321660674117 iter num 500\n",
            "loss 0.012905342504382133 average time 0.002703572355833855 iter num 520\n",
            "loss 0.11961089819669724 average time 0.002698500061173777 iter num 540\n",
            "loss 0.26321646571159363 average time 0.0026930382125621172 iter num 560\n",
            "loss 1.6405459642410278 average time 0.0026917066017819614 iter num 580\n",
            "loss 0.22947677969932556 average time 0.00269142510005319 iter num 600\n",
            "loss 2.66049861907959 average time 0.002705726067796927 iter num 620\n",
            "loss 0.007270879112184048 average time 0.002705103131305009 iter num 640\n",
            "loss 0.06721287220716476 average time 0.0026935344212578264 iter num 660\n",
            "loss 0.19514605402946472 average time 0.00269598040151376 iter num 680\n",
            "loss 1.4871326684951782 average time 0.002693135890045336 iter num 700\n",
            "loss 1.5291486978530884 average time 0.0026893642333789105 iter num 720\n",
            "loss 1.7500866651535034 average time 0.002689163059501978 iter num 740\n",
            "loss 0.8659936189651489 average time 0.0026902961118809654 iter num 760\n",
            "loss 0.010652446188032627 average time 0.002687168575681799 iter num 780\n",
            "loss 0.18007679283618927 average time 0.0026895057662886758 iter num 800\n",
            "loss 0.4137505292892456 average time 0.0026873151000383986 iter num 820\n",
            "loss 1.8877936601638794 average time 0.0026971698119420276 iter num 840\n",
            "loss 0.6337397694587708 average time 0.0026970565349159208 iter num 860\n",
            "loss 0.06312622874975204 average time 0.002696708367071468 iter num 880\n",
            "loss 1.396504521369934 average time 0.0026913621355823935 iter num 900\n",
            "loss 1.013042688369751 average time 0.002697645472851392 iter num 920\n",
            "loss 0.0030206292867660522 average time 0.0026948393489545468 iter num 940\n",
            "loss 6.817859172821045 average time 0.002695690062525576 iter num 960\n",
            "loss 0.22043012082576752 average time 0.0026945470694100756 iter num 980\n",
            "loss 57.64279556274414 average time 0.002691420082024706 iter num 1000\n",
            "loss 7.78218412399292 average time 0.0033105741499639407 iter num 20\n",
            "loss 13.76278018951416 average time 0.003078117325094354 iter num 40\n",
            "loss 2.24981689453125 average time 0.0031010750333128573 iter num 60\n",
            "loss 8.398308753967285 average time 0.003011345687514222 iter num 80\n",
            "loss 0.025153912603855133 average time 0.002967056460020103 iter num 100\n",
            "loss 1.0650620460510254 average time 0.0029241325916700587 iter num 120\n",
            "loss 2.5501718521118164 average time 0.002902164121431789 iter num 140\n",
            "loss 0.062286559492349625 average time 0.0028793360062536522 iter num 160\n",
            "loss 0.004848822019994259 average time 0.0028136944611307827 iter num 180\n",
            "loss 12.965263366699219 average time 0.0028450394850005976 iter num 200\n",
            "loss 5.044796943664551 average time 0.0028146425636061227 iter num 220\n",
            "loss 0.16636206209659576 average time 0.0028065850416472433 iter num 240\n",
            "loss 10.058032035827637 average time 0.0027723673230446787 iter num 260\n",
            "loss 2.208354949951172 average time 0.0027619886749627245 iter num 280\n",
            "loss 0.03379075974225998 average time 0.0027657042199462013 iter num 300\n",
            "loss 1.586178183555603 average time 0.002755179903078897 iter num 320\n",
            "loss 1.7736772298812866 average time 0.0027527865470106275 iter num 340\n",
            "loss 1.9059088230133057 average time 0.0027475819971742666 iter num 360\n",
            "loss 0.02163461409509182 average time 0.002749256505218287 iter num 380\n",
            "loss 6.469057083129883 average time 0.0027512945924536326 iter num 400\n",
            "loss 0.9096547961235046 average time 0.002750616328527637 iter num 420\n",
            "loss 2.739021062850952 average time 0.00274023192268115 iter num 440\n",
            "loss 0.000436840346083045 average time 0.0027359322042961455 iter num 460\n",
            "loss 1.2486534118652344 average time 0.0027339070770305324 iter num 480\n",
            "loss 0.7101384997367859 average time 0.0027266053799539806 iter num 500\n",
            "loss 101.22903442382812 average time 0.002727217061489612 iter num 520\n",
            "loss 30.634069442749023 average time 0.0027275111295845516 iter num 540\n",
            "loss 19.024377822875977 average time 0.002725247755318248 iter num 560\n",
            "loss 2.139435052871704 average time 0.002728079567212513 iter num 580\n",
            "loss 3.2190611362457275 average time 0.0027285975399809104 iter num 600\n",
            "loss 0.6730002164840698 average time 0.0027291422161133303 iter num 620\n",
            "loss 0.6091955900192261 average time 0.002728836557795944 iter num 640\n",
            "loss 0.9738075733184814 average time 0.0027359063545218582 iter num 660\n",
            "loss 0.013481182046234608 average time 0.0027346162985101246 iter num 680\n",
            "loss 0.3602997064590454 average time 0.002746975225698926 iter num 700\n",
            "loss 13.137527465820312 average time 0.0027465391166566003 iter num 720\n",
            "loss 12.005703926086426 average time 0.0027476208999900878 iter num 740\n",
            "loss 10.059992790222168 average time 0.002744335653936727 iter num 760\n",
            "loss 51.76791000366211 average time 0.0027355888781876742 iter num 780\n",
            "loss 15.325021743774414 average time 0.0027395332199785117 iter num 800\n",
            "loss 15.623879432678223 average time 0.0027387898402239223 iter num 820\n",
            "loss 0.665403425693512 average time 0.0027386013702176745 iter num 840\n",
            "loss 78.57087707519531 average time 0.0027436032104433674 iter num 860\n",
            "loss 68.9888687133789 average time 0.002737843532934841 iter num 880\n",
            "loss 0.1054154559969902 average time 0.0027382376677572515 iter num 900\n",
            "loss 0.0604669451713562 average time 0.00272972428150277 iter num 920\n",
            "loss 0.05813252180814743 average time 0.0027212179435953153 iter num 940\n",
            "loss 16.871337890625 average time 0.002714673813521055 iter num 960\n",
            "loss 90.81694793701172 average time 0.0027147798856944697 iter num 980\n",
            "loss 302.65625 average time 0.00270895115498206 iter num 1000\n",
            "loss 17.19390296936035 average time 0.002986580399738159 iter num 20\n",
            "loss 0.5231002569198608 average time 0.0028820517999065486 iter num 40\n",
            "loss 2.9044041633605957 average time 0.002816446066572098 iter num 60\n",
            "loss 0.09038438647985458 average time 0.002790132212408025 iter num 80\n",
            "loss 0.23230411112308502 average time 0.0027689446899239554 iter num 100\n",
            "loss 0.007099102716892958 average time 0.0027701693749349944 iter num 120\n",
            "loss 4.613194465637207 average time 0.0027877346570936165 iter num 140\n",
            "loss 0.012792916037142277 average time 0.002770730693691803 iter num 160\n",
            "loss 2.76570725440979 average time 0.002750715361071343 iter num 180\n",
            "loss 2.444530487060547 average time 0.0027357462999589187 iter num 200\n",
            "loss 4.2705078125 average time 0.002733596936294899 iter num 220\n",
            "loss 60.452903747558594 average time 0.002730062204113892 iter num 240\n",
            "loss 62.584754943847656 average time 0.002714050623014303 iter num 260\n",
            "loss 0.00968494638800621 average time 0.0027054008892199426 iter num 280\n",
            "loss 178.81288146972656 average time 0.0027043019399328235 iter num 300\n",
            "loss 13.966933250427246 average time 0.0027098718124477727 iter num 320\n",
            "loss 19.965158462524414 average time 0.0026892312146628685 iter num 340\n",
            "loss 0.540497899055481 average time 0.002692108311061424 iter num 360\n",
            "loss 3.49601149559021 average time 0.002696083110478005 iter num 380\n",
            "loss 0.02362026274204254 average time 0.0027007735524557574 iter num 400\n",
            "loss 0.0017277831211686134 average time 0.0026939874309001815 iter num 420\n",
            "loss 1.2431681156158447 average time 0.0026903467885982866 iter num 440\n",
            "loss 0.012486917898058891 average time 0.0026949559738687124 iter num 460\n",
            "loss 4.139594554901123 average time 0.0027011853582848745 iter num 480\n",
            "loss 8.58745002746582 average time 0.0027115616299633986 iter num 500\n",
            "loss 5.047267913818359 average time 0.002711851501883827 iter num 520\n",
            "loss 1.6013383865356445 average time 0.002712491857366533 iter num 540\n",
            "loss 10.09426212310791 average time 0.002725174496397033 iter num 560\n",
            "loss 53.7041015625 average time 0.0027187643154885054 iter num 580\n",
            "loss 0.30744341015815735 average time 0.0027173633516334424 iter num 600\n",
            "loss 28.400625228881836 average time 0.002711577148364731 iter num 620\n",
            "loss 0.27408266067504883 average time 0.0027066264359120852 iter num 640\n",
            "loss 29.484695434570312 average time 0.0027047536681658875 iter num 660\n",
            "loss 0.4123724400997162 average time 0.002704508151461649 iter num 680\n",
            "loss 78.2096176147461 average time 0.002711615128558021 iter num 700\n",
            "loss 15.502584457397461 average time 0.002713781169429947 iter num 720\n",
            "loss 2.08121657371521 average time 0.0027217636337711058 iter num 740\n",
            "loss 11.512873649597168 average time 0.002719277317086572 iter num 760\n",
            "loss 0.0017444177065044641 average time 0.0027168296179344254 iter num 780\n",
            "loss 36.288692474365234 average time 0.002714593244993466 iter num 800\n",
            "loss 0.0017985652666538954 average time 0.002712039054874434 iter num 820\n",
            "loss 0.7331457734107971 average time 0.0027142772630971497 iter num 840\n",
            "loss 15.94118595123291 average time 0.0027174262790711423 iter num 860\n",
            "loss 0.27243155241012573 average time 0.0027272233534135506 iter num 880\n",
            "loss 13.015016555786133 average time 0.0027267590933378314 iter num 900\n",
            "loss 0.1105387955904007 average time 0.002724389166310768 iter num 920\n",
            "loss 0.8977627754211426 average time 0.002724318434053551 iter num 940\n",
            "loss 0.8668031692504883 average time 0.0027253799093898577 iter num 960\n",
            "loss 9.177287101745605 average time 0.002728508520423781 iter num 980\n",
            "loss 1.6451616287231445 average time 0.0027296058580141107 iter num 1000\n",
            "loss 1.0893614292144775 average time 0.003470734450002055 iter num 20\n",
            "loss 13.257261276245117 average time 0.0030544619750344283 iter num 40\n",
            "loss 0.32866784930229187 average time 0.002983436883308362 iter num 60\n",
            "loss 5.584228515625 average time 0.0029252085999587505 iter num 80\n",
            "loss 23.872936248779297 average time 0.002879108809884201 iter num 100\n",
            "loss 0.30484092235565186 average time 0.002866150074896723 iter num 120\n",
            "loss 0.2753274142742157 average time 0.0028644214427523754 iter num 140\n",
            "loss 3.5462117195129395 average time 0.0028612629123927038 iter num 160\n",
            "loss 118.2624740600586 average time 0.002895292316558577 iter num 180\n",
            "loss 1.6134713888168335 average time 0.0029178201548984363 iter num 200\n",
            "loss 0.35929813981056213 average time 0.002940668849913147 iter num 220\n",
            "loss 4.803264617919922 average time 0.0029114715499190423 iter num 240\n",
            "loss 3.3458497524261475 average time 0.0028955564037670017 iter num 260\n",
            "loss 2.0027036666870117 average time 0.002900315078503419 iter num 280\n",
            "loss 12.101716041564941 average time 0.0028864014899409084 iter num 300\n",
            "loss 4.928769588470459 average time 0.0028687991405718094 iter num 320\n",
            "loss 0.07738663256168365 average time 0.0028602379146564893 iter num 340\n",
            "loss 0.257984459400177 average time 0.002853874044391584 iter num 360\n",
            "loss 50.35614776611328 average time 0.002848600078883273 iter num 380\n",
            "loss 22.2063045501709 average time 0.0028435110974305644 iter num 400\n",
            "loss 11.069815635681152 average time 0.0028277504832745068 iter num 420\n",
            "loss 1.6046854257583618 average time 0.0028402926931200704 iter num 440\n",
            "loss 18.816898345947266 average time 0.0028361234108160716 iter num 460\n",
            "loss 3.5375027656555176 average time 0.002826462816616034 iter num 480\n",
            "loss 0.07903385162353516 average time 0.0028197634239404577 iter num 500\n",
            "loss 0.04879409819841385 average time 0.002814250080704229 iter num 520\n",
            "loss 0.3366278409957886 average time 0.0028107269017911877 iter num 540\n",
            "loss 0.3289121389389038 average time 0.0028007875874339204 iter num 560\n",
            "loss 0.4185933768749237 average time 0.00279609472924582 iter num 580\n",
            "loss 15.86694622039795 average time 0.0028057481582709444 iter num 600\n",
            "loss 0.07046898454427719 average time 0.0028054434338041427 iter num 620\n",
            "loss 1.044856071472168 average time 0.0027999082436849674 iter num 640\n",
            "loss 0.08565419912338257 average time 0.002796003471146171 iter num 660\n",
            "loss 0.01760667935013771 average time 0.0027899320793414303 iter num 680\n",
            "loss 0.3379615545272827 average time 0.0027884082442246184 iter num 700\n",
            "loss 0.34206879138946533 average time 0.002793815120776344 iter num 720\n",
            "loss 0.08234419673681259 average time 0.0027961874404895384 iter num 740\n",
            "loss 24.363689422607422 average time 0.002818088351262448 iter num 760\n",
            "loss 23.66234016418457 average time 0.0028153723460980894 iter num 780\n",
            "loss 2.602085590362549 average time 0.002812385574943619 iter num 800\n",
            "loss 3.2081878185272217 average time 0.00281300364262412 iter num 820\n",
            "loss 5.534784577321261e-05 average time 0.0028122373547072735 iter num 840\n",
            "loss 0.8931686282157898 average time 0.0028187782987896394 iter num 860\n",
            "loss 1.860824704170227 average time 0.002814893599956618 iter num 880\n",
            "loss 25.515939712524414 average time 0.002813437154406226 iter num 900\n",
            "loss 0.029951557517051697 average time 0.002818144966271496 iter num 920\n",
            "loss 3.307762861251831 average time 0.0028158478616747513 iter num 940\n",
            "loss 0.02169414795935154 average time 0.002812608974975698 iter num 960\n",
            "loss 2.6258676052093506 average time 0.0028094799030404087 iter num 980\n",
            "loss 0.05714224651455879 average time 0.0028086594689793855 iter num 1000\n",
            "loss 0.019717196002602577 average time 0.0033553398498952446 iter num 20\n",
            "loss 0.051351312547922134 average time 0.00302041035001821 iter num 40\n",
            "loss 13.130006790161133 average time 0.0029440841666049287 iter num 60\n",
            "loss 113.667236328125 average time 0.0030383617499865068 iter num 80\n",
            "loss 4.527874946594238 average time 0.002990201539996633 iter num 100\n",
            "loss 0.003317116992548108 average time 0.002938290849988334 iter num 120\n",
            "loss 0.11445640027523041 average time 0.002920108557113313 iter num 140\n",
            "loss 133.38917541503906 average time 0.002913802018736078 iter num 160\n",
            "loss 2.3317534923553467 average time 0.00289038660002916 iter num 180\n",
            "loss 0.16409353911876678 average time 0.00287162570003602 iter num 200\n",
            "loss 9.678154945373535 average time 0.002857670413678451 iter num 220\n",
            "loss 11.630830764770508 average time 0.002849870866702986 iter num 240\n",
            "loss 1.1479995250701904 average time 0.0028369177192941538 iter num 260\n",
            "loss 36.133975982666016 average time 0.0028283598500560662 iter num 280\n",
            "loss 0.6043107509613037 average time 0.0028085115033779097 iter num 300\n",
            "loss 1.4147652387619019 average time 0.0028063146594263346 iter num 320\n",
            "loss 0.006301190238445997 average time 0.0027991106618173943 iter num 340\n",
            "loss 1.0482145547866821 average time 0.0028269624472664467 iter num 360\n",
            "loss 0.3515961766242981 average time 0.0028289569632043393 iter num 380\n",
            "loss 0.9761268496513367 average time 0.0028260790550530147 iter num 400\n",
            "loss 2.315471887588501 average time 0.0028249184429071086 iter num 420\n",
            "loss 0.05505598708987236 average time 0.0028261416841360186 iter num 440\n",
            "loss 0.5969611406326294 average time 0.002840887356567533 iter num 460\n",
            "loss 135.82672119140625 average time 0.002835230322962919 iter num 480\n",
            "loss 0.9886534810066223 average time 0.0028392155520377857 iter num 500\n",
            "loss 0.24139313399791718 average time 0.0028459231442586595 iter num 520\n",
            "loss 6.792582988739014 average time 0.002840408644472821 iter num 540\n",
            "loss 3.756182909011841 average time 0.0028254794536029036 iter num 560\n",
            "loss 3.1024173949845135e-05 average time 0.002813355351755208 iter num 580\n",
            "loss 0.1916746199131012 average time 0.002825558461703016 iter num 600\n",
            "loss 0.5722233653068542 average time 0.002829523177452727 iter num 620\n",
            "loss 0.5642884969711304 average time 0.0028204788969048876 iter num 640\n",
            "loss 27.648683547973633 average time 0.002827300230331854 iter num 660\n",
            "loss 18.04363441467285 average time 0.0028284805132577327 iter num 680\n",
            "loss 5.340230941772461 average time 0.00281389476287846 iter num 700\n",
            "loss 21.46659278869629 average time 0.002798587233355142 iter num 720\n",
            "loss 3.0264511108398438 average time 0.002792138455434552 iter num 740\n",
            "loss 0.1045471727848053 average time 0.00279410166581568 iter num 760\n",
            "loss 21.820999145507812 average time 0.002792550069261779 iter num 780\n",
            "loss 3.427506685256958 average time 0.0028020975325307516 iter num 800\n",
            "loss 1.1459200382232666 average time 0.002801345759783034 iter num 820\n",
            "loss 0.06910724192857742 average time 0.0027983754524094754 iter num 840\n",
            "loss 0.16730628907680511 average time 0.002785803653514026 iter num 860\n",
            "loss 0.10618910193443298 average time 0.0027770513284291485 iter num 880\n",
            "loss 38.45585632324219 average time 0.002777623163347016 iter num 900\n",
            "loss 0.8790560960769653 average time 0.0027780848913192564 iter num 920\n",
            "loss 39.45122528076172 average time 0.0027771214851220957 iter num 940\n",
            "loss 28.286731719970703 average time 0.0027871753385644146 iter num 960\n",
            "loss 0.024745387956500053 average time 0.0027871689255353346 iter num 980\n",
            "loss 1.8814884424209595 average time 0.0027843572740221135 iter num 1000\n",
            "loss 81.07760620117188 average time 0.00322837410012653 iter num 20\n",
            "loss 0.06158667802810669 average time 0.0028316663499026616 iter num 40\n",
            "loss 0.14101579785346985 average time 0.0026548807665676575 iter num 60\n",
            "loss 5.900240898132324 average time 0.0026601541124364305 iter num 80\n",
            "loss 2.017435073852539 average time 0.002582066759969166 iter num 100\n",
            "loss 0.5559919476509094 average time 0.0026902040166229806 iter num 120\n",
            "loss 50.58354949951172 average time 0.0027083485070761525 iter num 140\n",
            "loss 0.5682883858680725 average time 0.0026777614749562417 iter num 160\n",
            "loss 0.00474105030298233 average time 0.002669669788863555 iter num 180\n",
            "loss 120.37457275390625 average time 0.0026914703349757473 iter num 200\n",
            "loss 33.73435592651367 average time 0.002706864472706498 iter num 220\n",
            "loss 0.009225579909980297 average time 0.002677681470807632 iter num 240\n",
            "loss 13.55616283416748 average time 0.002672722076903693 iter num 260\n",
            "loss 5.423932075500488 average time 0.0026654282714129555 iter num 280\n",
            "loss 1.2585523128509521 average time 0.002668341883315103 iter num 300\n",
            "loss 3.008744716644287 average time 0.0026488598156163335 iter num 320\n",
            "loss 11.169748306274414 average time 0.0026442262529385247 iter num 340\n",
            "loss 0.440290242433548 average time 0.0026445899166750073 iter num 360\n",
            "loss 13.757187843322754 average time 0.0026347517736930487 iter num 380\n",
            "loss 0.005840281955897808 average time 0.0026200455900197996 iter num 400\n",
            "loss 1.4064757823944092 average time 0.0026149450666924255 iter num 420\n",
            "loss 0.9659467935562134 average time 0.002628632890946392 iter num 440\n",
            "loss 0.6585410833358765 average time 0.0026223986696174467 iter num 460\n",
            "loss 0.07346576452255249 average time 0.0026209798292181103 iter num 480\n",
            "loss 4.517148971557617 average time 0.002610893178054539 iter num 500\n",
            "loss 0.31112414598464966 average time 0.002613224213522559 iter num 520\n",
            "loss 0.03092050924897194 average time 0.002614368350060869 iter num 540\n",
            "loss 4.139221668243408 average time 0.002604446423284961 iter num 560\n",
            "loss 0.006198054179549217 average time 0.0026077873448888695 iter num 580\n",
            "loss 87.21330261230469 average time 0.002601983665063017 iter num 600\n",
            "loss 0.3254617750644684 average time 0.002604518650065485 iter num 620\n",
            "loss 0.014387844130396843 average time 0.0026057129563128003 iter num 640\n",
            "loss 0.005106362514197826 average time 0.002605674478849268 iter num 660\n",
            "loss 9.96704387664795 average time 0.0026023789765264047 iter num 680\n",
            "loss 0.04668714478611946 average time 0.00260496006005269 iter num 700\n",
            "loss 0.020222600549459457 average time 0.002606975093105272 iter num 720\n",
            "loss 0.09970457851886749 average time 0.0026113655270794856 iter num 740\n",
            "loss 2.621814012527466 average time 0.0026233065197821385 iter num 760\n",
            "loss 7.647415637969971 average time 0.0026206708141520113 iter num 780\n",
            "loss 0.21289263665676117 average time 0.002620123676304047 iter num 800\n",
            "loss 0.00024557323195040226 average time 0.002618965643958335 iter num 820\n",
            "loss 36.228511810302734 average time 0.0026347213440983197 iter num 840\n",
            "loss 8.704395294189453 average time 0.002634057438421604 iter num 860\n",
            "loss 5.558427333831787 average time 0.002636073429591141 iter num 880\n",
            "loss 28.318187713623047 average time 0.002637642507822117 iter num 900\n",
            "loss 23.52788734436035 average time 0.002640207694617936 iter num 920\n",
            "loss 0.18884555995464325 average time 0.0026393194287749715 iter num 940\n",
            "loss 0.12882158160209656 average time 0.0026334853521329175 iter num 960\n",
            "loss 1.2765662670135498 average time 0.0026329415327029206 iter num 980\n",
            "loss 0.10009360313415527 average time 0.002632809106051354 iter num 1000\n",
            "loss 0.4546312391757965 average time 0.003252249750039482 iter num 20\n",
            "loss 1.6561423540115356 average time 0.002884288249970268 iter num 40\n",
            "loss 0.2807381749153137 average time 0.002988446583367477 iter num 60\n",
            "loss 1.9608641862869263 average time 0.0028994838999551577 iter num 80\n",
            "loss 7.360272407531738 average time 0.0028728310899896314 iter num 100\n",
            "loss 0.3170021176338196 average time 0.0028560373833139844 iter num 120\n",
            "loss 1.8160488605499268 average time 0.0028347449213859885 iter num 140\n",
            "loss 0.11469140648841858 average time 0.0028129080374469594 iter num 160\n",
            "loss 4.5106329917907715 average time 0.002804119722158147 iter num 180\n",
            "loss 0.08589328825473785 average time 0.0028397173999383084 iter num 200\n",
            "loss 9.23335075378418 average time 0.0028283706499513013 iter num 220\n",
            "loss 0.010325265116989613 average time 0.002817191808298958 iter num 240\n",
            "loss 5.824751377105713 average time 0.002814223269181709 iter num 260\n",
            "loss 0.0007866657106205821 average time 0.002805087928533924 iter num 280\n",
            "loss 2.4576096534729004 average time 0.0028209840133179872 iter num 300\n",
            "loss 0.20749850571155548 average time 0.002811988603082227 iter num 320\n",
            "loss 21.5289306640625 average time 0.002793247491129424 iter num 340\n",
            "loss 16.50943946838379 average time 0.0027964186055113613 iter num 360\n",
            "loss 400.94171142578125 average time 0.0027874610789024846 iter num 380\n",
            "loss 6.548159122467041 average time 0.0027813390624669408 iter num 400\n",
            "loss 2.783939838409424 average time 0.0027685514594936863 iter num 420\n",
            "loss 0.0023179694544523954 average time 0.0027665549818059595 iter num 440\n",
            "loss 2.7611162662506104 average time 0.002758984386946395 iter num 460\n",
            "loss 35.429752349853516 average time 0.0027452437124907193 iter num 480\n",
            "loss 0.011213154532015324 average time 0.002739415743984864 iter num 500\n",
            "loss 12.891141891479492 average time 0.0027419958096008765 iter num 520\n",
            "loss 5.588398456573486 average time 0.0027431541611029524 iter num 540\n",
            "loss 70.52734375 average time 0.0027393343535647677 iter num 560\n",
            "loss 43.75183868408203 average time 0.0027356288499818062 iter num 580\n",
            "loss 7.040918350219727 average time 0.002721840463312522 iter num 600\n",
            "loss 13.365151405334473 average time 0.002719745406428105 iter num 620\n",
            "loss 6.72698974609375 average time 0.002710913604656184 iter num 640\n",
            "loss 0.37941980361938477 average time 0.0027079072393600212 iter num 660\n",
            "loss 0.023886462673544884 average time 0.002696190974973647 iter num 680\n",
            "loss 22.294836044311523 average time 0.0026943254957015076 iter num 700\n",
            "loss 2.0923383235931396 average time 0.002683554888873611 iter num 720\n",
            "loss 3.5702521800994873 average time 0.002681260036476758 iter num 740\n",
            "loss 2.2903711795806885 average time 0.002671252056574016 iter num 760\n",
            "loss 0.8845586776733398 average time 0.002670218156403373 iter num 780\n",
            "loss 1.9888418912887573 average time 0.002672363036240313 iter num 800\n",
            "loss 1.7230017185211182 average time 0.0026690500292693843 iter num 820\n",
            "loss 1.2790155410766602 average time 0.002663837039281567 iter num 840\n",
            "loss 0.08398109674453735 average time 0.00265401401744638 iter num 860\n",
            "loss 3.687096118927002 average time 0.0026472632875042604 iter num 880\n",
            "loss 0.2519990801811218 average time 0.0026405809277841603 iter num 900\n",
            "loss 0.4372580051422119 average time 0.002644242796741705 iter num 920\n",
            "loss 1.434212327003479 average time 0.002635834213833732 iter num 940\n",
            "loss 1.2920547723770142 average time 0.0026366394614683484 iter num 960\n",
            "loss 13.565715789794922 average time 0.002633272510218153 iter num 980\n",
            "loss 2.255324602127075 average time 0.0026283089020071202 iter num 1000\n",
            "loss 100.93325805664062 average time 0.0029545288002736925 iter num 20\n",
            "loss 27.337614059448242 average time 0.002620602025081098 iter num 40\n",
            "loss 64.83829498291016 average time 0.002656894500069029 iter num 60\n",
            "loss 5.2390289306640625 average time 0.0025985225375052324 iter num 80\n",
            "loss 0.7343711256980896 average time 0.002537289250030881 iter num 100\n",
            "loss 8.661018371582031 average time 0.00256343876670447 iter num 120\n",
            "loss 1.7020825147628784 average time 0.002537545014313634 iter num 140\n",
            "loss 0.026709122583270073 average time 0.0025115078437693227 iter num 160\n",
            "loss 0.5019017457962036 average time 0.0025058550500337636 iter num 180\n",
            "loss 2.634974718093872 average time 0.0024997592550607805 iter num 200\n",
            "loss 7.994615077972412 average time 0.002483704018231947 iter num 220\n",
            "loss 0.19802641868591309 average time 0.0024745056417259546 iter num 240\n",
            "loss 14.018988609313965 average time 0.002457344142364421 iter num 260\n",
            "loss 1.159681797027588 average time 0.0024448382857761835 iter num 280\n",
            "loss 4.151803970336914 average time 0.0024328434867129543 iter num 300\n",
            "loss 0.022045159712433815 average time 0.002419981506290014 iter num 320\n",
            "loss 14.017260551452637 average time 0.0024233731000576344 iter num 340\n",
            "loss 9.144034385681152 average time 0.002444705686164323 iter num 360\n",
            "loss 52.601226806640625 average time 0.0024377214474139023 iter num 380\n",
            "loss 22.087892532348633 average time 0.0024629069875300048 iter num 400\n",
            "loss 7.475137710571289 average time 0.0024572517833716815 iter num 420\n",
            "loss 1.2971470355987549 average time 0.0024511700886912214 iter num 440\n",
            "loss 0.6831955313682556 average time 0.002461388819625901 iter num 460\n",
            "loss 3.51654052734375 average time 0.0024628766188167597 iter num 480\n",
            "loss 8.820165634155273 average time 0.0024707081160559026 iter num 500\n",
            "loss 0.16187545657157898 average time 0.002471709478896418 iter num 520\n",
            "loss 14.52177906036377 average time 0.0024768731519038234 iter num 540\n",
            "loss 2.83992075920105 average time 0.002480992296487524 iter num 560\n",
            "loss 1.9341880083084106 average time 0.0024889466690277413 iter num 580\n",
            "loss 4.223292827606201 average time 0.002498561965051825 iter num 600\n",
            "loss 10.856585502624512 average time 0.002501539048429432 iter num 620\n",
            "loss 1.1417341232299805 average time 0.0025067195437912916 iter num 640\n",
            "loss 1.9103983640670776 average time 0.002506983587919063 iter num 660\n",
            "loss 0.009019434452056885 average time 0.002509028372102929 iter num 680\n",
            "loss 2.746739625930786 average time 0.0025171815543269206 iter num 700\n",
            "loss 44.181739807128906 average time 0.0025235846417015436 iter num 720\n",
            "loss 92.63240051269531 average time 0.0025194498243616033 iter num 740\n",
            "loss 14.562860488891602 average time 0.002540109421086431 iter num 760\n",
            "loss 0.009065323509275913 average time 0.0025439278090184066 iter num 780\n",
            "loss 9.283447265625 average time 0.002546505692541814 iter num 800\n",
            "loss 3.9592792987823486 average time 0.0025499894744337704 iter num 820\n",
            "loss 648.9331665039062 average time 0.0025549613178944648 iter num 840\n",
            "loss 0.03782190755009651 average time 0.0025555694093401505 iter num 860\n",
            "loss 0.09596136212348938 average time 0.0025550336750401665 iter num 880\n",
            "loss 4.157838344573975 average time 0.00255759011448188 iter num 900\n",
            "loss 8.43952751159668 average time 0.0025625323565513416 iter num 920\n",
            "loss 7.838991641998291 average time 0.0025756606244922682 iter num 940\n",
            "loss 0.00038228536141104996 average time 0.00257796437918311 iter num 960\n",
            "loss 1.39511239528656 average time 0.002577855077563109 iter num 980\n",
            "loss 0.008938845247030258 average time 0.002580189716010864 iter num 1000\n",
            "loss 4.896648406982422 average time 0.0031880213001386436 iter num 20\n",
            "loss 6.897195339202881 average time 0.002792350175059255 iter num 40\n",
            "loss 0.6426277160644531 average time 0.00274147163336238 iter num 60\n",
            "loss 9.042848587036133 average time 0.0026900147125616058 iter num 80\n",
            "loss 3.121062994003296 average time 0.0026864571700207307 iter num 100\n",
            "loss 8.346452713012695 average time 0.002672785408337101 iter num 120\n",
            "loss 0.10681065917015076 average time 0.0026900614429125978 iter num 140\n",
            "loss 29.047693252563477 average time 0.0026953376938195104 iter num 160\n",
            "loss 1.6180148124694824 average time 0.0026996333389231746 iter num 180\n",
            "loss 0.5077399611473083 average time 0.0026664033500401274 iter num 200\n",
            "loss 0.33824270963668823 average time 0.0026654538363965747 iter num 220\n",
            "loss 1.5335553884506226 average time 0.0027063620208764407 iter num 240\n",
            "loss 11.286630630493164 average time 0.002715599834657321 iter num 260\n",
            "loss 55.648738861083984 average time 0.002708449546454566 iter num 280\n",
            "loss 518.206298828125 average time 0.0027014294566955264 iter num 300\n",
            "loss 4.3887104988098145 average time 0.0026887855375207436 iter num 320\n",
            "loss 0.5446606874465942 average time 0.0026895718147416656 iter num 340\n",
            "loss 6.560464382171631 average time 0.0026903745833452477 iter num 360\n",
            "loss 0.47529053688049316 average time 0.0026839594447521545 iter num 380\n",
            "loss 10.321293830871582 average time 0.0026886689975208354 iter num 400\n",
            "loss 0.0528348833322525 average time 0.0026857131214455877 iter num 420\n",
            "loss 0.00027358904480934143 average time 0.0026705598704666045 iter num 440\n",
            "loss 2.6786484718322754 average time 0.002655550491323558 iter num 460\n",
            "loss 0.010606775060296059 average time 0.0026520744729244448 iter num 480\n",
            "loss 0.009304733015596867 average time 0.0026483690260065487 iter num 500\n",
            "loss 5.631062030792236 average time 0.002645501542313538 iter num 520\n",
            "loss 28.40599250793457 average time 0.002642707344448017 iter num 540\n",
            "loss 1.1394363641738892 average time 0.0026577599732003623 iter num 560\n",
            "loss 3.7923781871795654 average time 0.002655621762055646 iter num 580\n",
            "loss 0.6153447031974792 average time 0.0026533732316511307 iter num 600\n",
            "loss 0.015032065100967884 average time 0.0026523332064361084 iter num 620\n",
            "loss 2.186798095703125 average time 0.002652899056235469 iter num 640\n",
            "loss 0.00467352569103241 average time 0.0026556543605913635 iter num 660\n",
            "loss 1.1434956789016724 average time 0.002657172672048974 iter num 680\n",
            "loss 17.296998977661133 average time 0.0026593946957005495 iter num 700\n",
            "loss 0.5565249919891357 average time 0.0026646306610978677 iter num 720\n",
            "loss 4.046337127685547 average time 0.002659267493229866 iter num 740\n",
            "loss 4.77168083190918 average time 0.002659386776304018 iter num 760\n",
            "loss 2.281984567642212 average time 0.002659084952546646 iter num 780\n",
            "loss 22.548622131347656 average time 0.002659177529981207 iter num 800\n",
            "loss 0.0002977043914142996 average time 0.002657630204865244 iter num 820\n",
            "loss 0.10548298805952072 average time 0.002657733370229142 iter num 840\n",
            "loss 2.284970760345459 average time 0.002654264968598084 iter num 860\n",
            "loss 2.168480396270752 average time 0.002653773740902662 iter num 880\n",
            "loss 1.7994567155838013 average time 0.0026512744044379765 iter num 900\n",
            "loss 26.95077896118164 average time 0.002649786182602206 iter num 920\n",
            "loss 0.011357818730175495 average time 0.0026493686276556584 iter num 940\n",
            "loss 35.867828369140625 average time 0.0026502947687504276 iter num 960\n",
            "loss 37.68385314941406 average time 0.0026497181500027573 iter num 980\n",
            "loss 0.1251499205827713 average time 0.0026503607590057073 iter num 1000\n",
            "loss 1.3474498987197876 average time 0.003148349000093731 iter num 20\n",
            "loss 97.34723663330078 average time 0.0029565747500328145 iter num 40\n",
            "loss 1.407113790512085 average time 0.0028796167999947404 iter num 60\n",
            "loss 91.15156555175781 average time 0.002861825512445648 iter num 80\n",
            "loss 3.1478683948516846 average time 0.0028066840199790022 iter num 100\n",
            "loss 60.6789436340332 average time 0.00281063056666729 iter num 120\n",
            "loss 0.10870491713285446 average time 0.002761367900010165 iter num 140\n",
            "loss 2.2950382232666016 average time 0.0028015689187554926 iter num 160\n",
            "loss 0.013784815557301044 average time 0.0027992884110972227 iter num 180\n",
            "loss 2.9278814792633057 average time 0.0027629084599993803 iter num 200\n",
            "loss 5.703821659088135 average time 0.0027369357908934365 iter num 220\n",
            "loss 0.14576372504234314 average time 0.0027228536541694364 iter num 240\n",
            "loss 0.5034596920013428 average time 0.0027141658423156163 iter num 260\n",
            "loss 2.8877811431884766 average time 0.0027070353428890873 iter num 280\n",
            "loss 0.04764484614133835 average time 0.0027088480266987363 iter num 300\n",
            "loss 338.1474609375 average time 0.002725226934398961 iter num 320\n",
            "loss 1.1977581977844238 average time 0.002715014564733685 iter num 340\n",
            "loss 67.301025390625 average time 0.00271822354447977 iter num 360\n",
            "loss 0.3057430386543274 average time 0.0027201552447638135 iter num 380\n",
            "loss 3.560896158218384 average time 0.002705723452518214 iter num 400\n",
            "loss 3.937100648880005 average time 0.002705551133346619 iter num 420\n",
            "loss 0.22086529433727264 average time 0.002711605675019448 iter num 440\n",
            "loss 6.114745616912842 average time 0.0027170564543587757 iter num 460\n",
            "loss 11.39419174194336 average time 0.0027205870896030624 iter num 480\n",
            "loss 1.2358330488204956 average time 0.002716973686019628 iter num 500\n",
            "loss 7.6678948402404785 average time 0.002706270038480887 iter num 520\n",
            "loss 2.322768449783325 average time 0.0027026421889045364 iter num 540\n",
            "loss 0.7674686312675476 average time 0.0026981424268050043 iter num 560\n",
            "loss 15.249909400939941 average time 0.002683966708637258 iter num 580\n",
            "loss 0.0890704095363617 average time 0.002683816481685426 iter num 600\n",
            "loss 7.106052875518799 average time 0.002683576190341433 iter num 620\n",
            "loss 2.5480096340179443 average time 0.002687679206263738 iter num 640\n",
            "loss 8.664060592651367 average time 0.002677789343956785 iter num 660\n",
            "loss 343.9271545410156 average time 0.002669029255899017 iter num 680\n",
            "loss 0.05082916468381882 average time 0.002659179300007963 iter num 700\n",
            "loss 8.501011848449707 average time 0.0026579568833439123 iter num 720\n",
            "loss 15.68527889251709 average time 0.0026501408027134192 iter num 740\n",
            "loss 17.635663986206055 average time 0.0026428364394824283 iter num 760\n",
            "loss 0.42056766152381897 average time 0.00263817742052197 iter num 780\n",
            "loss 15.225101470947266 average time 0.002642158330006623 iter num 800\n",
            "loss 57.23411178588867 average time 0.0026354345256239444 iter num 820\n",
            "loss 3915.49072265625 average time 0.0026300342773928217 iter num 840\n",
            "loss 9.338994979858398 average time 0.002628672134890854 iter num 860\n",
            "loss 0.40686941146850586 average time 0.0026293684829624907 iter num 880\n",
            "loss 0.1795012652873993 average time 0.0026247502477821805 iter num 900\n",
            "loss 4.888582229614258 average time 0.002623902954345518 iter num 920\n",
            "loss 3.9574501514434814 average time 0.0026288304542562246 iter num 940\n",
            "loss 0.4003937244415283 average time 0.0026350588374990974 iter num 960\n",
            "loss 0.17556391656398773 average time 0.0026289314969419916 iter num 980\n",
            "loss 0.5360130071640015 average time 0.0026242909300035534 iter num 1000\n",
            "loss 9.726099967956543 average time 0.0032985048002046823 iter num 20\n",
            "loss 2.996964931488037 average time 0.0029402655253306874 iter num 40\n",
            "loss 9.858062744140625 average time 0.0027600299001581635 iter num 60\n",
            "loss 2.016394853591919 average time 0.002663810687658952 iter num 80\n",
            "loss 34.2342643737793 average time 0.00266034740016039 iter num 100\n",
            "loss 1.7721731662750244 average time 0.002622787400150628 iter num 120\n",
            "loss 2.376528263092041 average time 0.002627486150101634 iter num 140\n",
            "loss 0.39266225695610046 average time 0.0025926888375693126 iter num 160\n",
            "loss 0.009866097941994667 average time 0.002590377222309649 iter num 180\n",
            "loss 6.496028900146484 average time 0.0025597819800805156 iter num 200\n",
            "loss 24.897336959838867 average time 0.0025357719636965406 iter num 220\n",
            "loss 9.48106575012207 average time 0.0025170868208912603 iter num 240\n",
            "loss 0.4699954390525818 average time 0.0025135260000542286 iter num 260\n",
            "loss 1.5551083087921143 average time 0.0025021131607575495 iter num 280\n",
            "loss 4.979858875274658 average time 0.002495978756705881 iter num 300\n",
            "loss 2.5279488563537598 average time 0.0024883368937935304 iter num 320\n",
            "loss 89.80089569091797 average time 0.0024967900206427336 iter num 340\n",
            "loss 6.121907711029053 average time 0.0025938561083876264 iter num 360\n",
            "loss 1.805694818496704 average time 0.002633371089527109 iter num 380\n",
            "loss 7.26693058013916 average time 0.0026359612375517825 iter num 400\n",
            "loss 0.9836640954017639 average time 0.002649813257184654 iter num 420\n",
            "loss 1.2949930429458618 average time 0.002653899090943345 iter num 440\n",
            "loss 0.05746264383196831 average time 0.0026409292761380367 iter num 460\n",
            "loss 98.79606628417969 average time 0.0026290756688050958 iter num 480\n",
            "loss 0.09717761725187302 average time 0.0026192674220583286 iter num 500\n",
            "loss 0.45362287759780884 average time 0.0026052352038942236 iter num 520\n",
            "loss 16.381797790527344 average time 0.0025958893018974373 iter num 540\n",
            "loss 0.2175673544406891 average time 0.0025966931089702223 iter num 560\n",
            "loss 0.20906415581703186 average time 0.0026054458483141104 iter num 580\n",
            "loss 1.5948426723480225 average time 0.002608564276697507 iter num 600\n",
            "loss 8.202475547790527 average time 0.0026149863758350433 iter num 620\n",
            "loss 49.197479248046875 average time 0.002607373607838781 iter num 640\n",
            "loss 14.500853538513184 average time 0.002607430210633593 iter num 660\n",
            "loss 0.5255840420722961 average time 0.002598636352968242 iter num 680\n",
            "loss 19.26445960998535 average time 0.002596153174313908 iter num 700\n",
            "loss 1.1031633615493774 average time 0.0025985198958627127 iter num 720\n",
            "loss 1.0653499364852905 average time 0.002589461021656265 iter num 740\n",
            "loss 3.767162561416626 average time 0.002580635872400786 iter num 760\n",
            "loss 0.011660661548376083 average time 0.00257378333848791 iter num 780\n",
            "loss 1.8562378883361816 average time 0.002575553708782081 iter num 800\n",
            "loss 0.02534937858581543 average time 0.0025770361975890233 iter num 820\n",
            "loss 5.420770168304443 average time 0.00257976162026699 iter num 840\n",
            "loss 2.9370007514953613 average time 0.002583663975605474 iter num 860\n",
            "loss 0.01386195793747902 average time 0.002585420939805193 iter num 880\n",
            "loss 9.34349536895752 average time 0.002585756416695707 iter num 900\n",
            "loss 0.002622310072183609 average time 0.0025872126021943627 iter num 920\n",
            "loss 0.7885448932647705 average time 0.0025895915808719786 iter num 940\n",
            "loss 0.03045537881553173 average time 0.002585286220856157 iter num 960\n",
            "loss 9.666125297546387 average time 0.0025794199398140854 iter num 980\n",
            "loss 0.7413769364356995 average time 0.0025747920460198657 iter num 1000\n",
            "loss 2.010375738143921 average time 0.003445415999976831 iter num 20\n",
            "loss 0.192589670419693 average time 0.002990612049916308 iter num 40\n",
            "loss 27.2689266204834 average time 0.0027825761332678665 iter num 60\n",
            "loss 10.545794486999512 average time 0.002691189437405228 iter num 80\n",
            "loss 1.3969777822494507 average time 0.002649526039913326 iter num 100\n",
            "loss 0.20552541315555573 average time 0.0026555371582617227 iter num 120\n",
            "loss 0.09346666932106018 average time 0.002611776457095922 iter num 140\n",
            "loss 4.081211090087891 average time 0.0025945597061991068 iter num 160\n",
            "loss 2.8070363998413086 average time 0.0025808543944145237 iter num 180\n",
            "loss 11.599459648132324 average time 0.002591973829994458 iter num 200\n",
            "loss 1.5021170377731323 average time 0.0025678063227298313 iter num 220\n",
            "loss 16.55831527709961 average time 0.002565876987508394 iter num 240\n",
            "loss 0.0012814337387681007 average time 0.00255992718845776 iter num 260\n",
            "loss 0.30749839544296265 average time 0.002544010342866646 iter num 280\n",
            "loss 0.6518758535385132 average time 0.0025313104433310704 iter num 300\n",
            "loss 4.635687828063965 average time 0.0025428784875032306 iter num 320\n",
            "loss 0.23628506064414978 average time 0.0025575286176664283 iter num 340\n",
            "loss 3.1634814739227295 average time 0.0025955225055693315 iter num 360\n",
            "loss 1.5949196815490723 average time 0.0025953075763362377 iter num 380\n",
            "loss 1.5680863857269287 average time 0.0025923149450181883 iter num 400\n",
            "loss 6.355074882507324 average time 0.0025945148238125035 iter num 420\n",
            "loss 4.744687080383301 average time 0.002584714197721703 iter num 440\n",
            "loss 7.82951021194458 average time 0.002573921417388192 iter num 460\n",
            "loss 1.9936327934265137 average time 0.0025721474854094595 iter num 480\n",
            "loss 18.947982788085938 average time 0.002573966192005173 iter num 500\n",
            "loss 0.2295178323984146 average time 0.0025660538923113142 iter num 520\n",
            "loss 42.18243408203125 average time 0.0025740233000053395 iter num 540\n",
            "loss 1.1946290731430054 average time 0.002576014846437959 iter num 560\n",
            "loss 1.0681995153427124 average time 0.002573196586224091 iter num 580\n",
            "loss 9.06170654296875 average time 0.002571463240007385 iter num 600\n",
            "loss 66.40449523925781 average time 0.002566236385480865 iter num 620\n",
            "loss 1.4348200559616089 average time 0.002566460921875091 iter num 640\n",
            "loss 12.635966300964355 average time 0.0025788121636375737 iter num 660\n",
            "loss 2.13226580619812 average time 0.0025741033470614424 iter num 680\n",
            "loss 0.018421798944473267 average time 0.002569432198576708 iter num 700\n",
            "loss 5.407828330993652 average time 0.0025637956569527077 iter num 720\n",
            "loss 1.0495179891586304 average time 0.002567179867585494 iter num 740\n",
            "loss 4.279057502746582 average time 0.0025625081618560024 iter num 760\n",
            "loss 0.01995173469185829 average time 0.0025556629487348405 iter num 780\n",
            "loss 1.684151291847229 average time 0.0025486307262644913 iter num 800\n",
            "loss 0.02804705686867237 average time 0.0025619186804982656 iter num 820\n",
            "loss 359.6334533691406 average time 0.0025554934607238725 iter num 840\n",
            "loss 3.0271942615509033 average time 0.002553943808149153 iter num 860\n",
            "loss 0.3238285779953003 average time 0.0025491595579627425 iter num 880\n",
            "loss 0.020588239654898643 average time 0.0025483743655604486 iter num 900\n",
            "loss 1.8825559616088867 average time 0.0025465638282639704 iter num 920\n",
            "loss 1.2917826175689697 average time 0.002552377938304454 iter num 940\n",
            "loss 0.5698941349983215 average time 0.0025533749468858486 iter num 960\n",
            "loss 0.08719003945589066 average time 0.002557340900008911 iter num 980\n",
            "loss 9.331768035888672 average time 0.0025609207460111066 iter num 1000\n",
            "loss 2.191713571548462 average time 0.003342795699973067 iter num 20\n",
            "loss 4.844351768493652 average time 0.0029740087000391215 iter num 40\n",
            "loss 0.523577094078064 average time 0.002853772566777479 iter num 60\n",
            "loss 2.4363067150115967 average time 0.0027328264750394737 iter num 80\n",
            "loss 1.4730932712554932 average time 0.002685266570024396 iter num 100\n",
            "loss 18.21098518371582 average time 0.002639512308345123 iter num 120\n",
            "loss 1.105376124382019 average time 0.0025958389000542022 iter num 140\n",
            "loss 16.561731338500977 average time 0.0025668734750297515 iter num 160\n",
            "loss 86.11483764648438 average time 0.0025703064555576325 iter num 180\n",
            "loss 432.95123291015625 average time 0.0025526150650239288 iter num 200\n",
            "loss 0.14060211181640625 average time 0.0025242329409179962 iter num 220\n",
            "loss 39.128475189208984 average time 0.002509053466686358 iter num 240\n",
            "loss 0.8828517198562622 average time 0.002512538588472615 iter num 260\n",
            "loss 2.203615258622449e-05 average time 0.0025039699214175924 iter num 280\n",
            "loss 25.94211196899414 average time 0.002497562583339459 iter num 300\n",
            "loss 0.9407099485397339 average time 0.002506622825012528 iter num 320\n",
            "loss 0.1690862625837326 average time 0.0024976770441486116 iter num 340\n",
            "loss 12.187461853027344 average time 0.002490380666702347 iter num 360\n",
            "loss 2.4792187213897705 average time 0.0024975902158362977 iter num 380\n",
            "loss 0.15170107781887054 average time 0.002501593057550053 iter num 400\n",
            "loss 0.13963273167610168 average time 0.002504913307196451 iter num 420\n",
            "loss 2.7124183177948 average time 0.00250508751141338 iter num 440\n",
            "loss 5.031192302703857 average time 0.0025215785326548465 iter num 460\n",
            "loss 1.6497641801834106 average time 0.0025248655062985867 iter num 480\n",
            "loss 1.3110904693603516 average time 0.0025364102400635604 iter num 500\n",
            "loss 14.307026863098145 average time 0.0025412167577472315 iter num 520\n",
            "loss 1.3804495334625244 average time 0.002547381459306861 iter num 540\n",
            "loss 10.00081729888916 average time 0.002553631132179492 iter num 560\n",
            "loss 0.08631640672683716 average time 0.002559875525903094 iter num 580\n",
            "loss 36.48686599731445 average time 0.002567521280037302 iter num 600\n",
            "loss 3.781569719314575 average time 0.0025704701548801816 iter num 620\n",
            "loss 1.7909505367279053 average time 0.002573624021911769 iter num 640\n",
            "loss 12.213418006896973 average time 0.0025783160924606127 iter num 660\n",
            "loss 51.85874557495117 average time 0.0025785357367968734 iter num 680\n",
            "loss 4.490652084350586 average time 0.002583228402885912 iter num 700\n",
            "loss 5.695625305175781 average time 0.0025795173139183843 iter num 720\n",
            "loss 81.00487518310547 average time 0.002582705943277196 iter num 740\n",
            "loss 0.20667967200279236 average time 0.0025987639052968197 iter num 760\n",
            "loss 3.0600438117980957 average time 0.0026025615718376334 iter num 780\n",
            "loss 0.290251225233078 average time 0.0026060806162922744 iter num 800\n",
            "loss 23.330244064331055 average time 0.0026053988744246365 iter num 820\n",
            "loss 0.14845524728298187 average time 0.002610656894077173 iter num 840\n",
            "loss 0.07094300538301468 average time 0.0026098074570041338 iter num 860\n",
            "loss 10.145181655883789 average time 0.002614940376162684 iter num 880\n",
            "loss 0.6658341884613037 average time 0.002615846567807441 iter num 900\n",
            "loss 0.6092374920845032 average time 0.0026171883413316326 iter num 920\n",
            "loss 2.2591187953948975 average time 0.0026205605861987545 iter num 940\n",
            "loss 0.003151318756863475 average time 0.0026208740458609253 iter num 960\n",
            "loss 0.0010737406555563211 average time 0.00262108411839201 iter num 980\n",
            "loss 1.5529017448425293 average time 0.002621837653023249 iter num 1000\n",
            "loss 2.8858017921447754 average time 0.003179585049929301 iter num 20\n",
            "loss 0.2875692844390869 average time 0.0029851358749056088 iter num 40\n",
            "loss 26.333860397338867 average time 0.0029652125166345893 iter num 60\n",
            "loss 5.807786464691162 average time 0.00285146571243331 iter num 80\n",
            "loss 0.12704481184482574 average time 0.002838355169915303 iter num 100\n",
            "loss 0.0794280543923378 average time 0.0028073501499117507 iter num 120\n",
            "loss 26.710424423217773 average time 0.002774736449945132 iter num 140\n",
            "loss 3.47951602935791 average time 0.0027550618186751308 iter num 160\n",
            "loss 3.1945176124572754 average time 0.0027524138332814295 iter num 180\n",
            "loss 4.751985549926758 average time 0.002762538919951112 iter num 200\n",
            "loss 59.50815963745117 average time 0.0027748854772240024 iter num 220\n",
            "loss 2.9944701194763184 average time 0.0027605019124469737 iter num 240\n",
            "loss 11.677399635314941 average time 0.0027578873460837572 iter num 260\n",
            "loss 1.5806288719177246 average time 0.0027466531999445058 iter num 280\n",
            "loss 1.5528230667114258 average time 0.00274945926328049 iter num 300\n",
            "loss 1.5405395030975342 average time 0.002752396649941602 iter num 320\n",
            "loss 260.8227844238281 average time 0.002743328605838007 iter num 340\n",
            "loss 3.0819032192230225 average time 0.002756775608289293 iter num 360\n",
            "loss 7.965825080871582 average time 0.0027889541973213213 iter num 380\n",
            "loss 0.6361106634140015 average time 0.002780774324946833 iter num 400\n",
            "loss 4.350625991821289 average time 0.002787163333271435 iter num 420\n",
            "loss 0.005796707700937986 average time 0.0027797368521946322 iter num 440\n",
            "loss 0.22989454865455627 average time 0.00279431481078617 iter num 460\n",
            "loss 0.040725305676460266 average time 0.002778034214490314 iter num 480\n",
            "loss 0.006193770561367273 average time 0.002777588931920036 iter num 500\n",
            "loss 0.3923434913158417 average time 0.002773781680693551 iter num 520\n",
            "loss 11.767518997192383 average time 0.002791406836964867 iter num 540\n",
            "loss 0.3880828320980072 average time 0.002788195805289563 iter num 560\n",
            "loss 8.518415451049805 average time 0.002785500118898199 iter num 580\n",
            "loss 0.7727913856506348 average time 0.0027826340682653 iter num 600\n",
            "loss 75.85478210449219 average time 0.0027772139402523245 iter num 620\n",
            "loss 1.2928364276885986 average time 0.002774818457743322 iter num 640\n",
            "loss 0.23131129145622253 average time 0.0027688915347784076 iter num 660\n",
            "loss 0.5577835440635681 average time 0.002762996726393313 iter num 680\n",
            "loss 0.0022302905563265085 average time 0.0027670939656387157 iter num 700\n",
            "loss 11.477720260620117 average time 0.0027641058235480563 iter num 720\n",
            "loss 53.0648307800293 average time 0.0027651099107503328 iter num 740\n",
            "loss 0.7342485785484314 average time 0.0027591851828363263 iter num 760\n",
            "loss 0.030378229916095734 average time 0.0027552698537967957 iter num 780\n",
            "loss 1.2765640020370483 average time 0.0027510127262053174 iter num 800\n",
            "loss 5.379035949707031 average time 0.002753760241418005 iter num 820\n",
            "loss 0.09325525909662247 average time 0.0027540095630424082 iter num 840\n",
            "loss 313.2763977050781 average time 0.0027618962266980056 iter num 860\n",
            "loss 1.727928638458252 average time 0.0027564465533590587 iter num 880\n",
            "loss 6.776307582855225 average time 0.0027612055888393016 iter num 900\n",
            "loss 3.702582597732544 average time 0.0027606631282157215 iter num 920\n",
            "loss 1.055436134338379 average time 0.002760255533999914 iter num 940\n",
            "loss 0.5906915068626404 average time 0.0027594218916249247 iter num 960\n",
            "loss 3.1770386695861816 average time 0.0027529763999600432 iter num 980\n",
            "loss 0.012975238263607025 average time 0.0027502389529636276 iter num 1000\n",
            "loss 1.386437177658081 average time 0.003609009499905369 iter num 20\n",
            "loss 1.1425127983093262 average time 0.003163141125060065 iter num 40\n",
            "loss 7.484402179718018 average time 0.003027585416778796 iter num 60\n",
            "loss 1.3387759923934937 average time 0.002933272275095078 iter num 80\n",
            "loss 0.06255300343036652 average time 0.002864829730060592 iter num 100\n",
            "loss 25.33136749267578 average time 0.002817494425031934 iter num 120\n",
            "loss 0.6356213092803955 average time 0.0028123531143527153 iter num 140\n",
            "loss 2.5812978744506836 average time 0.0027937701812788874 iter num 160\n",
            "loss 0.7199413776397705 average time 0.002811544650012365 iter num 180\n",
            "loss 5.827412128448486 average time 0.0027849579850044394 iter num 200\n",
            "loss 7.536024570465088 average time 0.0027580131181904025 iter num 220\n",
            "loss 9.085506439208984 average time 0.002747992358354168 iter num 240\n",
            "loss 4.800790309906006 average time 0.0027442721615373628 iter num 260\n",
            "loss 12.930452346801758 average time 0.0027284396678689 iter num 280\n",
            "loss 0.1837080419063568 average time 0.0027193693400234527 iter num 300\n",
            "loss 55.51734924316406 average time 0.002717975006277129 iter num 320\n",
            "loss 326.44244384765625 average time 0.0027137760617947874 iter num 340\n",
            "loss 31.10883903503418 average time 0.0027039458222589017 iter num 360\n",
            "loss 1.217005968093872 average time 0.0027000903473938373 iter num 380\n",
            "loss 10.736882209777832 average time 0.002701307775027999 iter num 400\n",
            "loss 1.6879802942276 average time 0.002707702019069118 iter num 420\n",
            "loss 1.1277878284454346 average time 0.0027004910863731558 iter num 440\n",
            "loss 4.812323093414307 average time 0.00268028161958089 iter num 460\n",
            "loss 0.8922269344329834 average time 0.0026641889771023366 iter num 480\n",
            "loss 0.3825041949748993 average time 0.0026580050460106577 iter num 500\n",
            "loss 0.9498364925384521 average time 0.002657114198084925 iter num 520\n",
            "loss 0.817090630531311 average time 0.002645555105566557 iter num 540\n",
            "loss 1.484315037727356 average time 0.0026350822821606407 iter num 560\n",
            "loss 2.8754916191101074 average time 0.002633779377597891 iter num 580\n",
            "loss 9.512371063232422 average time 0.0026253672583485847 iter num 600\n",
            "loss 9.929335594177246 average time 0.0026275783161509025 iter num 620\n",
            "loss 4.993198871612549 average time 0.0026207654968970926 iter num 640\n",
            "loss 0.30478617548942566 average time 0.002617294810627782 iter num 660\n",
            "loss 6.537542819976807 average time 0.0026110134956016896 iter num 680\n",
            "loss 0.5261040329933167 average time 0.0026053157385857568 iter num 700\n",
            "loss 1.4796478748321533 average time 0.002598999805561814 iter num 720\n",
            "loss 0.08273366838693619 average time 0.002593457421625243 iter num 740\n",
            "loss 0.11620765179395676 average time 0.002587937885530329 iter num 760\n",
            "loss 24.697877883911133 average time 0.0025808901820476957 iter num 780\n",
            "loss 1.6091536283493042 average time 0.0025718176437453623 iter num 800\n",
            "loss 4.297004699707031 average time 0.002583277262184732 iter num 820\n",
            "loss 1.1772726774215698 average time 0.002575729213083919 iter num 840\n",
            "loss 5.45086669921875 average time 0.002579164984871208 iter num 860\n",
            "loss 0.014628109522163868 average time 0.0025723486204407725 iter num 880\n",
            "loss 9.003341674804688 average time 0.002568221525541756 iter num 900\n",
            "loss 1.0677410364151 average time 0.002564130055422894 iter num 920\n",
            "loss 3.9002950191497803 average time 0.0025640966563650123 iter num 940\n",
            "loss 0.6687134504318237 average time 0.002558935758319573 iter num 960\n",
            "loss 0.865340530872345 average time 0.002565151646920603 iter num 980\n",
            "loss 0.015602597035467625 average time 0.0025589839689819202 iter num 1000\n",
            "loss 0.21479126811027527 average time 0.002942632149824931 iter num 20\n",
            "loss 2.2799222469329834 average time 0.002614155849960298 iter num 40\n",
            "loss 19.92842674255371 average time 0.0025098337666349833 iter num 60\n",
            "loss 1.122113823890686 average time 0.0024611837874772393 iter num 80\n",
            "loss 6.700732231140137 average time 0.0024532280899620673 iter num 100\n",
            "loss 15.241494178771973 average time 0.002434543533308897 iter num 120\n",
            "loss 0.06275514513254166 average time 0.002513298935692936 iter num 140\n",
            "loss 0.8107307553291321 average time 0.0024804184499885194 iter num 160\n",
            "loss 2.3345038890838623 average time 0.002485274622237436 iter num 180\n",
            "loss 0.028426630422472954 average time 0.0024664819300232923 iter num 200\n",
            "loss 0.11132844537496567 average time 0.0024665182227760272 iter num 220\n",
            "loss 2.409728527069092 average time 0.0024536440666906856 iter num 240\n",
            "loss 2.263920307159424 average time 0.002448135076953734 iter num 260\n",
            "loss 9.960752487182617 average time 0.0024514918964606684 iter num 280\n",
            "loss 9.608843803405762 average time 0.0024423935566907553 iter num 300\n",
            "loss 4.119718074798584 average time 0.0024320250312769077 iter num 320\n",
            "loss 2.9546260833740234 average time 0.0024491345323921824 iter num 340\n",
            "loss 0.8659510016441345 average time 0.0024421542083776634 iter num 360\n",
            "loss 2.4371166229248047 average time 0.002438273897424599 iter num 380\n",
            "loss 7.315094947814941 average time 0.002429457855059809 iter num 400\n",
            "loss 0.5092034339904785 average time 0.0024403122048256808 iter num 420\n",
            "loss 0.047257620841264725 average time 0.002439898777340039 iter num 440\n",
            "loss 1.1920464038848877 average time 0.00244731079136055 iter num 460\n",
            "loss 0.10606980323791504 average time 0.0024541522396399765 iter num 480\n",
            "loss 742.6431884765625 average time 0.0024673897280554228 iter num 500\n",
            "loss 0.04797917604446411 average time 0.0024746902423605486 iter num 520\n",
            "loss 0.5258528590202332 average time 0.00246968929264363 iter num 540\n",
            "loss 12.419020652770996 average time 0.002464868878629594 iter num 560\n",
            "loss 1.0756640434265137 average time 0.0024656270983322084 iter num 580\n",
            "loss 95.10639190673828 average time 0.0024763152517243724 iter num 600\n",
            "loss 0.007681237533688545 average time 0.002480773125857776 iter num 620\n",
            "loss 1.8054590225219727 average time 0.002477655848491622 iter num 640\n",
            "loss 0.26218852400779724 average time 0.00247653073490779 iter num 660\n",
            "loss 3.953732490539551 average time 0.0024722081162428153 iter num 680\n",
            "loss 21.259984970092773 average time 0.002467691908638829 iter num 700\n",
            "loss 1.1691906452178955 average time 0.0024644252972848336 iter num 720\n",
            "loss 28.913101196289062 average time 0.0024614651676357255 iter num 740\n",
            "loss 2.0897717475891113 average time 0.002473979788220803 iter num 760\n",
            "loss 0.2649925947189331 average time 0.002470125057751806 iter num 780\n",
            "loss 0.044819094240665436 average time 0.0024661551225563017 iter num 800\n",
            "loss 0.018537797033786774 average time 0.0024672190732261943 iter num 820\n",
            "loss 0.4761296808719635 average time 0.002465960273860089 iter num 840\n",
            "loss 9.042668342590332 average time 0.0024652662186527715 iter num 860\n",
            "loss 0.11522233486175537 average time 0.002461004275046848 iter num 880\n",
            "loss 0.37309736013412476 average time 0.0024614483500388614 iter num 900\n",
            "loss 0.12203474342823029 average time 0.0024734671728627133 iter num 920\n",
            "loss 665.7527465820312 average time 0.0024706031564222784 iter num 940\n",
            "loss 2.357325792312622 average time 0.002466780618789244 iter num 960\n",
            "loss 40.6104736328125 average time 0.0024629436357455994 iter num 980\n",
            "loss 0.43000343441963196 average time 0.0024647923090269615 iter num 1000\n",
            "loss 0.6958354115486145 average time 0.0029761274498014247 iter num 20\n",
            "loss 0.008217178285121918 average time 0.0026526507749167648 iter num 40\n",
            "loss 31.16202735900879 average time 0.0025579715498982598 iter num 60\n",
            "loss 2.3118860721588135 average time 0.002674615887372056 iter num 80\n",
            "loss 1.0828003883361816 average time 0.0026015673499387047 iter num 100\n",
            "loss 0.34256991744041443 average time 0.002565586408263698 iter num 120\n",
            "loss 0.010633113794028759 average time 0.002523370421334091 iter num 140\n",
            "loss 0.896112859249115 average time 0.002505413731171302 iter num 160\n",
            "loss 36.70166015625 average time 0.002476518355463971 iter num 180\n",
            "loss 1.7954052686691284 average time 0.0024605155099197873 iter num 200\n",
            "loss 1.3160713911056519 average time 0.002457609695358604 iter num 220\n",
            "loss 5.278018474578857 average time 0.002468004383255599 iter num 240\n",
            "loss 3.675093173980713 average time 0.0024557925076036415 iter num 260\n",
            "loss 4.670997805078514e-05 average time 0.002457494424925244 iter num 280\n",
            "loss 38.55565643310547 average time 0.00246004007993785 iter num 300\n",
            "loss 17.886571884155273 average time 0.002465626649944852 iter num 320\n",
            "loss 96.16825866699219 average time 0.002459666805824621 iter num 340\n",
            "loss 6.530951023101807 average time 0.0024503937693983366 iter num 360\n",
            "loss 1.0210754871368408 average time 0.002457718463124605 iter num 380\n",
            "loss 2.6220240592956543 average time 0.0024724013474815365 iter num 400\n",
            "loss 68.61296844482422 average time 0.002476343454738872 iter num 420\n",
            "loss 32.85191345214844 average time 0.002470558365894249 iter num 440\n",
            "loss 0.7715737223625183 average time 0.0024669592326023596 iter num 460\n",
            "loss 0.7314613461494446 average time 0.0024713195062380086 iter num 480\n",
            "loss 0.3143376410007477 average time 0.0024671014979867323 iter num 500\n",
            "loss 0.35353636741638184 average time 0.0024662053961387407 iter num 520\n",
            "loss 15.180925369262695 average time 0.0024750574648014327 iter num 540\n",
            "loss 7.980564594268799 average time 0.0024793097428398273 iter num 560\n",
            "loss 5.217232704162598 average time 0.002472232006885892 iter num 580\n",
            "loss 1.9294854402542114 average time 0.0024722051399900615 iter num 600\n",
            "loss 82.14411926269531 average time 0.002467979266114731 iter num 620\n",
            "loss 0.6890233755111694 average time 0.00246814663279622 iter num 640\n",
            "loss 154.54190063476562 average time 0.002467157168178925 iter num 660\n",
            "loss 0.18332237005233765 average time 0.002472360919112843 iter num 680\n",
            "loss 2.2859394550323486 average time 0.002470554301419595 iter num 700\n",
            "loss 0.6188453435897827 average time 0.0024787532305405573 iter num 720\n",
            "loss 1.9548166990280151 average time 0.002475490377012623 iter num 740\n",
            "loss 7.777124881744385 average time 0.002482885764455109 iter num 760\n",
            "loss 2.156576633453369 average time 0.0024883051987042285 iter num 780\n",
            "loss 0.17965513467788696 average time 0.0024962262662393186 iter num 800\n",
            "loss 0.8362217545509338 average time 0.0024921965390115853 iter num 820\n",
            "loss 47.42594909667969 average time 0.0024908097773645534 iter num 840\n",
            "loss 0.20970477163791656 average time 0.002486062893003268 iter num 860\n",
            "loss 2.7934250831604004 average time 0.002482128384078599 iter num 880\n",
            "loss 29.121631622314453 average time 0.0024810579866506384 iter num 900\n",
            "loss 32.27947998046875 average time 0.0024788989336862553 iter num 920\n",
            "loss 0.3850873112678528 average time 0.0024750078276562643 iter num 940\n",
            "loss 0.005617678165435791 average time 0.0024846885218702632 iter num 960\n",
            "loss 0.10186628997325897 average time 0.002482687110197582 iter num 980\n",
            "loss 15.384454727172852 average time 0.002478823487994305 iter num 1000\n",
            "loss 0.49308744072914124 average time 0.0029299942997567997 iter num 20\n",
            "loss 5.680222511291504 average time 0.0026265426249210575 iter num 40\n",
            "loss 2.8428046703338623 average time 0.0025442333998701846 iter num 60\n",
            "loss 0.010073070414364338 average time 0.0024823556748970075 iter num 80\n",
            "loss 10.031386375427246 average time 0.0024523560099441967 iter num 100\n",
            "loss 22.634021759033203 average time 0.0024720308082578414 iter num 120\n",
            "loss 0.17298388481140137 average time 0.0024809267784933454 iter num 140\n",
            "loss 2.0285251140594482 average time 0.0024616619936637107 iter num 160\n",
            "loss 0.008510214276611805 average time 0.0024447630110039933 iter num 180\n",
            "loss 0.6928378939628601 average time 0.0024611898798775657 iter num 200\n",
            "loss 12.407193183898926 average time 0.0024459392862478456 iter num 220\n",
            "loss 8.153048515319824 average time 0.0024386447290604945 iter num 240\n",
            "loss 0.17328807711601257 average time 0.0024309383729884688 iter num 260\n",
            "loss 36.21794891357422 average time 0.0024357364391952227 iter num 280\n",
            "loss 0.3695872128009796 average time 0.002450125943232706 iter num 300\n",
            "loss 0.23801641166210175 average time 0.002450017803028004 iter num 320\n",
            "loss 0.5788812041282654 average time 0.002443098126374988 iter num 340\n",
            "loss 3.225196361541748 average time 0.002448650138785524 iter num 360\n",
            "loss 3.609618902206421 average time 0.0024437433420021796 iter num 380\n",
            "loss 11.702754974365234 average time 0.0024508492499171553 iter num 400\n",
            "loss 8.6680326461792 average time 0.0024510880951744357 iter num 420\n",
            "loss 0.5871517062187195 average time 0.0024580044181055365 iter num 440\n",
            "loss 4.792990684509277 average time 0.0024542391847084534 iter num 460\n",
            "loss 6.671387195587158 average time 0.0024520974978334683 iter num 480\n",
            "loss 0.40163537859916687 average time 0.0024529763999198624 iter num 500\n",
            "loss 0.4899102747440338 average time 0.002455003244152137 iter num 520\n",
            "loss 0.016035838052630424 average time 0.0024525025165901214 iter num 540\n",
            "loss 4.680393218994141 average time 0.002455973976706056 iter num 560\n",
            "loss 0.3025684058666229 average time 0.002455757030945498 iter num 580\n",
            "loss 0.16055674850940704 average time 0.002460749451583979 iter num 600\n",
            "loss 3.028226137161255 average time 0.002458209295077869 iter num 620\n",
            "loss 2.4394278526306152 average time 0.002455798781170415 iter num 640\n",
            "loss 5.7883687019348145 average time 0.0024589980771975895 iter num 660\n",
            "loss 0.048100490123033524 average time 0.002465518816100431 iter num 680\n",
            "loss 4.3647050857543945 average time 0.002469088818493869 iter num 700\n",
            "loss 0.12382093071937561 average time 0.0024732513387991477 iter num 720\n",
            "loss 5.143606185913086 average time 0.0024792430769348113 iter num 740\n",
            "loss 0.10248161107301712 average time 0.0024840615249104303 iter num 760\n",
            "loss 0.11844222247600555 average time 0.0024903478665738734 iter num 780\n",
            "loss 3.9361093044281006 average time 0.0024919634324191975 iter num 800\n",
            "loss 0.12616153061389923 average time 0.0025028234877226634 iter num 820\n",
            "loss 0.9686829447746277 average time 0.0025083381927743175 iter num 840\n",
            "loss 0.3559378981590271 average time 0.0025130291289886288 iter num 860\n",
            "loss 0.46567201614379883 average time 0.002517447049924406 iter num 880\n",
            "loss 1.2576895952224731 average time 0.00252426616659755 iter num 900\n",
            "loss 122.82933807373047 average time 0.0025278231249360587 iter num 920\n",
            "loss 5.692202568054199 average time 0.0025271851020621165 iter num 940\n",
            "loss 7.812185287475586 average time 0.0025285830072277805 iter num 960\n",
            "loss 29.513328552246094 average time 0.002535434174424896 iter num 980\n",
            "loss 1.0026261806488037 average time 0.0025486448139381535 iter num 1000\n",
            "loss 3.2375121116638184 average time 0.003082379399893398 iter num 20\n",
            "loss 9.790018081665039 average time 0.002821775725033149 iter num 40\n",
            "loss 5.482583522796631 average time 0.002761466666712901 iter num 60\n",
            "loss 9.019671440124512 average time 0.00272247829996104 iter num 80\n",
            "loss 15.209774017333984 average time 0.0027439431099628565 iter num 100\n",
            "loss 0.7264626026153564 average time 0.0027198915582478853 iter num 120\n",
            "loss 0.5888351202011108 average time 0.0027073546284684977 iter num 140\n",
            "loss 9.583377838134766 average time 0.002689461931186088 iter num 160\n",
            "loss 16.291784286499023 average time 0.002761527383255371 iter num 180\n",
            "loss 0.11061491072177887 average time 0.00275624522493672 iter num 200\n",
            "loss 6.909704208374023 average time 0.0027436428408526064 iter num 220\n",
            "loss 0.39344340562820435 average time 0.002717091404125919 iter num 240\n",
            "loss 5.614598751068115 average time 0.0027221268807177414 iter num 260\n",
            "loss 0.2984905242919922 average time 0.002720269317822905 iter num 280\n",
            "loss 2.1742477416992188 average time 0.0027093400199737516 iter num 300\n",
            "loss 16.033830642700195 average time 0.002704496671861989 iter num 320\n",
            "loss 3.434417247772217 average time 0.00270368132940027 iter num 340\n",
            "loss 9.25733757019043 average time 0.002697521047220006 iter num 360\n",
            "loss 0.2612220346927643 average time 0.0026857118000120144 iter num 380\n",
            "loss 0.829491913318634 average time 0.0026686688125209914 iter num 400\n",
            "loss 18.61332130432129 average time 0.002664775802402021 iter num 420\n",
            "loss 1.6374986171722412 average time 0.0026737302568314836 iter num 440\n",
            "loss 548.0218505859375 average time 0.0026754128478268797 iter num 460\n",
            "loss 0.15894705057144165 average time 0.0026770361541669746 iter num 480\n",
            "loss 12.246969223022461 average time 0.002678431498010468 iter num 500\n",
            "loss 0.11863134801387787 average time 0.002679912642315685 iter num 520\n",
            "loss 0.3859351575374603 average time 0.002680407750004734 iter num 540\n",
            "loss 10.671607971191406 average time 0.0026769687392873363 iter num 560\n",
            "loss 12.909775733947754 average time 0.0026739373948312904 iter num 580\n",
            "loss 1.0440343618392944 average time 0.0026760662533433788 iter num 600\n",
            "loss 3.582371711730957 average time 0.0026775992032232734 iter num 620\n",
            "loss 0.2549625039100647 average time 0.0026793434249952953 iter num 640\n",
            "loss 9.19018840789795 average time 0.0026757329818158752 iter num 660\n",
            "loss 0.6346450448036194 average time 0.0026874407161679246 iter num 680\n",
            "loss 0.2043403685092926 average time 0.0026860458542744578 iter num 700\n",
            "loss 2.0137522220611572 average time 0.0026869375861022287 iter num 720\n",
            "loss 1.4325956106185913 average time 0.0026839889405326518 iter num 740\n",
            "loss 3.250105619430542 average time 0.002676015343408117 iter num 760\n",
            "loss 0.7669874429702759 average time 0.0026762714551156162 iter num 780\n",
            "loss 0.000384755025152117 average time 0.0026729194687436573 iter num 800\n",
            "loss 2.6342005729675293 average time 0.0026723161402359683 iter num 820\n",
            "loss 9.98755168914795 average time 0.0026711246464163284 iter num 840\n",
            "loss 3.4003636837005615 average time 0.0026739860441688675 iter num 860\n",
            "loss 0.003190898336470127 average time 0.0026730360045266106 iter num 880\n",
            "loss 0.002508522244170308 average time 0.002685409668863738 iter num 900\n",
            "loss 0.0407140776515007 average time 0.0026867913217163576 iter num 920\n",
            "loss 1.148804783821106 average time 0.0026878608435931418 iter num 940\n",
            "loss 4.0601301193237305 average time 0.0026879388353923633 iter num 960\n",
            "loss 0.4995480179786682 average time 0.0026880245295707976 iter num 980\n",
            "loss 0.035765402019023895 average time 0.0026844372779814877 iter num 1000\n",
            "loss 71.14918518066406 average time 0.003203425299943774 iter num 20\n",
            "loss 0.0005253542913123965 average time 0.0030985131000306866 iter num 40\n",
            "loss 0.07593123614788055 average time 0.0029651911833449653 iter num 60\n",
            "loss 10.8588228225708 average time 0.0028619134749988005 iter num 80\n",
            "loss 8.765705108642578 average time 0.0028130417200372903 iter num 100\n",
            "loss 0.42739754915237427 average time 0.0027465767083564665 iter num 120\n",
            "loss 0.2500162124633789 average time 0.0027328876285927046 iter num 140\n",
            "loss 1.3831403255462646 average time 0.0027077860125132246 iter num 160\n",
            "loss 2.7337722778320312 average time 0.0027026613833287328 iter num 180\n",
            "loss 65.89653778076172 average time 0.002701599424981396 iter num 200\n",
            "loss 1.3665664196014404 average time 0.0027116744090893586 iter num 220\n",
            "loss 0.7670292258262634 average time 0.0026991208499869876 iter num 240\n",
            "loss 1.934410810470581 average time 0.002690996715395718 iter num 260\n",
            "loss 0.43770208954811096 average time 0.002677503428568733 iter num 280\n",
            "loss 0.23142242431640625 average time 0.0026816409333090025 iter num 300\n",
            "loss 2.101473569869995 average time 0.002674993318731822 iter num 320\n",
            "loss 20.68212127685547 average time 0.0026739569088129107 iter num 340\n",
            "loss 0.13203424215316772 average time 0.002674630033339377 iter num 360\n",
            "loss 0.7162594199180603 average time 0.0026715065499908967 iter num 380\n",
            "loss 94.89881134033203 average time 0.0026676959624728626 iter num 400\n",
            "loss 1.1832154989242554 average time 0.002665779249963678 iter num 420\n",
            "loss 23.54639434814453 average time 0.002662862286338581 iter num 440\n",
            "loss 8.629620552062988 average time 0.0026549773804064266 iter num 460\n",
            "loss 3.3707785606384277 average time 0.002640862064557344 iter num 480\n",
            "loss 2.8357596397399902 average time 0.0026401144539813684 iter num 500\n",
            "loss 0.05497661978006363 average time 0.002639881969211134 iter num 520\n",
            "loss 0.28649887442588806 average time 0.0026393398166503716 iter num 540\n",
            "loss 2.247299909591675 average time 0.0026287933982043145 iter num 560\n",
            "loss 13.353997230529785 average time 0.002617086372412877 iter num 580\n",
            "loss 5.230328559875488 average time 0.002609470799995203 iter num 600\n",
            "loss 5.86065673828125 average time 0.0025993736661304515 iter num 620\n",
            "loss 1.3691118955612183 average time 0.002590721485930203 iter num 640\n",
            "loss 1.3595390319824219 average time 0.0025827605121087277 iter num 660\n",
            "loss 4.346426010131836 average time 0.002572297802929397 iter num 680\n",
            "loss 0.23200176656246185 average time 0.0025714609056948184 iter num 700\n",
            "loss 3.691990852355957 average time 0.0025655101833232646 iter num 720\n",
            "loss 1.973357081413269 average time 0.0025593437959361 iter num 740\n",
            "loss 2.9996204376220703 average time 0.0025540338670979462 iter num 760\n",
            "loss 0.2082364708185196 average time 0.002548377324353332 iter num 780\n",
            "loss 1.1141910552978516 average time 0.0025476193824988513 iter num 800\n",
            "loss 0.4186544418334961 average time 0.002542428934141687 iter num 820\n",
            "loss 40.785789489746094 average time 0.0025402725904768884 iter num 840\n",
            "loss 0.06499557197093964 average time 0.002539715468607705 iter num 860\n",
            "loss 8.976852416992188 average time 0.0025468352568209823 iter num 880\n",
            "loss 1.470252513885498 average time 0.002542631855560305 iter num 900\n",
            "loss 73.52298736572266 average time 0.0025381971586976642 iter num 920\n",
            "loss 0.00015985078061930835 average time 0.002536657630852015 iter num 940\n",
            "loss 144.53883361816406 average time 0.002532202006254162 iter num 960\n",
            "loss 4.980067729949951 average time 0.0025302260428621336 iter num 980\n",
            "loss 128.06761169433594 average time 0.002526990176003892 iter num 1000\n",
            "loss 0.07936537265777588 average time 0.002781944300113537 iter num 20\n",
            "loss 20.108131408691406 average time 0.0025447367249853414 iter num 40\n",
            "loss 7.888970375061035 average time 0.0025386868499481354 iter num 60\n",
            "loss 1.6421929597854614 average time 0.002459640725010104 iter num 80\n",
            "loss 5.219010353088379 average time 0.002428346390079241 iter num 100\n",
            "loss 0.48580703139305115 average time 0.002434265150077408 iter num 120\n",
            "loss 2.2609825134277344 average time 0.0024106278072135215 iter num 140\n",
            "loss 27.217039108276367 average time 0.00240194117509418 iter num 160\n",
            "loss 0.7134164571762085 average time 0.0023982680222919346 iter num 180\n",
            "loss 0.013981684111058712 average time 0.0023950269950819346 iter num 200\n",
            "loss 178.42173767089844 average time 0.0023960296955175923 iter num 220\n",
            "loss 0.3240429162979126 average time 0.002403614150057365 iter num 240\n",
            "loss 17.720495223999023 average time 0.002414762969307888 iter num 260\n",
            "loss 129.20913696289062 average time 0.002408154007213982 iter num 280\n",
            "loss 7.997816562652588 average time 0.002410466610072035 iter num 300\n",
            "loss 87.43573760986328 average time 0.002406408584442943 iter num 320\n",
            "loss 0.1582895815372467 average time 0.002399880861824332 iter num 340\n",
            "loss 33.435733795166016 average time 0.0023937874556294344 iter num 360\n",
            "loss 0.11837511509656906 average time 0.002399116036921393 iter num 380\n",
            "loss 4.419611930847168 average time 0.002398890740096249 iter num 400\n",
            "loss 307.9479675292969 average time 0.0024226259667600625 iter num 420\n",
            "loss 0.18380124866962433 average time 0.0024181837455547464 iter num 440\n",
            "loss 71.05525970458984 average time 0.0024153037979332387 iter num 460\n",
            "loss 1.2152906656265259 average time 0.0024097638771877427 iter num 480\n",
            "loss 0.005627975799143314 average time 0.002403698738096864 iter num 500\n",
            "loss 10.73874282836914 average time 0.0024022268750881126 iter num 520\n",
            "loss 147.36810302734375 average time 0.0024051538945362456 iter num 540\n",
            "loss 0.0007394261774607003 average time 0.0024053695447264546 iter num 560\n",
            "loss 14.997537612915039 average time 0.0024060524500751413 iter num 580\n",
            "loss 0.7343221306800842 average time 0.002420161468404937 iter num 600\n",
            "loss 3.463402032852173 average time 0.0024280019065108425 iter num 620\n",
            "loss 19.121803283691406 average time 0.0024223305813166006 iter num 640\n",
            "loss 18.977418899536133 average time 0.002419520821276268 iter num 660\n",
            "loss 0.062286559492349625 average time 0.0024152254000589036 iter num 680\n",
            "loss 0.05728629231452942 average time 0.0024116385943359223 iter num 700\n",
            "loss 18.289274215698242 average time 0.0024100186806006404 iter num 720\n",
            "loss 3.098111152648926 average time 0.0024076313230211414 iter num 740\n",
            "loss 90.10249328613281 average time 0.0024043655816225703 iter num 760\n",
            "loss 17.98780632019043 average time 0.0024197011667102066 iter num 780\n",
            "loss 3.910449504852295 average time 0.0024155845162908917 iter num 800\n",
            "loss 1.4486252069473267 average time 0.002413147496379058 iter num 820\n",
            "loss 3.202382802963257 average time 0.002411575214325369 iter num 840\n",
            "loss 0.08497675508260727 average time 0.0024095366604998097 iter num 860\n",
            "loss 0.48899930715560913 average time 0.002407853840939176 iter num 880\n",
            "loss 0.011268360540270805 average time 0.0024062688244723377 iter num 900\n",
            "loss 7.17222261428833 average time 0.0024046418967689377 iter num 920\n",
            "loss 9.32272720336914 average time 0.002404981577688267 iter num 940\n",
            "loss 8.126927375793457 average time 0.002408213143773234 iter num 960\n",
            "loss 0.0032274462282657623 average time 0.0024067085643059262 iter num 980\n",
            "loss 0.000523652764968574 average time 0.0024073106170217217 iter num 1000\n",
            "loss 3.7301156520843506 average time 0.0029948491500363162 iter num 20\n",
            "loss 204.6249542236328 average time 0.0026300265750251127 iter num 40\n",
            "loss 3.9768097400665283 average time 0.0025224893832879996 iter num 60\n",
            "loss 0.12872977554798126 average time 0.0025274029249430898 iter num 80\n",
            "loss 3.4354071617126465 average time 0.002526641849999578 iter num 100\n",
            "loss 0.8188648819923401 average time 0.002503262816677913 iter num 120\n",
            "loss 0.12520535290241241 average time 0.0024753149714472652 iter num 140\n",
            "loss 0.03684168681502342 average time 0.0024441447812932893 iter num 160\n",
            "loss 0.2225681096315384 average time 0.00247910087227865 iter num 180\n",
            "loss 20.477088928222656 average time 0.0024714013500852163 iter num 200\n",
            "loss 5.1953396905446425e-05 average time 0.0024673246682720097 iter num 220\n",
            "loss 2.2316126823425293 average time 0.002457163279238254 iter num 240\n",
            "loss 3.3035459518432617 average time 0.002462822426976065 iter num 260\n",
            "loss 0.00022231557522900403 average time 0.0024514667250384392 iter num 280\n",
            "loss 16.793663024902344 average time 0.0024655433000225456 iter num 300\n",
            "loss 0.5083475112915039 average time 0.0024723457562629393 iter num 320\n",
            "loss 0.010620824061334133 average time 0.0024655122911794664 iter num 340\n",
            "loss 16.617292404174805 average time 0.0024567163416880553 iter num 360\n",
            "loss 0.027056876569986343 average time 0.0024545071552941073 iter num 380\n",
            "loss 1.3647770881652832 average time 0.0024501764975366313 iter num 400\n",
            "loss 3.233285427093506 average time 0.0024576749309831248 iter num 420\n",
            "loss 0.5531550049781799 average time 0.0024522617136674605 iter num 440\n",
            "loss 2.0214030742645264 average time 0.0024471016478460313 iter num 460\n",
            "loss 16.94571304321289 average time 0.0024599237833588935 iter num 480\n",
            "loss 1.1416852474212646 average time 0.0024836701640197135 iter num 500\n",
            "loss 1.3839510679244995 average time 0.002473800105781265 iter num 520\n",
            "loss 14.109230995178223 average time 0.0024663808814828505 iter num 540\n",
            "loss 0.13080623745918274 average time 0.0024668879982105603 iter num 560\n",
            "loss 0.10029525309801102 average time 0.002465820786205611 iter num 580\n",
            "loss 0.0028073610737919807 average time 0.0024616563166576576 iter num 600\n",
            "loss 0.3058147728443146 average time 0.0024554525209579525 iter num 620\n",
            "loss 15.500421524047852 average time 0.0024572044234275835 iter num 640\n",
            "loss 32.14974594116211 average time 0.002460520792409983 iter num 660\n",
            "loss 29.041484832763672 average time 0.002458304299986647 iter num 680\n",
            "loss 4.999610900878906 average time 0.0024541498428438248 iter num 700\n",
            "loss 4.583140850067139 average time 0.0024523837152653667 iter num 720\n",
            "loss 0.001710247015580535 average time 0.0024611962297156524 iter num 740\n",
            "loss 148.3321533203125 average time 0.002457221656567 iter num 760\n",
            "loss 1.3887660503387451 average time 0.0024561176307636347 iter num 780\n",
            "loss 24.90715980529785 average time 0.002458993667496543 iter num 800\n",
            "loss 2.357430934906006 average time 0.002459246080483043 iter num 820\n",
            "loss 0.9380627274513245 average time 0.002463064529763956 iter num 840\n",
            "loss 12.326114654541016 average time 0.002459801008140054 iter num 860\n",
            "loss 0.6641606092453003 average time 0.002455991695451716 iter num 880\n",
            "loss 0.0758286714553833 average time 0.00246165712777737 iter num 900\n",
            "loss 3.995805025100708 average time 0.0024570687706549823 iter num 920\n",
            "loss 72.7962875366211 average time 0.0024541521872417935 iter num 940\n",
            "loss 30.16253089904785 average time 0.0024522805677217245 iter num 960\n",
            "loss 0.15664279460906982 average time 0.0024537410745064593 iter num 980\n",
            "loss 0.02634384110569954 average time 0.00245290322801884 iter num 1000\n",
            "loss 0.1803978532552719 average time 0.002910377149873966 iter num 20\n",
            "loss 4.8044352531433105 average time 0.0026337967250128712 iter num 40\n",
            "loss 4.923241138458252 average time 0.002687149716651523 iter num 60\n",
            "loss 0.15283237397670746 average time 0.0025943140374465657 iter num 80\n",
            "loss 2.8304383754730225 average time 0.002572176049961854 iter num 100\n",
            "loss 34.866668701171875 average time 0.0025316223416060285 iter num 120\n",
            "loss 6.302361011505127 average time 0.0025205484999527733 iter num 140\n",
            "loss 3.390887975692749 average time 0.002497873899926617 iter num 160\n",
            "loss 1.8745956420898438 average time 0.0024870440054857884 iter num 180\n",
            "loss 87.95987701416016 average time 0.0024791599049513026 iter num 200\n",
            "loss 1.1766622066497803 average time 0.0025009768590610873 iter num 220\n",
            "loss 1.0384712219238281 average time 0.002493418179119544 iter num 240\n",
            "loss 2.2673120498657227 average time 0.00248422470764266 iter num 260\n",
            "loss 3.4286134243011475 average time 0.002472104635665216 iter num 280\n",
            "loss 2.8625588417053223 average time 0.002462329176608667 iter num 300\n",
            "loss 41.38671112060547 average time 0.0024537116561987203 iter num 320\n",
            "loss 0.10478835552930832 average time 0.0024484446234804206 iter num 340\n",
            "loss 0.06410293281078339 average time 0.0024629719499444035 iter num 360\n",
            "loss 5.43998908996582 average time 0.0024631879920602126 iter num 380\n",
            "loss 3.2185683250427246 average time 0.0024540746449520155 iter num 400\n",
            "loss 129.1650848388672 average time 0.0024511135642353026 iter num 420\n",
            "loss 1.534436583518982 average time 0.002456689236317867 iter num 440\n",
            "loss 0.19109928607940674 average time 0.002463863965172293 iter num 460\n",
            "loss 10.514055252075195 average time 0.0024594227478701215 iter num 480\n",
            "loss 3.0636298656463623 average time 0.002452394417949108 iter num 500\n",
            "loss 27.77370834350586 average time 0.002467854015332285 iter num 520\n",
            "loss 0.12417853623628616 average time 0.0024784085721674073 iter num 540\n",
            "loss 4.07919979095459 average time 0.002482742189226883 iter num 560\n",
            "loss 9.057403564453125 average time 0.0024753029258073214 iter num 580\n",
            "loss 0.018621772527694702 average time 0.0024741932616204093 iter num 600\n",
            "loss 0.8046044111251831 average time 0.002478878477364971 iter num 620\n",
            "loss 12.273188591003418 average time 0.0024769602811971934 iter num 640\n",
            "loss 18.86876106262207 average time 0.0024796802514615453 iter num 660\n",
            "loss 268.0958251953125 average time 0.002485388407296127 iter num 680\n",
            "loss 189.93714904785156 average time 0.002497158985658773 iter num 700\n",
            "loss 1.5955556631088257 average time 0.002499474661062272 iter num 720\n",
            "loss 2.1005666255950928 average time 0.002505160128335725 iter num 740\n",
            "loss 0.0001984764967346564 average time 0.00251507903416687 iter num 760\n",
            "loss 790.567626953125 average time 0.0025200422076499633 iter num 780\n",
            "loss 3.2983617782592773 average time 0.0025237027774505805 iter num 800\n",
            "loss 0.1729171872138977 average time 0.0025297802926349793 iter num 820\n",
            "loss 6.851827144622803 average time 0.00254539371423908 iter num 840\n",
            "loss 9.816091537475586 average time 0.0025492431929769526 iter num 860\n",
            "loss 8.116100311279297 average time 0.0025520124385882974 iter num 880\n",
            "loss 0.10371258109807968 average time 0.0025537356743977097 iter num 900\n",
            "loss 1.2874852418899536 average time 0.00255505044343092 iter num 920\n",
            "loss 0.07534925639629364 average time 0.0025596945180370043 iter num 940\n",
            "loss 312.8006896972656 average time 0.0025611066332828615 iter num 960\n",
            "loss 0.5203921794891357 average time 0.002566289085666076 iter num 980\n",
            "loss 13.998257637023926 average time 0.0025678897459565633 iter num 1000\n",
            "loss 5.698939323425293 average time 0.00365466520006521 iter num 20\n",
            "loss 4.482387065887451 average time 0.003155935099994167 iter num 40\n",
            "loss 9.278403282165527 average time 0.002899306283355448 iter num 60\n",
            "loss 1.0160858631134033 average time 0.002854020150039105 iter num 80\n",
            "loss 0.14090551435947418 average time 0.0028192033700543107 iter num 100\n",
            "loss 5.787506103515625 average time 0.0028092827833612927 iter num 120\n",
            "loss 0.36573371291160583 average time 0.0027746447928880765 iter num 140\n",
            "loss 5.954002857208252 average time 0.0027734374375313563 iter num 160\n",
            "loss 0.9493002891540527 average time 0.0027810797555604143 iter num 180\n",
            "loss 2.428738832473755 average time 0.0028330412200102727 iter num 200\n",
            "loss 0.15685288608074188 average time 0.0028159003818225095 iter num 220\n",
            "loss 12.525179862976074 average time 0.0028061589542024497 iter num 240\n",
            "loss 31.75832176208496 average time 0.0028018689115994607 iter num 260\n",
            "loss 93.46770477294922 average time 0.002789913325042497 iter num 280\n",
            "loss 3.509005308151245 average time 0.00279201474337242 iter num 300\n",
            "loss 0.11753939837217331 average time 0.0027878555656627667 iter num 320\n",
            "loss 23.835451126098633 average time 0.0027867517618046004 iter num 340\n",
            "loss 2.0587141513824463 average time 0.0027917388278284406 iter num 360\n",
            "loss 13.758829116821289 average time 0.002813307365824202 iter num 380\n",
            "loss 63.647945404052734 average time 0.002807083580037215 iter num 400\n",
            "loss 1.4175758361816406 average time 0.002793104028608338 iter num 420\n",
            "loss 636.6373901367188 average time 0.0027951337295772562 iter num 440\n",
            "loss 12.610268592834473 average time 0.0027952286500294576 iter num 460\n",
            "loss 0.00261664972640574 average time 0.002789956204196642 iter num 480\n",
            "loss 34.4284553527832 average time 0.0027858231760255875 iter num 500\n",
            "loss 0.2705175280570984 average time 0.0027813876596400615 iter num 520\n",
            "loss 0.6381465792655945 average time 0.0027756053407689183 iter num 540\n",
            "loss 17.629722595214844 average time 0.0027803734803683255 iter num 560\n",
            "loss 0.23550134897232056 average time 0.0027798677741414173 iter num 580\n",
            "loss 0.18512053787708282 average time 0.002773953126673708 iter num 600\n",
            "loss 0.007920445874333382 average time 0.00277497733871813 iter num 620\n",
            "loss 1.3317673206329346 average time 0.002772561643749327 iter num 640\n",
            "loss 5.738613128662109 average time 0.0027669979560552304 iter num 660\n",
            "loss 0.2185194492340088 average time 0.002762031247052351 iter num 680\n",
            "loss 1.6079730987548828 average time 0.0027627508228449315 iter num 700\n",
            "loss 44.43769836425781 average time 0.0027601330277598713 iter num 720\n",
            "loss 0.03418930619955063 average time 0.002770474387828447 iter num 740\n",
            "loss 37.25998306274414 average time 0.0027673180328843285 iter num 760\n",
            "loss 2.6544790267944336 average time 0.0027593248551149884 iter num 780\n",
            "loss 3.876569986343384 average time 0.002753382319983757 iter num 800\n",
            "loss 0.07215286791324615 average time 0.0027557568536394684 iter num 820\n",
            "loss 3.4371891021728516 average time 0.002758292308315157 iter num 840\n",
            "loss 8.846939086914062 average time 0.0027631013348687955 iter num 860\n",
            "loss 42.51970672607422 average time 0.002757098985208276 iter num 880\n",
            "loss 100.310302734375 average time 0.002763968634424398 iter num 900\n",
            "loss 113.50769805908203 average time 0.002756187642367165 iter num 920\n",
            "loss 8.228116035461426 average time 0.002749626157422794 iter num 940\n",
            "loss 0.359677791595459 average time 0.0027411304926848365 iter num 960\n",
            "loss 1.075520634651184 average time 0.002736962784664294 iter num 980\n",
            "loss 0.4831518530845642 average time 0.002736898114973883 iter num 1000\n",
            "loss 0.004196247085928917 average time 0.0031950482502907107 iter num 20\n",
            "loss 5.928014755249023 average time 0.002986516525152183 iter num 40\n",
            "loss 0.7305872440338135 average time 0.0028806584500671306 iter num 60\n",
            "loss 7.165805816650391 average time 0.0028154420375585687 iter num 80\n",
            "loss 0.4887255132198334 average time 0.002853936470110057 iter num 100\n",
            "loss 2.228240489959717 average time 0.002841879208441848 iter num 120\n",
            "loss 18.597591400146484 average time 0.0028114611929205627 iter num 140\n",
            "loss 0.0702974796295166 average time 0.0028095733500549613 iter num 160\n",
            "loss 32.189903259277344 average time 0.002796339233363041 iter num 180\n",
            "loss 0.5048573613166809 average time 0.0027849921850338433 iter num 200\n",
            "loss 6.009777069091797 average time 0.002763675463657736 iter num 220\n",
            "loss 10.461884498596191 average time 0.002760107200060702 iter num 240\n",
            "loss 0.4500710368156433 average time 0.0027687507654683523 iter num 260\n",
            "loss 8.05591869354248 average time 0.002756230885799076 iter num 280\n",
            "loss 0.16022713482379913 average time 0.002741420883412502 iter num 300\n",
            "loss 7.402682304382324 average time 0.002744557215697796 iter num 320\n",
            "loss 63.722957611083984 average time 0.002741938144192639 iter num 340\n",
            "loss 4.788694858551025 average time 0.0027470667889449235 iter num 360\n",
            "loss 2.1598269939422607 average time 0.0027427344789956757 iter num 380\n",
            "loss 0.03464173153042793 average time 0.0027279619175396876 iter num 400\n",
            "loss 20.694475173950195 average time 0.0027271718928984358 iter num 420\n",
            "loss 1.382080078125 average time 0.002723404225046331 iter num 440\n",
            "loss 11.335485458374023 average time 0.0027183538283007576 iter num 460\n",
            "loss 0.5926707983016968 average time 0.0027088560771251955 iter num 480\n",
            "loss 0.2280053049325943 average time 0.0026962382980382244 iter num 500\n",
            "loss 9.600656509399414 average time 0.002694584394273009 iter num 520\n",
            "loss 1.169215440750122 average time 0.002692608520414473 iter num 540\n",
            "loss 22.39141273498535 average time 0.002687821678620951 iter num 560\n",
            "loss 0.3343237042427063 average time 0.0026870348914254183 iter num 580\n",
            "loss 0.47448858618736267 average time 0.0026863538183685403 iter num 600\n",
            "loss 1.3516510725021362 average time 0.0026817724081029744 iter num 620\n",
            "loss 2.646557569503784 average time 0.002672409817230914 iter num 640\n",
            "loss 0.0026074848137795925 average time 0.002673195112156739 iter num 660\n",
            "loss 3.8604910373687744 average time 0.002673313947094785 iter num 680\n",
            "loss 2.108391761779785 average time 0.0026632566443212063 iter num 700\n",
            "loss 0.023062586784362793 average time 0.002652496127812911 iter num 720\n",
            "loss 6.224086973816156e-06 average time 0.002645111116251772 iter num 740\n",
            "loss 28.273099899291992 average time 0.0026453386263471513 iter num 760\n",
            "loss 58.699851989746094 average time 0.002640214446182654 iter num 780\n",
            "loss 4.510568141937256 average time 0.002633040346274811 iter num 800\n",
            "loss 0.03983111307024956 average time 0.0026291977219687662 iter num 820\n",
            "loss 0.7818789482116699 average time 0.0026287712607405583 iter num 840\n",
            "loss 9.047004699707031 average time 0.0026214771163088086 iter num 860\n",
            "loss 0.27584293484687805 average time 0.002614842193210362 iter num 880\n",
            "loss 7.432021617889404 average time 0.0026096561644691164 iter num 900\n",
            "loss 1.6257456541061401 average time 0.002607691022852953 iter num 920\n",
            "loss 1.1941355466842651 average time 0.002602972482998937 iter num 940\n",
            "loss 99.65773010253906 average time 0.00261086020835819 iter num 960\n",
            "loss 8.451966285705566 average time 0.0026069455224814546 iter num 980\n",
            "loss 0.008561670780181885 average time 0.002608700322034565 iter num 1000\n",
            "loss 0.01919393427670002 average time 0.00323831980003888 iter num 20\n",
            "loss 0.20131555199623108 average time 0.002779693050069909 iter num 40\n",
            "loss 60.57183837890625 average time 0.002723061950079379 iter num 60\n",
            "loss 1.1566028594970703 average time 0.0026258862751092236 iter num 80\n",
            "loss 0.25905606150627136 average time 0.002581576590109762 iter num 100\n",
            "loss 1.412440299987793 average time 0.002544152000109534 iter num 120\n",
            "loss 2.3114683628082275 average time 0.002598514328669158 iter num 140\n",
            "loss 1.1532330513000488 average time 0.0026031373125988467 iter num 160\n",
            "loss 13.227818489074707 average time 0.0025767605889591826 iter num 180\n",
            "loss 0.9807605743408203 average time 0.002589426495051157 iter num 200\n",
            "loss 1.319644808769226 average time 0.0025944849818767 iter num 220\n",
            "loss 11.795819282531738 average time 0.002611901079224784 iter num 240\n",
            "loss 1.2428799867630005 average time 0.002629480219296126 iter num 260\n",
            "loss 0.3373993933200836 average time 0.0026389295000561626 iter num 280\n",
            "loss 8.643917083740234 average time 0.0026473451367140417 iter num 300\n",
            "loss 35.69431686401367 average time 0.002650022921903883 iter num 320\n",
            "loss 3.3925302028656006 average time 0.0026512636941387266 iter num 340\n",
            "loss 65.94745635986328 average time 0.00265862466669407 iter num 360\n",
            "loss 0.6041743755340576 average time 0.0026634627052819844 iter num 380\n",
            "loss 39.02855682373047 average time 0.0026697000825242866 iter num 400\n",
            "loss 1.145536184310913 average time 0.0026734369024086933 iter num 420\n",
            "loss 5.019128799438477 average time 0.002679669215922331 iter num 440\n",
            "loss 0.6523687839508057 average time 0.0026773750326158376 iter num 460\n",
            "loss 2.4304513931274414 average time 0.0026669866979280718 iter num 480\n",
            "loss 0.755657434463501 average time 0.0026638676820221006 iter num 500\n",
            "loss 12.40918254852295 average time 0.002676023555792339 iter num 520\n",
            "loss 26.505760192871094 average time 0.002685875694465654 iter num 540\n",
            "loss 6.700011253356934 average time 0.0026778661821643774 iter num 560\n",
            "loss 0.7707471251487732 average time 0.0026746514310491028 iter num 580\n",
            "loss 2.606419563293457 average time 0.002676184515018273 iter num 600\n",
            "loss 59.70377731323242 average time 0.0026749328935634807 iter num 620\n",
            "loss 0.33335432410240173 average time 0.0026770151859551563 iter num 640\n",
            "loss 0.1438959836959839 average time 0.0026827937757733515 iter num 660\n",
            "loss 2.6158876419067383 average time 0.0026804017573688137 iter num 680\n",
            "loss 0.05132216587662697 average time 0.002697422395735235 iter num 700\n",
            "loss 2.1674582958221436 average time 0.0026939466666918736 iter num 720\n",
            "loss 0.11044242978096008 average time 0.002690921481100943 iter num 740\n",
            "loss 0.9013060331344604 average time 0.0026898602381702644 iter num 760\n",
            "loss 9.707988739013672 average time 0.002687293011545896 iter num 780\n",
            "loss 0.25926241278648376 average time 0.0026918521187553777 iter num 800\n",
            "loss 0.13704144954681396 average time 0.0026914069390330973 iter num 820\n",
            "loss 4.987932205200195 average time 0.0026869485345352067 iter num 840\n",
            "loss 8.278000831604004 average time 0.0026840961209462304 iter num 860\n",
            "loss 133.74539184570312 average time 0.0026922482443317427 iter num 880\n",
            "loss 4.250130653381348 average time 0.0026907806777934536 iter num 900\n",
            "loss 37.73979568481445 average time 0.002690081183711458 iter num 920\n",
            "loss 0.3155742287635803 average time 0.0026849994702310954 iter num 940\n",
            "loss 0.49474960565567017 average time 0.002683750229185004 iter num 960\n",
            "loss 220.75794982910156 average time 0.0026811729561387085 iter num 980\n",
            "loss 0.6022840738296509 average time 0.0026745432790230552 iter num 1000\n",
            "loss 2.879723310470581 average time 0.0033421335999264555 iter num 20\n",
            "loss 0.24853308498859406 average time 0.003011707549876519 iter num 40\n",
            "loss 7.1252241134643555 average time 0.002973264333225719 iter num 60\n",
            "loss 4.527240753173828 average time 0.002849010587374323 iter num 80\n",
            "loss 0.8122427463531494 average time 0.0028147718398759025 iter num 100\n",
            "loss 12.433167457580566 average time 0.0028224358832327806 iter num 120\n",
            "loss 7.013251304626465 average time 0.002795464457059487 iter num 140\n",
            "loss 2.904651165008545 average time 0.002769416443652517 iter num 160\n",
            "loss 1.17155122756958 average time 0.0027648129832515324 iter num 180\n",
            "loss 91.64228820800781 average time 0.0027524132999224094 iter num 200\n",
            "loss 4.913309097290039 average time 0.0027473610862795215 iter num 220\n",
            "loss 12.839216232299805 average time 0.0027882319457679236 iter num 240\n",
            "loss 7.282487392425537 average time 0.0027862015960916043 iter num 260\n",
            "loss 1.3310365676879883 average time 0.0027735355249335824 iter num 280\n",
            "loss 1.0833244323730469 average time 0.0027649306532778915 iter num 300\n",
            "loss 0.1599462926387787 average time 0.0027490457280691773 iter num 320\n",
            "loss 5.455686092376709 average time 0.0027466851411190873 iter num 340\n",
            "loss 0.0468125157058239 average time 0.002748348574964944 iter num 360\n",
            "loss 7.80954122543335 average time 0.0027426590736467915 iter num 380\n",
            "loss 0.3032911717891693 average time 0.0027409284449549888 iter num 400\n",
            "loss 2.8510348796844482 average time 0.0027503903713901917 iter num 420\n",
            "loss 19.138723373413086 average time 0.0027384862885893118 iter num 440\n",
            "loss 52.78298568725586 average time 0.002741064202125373 iter num 460\n",
            "loss 1.4207853078842163 average time 0.002735476372864317 iter num 480\n",
            "loss 1.8356620073318481 average time 0.0027332794959511377 iter num 500\n",
            "loss 0.22579005360603333 average time 0.002725100876869664 iter num 520\n",
            "loss 2.1023361682891846 average time 0.002726765072161975 iter num 540\n",
            "loss 0.8933488726615906 average time 0.0027301723749392943 iter num 560\n",
            "loss 24.903886795043945 average time 0.0027230587947683644 iter num 580\n",
            "loss 1.9063564538955688 average time 0.00271878854826961 iter num 600\n",
            "loss 7.522417068481445 average time 0.002730478970906622 iter num 620\n",
            "loss 0.9822269082069397 average time 0.002731313046817263 iter num 640\n",
            "loss 7.80086612701416 average time 0.00272653605903322 iter num 660\n",
            "loss 45.42006301879883 average time 0.00272556635140705 iter num 680\n",
            "loss 36.003662109375 average time 0.002719999728503483 iter num 700\n",
            "loss 0.0017236827407032251 average time 0.0027210981999334963 iter num 720\n",
            "loss 10.797565460205078 average time 0.002713531553989604 iter num 740\n",
            "loss 0.5464336276054382 average time 0.002712696343357828 iter num 760\n",
            "loss 6.120104789733887 average time 0.0027116933101915025 iter num 780\n",
            "loss 0.0012693818425759673 average time 0.0027135030474391897 iter num 800\n",
            "loss 118.0912857055664 average time 0.0027067427914117593 iter num 820\n",
            "loss 0.09576411545276642 average time 0.0027034533666188683 iter num 840\n",
            "loss 6.175702095031738 average time 0.0027006860976228403 iter num 860\n",
            "loss 8.145784378051758 average time 0.0026929998670001706 iter num 880\n",
            "loss 0.20783215761184692 average time 0.00269776810884044 iter num 900\n",
            "loss 0.1570703387260437 average time 0.0026956613021292984 iter num 920\n",
            "loss 2.814242362976074 average time 0.0026963660669799597 iter num 940\n",
            "loss 0.03213812783360481 average time 0.002689962147875728 iter num 960\n",
            "loss 3.2693557739257812 average time 0.0026867797081259986 iter num 980\n",
            "loss 0.3517603278160095 average time 0.002688104106964602 iter num 1000\n",
            "loss 0.0936029702425003 average time 0.003391588599970419 iter num 20\n",
            "loss 1.5880091190338135 average time 0.0029141688501567843 iter num 40\n",
            "loss 14.436544418334961 average time 0.0027879216334743737 iter num 60\n",
            "loss 0.08957889676094055 average time 0.002757135975116398 iter num 80\n",
            "loss 0.0003214357711840421 average time 0.0027680257300562515 iter num 100\n",
            "loss 1.672361969947815 average time 0.0027389134084084316 iter num 120\n",
            "loss 0.3060722053050995 average time 0.0026994467286645626 iter num 140\n",
            "loss 23.000404357910156 average time 0.0026851801625525696 iter num 160\n",
            "loss 32.65623474121094 average time 0.002672923938967465 iter num 180\n",
            "loss 7.723812580108643 average time 0.0026403328550532023 iter num 200\n",
            "loss 0.03795667365193367 average time 0.002657341763700639 iter num 220\n",
            "loss 6.911604404449463 average time 0.0026367577500271485 iter num 240\n",
            "loss 0.5108078122138977 average time 0.002619893815384645 iter num 260\n",
            "loss 43.96516036987305 average time 0.002603132050009143 iter num 280\n",
            "loss 43.3737678527832 average time 0.0026062846500159746 iter num 300\n",
            "loss 2.0493645668029785 average time 0.002617679518766636 iter num 320\n",
            "loss 16.744674682617188 average time 0.0025996675117793905 iter num 340\n",
            "loss 52.17329406738281 average time 0.0025863593472321453 iter num 360\n",
            "loss 91.93028259277344 average time 0.0025961258342201625 iter num 380\n",
            "loss 0.5171226263046265 average time 0.002583802485000888 iter num 400\n",
            "loss 5.871614456176758 average time 0.002588553447627159 iter num 420\n",
            "loss 2.4755589962005615 average time 0.0025927980818199682 iter num 440\n",
            "loss 6.558353900909424 average time 0.0025919680043443804 iter num 460\n",
            "loss 0.4071761965751648 average time 0.0025937219249991964 iter num 480\n",
            "loss 9.083724021911621 average time 0.002596600180007954 iter num 500\n",
            "loss 107.85301971435547 average time 0.0025839733942330683 iter num 520\n",
            "loss 16.990205764770508 average time 0.002590093942591112 iter num 540\n",
            "loss 0.5492410063743591 average time 0.0025805732571403234 iter num 560\n",
            "loss 10.761420249938965 average time 0.0025740043930956493 iter num 580\n",
            "loss 32.026920318603516 average time 0.0025672874133306324 iter num 600\n",
            "loss 0.4688558876514435 average time 0.0025669802483794376 iter num 620\n",
            "loss 3.0220062732696533 average time 0.002559218134376806 iter num 640\n",
            "loss 0.020371511578559875 average time 0.002551424425757542 iter num 660\n",
            "loss 11.296680450439453 average time 0.0025498116073616557 iter num 680\n",
            "loss 2.8583006858825684 average time 0.002549978221434555 iter num 700\n",
            "loss 0.11730541288852692 average time 0.0025527971125054844 iter num 720\n",
            "loss 0.8732933402061462 average time 0.00254845982027119 iter num 740\n",
            "loss 2.4581000804901123 average time 0.002545621959212727 iter num 760\n",
            "loss 1.567711353302002 average time 0.002539795191030582 iter num 780\n",
            "loss 0.5760838389396667 average time 0.0025355128599994716 iter num 800\n",
            "loss 10.896139144897461 average time 0.0025309534597576337 iter num 820\n",
            "loss 1.9101663827896118 average time 0.0025274153690458792 iter num 840\n",
            "loss 3.7868385314941406 average time 0.0025223897755770235 iter num 860\n",
            "loss 1.8065663576126099 average time 0.0025159287783997736 iter num 880\n",
            "loss 25.514862060546875 average time 0.002511563262212601 iter num 900\n",
            "loss 12.253952026367188 average time 0.002509777393466404 iter num 920\n",
            "loss 33.32817459106445 average time 0.0025060264744597395 iter num 940\n",
            "loss 1.3210474252700806 average time 0.002502051329158424 iter num 960\n",
            "loss 65.38719940185547 average time 0.002498462912238637 iter num 980\n",
            "loss 0.014250673353672028 average time 0.002504734100992209 iter num 1000\n",
            "loss 0.04077998176217079 average time 0.0029964779999318127 iter num 20\n",
            "loss 4.263392448425293 average time 0.002646427274976304 iter num 40\n",
            "loss 0.08853839337825775 average time 0.0026319163667115693 iter num 60\n",
            "loss 3.6055917739868164 average time 0.002649889887561585 iter num 80\n",
            "loss 464.169189453125 average time 0.0025798168000437725 iter num 100\n",
            "loss 1.092753529548645 average time 0.0025437417833927612 iter num 120\n",
            "loss 1.7549105882644653 average time 0.00252824215718387 iter num 140\n",
            "loss 5.044148921966553 average time 0.0025118740625543977 iter num 160\n",
            "loss 1.2737489938735962 average time 0.0025242325000363053 iter num 180\n",
            "loss 0.6649255752563477 average time 0.0025079401150196645 iter num 200\n",
            "loss 0.014545679092407227 average time 0.002513380459128133 iter num 220\n",
            "loss 7.533092498779297 average time 0.0025366375375369898 iter num 240\n",
            "loss 41.9538688659668 average time 0.002555982507713522 iter num 260\n",
            "loss 5.520054817199707 average time 0.002563335967884736 iter num 280\n",
            "loss 12.676950454711914 average time 0.0025538923167005125 iter num 300\n",
            "loss 0.47479870915412903 average time 0.002589794321903582 iter num 320\n",
            "loss 1.3257880210876465 average time 0.0025726310676552257 iter num 340\n",
            "loss 4.743524074554443 average time 0.0025624796444440614 iter num 360\n",
            "loss 2.472594976425171 average time 0.002548653236834453 iter num 380\n",
            "loss 0.08755193650722504 average time 0.0025484453349963587 iter num 400\n",
            "loss 3.058642625808716 average time 0.0025385176118972942 iter num 420\n",
            "loss 0.17840684950351715 average time 0.0025308263477158604 iter num 440\n",
            "loss 31.234071731567383 average time 0.0025219993521442 iter num 460\n",
            "loss 13.2752685546875 average time 0.002522465504144596 iter num 480\n",
            "loss 6.653654098510742 average time 0.0025197075519827195 iter num 500\n",
            "loss 83.6596450805664 average time 0.0025232773422990597 iter num 520\n",
            "loss 21.001863479614258 average time 0.002517016790739877 iter num 540\n",
            "loss 0.04483458027243614 average time 0.002521159757134228 iter num 560\n",
            "loss 0.05014491081237793 average time 0.0025138764724033534 iter num 580\n",
            "loss 2.969174385070801 average time 0.002505892788331039 iter num 600\n",
            "loss 1.13688063621521 average time 0.0025006567241865514 iter num 620\n",
            "loss 20.34500503540039 average time 0.0025035431812455043 iter num 640\n",
            "loss 0.0374162495136261 average time 0.0024993953227253353 iter num 660\n",
            "loss 2.523786783218384 average time 0.002501582357345957 iter num 680\n",
            "loss 0.012291126884520054 average time 0.002502213457137259 iter num 700\n",
            "loss 15.487748146057129 average time 0.0025026466916642674 iter num 720\n",
            "loss 6.624540328979492 average time 0.002502700681083838 iter num 740\n",
            "loss 276.8687744140625 average time 0.002498148373687352 iter num 760\n",
            "loss 0.6799718141555786 average time 0.002494940730775852 iter num 780\n",
            "loss 0.43269842863082886 average time 0.002495133515010366 iter num 800\n",
            "loss 3.833421230316162 average time 0.002492792419516485 iter num 820\n",
            "loss 0.005410056561231613 average time 0.002487286673816752 iter num 840\n",
            "loss 0.17560073733329773 average time 0.0024900444220969974 iter num 860\n",
            "loss 0.011874601244926453 average time 0.00250560617273343 iter num 880\n",
            "loss 3.8698205947875977 average time 0.002504737335558376 iter num 900\n",
            "loss 0.09333259612321854 average time 0.002501622894568873 iter num 920\n",
            "loss 0.04997418448328972 average time 0.002500309695750865 iter num 940\n",
            "loss 0.025142420083284378 average time 0.002498422461458934 iter num 960\n",
            "loss 8.966888427734375 average time 0.002495252957140444 iter num 980\n",
            "loss 9.297027587890625 average time 0.002491346896997129 iter num 1000\n",
            "loss 66.13717651367188 average time 0.003219888750027167 iter num 20\n",
            "loss 11.820549964904785 average time 0.0027809531500224693 iter num 40\n",
            "loss 1.5358842611312866 average time 0.0026834382834143374 iter num 60\n",
            "loss 0.01802118681371212 average time 0.002719494025041058 iter num 80\n",
            "loss 4.8961591720581055 average time 0.0026540808599384035 iter num 100\n",
            "loss 0.11901794373989105 average time 0.0026049770665849794 iter num 120\n",
            "loss 6.232464790344238 average time 0.002579400671363276 iter num 140\n",
            "loss 24.556995391845703 average time 0.0025556615312211763 iter num 160\n",
            "loss 1.4991168975830078 average time 0.0025591932444007804 iter num 180\n",
            "loss 1.4578224420547485 average time 0.0025407324999832783 iter num 200\n",
            "loss 0.272959440946579 average time 0.002552771281815777 iter num 220\n",
            "loss 4.745788097381592 average time 0.0025268283375074435 iter num 240\n",
            "loss 2.8719680309295654 average time 0.002517407080771451 iter num 260\n",
            "loss 38.209049224853516 average time 0.00253718353214286 iter num 280\n",
            "loss 0.3606640100479126 average time 0.002521118533331901 iter num 300\n",
            "loss 0.028384197503328323 average time 0.00250766039375776 iter num 320\n",
            "loss 0.2206990122795105 average time 0.002498523523546978 iter num 340\n",
            "loss 10.269930839538574 average time 0.0024861077194752094 iter num 360\n",
            "loss 5.153058052062988 average time 0.0024810123395103516 iter num 380\n",
            "loss 7.713002681732178 average time 0.0024737244150310287 iter num 400\n",
            "loss 4.050358772277832 average time 0.0024727060333567526 iter num 420\n",
            "loss 0.5459325909614563 average time 0.0024658130000179052 iter num 440\n",
            "loss 4.187081813812256 average time 0.002455587804354803 iter num 460\n",
            "loss 775.7333374023438 average time 0.0024541702124944702 iter num 480\n",
            "loss 3.1507251262664795 average time 0.0024548989839895514 iter num 500\n",
            "loss 12.341493606567383 average time 0.002451717403825499 iter num 520\n",
            "loss 8.95003604888916 average time 0.0024461569407119694 iter num 540\n",
            "loss 1.6569550037384033 average time 0.0024470736928378757 iter num 560\n",
            "loss 3.101529598236084 average time 0.00244703523101258 iter num 580\n",
            "loss 0.004601001273840666 average time 0.0024395462266450824 iter num 600\n",
            "loss 0.9161469340324402 average time 0.002436418380623382 iter num 620\n",
            "loss 0.005841739475727081 average time 0.0024466642999783515 iter num 640\n",
            "loss 0.060998037457466125 average time 0.0024458725227001804 iter num 660\n",
            "loss 19.34635353088379 average time 0.002445352511735751 iter num 680\n",
            "loss 3.0324196815490723 average time 0.0024422466456858923 iter num 700\n",
            "loss 1.7053364515304565 average time 0.0024377379305254485 iter num 720\n",
            "loss 0.2482331097126007 average time 0.0024413566999740128 iter num 740\n",
            "loss 0.34408313035964966 average time 0.0024385102104971385 iter num 760\n",
            "loss 0.0013827739749103785 average time 0.002436113098683097 iter num 780\n",
            "loss 53.94478225708008 average time 0.002432787917459791 iter num 800\n",
            "loss 3.200444459915161 average time 0.0024403236414178627 iter num 820\n",
            "loss 522.904052734375 average time 0.002437953292809696 iter num 840\n",
            "loss 0.016278767958283424 average time 0.002442301599956747 iter num 860\n",
            "loss 6.491683483123779 average time 0.0024489829988169733 iter num 880\n",
            "loss 0.05307365208864212 average time 0.002451459882174984 iter num 900\n",
            "loss 0.14341379702091217 average time 0.0024496763543004857 iter num 920\n",
            "loss 12.172311782836914 average time 0.0024472369105945076 iter num 940\n",
            "loss 0.12126579880714417 average time 0.00244306158953691 iter num 960\n",
            "loss 39.3828239440918 average time 0.0024402910764848105 iter num 980\n",
            "loss 10.348321914672852 average time 0.002437395895953159 iter num 1000\n",
            "loss 0.003061228431761265 average time 0.003088002300228254 iter num 20\n",
            "loss 0.012635916471481323 average time 0.002729426350106223 iter num 40\n",
            "loss 23.389612197875977 average time 0.0026723107166314246 iter num 60\n",
            "loss 4.637503147125244 average time 0.0027742563499487003 iter num 80\n",
            "loss 0.19139550626277924 average time 0.0027094592299908983 iter num 100\n",
            "loss 0.1742449849843979 average time 0.002681701708373415 iter num 120\n",
            "loss 0.720576286315918 average time 0.002637425621508425 iter num 140\n",
            "loss 1.216046690940857 average time 0.002597982356337525 iter num 160\n",
            "loss 2.706315279006958 average time 0.002647330477854363 iter num 180\n",
            "loss 0.36204269528388977 average time 0.002639187130080245 iter num 200\n",
            "loss 2.41335391998291 average time 0.00262029864100193 iter num 220\n",
            "loss 9.998513221740723 average time 0.0025952284250782514 iter num 240\n",
            "loss 0.29265496134757996 average time 0.0025770962846833685 iter num 260\n",
            "loss 0.619256317615509 average time 0.0026017951322111392 iter num 280\n",
            "loss 0.5324183702468872 average time 0.0025991383733829326 iter num 300\n",
            "loss 0.5270895957946777 average time 0.0026100071531800495 iter num 320\n",
            "loss 0.8981796503067017 average time 0.002626687867701976 iter num 340\n",
            "loss 48.99492645263672 average time 0.0026445736194950263 iter num 360\n",
            "loss 0.0450899638235569 average time 0.0026370123368858337 iter num 380\n",
            "loss 1.0520753860473633 average time 0.002642157322525236 iter num 400\n",
            "loss 4.998391151428223 average time 0.002640347704787668 iter num 420\n",
            "loss 5.052788734436035 average time 0.0026556881704767545 iter num 440\n",
            "loss 0.6968138217926025 average time 0.002667669604366181 iter num 460\n",
            "loss 4.999661922454834 average time 0.002665559558348226 iter num 480\n",
            "loss 8.387500762939453 average time 0.0026659878180071246 iter num 500\n",
            "loss 0.4542808532714844 average time 0.002666460196157389 iter num 520\n",
            "loss 0.36668941378593445 average time 0.002660825929635596 iter num 540\n",
            "loss 0.0948161780834198 average time 0.0026602539821461895 iter num 560\n",
            "loss 6.124623775482178 average time 0.0026620656431077805 iter num 580\n",
            "loss 1.3606245517730713 average time 0.0026631257016712577 iter num 600\n",
            "loss 47.91964340209961 average time 0.0026645570096896394 iter num 620\n",
            "loss 1.2509948015213013 average time 0.0026582187359537103 iter num 640\n",
            "loss 1.04642653465271 average time 0.002658423466679475 iter num 660\n",
            "loss 0.029794711619615555 average time 0.0026604146441246376 iter num 680\n",
            "loss 0.3933527171611786 average time 0.0026644182942956313 iter num 700\n",
            "loss 10.586906433105469 average time 0.0026644692638986573 iter num 720\n",
            "loss 5.750672817230225 average time 0.002662641864876728 iter num 740\n",
            "loss 0.5247271060943604 average time 0.0026632573105344866 iter num 760\n",
            "loss 0.08824330568313599 average time 0.002670649762834588 iter num 780\n",
            "loss 2.7688755989074707 average time 0.0026735623475133254 iter num 800\n",
            "loss 1.0337172746658325 average time 0.002685007198796506 iter num 820\n",
            "loss 2.2665555477142334 average time 0.002685247092867506 iter num 840\n",
            "loss 0.07804741710424423 average time 0.0026878946035055356 iter num 860\n",
            "loss 5.32432222366333 average time 0.002685331457965648 iter num 880\n",
            "loss 0.003695547580718994 average time 0.0026858634077931735 iter num 900\n",
            "loss 410.78399658203125 average time 0.0026845259587073246 iter num 920\n",
            "loss 12.261324882507324 average time 0.002685137042565057 iter num 940\n",
            "loss 3.120577812194824 average time 0.0026859027843840976 iter num 960\n",
            "loss 0.00900784507393837 average time 0.002684314639807372 iter num 980\n",
            "loss 15.064385414123535 average time 0.002685130347012091 iter num 1000\n",
            "loss 0.10014814883470535 average time 0.0033603081498768004 iter num 20\n",
            "loss 13.342513084411621 average time 0.0030401975498989486 iter num 40\n",
            "loss 1.7895839214324951 average time 0.0029474367165676085 iter num 60\n",
            "loss 3.6556954383850098 average time 0.0028844850124642107 iter num 80\n",
            "loss 51.1675910949707 average time 0.0028546390899646212 iter num 100\n",
            "loss 3.8760671615600586 average time 0.002817740058299023 iter num 120\n",
            "loss 7.196967124938965 average time 0.0027697275713502935 iter num 140\n",
            "loss 1.809767246246338 average time 0.002730662399937955 iter num 160\n",
            "loss 27.6512508392334 average time 0.0027339503110447873 iter num 180\n",
            "loss 0.1263037919998169 average time 0.0026995027249267878 iter num 200\n",
            "loss 1.2756526470184326 average time 0.002684645722630111 iter num 220\n",
            "loss 5.303217887878418 average time 0.0026759987790607436 iter num 240\n",
            "loss 0.26174506545066833 average time 0.0026783650383619645 iter num 260\n",
            "loss 0.0017664175247773528 average time 0.002705253239206026 iter num 280\n",
            "loss 1.3199734687805176 average time 0.0027128501632675277 iter num 300\n",
            "loss 6.035353183746338 average time 0.0027104004530713157 iter num 320\n",
            "loss 1.4120957851409912 average time 0.0026990151470165395 iter num 340\n",
            "loss 48.38457489013672 average time 0.0027056065388428073 iter num 360\n",
            "loss 0.5271311402320862 average time 0.0027141871525935514 iter num 380\n",
            "loss 0.197364941239357 average time 0.00271245331996397 iter num 400\n",
            "loss 0.12395964562892914 average time 0.002714371199956423 iter num 420\n",
            "loss 2.92665696144104 average time 0.002715925011315531 iter num 440\n",
            "loss 2.7823870182037354 average time 0.002712254417340022 iter num 460\n",
            "loss 0.007392078172415495 average time 0.0027166204416251578 iter num 480\n",
            "loss 4.1680498123168945 average time 0.002708608381963131 iter num 500\n",
            "loss 10.035107612609863 average time 0.002707571496113395 iter num 520\n",
            "loss 4.054259777069092 average time 0.0027097987981101646 iter num 540\n",
            "loss 0.8977530598640442 average time 0.0027191097124646796 iter num 560\n",
            "loss 39.657073974609375 average time 0.0027213031913435833 iter num 580\n",
            "loss 188.2007598876953 average time 0.0027255607332942115 iter num 600\n",
            "loss 0.811634361743927 average time 0.002717251490289087 iter num 620\n",
            "loss 0.00029069531592540443 average time 0.0027149165343445247 iter num 640\n",
            "loss 1.0964264869689941 average time 0.002713975259057682 iter num 660\n",
            "loss 2.3724782466888428 average time 0.0027148433058541473 iter num 680\n",
            "loss 0.3120408356189728 average time 0.0027152900299630086 iter num 700\n",
            "loss 332.47296142578125 average time 0.0027153787430178353 iter num 720\n",
            "loss 2.780223846435547 average time 0.002719898081041056 iter num 740\n",
            "loss 10.182979583740234 average time 0.0027224405210170897 iter num 760\n",
            "loss 49.46519470214844 average time 0.0027220596679142497 iter num 780\n",
            "loss 0.105686254799366 average time 0.0027213369112132567 iter num 800\n",
            "loss 26.095579147338867 average time 0.002719218090207017 iter num 820\n",
            "loss 3.194005250930786 average time 0.0027208688940131 iter num 840\n",
            "loss 0.6621289849281311 average time 0.0027190131685761857 iter num 860\n",
            "loss 0.523169755935669 average time 0.002716235595430176 iter num 880\n",
            "loss 0.09840603917837143 average time 0.002713014866644193 iter num 900\n",
            "loss 6.83107328414917 average time 0.002715923441290057 iter num 920\n",
            "loss 0.641253650188446 average time 0.0027212740542420354 iter num 940\n",
            "loss 2.9312636852264404 average time 0.002721654462487777 iter num 960\n",
            "loss 0.06873252242803574 average time 0.0027174576673374127 iter num 980\n",
            "loss 0.08982996642589569 average time 0.002714957959989988 iter num 1000\n",
            "loss 0.00884996447712183 average time 0.0032875028497983292 iter num 20\n",
            "loss 0.05454201623797417 average time 0.003069301649929912 iter num 40\n",
            "loss 0.018324589356780052 average time 0.0028620381333287997 iter num 60\n",
            "loss 214.03280639648438 average time 0.00279548107505434 iter num 80\n",
            "loss 0.6723213195800781 average time 0.0027720869601034794 iter num 100\n",
            "loss 3.3614840507507324 average time 0.002819816458410666 iter num 120\n",
            "loss 0.15701766312122345 average time 0.002789437971478037 iter num 140\n",
            "loss 21.749067306518555 average time 0.0027670009062717325 iter num 160\n",
            "loss 2.308534622192383 average time 0.0027618450111327143 iter num 180\n",
            "loss 2.851519823074341 average time 0.0027434254650142973 iter num 200\n",
            "loss 0.39681723713874817 average time 0.002748291845480046 iter num 220\n",
            "loss 0.018314262852072716 average time 0.0027481617167116686 iter num 240\n",
            "loss 14.34583854675293 average time 0.0027507470846523155 iter num 260\n",
            "loss 0.11248267441987991 average time 0.002753990325014196 iter num 280\n",
            "loss 38.3561897277832 average time 0.002767571510000077 iter num 300\n",
            "loss 4.371703147888184 average time 0.002758740321860387 iter num 320\n",
            "loss 6.202635288238525 average time 0.0027979996646857164 iter num 340\n",
            "loss 0.7464141845703125 average time 0.002793514374964919 iter num 360\n",
            "loss 1.2686996459960938 average time 0.0027866232210104307 iter num 380\n",
            "loss 5.89774751663208 average time 0.0027769926574637794 iter num 400\n",
            "loss 0.5822075605392456 average time 0.002762284559503314 iter num 420\n",
            "loss 0.25100046396255493 average time 0.0027475565522556943 iter num 440\n",
            "loss 1.0449973344802856 average time 0.002728892684769127 iter num 460\n",
            "loss 235.4980926513672 average time 0.002718057460416882 iter num 480\n",
            "loss 15.684855461120605 average time 0.0027061514079978225 iter num 500\n",
            "loss 0.9276885986328125 average time 0.0027099652980653514 iter num 520\n",
            "loss 0.26528477668762207 average time 0.0026975691648018526 iter num 540\n",
            "loss 0.9720155596733093 average time 0.002692650108919484 iter num 560\n",
            "loss 0.20149600505828857 average time 0.002681619462058232 iter num 580\n",
            "loss 8.597514152526855 average time 0.002668604070007253 iter num 600\n",
            "loss 1.1286954879760742 average time 0.0026567616951685903 iter num 620\n",
            "loss 1.5417932271957397 average time 0.00264607647032733 iter num 640\n",
            "loss 9.292561531066895 average time 0.002654319624250065 iter num 660\n",
            "loss 0.37115195393562317 average time 0.0026551336426591126 iter num 680\n",
            "loss 161.2344970703125 average time 0.002645363524305659 iter num 700\n",
            "loss 0.391390860080719 average time 0.002643586772238551 iter num 720\n",
            "loss 4.401346206665039 average time 0.0026380959729952313 iter num 740\n",
            "loss 0.6523246765136719 average time 0.0026357192487036006 iter num 760\n",
            "loss 2.0529658794403076 average time 0.0026325820192444854 iter num 780\n",
            "loss 0.15669812262058258 average time 0.0026301716662669606 iter num 800\n",
            "loss 0.18480513989925385 average time 0.002633063173193588 iter num 820\n",
            "loss 6.5165696144104 average time 0.0026275618333524366 iter num 840\n",
            "loss 1.6044148206710815 average time 0.002620845069789137 iter num 860\n",
            "loss 30.766891479492188 average time 0.0026155287636542694 iter num 880\n",
            "loss 2.9412124156951904 average time 0.002608614372238662 iter num 900\n",
            "loss 2.427443027496338 average time 0.0026004767206695366 iter num 920\n",
            "loss 0.12058387696743011 average time 0.0025950937223589133 iter num 940\n",
            "loss 6.297544956207275 average time 0.00258904864480769 iter num 960\n",
            "loss 0.1320524364709854 average time 0.002584639670428204 iter num 980\n",
            "loss 0.5433482527732849 average time 0.002578338305018406 iter num 1000\n",
            "loss 1.0007935762405396 average time 0.0031671964000452137 iter num 20\n",
            "loss 674.662109375 average time 0.0027352778000476973 iter num 40\n",
            "loss 52.305938720703125 average time 0.0025956899332716904 iter num 60\n",
            "loss 5.035619258880615 average time 0.0026697099749981136 iter num 80\n",
            "loss 0.7736937403678894 average time 0.0026775706200169226 iter num 100\n",
            "loss 199.88230895996094 average time 0.002618529141682302 iter num 120\n",
            "loss 0.009695119224488735 average time 0.0025794561571793953 iter num 140\n",
            "loss 25.038619995117188 average time 0.0025411928875314514 iter num 160\n",
            "loss 8.975252151489258 average time 0.0025536492556057057 iter num 180\n",
            "loss 1.9246503114700317 average time 0.0025301499400666215 iter num 200\n",
            "loss 13.341621398925781 average time 0.0025381370137024946 iter num 220\n",
            "loss 33.197139739990234 average time 0.0025410940042320364 iter num 240\n",
            "loss 7.094948768615723 average time 0.0025325474346573175 iter num 260\n",
            "loss 0.2617975175380707 average time 0.002521557060754276 iter num 280\n",
            "loss 1.1926926374435425 average time 0.0025305778900352985 iter num 300\n",
            "loss 0.1586810201406479 average time 0.002529791037540008 iter num 320\n",
            "loss 1.08768630027771 average time 0.0025186997382822002 iter num 340\n",
            "loss 15.237874984741211 average time 0.002508556677826669 iter num 360\n",
            "loss 0.1983160674571991 average time 0.002517051834269966 iter num 380\n",
            "loss 7.210912227630615 average time 0.0025033651475541772 iter num 400\n",
            "loss 14.7122802734375 average time 0.0024962921214734834 iter num 420\n",
            "loss 0.1370488554239273 average time 0.0024970104159489316 iter num 440\n",
            "loss 0.6902081370353699 average time 0.002494188808731965 iter num 460\n",
            "loss 5.074007987976074 average time 0.0024869186750341517 iter num 480\n",
            "loss 2.3470401763916016 average time 0.002485775980036124 iter num 500\n",
            "loss 7.068437099456787 average time 0.002478922707720043 iter num 520\n",
            "loss 0.03532462567090988 average time 0.0024740552555798517 iter num 540\n",
            "loss 3.895106077194214 average time 0.0024684167553719557 iter num 560\n",
            "loss 0.252372145652771 average time 0.0024712498034706845 iter num 580\n",
            "loss 24.746891021728516 average time 0.0024651672216896257 iter num 600\n",
            "loss 0.4413083791732788 average time 0.0024733333467954633 iter num 620\n",
            "loss 4.122908592224121 average time 0.0024793659890775645 iter num 640\n",
            "loss 1.9511915445327759 average time 0.002490216383348249 iter num 660\n",
            "loss 11.804030418395996 average time 0.0024861539088332765 iter num 680\n",
            "loss 0.012961740605533123 average time 0.0024897601885848935 iter num 700\n",
            "loss 81.6370849609375 average time 0.0024844632000117096 iter num 720\n",
            "loss 1.113746166229248 average time 0.0024790100743425805 iter num 740\n",
            "loss 3.746371269226074 average time 0.002475983680288233 iter num 760\n",
            "loss 2.771186590194702 average time 0.0024724983743838564 iter num 780\n",
            "loss 0.004236016888171434 average time 0.002469075627516304 iter num 800\n",
            "loss 0.1021433100104332 average time 0.0024715748402630243 iter num 820\n",
            "loss 265.9682312011719 average time 0.002477041361923208 iter num 840\n",
            "loss 0.222222700715065 average time 0.0024745342232753774 iter num 860\n",
            "loss 13.61279582977295 average time 0.0024708870602456624 iter num 880\n",
            "loss 2.3558380603790283 average time 0.002469356132237913 iter num 900\n",
            "loss 0.15906265377998352 average time 0.002483968644583001 iter num 920\n",
            "loss 10.429915428161621 average time 0.002488562636186698 iter num 940\n",
            "loss 3.637978807091713e-06 average time 0.0024935933646001254 iter num 960\n",
            "loss 4.406949996948242 average time 0.002489440609200273 iter num 980\n",
            "loss 0.07333864271640778 average time 0.0024854358110151225 iter num 1000\n",
            "loss 0.23231370747089386 average time 0.003186540899969259 iter num 20\n",
            "loss 16.60796356201172 average time 0.0028755728751093555 iter num 40\n",
            "loss 0.03180956467986107 average time 0.0026881568334526187 iter num 60\n",
            "loss 1.3377232551574707 average time 0.0026974861876624344 iter num 80\n",
            "loss 0.005780091974884272 average time 0.002657387950166594 iter num 100\n",
            "loss 1.3510656356811523 average time 0.002602264608458427 iter num 120\n",
            "loss 0.07933347672224045 average time 0.0025707976215406754 iter num 140\n",
            "loss 3.403172731399536 average time 0.002551269787591082 iter num 160\n",
            "loss 261.82720947265625 average time 0.002528312044503562 iter num 180\n",
            "loss 0.0029431653674691916 average time 0.002505738165036746 iter num 200\n",
            "loss 0.6068399548530579 average time 0.0024920859227677283 iter num 220\n",
            "loss 2.214958429336548 average time 0.002536988416689686 iter num 240\n",
            "loss 9.860889434814453 average time 0.0025161827115670558 iter num 260\n",
            "loss 201.00729370117188 average time 0.002508384528605997 iter num 280\n",
            "loss 0.06988542526960373 average time 0.0024953165100305343 iter num 300\n",
            "loss 1.1888530254364014 average time 0.002500193878159962 iter num 320\n",
            "loss 0.10585125535726547 average time 0.0024911833059216887 iter num 340\n",
            "loss 0.34428903460502625 average time 0.002480200991698843 iter num 360\n",
            "loss 202.939453125 average time 0.0024751019789810494 iter num 380\n",
            "loss 4.9326605796813965 average time 0.00248794866753542 iter num 400\n",
            "loss 0.6430480480194092 average time 0.00249566452383598 iter num 420\n",
            "loss 0.9124656915664673 average time 0.002502765513657902 iter num 440\n",
            "loss 13.35561466217041 average time 0.002495188389148888 iter num 460\n",
            "loss 18.712133407592773 average time 0.002488212508357416 iter num 480\n",
            "loss 2.986210346221924 average time 0.002481412658027693 iter num 500\n",
            "loss 5.015129566192627 average time 0.0024780016461800887 iter num 520\n",
            "loss 3.79154634475708 average time 0.0024739534833585182 iter num 540\n",
            "loss 5.681250095367432 average time 0.00247894873038084 iter num 560\n",
            "loss 0.9871422052383423 average time 0.0024739693793262947 iter num 580\n",
            "loss 0.4648419916629791 average time 0.002471480690013171 iter num 600\n",
            "loss 1.051328182220459 average time 0.0024645010871168897 iter num 620\n",
            "loss 1.0790703296661377 average time 0.002476354785957824 iter num 640\n",
            "loss 7.889763355255127 average time 0.0024689831515360946 iter num 660\n",
            "loss 0.17231310904026031 average time 0.0024628359647254805 iter num 680\n",
            "loss 0.11490155011415482 average time 0.0024569015028854274 iter num 700\n",
            "loss 0.007665532175451517 average time 0.002459351637526197 iter num 720\n",
            "loss 4.593355178833008 average time 0.002458340129755556 iter num 740\n",
            "loss 0.4342353343963623 average time 0.002456836736866152 iter num 760\n",
            "loss 6.976446628570557 average time 0.002452393167974757 iter num 780\n",
            "loss 0.35676905512809753 average time 0.0024612250412747016 iter num 800\n",
            "loss 17.485097885131836 average time 0.0024608592671007145 iter num 820\n",
            "loss 0.20530201494693756 average time 0.0024593931440774343 iter num 840\n",
            "loss 0.025637807324528694 average time 0.0024554761279347963 iter num 860\n",
            "loss 3.025070905685425 average time 0.0024613075375265743 iter num 880\n",
            "loss 1.31017005443573 average time 0.00246083156447033 iter num 900\n",
            "loss 0.3969097435474396 average time 0.0024589726456764292 iter num 920\n",
            "loss 3.4863428481912706e-06 average time 0.0024562193298132773 iter num 940\n",
            "loss 8.726851463317871 average time 0.0024580819406499663 iter num 960\n",
            "loss 6.0088791847229 average time 0.0024563674643086043 iter num 980\n",
            "loss 0.0004678280674852431 average time 0.0024544630170221355 iter num 1000\n",
            "loss 3.9352993965148926 average time 0.0031427547500243237 iter num 20\n",
            "loss 1.5302432775497437 average time 0.0028546070749598585 iter num 40\n",
            "loss 2.604018211364746 average time 0.0026715292499526794 iter num 60\n",
            "loss 0.45419344305992126 average time 0.0025906456250140764 iter num 80\n",
            "loss 0.0008577617118135095 average time 0.0025382135099789593 iter num 100\n",
            "loss 0.0021243314258754253 average time 0.0025498481166475054 iter num 120\n",
            "loss 2.7119667530059814 average time 0.0025431110142822683 iter num 140\n",
            "loss 0.7647840976715088 average time 0.0025323588374931206 iter num 160\n",
            "loss 24.226957321166992 average time 0.0025114757277858897 iter num 180\n",
            "loss 0.006146132480353117 average time 0.0025085429899991143 iter num 200\n",
            "loss 27.887733459472656 average time 0.002504105972754835 iter num 220\n",
            "loss 4.43123197555542 average time 0.0024910215042003377 iter num 240\n",
            "loss 0.7812179923057556 average time 0.0024961116884906704 iter num 260\n",
            "loss 0.5108652710914612 average time 0.0025109034428753927 iter num 280\n",
            "loss 6.5752458572387695 average time 0.0025021683000098468 iter num 300\n",
            "loss 1.9603019952774048 average time 0.002495326928152508 iter num 320\n",
            "loss 1.3240174055099487 average time 0.0024941238147221157 iter num 340\n",
            "loss 11.363578796386719 average time 0.0025158635527986915 iter num 360\n",
            "loss 15.383197784423828 average time 0.002528286502643153 iter num 380\n",
            "loss 0.37011152505874634 average time 0.002534426077513672 iter num 400\n",
            "loss 8.620235443115234 average time 0.002553796821432895 iter num 420\n",
            "loss 3.2756221294403076 average time 0.002567718043184703 iter num 440\n",
            "loss 984.7573852539062 average time 0.0025746446956635854 iter num 460\n",
            "loss 0.05502829700708389 average time 0.0025754133291798096 iter num 480\n",
            "loss 0.49334728717803955 average time 0.0025792770060143085 iter num 500\n",
            "loss 0.3855482339859009 average time 0.002577148273086585 iter num 520\n",
            "loss 26.5926570892334 average time 0.002583424509261763 iter num 540\n",
            "loss 0.03662155568599701 average time 0.0025873726142987964 iter num 560\n",
            "loss 21.494915008544922 average time 0.0025844794638032907 iter num 580\n",
            "loss 2.9018824100494385 average time 0.0026006353350112475 iter num 600\n",
            "loss 3.011418581008911 average time 0.0026168808693646205 iter num 620\n",
            "loss 7.591060638427734 average time 0.002622899437506021 iter num 640\n",
            "loss 0.003153237048536539 average time 0.002624222760611398 iter num 660\n",
            "loss 115.00873565673828 average time 0.002618597895595004 iter num 680\n",
            "loss 0.03504690155386925 average time 0.002621152648579092 iter num 700\n",
            "loss 276.1562805175781 average time 0.002623881141673539 iter num 720\n",
            "loss 222.23495483398438 average time 0.0026252594675768067 iter num 740\n",
            "loss 5.7459716796875 average time 0.00262832817763506 iter num 760\n",
            "loss 1.6473348140716553 average time 0.0026286575512854027 iter num 780\n",
            "loss 0.4245774447917938 average time 0.0026283620012577556 iter num 800\n",
            "loss 27.263866424560547 average time 0.0026376938183026006 iter num 820\n",
            "loss 0.13550826907157898 average time 0.0026354626476296247 iter num 840\n",
            "loss 2.500288724899292 average time 0.002638578148849605 iter num 860\n",
            "loss 0.15909308195114136 average time 0.0026385864022834293 iter num 880\n",
            "loss 2.506831645965576 average time 0.0026460363311182136 iter num 900\n",
            "loss 0.2714289724826813 average time 0.0026505271989188495 iter num 920\n",
            "loss 0.04684792086482048 average time 0.002652154260648147 iter num 940\n",
            "loss 14.356301307678223 average time 0.0026535180697995504 iter num 960\n",
            "loss 0.33924347162246704 average time 0.0026566565540949287 iter num 980\n",
            "loss 2.556993007659912 average time 0.002655100881014732 iter num 1000\n",
            "loss 3.3385097980499268 average time 0.0034983315498720914 iter num 20\n",
            "loss 39.228233337402344 average time 0.003160401125023782 iter num 40\n",
            "loss 3.485609292984009 average time 0.003006550750099753 iter num 60\n",
            "loss 0.6160570979118347 average time 0.002912377762595497 iter num 80\n",
            "loss 31.87640953063965 average time 0.002829328930074553 iter num 100\n",
            "loss 8.427984237670898 average time 0.0028025788500296283 iter num 120\n",
            "loss 1.276889443397522 average time 0.0027957399285826667 iter num 140\n",
            "loss 63.04254913330078 average time 0.002775151425032618 iter num 160\n",
            "loss 26.90192413330078 average time 0.0027804802611374017 iter num 180\n",
            "loss 11.856632232666016 average time 0.0027662408850119393 iter num 200\n",
            "loss 0.9715213179588318 average time 0.0027646075636601547 iter num 220\n",
            "loss 0.03649848327040672 average time 0.0027519834958638968 iter num 240\n",
            "loss 7.809584140777588 average time 0.002743910326968874 iter num 260\n",
            "loss 0.1895619034767151 average time 0.002741696210737895 iter num 280\n",
            "loss 13.149919509887695 average time 0.0027364012233556424 iter num 300\n",
            "loss 1.8733972311019897 average time 0.0027359707000130127 iter num 320\n",
            "loss 0.3679135739803314 average time 0.0027363099852878163 iter num 340\n",
            "loss 6.623182773590088 average time 0.0027283711083226888 iter num 360\n",
            "loss 1.159278154373169 average time 0.0027133150920953517 iter num 380\n",
            "loss 0.0693730041384697 average time 0.002713053727497936 iter num 400\n",
            "loss 0.002584651578217745 average time 0.002726757373797487 iter num 420\n",
            "loss 0.2863348126411438 average time 0.0027346077681737703 iter num 440\n",
            "loss 624.2601928710938 average time 0.0027348408108556887 iter num 460\n",
            "loss 0.009709534235298634 average time 0.0027227151041453604 iter num 480\n",
            "loss 3.0810329914093018 average time 0.0027220676159631692 iter num 500\n",
            "loss 22.600858688354492 average time 0.0027248068095804437 iter num 520\n",
            "loss 1.9243221282958984 average time 0.0027190652777453242 iter num 540\n",
            "loss 1.3280192613601685 average time 0.0027195366839090898 iter num 560\n",
            "loss 0.4416074752807617 average time 0.0027143835844605025 iter num 580\n",
            "loss 76.794189453125 average time 0.0027177940383201833 iter num 600\n",
            "loss 17.155738830566406 average time 0.002722092962895042 iter num 620\n",
            "loss 0.525036633014679 average time 0.002717857814050717 iter num 640\n",
            "loss 1.4640424251556396 average time 0.0027173402848320346 iter num 660\n",
            "loss 7.028756618499756 average time 0.002721876777923171 iter num 680\n",
            "loss 0.20156818628311157 average time 0.0027199509228505903 iter num 700\n",
            "loss 0.02864682674407959 average time 0.0027200548319468807 iter num 720\n",
            "loss 0.5250241160392761 average time 0.0027197652783822403 iter num 740\n",
            "loss 0.20033669471740723 average time 0.0027175203815802793 iter num 760\n",
            "loss 0.03552377596497536 average time 0.002718973930773362 iter num 780\n",
            "loss 0.05998896807432175 average time 0.0027164646187566176 iter num 800\n",
            "loss 8.999725341796875 average time 0.0027219484097635934 iter num 820\n",
            "loss 0.442013144493103 average time 0.002721273465491928 iter num 840\n",
            "loss 0.08496648073196411 average time 0.002713771105822542 iter num 860\n",
            "loss 0.9677478671073914 average time 0.0027164715681940585 iter num 880\n",
            "loss 9.941022872924805 average time 0.00271628638668618 iter num 900\n",
            "loss 87.65789031982422 average time 0.0027100414032781334 iter num 920\n",
            "loss 0.0008401570958085358 average time 0.002710297802138697 iter num 940\n",
            "loss 303.6535949707031 average time 0.0027129360229309896 iter num 960\n",
            "loss 0.0001096889900509268 average time 0.0027103690887923556 iter num 980\n",
            "loss 3.2149558067321777 average time 0.002709590513015428 iter num 1000\n",
            "loss 0.31809505820274353 average time 0.0035548010498132497 iter num 20\n",
            "loss 115.36640167236328 average time 0.0031101956248676286 iter num 40\n",
            "loss 176.28482055664062 average time 0.0029390333332230513 iter num 60\n",
            "loss 33.08259582519531 average time 0.002844427424861351 iter num 80\n",
            "loss 2.0559568405151367 average time 0.0028601770598834265 iter num 100\n",
            "loss 3.1194255352020264 average time 0.0028092208165768776 iter num 120\n",
            "loss 0.9839364886283875 average time 0.00277027176419194 iter num 140\n",
            "loss 8.066272735595703 average time 0.00275394456241429 iter num 160\n",
            "loss 0.01762978918850422 average time 0.002748985966587093 iter num 180\n",
            "loss 12.332704544067383 average time 0.0027157428649024953 iter num 200\n",
            "loss 1.5386734008789062 average time 0.002751184486260172 iter num 220\n",
            "loss 0.030909929424524307 average time 0.0027470840540748517 iter num 240\n",
            "loss 5.288934707641602 average time 0.002731797226841501 iter num 260\n",
            "loss 0.6680328845977783 average time 0.002732472310650077 iter num 280\n",
            "loss 50.54624938964844 average time 0.0027275556199189547 iter num 300\n",
            "loss 12.913832664489746 average time 0.002701354809289569 iter num 320\n",
            "loss 15.57163143157959 average time 0.0027015540469940737 iter num 340\n",
            "loss 4.203263282775879 average time 0.002683561916617489 iter num 360\n",
            "loss 4.62279748916626 average time 0.0026786434631216444 iter num 380\n",
            "loss 123.98300170898438 average time 0.002664618429962502 iter num 400\n",
            "loss 17.632221221923828 average time 0.0026671148761471114 iter num 420\n",
            "loss 0.32200923562049866 average time 0.0026521117158650174 iter num 440\n",
            "loss 43.98686599731445 average time 0.002636279254301885 iter num 460\n",
            "loss 46.584957122802734 average time 0.0026225687082804447 iter num 480\n",
            "loss 0.42203378677368164 average time 0.0026207059799489797 iter num 500\n",
            "loss 7.494173526763916 average time 0.0026103494807242756 iter num 520\n",
            "loss 1.7987812757492065 average time 0.002597312020322904 iter num 540\n",
            "loss 2.1471755504608154 average time 0.0025862767481742463 iter num 560\n",
            "loss 5.7590413093566895 average time 0.0025917094172122047 iter num 580\n",
            "loss 24.857837677001953 average time 0.0025819143033095314 iter num 600\n",
            "loss 4.52001953125 average time 0.00257758129514367 iter num 620\n",
            "loss 9.808969497680664 average time 0.0025676893187323913 iter num 640\n",
            "loss 31.119733810424805 average time 0.002566134807558697 iter num 660\n",
            "loss 2.2170252799987793 average time 0.002557149549987598 iter num 680\n",
            "loss 0.05210161209106445 average time 0.0025529756271394687 iter num 700\n",
            "loss 1.8293371200561523 average time 0.002547089805542176 iter num 720\n",
            "loss 0.024460576474666595 average time 0.002551280232413823 iter num 740\n",
            "loss 0.13112099468708038 average time 0.002545310723670761 iter num 760\n",
            "loss 26.127859115600586 average time 0.0025423050371547362 iter num 780\n",
            "loss 2.8790016174316406 average time 0.002548925136231901 iter num 800\n",
            "loss 21.834043502807617 average time 0.0025476696890042905 iter num 820\n",
            "loss 1.1476398706436157 average time 0.002541348053550575 iter num 840\n",
            "loss 4.675475597381592 average time 0.0025381270336934944 iter num 860\n",
            "loss 1.162419319152832 average time 0.002534525074977203 iter num 880\n",
            "loss 1.7095144987106323 average time 0.0025306764110953534 iter num 900\n",
            "loss 3.1291890144348145 average time 0.0025273606043336497 iter num 920\n",
            "loss 2.3992795944213867 average time 0.002523780096793842 iter num 940\n",
            "loss 14.580741882324219 average time 0.0025197622708181674 iter num 960\n",
            "loss 1.0706325769424438 average time 0.002520821233659318 iter num 980\n",
            "loss 16.857975006103516 average time 0.00253326783798002 iter num 1000\n",
            "loss 0.9824679493904114 average time 0.0029025563000686814 iter num 20\n",
            "loss 54.101348876953125 average time 0.002576360799957911 iter num 40\n",
            "loss 32.90790939331055 average time 0.002653359316749023 iter num 60\n",
            "loss 1.2602475881576538 average time 0.0025866530749908633 iter num 80\n",
            "loss 0.2000405639410019 average time 0.002529651529985131 iter num 100\n",
            "loss 199.30145263671875 average time 0.002584280233334842 iter num 120\n",
            "loss 0.048122651875019073 average time 0.0025837255142635383 iter num 140\n",
            "loss 24.35630989074707 average time 0.0025575551437668764 iter num 160\n",
            "loss 1.1431694030761719 average time 0.0025341537166645545 iter num 180\n",
            "loss 0.5966428518295288 average time 0.00256176604502798 iter num 200\n",
            "loss 161.89373779296875 average time 0.0025833717409444613 iter num 220\n",
            "loss 1.8035322427749634 average time 0.002563808783368889 iter num 240\n",
            "loss 1.7612621784210205 average time 0.0025479689538909812 iter num 260\n",
            "loss 1.2269551753997803 average time 0.0025701891572030683 iter num 280\n",
            "loss 0.3101609945297241 average time 0.002560089900058908 iter num 300\n",
            "loss 1.2003647089004517 average time 0.002549039621931115 iter num 320\n",
            "loss 5.558247089385986 average time 0.0025378598765307876 iter num 340\n",
            "loss 27.497570037841797 average time 0.0025362680639369095 iter num 360\n",
            "loss 18.256921768188477 average time 0.0025468956289937763 iter num 380\n",
            "loss 0.004251518286764622 average time 0.0025329691675460707 iter num 400\n",
            "loss 12.637864112854004 average time 0.0025347953691033623 iter num 420\n",
            "loss 0.7188509702682495 average time 0.002535996788694981 iter num 440\n",
            "loss 0.021174466237425804 average time 0.002539925797879297 iter num 460\n",
            "loss 0.8337119817733765 average time 0.002533461335474385 iter num 480\n",
            "loss 1.1774051189422607 average time 0.002524976408058137 iter num 500\n",
            "loss 4.467716217041016 average time 0.0025190676616008343 iter num 520\n",
            "loss 4.156437873840332 average time 0.002524321816727698 iter num 540\n",
            "loss 0.02142365649342537 average time 0.002516545662550535 iter num 560\n",
            "loss 0.047811515629291534 average time 0.0025083739172855686 iter num 580\n",
            "loss 0.6782793402671814 average time 0.0025022154467023937 iter num 600\n",
            "loss 0.1593049168586731 average time 0.002495740743588906 iter num 620\n",
            "loss 0.07730000466108322 average time 0.0025023508078419352 iter num 640\n",
            "loss 45.202518463134766 average time 0.0024971962515502872 iter num 660\n",
            "loss 1.259384274482727 average time 0.0024921389853288394 iter num 680\n",
            "loss 109.63961791992188 average time 0.002486589034321826 iter num 700\n",
            "loss 0.22641445696353912 average time 0.0024893701611517828 iter num 720\n",
            "loss 0.06647121906280518 average time 0.0024818360784101476 iter num 740\n",
            "loss 0.17023053765296936 average time 0.002487653625032755 iter num 760\n",
            "loss 0.9136722683906555 average time 0.002484150392331522 iter num 780\n",
            "loss 42.44521713256836 average time 0.0024869582787709985 iter num 800\n",
            "loss 4.507976055145264 average time 0.0024815097109883314 iter num 820\n",
            "loss 1.5104318857192993 average time 0.002489320475011222 iter num 840\n",
            "loss 1.4154839515686035 average time 0.00249953028024445 iter num 860\n",
            "loss 1.610779881477356 average time 0.0024936185125149926 iter num 880\n",
            "loss 0.08882056176662445 average time 0.0024880800233465076 iter num 900\n",
            "loss 1.8965462446212769 average time 0.002491031745670546 iter num 920\n",
            "loss 8.836186408996582 average time 0.0024861978032102807 iter num 940\n",
            "loss 0.6996272206306458 average time 0.002481263803144884 iter num 960\n",
            "loss 32.719852447509766 average time 0.0024776577408374576 iter num 980\n",
            "loss 0.15003861486911774 average time 0.0024741284830106453 iter num 1000\n",
            "loss 0.8824503421783447 average time 0.0030657225999675573 iter num 20\n",
            "loss 70.45304107666016 average time 0.0027966558500793328 iter num 40\n",
            "loss 7.633749961853027 average time 0.002661067800060361 iter num 60\n",
            "loss 10.07483196258545 average time 0.0026186221625494 iter num 80\n",
            "loss 16.79553985595703 average time 0.0026215392400627023 iter num 100\n",
            "loss 0.5337392687797546 average time 0.0025608287500290317 iter num 120\n",
            "loss 1.5569926500320435 average time 0.0025267546071648084 iter num 140\n",
            "loss 0.06081774830818176 average time 0.002543192443749831 iter num 160\n",
            "loss 27.429519653320312 average time 0.002518437844456558 iter num 180\n",
            "loss 2.3270580768585205 average time 0.0024951850150318933 iter num 200\n",
            "loss 9.163840293884277 average time 0.0025270020227418917 iter num 220\n",
            "loss 0.15951521694660187 average time 0.002505238124998262 iter num 240\n",
            "loss 0.010182095691561699 average time 0.002515646619226922 iter num 260\n",
            "loss 36.85091781616211 average time 0.002494487085713055 iter num 280\n",
            "loss 2.530393600463867 average time 0.002488994286674521 iter num 300\n",
            "loss 166.8794403076172 average time 0.0024749433593683535 iter num 320\n",
            "loss 0.6399407982826233 average time 0.002483081905874689 iter num 340\n",
            "loss 1.243560552597046 average time 0.002497782902774917 iter num 360\n",
            "loss 37.40971755981445 average time 0.002515630065782285 iter num 380\n",
            "loss 0.7232174277305603 average time 0.0025072103974889616 iter num 400\n",
            "loss 0.6313694715499878 average time 0.0025023950857194863 iter num 420\n",
            "loss 7.035114765167236 average time 0.002502881818182604 iter num 440\n",
            "loss 3.3607287406921387 average time 0.002497343330433859 iter num 460\n",
            "loss 9.717190742492676 average time 0.0024971265874910386 iter num 480\n",
            "loss 88.17552947998047 average time 0.002508109867991152 iter num 500\n",
            "loss 0.21755756437778473 average time 0.0025054418230655968 iter num 520\n",
            "loss 0.19305869936943054 average time 0.0025090175703587226 iter num 540\n",
            "loss 0.08629399538040161 average time 0.002504175871419128 iter num 560\n",
            "loss 2.272670269012451 average time 0.0025009928189633525 iter num 580\n",
            "loss 3.1318888664245605 average time 0.0025004587200116173 iter num 600\n",
            "loss 1.503838062286377 average time 0.002503703633887668 iter num 620\n",
            "loss 0.9426820874214172 average time 0.0024998980687655605 iter num 640\n",
            "loss 0.023868778720498085 average time 0.0024938779227423684 iter num 660\n",
            "loss 22.112747192382812 average time 0.0024954320000180065 iter num 680\n",
            "loss 47.71357345581055 average time 0.002511622137161404 iter num 700\n",
            "loss 5.664495944976807 average time 0.0025074684444664147 iter num 720\n",
            "loss 28.59950828552246 average time 0.00250057455271884 iter num 740\n",
            "loss 0.20548716187477112 average time 0.002499204667123865 iter num 760\n",
            "loss 7.314971446990967 average time 0.0025040492256569753 iter num 780\n",
            "loss 0.007924520410597324 average time 0.002503297490013665 iter num 800\n",
            "loss 0.0382423996925354 average time 0.0024969801329439733 iter num 820\n",
            "loss 4.125829219818115 average time 0.002490765172636938 iter num 840\n",
            "loss 1.981038212776184 average time 0.0024952960232693905 iter num 860\n",
            "loss 2.7012720108032227 average time 0.0024932263306978214 iter num 880\n",
            "loss 2.9511125087738037 average time 0.002491389671126348 iter num 900\n",
            "loss 2.087533473968506 average time 0.0024972214684883354 iter num 920\n",
            "loss 9.102330207824707 average time 0.002500990268099292 iter num 940\n",
            "loss 0.07521530240774155 average time 0.0024963578823076205 iter num 960\n",
            "loss 0.4733436107635498 average time 0.002494629821439401 iter num 980\n",
            "loss 33.64463806152344 average time 0.0024907598870140646 iter num 1000\n",
            "loss 4.376519680023193 average time 0.0033268956997744683 iter num 20\n",
            "loss 15.032828330993652 average time 0.0028193611248298112 iter num 40\n",
            "loss 5.393205642700195 average time 0.0027113011998759853 iter num 60\n",
            "loss 1.2133054733276367 average time 0.002628950462371904 iter num 80\n",
            "loss 1.604004144668579 average time 0.002648415429866873 iter num 100\n",
            "loss 0.14118388295173645 average time 0.0026461085998410756 iter num 120\n",
            "loss 2.8968677520751953 average time 0.0026202376284215592 iter num 140\n",
            "loss 0.0172311682254076 average time 0.002591253412390415 iter num 160\n",
            "loss 22.05799674987793 average time 0.0025927449332205773 iter num 180\n",
            "loss 3.540703535079956 average time 0.002556577854920761 iter num 200\n",
            "loss 12.491585731506348 average time 0.0025411321181143813 iter num 220\n",
            "loss 0.004190179985016584 average time 0.0025156997916383262 iter num 240\n",
            "loss 9.973090171813965 average time 0.0025189257461254153 iter num 260\n",
            "loss 12.339457511901855 average time 0.0025151839213906767 iter num 280\n",
            "loss 4.910565376281738 average time 0.0025040465999700244 iter num 300\n",
            "loss 0.6399194598197937 average time 0.002499399587463813 iter num 320\n",
            "loss 0.4582386910915375 average time 0.0025050275205531387 iter num 340\n",
            "loss 52.12577438354492 average time 0.002512955927740121 iter num 360\n",
            "loss 1.822068452835083 average time 0.0025244645789155727 iter num 380\n",
            "loss 35.01395797729492 average time 0.0025302035399727175 iter num 400\n",
            "loss 1.2203412055969238 average time 0.0025373837642551473 iter num 420\n",
            "loss 2.0278513431549072 average time 0.00254282472953326 iter num 440\n",
            "loss 4.695028305053711 average time 0.002543384334777606 iter num 460\n",
            "loss 0.06488554179668427 average time 0.0025459563958293075 iter num 480\n",
            "loss 7.435796737670898 average time 0.00255593946999943 iter num 500\n",
            "loss 2.9865267276763916 average time 0.00255131871152536 iter num 520\n",
            "loss 0.16510359942913055 average time 0.002556987731478094 iter num 540\n",
            "loss 3.8298070430755615 average time 0.002562748899988167 iter num 560\n",
            "loss 1.4909253120422363 average time 0.0025736429810265314 iter num 580\n",
            "loss 31.528030395507812 average time 0.0025814796349914104 iter num 600\n",
            "loss 0.5481191873550415 average time 0.0025885470774013692 iter num 620\n",
            "loss 0.49129968881607056 average time 0.002592851415607811 iter num 640\n",
            "loss 0.15223494172096252 average time 0.0025927803999834533 iter num 660\n",
            "loss 63.003665924072266 average time 0.002597898582341847 iter num 680\n",
            "loss 1.6449757814407349 average time 0.0025996450728468646 iter num 700\n",
            "loss 0.2937720715999603 average time 0.0026026948291574727 iter num 720\n",
            "loss 1.496157169342041 average time 0.002607677522969056 iter num 740\n",
            "loss 9.956881523132324 average time 0.002611375555261475 iter num 760\n",
            "loss 0.17240311205387115 average time 0.0026148880897334235 iter num 780\n",
            "loss 54.09175491333008 average time 0.0026211740274970905 iter num 800\n",
            "loss 0.8943659663200378 average time 0.0026199814829208374 iter num 820\n",
            "loss 0.709736704826355 average time 0.0026215302857097067 iter num 840\n",
            "loss 32.7509765625 average time 0.0026293946860489596 iter num 860\n",
            "loss 0.6098822951316833 average time 0.0026277747125050153 iter num 880\n",
            "loss 2.8400909900665283 average time 0.002630208314450202 iter num 900\n",
            "loss 4.9131059646606445 average time 0.0026322528228359694 iter num 920\n",
            "loss 16.497955322265625 average time 0.00263305458299154 iter num 940\n",
            "loss 0.667288601398468 average time 0.0026377491864745177 iter num 960\n",
            "loss 0.8198964595794678 average time 0.0026428727081797753 iter num 980\n",
            "loss 128.0954132080078 average time 0.0026465869390158332 iter num 1000\n",
            "loss 0.9394957423210144 average time 0.0031946208500812645 iter num 20\n",
            "loss 0.6706114411354065 average time 0.002955337099774624 iter num 40\n",
            "loss 3.546304702758789 average time 0.0029317637831203077 iter num 60\n",
            "loss 34.78877639770508 average time 0.003039219912398039 iter num 80\n",
            "loss 0.7298617362976074 average time 0.0033992427899647735 iter num 100\n",
            "loss 15.33219051361084 average time 0.0032785940583228996 iter num 120\n",
            "loss 2.0938048362731934 average time 0.003254120050054813 iter num 140\n",
            "loss 0.4304669499397278 average time 0.0031825607500650223 iter num 160\n",
            "loss 105.27241516113281 average time 0.003140312550052234 iter num 180\n",
            "loss 5.24071741104126 average time 0.003080802235044757 iter num 200\n",
            "loss 2.2696475982666016 average time 0.0030512104227537664 iter num 220\n",
            "loss 20.851648330688477 average time 0.0030158165291898817 iter num 240\n",
            "loss 10.590686798095703 average time 0.0029920190807738085 iter num 260\n",
            "loss 8.167236328125 average time 0.002965603900007149 iter num 280\n",
            "loss 0.0797099769115448 average time 0.0029421895333143766 iter num 300\n",
            "loss 0.2827126383781433 average time 0.0029415354218372157 iter num 320\n",
            "loss 0.4245724678039551 average time 0.002929271626432156 iter num 340\n",
            "loss 0.4807049036026001 average time 0.0029148199471769154 iter num 360\n",
            "loss 2.1278116703033447 average time 0.002905315826281271 iter num 380\n",
            "loss 1.5720417499542236 average time 0.002886981692477093 iter num 400\n",
            "loss 2.0553770065307617 average time 0.00287449035235373 iter num 420\n",
            "loss 0.036635622382164 average time 0.0028711606431608577 iter num 440\n",
            "loss 0.006657817400991917 average time 0.0028649673369332248 iter num 460\n",
            "loss 5.823464870452881 average time 0.0028599372354013515 iter num 480\n",
            "loss 4.451973915100098 average time 0.0028551552039862145 iter num 500\n",
            "loss 3.337007761001587 average time 0.002845084401909704 iter num 520\n",
            "loss 1.351402759552002 average time 0.002859189494433344 iter num 540\n",
            "loss 2.15908145904541 average time 0.002848436864269388 iter num 560\n",
            "loss 0.16870491206645966 average time 0.0028441220861921087 iter num 580\n",
            "loss 4.993590831756592 average time 0.002836643321652446 iter num 600\n",
            "loss 0.14377237856388092 average time 0.002834013662894933 iter num 620\n",
            "loss 2.050250291824341 average time 0.0028313661328041918 iter num 640\n",
            "loss 0.09905672818422318 average time 0.0028295957954441926 iter num 660\n",
            "loss 0.7196403741836548 average time 0.0028261834470520303 iter num 680\n",
            "loss 0.5181724429130554 average time 0.0028253388028393342 iter num 700\n",
            "loss 0.9325417876243591 average time 0.0028199223860939228 iter num 720\n",
            "loss 0.3232622444629669 average time 0.002820402220250135 iter num 740\n",
            "loss 0.0469924733042717 average time 0.0028152014170820237 iter num 760\n",
            "loss 0.1631353348493576 average time 0.002811007748695351 iter num 780\n",
            "loss 0.0005176013801246881 average time 0.002808745804973114 iter num 800\n",
            "loss 1.0067877769470215 average time 0.002809244123146505 iter num 820\n",
            "loss 0.11369550973176956 average time 0.0028089654916454623 iter num 840\n",
            "loss 0.014322029426693916 average time 0.0028053044360202093 iter num 860\n",
            "loss 0.023129649460315704 average time 0.0028043369590622287 iter num 880\n",
            "loss 4.50959587097168 average time 0.0027991392488588137 iter num 900\n",
            "loss 282.7581481933594 average time 0.0027928076782285168 iter num 920\n",
            "loss 1.8308390963284182e-06 average time 0.002795850579752098 iter num 940\n",
            "loss 0.1658913493156433 average time 0.0027948238041365886 iter num 960\n",
            "loss 3.167390823364258 average time 0.0027930565979269366 iter num 980\n",
            "loss 4.915879726409912 average time 0.0027893232409624035 iter num 1000\n",
            "loss 6.3425798416137695 average time 0.0033002314501572984 iter num 20\n",
            "loss 2.12271785736084 average time 0.002973923150011615 iter num 40\n",
            "loss 0.0978136733174324 average time 0.0029623278333322863 iter num 60\n",
            "loss 2.151078939437866 average time 0.0028994699499889976 iter num 80\n",
            "loss 2.2835869789123535 average time 0.0029015148300095463 iter num 100\n",
            "loss 13.504862785339355 average time 0.002890303524994427 iter num 120\n",
            "loss 1.35568106174469 average time 0.0028536073643018814 iter num 140\n",
            "loss 4.317129135131836 average time 0.002845496287500282 iter num 160\n",
            "loss 336.9669189453125 average time 0.0028367345500050255 iter num 180\n",
            "loss 1.21507728099823 average time 0.002829815929999313 iter num 200\n",
            "loss 27.15069007873535 average time 0.0028399654727267755 iter num 220\n",
            "loss 4.376765251159668 average time 0.0027980398750059978 iter num 240\n",
            "loss 0.27659475803375244 average time 0.0027811303269397914 iter num 260\n",
            "loss 43.87424850463867 average time 0.002764110007157277 iter num 280\n",
            "loss 73.81163024902344 average time 0.0027626698200219836 iter num 300\n",
            "loss 0.0024244983214884996 average time 0.002740855928146857 iter num 320\n",
            "loss 0.08337211608886719 average time 0.0027328711853282154 iter num 340\n",
            "loss 0.47316402196884155 average time 0.002722976066681642 iter num 360\n",
            "loss 25.03067970275879 average time 0.0027157562184344755 iter num 380\n",
            "loss 0.23374043405056 average time 0.002719320719997995 iter num 400\n",
            "loss 9.280355453491211 average time 0.0027149342618984175 iter num 420\n",
            "loss 0.19875194132328033 average time 0.0026967403204542443 iter num 440\n",
            "loss 1.4930232763290405 average time 0.002691275776096122 iter num 460\n",
            "loss 0.009218346327543259 average time 0.0026808607375073735 iter num 480\n",
            "loss 9.660054206848145 average time 0.002682854557999235 iter num 500\n",
            "loss 11.445666313171387 average time 0.0026848934692225157 iter num 520\n",
            "loss 9.493673324584961 average time 0.002686195449984586 iter num 540\n",
            "loss 0.8270239233970642 average time 0.002675003162487753 iter num 560\n",
            "loss 0.0010801426833495498 average time 0.0026732987137871407 iter num 580\n",
            "loss 0.5815121531486511 average time 0.002661170144992866 iter num 600\n",
            "loss 0.49142804741859436 average time 0.0026518995225747097 iter num 620\n",
            "loss 0.036530349403619766 average time 0.0026493607687484654 iter num 640\n",
            "loss 8.368685722351074 average time 0.002638649477274047 iter num 660\n",
            "loss 117.18221282958984 average time 0.0026375705852869405 iter num 680\n",
            "loss 18.183452606201172 average time 0.002636267292844942 iter num 700\n",
            "loss 0.1075512021780014 average time 0.002633616437487439 iter num 720\n",
            "loss 5.7834320068359375 average time 0.0026331034229597947 iter num 740\n",
            "loss 0.7572367191314697 average time 0.0026538118539448127 iter num 760\n",
            "loss 37.09320068359375 average time 0.002656280249998534 iter num 780\n",
            "loss 0.022885985672473907 average time 0.002656927948748944 iter num 800\n",
            "loss 143.53529357910156 average time 0.0026631563963414144 iter num 820\n",
            "loss 1.3595302104949951 average time 0.002668336058334154 iter num 840\n",
            "loss 17.368083953857422 average time 0.0026723909546553628 iter num 860\n",
            "loss 3.229541301727295 average time 0.002673973672734643 iter num 880\n",
            "loss 3.33292555809021 average time 0.0026754591600082573 iter num 900\n",
            "loss 77.43226623535156 average time 0.00267890253479614 iter num 920\n",
            "loss 7.310060977935791 average time 0.0026757177659748506 iter num 940\n",
            "loss 3.8657095432281494 average time 0.0026707320708472555 iter num 960\n",
            "loss 0.0015605076914653182 average time 0.002663568087767516 iter num 980\n",
            "loss 1.8105524778366089 average time 0.002665096954013279 iter num 1000\n",
            "loss 428.55999755859375 average time 0.0033060459499210993 iter num 20\n",
            "loss 1.3793416023254395 average time 0.002853453299940156 iter num 40\n",
            "loss 8.1491060256958 average time 0.002774124366654481 iter num 60\n",
            "loss 1.395553469657898 average time 0.00276986507494712 iter num 80\n",
            "loss 0.003697634907439351 average time 0.002708632019966899 iter num 100\n",
            "loss 0.7630636692047119 average time 0.0026865975999650496 iter num 120\n",
            "loss 1.1311771869659424 average time 0.002704646549968207 iter num 140\n",
            "loss 0.002545867580920458 average time 0.0027233460562229085 iter num 160\n",
            "loss 0.035696178674697876 average time 0.0027191250277408268 iter num 180\n",
            "loss 8.27146053314209 average time 0.002711133379934836 iter num 200\n",
            "loss 3.3451170921325684 average time 0.002731852354504967 iter num 220\n",
            "loss 2.34155011177063 average time 0.0027214737374530768 iter num 240\n",
            "loss 31.556180953979492 average time 0.0026936076383907884 iter num 260\n",
            "loss 1.8291761875152588 average time 0.002686665867765571 iter num 280\n",
            "loss 1.7364922761917114 average time 0.0026927116532533546 iter num 300\n",
            "loss 0.2211737483739853 average time 0.0026873113936687785 iter num 320\n",
            "loss 30.334989547729492 average time 0.002690163732286772 iter num 340\n",
            "loss 4.345089912414551 average time 0.00268147446660502 iter num 360\n",
            "loss 11.436504364013672 average time 0.002694085563100663 iter num 380\n",
            "loss 0.5955369472503662 average time 0.002698228649946941 iter num 400\n",
            "loss 0.9374421238899231 average time 0.0026957852094753997 iter num 420\n",
            "loss 4.3541436195373535 average time 0.0026907537863239254 iter num 440\n",
            "loss 11.751245498657227 average time 0.0026805318825767165 iter num 460\n",
            "loss 0.006254643201828003 average time 0.0026809248312285186 iter num 480\n",
            "loss 255.7834930419922 average time 0.002680297841976426 iter num 500\n",
            "loss 113.54834747314453 average time 0.002668238315370148 iter num 520\n",
            "loss 19.149505615234375 average time 0.0026595917629459076 iter num 540\n",
            "loss 0.10837046056985855 average time 0.0026573845696183135 iter num 560\n",
            "loss 0.3877965211868286 average time 0.0026682598689305825 iter num 580\n",
            "loss 5.0850776460720226e-05 average time 0.0026649538249633527 iter num 600\n",
            "loss 0.2871868908405304 average time 0.0026659151983450657 iter num 620\n",
            "loss 2.5666401386260986 average time 0.002663503585898752 iter num 640\n",
            "loss 9.385636329650879 average time 0.00265208158633124 iter num 660\n",
            "loss 0.348908931016922 average time 0.0026435243573119166 iter num 680\n",
            "loss 0.034902069717645645 average time 0.00264163744853639 iter num 700\n",
            "loss 1.2029469013214111 average time 0.002643511752752501 iter num 720\n",
            "loss 1.1013691425323486 average time 0.0026401553378171817 iter num 740\n",
            "loss 124.4688949584961 average time 0.0026344473723431865 iter num 760\n",
            "loss 1.2275021076202393 average time 0.0026393576102306656 iter num 780\n",
            "loss 25.60882568359375 average time 0.0026357817899679502 iter num 800\n",
            "loss 2.375293493270874 average time 0.00263346615850135 iter num 820\n",
            "loss 2.167997360229492 average time 0.002628264126154872 iter num 840\n",
            "loss 0.018392816185951233 average time 0.002627014679030761 iter num 860\n",
            "loss 0.7922211289405823 average time 0.002626827215873494 iter num 880\n",
            "loss 0.033544380217790604 average time 0.0026275267066294974 iter num 900\n",
            "loss 0.7577148079872131 average time 0.002633242947790084 iter num 920\n",
            "loss 0.6402089595794678 average time 0.0026355820116708505 iter num 940\n",
            "loss 6.9612202644348145 average time 0.002637593878101067 iter num 960\n",
            "loss 0.02619541436433792 average time 0.002652691707120242 iter num 980\n",
            "loss 0.9616780877113342 average time 0.0026536071169775822 iter num 1000\n",
            "loss 0.8800796866416931 average time 0.003342490850172908 iter num 20\n",
            "loss 5.229194164276123 average time 0.003074933825109838 iter num 40\n",
            "loss 16.386091232299805 average time 0.002941772933415147 iter num 60\n",
            "loss 0.19063764810562134 average time 0.002822381500072879 iter num 80\n",
            "loss 0.34663766622543335 average time 0.0027357481500075664 iter num 100\n",
            "loss 4.7023444175720215 average time 0.0027104772833354217 iter num 120\n",
            "loss 10.412773132324219 average time 0.002663110114294146 iter num 140\n",
            "loss 2.9060165882110596 average time 0.002664699174999896 iter num 160\n",
            "loss 15.078958511352539 average time 0.0026444917166271705 iter num 180\n",
            "loss 5.459794521331787 average time 0.0026550820999727874 iter num 200\n",
            "loss 0.9117334485054016 average time 0.0026517818817906533 iter num 220\n",
            "loss 7.620391368865967 average time 0.002653322958303761 iter num 240\n",
            "loss 0.10779216140508652 average time 0.0026488648999754964 iter num 260\n",
            "loss 4.325733184814453 average time 0.002641141860684521 iter num 280\n",
            "loss 27.885074615478516 average time 0.0026345683466267172 iter num 300\n",
            "loss 0.273293137550354 average time 0.0026369082343308038 iter num 320\n",
            "loss 0.7449910640716553 average time 0.0026204514293728127 iter num 340\n",
            "loss 1.7520098686218262 average time 0.002604414172199338 iter num 360\n",
            "loss 0.009139248169958591 average time 0.002604091228927006 iter num 380\n",
            "loss 10.053049087524414 average time 0.002617547357481271 iter num 400\n",
            "loss 0.07405006885528564 average time 0.002614140302362752 iter num 420\n",
            "loss 9.764337539672852 average time 0.002618447404537702 iter num 440\n",
            "loss 3.7887539863586426 average time 0.002615858341311611 iter num 460\n",
            "loss 26.117408752441406 average time 0.0026109670375073315 iter num 480\n",
            "loss 0.037138402462005615 average time 0.002601718420002726 iter num 500\n",
            "loss 0.6193351149559021 average time 0.0025979958192342916 iter num 520\n",
            "loss 126.62722778320312 average time 0.002589668948163577 iter num 540\n",
            "loss 9.168148040771484 average time 0.0025975519142938147 iter num 560\n",
            "loss 1.5923842191696167 average time 0.002587562905174654 iter num 580\n",
            "loss 1.165102481842041 average time 0.0025911932316800327 iter num 600\n",
            "loss 0.6130128502845764 average time 0.0025970336500112383 iter num 620\n",
            "loss 0.5151060223579407 average time 0.002587964104699836 iter num 640\n",
            "loss 125.86720275878906 average time 0.002578784816669764 iter num 660\n",
            "loss 0.11135198920965195 average time 0.0025718845338280304 iter num 680\n",
            "loss 2.802645683288574 average time 0.0025752222614339967 iter num 700\n",
            "loss 7.907516956329346 average time 0.002567047365283138 iter num 720\n",
            "loss 4.545098781585693 average time 0.0025693522310821456 iter num 740\n",
            "loss 37.571720123291016 average time 0.0025633220394770196 iter num 760\n",
            "loss 2.6862082481384277 average time 0.002566925603854869 iter num 780\n",
            "loss 4.121809005737305 average time 0.0025598665987604362 iter num 800\n",
            "loss 0.09655341506004333 average time 0.002555333996353023 iter num 820\n",
            "loss 0.08466900140047073 average time 0.002547666689302527 iter num 840\n",
            "loss 1.9142177104949951 average time 0.0025435114430386653 iter num 860\n",
            "loss 0.8926495313644409 average time 0.00254227384887558 iter num 880\n",
            "loss 0.005647452548146248 average time 0.00253829558000992 iter num 900\n",
            "loss 5.641277313232422 average time 0.0025364376847906186 iter num 920\n",
            "loss 0.16422492265701294 average time 0.0025361158266024816 iter num 940\n",
            "loss 1.0429315567016602 average time 0.002531610405221348 iter num 960\n",
            "loss 0.22423410415649414 average time 0.0025281996061364354 iter num 980\n",
            "loss 1.7073695659637451 average time 0.0025234878970095452 iter num 1000\n",
            "loss 0.2869395911693573 average time 0.0029685403501389374 iter num 20\n",
            "loss 0.7049787640571594 average time 0.0029740573250364834 iter num 40\n",
            "loss 0.6666489243507385 average time 0.002777865716628488 iter num 60\n",
            "loss 3.5223588943481445 average time 0.0027338009749882986 iter num 80\n",
            "loss 1.953465461730957 average time 0.002735942270010128 iter num 100\n",
            "loss 79.5309829711914 average time 0.0026605836666628115 iter num 120\n",
            "loss 83.2745361328125 average time 0.0026191326785530173 iter num 140\n",
            "loss 27.384626388549805 average time 0.0026071450124845797 iter num 160\n",
            "loss 86.13253784179688 average time 0.0025996263944256903 iter num 180\n",
            "loss 10.837212562561035 average time 0.00257025222997072 iter num 200\n",
            "loss 11.725543975830078 average time 0.002551793995437699 iter num 220\n",
            "loss 14.942749977111816 average time 0.0025411764750060684 iter num 240\n",
            "loss 22.147668838500977 average time 0.002551673730788305 iter num 260\n",
            "loss 1.970485806465149 average time 0.0025552229357214983 iter num 280\n",
            "loss 0.000246920099016279 average time 0.0025614853600200147 iter num 300\n",
            "loss 20.2158203125 average time 0.002550872409386784 iter num 320\n",
            "loss 1.3188785314559937 average time 0.0025567631500266813 iter num 340\n",
            "loss 0.22729864716529846 average time 0.0025459317972642264 iter num 360\n",
            "loss 0.058603983372449875 average time 0.0025469144000501392 iter num 380\n",
            "loss 2.4396421909332275 average time 0.0025545939025460027 iter num 400\n",
            "loss 6.1893415451049805 average time 0.002565392890530694 iter num 420\n",
            "loss 0.3133665919303894 average time 0.002567307747780102 iter num 440\n",
            "loss 3.2135744094848633 average time 0.0025827579717849366 iter num 460\n",
            "loss 8.443273544311523 average time 0.002584699343780509 iter num 480\n",
            "loss 1.0991394519805908 average time 0.0025812824820313834 iter num 500\n",
            "loss 29.352649688720703 average time 0.002584831130798193 iter num 520\n",
            "loss 0.8081805109977722 average time 0.002590695224093738 iter num 540\n",
            "loss 0.004371750634163618 average time 0.002600418601806658 iter num 560\n",
            "loss 3.2656872272491455 average time 0.0026042555086421308 iter num 580\n",
            "loss 1.520199179649353 average time 0.0026086567600153406 iter num 600\n",
            "loss 0.19271859526634216 average time 0.0026110905709790513 iter num 620\n",
            "loss 47.5498161315918 average time 0.002613466789082963 iter num 640\n",
            "loss 4.704390048980713 average time 0.0026327348636545084 iter num 660\n",
            "loss 0.16318464279174805 average time 0.0026377746514834356 iter num 680\n",
            "loss 0.5430456399917603 average time 0.002640874661449613 iter num 700\n",
            "loss 0.369828462600708 average time 0.002643771948634013 iter num 720\n",
            "loss 22.246517181396484 average time 0.002648784905436883 iter num 740\n",
            "loss 0.34586378931999207 average time 0.0026545278237144407 iter num 760\n",
            "loss 0.1306958794593811 average time 0.002652383135927476 iter num 780\n",
            "loss 38.24730682373047 average time 0.0026509012500332573 iter num 800\n",
            "loss 0.10009360313415527 average time 0.002652482968325075 iter num 820\n",
            "loss 0.00042990854126401246 average time 0.0026542771345573002 iter num 840\n",
            "loss 0.1375848799943924 average time 0.0026515339198001954 iter num 860\n",
            "loss 71.11932373046875 average time 0.0026549277477587647 iter num 880\n",
            "loss 0.00951952114701271 average time 0.002655471882254561 iter num 900\n",
            "loss 100.8683090209961 average time 0.0026562519717671144 iter num 920\n",
            "loss 9.557320594787598 average time 0.0026580166521485574 iter num 940\n",
            "loss 0.2661376893520355 average time 0.0026597503927215864 iter num 960\n",
            "loss 0.4844997823238373 average time 0.0026584685632769834 iter num 980\n",
            "loss 0.3650745153427124 average time 0.002657531981012653 iter num 1000\n",
            "loss 0.16784971952438354 average time 0.0034404443998937496 iter num 20\n",
            "loss 0.13163761794567108 average time 0.0030834341750960448 iter num 40\n",
            "loss 2.3496153354644775 average time 0.002977035366651156 iter num 60\n",
            "loss 0.01836734637618065 average time 0.0028500729625420716 iter num 80\n",
            "loss 0.42325299978256226 average time 0.002778643930050748 iter num 100\n",
            "loss 0.037297915667295456 average time 0.0027744270083682448 iter num 120\n",
            "loss 0.9168332815170288 average time 0.002760798271460122 iter num 140\n",
            "loss 10.380497932434082 average time 0.002760063400057788 iter num 160\n",
            "loss 3.9702398777008057 average time 0.002754547150056573 iter num 180\n",
            "loss 0.04866946488618851 average time 0.0027450820200465385 iter num 200\n",
            "loss 0.7819464206695557 average time 0.00275612050912638 iter num 220\n",
            "loss 50.836097717285156 average time 0.0027482081125072 iter num 240\n",
            "loss 2.1645612716674805 average time 0.0027741018923384568 iter num 260\n",
            "loss 1.0781292915344238 average time 0.0027702584393019996 iter num 280\n",
            "loss 1.2460333108901978 average time 0.0027931555500193403 iter num 300\n",
            "loss 1.1343213319778442 average time 0.002781703612504316 iter num 320\n",
            "loss 0.22271473705768585 average time 0.0027703030794274286 iter num 340\n",
            "loss 31.805118560791016 average time 0.00276683086391232 iter num 360\n",
            "loss 8.535369873046875 average time 0.0027621372500250705 iter num 380\n",
            "loss 4.405604839324951 average time 0.002759130215017649 iter num 400\n",
            "loss 2.774352550506592 average time 0.002763508280960585 iter num 420\n",
            "loss 32.02182388305664 average time 0.002755283425011095 iter num 440\n",
            "loss 0.04296625033020973 average time 0.0027518454347836784 iter num 460\n",
            "loss 0.7827427387237549 average time 0.0027499428104268493 iter num 480\n",
            "loss 6.679498672485352 average time 0.00275139025399767 iter num 500\n",
            "loss 2.6006996631622314 average time 0.002747076948071481 iter num 520\n",
            "loss 0.014657746069133282 average time 0.002746900246293754 iter num 540\n",
            "loss 7.341769218444824 average time 0.0027451991232088145 iter num 560\n",
            "loss 41.418914794921875 average time 0.0027457132396475886 iter num 580\n",
            "loss 6.640868186950684 average time 0.002748633814993203 iter num 600\n",
            "loss 8.38087272644043 average time 0.0027444999290251403 iter num 620\n",
            "loss 0.09764079004526138 average time 0.0027420542077976505 iter num 640\n",
            "loss 0.36074569821357727 average time 0.0027373066121072044 iter num 660\n",
            "loss 0.04684223234653473 average time 0.0027344508867479496 iter num 680\n",
            "loss 1.877077341079712 average time 0.002732771042841965 iter num 700\n",
            "loss 10.69432544708252 average time 0.0027424450624822486 iter num 720\n",
            "loss 0.5811647176742554 average time 0.0027432530621464704 iter num 740\n",
            "loss 0.01227828860282898 average time 0.0027445172776256904 iter num 760\n",
            "loss 0.005365867633372545 average time 0.0027448044358863674 iter num 780\n",
            "loss 2.354339361190796 average time 0.002741965613743105 iter num 800\n",
            "loss 1.2828525304794312 average time 0.002744293279257119 iter num 820\n",
            "loss 12.778993606567383 average time 0.0027421271702288714 iter num 840\n",
            "loss 51.85929489135742 average time 0.002743911895339447 iter num 860\n",
            "loss 44.44532775878906 average time 0.002743299219305713 iter num 880\n",
            "loss 5.829171180725098 average time 0.0027411179655427984 iter num 900\n",
            "loss 0.00023155183589551598 average time 0.0027507531249897433 iter num 920\n",
            "loss 0.5846639275550842 average time 0.0027476327393529533 iter num 940\n",
            "loss 23.784076690673828 average time 0.0027431576031195465 iter num 960\n",
            "loss 0.015487497672438622 average time 0.002743605106117721 iter num 980\n",
            "loss 18.984865188598633 average time 0.002742302506996566 iter num 1000\n",
            "loss 1.1280795335769653 average time 0.003318557500097086 iter num 20\n",
            "loss 23.351070404052734 average time 0.0029501298251034314 iter num 40\n",
            "loss 0.8950758576393127 average time 0.002839603400055542 iter num 60\n",
            "loss 2.2443387508392334 average time 0.002832008900054461 iter num 80\n",
            "loss 0.5450623035430908 average time 0.002812447370051814 iter num 100\n",
            "loss 0.11597134172916412 average time 0.0028242113416884723 iter num 120\n",
            "loss 12.59400463104248 average time 0.002804862864299399 iter num 140\n",
            "loss 58.24748229980469 average time 0.0027890833375295186 iter num 160\n",
            "loss 8.80315113067627 average time 0.0027662419833682683 iter num 180\n",
            "loss 3.1165738105773926 average time 0.002779294730044057 iter num 200\n",
            "loss 3.3460731506347656 average time 0.002753489468217264 iter num 220\n",
            "loss 7.767391204833984 average time 0.0027624250333625846 iter num 240\n",
            "loss 1.2716144323349 average time 0.002758294676984336 iter num 260\n",
            "loss 0.06786175072193146 average time 0.002750405667926056 iter num 280\n",
            "loss 20.85352897644043 average time 0.0027511957133901886 iter num 300\n",
            "loss 26.279624938964844 average time 0.0027769513156727043 iter num 320\n",
            "loss 1.0143446922302246 average time 0.002765989602989173 iter num 340\n",
            "loss 2.4069106578826904 average time 0.002760733622259674 iter num 360\n",
            "loss 27.42041015625 average time 0.002758583405289085 iter num 380\n",
            "loss 50.30180740356445 average time 0.00275398415501968 iter num 400\n",
            "loss 9.150773048400879 average time 0.0027325427666775276 iter num 420\n",
            "loss 0.27375948429107666 average time 0.002717547206831031 iter num 440\n",
            "loss 7.027320861816406 average time 0.002710640476087302 iter num 460\n",
            "loss 0.1812697798013687 average time 0.002699965175001277 iter num 480\n",
            "loss 0.17766167223453522 average time 0.0026843429100044886 iter num 500\n",
            "loss 25.21760368347168 average time 0.002676709946147709 iter num 520\n",
            "loss 0.6224036812782288 average time 0.0026733601129645076 iter num 540\n",
            "loss 12.594559669494629 average time 0.0026646929928574536 iter num 560\n",
            "loss 0.12382883578538895 average time 0.00265633876724678 iter num 580\n",
            "loss 0.994712233543396 average time 0.0026558432266695796 iter num 600\n",
            "loss 0.6419106125831604 average time 0.0026453889483843427 iter num 620\n",
            "loss 0.0004557692154776305 average time 0.0026350020734412284 iter num 640\n",
            "loss 0.034287285059690475 average time 0.0026229645409164897 iter num 660\n",
            "loss 15.016098022460938 average time 0.0026166917220667957 iter num 680\n",
            "loss 0.21988005936145782 average time 0.0026073848828595406 iter num 700\n",
            "loss 0.4176757335662842 average time 0.002601547768055449 iter num 720\n",
            "loss 4.6537909507751465 average time 0.0025953689810882456 iter num 740\n",
            "loss 0.6213380098342896 average time 0.002594966456586247 iter num 760\n",
            "loss 0.376816064119339 average time 0.002588183994880521 iter num 780\n",
            "loss 0.25883767008781433 average time 0.0025840343175150336 iter num 800\n",
            "loss 2.9244751930236816 average time 0.0025794283634240855 iter num 820\n",
            "loss 4.460026264190674 average time 0.0025728610500036233 iter num 840\n",
            "loss 0.8995214104652405 average time 0.0025672023651210577 iter num 860\n",
            "loss 2.3157505989074707 average time 0.002567341029552236 iter num 880\n",
            "loss 0.2714289724826813 average time 0.00257579829001568 iter num 900\n",
            "loss 0.03969376161694527 average time 0.002577805054362097 iter num 920\n",
            "loss 0.22438043355941772 average time 0.002584942504271315 iter num 940\n",
            "loss 3.236825704574585 average time 0.0025878845479288277 iter num 960\n",
            "loss 40.99352264404297 average time 0.0025896387224654937 iter num 980\n",
            "loss 0.10870994627475739 average time 0.0025955148600187387 iter num 1000\n",
            "loss 2.609746217727661 average time 0.003672214000107488 iter num 20\n",
            "loss 0.10280339419841766 average time 0.003188249975028157 iter num 40\n",
            "loss 0.4261597692966461 average time 0.003042165983333689 iter num 60\n",
            "loss 0.9955874681472778 average time 0.002936336674952145 iter num 80\n",
            "loss 1.2111214399337769 average time 0.0028680947599423233 iter num 100\n",
            "loss 3.8144290447235107 average time 0.002835961608343496 iter num 120\n",
            "loss 6.022727012634277 average time 0.0028108134142712515 iter num 140\n",
            "loss 0.027217119932174683 average time 0.0028186023999637656 iter num 160\n",
            "loss 13.142643928527832 average time 0.0027944733555260526 iter num 180\n",
            "loss 1.4594006538391113 average time 0.0027911264349586417 iter num 200\n",
            "loss 7.061852931976318 average time 0.002784897395411628 iter num 220\n",
            "loss 7.4869866371154785 average time 0.0027712892582940187 iter num 240\n",
            "loss 0.46817702054977417 average time 0.0027534831691879776 iter num 260\n",
            "loss 50.203372955322266 average time 0.0027549778821009696 iter num 280\n",
            "loss 0.23770758509635925 average time 0.0027433503933085982 iter num 300\n",
            "loss 19.523250579833984 average time 0.0027352742499942907 iter num 320\n",
            "loss 16.947778701782227 average time 0.0027256183382312026 iter num 340\n",
            "loss 4.181018829345703 average time 0.0027234872416708336 iter num 360\n",
            "loss 8.528616905212402 average time 0.0027335405579019846 iter num 380\n",
            "loss 0.7131892442703247 average time 0.002731926454994209 iter num 400\n",
            "loss 34.41350555419922 average time 0.0027293533571320864 iter num 420\n",
            "loss 3.32757568359375 average time 0.0027281207477203267 iter num 440\n",
            "loss 0.23507575690746307 average time 0.0027414336434839755 iter num 460\n",
            "loss 0.12635281682014465 average time 0.0027352910187498007 iter num 480\n",
            "loss 23.173412322998047 average time 0.002733942452006886 iter num 500\n",
            "loss 1.5073111057281494 average time 0.0027251793500174524 iter num 520\n",
            "loss 2.2994439601898193 average time 0.0027249947000132966 iter num 540\n",
            "loss 3.8569841384887695 average time 0.0027144938785795603 iter num 560\n",
            "loss 0.6646244525909424 average time 0.0027136129879432574 iter num 580\n",
            "loss 0.8424985408782959 average time 0.0027269452383522244 iter num 600\n",
            "loss 4.240258693695068 average time 0.0027292024903339727 iter num 620\n",
            "loss 2.3589539527893066 average time 0.002727523753142691 iter num 640\n",
            "loss 0.000593813369050622 average time 0.002717374998497469 iter num 660\n",
            "loss 0.22527216374874115 average time 0.002716086436772885 iter num 680\n",
            "loss 8.434940338134766 average time 0.002717832192858103 iter num 700\n",
            "loss 0.0008445463026873767 average time 0.0027139282208332185 iter num 720\n",
            "loss 0.2490563988685608 average time 0.002712777294596595 iter num 740\n",
            "loss 8.982064247131348 average time 0.002716140709212835 iter num 760\n",
            "loss 1.281052589416504 average time 0.002710636920519158 iter num 780\n",
            "loss 0.26904040575027466 average time 0.0027089637462586326 iter num 800\n",
            "loss 0.011320861056447029 average time 0.002721893118299837 iter num 820\n",
            "loss 0.018656698986887932 average time 0.0027203989678647694 iter num 840\n",
            "loss 0.036134276539087296 average time 0.0027212389848881324 iter num 860\n",
            "loss 13.150957107543945 average time 0.0027247552761392314 iter num 880\n",
            "loss 1.3393322229385376 average time 0.0027244055744449725 iter num 900\n",
            "loss 9.6690673828125 average time 0.00272308925652159 iter num 920\n",
            "loss 0.09532982110977173 average time 0.0027164644872368143 iter num 940\n",
            "loss 0.06460721045732498 average time 0.002716264950006083 iter num 960\n",
            "loss 2.5500316619873047 average time 0.0027147195296010423 iter num 980\n",
            "loss 1.889282464981079 average time 0.0027127138770083547 iter num 1000\n",
            "loss 2.660423994064331 average time 0.003593992449987127 iter num 20\n",
            "loss 20.42926597595215 average time 0.0034137170750000224 iter num 40\n",
            "loss 22.792552947998047 average time 0.003163141083496157 iter num 60\n",
            "loss 58.826881408691406 average time 0.0030483357251569034 iter num 80\n",
            "loss 1.4667391777038574 average time 0.002971814770171477 iter num 100\n",
            "loss 1.3063075542449951 average time 0.0029319737834915334 iter num 120\n",
            "loss 59.37446212768555 average time 0.0028582713715747687 iter num 140\n",
            "loss 0.2544138431549072 average time 0.002839113056381848 iter num 160\n",
            "loss 1.0279115438461304 average time 0.002841789955709828 iter num 180\n",
            "loss 0.44170886278152466 average time 0.0028261496251525387 iter num 200\n",
            "loss 0.0044912248849868774 average time 0.0028021762865219815 iter num 220\n",
            "loss 156.13442993164062 average time 0.0027724329418409373 iter num 240\n",
            "loss 310.6196594238281 average time 0.002772331980913105 iter num 260\n",
            "loss 1.4343808889389038 average time 0.002750340960840601 iter num 280\n",
            "loss 0.02212182991206646 average time 0.002752669973451702 iter num 300\n",
            "loss 0.9644295573234558 average time 0.0027696439032467877 iter num 320\n",
            "loss 0.010810840874910355 average time 0.00276041175599376 iter num 340\n",
            "loss 3.6717851161956787 average time 0.002755823416782732 iter num 360\n",
            "loss 0.9087197780609131 average time 0.002753785534318204 iter num 380\n",
            "loss 4.915507793426514 average time 0.0027396474400984516 iter num 400\n",
            "loss 0.007894919253885746 average time 0.0027350782286789796 iter num 420\n",
            "loss 0.003264583647251129 average time 0.0027318611296447094 iter num 440\n",
            "loss 0.000839090149383992 average time 0.002733207206616182 iter num 460\n",
            "loss 0.95883709192276 average time 0.0027322408375880514 iter num 480\n",
            "loss 0.0029371418058872223 average time 0.002730488320088625 iter num 500\n",
            "loss 12.268753051757812 average time 0.0027185141250846267 iter num 520\n",
            "loss 15.245678901672363 average time 0.002719624024158057 iter num 540\n",
            "loss 0.9712071418762207 average time 0.002720600889356969 iter num 560\n",
            "loss 0.7772377133369446 average time 0.00271879962765838 iter num 580\n",
            "loss 8.611927032470703 average time 0.0027087768667388447 iter num 600\n",
            "loss 3.5782718658447266 average time 0.002698692877478489 iter num 620\n",
            "loss 111.81119537353516 average time 0.002704183687555428 iter num 640\n",
            "loss 7.4998345375061035 average time 0.002704621256116573 iter num 660\n",
            "loss 0.00817972980439663 average time 0.0027010554750471357 iter num 680\n",
            "loss 1.130242109298706 average time 0.0026969178914753554 iter num 700\n",
            "loss 0.01624131202697754 average time 0.002697769431996575 iter num 720\n",
            "loss 0.5222746133804321 average time 0.0026955205460015693 iter num 740\n",
            "loss 0.15019407868385315 average time 0.0026987327579502704 iter num 760\n",
            "loss 16.430221557617188 average time 0.002699501974408728 iter num 780\n",
            "loss 1.3276499509811401 average time 0.002696763650048979 iter num 800\n",
            "loss 0.08316943049430847 average time 0.002694580543953723 iter num 820\n",
            "loss 13.201983451843262 average time 0.0026855846286187963 iter num 840\n",
            "loss 25.39922523498535 average time 0.0026852582616748106 iter num 860\n",
            "loss 0.012926850467920303 average time 0.0026796176750436148 iter num 880\n",
            "loss 3.267810821533203 average time 0.0026716015655963727 iter num 900\n",
            "loss 0.4071906507015228 average time 0.0026679276315640576 iter num 920\n",
            "loss 132.59011840820312 average time 0.0026632632862082515 iter num 940\n",
            "loss 0.6660707592964172 average time 0.0026619126625386496 iter num 960\n",
            "loss 0.008292039856314659 average time 0.002655961681670751 iter num 980\n",
            "loss 2.9284820556640625 average time 0.002649820728029226 iter num 1000\n",
            "loss 0.00638648122549057 average time 0.0031090613499145546 iter num 20\n",
            "loss 0.36424973607063293 average time 0.002788257674956185 iter num 40\n",
            "loss 0.046036798506975174 average time 0.002627108149954438 iter num 60\n",
            "loss 28.677614212036133 average time 0.0025554418500405517 iter num 80\n",
            "loss 0.03906803950667381 average time 0.0025396286200157193 iter num 100\n",
            "loss 0.07961738109588623 average time 0.002512121708302099 iter num 120\n",
            "loss 44.678279876708984 average time 0.0024920868928217845 iter num 140\n",
            "loss 27.53887367248535 average time 0.0024721757874772267 iter num 160\n",
            "loss 7.080896854400635 average time 0.0024645517888529866 iter num 180\n",
            "loss 15.226946830749512 average time 0.0024521619099596137 iter num 200\n",
            "loss 32.15536880493164 average time 0.0024592774726856573 iter num 220\n",
            "loss 3.926382541656494 average time 0.0024536901249727332 iter num 240\n",
            "loss 0.7574815154075623 average time 0.002482590338450581 iter num 260\n",
            "loss 4.6952104568481445 average time 0.002497171782130993 iter num 280\n",
            "loss 40.72003936767578 average time 0.002488065193319926 iter num 300\n",
            "loss 21.77953338623047 average time 0.002480108715616325 iter num 320\n",
            "loss 5.809625625610352 average time 0.00249755228528289 iter num 340\n",
            "loss 154.70773315429688 average time 0.0025127434833140997 iter num 360\n",
            "loss 0.9920414090156555 average time 0.0025300255605160554 iter num 380\n",
            "loss 4.04734992980957 average time 0.0025319458624926483 iter num 400\n",
            "loss 0.0067116133868694305 average time 0.002526914650003337 iter num 420\n",
            "loss 11.518077850341797 average time 0.002517592286378865 iter num 440\n",
            "loss 0.0022964824456721544 average time 0.0025124189891397217 iter num 460\n",
            "loss 0.5035919547080994 average time 0.0025068509749947526 iter num 480\n",
            "loss 0.23699764907360077 average time 0.002514735775996087 iter num 500\n",
            "loss 0.5491561889648438 average time 0.002505688426918613 iter num 520\n",
            "loss 6.567070960998535 average time 0.0025105609629631712 iter num 540\n",
            "loss 4.16281795501709 average time 0.0025073231589236196 iter num 560\n",
            "loss 1.409159779548645 average time 0.002509375779306444 iter num 580\n",
            "loss 8.637155532836914 average time 0.0025015783366567727 iter num 600\n",
            "loss 2.411860704421997 average time 0.0025104695628890054 iter num 620\n",
            "loss 11.870020866394043 average time 0.0025046653218566916 iter num 640\n",
            "loss 1.1230449676513672 average time 0.0025044430848317986 iter num 660\n",
            "loss 5.172195911407471 average time 0.0025086637293925914 iter num 680\n",
            "loss 0.14560647308826447 average time 0.002502711802839518 iter num 700\n",
            "loss 6.529780864715576 average time 0.002497070565262523 iter num 720\n",
            "loss 2.164987802505493 average time 0.002499459835121957 iter num 740\n",
            "loss 0.00011055669892812148 average time 0.002496817547348416 iter num 760\n",
            "loss 1.0920850038528442 average time 0.002494474724332973 iter num 780\n",
            "loss 2.2614471912384033 average time 0.002510537368734731 iter num 800\n",
            "loss 0.8814758658409119 average time 0.0025108590719311197 iter num 820\n",
            "loss 2.296332836151123 average time 0.0025071529952150565 iter num 840\n",
            "loss 0.02558118663728237 average time 0.0025031029302142065 iter num 860\n",
            "loss 0.8655392527580261 average time 0.0025000695022547666 iter num 880\n",
            "loss 0.3125556707382202 average time 0.002501814102201428 iter num 900\n",
            "loss 22.2666015625 average time 0.0024988029695459375 iter num 920\n",
            "loss 0.27568429708480835 average time 0.002494472949980805 iter num 940\n",
            "loss 0.013691813684999943 average time 0.002490225509357439 iter num 960\n",
            "loss 0.01569373905658722 average time 0.0024876161969271436 iter num 980\n",
            "loss 0.05653823912143707 average time 0.0024840729489842488 iter num 1000\n",
            "loss 2.2343990802764893 average time 0.003933421049987373 iter num 20\n",
            "loss 0.33247095346450806 average time 0.003337665450044369 iter num 40\n",
            "loss 0.7686727643013 average time 0.0030376602334702815 iter num 60\n",
            "loss 1.7823652029037476 average time 0.0028525742751071446 iter num 80\n",
            "loss 13.142229080200195 average time 0.0028007659100876482 iter num 100\n",
            "loss 4.673525333404541 average time 0.0027325844501168224 iter num 120\n",
            "loss 1.3710299730300903 average time 0.0026719918786901483 iter num 140\n",
            "loss 0.31346482038497925 average time 0.0026288503438422596 iter num 160\n",
            "loss 32.909400939941406 average time 0.0025947856945499046 iter num 180\n",
            "loss 27.58197021484375 average time 0.002600218500092524 iter num 200\n",
            "loss 0.6122006773948669 average time 0.0025770286364439183 iter num 220\n",
            "loss 11.229494094848633 average time 0.0025750156000640344 iter num 240\n",
            "loss 0.7661493420600891 average time 0.002556207957758698 iter num 260\n",
            "loss 1.1763724088668823 average time 0.0025513929286587102 iter num 280\n",
            "loss 0.05031593143939972 average time 0.0025349619467488083 iter num 300\n",
            "loss 27.467533111572266 average time 0.0025199464282081863 iter num 320\n",
            "loss 1.449331521987915 average time 0.0025086136294756966 iter num 340\n",
            "loss 0.44951117038726807 average time 0.0025339617222875353 iter num 360\n",
            "loss 16.1276798248291 average time 0.002534553944803376 iter num 380\n",
            "loss 46.755287170410156 average time 0.002524044940050771 iter num 400\n",
            "loss 0.04870292916893959 average time 0.0025152864809959803 iter num 420\n",
            "loss 20.03934669494629 average time 0.00250876933186274 iter num 440\n",
            "loss 64.03076171875 average time 0.002503711480474759 iter num 460\n",
            "loss 1.0451611280441284 average time 0.002511361139621234 iter num 480\n",
            "loss 0.20749904215335846 average time 0.0025034851720483857 iter num 500\n",
            "loss 13.306809425354004 average time 0.0024972358442902566 iter num 520\n",
            "loss 2.1975066661834717 average time 0.0025008972982134394 iter num 540\n",
            "loss 0.01987549662590027 average time 0.002496168319700181 iter num 560\n",
            "loss 0.8007407784461975 average time 0.002487779948331018 iter num 580\n",
            "loss 2.0933854579925537 average time 0.0024917077550495985 iter num 600\n",
            "loss 152.02066040039062 average time 0.002487556935527884 iter num 620\n",
            "loss 1.5319898128509521 average time 0.002487771518795512 iter num 640\n",
            "loss 15.048577308654785 average time 0.0024955450106559016 iter num 660\n",
            "loss 1.399052619934082 average time 0.0024997419073984287 iter num 680\n",
            "loss 6.324914932250977 average time 0.002495006071478981 iter num 700\n",
            "loss 20.346933364868164 average time 0.0024974415486566513 iter num 720\n",
            "loss 16.80004119873047 average time 0.0024995428230205428 iter num 740\n",
            "loss 14.188899993896484 average time 0.0024988821434649973 iter num 760\n",
            "loss 2.1224842071533203 average time 0.0024951167564536145 iter num 780\n",
            "loss 6.489078998565674 average time 0.0024921960875531114 iter num 800\n",
            "loss 0.25977250933647156 average time 0.00248823583785962 iter num 820\n",
            "loss 0.12740567326545715 average time 0.002486665594094683 iter num 840\n",
            "loss 0.034412071108818054 average time 0.002484839704691187 iter num 860\n",
            "loss 42.61254119873047 average time 0.002483622806857966 iter num 880\n",
            "loss 0.10584133118391037 average time 0.002481202282261721 iter num 900\n",
            "loss 0.13180360198020935 average time 0.0024815003272064843 iter num 920\n",
            "loss 1.2204002141952515 average time 0.0024797587936518537 iter num 940\n",
            "loss 0.4621618092060089 average time 0.0024816631885698826 iter num 960\n",
            "loss 2.6925485134124756 average time 0.002478567176555715 iter num 980\n",
            "loss 2.1222286224365234 average time 0.0024797380640302433 iter num 1000\n",
            "loss 0.7841540575027466 average time 0.0029951391499707823 iter num 20\n",
            "loss 3.729334592819214 average time 0.002756529650059747 iter num 40\n",
            "loss 0.7341521382331848 average time 0.002604735916762972 iter num 60\n",
            "loss 0.008940054103732109 average time 0.002549270300005446 iter num 80\n",
            "loss 0.3096250593662262 average time 0.0025060219999795664 iter num 100\n",
            "loss 0.8610875010490417 average time 0.0025236471583108748 iter num 120\n",
            "loss 0.7538554072380066 average time 0.0025042449500038595 iter num 140\n",
            "loss 0.3401642143726349 average time 0.0025193416000206525 iter num 160\n",
            "loss 0.00026663008611649275 average time 0.0025306664500223835 iter num 180\n",
            "loss 0.43811607360839844 average time 0.002510530275039855 iter num 200\n",
            "loss 4.586457252502441 average time 0.0025022615318531197 iter num 220\n",
            "loss 1.9838721752166748 average time 0.0024909826333517535 iter num 240\n",
            "loss 6.460124492645264 average time 0.0024973511307857382 iter num 260\n",
            "loss 2.2523581981658936 average time 0.0025011263071454386 iter num 280\n",
            "loss 3.5850799083709717 average time 0.00249417499335929 iter num 300\n",
            "loss 1.2479630708694458 average time 0.002498267046905767 iter num 320\n",
            "loss 5.696025848388672 average time 0.0025073174412147425 iter num 340\n",
            "loss 8.126753807067871 average time 0.0024977498111537796 iter num 360\n",
            "loss 0.6376777291297913 average time 0.002487328092143128 iter num 380\n",
            "loss 156.692626953125 average time 0.0024914991700279642 iter num 400\n",
            "loss 15.143315315246582 average time 0.0024820597928737697 iter num 420\n",
            "loss 1.1338529586791992 average time 0.002475407522747859 iter num 440\n",
            "loss 15.712606430053711 average time 0.0024686894674153374 iter num 460\n",
            "loss 142.92425537109375 average time 0.002464838414607584 iter num 480\n",
            "loss 1.6897202730178833 average time 0.00247522401603419 iter num 500\n",
            "loss 0.014833716675639153 average time 0.002470280092351319 iter num 520\n",
            "loss 0.08779986947774887 average time 0.002466443927813897 iter num 540\n",
            "loss 1.21318781375885 average time 0.002469128307182343 iter num 560\n",
            "loss 3.9834156036376953 average time 0.0024721308396880794 iter num 580\n",
            "loss 0.031888533383607864 average time 0.0024651535917049236 iter num 600\n",
            "loss 0.19955545663833618 average time 0.002481701080690865 iter num 620\n",
            "loss 1.3485040664672852 average time 0.002478202345363911 iter num 640\n",
            "loss 0.4721764326095581 average time 0.002475037721265063 iter num 660\n",
            "loss 715.4388427734375 average time 0.002471016547111931 iter num 680\n",
            "loss 20.67643165588379 average time 0.0024693923529100306 iter num 700\n",
            "loss 11.050430297851562 average time 0.00246698388338397 iter num 720\n",
            "loss 0.33827653527259827 average time 0.0024629898878825965 iter num 740\n",
            "loss 0.8761332631111145 average time 0.002459420393468367 iter num 760\n",
            "loss 0.6476447582244873 average time 0.002466520625682442 iter num 780\n",
            "loss 0.009159483015537262 average time 0.002463051097533935 iter num 800\n",
            "loss 0.09063082188367844 average time 0.0024602561744203983 iter num 820\n",
            "loss 35.5944709777832 average time 0.0024580736774125747 iter num 840\n",
            "loss 1.5444327592849731 average time 0.002455376447706776 iter num 860\n",
            "loss 205.0267791748047 average time 0.00245170535344476 iter num 880\n",
            "loss 37.464332580566406 average time 0.00245108046669783 iter num 900\n",
            "loss 1.9236449003219604 average time 0.002449371092416186 iter num 920\n",
            "loss 0.3851233422756195 average time 0.0024491588298104112 iter num 940\n",
            "loss 0.13891363143920898 average time 0.0024453470354387718 iter num 960\n",
            "loss 21.388084411621094 average time 0.0024487069663504074 iter num 980\n",
            "loss 1.1156350374221802 average time 0.00246720027302581 iter num 1000\n",
            "loss 10.53593635559082 average time 0.00324283119998654 iter num 20\n",
            "loss 10.525485038757324 average time 0.002941761499914719 iter num 40\n",
            "loss 0.58216392993927 average time 0.0028659815999162674 iter num 60\n",
            "loss 7.242065906524658 average time 0.0028132271499089257 iter num 80\n",
            "loss 216.69236755371094 average time 0.002788391919930291 iter num 100\n",
            "loss 0.25321462750434875 average time 0.002772911666609919 iter num 120\n",
            "loss 8.340117454528809 average time 0.002753035935659552 iter num 140\n",
            "loss 1.050495982170105 average time 0.0027237072187176635 iter num 160\n",
            "loss 31.225543975830078 average time 0.0027280956944196076 iter num 180\n",
            "loss 0.039461586624383926 average time 0.002722676045004846 iter num 200\n",
            "loss 237.84104919433594 average time 0.002747213404580345 iter num 220\n",
            "loss 1.9535582065582275 average time 0.002738720150030834 iter num 240\n",
            "loss 3.032904863357544 average time 0.0027361857115675565 iter num 260\n",
            "loss 0.30882421135902405 average time 0.0027422860607592674 iter num 280\n",
            "loss 0.11195618659257889 average time 0.0027429961733650998 iter num 300\n",
            "loss 0.6343032121658325 average time 0.0027475141656566394 iter num 320\n",
            "loss 0.006446916610002518 average time 0.0027469220500172336 iter num 340\n",
            "loss 10.062225341796875 average time 0.0027519004277969036 iter num 360\n",
            "loss 0.0934797152876854 average time 0.0027521795368652658 iter num 380\n",
            "loss 0.32747048139572144 average time 0.0027385607225096464 iter num 400\n",
            "loss 2.9813342094421387 average time 0.0027425948738276757 iter num 420\n",
            "loss 0.0008188181091099977 average time 0.002741771220483067 iter num 440\n",
            "loss 67.73641204833984 average time 0.002735973063060911 iter num 460\n",
            "loss 0.737502932548523 average time 0.002733415297927877 iter num 480\n",
            "loss 0.7750230431556702 average time 0.002729173930012621 iter num 500\n",
            "loss 4.680591106414795 average time 0.002723551388470906 iter num 520\n",
            "loss 0.07837355136871338 average time 0.002728993046295929 iter num 540\n",
            "loss 13.753849029541016 average time 0.0027323338678538027 iter num 560\n",
            "loss 0.14159610867500305 average time 0.0027311213982729584 iter num 580\n",
            "loss 1.1171568632125854 average time 0.0027328373166710662 iter num 600\n",
            "loss 24.250883102416992 average time 0.0027298074935559625 iter num 620\n",
            "loss 0.1581999510526657 average time 0.002726835342187428 iter num 640\n",
            "loss 1.9178928136825562 average time 0.002737688606066513 iter num 660\n",
            "loss 2.9018824100494385 average time 0.002751756930889742 iter num 680\n",
            "loss 9.666315078735352 average time 0.002754078660010626 iter num 700\n",
            "loss 0.08925874531269073 average time 0.0027553486847359133 iter num 720\n",
            "loss 7.434631824493408 average time 0.0027525142905565065 iter num 740\n",
            "loss 1.101120948791504 average time 0.0027511364250107076 iter num 760\n",
            "loss 2.4791977405548096 average time 0.0027521981782159016 iter num 780\n",
            "loss 0.027758575975894928 average time 0.002750797621260972 iter num 800\n",
            "loss 12.427437782287598 average time 0.0027487629231783524 iter num 820\n",
            "loss 32.9459114074707 average time 0.002748347345240767 iter num 840\n",
            "loss 8.278923034667969 average time 0.002740479516272222 iter num 860\n",
            "loss 147.16293334960938 average time 0.002739273972724732 iter num 880\n",
            "loss 1.137055516242981 average time 0.0027422011788864136 iter num 900\n",
            "loss 1.6522737741470337 average time 0.002738959904346579 iter num 920\n",
            "loss 7.269069671630859 average time 0.0027376347085087314 iter num 940\n",
            "loss 150.31719970703125 average time 0.002736488666666522 iter num 960\n",
            "loss 0.14279624819755554 average time 0.0027330626704088917 iter num 980\n",
            "loss 7.6658034324646 average time 0.0027332448849992945 iter num 1000\n",
            "loss 0.10992579907178879 average time 0.0031321352496888723 iter num 20\n",
            "loss 1.748923659324646 average time 0.0028526729749046354 iter num 40\n",
            "loss 0.05946281924843788 average time 0.002821316799872875 iter num 60\n",
            "loss 13.145589828491211 average time 0.002700367762463429 iter num 80\n",
            "loss 5.993816375732422 average time 0.002687550409918913 iter num 100\n",
            "loss 18.401521682739258 average time 0.0027408170249448934 iter num 120\n",
            "loss 8.448129653930664 average time 0.0026900579570922544 iter num 140\n",
            "loss 26.555923461914062 average time 0.002684030831198925 iter num 160\n",
            "loss 19.578086853027344 average time 0.0026828090054651613 iter num 180\n",
            "loss 4.109349250793457 average time 0.0026763214299171524 iter num 200\n",
            "loss 0.9878107905387878 average time 0.002685451136312622 iter num 220\n",
            "loss 0.9272171258926392 average time 0.0026943903707736657 iter num 240\n",
            "loss 0.2802754044532776 average time 0.0026882220538027466 iter num 260\n",
            "loss 13.577576637268066 average time 0.0026861571570991924 iter num 280\n",
            "loss 2.4001922607421875 average time 0.002695220353301314 iter num 300\n",
            "loss 3.9593324661254883 average time 0.002689895143720378 iter num 320\n",
            "loss 40.36343002319336 average time 0.0026912739146877462 iter num 340\n",
            "loss 0.0023566982708871365 average time 0.002691555702757695 iter num 360\n",
            "loss 2.3065006732940674 average time 0.00269605560788956 iter num 380\n",
            "loss 15.012284278869629 average time 0.0026923169374913412 iter num 400\n",
            "loss 67.24795532226562 average time 0.002689122935706629 iter num 420\n",
            "loss 3.18105149269104 average time 0.002690241965902632 iter num 440\n",
            "loss 1.347110629081726 average time 0.002688520371734542 iter num 460\n",
            "loss 2.6774685382843018 average time 0.002687091031248201 iter num 480\n",
            "loss 1.2083523273468018 average time 0.0026838090180062862 iter num 500\n",
            "loss 0.1763736605644226 average time 0.0026874377076952583 iter num 520\n",
            "loss 5.4865498542785645 average time 0.0026843840592543225 iter num 540\n",
            "loss 0.008484610356390476 average time 0.002684998323200359 iter num 560\n",
            "loss 7.020809650421143 average time 0.0026840228585946345 iter num 580\n",
            "loss 0.01919427327811718 average time 0.002698164883310407 iter num 600\n",
            "loss 8.050704956054688 average time 0.0027003839048149766 iter num 620\n",
            "loss 29.626008987426758 average time 0.0026978933906036673 iter num 640\n",
            "loss 1.4502969980239868 average time 0.002695796495432164 iter num 660\n",
            "loss 8.50350284576416 average time 0.0026904834896787876 iter num 680\n",
            "loss 2.1492106914520264 average time 0.002688388844266488 iter num 700\n",
            "loss 0.3225516378879547 average time 0.0026864390763623506 iter num 720\n",
            "loss 0.4209957420825958 average time 0.002686609936451557 iter num 740\n",
            "loss 0.026276975870132446 average time 0.0026851017999649086 iter num 760\n",
            "loss 0.03915384039282799 average time 0.0026991272050952086 iter num 780\n",
            "loss 2.3330352306365967 average time 0.0026926955587191514 iter num 800\n",
            "loss 1.786676287651062 average time 0.00269339227801893 iter num 820\n",
            "loss 0.0015759363304823637 average time 0.0027058867773489294 iter num 840\n",
            "loss 1.0943145751953125 average time 0.0027036117127609877 iter num 860\n",
            "loss 27.9857234954834 average time 0.002702078357932888 iter num 880\n",
            "loss 0.417394757270813 average time 0.002701463831092244 iter num 900\n",
            "loss 0.08439727127552032 average time 0.0026949390445541056 iter num 920\n",
            "loss 1.9238035678863525 average time 0.002687631506370885 iter num 940\n",
            "loss 4.784555435180664 average time 0.0026791254093628445 iter num 960\n",
            "loss 0.40333428978919983 average time 0.0026750916846882615 iter num 980\n",
            "loss 0.1409928798675537 average time 0.002676259215993923 iter num 1000\n",
            "loss 0.040203504264354706 average time 0.003286607900099625 iter num 20\n",
            "loss 0.5721840262413025 average time 0.0027927886001180013 iter num 40\n",
            "loss 8.476781845092773 average time 0.0026597483334929468 iter num 60\n",
            "loss 11.400978088378906 average time 0.002749622225132953 iter num 80\n",
            "loss 50.67173385620117 average time 0.002733838400054083 iter num 100\n",
            "loss 0.17612259089946747 average time 0.002670376183383875 iter num 120\n",
            "loss 0.7492520213127136 average time 0.002610636221457493 iter num 140\n",
            "loss 11.747114181518555 average time 0.0025752792312687236 iter num 160\n",
            "loss 2.405111789703369 average time 0.002594414405575662 iter num 180\n",
            "loss 10.820842742919922 average time 0.002562731435018577 iter num 200\n",
            "loss 7.432229518890381 average time 0.0025463952636693484 iter num 220\n",
            "loss 4.9161505699157715 average time 0.002537697550026981 iter num 240\n",
            "loss 5.158895969390869 average time 0.0025524024423598 iter num 260\n",
            "loss 0.8576077818870544 average time 0.0025322799464772418 iter num 280\n",
            "loss 29.00839614868164 average time 0.0025253007633909874 iter num 300\n",
            "loss 7.144094467163086 average time 0.0025133931375307837 iter num 320\n",
            "loss 0.22182366251945496 average time 0.0025171518823780764 iter num 340\n",
            "loss 134.30343627929688 average time 0.0025084503694567197 iter num 360\n",
            "loss 2.6915502548217773 average time 0.0024972485552720363 iter num 380\n",
            "loss 0.03345361351966858 average time 0.002493945552510013 iter num 400\n",
            "loss 1.1380279064178467 average time 0.002501783433351756 iter num 420\n",
            "loss 0.05945032089948654 average time 0.0024966513727576966 iter num 440\n",
            "loss 4.061135292053223 average time 0.0024922320109038516 iter num 460\n",
            "loss 2.36197829246521 average time 0.002492596622941316 iter num 480\n",
            "loss 0.36961737275123596 average time 0.0024971620780233936 iter num 500\n",
            "loss 10.894627571105957 average time 0.002496420800022091 iter num 520\n",
            "loss 5.196828842163086 average time 0.0024901540074299395 iter num 540\n",
            "loss 167.7650604248047 average time 0.002502048326800832 iter num 560\n",
            "loss 0.1930208057165146 average time 0.0025014222706980444 iter num 580\n",
            "loss 0.00824105553328991 average time 0.002492605778346236 iter num 600\n",
            "loss 9.52263355255127 average time 0.002487981566146998 iter num 620\n",
            "loss 3.1046206951141357 average time 0.002497210357819313 iter num 640\n",
            "loss 0.007559360004961491 average time 0.0024944625454653845 iter num 660\n",
            "loss 0.43892672657966614 average time 0.0024976673220728973 iter num 680\n",
            "loss 103.55366516113281 average time 0.0025020608328694444 iter num 700\n",
            "loss 0.3959646224975586 average time 0.0025007441402825257 iter num 720\n",
            "loss 0.2979676127433777 average time 0.002499436758109762 iter num 740\n",
            "loss 0.44172218441963196 average time 0.0025016287710514008 iter num 760\n",
            "loss 0.8083277940750122 average time 0.0025027974640975934 iter num 780\n",
            "loss 0.31514647603034973 average time 0.0024994856424996213 iter num 800\n",
            "loss 1.3688912391662598 average time 0.002500337735368592 iter num 820\n",
            "loss 0.2586539387702942 average time 0.0024986479869095915 iter num 840\n",
            "loss 0.478421151638031 average time 0.0025016364116264983 iter num 860\n",
            "loss 7.938548564910889 average time 0.0025040715250022254 iter num 880\n",
            "loss 0.006969712674617767 average time 0.0024996213877804823 iter num 900\n",
            "loss 101.86715698242188 average time 0.002497074831531474 iter num 920\n",
            "loss 49.3996467590332 average time 0.002493415574476688 iter num 940\n",
            "loss 4.677455425262451 average time 0.002497822011470892 iter num 960\n",
            "loss 0.12861356139183044 average time 0.002506675527558623 iter num 980\n",
            "loss 0.30436158180236816 average time 0.0025042256350079695 iter num 1000\n",
            "loss 0.7420283555984497 average time 0.0034256077501595428 iter num 20\n",
            "loss 16.205827713012695 average time 0.0028971482252472926 iter num 40\n",
            "loss 36.1309928894043 average time 0.002798207316876263 iter num 60\n",
            "loss 0.7707454562187195 average time 0.002685685562641993 iter num 80\n",
            "loss 12.739505767822266 average time 0.002664870740118204 iter num 100\n",
            "loss 11.121137619018555 average time 0.0026069698917732848 iter num 120\n",
            "loss 7.743459224700928 average time 0.0025653653286358997 iter num 140\n",
            "loss 1.3541091680526733 average time 0.0025306487750412997 iter num 160\n",
            "loss 0.6108784079551697 average time 0.0025480893500369147 iter num 180\n",
            "loss 0.4051581919193268 average time 0.0025713248650572496 iter num 200\n",
            "loss 1.0012134313583374 average time 0.0025496748773135053 iter num 220\n",
            "loss 1.766260027885437 average time 0.0025305179791757838 iter num 240\n",
            "loss 1.0956275463104248 average time 0.002515512973087215 iter num 260\n",
            "loss 2.4269378185272217 average time 0.0024994843071518905 iter num 280\n",
            "loss 22.02733612060547 average time 0.0024891606666703108 iter num 300\n",
            "loss 9.658536911010742 average time 0.002482466687501983 iter num 320\n",
            "loss 44.72877883911133 average time 0.002475191952929462 iter num 340\n",
            "loss 3.8388679027557373 average time 0.002482075777773692 iter num 360\n",
            "loss 8.329753875732422 average time 0.002467854105242096 iter num 380\n",
            "loss 9.926403045654297 average time 0.0024584108874796586 iter num 400\n",
            "loss 1.3435560464859009 average time 0.0024490095452295332 iter num 420\n",
            "loss 8.914349555969238 average time 0.002456914988632971 iter num 440\n",
            "loss 1.411678671836853 average time 0.002458029376090132 iter num 460\n",
            "loss 13.188347816467285 average time 0.0024534243437453066 iter num 480\n",
            "loss 0.7924781441688538 average time 0.0024452478319799413 iter num 500\n",
            "loss 1.0965384244918823 average time 0.002457434496136557 iter num 520\n",
            "loss 0.153752401471138 average time 0.002451198137027354 iter num 540\n",
            "loss 7.120500087738037 average time 0.002446895278564755 iter num 560\n",
            "loss 4.4844536781311035 average time 0.0024413250948312234 iter num 580\n",
            "loss 0.049077436327934265 average time 0.002447269870005281 iter num 600\n",
            "loss 1.5292407274246216 average time 0.002441131767746781 iter num 620\n",
            "loss 67.47174835205078 average time 0.0024385718453061147 iter num 640\n",
            "loss 48.09376907348633 average time 0.002432888136365474 iter num 660\n",
            "loss 0.2851133942604065 average time 0.0024304060426455928 iter num 680\n",
            "loss 3.139373302459717 average time 0.0024362394257072344 iter num 700\n",
            "loss 0.12302608788013458 average time 0.0024308035222197254 iter num 720\n",
            "loss 0.30893850326538086 average time 0.0024279819621566474 iter num 740\n",
            "loss 0.18260225653648376 average time 0.002424759271049257 iter num 760\n",
            "loss 1.9945000410079956 average time 0.002422734465383259 iter num 780\n",
            "loss 0.917267382144928 average time 0.0024206584787452813 iter num 800\n",
            "loss 0.030802898108959198 average time 0.0024181096060867896 iter num 820\n",
            "loss 27.316396713256836 average time 0.002415946702369963 iter num 840\n",
            "loss 69.4797134399414 average time 0.002414639110452828 iter num 860\n",
            "loss 1.5692306756973267 average time 0.002412987893167569 iter num 880\n",
            "loss 3.743964672088623 average time 0.0024105308788724264 iter num 900\n",
            "loss 0.018687844276428223 average time 0.002409663889108307 iter num 920\n",
            "loss 24.419530868530273 average time 0.002412494215941672 iter num 940\n",
            "loss 0.8501031994819641 average time 0.002412166143731535 iter num 960\n",
            "loss 0.4163147509098053 average time 0.0024104113754943608 iter num 980\n",
            "loss 0.019555527716875076 average time 0.002407705568984966 iter num 1000\n",
            "loss 0.007253406103700399 average time 0.0029441665999001996 iter num 20\n",
            "loss 0.336738646030426 average time 0.002608466899891937 iter num 40\n",
            "loss 9.44106674194336 average time 0.002526062616592147 iter num 60\n",
            "loss 0.19444839656352997 average time 0.0025594548999379185 iter num 80\n",
            "loss 7.422463417053223 average time 0.0025064565999491605 iter num 100\n",
            "loss 283.95123291015625 average time 0.0025129369582373327 iter num 120\n",
            "loss 30.758174896240234 average time 0.002506937821388939 iter num 140\n",
            "loss 104.78998565673828 average time 0.002531955912456851 iter num 160\n",
            "loss 0.24448420107364655 average time 0.0025742149332876984 iter num 180\n",
            "loss 29.270915985107422 average time 0.0025445851049516934 iter num 200\n",
            "loss 12.990384101867676 average time 0.0025271802090421924 iter num 220\n",
            "loss 7.176371097564697 average time 0.0025293471207836165 iter num 240\n",
            "loss 24.80449867248535 average time 0.002516501119190742 iter num 260\n",
            "loss 0.35853853821754456 average time 0.002503525289245902 iter num 280\n",
            "loss 17.185646057128906 average time 0.0024997451499863626 iter num 300\n",
            "loss 3.155426263809204 average time 0.0025020047655971212 iter num 320\n",
            "loss 0.030078448355197906 average time 0.002485283144094009 iter num 340\n",
            "loss 18.772974014282227 average time 0.002475203908316972 iter num 360\n",
            "loss 0.07672177255153656 average time 0.0024795257499853935 iter num 380\n",
            "loss 2.507483959197998 average time 0.002509399764990121 iter num 400\n",
            "loss 0.0021414768416434526 average time 0.0024990772047463645 iter num 420\n",
            "loss 8.939631462097168 average time 0.002493552852266393 iter num 440\n",
            "loss 1.6142628192901611 average time 0.002487895084777847 iter num 460\n",
            "loss 0.02036770060658455 average time 0.002479380191664404 iter num 480\n",
            "loss 3.40132737159729 average time 0.002473678039998049 iter num 500\n",
            "loss 1.017578363418579 average time 0.002468115211538064 iter num 520\n",
            "loss 2.9130702018737793 average time 0.0024658614185143423 iter num 540\n",
            "loss 0.24415963888168335 average time 0.002460567571431836 iter num 560\n",
            "loss 2.5528526306152344 average time 0.0024546318241407098 iter num 580\n",
            "loss 0.0037235443014651537 average time 0.0024498427766684473 iter num 600\n",
            "loss 0.02838323451578617 average time 0.0024456539838719174 iter num 620\n",
            "loss 0.8810604810714722 average time 0.002442405298435801 iter num 640\n",
            "loss 12.73024845123291 average time 0.0024550072848411 iter num 660\n",
            "loss 0.07878757268190384 average time 0.0024516994544014513 iter num 680\n",
            "loss 0.0058065140619874 average time 0.002450889191420304 iter num 700\n",
            "loss 14.073230743408203 average time 0.0024469146958254998 iter num 720\n",
            "loss 1.1479218006134033 average time 0.0024570211053902015 iter num 740\n",
            "loss 0.04205390810966492 average time 0.002454040018404301 iter num 760\n",
            "loss 0.7877236008644104 average time 0.0024552184794675923 iter num 780\n",
            "loss 0.8866479992866516 average time 0.002452559328735333 iter num 800\n",
            "loss 17.276824951171875 average time 0.0024645955414509843 iter num 820\n",
            "loss 3.4848151206970215 average time 0.002461827217848622 iter num 840\n",
            "loss 4.1340390453115106e-06 average time 0.002461665606964278 iter num 860\n",
            "loss 225.82151794433594 average time 0.00245837977272045 iter num 880\n",
            "loss 0.009343273937702179 average time 0.0024565055655552392 iter num 900\n",
            "loss 0.3827590346336365 average time 0.00245337418912878 iter num 920\n",
            "loss 3.835587501525879 average time 0.0024516617563851003 iter num 940\n",
            "loss 2.0075316429138184 average time 0.002450127492708513 iter num 960\n",
            "loss 47.27223587036133 average time 0.002446935585716606 iter num 980\n",
            "loss 1.769513726234436 average time 0.002451296249000734 iter num 1000\n",
            "loss 0.12245381623506546 average time 0.003048182900147367 iter num 20\n",
            "loss 0.8008935451507568 average time 0.0026811505002115156 iter num 40\n",
            "loss 0.4263151288032532 average time 0.002695824783343899 iter num 60\n",
            "loss 0.9806097745895386 average time 0.0027019901500352716 iter num 80\n",
            "loss 1.209649920463562 average time 0.0026969401300812024 iter num 100\n",
            "loss 1.8629028797149658 average time 0.0026964934083935077 iter num 120\n",
            "loss 0.11875225603580475 average time 0.002703214321536507 iter num 140\n",
            "loss 2.5437369346618652 average time 0.002701287300089916 iter num 160\n",
            "loss 55.36856460571289 average time 0.0026895722111880283 iter num 180\n",
            "loss 1.304561972618103 average time 0.0027030260750416347 iter num 200\n",
            "loss 0.9584710597991943 average time 0.002712929381852353 iter num 220\n",
            "loss 6.073235988616943 average time 0.002709830716715563 iter num 240\n",
            "loss 0.09207785874605179 average time 0.0027053050846776528 iter num 260\n",
            "loss 11.59867000579834 average time 0.0027079792321858674 iter num 280\n",
            "loss 1.979565978050232 average time 0.0027333731233617677 iter num 300\n",
            "loss 0.009821966290473938 average time 0.002719062118785587 iter num 320\n",
            "loss 1.1636863946914673 average time 0.0027144584176847487 iter num 340\n",
            "loss 0.10107113420963287 average time 0.0027119997028017275 iter num 360\n",
            "loss 22.453622817993164 average time 0.0027011552684406957 iter num 380\n",
            "loss 0.767876386642456 average time 0.002698984540006677 iter num 400\n",
            "loss 2.133358955383301 average time 0.0026952091976324612 iter num 420\n",
            "loss 0.22665029764175415 average time 0.0026926186341163635 iter num 440\n",
            "loss 6.252518177032471 average time 0.0026905167000143633 iter num 460\n",
            "loss 5.411856651306152 average time 0.002686967491676266 iter num 480\n",
            "loss 0.4838494658470154 average time 0.0026898448840038326 iter num 500\n",
            "loss 8.762542724609375 average time 0.0026830908019117206 iter num 520\n",
            "loss 3.59025502204895 average time 0.0026854710055414653 iter num 540\n",
            "loss 2.276355266571045 average time 0.0026918525857061986 iter num 560\n",
            "loss 0.22306382656097412 average time 0.002691720384484205 iter num 580\n",
            "loss 0.789954662322998 average time 0.0026921685400126687 iter num 600\n",
            "loss 0.027843089774250984 average time 0.002690904408087414 iter num 620\n",
            "loss 0.5990437865257263 average time 0.0026942680187630685 iter num 640\n",
            "loss 1.3432642221450806 average time 0.002694588428797336 iter num 660\n",
            "loss 0.5186173915863037 average time 0.0026902014970747747 iter num 680\n",
            "loss 9.171833038330078 average time 0.0026887580428774528 iter num 700\n",
            "loss 1.1310148239135742 average time 0.002687633573635948 iter num 720\n",
            "loss 30.528087615966797 average time 0.0026834944770524924 iter num 740\n",
            "loss 0.5547335743904114 average time 0.0026824306237095267 iter num 760\n",
            "loss 0.32428717613220215 average time 0.0026925078730994593 iter num 780\n",
            "loss 21.980953216552734 average time 0.0026907443812774546 iter num 800\n",
            "loss 0.6435070037841797 average time 0.002692544435392004 iter num 820\n",
            "loss 221.37277221679688 average time 0.0026945363738420944 iter num 840\n",
            "loss 4.826270580291748 average time 0.0026953967849146655 iter num 860\n",
            "loss 1.1891753673553467 average time 0.002696577504579264 iter num 880\n",
            "loss 0.3026292622089386 average time 0.0026978170511453453 iter num 900\n",
            "loss 10.018486022949219 average time 0.0026979847511226936 iter num 920\n",
            "loss 0.7292444705963135 average time 0.002696782585151092 iter num 940\n",
            "loss 0.47967925667762756 average time 0.0026994137958752163 iter num 960\n",
            "loss 0.6069677472114563 average time 0.0026972360194270793 iter num 980\n",
            "loss 0.18281640112400055 average time 0.002696192181034348 iter num 1000\n",
            "loss 0.5821145176887512 average time 0.003436107199922844 iter num 20\n",
            "loss 0.13858860731124878 average time 0.0031158359247456247 iter num 40\n",
            "loss 2.735382556915283 average time 0.0029907369665124863 iter num 60\n",
            "loss 1.5640301704406738 average time 0.00294191611237693 iter num 80\n",
            "loss 0.4735535979270935 average time 0.002894626949855592 iter num 100\n",
            "loss 0.0016116912011057138 average time 0.0028418084998975248 iter num 120\n",
            "loss 1.9964985847473145 average time 0.0028101340427513478 iter num 140\n",
            "loss 3.3597776889801025 average time 0.0027929137561841346 iter num 160\n",
            "loss 6.329290390014648 average time 0.0027833655888268066 iter num 180\n",
            "loss 0.5286694169044495 average time 0.0027812321949568287 iter num 200\n",
            "loss 0.39826276898384094 average time 0.0027971725317663433 iter num 220\n",
            "loss 14.605281829833984 average time 0.0027728508541258632 iter num 240\n",
            "loss 0.6484708189964294 average time 0.0027961580191983486 iter num 260\n",
            "loss 0.9889547228813171 average time 0.0027989112571244084 iter num 280\n",
            "loss 89.07648468017578 average time 0.002793147883318549 iter num 300\n",
            "loss 0.5163849592208862 average time 0.0027909914843462502 iter num 320\n",
            "loss 2.5936498641967773 average time 0.0027842439587991118 iter num 340\n",
            "loss 175.5293426513672 average time 0.00276945341386939 iter num 360\n",
            "loss 5.286399841308594 average time 0.0027663056157699 iter num 380\n",
            "loss 18.047264099121094 average time 0.0027581351899880245 iter num 400\n",
            "loss 61.27762985229492 average time 0.0027531947571419768 iter num 420\n",
            "loss 0.883185088634491 average time 0.002747398749992995 iter num 440\n",
            "loss 0.044133905321359634 average time 0.002743601547808794 iter num 460\n",
            "loss 6.007401943206787 average time 0.002734445449997717 iter num 480\n",
            "loss 1.466813087463379 average time 0.0027420991160033736 iter num 500\n",
            "loss 5.223054885864258 average time 0.0027365825269253735 iter num 520\n",
            "loss 0.43152564764022827 average time 0.002740159018527198 iter num 540\n",
            "loss 73.75422668457031 average time 0.0027346493214411437 iter num 560\n",
            "loss 8.865829467773438 average time 0.002735353455174281 iter num 580\n",
            "loss 3.312232255935669 average time 0.0027295281099971665 iter num 600\n",
            "loss 16.256759643554688 average time 0.002728151337091291 iter num 620\n",
            "loss 0.06808891147375107 average time 0.0027267055921811334 iter num 640\n",
            "loss 5.39987850189209 average time 0.002723762136354873 iter num 660\n",
            "loss 20.207929611206055 average time 0.002722871854404516 iter num 680\n",
            "loss 15.689478874206543 average time 0.0027263238785703186 iter num 700\n",
            "loss 6.726015567779541 average time 0.002720729404164659 iter num 720\n",
            "loss 0.03305647522211075 average time 0.0027122871432397546 iter num 740\n",
            "loss 0.168442964553833 average time 0.0027120936815759034 iter num 760\n",
            "loss 15.207096099853516 average time 0.002707296257689543 iter num 780\n",
            "loss 1.5009764432907104 average time 0.002699378809998052 iter num 800\n",
            "loss 13.314882278442383 average time 0.0026909493475503086 iter num 820\n",
            "loss 0.17848044633865356 average time 0.002695871216656087 iter num 840\n",
            "loss 0.33287137746810913 average time 0.0026924608371996857 iter num 860\n",
            "loss 0.814967930316925 average time 0.0026931444283966564 iter num 880\n",
            "loss 62.73507308959961 average time 0.0026938237733197135 iter num 900\n",
            "loss 5.587298393249512 average time 0.0026991210575962885 iter num 920\n",
            "loss 0.01894017495214939 average time 0.0027017046191391042 iter num 940\n",
            "loss 127.75464630126953 average time 0.0027022329499952016 iter num 960\n",
            "loss 4.150972366333008 average time 0.00270294339183312 iter num 980\n",
            "loss 1.9063091278076172 average time 0.0027052604659966164 iter num 1000\n",
            "loss 3.7332842350006104 average time 0.0032449895497848047 iter num 20\n",
            "loss 48.037540435791016 average time 0.0030433886999162497 iter num 40\n",
            "loss 0.13598471879959106 average time 0.0029510624666424217 iter num 60\n",
            "loss 0.29725563526153564 average time 0.002910747250007262 iter num 80\n",
            "loss 2.6504592895507812 average time 0.0028430774600019504 iter num 100\n",
            "loss 0.006573573220521212 average time 0.002772034283331474 iter num 120\n",
            "loss 23.91381072998047 average time 0.0027343754000087625 iter num 140\n",
            "loss 0.7132125496864319 average time 0.002728767200017046 iter num 160\n",
            "loss 98.91789245605469 average time 0.0027231322722198253 iter num 180\n",
            "loss 128.4837646484375 average time 0.0026784032199793726 iter num 200\n",
            "loss 66.5936279296875 average time 0.002648785577283971 iter num 220\n",
            "loss 1.458506464958191 average time 0.002621989829200781 iter num 240\n",
            "loss 10.021432876586914 average time 0.002615101130812456 iter num 260\n",
            "loss 19.858736038208008 average time 0.0025926135536013003 iter num 280\n",
            "loss 3.159964084625244 average time 0.0025736227733553583 iter num 300\n",
            "loss 0.009391164407134056 average time 0.0025614048906447808 iter num 320\n",
            "loss 1.6550894975662231 average time 0.002549462967646618 iter num 340\n",
            "loss 0.1523987054824829 average time 0.0025460594638894284 iter num 360\n",
            "loss 5.415406703948975 average time 0.0025374984315691875 iter num 380\n",
            "loss 1.740234613418579 average time 0.0025584154399803083 iter num 400\n",
            "loss 44.361976623535156 average time 0.002550631054747923 iter num 420\n",
            "loss 7.293238639831543 average time 0.002541400088607175 iter num 440\n",
            "loss 2.176250696182251 average time 0.002534918673886157 iter num 460\n",
            "loss 10.235573768615723 average time 0.0025274170749791363 iter num 480\n",
            "loss 1.2199957370758057 average time 0.0025183776579797267 iter num 500\n",
            "loss 37.133697509765625 average time 0.0025132652288308377 iter num 520\n",
            "loss 2.1084847450256348 average time 0.0025140460722030654 iter num 540\n",
            "loss 31.71040153503418 average time 0.002530834121418073 iter num 560\n",
            "loss 12.57480239868164 average time 0.002528809415500667 iter num 580\n",
            "loss 4.808115005493164 average time 0.0025405494016558804 iter num 600\n",
            "loss 0.00046382457367144525 average time 0.002534615145146569 iter num 620\n",
            "loss 0.4141121506690979 average time 0.0025305543234310337 iter num 640\n",
            "loss 0.19030633568763733 average time 0.002533949172715383 iter num 660\n",
            "loss 2.5953211784362793 average time 0.00252805590734009 iter num 680\n",
            "loss 1.112092137336731 average time 0.00252237462141628 iter num 700\n",
            "loss 0.008821980096399784 average time 0.002528236674998475 iter num 720\n",
            "loss 0.54363614320755 average time 0.002523755748645911 iter num 740\n",
            "loss 0.22970062494277954 average time 0.0025197905065756218 iter num 760\n",
            "loss 12.060506820678711 average time 0.0025213295794809455 iter num 780\n",
            "loss 0.6263183951377869 average time 0.0025172999087476455 iter num 800\n",
            "loss 0.1400431990623474 average time 0.0025101580548812863 iter num 820\n",
            "loss 9.947519302368164 average time 0.002513255257142754 iter num 840\n",
            "loss 155.3445587158203 average time 0.002507903075583758 iter num 860\n",
            "loss 0.7247169613838196 average time 0.0025039683000076447 iter num 880\n",
            "loss 0.3060215413570404 average time 0.0025010153033387422 iter num 900\n",
            "loss 2.77114200592041 average time 0.002498104560867353 iter num 920\n",
            "loss 193.67120361328125 average time 0.0024980392978637186 iter num 940\n",
            "loss 5.12317419052124 average time 0.002501894730202518 iter num 960\n",
            "loss 6.775294780731201 average time 0.002499613276522352 iter num 980\n",
            "loss 0.16857606172561646 average time 0.002497611090000646 iter num 1000\n",
            "loss 68.93362426757812 average time 0.002944836949973251 iter num 20\n",
            "loss 1.2755061388015747 average time 0.0027826165499845955 iter num 40\n",
            "loss 5.073718070983887 average time 0.0027497542165595707 iter num 60\n",
            "loss 0.6359281539916992 average time 0.0026791797374698945 iter num 80\n",
            "loss 0.02208259329199791 average time 0.0026514780299294214 iter num 100\n",
            "loss 0.05027130991220474 average time 0.0026536266832257144 iter num 120\n",
            "loss 4.971792221069336 average time 0.002596625042770029 iter num 140\n",
            "loss 0.2915783226490021 average time 0.002555557812445386 iter num 160\n",
            "loss 2.357987403869629 average time 0.002564114644418522 iter num 180\n",
            "loss 39.003013610839844 average time 0.002569138489998295 iter num 200\n",
            "loss 2.748284101486206 average time 0.002548529563633069 iter num 220\n",
            "loss 10.607378005981445 average time 0.0025523392541723904 iter num 240\n",
            "loss 0.0005047651939094067 average time 0.002530535700008421 iter num 260\n",
            "loss 1.3165138959884644 average time 0.0025305198821375338 iter num 280\n",
            "loss 18.934038162231445 average time 0.0025210718199862943 iter num 300\n",
            "loss 0.5363888740539551 average time 0.0025263433281111245 iter num 320\n",
            "loss 4.928083419799805 average time 0.0025166352176283374 iter num 340\n",
            "loss 0.045982617884874344 average time 0.002523659627761137 iter num 360\n",
            "loss 0.06767550110816956 average time 0.0025103640973468014 iter num 380\n",
            "loss 16.2741756439209 average time 0.002502927737459686 iter num 400\n",
            "loss 0.3245311975479126 average time 0.0024928435570992797 iter num 420\n",
            "loss 9.391691207885742 average time 0.002490499718148633 iter num 440\n",
            "loss 14.234109878540039 average time 0.002484573980405991 iter num 460\n",
            "loss 2.274764060974121 average time 0.0024778359020539635 iter num 480\n",
            "loss 11.818426132202148 average time 0.002470301421974 iter num 500\n",
            "loss 6.680741310119629 average time 0.0024670499499699454 iter num 520\n",
            "loss 7.551845550537109 average time 0.002474336290709255 iter num 540\n",
            "loss 0.8197727799415588 average time 0.002488104137481579 iter num 560\n",
            "loss 4.544008731842041 average time 0.002491897977566184 iter num 580\n",
            "loss 0.23889769613742828 average time 0.002486970913314508 iter num 600\n",
            "loss 3.8442511558532715 average time 0.0024840714822417912 iter num 620\n",
            "loss 12.362730979919434 average time 0.0024802434531096653 iter num 640\n",
            "loss 3.015424966812134 average time 0.0024867020711925843 iter num 660\n",
            "loss 45.73301696777344 average time 0.0024831528690944706 iter num 680\n",
            "loss 1.3583828210830688 average time 0.0024789929628345167 iter num 700\n",
            "loss 18.815731048583984 average time 0.002475298159700085 iter num 720\n",
            "loss 0.8126278519630432 average time 0.002471786062137284 iter num 740\n",
            "loss 2.149747610092163 average time 0.00246524800260503 iter num 760\n",
            "loss 0.4015023708343506 average time 0.002472004080743481 iter num 780\n",
            "loss 7.293197154998779 average time 0.00246888342622924 iter num 800\n",
            "loss 5.613134384155273 average time 0.002472554271930787 iter num 820\n",
            "loss 0.0027640420012176037 average time 0.002468554695211164 iter num 840\n",
            "loss 0.010038494132459164 average time 0.002474372975554383 iter num 860\n",
            "loss 0.888746976852417 average time 0.0024758274976958007 iter num 880\n",
            "loss 0.6942833662033081 average time 0.0024768641799689955 iter num 900\n",
            "loss 0.9768701791763306 average time 0.002474399529317294 iter num 920\n",
            "loss 1.7646254301071167 average time 0.002471398934013702 iter num 940\n",
            "loss 4.0555195808410645 average time 0.002474307160389344 iter num 960\n",
            "loss 8.872736930847168 average time 0.0024856468856898797 iter num 980\n",
            "loss 15.80128002166748 average time 0.0024875602499778325 iter num 1000\n",
            "loss 0.27958205342292786 average time 0.003293954950186162 iter num 20\n",
            "loss 3.974740982055664 average time 0.0028093431251818403 iter num 40\n",
            "loss 0.15026772022247314 average time 0.002780805033520058 iter num 60\n",
            "loss 1.1889960765838623 average time 0.0026577137626645707 iter num 80\n",
            "loss 66.64219665527344 average time 0.0025866869101628252 iter num 100\n",
            "loss 19.252471923828125 average time 0.0025648619584747695 iter num 120\n",
            "loss 2.490767478942871 average time 0.002568692278704735 iter num 140\n",
            "loss 4.282277584075928 average time 0.0025462900563525182 iter num 160\n",
            "loss 72.13331604003906 average time 0.0025514021389931763 iter num 180\n",
            "loss 0.6739330887794495 average time 0.002527277430081085 iter num 200\n",
            "loss 1.8299810886383057 average time 0.002513992195508763 iter num 220\n",
            "loss 0.002595827914774418 average time 0.0024937661292218157 iter num 240\n",
            "loss 15.545931816101074 average time 0.0024786675616059466 iter num 260\n",
            "loss 28.740924835205078 average time 0.0024627605929189098 iter num 280\n",
            "loss 0.02541148103773594 average time 0.0024747374633989237 iter num 300\n",
            "loss 8.648195266723633 average time 0.0024668936844307156 iter num 320\n",
            "loss 10.227874755859375 average time 0.002469363420657507 iter num 340\n",
            "loss 42.65882110595703 average time 0.002458330630613798 iter num 360\n",
            "loss 4.069882869720459 average time 0.0024691107474130772 iter num 380\n",
            "loss 0.606482744216919 average time 0.0024596003300439407 iter num 400\n",
            "loss 85.2215576171875 average time 0.0024515278809953346 iter num 420\n",
            "loss 14.281989097595215 average time 0.0024584449909525576 iter num 440\n",
            "loss 13.062087059020996 average time 0.002464591989151497 iter num 460\n",
            "loss 1.9047714471817017 average time 0.0024607256437851294 iter num 480\n",
            "loss 1.0419418811798096 average time 0.002457511410033476 iter num 500\n",
            "loss 1.1064010858535767 average time 0.00246448644425772 iter num 520\n",
            "loss 0.15775087475776672 average time 0.0024667539463229735 iter num 540\n",
            "loss 1.1199424266815186 average time 0.002474637719670422 iter num 560\n",
            "loss 0.14139243960380554 average time 0.002468776965539793 iter num 580\n",
            "loss 6.986001491546631 average time 0.0024620925100255894 iter num 600\n",
            "loss 1.9560328722000122 average time 0.002465386162924504 iter num 620\n",
            "loss 0.7893038392066956 average time 0.002469763148457105 iter num 640\n",
            "loss 3.4336254596710205 average time 0.0024629342894155397 iter num 660\n",
            "loss 67.28926086425781 average time 0.0024587770588422085 iter num 680\n",
            "loss 0.7599707245826721 average time 0.0024738770057332916 iter num 700\n",
            "loss 0.08351743966341019 average time 0.0024762999680711397 iter num 720\n",
            "loss 0.8810945153236389 average time 0.0024711346973138437 iter num 740\n",
            "loss 0.07764584571123123 average time 0.0024679583894938236 iter num 760\n",
            "loss 2.973540782928467 average time 0.002471398753867759 iter num 780\n",
            "loss 21.970796585083008 average time 0.0024743840787687077 iter num 800\n",
            "loss 45.725379943847656 average time 0.0024729595561217227 iter num 820\n",
            "loss 1.2839902639389038 average time 0.002475365848836407 iter num 840\n",
            "loss 59.08393096923828 average time 0.0024742161511820213 iter num 860\n",
            "loss 0.19456343352794647 average time 0.0024757199534261335 iter num 880\n",
            "loss 0.019349435344338417 average time 0.0024720688277900787 iter num 900\n",
            "loss 0.06170906126499176 average time 0.002470904273927179 iter num 920\n",
            "loss 0.13846959173679352 average time 0.002471573820221625 iter num 940\n",
            "loss 3.493914846330881e-08 average time 0.0024696710500033228 iter num 960\n",
            "loss 7.3414692878723145 average time 0.002468944893887371 iter num 980\n",
            "loss 0.029472313821315765 average time 0.0024671595910094766 iter num 1000\n",
            "loss 1.928192377090454 average time 0.00299450765032816 iter num 20\n",
            "loss 0.04772418364882469 average time 0.0026366199502263045 iter num 40\n",
            "loss 2.499251365661621 average time 0.002537105900106932 iter num 60\n",
            "loss 10.398991584777832 average time 0.0025294806500369303 iter num 80\n",
            "loss 4.008248805999756 average time 0.002490530720042443 iter num 100\n",
            "loss 6.620633125305176 average time 0.002501593566679124 iter num 120\n",
            "loss 4.63356876373291 average time 0.00251837878569339 iter num 140\n",
            "loss 56.352813720703125 average time 0.002572026693724183 iter num 160\n",
            "loss 0.15425539016723633 average time 0.002582880938835943 iter num 180\n",
            "loss 71.51596069335938 average time 0.0025944987849561584 iter num 200\n",
            "loss 3.9582319259643555 average time 0.0025873255953973223 iter num 220\n",
            "loss 6.288549423217773 average time 0.0025961046416114186 iter num 240\n",
            "loss 24.93187713623047 average time 0.0025919732076405268 iter num 260\n",
            "loss 37.554420471191406 average time 0.0025953430213771105 iter num 280\n",
            "loss 0.12065806984901428 average time 0.002593279319953581 iter num 300\n",
            "loss 7.53106164932251 average time 0.0025953234155849715 iter num 320\n",
            "loss 60.385921478271484 average time 0.002603179732298432 iter num 340\n",
            "loss 0.7134050726890564 average time 0.002604414774941688 iter num 360\n",
            "loss 0.10810498893260956 average time 0.0025948666183515006 iter num 380\n",
            "loss 20.163198471069336 average time 0.0026066689124445474 iter num 400\n",
            "loss 13.01294231414795 average time 0.002604812314231302 iter num 420\n",
            "loss 6.728034019470215 average time 0.0025964576885764306 iter num 440\n",
            "loss 0.16691020131111145 average time 0.0026008455303702287 iter num 460\n",
            "loss 3.844587802886963 average time 0.002600549962437526 iter num 480\n",
            "loss 2.4942967891693115 average time 0.002607618425947294 iter num 500\n",
            "loss 6.647240161895752 average time 0.002612516013414279 iter num 520\n",
            "loss 0.45545798540115356 average time 0.002620748422180407 iter num 540\n",
            "loss 0.4794573485851288 average time 0.002627563649970658 iter num 560\n",
            "loss 0.8079989552497864 average time 0.0026311086465315822 iter num 580\n",
            "loss 1.0021984577178955 average time 0.0026304183833084 iter num 600\n",
            "loss 3.3504984378814697 average time 0.002628587903200241 iter num 620\n",
            "loss 15.584640502929688 average time 0.002646149060916514 iter num 640\n",
            "loss 4.50217866897583 average time 0.0026433982302781563 iter num 660\n",
            "loss 14.276338577270508 average time 0.0026407396308594103 iter num 680\n",
            "loss 0.424140065908432 average time 0.0026397646514098078 iter num 700\n",
            "loss 22.96011734008789 average time 0.0026398202499800997 iter num 720\n",
            "loss 0.8199275135993958 average time 0.002647473174307084 iter num 740\n",
            "loss 0.4292639195919037 average time 0.0026514982644608893 iter num 760\n",
            "loss 1.8798667192459106 average time 0.0026533669499864726 iter num 780\n",
            "loss 0.008934138342738152 average time 0.0026546222112369833 iter num 800\n",
            "loss 0.34202757477760315 average time 0.002654934714625663 iter num 820\n",
            "loss 18.813819885253906 average time 0.0026570363011809866 iter num 840\n",
            "loss 14.839705467224121 average time 0.002658149087203001 iter num 860\n",
            "loss 1.1489028930664062 average time 0.002669321555673708 iter num 880\n",
            "loss 0.6822070479393005 average time 0.0026675994866632714 iter num 900\n",
            "loss 19.82675552368164 average time 0.0026664591902159454 iter num 920\n",
            "loss 7.634298324584961 average time 0.002665507344681828 iter num 940\n",
            "loss 5.141149520874023 average time 0.00266221846666402 iter num 960\n",
            "loss 13.082500457763672 average time 0.0026625154632636955 iter num 980\n",
            "loss 14.506519317626953 average time 0.0026640173479954682 iter num 1000\n",
            "loss 0.03185997158288956 average time 0.0034729454000625992 iter num 20\n",
            "loss 0.07407083362340927 average time 0.003083206725113996 iter num 40\n",
            "loss 0.32162031531333923 average time 0.002956815066772833 iter num 60\n",
            "loss 20.125154495239258 average time 0.00290074535007534 iter num 80\n",
            "loss 9.906702041625977 average time 0.0028236083100637186 iter num 100\n",
            "loss 1.9711153507232666 average time 0.002790192858401497 iter num 120\n",
            "loss 0.7210131287574768 average time 0.0027919734929257953 iter num 140\n",
            "loss 5.7444539070129395 average time 0.002830304075064305 iter num 160\n",
            "loss 0.14780397713184357 average time 0.0028283978667079483 iter num 180\n",
            "loss 31.35259246826172 average time 0.002817151655008274 iter num 200\n",
            "loss 6.6199164390563965 average time 0.0028110832454413784 iter num 220\n",
            "loss 15.915212631225586 average time 0.002794245970805302 iter num 240\n",
            "loss 0.5635533332824707 average time 0.0027889224499911226 iter num 260\n",
            "loss 1.0094444751739502 average time 0.002786736282126055 iter num 280\n",
            "loss 11.26096248626709 average time 0.0027709188533359946 iter num 300\n",
            "loss 2.1400294303894043 average time 0.002769321074998743 iter num 320\n",
            "loss 4.5934529304504395 average time 0.0027867810382304014 iter num 340\n",
            "loss 3.1848490238189697 average time 0.00276656141110531 iter num 360\n",
            "loss 3.461969390627928e-05 average time 0.002759250834218332 iter num 380\n",
            "loss 1.6426104307174683 average time 0.0027579994425195762 iter num 400\n",
            "loss 9.264813423156738 average time 0.0027563880381031984 iter num 420\n",
            "loss 72.14368438720703 average time 0.0027475019136421574 iter num 440\n",
            "loss 3.543776273727417 average time 0.0027460210500027207 iter num 460\n",
            "loss 2.9102895259857178 average time 0.0027470368937504946 iter num 480\n",
            "loss 1.7690833806991577 average time 0.0027453605660011818 iter num 500\n",
            "loss 0.0741315484046936 average time 0.002745971348080135 iter num 520\n",
            "loss 1.8175181150436401 average time 0.0027487447203855954 iter num 540\n",
            "loss 0.13046863675117493 average time 0.002745233139294864 iter num 560\n",
            "loss 0.02792033739387989 average time 0.0027527877758765154 iter num 580\n",
            "loss 0.5803927183151245 average time 0.0027499212066777546 iter num 600\n",
            "loss 0.6751299500465393 average time 0.002752542238713138 iter num 620\n",
            "loss 1.2328805923461914 average time 0.002749862226562527 iter num 640\n",
            "loss 0.03627618029713631 average time 0.002749288765161592 iter num 660\n",
            "loss 0.0729965791106224 average time 0.00275113238089141 iter num 680\n",
            "loss 2.182744026184082 average time 0.002748854791433197 iter num 700\n",
            "loss 0.012486590072512627 average time 0.0027471664458415842 iter num 720\n",
            "loss 0.22631745040416718 average time 0.0027485278310893126 iter num 740\n",
            "loss 1.1813770532608032 average time 0.0027500543736909766 iter num 760\n",
            "loss 0.35236525535583496 average time 0.0027482321256497807 iter num 780\n",
            "loss 0.003851373214274645 average time 0.0027404497700081265 iter num 800\n",
            "loss 0.8228939175605774 average time 0.002734969347567108 iter num 820\n",
            "loss 0.45778948068618774 average time 0.0027332892940540618 iter num 840\n",
            "loss 0.0014372754376381636 average time 0.0027340033162904865 iter num 860\n",
            "loss 0.4396273195743561 average time 0.0027282291852378134 iter num 880\n",
            "loss 1.3616571426391602 average time 0.0027241286133458846 iter num 900\n",
            "loss 4.271358966827393 average time 0.002722928726101916 iter num 920\n",
            "loss 0.0264224112033844 average time 0.002719172980865319 iter num 940\n",
            "loss 41.00583267211914 average time 0.002712944542719242 iter num 960\n",
            "loss 27.06711196899414 average time 0.002715349675512772 iter num 980\n",
            "loss 6.0302934646606445 average time 0.002713611826005945 iter num 1000\n",
            "loss 0.08950155973434448 average time 0.0033972101999097505 iter num 20\n",
            "loss 0.007135649677366018 average time 0.003080294475057599 iter num 40\n",
            "loss 1.2729827165603638 average time 0.0031809048667431248 iter num 60\n",
            "loss 3.498422622680664 average time 0.003049034187597499 iter num 80\n",
            "loss 11.020726203918457 average time 0.0029785512200760423 iter num 100\n",
            "loss 2.8161816596984863 average time 0.0028709603666963327 iter num 120\n",
            "loss 10.104179382324219 average time 0.002795204649997426 iter num 140\n",
            "loss 4.761952877044678 average time 0.0027677386687855686 iter num 160\n",
            "loss 19.098474502563477 average time 0.002723585644495567 iter num 180\n",
            "loss 24.155433654785156 average time 0.002715368270055478 iter num 200\n",
            "loss 67.25946807861328 average time 0.0026857056046124357 iter num 220\n",
            "loss 0.7793528437614441 average time 0.0026536877917351376 iter num 240\n",
            "loss 8.537065505981445 average time 0.0026330344231190305 iter num 260\n",
            "loss 51.5587043762207 average time 0.0026069099857522816 iter num 280\n",
            "loss 0.434507817029953 average time 0.0026122977866968235 iter num 300\n",
            "loss 3.958406448364258 average time 0.002594325453156898 iter num 320\n",
            "loss 0.34169748425483704 average time 0.0025762648235553675 iter num 340\n",
            "loss 742.9800415039062 average time 0.002564370413918166 iter num 360\n",
            "loss 2.1540005207061768 average time 0.002567994747397805 iter num 380\n",
            "loss 23.4725399017334 average time 0.002559338182513784 iter num 400\n",
            "loss 0.0041394662111997604 average time 0.0025480391023891226 iter num 420\n",
            "loss 0.918422281742096 average time 0.0025395752681726495 iter num 440\n",
            "loss 1.1536017656326294 average time 0.0025549841934701797 iter num 460\n",
            "loss 0.38509175181388855 average time 0.0025609235187478894 iter num 480\n",
            "loss 1.3515312671661377 average time 0.002551305324002897 iter num 500\n",
            "loss 6.495095729827881 average time 0.0025448719673092386 iter num 520\n",
            "loss 66.41792297363281 average time 0.0025358790296397477 iter num 540\n",
            "loss 0.010244091041386127 average time 0.0025299578375097553 iter num 560\n",
            "loss 0.12382428348064423 average time 0.002523389718969376 iter num 580\n",
            "loss 1.2815793752670288 average time 0.0025166074583345714 iter num 600\n",
            "loss 0.0990343689918518 average time 0.0025149886774142355 iter num 620\n",
            "loss 4.594728469848633 average time 0.0025213351421740525 iter num 640\n",
            "loss 0.06235887482762337 average time 0.002517843956047727 iter num 660\n",
            "loss 1.1878019571304321 average time 0.0025114644264490112 iter num 680\n",
            "loss 1.210970401763916 average time 0.0025145186285486227 iter num 700\n",
            "loss 3.326145887374878 average time 0.0025145243374759554 iter num 720\n",
            "loss 5.558933844440617e-05 average time 0.0025096082810656247 iter num 740\n",
            "loss 17.489627838134766 average time 0.002506261167086689 iter num 760\n",
            "loss 3.3330509662628174 average time 0.00250968852561784 iter num 780\n",
            "loss 0.09603036940097809 average time 0.0025115080724799556 iter num 800\n",
            "loss 2.060225248336792 average time 0.0025059353377844496 iter num 820\n",
            "loss 2.8228752613067627 average time 0.0024991974940218953 iter num 840\n",
            "loss 0.12360019236803055 average time 0.002505368032536861 iter num 860\n",
            "loss 42.34725570678711 average time 0.0025013021363437557 iter num 880\n",
            "loss 4.650730133056641 average time 0.0024971270644245022 iter num 900\n",
            "loss 3.576266050338745 average time 0.0024934363130242948 iter num 920\n",
            "loss 6.286253929138184 average time 0.0024964089829618966 iter num 940\n",
            "loss 0.0509062260389328 average time 0.0024921427874763443 iter num 960\n",
            "loss 0.6987022161483765 average time 0.002488827331606964 iter num 980\n",
            "loss 2.3030433654785156 average time 0.002490190703976623 iter num 1000\n",
            "loss 7.621992111206055 average time 0.0031263494498489307 iter num 20\n",
            "loss 47.369747161865234 average time 0.00273717114973806 iter num 40\n",
            "loss 24.253700256347656 average time 0.0025895814664788 iter num 60\n",
            "loss 11.627656936645508 average time 0.0026397902624012205 iter num 80\n",
            "loss 4.413871765136719 average time 0.0026232247399275367 iter num 100\n",
            "loss 5.457406044006348 average time 0.002607512783257941 iter num 120\n",
            "loss 7.925957202911377 average time 0.0025788769356690213 iter num 140\n",
            "loss 0.003938502632081509 average time 0.002550229418716299 iter num 160\n",
            "loss 1.959812045097351 average time 0.0025693273666446558 iter num 180\n",
            "loss 0.2892710268497467 average time 0.0025435279249632005 iter num 200\n",
            "loss 1.3275972604751587 average time 0.002543433881816203 iter num 220\n",
            "loss 0.9719704389572144 average time 0.002528530308321327 iter num 240\n",
            "loss 2.677375078201294 average time 0.002531338869217647 iter num 260\n",
            "loss 10.238320350646973 average time 0.0025193382535625072 iter num 280\n",
            "loss 0.4445505738258362 average time 0.002505073050003072 iter num 300\n",
            "loss 0.020819956436753273 average time 0.002494827868753191 iter num 320\n",
            "loss 18.393569946289062 average time 0.0025039945999945786 iter num 340\n",
            "loss 6.8265275955200195 average time 0.00249397528887635 iter num 360\n",
            "loss 3.3607187271118164 average time 0.0024871065762980785 iter num 380\n",
            "loss 4.7997870445251465 average time 0.0024772905849886227 iter num 400\n",
            "loss 1.5659732818603516 average time 0.002479767214282176 iter num 420\n",
            "loss 17.340686798095703 average time 0.002472164497732427 iter num 440\n",
            "loss 0.21715512871742249 average time 0.002486919415217847 iter num 460\n",
            "loss 24.856164932250977 average time 0.002482744195822306 iter num 480\n",
            "loss 0.05529164522886276 average time 0.0024913089939946078 iter num 500\n",
            "loss 603.3741455078125 average time 0.00248634639422632 iter num 520\n",
            "loss 0.5893518924713135 average time 0.0024778921148094083 iter num 540\n",
            "loss 3.456450939178467 average time 0.0024793459749941705 iter num 560\n",
            "loss 0.14706702530384064 average time 0.002482281925865115 iter num 580\n",
            "loss 3.8649895191192627 average time 0.0024792325783346315 iter num 600\n",
            "loss 18.039031982421875 average time 0.0024721421000028767 iter num 620\n",
            "loss 0.30206894874572754 average time 0.002473381793760154 iter num 640\n",
            "loss 5.810949802398682 average time 0.0024709032803140432 iter num 660\n",
            "loss 1.0337114334106445 average time 0.002472615314721171 iter num 680\n",
            "loss 5.237222671508789 average time 0.0024683103342951133 iter num 700\n",
            "loss 2.3043923377990723 average time 0.002464652030564846 iter num 720\n",
            "loss 61.18545150756836 average time 0.0024687440892095665 iter num 740\n",
            "loss 1.9859325885772705 average time 0.002463243059231134 iter num 760\n",
            "loss 3.2224018573760986 average time 0.0024592666038678055 iter num 780\n",
            "loss 0.5058533549308777 average time 0.0024599881462722805 iter num 800\n",
            "loss 0.6487665176391602 average time 0.0024629066597875995 iter num 820\n",
            "loss 58.942100524902344 average time 0.002460286345270409 iter num 840\n",
            "loss 21.548431396484375 average time 0.002456781887242467 iter num 860\n",
            "loss 11.971699714660645 average time 0.002458360152302868 iter num 880\n",
            "loss 107.30684661865234 average time 0.0024676363978121825 iter num 900\n",
            "loss 1.6266990900039673 average time 0.0024723775609029122 iter num 920\n",
            "loss 0.22122937440872192 average time 0.002475635905354098 iter num 940\n",
            "loss 2.366600275039673 average time 0.0024735868135811264 iter num 960\n",
            "loss 0.9071424603462219 average time 0.002475883526570827 iter num 980\n",
            "loss 1.847651481628418 average time 0.0024728704110420947 iter num 1000\n",
            "loss 2.1988415718078613 average time 0.002999760749935376 iter num 20\n",
            "loss 3.200232744216919 average time 0.002647583149928323 iter num 40\n",
            "loss 14.637372970581055 average time 0.0026378688166611634 iter num 60\n",
            "loss 130.56625366210938 average time 0.0025623363874046844 iter num 80\n",
            "loss 18.055755615234375 average time 0.0025291463297980954 iter num 100\n",
            "loss 0.06947458535432816 average time 0.00248805418318625 iter num 120\n",
            "loss 0.06075943633913994 average time 0.002474622414177117 iter num 140\n",
            "loss 14.360116958618164 average time 0.002448724168652916 iter num 160\n",
            "loss 1.2778983116149902 average time 0.0024640337832048925 iter num 180\n",
            "loss 0.08952105045318604 average time 0.0024746260298707055 iter num 200\n",
            "loss 10.153347969055176 average time 0.0024608152680808747 iter num 220\n",
            "loss 9.929864883422852 average time 0.0024812130415739373 iter num 240\n",
            "loss 12.584327697753906 average time 0.0024729492922163513 iter num 260\n",
            "loss 8.256880760192871 average time 0.0024652878034755435 iter num 280\n",
            "loss 6.296439170837402 average time 0.0024628937065608626 iter num 300\n",
            "loss 1.9744932651519775 average time 0.0024499113030174158 iter num 320\n",
            "loss 5.918517112731934 average time 0.0024456675146051136 iter num 340\n",
            "loss 0.09948626160621643 average time 0.0024528373137854944 iter num 360\n",
            "loss 0.006999196019023657 average time 0.0024447017183248185 iter num 380\n",
            "loss 2.650204658508301 average time 0.0024675383323983623 iter num 400\n",
            "loss 0.002625436522066593 average time 0.0024563485737157213 iter num 420\n",
            "loss 0.006044056266546249 average time 0.0024534823749160174 iter num 440\n",
            "loss 0.7232368588447571 average time 0.0024471828216598586 iter num 460\n",
            "loss 1.242003321647644 average time 0.0024433589290955146 iter num 480\n",
            "loss 0.11673124879598618 average time 0.0024404998459285707 iter num 500\n",
            "loss 107.65882873535156 average time 0.0024424640441548734 iter num 520\n",
            "loss 0.6740019917488098 average time 0.0024381235665849226 iter num 540\n",
            "loss 4.01035213470459 average time 0.0024447682267041923 iter num 560\n",
            "loss 21.78836441040039 average time 0.0024408615154368754 iter num 580\n",
            "loss 0.7410577535629272 average time 0.0024416852949131376 iter num 600\n",
            "loss 2.4848709106445312 average time 0.002437188407985823 iter num 620\n",
            "loss 0.8987671136856079 average time 0.0024345219608704837 iter num 640\n",
            "loss 0.3525843620300293 average time 0.0024313859135735114 iter num 660\n",
            "loss 0.017865845933556557 average time 0.0024318065940486335 iter num 680\n",
            "loss 5.308419704437256 average time 0.0024290820027895927 iter num 700\n",
            "loss 0.20245029032230377 average time 0.0024328281916041307 iter num 720\n",
            "loss 0.4542680084705353 average time 0.0024307904539971393 iter num 740\n",
            "loss 0.6208224296569824 average time 0.002430231823619148 iter num 760\n",
            "loss 0.34118032455444336 average time 0.0024302748537803173 iter num 780\n",
            "loss 24.342531204223633 average time 0.002429913444941576 iter num 800\n",
            "loss 0.22853931784629822 average time 0.0024281349889639474 iter num 820\n",
            "loss 0.8436194062232971 average time 0.0024258883249504357 iter num 840\n",
            "loss 4.041212558746338 average time 0.002426072889482934 iter num 860\n",
            "loss 0.0198990311473608 average time 0.0024243117431296925 iter num 880\n",
            "loss 555.2554321289062 average time 0.002429821442167142 iter num 900\n",
            "loss 0.05179806053638458 average time 0.002430162727122202 iter num 920\n",
            "loss 0.030046701431274414 average time 0.0024288886010176516 iter num 940\n",
            "loss 0.08079929649829865 average time 0.0024259021624554104 iter num 960\n",
            "loss 11.264802932739258 average time 0.0024224379683262815 iter num 980\n",
            "loss 0.7852827310562134 average time 0.00242509312596485 iter num 1000\n",
            "loss 10.802579879760742 average time 0.0028750141999807966 iter num 20\n",
            "loss 21.77554702758789 average time 0.0025696512749618706 iter num 40\n",
            "loss 0.0029371418058872223 average time 0.002507550233319004 iter num 60\n",
            "loss 5.9146246910095215 average time 0.0025144066499251496 iter num 80\n",
            "loss 19.430505752563477 average time 0.002496747479926853 iter num 100\n",
            "loss 0.9422719478607178 average time 0.002469174908280062 iter num 120\n",
            "loss 36.87787628173828 average time 0.002475614250007701 iter num 140\n",
            "loss 14.862756729125977 average time 0.002489379762516819 iter num 160\n",
            "loss 1.2366276979446411 average time 0.0024650805500237363 iter num 180\n",
            "loss 0.119965560734272 average time 0.002456424700030766 iter num 200\n",
            "loss 12.09447193145752 average time 0.002448472809125881 iter num 220\n",
            "loss 3.2768070697784424 average time 0.002454406612537241 iter num 240\n",
            "loss 7.128543853759766 average time 0.002463404311576876 iter num 260\n",
            "loss 1.47441828250885 average time 0.0024858055428921945 iter num 280\n",
            "loss 212.6503143310547 average time 0.0025099098033570045 iter num 300\n",
            "loss 0.07687724381685257 average time 0.002515180256284566 iter num 320\n",
            "loss 62.35374069213867 average time 0.002522094914740378 iter num 340\n",
            "loss 0.03793269768357277 average time 0.002533310977802709 iter num 360\n",
            "loss 2.9837586879730225 average time 0.0025509270579229786 iter num 380\n",
            "loss 0.08429977297782898 average time 0.00255949663753654 iter num 400\n",
            "loss 17.18504524230957 average time 0.002557025676235623 iter num 420\n",
            "loss 1.6787102222442627 average time 0.002562387065964603 iter num 440\n",
            "loss 10.93730354309082 average time 0.0025727061326625005 iter num 460\n",
            "loss 3.873297691345215 average time 0.0025722844813003574 iter num 480\n",
            "loss 29.287872314453125 average time 0.0025790597580380562 iter num 500\n",
            "loss 6.852755546569824 average time 0.0025799940211842253 iter num 520\n",
            "loss 0.2296823412179947 average time 0.0025814444278054265 iter num 540\n",
            "loss 0.2688443064689636 average time 0.0025838214178877804 iter num 560\n",
            "loss 1.0761873722076416 average time 0.002588134824164344 iter num 580\n",
            "loss 0.5852124094963074 average time 0.0025951260983523147 iter num 600\n",
            "loss 1.6054840087890625 average time 0.0025940931371077306 iter num 620\n",
            "loss 0.09644223004579544 average time 0.002597857157809358 iter num 640\n",
            "loss 2.3350400924682617 average time 0.002600275187876722 iter num 660\n",
            "loss 0.021765058860182762 average time 0.002600851911770138 iter num 680\n",
            "loss 0.2079615294933319 average time 0.0026026676899995695 iter num 700\n",
            "loss 0.3018438518047333 average time 0.0026059027138848655 iter num 720\n",
            "loss 0.010544008575379848 average time 0.0026108509499961755 iter num 740\n",
            "loss 0.004883948713541031 average time 0.0026144320578982603 iter num 760\n",
            "loss 2.6950185298919678 average time 0.0026198601705171034 iter num 780\n",
            "loss 0.8958727717399597 average time 0.0026189477212551536 iter num 800\n",
            "loss 469.9003601074219 average time 0.0026201691963473332 iter num 820\n",
            "loss 0.008484437130391598 average time 0.002621071675007226 iter num 840\n",
            "loss 0.008002816699445248 average time 0.0026235109686092266 iter num 860\n",
            "loss 3.2048680782318115 average time 0.002624765704550472 iter num 880\n",
            "loss 1.0694013833999634 average time 0.002628312557782111 iter num 900\n",
            "loss 47.43551254272461 average time 0.0026307914554368123 iter num 920\n",
            "loss 1.9194145202636719 average time 0.002630600141492323 iter num 940\n",
            "loss 0.4055028557777405 average time 0.002632602229166044 iter num 960\n",
            "loss 20.3127384185791 average time 0.0026358707449004697 iter num 980\n",
            "loss 1.2082265615463257 average time 0.0026461311480052247 iter num 1000\n",
            "loss 0.1993495523929596 average time 0.003227378049996332 iter num 20\n",
            "loss 3.7757561206817627 average time 0.0030164154499743743 iter num 40\n",
            "loss 4.535101890563965 average time 0.0028487717500259653 iter num 60\n",
            "loss 1.0583961009979248 average time 0.0027635070500082294 iter num 80\n",
            "loss 1.478158712387085 average time 0.0027593002400135447 iter num 100\n",
            "loss 10.252875328063965 average time 0.0027682666917219954 iter num 120\n",
            "loss 0.6829760670661926 average time 0.0027634471000445564 iter num 140\n",
            "loss 42.8538818359375 average time 0.002806262250078362 iter num 160\n",
            "loss 7.5905985832214355 average time 0.002777972594483597 iter num 180\n",
            "loss 0.9799598455429077 average time 0.0027786371950332977 iter num 200\n",
            "loss 1.0571955442428589 average time 0.002768063231839981 iter num 220\n",
            "loss 0.8977738618850708 average time 0.0027682881041603954 iter num 240\n",
            "loss 0.09975901246070862 average time 0.0027629373653815913 iter num 260\n",
            "loss 0.09435632079839706 average time 0.0027578572892967453 iter num 280\n",
            "loss 5.461452484130859 average time 0.002735876170014914 iter num 300\n",
            "loss 0.006691627204418182 average time 0.0027221036437765633 iter num 320\n",
            "loss 1.577816367149353 average time 0.002717261900023218 iter num 340\n",
            "loss 62.42304229736328 average time 0.0027151981750244483 iter num 360\n",
            "loss 0.40839648246765137 average time 0.0027504016210801448 iter num 380\n",
            "loss 2.9515843391418457 average time 0.0027409430925308697 iter num 400\n",
            "loss 0.3794597387313843 average time 0.0027362358119327316 iter num 420\n",
            "loss 1.2780838012695312 average time 0.002733537747748084 iter num 440\n",
            "loss 0.714149534702301 average time 0.0027248588413188017 iter num 460\n",
            "loss 1.0480588674545288 average time 0.0027280659166914727 iter num 480\n",
            "loss 9.391340255737305 average time 0.0027285543360267184 iter num 500\n",
            "loss 1.0583559274673462 average time 0.0027337974500194553 iter num 520\n",
            "loss 0.19218583405017853 average time 0.0027307950518627843 iter num 540\n",
            "loss 3.3895885944366455 average time 0.002729681610717957 iter num 560\n",
            "loss 65.780029296875 average time 0.002726479901741249 iter num 580\n",
            "loss 9.717738151550293 average time 0.0027281109766863665 iter num 600\n",
            "loss 1.3499574661254883 average time 0.002725312659699299 iter num 620\n",
            "loss 7.574269771575928 average time 0.0027330934093953373 iter num 640\n",
            "loss 0.002804853254929185 average time 0.002731964618201208 iter num 660\n",
            "loss 15.880959510803223 average time 0.002727992704435297 iter num 680\n",
            "loss 3.7477004528045654 average time 0.002729195240023858 iter num 700\n",
            "loss 4.535003662109375 average time 0.0027311595750183592 iter num 720\n",
            "loss 0.050938211381435394 average time 0.002730898059480997 iter num 740\n",
            "loss 0.2279626727104187 average time 0.0027255855197549144 iter num 760\n",
            "loss 0.07518137246370316 average time 0.002716973050020244 iter num 780\n",
            "loss 0.391092449426651 average time 0.002716667642514494 iter num 800\n",
            "loss 0.040104418992996216 average time 0.002714677381723826 iter num 820\n",
            "loss 1.836861252784729 average time 0.002713760382158355 iter num 840\n",
            "loss 0.6287147402763367 average time 0.0027128159011776598 iter num 860\n",
            "loss 1.495443344116211 average time 0.0027092050386520647 iter num 880\n",
            "loss 0.03498194366693497 average time 0.002707236572239506 iter num 900\n",
            "loss 0.02933233603835106 average time 0.002706994705455224 iter num 920\n",
            "loss 0.019431231543421745 average time 0.0027040542085315076 iter num 940\n",
            "loss 4.196383953094482 average time 0.0027023494260599063 iter num 960\n",
            "loss 2.0532829761505127 average time 0.0027034584653253604 iter num 980\n",
            "loss 0.25988030433654785 average time 0.00269960641002217 iter num 1000\n",
            "loss 0.030872231349349022 average time 0.0030402724000850867 iter num 20\n",
            "loss 1.7835265398025513 average time 0.0028868745250292703 iter num 40\n",
            "loss 0.20691484212875366 average time 0.002825033950011857 iter num 60\n",
            "loss 0.39912596344947815 average time 0.0027725477625381244 iter num 80\n",
            "loss 2.1996335983276367 average time 0.002770508960038569 iter num 100\n",
            "loss 0.003721645101904869 average time 0.0027549106833854847 iter num 120\n",
            "loss 90.50936889648438 average time 0.002738720121487859 iter num 140\n",
            "loss 9.064201354980469 average time 0.0027232186812966575 iter num 160\n",
            "loss 0.6076128482818604 average time 0.002677094377840048 iter num 180\n",
            "loss 4.756329536437988 average time 0.002662607670054058 iter num 200\n",
            "loss 0.00454756710678339 average time 0.0026323025455068007 iter num 220\n",
            "loss 21.82340431213379 average time 0.002625240545883874 iter num 240\n",
            "loss 27.916688919067383 average time 0.0026042000961821873 iter num 260\n",
            "loss 37.344974517822266 average time 0.002585478364309373 iter num 280\n",
            "loss 4.544529438018799 average time 0.002563586290046563 iter num 300\n",
            "loss 9.27357006072998 average time 0.0025629821000563878 iter num 320\n",
            "loss 0.41094616055488586 average time 0.0025532109000403792 iter num 340\n",
            "loss 0.3259199559688568 average time 0.0025412151472614317 iter num 360\n",
            "loss 0.12804579734802246 average time 0.0025384171632092485 iter num 380\n",
            "loss 6.25694465637207 average time 0.0025557288075515315 iter num 400\n",
            "loss 291.6117858886719 average time 0.0025431870691049662 iter num 420\n",
            "loss 5.780240058898926 average time 0.0025318708159581794 iter num 440\n",
            "loss 46.594017028808594 average time 0.0025245736304658865 iter num 460\n",
            "loss 3.12309193611145 average time 0.0025218574583694437 iter num 480\n",
            "loss 5.87013578414917 average time 0.0025104187240394824 iter num 500\n",
            "loss 4.828198432922363 average time 0.0025050327712121474 iter num 520\n",
            "loss 5.186572551727295 average time 0.0025069012685788846 iter num 540\n",
            "loss 22.270633697509766 average time 0.002504213575057942 iter num 560\n",
            "loss 0.4822719097137451 average time 0.0024975233224722613 iter num 580\n",
            "loss 0.19863905012607574 average time 0.0024890158533859602 iter num 600\n",
            "loss 0.0014305583899840713 average time 0.0024848779951988096 iter num 620\n",
            "loss 55.505863189697266 average time 0.0024838328344117143 iter num 640\n",
            "loss 1.6274386644363403 average time 0.002479185193979819 iter num 660\n",
            "loss 30.348773956298828 average time 0.0024846771088612193 iter num 680\n",
            "loss 0.35577404499053955 average time 0.0024813406057520686 iter num 700\n",
            "loss 0.11506813764572144 average time 0.002479266191709131 iter num 720\n",
            "loss 1.5686094760894775 average time 0.002487450733821567 iter num 740\n",
            "loss 14.926769256591797 average time 0.0024957003974075058 iter num 760\n",
            "loss 0.003773876465857029 average time 0.00251106111798622 iter num 780\n",
            "loss 2.1753053665161133 average time 0.002514072805035994 iter num 800\n",
            "loss 6.903408050537109 average time 0.0025201698634568525 iter num 820\n",
            "loss 0.0001635527005419135 average time 0.002520858126228545 iter num 840\n",
            "loss 0.20972223579883575 average time 0.0025233929477106484 iter num 860\n",
            "loss 0.21266895532608032 average time 0.0025401443500393064 iter num 880\n",
            "loss 0.2598021626472473 average time 0.002542365446707764 iter num 900\n",
            "loss 0.0534517765045166 average time 0.0025388880217791588 iter num 920\n",
            "loss 43.65076446533203 average time 0.0025421283585448226 iter num 940\n",
            "loss 0.16945895552635193 average time 0.0025425101146140604 iter num 960\n",
            "loss 20.395641326904297 average time 0.002545574020446018 iter num 980\n",
            "loss 0.004165729973465204 average time 0.0025477642220375855 iter num 1000\n",
            "loss 0.08310124278068542 average time 0.003352629400069418 iter num 20\n",
            "loss 41.06809997558594 average time 0.0030032106750695676 iter num 40\n",
            "loss 2.8265810012817383 average time 0.0028480455667704518 iter num 60\n",
            "loss 8.980303764343262 average time 0.0028485525750284067 iter num 80\n",
            "loss 0.14569732546806335 average time 0.002817455819986208 iter num 100\n",
            "loss 2.5171825885772705 average time 0.002804423024993715 iter num 120\n",
            "loss 0.16731798648834229 average time 0.002847283021414374 iter num 140\n",
            "loss 4.617193222045898 average time 0.0028428291312366126 iter num 160\n",
            "loss 1.1820218563079834 average time 0.002822732716645583 iter num 180\n",
            "loss 225.8884735107422 average time 0.002804324674998497 iter num 200\n",
            "loss 36.65300369262695 average time 0.00280281708180403 iter num 220\n",
            "loss 11.802457809448242 average time 0.002778419358295044 iter num 240\n",
            "loss 150.53091430664062 average time 0.0027642422230411074 iter num 260\n",
            "loss 48.213417053222656 average time 0.00275980473211348 iter num 280\n",
            "loss 19.850032806396484 average time 0.0027487923399833864 iter num 300\n",
            "loss 30.97010040283203 average time 0.002740455209345782 iter num 320\n",
            "loss 27.63897705078125 average time 0.0027339540293723984 iter num 340\n",
            "loss 0.6088802218437195 average time 0.0027260845721836327 iter num 360\n",
            "loss 7.007553577423096 average time 0.002749086594700968 iter num 380\n",
            "loss 7.165356636047363 average time 0.002745879712479109 iter num 400\n",
            "loss 0.766018807888031 average time 0.0027425589809397586 iter num 420\n",
            "loss 39.71623992919922 average time 0.0027320862772657246 iter num 440\n",
            "loss 3.733552932739258 average time 0.0027298271717367956 iter num 460\n",
            "loss 119.36019134521484 average time 0.002718861577094837 iter num 480\n",
            "loss 0.11825849860906601 average time 0.0027164724100039164 iter num 500\n",
            "loss 70.75703430175781 average time 0.0027116315480830403 iter num 520\n",
            "loss 27.318071365356445 average time 0.002724564742601177 iter num 540\n",
            "loss 0.863623857498169 average time 0.0027264378053717207 iter num 560\n",
            "loss 0.8100986480712891 average time 0.0027157304241537247 iter num 580\n",
            "loss 2.509103298187256 average time 0.002714441316678252 iter num 600\n",
            "loss 18.224580764770508 average time 0.0027169924306573163 iter num 620\n",
            "loss 47.94267272949219 average time 0.002714157235948278 iter num 640\n",
            "loss 13.842495918273926 average time 0.002710941165161895 iter num 660\n",
            "loss 102.89356231689453 average time 0.002705042035300079 iter num 680\n",
            "loss 2.1517839431762695 average time 0.0027060272857150785 iter num 700\n",
            "loss 0.11155575513839722 average time 0.0027034582333322356 iter num 720\n",
            "loss 0.04744022339582443 average time 0.002702465972974145 iter num 740\n",
            "loss 7.94973087310791 average time 0.0027035277684191034 iter num 760\n",
            "loss 5.366550922393799 average time 0.002700720771794388 iter num 780\n",
            "loss 0.694273054599762 average time 0.0026980615950037644 iter num 800\n",
            "loss 2.637601613998413 average time 0.0026902979487847295 iter num 820\n",
            "loss 0.9578998684883118 average time 0.00268906996786557 iter num 840\n",
            "loss 0.0022343795280903578 average time 0.0026857228418732627 iter num 860\n",
            "loss 96.50357818603516 average time 0.0026941250306911323 iter num 880\n",
            "loss 4.365462303161621 average time 0.0026927170600134155 iter num 900\n",
            "loss 1.313551902770996 average time 0.002688291540228064 iter num 920\n",
            "loss 0.03986004739999771 average time 0.0026830544649106124 iter num 940\n",
            "loss 40.2725944519043 average time 0.0026777581156447166 iter num 960\n",
            "loss 0.039339806884527206 average time 0.0026752078153308226 iter num 980\n",
            "loss 1.0662246942520142 average time 0.0026763646520212205 iter num 1000\n",
            "loss 13.855897903442383 average time 0.0032729096000366554 iter num 20\n",
            "loss 25.314359664916992 average time 0.0028169564249765243 iter num 40\n",
            "loss 0.8357473611831665 average time 0.0027758350000112843 iter num 60\n",
            "loss 0.9881032109260559 average time 0.002805268087490731 iter num 80\n",
            "loss 4.672539710998535 average time 0.002856855969930621 iter num 100\n",
            "loss 7.718046188354492 average time 0.002815711783326454 iter num 120\n",
            "loss 44.096683502197266 average time 0.002829295507126517 iter num 140\n",
            "loss 0.03312520682811737 average time 0.002791853106214148 iter num 160\n",
            "loss 4.973238468170166 average time 0.002792438677756258 iter num 180\n",
            "loss 16.19474220275879 average time 0.0027843896249760292 iter num 200\n",
            "loss 2.1580615043640137 average time 0.0027725947227075017 iter num 220\n",
            "loss 0.017507679760456085 average time 0.002772414641647932 iter num 240\n",
            "loss 0.04760424420237541 average time 0.002772700103804919 iter num 260\n",
            "loss 0.020961811766028404 average time 0.0027573552999651187 iter num 280\n",
            "loss 13.90854263305664 average time 0.0027465456066480933 iter num 300\n",
            "loss 170.58566284179688 average time 0.0027441004655941017 iter num 320\n",
            "loss 0.57353276014328 average time 0.0027332466264530977 iter num 340\n",
            "loss 0.9708086848258972 average time 0.0027242282166500646 iter num 360\n",
            "loss 3.686422348022461 average time 0.0027470113341941647 iter num 380\n",
            "loss 0.942780613899231 average time 0.002747669219970703 iter num 400\n",
            "loss 2.0007705688476562 average time 0.0027433743332992543 iter num 420\n",
            "loss 0.23697514832019806 average time 0.0027373363431541457 iter num 440\n",
            "loss 1.1709704399108887 average time 0.0027388606021581242 iter num 460\n",
            "loss 0.11559750884771347 average time 0.002737325206233739 iter num 480\n",
            "loss 2.131834030151367 average time 0.002732269843982067 iter num 500\n",
            "loss 7.758200168609619 average time 0.0027221427057611434 iter num 520\n",
            "loss 3.219581127166748 average time 0.002732768996291405 iter num 540\n",
            "loss 0.022523637861013412 average time 0.0027337616892802023 iter num 560\n",
            "loss 0.32269424200057983 average time 0.002726579460337736 iter num 580\n",
            "loss 2.5942766666412354 average time 0.0027286569616414152 iter num 600\n",
            "loss 16.0029296875 average time 0.0027293967693367447 iter num 620\n",
            "loss 1.7860950231552124 average time 0.002736180259356047 iter num 640\n",
            "loss 0.3897671699523926 average time 0.00273756761362165 iter num 660\n",
            "loss 1.4840872287750244 average time 0.002734263760278148 iter num 680\n",
            "loss 0.8024039268493652 average time 0.0027379656971243094 iter num 700\n",
            "loss 0.9348068237304688 average time 0.00272636872637122 iter num 720\n",
            "loss 186.5531768798828 average time 0.002717836856739981 iter num 740\n",
            "loss 0.022122114896774292 average time 0.0027090351697217174 iter num 760\n",
            "loss 34.75692367553711 average time 0.002708203557684987 iter num 780\n",
            "loss 0.00038767876685597 average time 0.002697577979995458 iter num 800\n",
            "loss 10.081830978393555 average time 0.002687256774387185 iter num 820\n",
            "loss 3.3083906173706055 average time 0.002679220579760849 iter num 840\n",
            "loss 28.225088119506836 average time 0.0026782514023305044 iter num 860\n",
            "loss 0.009709368459880352 average time 0.0026707325193187485 iter num 880\n",
            "loss 0.04885309934616089 average time 0.0026618976233334654 iter num 900\n",
            "loss 3.3419015407562256 average time 0.002654292208685745 iter num 920\n",
            "loss 0.885236918926239 average time 0.0026565709787064406 iter num 940\n",
            "loss 0.12663480639457703 average time 0.0026505299437341516 iter num 960\n",
            "loss 0.27137142419815063 average time 0.0026446032244778934 iter num 980\n",
            "loss 0.12870436906814575 average time 0.0026389066519986954 iter num 1000\n",
            "loss 2.751962423324585 average time 0.003391358550015866 iter num 20\n",
            "loss 2.350698709487915 average time 0.002883838050047416 iter num 40\n",
            "loss 309.88726806640625 average time 0.002697482016780365 iter num 60\n",
            "loss 1.3007034063339233 average time 0.002630369075109229 iter num 80\n",
            "loss 0.40256911516189575 average time 0.002632114270090824 iter num 100\n",
            "loss 3.978563070297241 average time 0.002589038350076104 iter num 120\n",
            "loss 2.0022923946380615 average time 0.002646979800088697 iter num 140\n",
            "loss 1.9813227653503418 average time 0.0026159273938446857 iter num 160\n",
            "loss 0.043537456542253494 average time 0.0025997241889652084 iter num 180\n",
            "loss 25.56591033935547 average time 0.0025663283050653264 iter num 200\n",
            "loss 71.74867248535156 average time 0.0025779278773453286 iter num 220\n",
            "loss 1.514165997505188 average time 0.002550560745870219 iter num 240\n",
            "loss 124.92025756835938 average time 0.0025494572615571086 iter num 260\n",
            "loss 3.2686781883239746 average time 0.0025390503607078635 iter num 280\n",
            "loss 11.237421035766602 average time 0.002521489116691858 iter num 300\n",
            "loss 51.18025207519531 average time 0.0025062726406588354 iter num 320\n",
            "loss 19.97755241394043 average time 0.0025214549529664508 iter num 340\n",
            "loss 0.7045063972473145 average time 0.0025087439139042543 iter num 360\n",
            "loss 0.9271583557128906 average time 0.0024979565526624162 iter num 380\n",
            "loss 135.89279174804688 average time 0.0025215499375235593 iter num 400\n",
            "loss 0.9144709706306458 average time 0.002525833854776595 iter num 420\n",
            "loss 0.20694653689861298 average time 0.002519893993204195 iter num 440\n",
            "loss 5.768616676330566 average time 0.002519955432636261 iter num 460\n",
            "loss 13.209691047668457 average time 0.002524499225027436 iter num 480\n",
            "loss 0.3900434672832489 average time 0.002518247706040711 iter num 500\n",
            "loss 24.032825469970703 average time 0.0025105639327333705 iter num 520\n",
            "loss 0.42896342277526855 average time 0.002504829712998563 iter num 540\n",
            "loss 13.176962852478027 average time 0.0025056981857525377 iter num 560\n",
            "loss 0.011634724214673042 average time 0.0024968218121071474 iter num 580\n",
            "loss 1.7944893836975098 average time 0.0024912782267134995 iter num 600\n",
            "loss 1.8366130590438843 average time 0.0024880053645574664 iter num 620\n",
            "loss 1.3803812265396118 average time 0.0024823287312926825 iter num 640\n",
            "loss 7.576070308685303 average time 0.0025028349333793315 iter num 660\n",
            "loss 1.388819932937622 average time 0.0024962882470978966 iter num 680\n",
            "loss 0.7583657503128052 average time 0.002498329120039021 iter num 700\n",
            "loss 0.6229026317596436 average time 0.0024992139180868536 iter num 720\n",
            "loss 26.02477264404297 average time 0.0024973174554385903 iter num 740\n",
            "loss 0.8522517085075378 average time 0.0024951676566017434 iter num 760\n",
            "loss 0.14685660600662231 average time 0.0024901302372036765 iter num 780\n",
            "loss 13.007878303527832 average time 0.002499516357520406 iter num 800\n",
            "loss 16.82801055908203 average time 0.002496248436605905 iter num 820\n",
            "loss 25.10218620300293 average time 0.002490865426207598 iter num 840\n",
            "loss 10.746533393859863 average time 0.00248831673722613 iter num 860\n",
            "loss 0.087753526866436 average time 0.002489179039798728 iter num 880\n",
            "loss 0.9411392211914062 average time 0.0024893098144699857 iter num 900\n",
            "loss 0.0009017837583087385 average time 0.002485244444596901 iter num 920\n",
            "loss 0.08637329190969467 average time 0.0024865765181199635 iter num 940\n",
            "loss 1.5248873233795166 average time 0.0024868645229503272 iter num 960\n",
            "loss 1.9596410989761353 average time 0.0024848020898240735 iter num 980\n",
            "loss 0.017071139067411423 average time 0.0024799962290326222 iter num 1000\n",
            "loss 0.004141798242926598 average time 0.0032163227499950155 iter num 20\n",
            "loss 2.776475667953491 average time 0.0029290570999819464 iter num 40\n",
            "loss 2.060856342315674 average time 0.002744676416599153 iter num 60\n",
            "loss 16.42598533630371 average time 0.002652360699948986 iter num 80\n",
            "loss 3.363346576690674 average time 0.002601255899971875 iter num 100\n",
            "loss 1.209546685218811 average time 0.0026091314666700782 iter num 120\n",
            "loss 1.9277210235595703 average time 0.0026171910571455167 iter num 140\n",
            "loss 0.008219598792493343 average time 0.0025731493562716422 iter num 160\n",
            "loss 3.932278871536255 average time 0.0025389602055838623 iter num 180\n",
            "loss 8.862786293029785 average time 0.002544666130015685 iter num 200\n",
            "loss 1.885844349861145 average time 0.0025181833863991247 iter num 220\n",
            "loss 0.9819169044494629 average time 0.002495319158363903 iter num 240\n",
            "loss 2.997037649154663 average time 0.002480584953872704 iter num 260\n",
            "loss 0.2538909912109375 average time 0.0024754296036072834 iter num 280\n",
            "loss 0.060239627957344055 average time 0.0024621654900511204 iter num 300\n",
            "loss 110.61046600341797 average time 0.0024578412781750105 iter num 320\n",
            "loss 975.2311401367188 average time 0.002456472252994418 iter num 340\n",
            "loss 44.05251693725586 average time 0.0024665828500625747 iter num 360\n",
            "loss 3.607701301574707 average time 0.0024627646132150977 iter num 380\n",
            "loss 6.918957233428955 average time 0.0024827437250496587 iter num 400\n",
            "loss 4.515300750732422 average time 0.0024841815548175615 iter num 420\n",
            "loss 4.596985816955566 average time 0.002480397302336066 iter num 440\n",
            "loss 0.0130003085359931 average time 0.0024713325457053977 iter num 460\n",
            "loss 0.4275355041027069 average time 0.002465968918818362 iter num 480\n",
            "loss 34.82760238647461 average time 0.0024651200500702543 iter num 500\n",
            "loss 19.188720703125 average time 0.002468368838533654 iter num 520\n",
            "loss 2.4841103553771973 average time 0.0024637259167320734 iter num 540\n",
            "loss 0.0446137972176075 average time 0.0024601086607780025 iter num 560\n",
            "loss 0.9286428689956665 average time 0.0024543052983376427 iter num 580\n",
            "loss 0.46285706758499146 average time 0.002461261985051048 iter num 600\n",
            "loss 0.12081597000360489 average time 0.0024572188581201302 iter num 620\n",
            "loss 122.259765625 average time 0.0024574346734823394 iter num 640\n",
            "loss 1.9702608585357666 average time 0.0024598451879214596 iter num 660\n",
            "loss 0.4708326756954193 average time 0.0024683473029814625 iter num 680\n",
            "loss 0.16044947504997253 average time 0.0024729386357518835 iter num 700\n",
            "loss 0.9456393122673035 average time 0.002467165644472718 iter num 720\n",
            "loss 3.8071908950805664 average time 0.002464358417595626 iter num 740\n",
            "loss 0.24780257046222687 average time 0.002471499948710755 iter num 760\n",
            "loss 2.044835329055786 average time 0.002467916703874205 iter num 780\n",
            "loss 2.9939279556274414 average time 0.0024673831812788193 iter num 800\n",
            "loss 29.166690826416016 average time 0.002465508876853497 iter num 820\n",
            "loss 32.647056579589844 average time 0.0024718665547836627 iter num 840\n",
            "loss 0.11672603338956833 average time 0.002467585502347711 iter num 860\n",
            "loss 1.3171941041946411 average time 0.002465492506838597 iter num 880\n",
            "loss 0.20896758139133453 average time 0.00246357321780023 iter num 900\n",
            "loss 0.041495658457279205 average time 0.002463010423936952 iter num 920\n",
            "loss 0.3131104111671448 average time 0.002459524674488537 iter num 940\n",
            "loss 0.20308132469654083 average time 0.0024574463541872167 iter num 960\n",
            "loss 0.06373152136802673 average time 0.0024547874949218695 iter num 980\n",
            "loss 6.138917922973633 average time 0.002457330980021652 iter num 1000\n",
            "loss 9.687105178833008 average time 0.003454842350038234 iter num 20\n",
            "loss 0.7736545205116272 average time 0.002892406149931048 iter num 40\n",
            "loss 0.41159871220588684 average time 0.002681724516575438 iter num 60\n",
            "loss 46.364376068115234 average time 0.002701498487408571 iter num 80\n",
            "loss 0.05338124558329582 average time 0.002688397229921975 iter num 100\n",
            "loss 0.1997668296098709 average time 0.0026433538999450926 iter num 120\n",
            "loss 19.228862762451172 average time 0.002598490764259103 iter num 140\n",
            "loss 2.186978578567505 average time 0.002601635712494499 iter num 160\n",
            "loss 0.19973674416542053 average time 0.0025843666833376727 iter num 180\n",
            "loss 2.9233474731445312 average time 0.0025601209750038835 iter num 200\n",
            "loss 0.8853256106376648 average time 0.002543161231816074 iter num 220\n",
            "loss 180.31797790527344 average time 0.002529101308346071 iter num 240\n",
            "loss 12.293885231018066 average time 0.0025284641038734452 iter num 260\n",
            "loss 0.025784609839320183 average time 0.0025159792928856665 iter num 280\n",
            "loss 0.23603282868862152 average time 0.002518719763362848 iter num 300\n",
            "loss 0.004755770787596703 average time 0.0025187162781492136 iter num 320\n",
            "loss 13.80427360534668 average time 0.002513473452954178 iter num 340\n",
            "loss 0.35836124420166016 average time 0.002505863113891691 iter num 360\n",
            "loss 142.36550903320312 average time 0.0024976676973749003 iter num 380\n",
            "loss 0.006227708887308836 average time 0.0024931689825280047 iter num 400\n",
            "loss 0.24219447374343872 average time 0.0024919569047813727 iter num 420\n",
            "loss 7.713934898376465 average time 0.0024862096568499096 iter num 440\n",
            "loss 210.46710205078125 average time 0.0024789751217727113 iter num 460\n",
            "loss 3.798948049545288 average time 0.0024715732166972278 iter num 480\n",
            "loss 6.5232319831848145 average time 0.002465037296031369 iter num 500\n",
            "loss 10.434523582458496 average time 0.0024580516884830455 iter num 520\n",
            "loss 0.09972704946994781 average time 0.002456663974091363 iter num 540\n",
            "loss 23.793601989746094 average time 0.002453016192875371 iter num 560\n",
            "loss 2.841505527496338 average time 0.0024584453551926406 iter num 580\n",
            "loss 5.45322847366333 average time 0.0024529148533565604 iter num 600\n",
            "loss 58.68734359741211 average time 0.002451638256479782 iter num 620\n",
            "loss 0.061370279639959335 average time 0.0024500573406669446 iter num 640\n",
            "loss 2.0415637493133545 average time 0.0024538325742772334 iter num 660\n",
            "loss 0.12889279425144196 average time 0.0024516782426845193 iter num 680\n",
            "loss 33.250614166259766 average time 0.0024540079271823095 iter num 700\n",
            "loss 0.3379637598991394 average time 0.002449585094478203 iter num 720\n",
            "loss 186.9120330810547 average time 0.0024479832257040127 iter num 740\n",
            "loss 8.481980323791504 average time 0.0024445005000248592 iter num 760\n",
            "loss 0.7720720171928406 average time 0.0024481030474653846 iter num 780\n",
            "loss 0.061409976333379745 average time 0.002452062136283075 iter num 800\n",
            "loss 0.015993356704711914 average time 0.0024551506792992836 iter num 820\n",
            "loss 5.9607625007629395 average time 0.0024630501536107444 iter num 840\n",
            "loss 22.51704216003418 average time 0.0024697880570149506 iter num 860\n",
            "loss 0.002232092432677746 average time 0.0024740836795858327 iter num 880\n",
            "loss 0.1484527289867401 average time 0.0024776300622620004 iter num 900\n",
            "loss 0.02640128880739212 average time 0.00248399348917266 iter num 920\n",
            "loss 0.1890752762556076 average time 0.0024964407266432976 iter num 940\n",
            "loss 0.06289598345756531 average time 0.002500335612537204 iter num 960\n",
            "loss 0.7254445552825928 average time 0.0025079064051355166 iter num 980\n",
            "loss 1.7170032262802124 average time 0.002513549325032727 iter num 1000\n",
            "loss 12.362247467041016 average time 0.0033616073999837683 iter num 20\n",
            "loss 0.16941621899604797 average time 0.0030121967497507285 iter num 40\n",
            "loss 0.17684414982795715 average time 0.0028915369164375687 iter num 60\n",
            "loss 4.9232707023620605 average time 0.0028167766874275914 iter num 80\n",
            "loss 18.660518646240234 average time 0.0027958602999751747 iter num 100\n",
            "loss 6.95035457611084 average time 0.00279486077497495 iter num 120\n",
            "loss 0.5018528699874878 average time 0.0027858160571538194 iter num 140\n",
            "loss 3.677053213119507 average time 0.0028106680375003636 iter num 160\n",
            "loss 0.28133559226989746 average time 0.002788340716657937 iter num 180\n",
            "loss 4.273125171661377 average time 0.002783747895009583 iter num 200\n",
            "loss 0.6522209048271179 average time 0.0027667613090753464 iter num 220\n",
            "loss 223.10748291015625 average time 0.002753676424974098 iter num 240\n",
            "loss 192.32513427734375 average time 0.0027464747422877387 iter num 260\n",
            "loss 0.12446675449609756 average time 0.0027409782714130416 iter num 280\n",
            "loss 21.316482543945312 average time 0.0027266835766689233 iter num 300\n",
            "loss 0.0014548504259437323 average time 0.0027134826031328884 iter num 320\n",
            "loss 2.16072416305542 average time 0.002717534888249836 iter num 340\n",
            "loss 6.189289569854736 average time 0.002712356372244863 iter num 360\n",
            "loss 4.072930812835693 average time 0.002721678976333925 iter num 380\n",
            "loss 8.61772632598877 average time 0.0027185263625142397 iter num 400\n",
            "loss 2.6476662158966064 average time 0.00271623015954295 iter num 420\n",
            "loss 22.172809600830078 average time 0.002705610981828696 iter num 440\n",
            "loss 0.03222246840596199 average time 0.002718623121753531 iter num 460\n",
            "loss 0.0320003479719162 average time 0.0027149432958481156 iter num 480\n",
            "loss 1.2695977687835693 average time 0.0027190496220100614 iter num 500\n",
            "loss 0.4023132622241974 average time 0.002712552663461583 iter num 520\n",
            "loss 29.713693618774414 average time 0.002716654529632689 iter num 540\n",
            "loss 67.97943878173828 average time 0.0027100149767972782 iter num 560\n",
            "loss 0.2578967809677124 average time 0.0026993783258713565 iter num 580\n",
            "loss 2.707024335861206 average time 0.0026945749283398377 iter num 600\n",
            "loss 0.5575442314147949 average time 0.0026971382629081718 iter num 620\n",
            "loss 0.8176148533821106 average time 0.0026930276656344176 iter num 640\n",
            "loss 2.7239906787872314 average time 0.002695346148495005 iter num 660\n",
            "loss 4.879477024078369 average time 0.002692389489718206 iter num 680\n",
            "loss 0.409648060798645 average time 0.0026915434043049964 iter num 700\n",
            "loss 1.1778687238693237 average time 0.0026947026875227998 iter num 720\n",
            "loss 0.717159628868103 average time 0.0026923433175938586 iter num 740\n",
            "loss 0.06597454100847244 average time 0.002689749401341894 iter num 760\n",
            "loss 4.521528244018555 average time 0.0026879999705390497 iter num 780\n",
            "loss 0.3695315718650818 average time 0.0026906870737775533 iter num 800\n",
            "loss 0.14928007125854492 average time 0.002691810369538516 iter num 820\n",
            "loss 2.1047041416168213 average time 0.0026852810262122753 iter num 840\n",
            "loss 0.19969862699508667 average time 0.002688077673278607 iter num 860\n",
            "loss 0.5979105830192566 average time 0.0026879905818366916 iter num 880\n",
            "loss 15.349701881408691 average time 0.002685944554460649 iter num 900\n",
            "loss 0.09535728394985199 average time 0.002685705588055498 iter num 920\n",
            "loss 4.013194561004639 average time 0.00268515002234903 iter num 940\n",
            "loss 0.006423507817089558 average time 0.002682223350007007 iter num 960\n",
            "loss 0.801794171333313 average time 0.002690407776533123 iter num 980\n",
            "loss 1.5328303575515747 average time 0.002689571737004371 iter num 1000\n",
            "loss 0.9999237060546875 average time 0.003091190849954728 iter num 20\n",
            "loss 8.411380767822266 average time 0.0028386220499669436 iter num 40\n",
            "loss 0.7058109641075134 average time 0.0027996441500666453 iter num 60\n",
            "loss 12.412944793701172 average time 0.0027316636375871893 iter num 80\n",
            "loss 9.387786865234375 average time 0.0027059124700645042 iter num 100\n",
            "loss 7.029019832611084 average time 0.0026511827834080274 iter num 120\n",
            "loss 10.21453857421875 average time 0.0026366334286389505 iter num 140\n",
            "loss 291.7363586425781 average time 0.002621982975040282 iter num 160\n",
            "loss 0.16125278174877167 average time 0.002644535861145414 iter num 180\n",
            "loss 3.358071804046631 average time 0.002637372890039842 iter num 200\n",
            "loss 13.9819917678833 average time 0.0026243194909263616 iter num 220\n",
            "loss 90.69876861572266 average time 0.002627727379172029 iter num 240\n",
            "loss 0.11537332087755203 average time 0.0026305322192316594 iter num 260\n",
            "loss 0.6667305827140808 average time 0.002632386710709917 iter num 280\n",
            "loss 0.5955861806869507 average time 0.002645260253351201 iter num 300\n",
            "loss 0.33640211820602417 average time 0.002647488887498639 iter num 320\n",
            "loss 6.032766819000244 average time 0.0026440367205823887 iter num 340\n",
            "loss 22.037755966186523 average time 0.0026617697972091668 iter num 360\n",
            "loss 0.038072362542152405 average time 0.0026683594289400054 iter num 380\n",
            "loss 0.6640989780426025 average time 0.002670182130000285 iter num 400\n",
            "loss 0.9277167320251465 average time 0.0026636978785713186 iter num 420\n",
            "loss 0.002875856589525938 average time 0.0026672171295475974 iter num 440\n",
            "loss 3.014371633529663 average time 0.002672738171741398 iter num 460\n",
            "loss 2.893758535385132 average time 0.0026776475437486624 iter num 480\n",
            "loss 5.784842491149902 average time 0.0026974952499913343 iter num 500\n",
            "loss 0.06440096348524094 average time 0.002698515619228531 iter num 520\n",
            "loss 1.5492531061172485 average time 0.002699495972211918 iter num 540\n",
            "loss 1.247588038444519 average time 0.0026957362178336554 iter num 560\n",
            "loss 2.282857894897461 average time 0.0027012562775592507 iter num 580\n",
            "loss 4.200479507446289 average time 0.002692195539981791 iter num 600\n",
            "loss 6.0835862159729 average time 0.002692559116114294 iter num 620\n",
            "loss 1.1154295206069946 average time 0.0026937681812256643 iter num 640\n",
            "loss 269.37738037109375 average time 0.002687192051499468 iter num 660\n",
            "loss 0.40479087829589844 average time 0.002688176497049961 iter num 680\n",
            "loss 0.3141700327396393 average time 0.0026903413842800155 iter num 700\n",
            "loss 2.5981733798980713 average time 0.00268604965971109 iter num 720\n",
            "loss 0.012654362246394157 average time 0.0026832648932385555 iter num 740\n",
            "loss 0.015998972579836845 average time 0.002685311886836261 iter num 760\n",
            "loss 2.021099328994751 average time 0.002684690205124076 iter num 780\n",
            "loss 6.456644058227539 average time 0.0026775383962399247 iter num 800\n",
            "loss 3.9836745262145996 average time 0.0026686216463331666 iter num 820\n",
            "loss 0.2368268221616745 average time 0.0026602887321327475 iter num 840\n",
            "loss 0.0003787255263887346 average time 0.00266291721743052 iter num 860\n",
            "loss 0.4309616982936859 average time 0.0026559532886308674 iter num 880\n",
            "loss 46.65976333618164 average time 0.0026496191144380846 iter num 900\n",
            "loss 0.6787329912185669 average time 0.002642269427172758 iter num 920\n",
            "loss 11.106245994567871 average time 0.002643906832969499 iter num 940\n",
            "loss 0.0003308206796646118 average time 0.0026369703999876036 iter num 960\n",
            "loss 0.45406490564346313 average time 0.0026358191632444147 iter num 980\n",
            "loss 2.0676019191741943 average time 0.002629392029983137 iter num 1000\n",
            "loss 7.8611159324646 average time 0.003920982400086359 iter num 20\n",
            "loss 1.975408673286438 average time 0.0032607126001039433 iter num 40\n",
            "loss 0.5820009708404541 average time 0.0031024443166946486 iter num 60\n",
            "loss 0.3170454800128937 average time 0.0029032326875267243 iter num 80\n",
            "loss 0.26716718077659607 average time 0.0027898632200594876 iter num 100\n",
            "loss 1.400659441947937 average time 0.002705275216734056 iter num 120\n",
            "loss 1.2989550828933716 average time 0.0026547277500737565 iter num 140\n",
            "loss 1.9993785619735718 average time 0.00261915081882762 iter num 160\n",
            "loss 16.920087814331055 average time 0.0026153954722960607 iter num 180\n",
            "loss 29.37447738647461 average time 0.0026034778050870954 iter num 200\n",
            "loss 0.6755437254905701 average time 0.002573549754635513 iter num 220\n",
            "loss 272.5229797363281 average time 0.0025596951000807166 iter num 240\n",
            "loss 5.921144008636475 average time 0.0025627802462272835 iter num 260\n",
            "loss 3.0532543659210205 average time 0.002587594639375571 iter num 280\n",
            "loss 2.1856701374053955 average time 0.0025637668667513936 iter num 300\n",
            "loss 1.4639132022857666 average time 0.0025581369719532175 iter num 320\n",
            "loss 597.1556396484375 average time 0.0025406229441881914 iter num 340\n",
            "loss 0.7501958012580872 average time 0.0025583689445081996 iter num 360\n",
            "loss 0.7492775917053223 average time 0.002547697555320682 iter num 380\n",
            "loss 0.5637452602386475 average time 0.0025375393025706214 iter num 400\n",
            "loss 2.0482189655303955 average time 0.002526264652442478 iter num 420\n",
            "loss 5.321946144104004 average time 0.0025156013773291555 iter num 440\n",
            "loss 5.574123382568359 average time 0.002508395382653322 iter num 460\n",
            "loss 15.484063148498535 average time 0.002509232114630322 iter num 480\n",
            "loss 49.417449951171875 average time 0.002498445428052946 iter num 500\n",
            "loss 36.729305267333984 average time 0.002492250911592027 iter num 520\n",
            "loss 1.4561964273452759 average time 0.0024871391685674436 iter num 540\n",
            "loss 6.681076526641846 average time 0.0024862243804071632 iter num 560\n",
            "loss 1.2690949440002441 average time 0.0024827684207405676 iter num 580\n",
            "loss 1.0325899124145508 average time 0.0024850961400443338 iter num 600\n",
            "loss 0.07709955424070358 average time 0.002483592280690749 iter num 620\n",
            "loss 2.7880020141601562 average time 0.0024912265734855056 iter num 640\n",
            "loss 1.6624560356140137 average time 0.002486727675808321 iter num 660\n",
            "loss 6.361231327056885 average time 0.002481775891232353 iter num 680\n",
            "loss 0.18191654980182648 average time 0.0024776215914867603 iter num 700\n",
            "loss 0.1253862977027893 average time 0.002474318765335839 iter num 720\n",
            "loss 67.08076477050781 average time 0.00246959889059449 iter num 740\n",
            "loss 0.23751698434352875 average time 0.0024737140000620694 iter num 760\n",
            "loss 8.132692337036133 average time 0.002477133885953756 iter num 780\n",
            "loss 79.36369323730469 average time 0.0024726270888004364 iter num 800\n",
            "loss 7.131477355957031 average time 0.0024712318159001326 iter num 820\n",
            "loss 2.1856024265289307 average time 0.0024748224810060664 iter num 840\n",
            "loss 3.0217809677124023 average time 0.0024750665151682476 iter num 860\n",
            "loss 2.5328927222290076e-05 average time 0.0024749248693669043 iter num 880\n",
            "loss 0.004299552645534277 average time 0.0024711076322677804 iter num 900\n",
            "loss 6.581429481506348 average time 0.0024787393446094146 iter num 920\n",
            "loss 0.09210599213838577 average time 0.0024757926106816586 iter num 940\n",
            "loss 0.008162176236510277 average time 0.0024799071573321876 iter num 960\n",
            "loss 260.6153564453125 average time 0.0024765965500424796 iter num 980\n",
            "loss 1.965444803237915 average time 0.0024787455510340804 iter num 1000\n",
            "loss 2.0942535400390625 average time 0.0029392983498837564 iter num 20\n",
            "loss 1.1965394020080566 average time 0.002842341774885426 iter num 40\n",
            "loss 2.3910984992980957 average time 0.002656718233326198 iter num 60\n",
            "loss 117.58393859863281 average time 0.0026245401500545997 iter num 80\n",
            "loss 1.0312379598617554 average time 0.0025615256100718397 iter num 100\n",
            "loss 4.002075672149658 average time 0.002568591033392901 iter num 120\n",
            "loss 2.4640846252441406 average time 0.002531173607206126 iter num 140\n",
            "loss 5.670839309692383 average time 0.0025047930875530255 iter num 160\n",
            "loss 1.932989239692688 average time 0.0025333690722719538 iter num 180\n",
            "loss 1.3141065835952759 average time 0.0025203173250338295 iter num 200\n",
            "loss 11.378628730773926 average time 0.002516732509105747 iter num 220\n",
            "loss 10.384806632995605 average time 0.0025058880333593456 iter num 240\n",
            "loss 3.869340419769287 average time 0.002514696034631925 iter num 260\n",
            "loss 0.04381808638572693 average time 0.002534828678562917 iter num 280\n",
            "loss 5.227781295776367 average time 0.0025408071699833576 iter num 300\n",
            "loss 14.369413375854492 average time 0.002526879753116873 iter num 320\n",
            "loss 1.990197777748108 average time 0.002541884641178673 iter num 340\n",
            "loss 0.16520027816295624 average time 0.00254253088056531 iter num 360\n",
            "loss 0.9850741028785706 average time 0.0025346940526392962 iter num 380\n",
            "loss 16.034320831298828 average time 0.0025289989800012336 iter num 400\n",
            "loss 0.07653704285621643 average time 0.0025283040500003805 iter num 420\n",
            "loss 19.83344841003418 average time 0.002529243295459144 iter num 440\n",
            "loss 7.402723789215088 average time 0.00251988289349 iter num 460\n",
            "loss 23.440656661987305 average time 0.002511272768769383 iter num 480\n",
            "loss 5.119069576263428 average time 0.0025068976980146544 iter num 500\n",
            "loss 0.501800000667572 average time 0.0025131547865455033 iter num 520\n",
            "loss 3.687828540802002 average time 0.0025129595129732884 iter num 540\n",
            "loss 0.377547025680542 average time 0.002506505896436855 iter num 560\n",
            "loss 52.595027923583984 average time 0.0025014653344975347 iter num 580\n",
            "loss 32.67670822143555 average time 0.002511496215010993 iter num 600\n",
            "loss 0.8309104442596436 average time 0.002513763893561953 iter num 620\n",
            "loss 1.927519679069519 average time 0.0025070021515773535 iter num 640\n",
            "loss 1.6995826959609985 average time 0.0025057964303138733 iter num 660\n",
            "loss 13.598837852478027 average time 0.0025062750161851 iter num 680\n",
            "loss 0.006441560108214617 average time 0.0025016772771518196 iter num 700\n",
            "loss 5.853013038635254 average time 0.002506426818068677 iter num 720\n",
            "loss 0.2655230760574341 average time 0.0025021102283898397 iter num 740\n",
            "loss 0.10448551177978516 average time 0.002496922680273584 iter num 760\n",
            "loss 4.253937721252441 average time 0.002496484270518405 iter num 780\n",
            "loss 0.009779848158359528 average time 0.002497965043755812 iter num 800\n",
            "loss 2486.856689453125 average time 0.002497438763422418 iter num 820\n",
            "loss 0.8087912797927856 average time 0.0024969561833434756 iter num 840\n",
            "loss 8.239214897155762 average time 0.002492887173268046 iter num 860\n",
            "loss 1.3683422803878784 average time 0.002487957370466244 iter num 880\n",
            "loss 3.9721555709838867 average time 0.002486773331121286 iter num 900\n",
            "loss 1.3870301246643066 average time 0.002484695714136488 iter num 920\n",
            "loss 0.01913267746567726 average time 0.0024812922138366085 iter num 940\n",
            "loss 0.07886168360710144 average time 0.0024771650031330714 iter num 960\n",
            "loss 4.048439979553223 average time 0.0024738502836786505 iter num 980\n",
            "loss 0.8500504493713379 average time 0.0024763077340066958 iter num 1000\n",
            "loss 9.175761222839355 average time 0.0029858684999453542 iter num 20\n",
            "loss 4.8858160972595215 average time 0.0026646587250525045 iter num 40\n",
            "loss 4.9986042976379395 average time 0.0027716757501063207 iter num 60\n",
            "loss 14.270069122314453 average time 0.002648152650067459 iter num 80\n",
            "loss 2.4347589015960693 average time 0.0026595185600490367 iter num 100\n",
            "loss 5.474154949188232 average time 0.0026186825583711954 iter num 120\n",
            "loss 5.22396183013916 average time 0.002580785178594981 iter num 140\n",
            "loss 0.43102869391441345 average time 0.0025470106124885206 iter num 160\n",
            "loss 37.84870529174805 average time 0.0025160728555420064 iter num 180\n",
            "loss 4.979016304016113 average time 0.0024951900099677003 iter num 200\n",
            "loss 4.202856540679932 average time 0.002480393977202766 iter num 220\n",
            "loss 2.5497026443481445 average time 0.0025134610582578415 iter num 240\n",
            "loss 2.4389421939849854 average time 0.0025055573114793964 iter num 260\n",
            "loss 1.10356605052948 average time 0.0024931972070914655 iter num 280\n",
            "loss 33.15275573730469 average time 0.0025003710266355483 iter num 300\n",
            "loss 0.5085502862930298 average time 0.002508004784328932 iter num 320\n",
            "loss 6.363617420196533 average time 0.0024947383264321507 iter num 340\n",
            "loss 14.88506031036377 average time 0.002491904405522089 iter num 360\n",
            "loss 0.7085152864456177 average time 0.0025076973420829363 iter num 380\n",
            "loss 53.11708450317383 average time 0.0024994148674795723 iter num 400\n",
            "loss 0.11212057620286942 average time 0.0024918092690227023 iter num 420\n",
            "loss 0.5451591610908508 average time 0.0024917324181594515 iter num 440\n",
            "loss 1.1839874982833862 average time 0.0024917796521549463 iter num 460\n",
            "loss 5.590310096740723 average time 0.0024856296562309884 iter num 480\n",
            "loss 11.36499309539795 average time 0.0024837079159806307 iter num 500\n",
            "loss 0.011687039397656918 average time 0.002472930032662099 iter num 520\n",
            "loss 3.4252047538757324 average time 0.002477903459229883 iter num 540\n",
            "loss 0.27449822425842285 average time 0.0024720291178320104 iter num 560\n",
            "loss 3.2374846935272217 average time 0.002477875894792619 iter num 580\n",
            "loss 0.7909615635871887 average time 0.0024690344516329786 iter num 600\n",
            "loss 5.369838714599609 average time 0.002476465524162655 iter num 620\n",
            "loss 0.00445024436339736 average time 0.0024738844905897394 iter num 640\n",
            "loss 2.9122629165649414 average time 0.002469308730266648 iter num 660\n",
            "loss 173.5252227783203 average time 0.0024656369249629172 iter num 680\n",
            "loss 2.0740575790405273 average time 0.0024727825442460018 iter num 700\n",
            "loss 7.443132400512695 average time 0.0024676743138469545 iter num 720\n",
            "loss 7.694431304931641 average time 0.002464522105362227 iter num 740\n",
            "loss 41.4554557800293 average time 0.002458840173645321 iter num 760\n",
            "loss 5.354309558868408 average time 0.002456483983298359 iter num 780\n",
            "loss 1.9236409664154053 average time 0.00245284734871575 iter num 800\n",
            "loss 0.28504234552383423 average time 0.002448633091430898 iter num 820\n",
            "loss 3.8935704231262207 average time 0.0024590277535415745 iter num 840\n",
            "loss 3.710808277130127 average time 0.002460416881369256 iter num 860\n",
            "loss 1.669924020767212 average time 0.0024564242670190983 iter num 880\n",
            "loss 1.1908129453659058 average time 0.0024557548333036215 iter num 900\n",
            "loss 0.0031371177174150944 average time 0.0024624539456236444 iter num 920\n",
            "loss 1.1282254457473755 average time 0.0024605905669964254 iter num 940\n",
            "loss 0.00493419636040926 average time 0.002463444799982047 iter num 960\n",
            "loss 0.013437682762742043 average time 0.002472311052016656 iter num 980\n",
            "loss 95.74823760986328 average time 0.0024782049089772046 iter num 1000\n",
            "loss 92.46769714355469 average time 0.0032456228001137787 iter num 20\n",
            "loss 0.8516550064086914 average time 0.002896351300069 iter num 40\n",
            "loss 1.808679461479187 average time 0.002854510616665114 iter num 60\n",
            "loss 0.02388528361916542 average time 0.002791974762476457 iter num 80\n",
            "loss 0.29611828923225403 average time 0.002888689799929125 iter num 100\n",
            "loss 0.7902937531471252 average time 0.0028466516832395426 iter num 120\n",
            "loss 0.04170656204223633 average time 0.0028396312713214553 iter num 140\n",
            "loss 3.3057093620300293 average time 0.0028006718311530676 iter num 160\n",
            "loss 0.27420249581336975 average time 0.00279588659436235 iter num 180\n",
            "loss 1.4006977081298828 average time 0.002784802444912202 iter num 200\n",
            "loss 2.320815324783325 average time 0.0027830882635581393 iter num 220\n",
            "loss 17.854480743408203 average time 0.002768774341598146 iter num 240\n",
            "loss 0.19686870276927948 average time 0.0027631824460933366 iter num 260\n",
            "loss 0.3968917429447174 average time 0.0027385544499468647 iter num 280\n",
            "loss 45.71258544921875 average time 0.0027188609199462616 iter num 300\n",
            "loss 87.03327178955078 average time 0.0027134531687124765 iter num 320\n",
            "loss 4.226687908172607 average time 0.0027099632587819274 iter num 340\n",
            "loss 5.737470626831055 average time 0.0027068203971945576 iter num 360\n",
            "loss 46.104942321777344 average time 0.002711466215748116 iter num 380\n",
            "loss 15.44856071472168 average time 0.0027017884349652375 iter num 400\n",
            "loss 8.687026977539062 average time 0.002702409888072344 iter num 420\n",
            "loss 40.523590087890625 average time 0.0027058655317969997 iter num 440\n",
            "loss 9.514065742492676 average time 0.0027101120325824014 iter num 460\n",
            "loss 5.43577241897583 average time 0.0027086124833052357 iter num 480\n",
            "loss 24.765871047973633 average time 0.0027076701619625967 iter num 500\n",
            "loss 1.5969630479812622 average time 0.002704605467274982 iter num 520\n",
            "loss 4.621063232421875 average time 0.0027087205481149323 iter num 540\n",
            "loss 12.890374183654785 average time 0.002707624274967202 iter num 560\n",
            "loss 12.04494571685791 average time 0.0027103651844456555 iter num 580\n",
            "loss 18.26142120361328 average time 0.0027061525883073046 iter num 600\n",
            "loss 9.85765552520752 average time 0.002712076491905229 iter num 620\n",
            "loss 0.608533501625061 average time 0.0027064327421527424 iter num 640\n",
            "loss 1.5506588220596313 average time 0.002706451793906264 iter num 660\n",
            "loss 1.8144915103912354 average time 0.002708753249972313 iter num 680\n",
            "loss 0.19710911810398102 average time 0.002705659417120582 iter num 700\n",
            "loss 5.706591606140137 average time 0.0027052946069210924 iter num 720\n",
            "loss 3.101801872253418 average time 0.0027015384986215567 iter num 740\n",
            "loss 1.4357043504714966 average time 0.002700199393398419 iter num 760\n",
            "loss 6.26243257522583 average time 0.0027004640602311925 iter num 780\n",
            "loss 0.284582257270813 average time 0.0027047737574707755 iter num 800\n",
            "loss 3.1044728755950928 average time 0.0027044297487475158 iter num 820\n",
            "loss 31.23048973083496 average time 0.00270231653090767 iter num 840\n",
            "loss 4.066908836364746 average time 0.0027010494662326255 iter num 860\n",
            "loss 2.638418674468994 average time 0.0027156455635866388 iter num 880\n",
            "loss 0.0002615598205011338 average time 0.00271687483550017 iter num 900\n",
            "loss 18.07573127746582 average time 0.002722338241255784 iter num 920\n",
            "loss 6.610507488250732 average time 0.002719409685060453 iter num 940\n",
            "loss 0.16355951130390167 average time 0.002717369749956333 iter num 960\n",
            "loss 20.563766479492188 average time 0.0027195361366893294 iter num 980\n",
            "loss 7.972721099853516 average time 0.0027231219599598263 iter num 1000\n",
            "loss 16.0438232421875 average time 0.003185290400051599 iter num 20\n",
            "loss 18.46785545349121 average time 0.0029593881250093547 iter num 40\n",
            "loss 0.036734260618686676 average time 0.0028970133833657505 iter num 60\n",
            "loss 32.68486404418945 average time 0.002827168537510261 iter num 80\n",
            "loss 7.727247714996338 average time 0.0027995900999667356 iter num 100\n",
            "loss 6.913073539733887 average time 0.0027692236916815696 iter num 120\n",
            "loss 1.102359414100647 average time 0.0027500931357800646 iter num 140\n",
            "loss 0.02750374563038349 average time 0.0027880521938300263 iter num 160\n",
            "loss 9.682024002075195 average time 0.0027703774112119895 iter num 180\n",
            "loss 0.18997043371200562 average time 0.002742533825103237 iter num 200\n",
            "loss 1.203903079032898 average time 0.0027315168637208195 iter num 220\n",
            "loss 6.110517978668213 average time 0.0027156104333926124 iter num 240\n",
            "loss 1.563568353652954 average time 0.002695775338508191 iter num 260\n",
            "loss 5.7912278175354 average time 0.0026982489036137328 iter num 280\n",
            "loss 1.1874668598175049 average time 0.0027084697500201096 iter num 300\n",
            "loss 7.934376239776611 average time 0.0027018061906403544 iter num 320\n",
            "loss 0.9842543601989746 average time 0.002686183470621686 iter num 340\n",
            "loss 1.206390619277954 average time 0.002696177430592191 iter num 360\n",
            "loss 1.4843310117721558 average time 0.002708238657937488 iter num 380\n",
            "loss 82.38908386230469 average time 0.0027278964200286283 iter num 400\n",
            "loss 5.260819911956787 average time 0.002725190880980898 iter num 420\n",
            "loss 0.38028278946876526 average time 0.0027082822500274647 iter num 440\n",
            "loss 15.449310302734375 average time 0.0027126355152335157 iter num 460\n",
            "loss 10.366442680358887 average time 0.002711479387517102 iter num 480\n",
            "loss 8.487648010253906 average time 0.0027122521060155124 iter num 500\n",
            "loss 8.608120918273926 average time 0.0027119171403893025 iter num 520\n",
            "loss 0.04975433275103569 average time 0.002710355314822529 iter num 540\n",
            "loss 3.965217351913452 average time 0.002707422035707298 iter num 560\n",
            "loss 0.001833303482271731 average time 0.0027106317068877426 iter num 580\n",
            "loss 5.166970252990723 average time 0.002708035318319162 iter num 600\n",
            "loss 0.9882397651672363 average time 0.0027198797838595525 iter num 620\n",
            "loss 0.0004898640909232199 average time 0.0027225595109229062 iter num 640\n",
            "loss 8.848573684692383 average time 0.002734479298473933 iter num 660\n",
            "loss 0.24477852880954742 average time 0.0027345959441123233 iter num 680\n",
            "loss 3.2970592975616455 average time 0.0027336774271316242 iter num 700\n",
            "loss 0.20928049087524414 average time 0.0027245395666644374 iter num 720\n",
            "loss 0.46225661039352417 average time 0.0027237101499948137 iter num 740\n",
            "loss 10.307229042053223 average time 0.0027213065710528003 iter num 760\n",
            "loss 0.08203115314245224 average time 0.0027225511935891214 iter num 780\n",
            "loss 0.0009662906522862613 average time 0.0027145703375003904 iter num 800\n",
            "loss 3.4106767177581787 average time 0.002714771325609923 iter num 820\n",
            "loss 0.25764113664627075 average time 0.002717845230942354 iter num 840\n",
            "loss 0.17042221128940582 average time 0.0027191544104510305 iter num 860\n",
            "loss 100.798095703125 average time 0.0027080739840833054 iter num 880\n",
            "loss 0.46824994683265686 average time 0.0026987888088782106 iter num 900\n",
            "loss 2.004479169845581 average time 0.002702736833688228 iter num 920\n",
            "loss 0.980896532535553 average time 0.0026985244084979524 iter num 940\n",
            "loss 0.09507830440998077 average time 0.002691206757274737 iter num 960\n",
            "loss 1.1516364812850952 average time 0.0026832253918173034 iter num 980\n",
            "loss 0.9105919003486633 average time 0.0026816813349796577 iter num 1000\n",
            "loss 11.351005554199219 average time 0.0028444895997381536 iter num 20\n",
            "loss 24.308740615844727 average time 0.0025750207500550458 iter num 40\n",
            "loss 0.5963425040245056 average time 0.002459407100044094 iter num 60\n",
            "loss 0.1651746928691864 average time 0.0024420715125870627 iter num 80\n",
            "loss 0.3917296528816223 average time 0.0024483661400154233 iter num 100\n",
            "loss 14.489873886108398 average time 0.0024323501416802173 iter num 120\n",
            "loss 0.14966228604316711 average time 0.00241459352856899 iter num 140\n",
            "loss 0.4151919186115265 average time 0.00241615221250413 iter num 160\n",
            "loss 127.2287368774414 average time 0.0024635045388903464 iter num 180\n",
            "loss 4.918129920959473 average time 0.0025180776199977117 iter num 200\n",
            "loss 14.754010200500488 average time 0.00250307348638175 iter num 220\n",
            "loss 0.02871129848062992 average time 0.0025233328083231754 iter num 240\n",
            "loss 1.9858895540237427 average time 0.002503117884610289 iter num 260\n",
            "loss 10.624430656433105 average time 0.0024890729214283574 iter num 280\n",
            "loss 0.29560473561286926 average time 0.00247958849998516 iter num 300\n",
            "loss 4.711064338684082 average time 0.002487924309355094 iter num 320\n",
            "loss 2.7497642040252686 average time 0.00248258236763778 iter num 340\n",
            "loss 3.1376163959503174 average time 0.00247277029164555 iter num 360\n",
            "loss 255.88063049316406 average time 0.0024626299447127646 iter num 380\n",
            "loss 0.7597767114639282 average time 0.002461462539981767 iter num 400\n",
            "loss 0.10669688880443573 average time 0.0024562266523692716 iter num 420\n",
            "loss 4.495058536529541 average time 0.0024494076636322215 iter num 440\n",
            "loss 0.1644817590713501 average time 0.0024482129913018943 iter num 460\n",
            "loss 12.515568733215332 average time 0.002455063285409172 iter num 480\n",
            "loss 0.159001424908638 average time 0.0024618769260050613 iter num 500\n",
            "loss 93.6346206665039 average time 0.002456136332697357 iter num 520\n",
            "loss 4.38541841506958 average time 0.0024519437425994882 iter num 540\n",
            "loss 42.44511795043945 average time 0.0024593148982278634 iter num 560\n",
            "loss 0.09754660725593567 average time 0.002463413462082199 iter num 580\n",
            "loss 0.734047532081604 average time 0.0024609619816753064 iter num 600\n",
            "loss 0.16705985367298126 average time 0.002458186966132123 iter num 620\n",
            "loss 140.51162719726562 average time 0.0024574126609422818 iter num 640\n",
            "loss 13.738008499145508 average time 0.002455119157581397 iter num 660\n",
            "loss 7.205975532531738 average time 0.002449320775017708 iter num 680\n",
            "loss 19.013065338134766 average time 0.002445251678592675 iter num 700\n",
            "loss 22.20500946044922 average time 0.0024412885847368672 iter num 720\n",
            "loss 0.026847705245018005 average time 0.002444394186499562 iter num 740\n",
            "loss 62.27328109741211 average time 0.0024422073223807897 iter num 760\n",
            "loss 0.6431520581245422 average time 0.002446612101292162 iter num 780\n",
            "loss 1.1490654945373535 average time 0.0024508647187622048 iter num 800\n",
            "loss 92.17198181152344 average time 0.0024464167073258466 iter num 820\n",
            "loss 0.4000606834888458 average time 0.002442530086916252 iter num 840\n",
            "loss 86.2703857421875 average time 0.0024406355267549158 iter num 860\n",
            "loss 0.04073410853743553 average time 0.002449832565918603 iter num 880\n",
            "loss 55.57750701904297 average time 0.0024541516011211367 iter num 900\n",
            "loss 52.289939880371094 average time 0.0024517487510958905 iter num 920\n",
            "loss 1.8773047924041748 average time 0.002450936565962385 iter num 940\n",
            "loss 0.9211149215698242 average time 0.0024525094406290765 iter num 960\n",
            "loss 0.6020013689994812 average time 0.0024502233714289957 iter num 980\n",
            "loss 1.7227263450622559 average time 0.0024580346699985965 iter num 1000\n",
            "loss 1.1473170518875122 average time 0.0030127633997835803 iter num 20\n",
            "loss 0.2132483273744583 average time 0.0027628619749066274 iter num 40\n",
            "loss 0.2564884126186371 average time 0.0026363240165968214 iter num 60\n",
            "loss 0.008711984381079674 average time 0.0025511754124181605 iter num 80\n",
            "loss 0.9229317307472229 average time 0.002496960919979756 iter num 100\n",
            "loss 0.7804359197616577 average time 0.002520391791616324 iter num 120\n",
            "loss 0.754377543926239 average time 0.0024900209928221425 iter num 140\n",
            "loss 6.117613792419434 average time 0.002472473568684563 iter num 160\n",
            "loss 0.029942316934466362 average time 0.0024559029777265094 iter num 180\n",
            "loss 0.040131669491529465 average time 0.002481248029962444 iter num 200\n",
            "loss 114.05001831054688 average time 0.002461184645430463 iter num 220\n",
            "loss 0.22963207960128784 average time 0.0024481069916494863 iter num 240\n",
            "loss 0.2463616579771042 average time 0.0024731558230716754 iter num 260\n",
            "loss 2.504488706588745 average time 0.002467709425003964 iter num 280\n",
            "loss 0.1300753504037857 average time 0.002459469076663178 iter num 300\n",
            "loss 2.2926809787750244 average time 0.00244636013438253 iter num 320\n",
            "loss 62.925689697265625 average time 0.0024420245941067097 iter num 340\n",
            "loss 4.246230602264404 average time 0.0024397921666453235 iter num 360\n",
            "loss 657.9620971679688 average time 0.0024358139157668215 iter num 380\n",
            "loss 78.83525085449219 average time 0.002427970487465245 iter num 400\n",
            "loss 3.4262638092041016 average time 0.0024260921332868403 iter num 420\n",
            "loss 52.96955871582031 average time 0.0024246583363203007 iter num 440\n",
            "loss 21.14728355407715 average time 0.0024197033130013037 iter num 460\n",
            "loss 0.037938643246889114 average time 0.0024152978770265086 iter num 480\n",
            "loss 0.38797545433044434 average time 0.002420738951950625 iter num 500\n",
            "loss 0.6040379405021667 average time 0.0024166907307237406 iter num 520\n",
            "loss 0.046148233115673065 average time 0.0024161268573758814 iter num 540\n",
            "loss 0.1755487322807312 average time 0.0024147590053254526 iter num 560\n",
            "loss 144.0545654296875 average time 0.002412547003420733 iter num 580\n",
            "loss 5.772061824798584 average time 0.0024082556283125693 iter num 600\n",
            "loss 94.17521667480469 average time 0.002416412399983411 iter num 620\n",
            "loss 32.06354522705078 average time 0.0024147277171664427 iter num 640\n",
            "loss 0.8040262460708618 average time 0.0024162045075558345 iter num 660\n",
            "loss 0.003362959250807762 average time 0.002416107151446019 iter num 680\n",
            "loss 1.0195813179016113 average time 0.002414574662839836 iter num 700\n",
            "loss 0.280036062002182 average time 0.0024121448097073677 iter num 720\n",
            "loss 3.242318630218506 average time 0.002431639951336783 iter num 740\n",
            "loss 0.20035547018051147 average time 0.0024275602091907594 iter num 760\n",
            "loss 1.7690215110778809 average time 0.002430260464076967 iter num 780\n",
            "loss 0.8978968858718872 average time 0.0024274709849782996 iter num 800\n",
            "loss 1.001564621925354 average time 0.002427339815831812 iter num 820\n",
            "loss 1.1666712760925293 average time 0.002424666755931477 iter num 840\n",
            "loss 0.022912025451660156 average time 0.0024247033581200096 iter num 860\n",
            "loss 1.3809996843338013 average time 0.0024205746283934623 iter num 880\n",
            "loss 0.345198392868042 average time 0.0024258033911003923 iter num 900\n",
            "loss 2.013145923614502 average time 0.0024241366858642204 iter num 920\n",
            "loss 0.5051934719085693 average time 0.002428451240420861 iter num 940\n",
            "loss 3.9204132556915283 average time 0.0024275488354097282 iter num 960\n",
            "loss 0.5339190363883972 average time 0.002431327349996555 iter num 980\n",
            "loss 0.5784820318222046 average time 0.0024290123600057994 iter num 1000\n",
            "loss 0.002455397043377161 average time 0.0034228904001793125 iter num 20\n",
            "loss 0.452383428812027 average time 0.002882393724985377 iter num 40\n",
            "loss 1.1322622299194336 average time 0.002710353899965412 iter num 60\n",
            "loss 5.01495885848999 average time 0.002721666462457506 iter num 80\n",
            "loss 0.7232368588447571 average time 0.002648383629966702 iter num 100\n",
            "loss 2.724003314971924 average time 0.002589776116671298 iter num 120\n",
            "loss 0.9209392070770264 average time 0.002546842449958474 iter num 140\n",
            "loss 3.1573238372802734 average time 0.0025185225437326154 iter num 160\n",
            "loss 35.14108657836914 average time 0.0024924301333258984 iter num 180\n",
            "loss 9.41932487487793 average time 0.002483953599985398 iter num 200\n",
            "loss 0.03185448423027992 average time 0.0025051318363445963 iter num 220\n",
            "loss 3.858452558517456 average time 0.0024907580374777657 iter num 240\n",
            "loss 0.8267012238502502 average time 0.002481876092287376 iter num 260\n",
            "loss 0.02836771123111248 average time 0.0024825956178379524 iter num 280\n",
            "loss 0.08918771147727966 average time 0.002495582039967606 iter num 300\n",
            "loss 0.7459396719932556 average time 0.0024892672749558644 iter num 320\n",
            "loss 0.003950817976146936 average time 0.0024798187234998346 iter num 340\n",
            "loss 0.07138025760650635 average time 0.002506185749982453 iter num 360\n",
            "loss 1.3047962188720703 average time 0.002524430963144129 iter num 380\n",
            "loss 3.3591485023498535 average time 0.0025130517249817787 iter num 400\n",
            "loss 10.443471908569336 average time 0.002505183221395176 iter num 420\n",
            "loss 0.8211897611618042 average time 0.0024937911976849136 iter num 440\n",
            "loss 1.3700921535491943 average time 0.0025014578499711047 iter num 460\n",
            "loss 0.19072593748569489 average time 0.002495457510394772 iter num 480\n",
            "loss 0.9208659529685974 average time 0.0024894520499765347 iter num 500\n",
            "loss 9.145027160644531 average time 0.0024872224442088527 iter num 520\n",
            "loss 1.6993439197540283 average time 0.002484417409228896 iter num 540\n",
            "loss 3.4653801918029785 average time 0.002479268369617265 iter num 560\n",
            "loss 10.410409927368164 average time 0.002472945156857569 iter num 580\n",
            "loss 2.475403070449829 average time 0.0024700112216335885 iter num 600\n",
            "loss 0.653790295124054 average time 0.0024747219628748537 iter num 620\n",
            "loss 1.0445996522903442 average time 0.0024711307390390402 iter num 640\n",
            "loss 7.1752471923828125 average time 0.0024638309151365926 iter num 660\n",
            "loss 0.0059260111302137375 average time 0.002458079526454907 iter num 680\n",
            "loss 0.3539719879627228 average time 0.0024561199956951896 iter num 700\n",
            "loss 2.0599186420440674 average time 0.002454711269428521 iter num 720\n",
            "loss 0.14865350723266602 average time 0.0024503045594478 iter num 740\n",
            "loss 1.2021708488464355 average time 0.002448353080248317 iter num 760\n",
            "loss 2.110685348510742 average time 0.0024539272576732446 iter num 780\n",
            "loss 0.2888062000274658 average time 0.0024496341637291153 iter num 800\n",
            "loss 0.3951584994792938 average time 0.002447606963392545 iter num 820\n",
            "loss 1.2589048147201538 average time 0.002444102060692222 iter num 840\n",
            "loss 0.08702265471220016 average time 0.0024502877476511773 iter num 860\n",
            "loss 19.4505558013916 average time 0.0024498028090709505 iter num 880\n",
            "loss 0.3960990607738495 average time 0.0024464600821981247 iter num 900\n",
            "loss 0.32254621386528015 average time 0.00244516173040171 iter num 920\n",
            "loss 0.06419359892606735 average time 0.0024523958616652075 iter num 940\n",
            "loss 0.6148719787597656 average time 0.002449740182254345 iter num 960\n",
            "loss 0.75653475522995 average time 0.0024474509867011838 iter num 980\n",
            "loss 0.0878428965806961 average time 0.0024502684379658604 iter num 1000\n",
            "loss 11.491785049438477 average time 0.003469540299829532 iter num 20\n",
            "loss 0.007149809971451759 average time 0.003032306649811289 iter num 40\n",
            "loss 19.098857879638672 average time 0.0029379844331439624 iter num 60\n",
            "loss 33.58140563964844 average time 0.002916065262388656 iter num 80\n",
            "loss 3.9878289699554443 average time 0.0028624383098940598 iter num 100\n",
            "loss 0.40988245606422424 average time 0.002820772974898015 iter num 120\n",
            "loss 24.447967529296875 average time 0.0028176550785117016 iter num 140\n",
            "loss 27.87387466430664 average time 0.002793846231190855 iter num 160\n",
            "loss 34.76960754394531 average time 0.002771254616608429 iter num 180\n",
            "loss 0.24606359004974365 average time 0.002765214004966765 iter num 200\n",
            "loss 8.275893211364746 average time 0.0027678651817950595 iter num 220\n",
            "loss 6.178046226501465 average time 0.0027610371374824656 iter num 240\n",
            "loss 3.1829705238342285 average time 0.002755927723060617 iter num 260\n",
            "loss 0.32509973645210266 average time 0.002757947517836458 iter num 280\n",
            "loss 64.69290161132812 average time 0.002745379073324633 iter num 300\n",
            "loss 18.56529426574707 average time 0.002736197043759603 iter num 320\n",
            "loss 0.41948726773262024 average time 0.0027386833970708454 iter num 340\n",
            "loss 27.632719039916992 average time 0.0027380953333502275 iter num 360\n",
            "loss 7.517583847045898 average time 0.002747396263159891 iter num 380\n",
            "loss 9.837138175964355 average time 0.0027370755125002686 iter num 400\n",
            "loss 1.852352261543274 average time 0.0027379305785784494 iter num 420\n",
            "loss 148.1199951171875 average time 0.002752153209104852 iter num 440\n",
            "loss 4.823484420776367 average time 0.0027483266804388816 iter num 460\n",
            "loss 0.11834115535020828 average time 0.002740893879168501 iter num 480\n",
            "loss 40.18699264526367 average time 0.002741470655993908 iter num 500\n",
            "loss 19.54029655456543 average time 0.0027387858576905554 iter num 520\n",
            "loss 0.8855276107788086 average time 0.002743727225913096 iter num 540\n",
            "loss 14.513116836547852 average time 0.0027417390482047006 iter num 560\n",
            "loss 2.745767831802368 average time 0.0027341339517235985 iter num 580\n",
            "loss 0.02987370640039444 average time 0.0027353256633280885 iter num 600\n",
            "loss 11.881325721740723 average time 0.0027317665274143024 iter num 620\n",
            "loss 0.45089587569236755 average time 0.002727901565629054 iter num 640\n",
            "loss 0.6796384453773499 average time 0.002722530018187778 iter num 660\n",
            "loss 0.27632400393486023 average time 0.0027192500676606226 iter num 680\n",
            "loss 1.9064881801605225 average time 0.0027192347671604823 iter num 700\n",
            "loss 0.1973462998867035 average time 0.002725562387516018 iter num 720\n",
            "loss 53.503902435302734 average time 0.0027212222054176153 iter num 740\n",
            "loss 3.7900161743164062 average time 0.0027170462565951118 iter num 760\n",
            "loss 0.0028367131017148495 average time 0.002714119356427639 iter num 780\n",
            "loss 0.07694399356842041 average time 0.0027045505525188675 iter num 800\n",
            "loss 1.9085561037063599 average time 0.002700098190256895 iter num 820\n",
            "loss 0.004822574555873871 average time 0.0026970363178688353 iter num 840\n",
            "loss 0.2921120822429657 average time 0.0026921778535049885 iter num 860\n",
            "loss 10.70151138305664 average time 0.002691105009109213 iter num 880\n",
            "loss 18.964326858520508 average time 0.002693409937797292 iter num 900\n",
            "loss 15.011722564697266 average time 0.002691309534799549 iter num 920\n",
            "loss 0.5765020847320557 average time 0.002689206887248958 iter num 940\n",
            "loss 31.984922409057617 average time 0.002689969866677681 iter num 960\n",
            "loss 0.394870787858963 average time 0.0026879635479677487 iter num 980\n",
            "loss 0.01762796752154827 average time 0.0026945018910082582 iter num 1000\n",
            "loss 0.4225638210773468 average time 0.0031210983502205636 iter num 20\n",
            "loss 295.8036804199219 average time 0.0029350014752708375 iter num 40\n",
            "loss 4.370716094970703 average time 0.002839061383504789 iter num 60\n",
            "loss 4.6374125480651855 average time 0.002768350212591031 iter num 80\n",
            "loss 0.15374816954135895 average time 0.002730463120005879 iter num 100\n",
            "loss 41.65257263183594 average time 0.002725129633351268 iter num 120\n",
            "loss 0.5802503228187561 average time 0.002740794900000765 iter num 140\n",
            "loss 192.1499481201172 average time 0.00272305491246243 iter num 160\n",
            "loss 0.45946866273880005 average time 0.0027040151277510126 iter num 180\n",
            "loss 0.007889242842793465 average time 0.002696136119975563 iter num 200\n",
            "loss 17.732572555541992 average time 0.002708718954545475 iter num 220\n",
            "loss 0.0017491059843450785 average time 0.002713254062488583 iter num 240\n",
            "loss 0.01069819089025259 average time 0.002714327080761555 iter num 260\n",
            "loss 13.237268447875977 average time 0.002733749110724862 iter num 280\n",
            "loss 0.07568984478712082 average time 0.0027292688600330925 iter num 300\n",
            "loss 0.6882292032241821 average time 0.002720051043769445 iter num 320\n",
            "loss 8.067832946777344 average time 0.002705782867660138 iter num 340\n",
            "loss 49.52058792114258 average time 0.0027104535833536326 iter num 360\n",
            "loss 1.9413355588912964 average time 0.002704499765805897 iter num 380\n",
            "loss 0.5592383742332458 average time 0.002705602075011484 iter num 400\n",
            "loss 21.35958480834961 average time 0.002703939730976604 iter num 420\n",
            "loss 6.391709327697754 average time 0.0027042631295774878 iter num 440\n",
            "loss 0.0026971392799168825 average time 0.0027021704478655643 iter num 460\n",
            "loss 173.8274688720703 average time 0.0027048642375461897 iter num 480\n",
            "loss 3.2293801307678223 average time 0.0027010900040440903 iter num 500\n",
            "loss 10.684322357177734 average time 0.002696071986590071 iter num 520\n",
            "loss 17.602630615234375 average time 0.0026955414222727455 iter num 540\n",
            "loss 5.461060523986816 average time 0.002716626523267353 iter num 560\n",
            "loss 0.010079202242195606 average time 0.0027069706224681104 iter num 580\n",
            "loss 1.0637283325195312 average time 0.002700301476719081 iter num 600\n",
            "loss 6.629037857055664 average time 0.0026976182581224307 iter num 620\n",
            "loss 1.7206178903579712 average time 0.002691151234429867 iter num 640\n",
            "loss 91.2684326171875 average time 0.0026917077864185776 iter num 660\n",
            "loss 6.107541084289551 average time 0.0026873108147596855 iter num 680\n",
            "loss 7.561204433441162 average time 0.0026922267972050965 iter num 700\n",
            "loss 0.8275986313819885 average time 0.0026899432500588068 iter num 720\n",
            "loss 2.8995206356048584 average time 0.0026871466622258203 iter num 740\n",
            "loss 3.532898187637329 average time 0.002688275355326129 iter num 760\n",
            "loss 3.4990007877349854 average time 0.0026890667308296728 iter num 780\n",
            "loss 14.785618782043457 average time 0.002687614085057248 iter num 800\n",
            "loss 0.6144353151321411 average time 0.002687648875665373 iter num 820\n",
            "loss 4.311376571655273 average time 0.002705314179814065 iter num 840\n",
            "loss 34.735694885253906 average time 0.002704334139578477 iter num 860\n",
            "loss 0.04351557791233063 average time 0.0026967358386793257 iter num 880\n",
            "loss 0.0001522236125310883 average time 0.0026947627800452917 iter num 900\n",
            "loss 17.017513275146484 average time 0.0026894114446092674 iter num 920\n",
            "loss 4.421857833862305 average time 0.0026885019649369574 iter num 940\n",
            "loss 0.0008064755820669234 average time 0.0026889890687944746 iter num 960\n",
            "loss 0.16640877723693848 average time 0.0026860355286140586 iter num 980\n",
            "loss 0.08710937947034836 average time 0.0026792898190469714 iter num 1000\n",
            "loss 2.577359199523926 average time 0.0031457305502954115 iter num 20\n",
            "loss 7.178895473480225 average time 0.0028311561000919027 iter num 40\n",
            "loss 0.06442846357822418 average time 0.00266185960005411 iter num 60\n",
            "loss 0.032559607177972794 average time 0.0026070642125432643 iter num 80\n",
            "loss 42.966426849365234 average time 0.0025462983300712947 iter num 100\n",
            "loss 0.03167771175503731 average time 0.002537477558401709 iter num 120\n",
            "loss 2.7963554859161377 average time 0.0025065663929386313 iter num 140\n",
            "loss 2.1923298835754395 average time 0.002483488312600457 iter num 160\n",
            "loss 0.0002057291567325592 average time 0.0024657827778557678 iter num 180\n",
            "loss 1.2405591011047363 average time 0.0024462868850969243 iter num 200\n",
            "loss 22.090545654296875 average time 0.0024434431182602237 iter num 220\n",
            "loss 42.98613357543945 average time 0.0024356610792513798 iter num 240\n",
            "loss 5.1650495529174805 average time 0.002430699515466236 iter num 260\n",
            "loss 0.6418861746788025 average time 0.002439729335771647 iter num 280\n",
            "loss 0.7220110893249512 average time 0.002430499003391257 iter num 300\n",
            "loss 5.793270587921143 average time 0.002433453840677657 iter num 320\n",
            "loss 0.41404908895492554 average time 0.002426138988282807 iter num 340\n",
            "loss 1.0575206279754639 average time 0.0024290044306073673 iter num 360\n",
            "loss 2.136657476425171 average time 0.002426739902674806 iter num 380\n",
            "loss 1.759992003440857 average time 0.002455028085041704 iter num 400\n",
            "loss 0.351997435092926 average time 0.0024568156548022153 iter num 420\n",
            "loss 0.047152142971754074 average time 0.0024542524523150696 iter num 440\n",
            "loss 15.393707275390625 average time 0.0024458608261224784 iter num 460\n",
            "loss 10.068245887756348 average time 0.0024430805312855835 iter num 480\n",
            "loss 2.2172980308532715 average time 0.002440170198035048 iter num 500\n",
            "loss 162.43801879882812 average time 0.0024473332365722365 iter num 520\n",
            "loss 10.269591331481934 average time 0.002444816781506368 iter num 540\n",
            "loss 4.353482723236084 average time 0.002437938633946552 iter num 560\n",
            "loss 0.004066163673996925 average time 0.0024371102396704876 iter num 580\n",
            "loss 0.00896981731057167 average time 0.002431538126684245 iter num 600\n",
            "loss 0.06348346918821335 average time 0.002427330472595889 iter num 620\n",
            "loss 1.746046781539917 average time 0.0024293324265840964 iter num 640\n",
            "loss 0.7107847929000854 average time 0.002426625604560038 iter num 660\n",
            "loss 1.0843302011489868 average time 0.002428490775010312 iter num 680\n",
            "loss 0.1320786029100418 average time 0.002423925452871377 iter num 700\n",
            "loss 164.71937561035156 average time 0.00242835918335105 iter num 720\n",
            "loss 1.812806487083435 average time 0.002427101085155497 iter num 740\n",
            "loss 1.9739412069320679 average time 0.002436192935546818 iter num 760\n",
            "loss 0.5341643691062927 average time 0.002435260793609837 iter num 780\n",
            "loss 83.95599365234375 average time 0.002438387337524546 iter num 800\n",
            "loss 3.762662172317505 average time 0.0024464278988112135 iter num 820\n",
            "loss 0.1683909147977829 average time 0.0024445923238415293 iter num 840\n",
            "loss 1.0314011573791504 average time 0.002442682961658605 iter num 860\n",
            "loss 0.10894779115915298 average time 0.0024431305216239705 iter num 880\n",
            "loss 18.660024642944336 average time 0.0024412309900233393 iter num 900\n",
            "loss 1.4141045808792114 average time 0.0024417132391511627 iter num 920\n",
            "loss 3.4209420680999756 average time 0.002440605992564707 iter num 940\n",
            "loss 1.5319048166275024 average time 0.0024468359187608257 iter num 960\n",
            "loss 0.0003038017894141376 average time 0.0024454965326649656 iter num 980\n",
            "loss 0.011285969987511635 average time 0.0024448259110140497 iter num 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 1000000\n",
              "\tepoch: 1000\n",
              "\tepoch_length: 1000\n",
              "\tmax_epochs: 1000\n",
              "\toutput: 0.011285969987511635\n",
              "\tbatch: <class 'tuple'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: <class 'cupy_dataset.NumbaOptionDataSet'>\n",
              "\tseed: <class 'NoneType'>\n",
              "\ttimes: <class 'dict'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU1EpGuInwjJ"
      },
      "source": [
        "$2365$ seconds The loss is keeping decreasing which means the pricing model can predict the option prices better. It takes about $12ms$ to compute one mini-batch in average, In the following sections, we will try to expore the full potentials of the GPU to accelerate the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8McNtejRNFT"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRtOr1XIPOvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "235eaae0-4954-4297-b54c-661cf687d04c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndftly2yPEaM"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'EuCall_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6DRO9K2RQoJ"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGXZSV_YRT8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "955616f3-5e1b-493f-e062-3dadf441e3d4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ntY-N5bOqdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66effa31-86a3-4359-d0d1-0bfbccf168f1"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'EuCall_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0GAGPAgPmgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dfbece9-0f89-4feb-add4-17582b4da64c"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=6, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc5): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc6): Linear(in_features=1024, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXT4Bg0wdL7l"
      },
      "source": [
        "### Continue to train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfa9cp6CdG8T"
      },
      "source": [
        "# from ignite.engine import Engine, Events\n",
        "# from ignite.handlers import Timer\n",
        "# from torch.nn import MSELoss\n",
        "# from torch.optim import Adam\n",
        "# from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "# from ignite.handlers import ModelCheckpoint\n",
        "# from model import Net\n",
        "# from cupy_dataset import NumbaOptionDataSet\n",
        "# timer = Timer(average=True)\n",
        "# #model = Net().cuda()\n",
        "# loss_fn = MSELoss()\n",
        "# optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "# # dataset = NumbaOptionDataSet(max_len=10000, number_path = 1024, batch=4800)\n",
        "# dataset = NumbaOptionDataSet(max_len=500, number_path = 1024, batch=32, stocks=3)\n",
        "\n",
        "# def train_update(engine, batch):\n",
        "#     model.train()\n",
        "#     optimizer.zero_grad()\n",
        "#     x = batch[0]\n",
        "#     y = batch[1]\n",
        "#     y_pred = model(x)\n",
        "#     loss = loss_fn(y_pred[:,0], y)\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#     return loss.item()\n",
        "\n",
        "# trainer = Engine(train_update)\n",
        "# log_interval = 20\n",
        "\n",
        "# scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "# trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "# timer.attach(trainer,\n",
        "#              start=Events.EPOCH_STARTED,\n",
        "#              resume=Events.ITERATION_STARTED,\n",
        "#              pause=Events.ITERATION_COMPLETED,\n",
        "#              step=Events.ITERATION_COMPLETED)    \n",
        "# @trainer.on(Events.ITERATION_COMPLETED)\n",
        "# def log_training_loss(engine):\n",
        "#     iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "#     if iter % log_interval == 0:\n",
        "#         print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "# trainer.run(dataset, max_epochs=20)\n",
        "\n",
        "# model_save_name = 'checkpoint15.pth'\n",
        "# path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "# torch.save(model.state_dict(), path)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehmhDw8BUtLi"
      },
      "source": [
        "### Inference and Greeks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uiro43mOU0Ro"
      },
      "source": [
        "We can load the model parameters and use it to do inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svlu6tGTRx1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f59b8186-ab14-47a5-9e8e-51b86aa87051"
      },
      "source": [
        "import torch\n",
        "# inputs = torch.tensor([[1, 110.0, 110.0, 0.35, 0.1, 0.05]*1]).cuda()\n",
        "# model(inputs.float())\n",
        "inputs = torch.tensor([[1, 110.0, 200.0, 0.35, 0.1, 0.05]*1]).cuda()\n",
        "model(inputs.float())"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[94.3892]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1Iy-9pWVRDO"
      },
      "source": [
        "One of the benefits of building a deep learning model is that the [Greeks](<https://en.wikipedia.org/wiki/Greeks_(finance)#First-order_Greeks>) can be easily computed. \n",
        "We just need to take advantage of the auto-grad feature in Pytorch. We can use `grad` function to compute the first order differentiation for parameters 'K, B, S0, sigma, mu, r'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytBZaYHKSnDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "497a4b0f-09ed-413f-80f8-c393507c887e"
      },
      "source": [
        "inputs = torch.tensor([[1, 110.0, 200.0, 0.35, 0.1, 0.05]*1]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4.7497, -0.9203,  0.9674,  9.0898,  0.5524, 87.9966]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KeijaDDVZGd"
      },
      "source": [
        "Here we are going to plot the Delta graph:-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skwgeVDsA_Mr"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USh3qaADSYQp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "5962b293-2944-427b-ee5d-501405e34f26"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    # inputs = torch.tensor([[110.0, 0.0, S, 0.35, 0.1, 0.05] + ([110.0, 0.0, 110.0, 0.35, 0.1, 0.05]*2)]).cuda()\n",
        "    inputs = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f877876b290>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "VGk5Hw64fMdh",
        "outputId": "10db1132-06ec-46fc-d4f4-2422a741eb48"
      },
      "source": [
        "## Using Finite Difference, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    epsilon = 0.01\n",
        "    inputs1 = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, S + epsilon, 0.35, 0.1, 0.05]]).cuda()\n",
        "    delta = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return delta\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f87786d28d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLStvS2qCSjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b07f3567-e4e9-4069-c927-81d0ee2969a9"
      },
      "source": [
        "compute_delta(110)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6197]], device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "4O1I8COnUxnz",
        "outputId": "8f6fdfcc-7394-480b-ffd9-fbb61e800b16"
      },
      "source": [
        "##Using Finite Difference, Change 3 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    epsilon = 0.01\n",
        "    inputs1 = torch.tensor([[110.0, 0.0, S, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs2 = torch.tensor([[110.0, 0.0, S + epsilon, 0.35, 0.1, 0.05]]).cuda()\n",
        "    delta = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return delta\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f87786bdd10>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySrey9KzB0AF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a62bae6c-14f6-452d-f41a-e4dafa9d8d78"
      },
      "source": [
        "compute_delta(110).item()  # It's not 0.5!! SOS"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2900.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMyME_1WCGZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a8dcc63-e907-4880-9a53-114ffb61f9c8"
      },
      "source": [
        "compute_delta(102).item() # Close to 0.5"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNB8LPwfBMHQ"
      },
      "source": [
        "# Gamma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLO_5nEGVcEc"
      },
      "source": [
        "Calculating the second order derivative is easy in PyTorch too. We just need to apply the `grad` function twice. Use this mechanism, we can calculate the second order derivatives $\\frac{\\partial^2 P}{\\partial K \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial B \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial S_0^2}$, $\\frac{\\partial^2 P}{\\partial \\sigma \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial \\mu \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial r \\partial S_0}$ in the following example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGzj7A3sThZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dac32dfd-5ac6-40b6-c9ab-9ca1f57d3ef3"
      },
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import grad\n",
        "from torch import nn\n",
        "\n",
        "inputs = torch.tensor([[1, 110.0, 110.0, 0.35, 0.1, 0.05]*1]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs)\n",
        "\n",
        "# instead of using loss.backward(), use torch.autograd.grad() to compute gradients\n",
        "# https://pytorch.org/docs/stable/autograd.html#torch.autograd.grad\n",
        "loss_grads = grad(x, inputs, create_graph=True)\n",
        "drv = grad(loss_grads[0][0][2], inputs)\n",
        "drv"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.1264, -0.0176,  0.0168, -0.1805,  0.1641,  1.7022]],\n",
              "        device='cuda:0'),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJbZYtvhVmSo"
      },
      "source": [
        "Gamma is the second order differenation of `S`. We can plot the the Gamma curve as a function of the stock price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JpQa3EJToA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "629f9fa5-93fc-410b-f25d-b3edf191a83c"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "import pylab\n",
        "import numpy as np\n",
        "def compute_gamma(S):\n",
        "    inputs = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    loss_grads = grad(x, inputs, create_graph=True)\n",
        "    drv = grad(loss_grads[0][0][2], inputs)\n",
        "    return drv[0][0][2]\n",
        "\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "gammas = []\n",
        "for p in prices:\n",
        "    gammas.append(compute_gamma(p).item())\n",
        "fig2 = pylab.plot(prices, gammas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Gamma')\n",
        "fig2"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8778635290>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsoaOyCDxQy0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "8c298c9e-a5e9-4484-deba-1b40ae8d5200"
      },
      "source": [
        "##Using Finite Difference, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_gamma(S):\n",
        "    epsilon = 0.5\n",
        "    inputs1 = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, S + epsilon, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs3 = torch.tensor([[1, 110.02, S - epsilon, 0.35, 0.1, 0.05]]).cuda()\n",
        "    gamma = (model(inputs2.float()) - 2*model(inputs1.float()) + model(inputs3.float()))/(epsilon**2)\n",
        "    return gamma\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "gammas = []\n",
        "for p in prices:\n",
        "    gammas.append(compute_gamma(p).item())\n",
        "fig = pylab.plot(prices, gammas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Gamma')\n",
        "fig"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f877858be50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "aOsXgOwWZ_ru",
        "outputId": "624e1e02-9a7b-465e-8ad6-d422c5a9b706"
      },
      "source": [
        "##Using Finite Difference, Change 3 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_gamma(S):\n",
        "    epsilon = 0.5\n",
        "    inputs1 = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]*1]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, S + epsilon, 0.35, 0.1, 0.05]*1]).cuda()\n",
        "    inputs3 = torch.tensor([[1, 110.0, S - epsilon, 0.35, 0.1, 0.05]*1]).cuda()\n",
        "    gamma = (model(inputs2.float()) - 2*model(inputs1.float()) + model(inputs3.float()))/(epsilon**2)\n",
        "    return gamma\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "gammas = []\n",
        "for p in prices:\n",
        "    gammas.append(compute_gamma(p).item())\n",
        "fig = pylab.plot(prices, gammas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Gamma')\n",
        "fig"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f87785855d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67lca2xrBh9a"
      },
      "source": [
        "# Vega"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muozc-hzhSGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "472ff449-6bc6-42de-cb4b-711149fe531e"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "# vega\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_vega(S):\n",
        "    epsilon = 0.5\n",
        "    inputs1 = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, S, 0.35 + epsilon, 0.1, 0.05]]).cuda()\n",
        "    vega = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return vega\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "vegas = []\n",
        "for p in prices:\n",
        "    vegas.append(compute_vega(p).item())\n",
        "fig = pylab.plot(prices, vegas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Vega')\n",
        "fig"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f87784f0650>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "0KATxBCAdlFt",
        "outputId": "b9774d5d-97aa-4a1c-fbff-72d5a23368a2"
      },
      "source": [
        "##Using Finite Difference, Change 3 S0 at a timev\n",
        "# vega\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_vega(S):\n",
        "    epsilon = 0.5\n",
        "    inputs1 = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]*1]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, S, 0.35 + epsilon, 0.1, 0.05]*1]).cuda()\n",
        "    vega = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return vega\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "vegas = []\n",
        "for p in prices:\n",
        "    vegas.append(compute_vega(p).item())\n",
        "fig = pylab.plot(prices, vegas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Vega')\n",
        "fig"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8778453e90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj7NlW6GVqSA"
      },
      "source": [
        "[Implied volatility](https://en.wikipedia.org/wiki/Implied_volatility) is the forecasted volatility of the underlying asset based on the quoted prices of the option. It is the reverse mapping of price to the option parameter given the model which is hard to do with the Monte Carlo simulation approach. But if we have the deep learning pricing model, it is an easy task. We can first plot the relationship between volatility and the option price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yrCw5UNT07t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "ff0bd962-a9be-4355-f486-be4bee70e1c0"
      },
      "source": [
        "import pylab\n",
        "import numpy as np\n",
        "def compute_price(sigma):\n",
        "    inputs = torch.tensor([[1, 110.0, 110.0, sigma, 0.1, 0.05]]).cuda()\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    return x.item()\n",
        "sigmas = np.arange(0, 0.5, 0.1)\n",
        "prices = []\n",
        "for s in sigmas:\n",
        "    prices.append(compute_price(s))\n",
        "fig3 = pylab.plot(sigmas, prices)\n",
        "pylab.xlabel('Sigma')\n",
        "pylab.ylabel('Price')\n",
        "fig3"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f8778440c50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU25Cj29VtCa"
      },
      "source": [
        "Given the prices `P`, the implied volatility is the root of the function `compute_price`. We can use bisection to find the root."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddHnwm_zUBYD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac0c8e5-208f-466e-ed79-893a38355436"
      },
      "source": [
        "def bisection_root(small, large, fun, target, EPS=1e-6):\n",
        "    if fun(large) - target < 0:\n",
        "        print('upper bound is too small')\n",
        "        return None\n",
        "    if fun(small) - target > 0:\n",
        "        print('lower bound is too large')\n",
        "        return None\n",
        "    while large - small > EPS:\n",
        "        mid = (large + small) / 2.0\n",
        "        if fun(mid) - target >= 0:\n",
        "            large = mid\n",
        "        else:\n",
        "            small = mid\n",
        "    mid = (large + small) / 2.0\n",
        "    return mid, abs(fun(mid) - target)\n",
        "quoted_price = 16.0\n",
        "sigma, err = bisection_root(0, 0.5, compute_price, quoted_price)\n",
        "print('implied volativity', sigma, 'error', err)     "
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "implied volativity 0.3573641777038574 error 6.67572021484375e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEiAredqQGxf"
      },
      "source": [
        ""
      ],
      "execution_count": 66,
      "outputs": []
    }
  ]
}