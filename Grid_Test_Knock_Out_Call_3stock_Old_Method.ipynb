{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grid Test_Knock Out Call 3stock_Old Method",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Erin/Grid_Test_Knock_Out_Call_3stock_Old_Method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPlLTzwwNfwg"
      },
      "source": [
        "nstock = 3"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYigDkiy0HU9"
      },
      "source": [
        "# import cupy\n",
        "# import jax\n",
        "# import jax.numpy as jnp\n",
        "# from jax import random\n",
        "# from jax import jit\n",
        "# import numpy as np\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# S_range = jnp.linspace(0.75, 1.25, 10)\n",
        "# K_range = jnp.linspace(0.75, 1.25, 8)\n",
        "# B_range = jnp.linspace(0.5, 1.0, 8) #in = (1.1, 1.6, 8)\n",
        "# sigma_range = jnp.linspace(0.15, 0.45, 4)\n",
        "# r_range = jnp.linspace(0.01, 0.04, 3)\n",
        "\n",
        "# print(S_range)\n",
        "# print(K_range)\n",
        "# print(B_range)\n",
        "# print(sigma_range)\n",
        "# print(r_range)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIQxpJqK6OZr"
      },
      "source": [
        "# import cupy\n",
        "# import jax\n",
        "# import jax.numpy as jnp\n",
        "# from jax import random\n",
        "# from jax import jit\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "#     stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "#     stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "#                             jax.ops.index[0],         # initialization of stock prices\n",
        "#                             initial_stocks)\n",
        "#     noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "#     sigma = jnp.diag(cov) ** 0.5\n",
        "#     dt = T / numsteps\n",
        "#     def time_step(t, val):\n",
        "#         dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "#         val = jax.ops.index_update(val,\n",
        "#                             jax.ops.index[t],\n",
        "#                             val[t-1] * dx)\n",
        "#         return val\n",
        "#     return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "# def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T): # down-and-out call\n",
        "#     return jnp.mean(jnp.maximum((1 - jnp.any(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2) < B, axis=1).astype(int))* \n",
        "#                                 (jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2))[:,-1]-K, 0) *\n",
        "#                     jnp.exp(-r[0] * T))\n",
        "\n",
        "# goptionvalueavg = jax.grad(optionvalueavg, argnums=1)\n",
        "\n",
        "# #################################################################### Adjust all parameters here (not inside class)\n",
        "# numstocks = nstock\n",
        "# numsteps = 50\n",
        "# numpaths = 2000000\n",
        "\n",
        "# rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "# rng, key = jax.random.split(rng)\n",
        "# keys = jax.random.split(key, numpaths)\n",
        "\n",
        "# S1_range = jnp.linspace(0.75, 1.25, 6)[2:4]\n",
        "# S2_range = jnp.linspace(0.75, 1.25, 6)\n",
        "# S3_range = jnp.linspace(0.75, 1.25, 6)\n",
        "# K_range = jnp.linspace(0.75, 1.25, 5)\n",
        "# B_range = jnp.linspace(0.5, 1.0, 6)\n",
        "# sigma_range = jnp.linspace(0.15, 0.45, 3)\n",
        "# r_range = jnp.linspace(0.01, 0.04, 3)\n",
        "# T = 1.0\n",
        "\n",
        "# fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "# batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "# ####################################################################\n",
        "\n",
        "# call = []\n",
        "# count = 0\n",
        "\n",
        "# # for S1 in S_range:\n",
        "# #   for K in K_range:\n",
        "# #     for B in B_range:\n",
        "# #       for r in r_range:\n",
        "# #         for sigma in sigma_range:    \n",
        "\n",
        "# #           initial_stocks = jnp.array([S]*numstocks) # must be float\n",
        "# #           r_tmp = jnp.array([r]*numstocks)\n",
        "# #           drift = r_tmp\n",
        "# #           cov = jnp.identity(numstocks)*sigma*sigma\n",
        "\n",
        "# #           Knock_Out_Call_price = optionvalueavg(key, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T)\n",
        "# #           Deltas = goptionvalueavg(keys, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T)\n",
        "# #           # call.append([T, K, B, S, sigma, r, r, Knock_Out_Call_price] + list(Deltas)) #T, K, B, S, sigma, mu, r, price, delta\n",
        "# #           call.append([T, K, S1, sigma, r, r,\n",
        "# #                          T, K, S2, sigma, r, r,\n",
        "# #                          T, K, S3, sigma, r, r, Knock_Out_Call_price] + list(Deltas))\n",
        "          \n",
        "# #           count += 1\n",
        "# #           print(count)\n",
        "\n",
        "# for S1 in S1_range:\n",
        "#   for S2 in S2_range:\n",
        "#     for S3 in S3_range:\n",
        "#       for K in K_range:\n",
        "#         for B in B_range:\n",
        "#           for r in r_range:\n",
        "#             for sigma in sigma_range:\n",
        "              \n",
        "#               initial_stocks = jnp.array([S1, S2, S3]) # must be float\n",
        "#               r_tmp = jnp.array([r]*numstocks)\n",
        "#               drift = r_tmp\n",
        "#               cov = jnp.identity(numstocks)*sigma*sigma\n",
        "              \n",
        "#               Knock_Out_Call_price = optionvalueavg(key, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T)\n",
        "#               Deltas = goptionvalueavg(keys, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T)\n",
        "#               call.append([T, K, B, S1, sigma, r, r,\n",
        "#                           T, K, B, S2, sigma, r, r,\n",
        "#                           T, K, B, S3, sigma, r, r, Knock_Out_Call_price] + list(Deltas)) #T, K, S, sigma, mu, r, price, delta\n",
        "                          \n",
        "#               count += 1\n",
        "#               print(count)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_OUtP8GUwj5"
      },
      "source": [
        "# Thedataset_3stock = pd.DataFrame(call)\n",
        "# Thedataset_3stock"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RsPX_tEBGFc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b754fe-d18e-4e72-d7d2-b620d9f40cda"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gv_WjCRV2OZK"
      },
      "source": [
        "# #save to csv\n",
        "# Thedataset_3stock.to_csv(f'/content/drive/MyDrive/AFP/Save_Models/Knock_Out_Call_{str(nstock)}stock_Datset_part2.csv', index=False, header=False)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skGWSSsG8TGG"
      },
      "source": [
        "# read csv\n",
        "import pandas as pd\n",
        "\n",
        "Thedataset_3stock = pd.read_csv(f'/content/drive/MyDrive/AFP/Save_Models/Knock_Out_Call_{str(nstock)}stock_Datset_part2.csv', header=None)\n",
        "# Thedataset_3stock"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4HV-G44th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5609c652-3c4c-4928-de42-fcf5d20799e4"
      },
      "source": [
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "import torch\n",
        "torch.set_printoptions(precision=6)\n",
        "\n",
        "# Thedataset_X = Thedataset_3stock.iloc[:,:7]\n",
        "# Thedataset_Y = Thedataset_3stock.iloc[:,7:]\n",
        "Thedataset_X = Thedataset_3stock.iloc[:,:7*nstock]\n",
        "Thedataset_Y = Thedataset_3stock.iloc[:,7*nstock:]\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.X = cupy.array(Thedataset_X)\n",
        "        self.Y = cupy.array(Thedataset_Y)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(self.X.toDlpack()), from_dlpack(self.Y.toDlpack()))\n",
        "\n",
        "# print\n",
        "ds = OptionDataSet(max_len = 1)\n",
        "for i in ds:\n",
        "    print(i[0])\n",
        "    print(i[0].shape)\n",
        "    print(i[1])\n",
        "    print(i[1].shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.000000, 0.750000, 0.500000,  ..., 0.150000, 0.010000, 0.010000],\n",
            "        [1.000000, 0.750000, 0.500000,  ..., 0.300000, 0.010000, 0.010000],\n",
            "        [1.000000, 0.750000, 0.500000,  ..., 0.450000, 0.010000, 0.010000],\n",
            "        ...,\n",
            "        [1.000000, 1.250000, 1.000000,  ..., 0.150000, 0.040000, 0.040000],\n",
            "        [1.000000, 1.250000, 1.000000,  ..., 0.300000, 0.040000, 0.040000],\n",
            "        [1.000000, 1.250000, 1.000000,  ..., 0.450000, 0.040000, 0.040000]],\n",
            "       device='cuda:0', dtype=torch.float64)\n",
            "torch.Size([19440, 21])\n",
            "tensor([[0.078892, 0.291162, 0.289874, 0.289884],\n",
            "        [0.099626, 0.247059, 0.243172, 0.243210],\n",
            "        [0.125490, 0.232048, 0.226150, 0.226236],\n",
            "        ...,\n",
            "        [0.033227, 0.148440, 0.150369, 0.150394],\n",
            "        [0.074446, 0.161058, 0.164708, 0.164757],\n",
            "        [0.110661, 0.153239, 0.158080, 0.158110]], device='cuda:0',\n",
            "       dtype=torch.float64)\n",
            "torch.Size([19440, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN6JO9OBHdvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01768089-8fba-4a85-ea2e-8fc301814f16"
      },
      "source": [
        "%%writefile model.py\n",
        "# version 1,2\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024, nstock = 1):\n",
        "        self.nstock = nstock\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(7*self.nstock, 64) # remember to change this!\n",
        "        self.fc2 = nn.Linear(64, 128)\n",
        "        self.fc3 = nn.Linear(128, 256)\n",
        "        self.fc4 = nn.Linear(256, 128)\n",
        "        self.fc5 = nn.Linear(128, 64)\n",
        "        self.fc6 = nn.Linear(64, nstock + 1) # outputs: prices, delta\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1.0, 0.5, 0.5, 0.5, 0.3, 0.03, 0.03] * self.nstock)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, B, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = (x - torch.tensor([0.0, 0.75, 0.5, 0.75, 0.15, 0.01, 0.01] * self.nstock).cuda()) / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlXD80xPNVc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38d60190-64c8-4b25-9eed-dc94ab310269"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.7/dist-packages (0.4.7)\n",
            "Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeLVZiiaDS4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d10e4ef8-5d88-42a1-cc6b-101b25df9ef0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3CyULkENYKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf79f9d5-3bef-4451-e511-6ba50aa06d42"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net(nstock = nstock).cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100) # Use max_len to adjust\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    # print(x)\n",
        "    # print(x.shape)\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    # print(y.shape)\n",
        "    y_pred = model(x.float())\n",
        "    # print(y_pred)\n",
        "    # print(y_pred.shape)\n",
        "\n",
        "    # def compute_deltas(x):\n",
        "    #   inputs = x.float()\n",
        "    #   inputs.requires_grad = True\n",
        "    #   first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "    #   return first_order_gradient[0][[3]]  # Now index 3 is stock price, not 2\n",
        "\n",
        "    # deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    # y_pred = torch.cat((y_pred, deltas), 1)\n",
        "    # # print(y_pred)\n",
        "    # # print(y_pred.shape)\n",
        "\n",
        "    loss_weight = torch.tensor([1] * (nstock+1)).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)\n",
        "\n",
        "model_save_name = f'jax_knock_out_{str(nstock)}stock_oldmethod_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.014548562962114441 average time 0.005644451600016964 iter num 20\n",
            "loss 0.011934831921132753 average time 0.005451355450009032 iter num 40\n",
            "loss 0.010111924620971276 average time 0.005369295233335455 iter num 60\n",
            "loss 0.009283863881762125 average time 0.005309529250001788 iter num 80\n",
            "loss 0.009098138528639398 average time 0.005275611930001105 iter num 100\n",
            "loss 0.0055225424474802075 average time 0.005204568649980956 iter num 20\n",
            "loss 0.0035844543648675168 average time 0.005177072474984357 iter num 40\n",
            "loss 0.003230894603557459 average time 0.005156606966653499 iter num 60\n",
            "loss 0.0031560394392817197 average time 0.00515674918748914 iter num 80\n",
            "loss 0.0031439499782795347 average time 0.005148883109987992 iter num 100\n",
            "loss 0.0029982232616028383 average time 0.005302868000006811 iter num 20\n",
            "loss 0.0029370562654637816 average time 0.005209622249995505 iter num 40\n",
            "loss 0.002911349961961915 average time 0.005175441599993747 iter num 60\n",
            "loss 0.002901627371711111 average time 0.005190445224992857 iter num 80\n",
            "loss 0.002899666997599166 average time 0.005193075759995054 iter num 100\n",
            "loss 0.002864749527385131 average time 0.005148830699999963 iter num 20\n",
            "loss 0.002836591115981332 average time 0.005167058824997639 iter num 40\n",
            "loss 0.0028183069282154655 average time 0.005166531516664463 iter num 60\n",
            "loss 0.0028098873193658485 average time 0.005166819449999594 iter num 80\n",
            "loss 0.002808090541975676 average time 0.005175106739995954 iter num 100\n",
            "loss 0.0027733371055969486 average time 0.005120040500020196 iter num 20\n",
            "loss 0.0027416732143205774 average time 0.0051514733250115794 iter num 40\n",
            "loss 0.0027200850494257267 average time 0.005182209166671707 iter num 60\n",
            "loss 0.002710007820752934 average time 0.00517300011250228 iter num 80\n",
            "loss 0.0027078562233043904 average time 0.005171343219999471 iter num 100\n",
            "loss 0.0026660566499226756 average time 0.005145856399991544 iter num 20\n",
            "loss 0.0026273683486388475 average time 0.005169803600000478 iter num 40\n",
            "loss 0.0026007425397404802 average time 0.005163252799998948 iter num 60\n",
            "loss 0.0025882783504288616 average time 0.0051656155000003425 iter num 80\n",
            "loss 0.0025856207478972193 average time 0.005171233170000278 iter num 100\n",
            "loss 0.0025339689831659906 average time 0.005190016999995351 iter num 20\n",
            "loss 0.0024858195909139877 average time 0.005176030174996527 iter num 40\n",
            "loss 0.0024525428672463687 average time 0.0052085273833313295 iter num 60\n",
            "loss 0.0024369560443701045 average time 0.005224250287498932 iter num 80\n",
            "loss 0.0024336380956698363 average time 0.005206379199998992 iter num 100\n",
            "loss 0.0023692519668747757 average time 0.005180311050014552 iter num 20\n",
            "loss 0.002309200655107391 average time 0.0051545104750033485 iter num 40\n",
            "loss 0.0022677583218033673 average time 0.005133740266666109 iter num 60\n",
            "loss 0.0022483920497241615 average time 0.0051395894124993905 iter num 80\n",
            "loss 0.002244279104870188 average time 0.005138607489998321 iter num 100\n",
            "loss 0.0021647566448523862 average time 0.005197078150001744 iter num 20\n",
            "loss 0.0020910247510483354 average time 0.005146262475003027 iter num 40\n",
            "loss 0.0020405672870366645 average time 0.005134752366668257 iter num 60\n",
            "loss 0.00201717323874156 average time 0.0051274703499998965 iter num 80\n",
            "loss 0.0020122287818263715 average time 0.005136494660000608 iter num 100\n",
            "loss 0.0019177642451572525 average time 0.005228373550016841 iter num 20\n",
            "loss 0.0018328420198168568 average time 0.00521220677500196 iter num 40\n",
            "loss 0.0017768473168664966 average time 0.005205665233332487 iter num 60\n",
            "loss 0.001751609337804325 average time 0.00521185749999944 iter num 80\n",
            "loss 0.0017463472307065746 average time 0.005239362250000568 iter num 100\n",
            "loss 0.0016488736127225417 average time 0.005178567500013287 iter num 20\n",
            "loss 0.0015670651411133485 average time 0.005174414900005786 iter num 40\n",
            "loss 0.001516198367493042 average time 0.005190131566668772 iter num 60\n",
            "loss 0.0014940177635844047 average time 0.005205079700000681 iter num 80\n",
            "loss 0.0014894553047250668 average time 0.005207271240000182 iter num 100\n",
            "loss 0.0014069020133902032 average time 0.005109391950003328 iter num 20\n",
            "loss 0.0013401273170823061 average time 0.00509098632500411 iter num 40\n",
            "loss 0.001299459767502389 average time 0.005093719400006572 iter num 60\n",
            "loss 0.0012818891573821312 average time 0.005101070650003692 iter num 80\n",
            "loss 0.0012782865452503913 average time 0.005105014490002304 iter num 100\n",
            "loss 0.001213311408537521 average time 0.00520609034999211 iter num 20\n",
            "loss 0.0011609782416294738 average time 0.005159278300007486 iter num 40\n",
            "loss 0.0011291347496735563 average time 0.005174995433336941 iter num 60\n",
            "loss 0.001115334726686193 average time 0.005164869612505641 iter num 80\n",
            "loss 0.001112494850762653 average time 0.005170659220005973 iter num 100\n",
            "loss 0.001060921801475964 average time 0.005260097900008987 iter num 20\n",
            "loss 0.0010188754141267175 average time 0.005249338150002813 iter num 40\n",
            "loss 0.0009930438541689954 average time 0.005233076099998849 iter num 60\n",
            "loss 0.0009818110415492406 average time 0.00522607097499872 iter num 80\n",
            "loss 0.0009794975031006338 average time 0.0052110348199983034 iter num 100\n",
            "loss 0.0009394015754287412 average time 0.005373801749993845 iter num 20\n",
            "loss 0.000904856845649945 average time 0.005295741424998823 iter num 40\n",
            "loss 0.0008852919483889923 average time 0.005286374499996782 iter num 60\n",
            "loss 0.0008769708145978326 average time 0.005264048612497163 iter num 80\n",
            "loss 0.0008752728014200953 average time 0.005241711209997675 iter num 100\n",
            "loss 0.0008451569187768762 average time 0.005125617150008565 iter num 20\n",
            "loss 0.0008219797432179307 average time 0.005109362850009802 iter num 40\n",
            "loss 0.0008084268821856276 average time 0.005119419683338341 iter num 60\n",
            "loss 0.0008026662256067562 average time 0.005154077600001017 iter num 80\n",
            "loss 0.0008014874022997934 average time 0.00515075963000072 iter num 100\n",
            "loss 0.0007873701643378848 average time 0.005213764450002145 iter num 20\n",
            "loss 0.0007686447189824876 average time 0.005228915124999389 iter num 40\n",
            "loss 0.0007588158448377775 average time 0.005236575916668092 iter num 60\n",
            "loss 0.0007550201052485012 average time 0.0052158413000015 iter num 80\n",
            "loss 0.0007542255115212211 average time 0.005219487840005286 iter num 100\n",
            "loss 0.0007396068361392029 average time 0.005181354650005687 iter num 20\n",
            "loss 0.0007271776156575799 average time 0.005167643425005508 iter num 40\n",
            "loss 0.0007192074705494187 average time 0.005127803400002525 iter num 60\n",
            "loss 0.0007156296128097174 average time 0.005136572537502104 iter num 80\n",
            "loss 0.0007148805512198391 average time 0.005139601969999603 iter num 100\n",
            "loss 0.000700818670809892 average time 0.0051255332500090844 iter num 20\n",
            "loss 0.0006885496168899472 average time 0.005126806549998264 iter num 40\n",
            "loss 0.0006805143252358993 average time 0.005135438649991404 iter num 60\n",
            "loss 0.0006768653092481151 average time 0.005142411274991332 iter num 80\n",
            "loss 0.0006760978753711073 average time 0.005138995599992313 iter num 100\n",
            "loss 0.0006615648004811496 average time 0.005195828799992341 iter num 20\n",
            "loss 0.0006486680393076997 average time 0.005223848449995216 iter num 40\n",
            "loss 0.0006401148617259063 average time 0.005233543616664823 iter num 60\n",
            "loss 0.0006362052516372388 average time 0.005196931100002189 iter num 80\n",
            "loss 0.0006353810868986624 average time 0.0051935926800035755 iter num 100\n",
            "loss 0.0006197095293233903 average time 0.005180756199985126 iter num 20\n",
            "loss 0.0006057027526189052 average time 0.005149043749997873 iter num 40\n",
            "loss 0.0005963809860633682 average time 0.005128825866664025 iter num 60\n",
            "loss 0.0005921177215347731 average time 0.005131841562497641 iter num 80\n",
            "loss 0.0005912193719376671 average time 0.005132659480001394 iter num 100\n",
            "loss 0.0005759029815510487 average time 0.0052088791999892695 iter num 20\n",
            "loss 0.0005595479785309458 average time 0.005203746774989781 iter num 40\n",
            "loss 0.0005495176981155658 average time 0.0051898471833321 iter num 60\n",
            "loss 0.000545081847722405 average time 0.005189910187499436 iter num 80\n",
            "loss 0.0005441517243954959 average time 0.0051791557299998205 iter num 100\n",
            "loss 0.0005467105474606535 average time 0.0052080699500265835 iter num 20\n",
            "loss 0.0005170274972808325 average time 0.005195773925021285 iter num 40\n",
            "loss 0.000506883486945079 average time 0.005193480866680981 iter num 60\n",
            "loss 0.0005032134238601814 average time 0.005189826112504648 iter num 80\n",
            "loss 0.0005024407408219147 average time 0.005186412700003302 iter num 100\n",
            "loss 0.0004882812016471666 average time 0.005193465449985979 iter num 20\n",
            "loss 0.0004764063547262276 average time 0.005200878424989242 iter num 40\n",
            "loss 0.00046901738943140353 average time 0.005191513733332916 iter num 60\n",
            "loss 0.0004657896135089142 average time 0.0051824531374990105 iter num 80\n",
            "loss 0.00046512367535801735 average time 0.005163528079999651 iter num 100\n",
            "loss 0.00045302554714550953 average time 0.00524812345000214 iter num 20\n",
            "loss 0.00044325334801822736 average time 0.0051834460499947 iter num 40\n",
            "loss 0.00043733003532779634 average time 0.005178463783331229 iter num 60\n",
            "loss 0.0004347760655172328 average time 0.005162018012498493 iter num 80\n",
            "loss 0.00043425148429525437 average time 0.00515738270999691 iter num 100\n",
            "loss 0.0004247776686684695 average time 0.005215952200001084 iter num 20\n",
            "loss 0.0004171627356963725 average time 0.005205745750004098 iter num 40\n",
            "loss 0.00041252410859478187 average time 0.00518425528333637 iter num 60\n",
            "loss 0.0004105089772416372 average time 0.005183872162503178 iter num 80\n",
            "loss 0.00041009327983782267 average time 0.0051958711600025255 iter num 100\n",
            "loss 0.0004025050984672828 average time 0.005220196999982818 iter num 20\n",
            "loss 0.00039624244997641506 average time 0.005206344874997626 iter num 40\n",
            "loss 0.0003923272260210173 average time 0.005206148833334131 iter num 60\n",
            "loss 0.000390598187459224 average time 0.0051943278624975164 iter num 80\n",
            "loss 0.000390238973860118 average time 0.005200717539999004 iter num 100\n",
            "loss 0.00038359185429434053 average time 0.005186285800010637 iter num 20\n",
            "loss 0.000377956420249675 average time 0.0051844003250010925 iter num 40\n",
            "loss 0.00037436017666327175 average time 0.0051685610833298295 iter num 60\n",
            "loss 0.0003727542859549733 average time 0.005174125375002348 iter num 80\n",
            "loss 0.00037241918066103043 average time 0.005163243300000886 iter num 100\n",
            "loss 0.00036617005414518906 average time 0.005149663849999797 iter num 20\n",
            "loss 0.00036079410439806376 average time 0.005143353850002086 iter num 40\n",
            "loss 0.0003573262422331099 average time 0.00515552771666421 iter num 60\n",
            "loss 0.0003557686955085822 average time 0.005153005549991008 iter num 80\n",
            "loss 0.0003554429196394721 average time 0.005155541389992777 iter num 100\n",
            "loss 0.0003493416970910448 average time 0.00512365984999974 iter num 20\n",
            "loss 0.00034404952900447095 average time 0.005110203050003292 iter num 40\n",
            "loss 0.0003406149062656612 average time 0.0051189860500016945 iter num 60\n",
            "loss 0.00033906719567596087 average time 0.005150403699997241 iter num 80\n",
            "loss 0.00033874314146961886 average time 0.0051474876199972645 iter num 100\n",
            "loss 0.00037113400384073823 average time 0.005189792749990829 iter num 20\n",
            "loss 0.00032895749078108456 average time 0.005177852650001568 iter num 40\n",
            "loss 0.00032494791549069174 average time 0.005189732966664451 iter num 60\n",
            "loss 0.0003235691901664696 average time 0.005171328262501618 iter num 80\n",
            "loss 0.00032328407010804943 average time 0.005164821150001444 iter num 100\n",
            "loss 0.0003179235216771649 average time 0.005141683199991576 iter num 20\n",
            "loss 0.000313225297397557 average time 0.005167974424989552 iter num 40\n",
            "loss 0.000310164037093991 average time 0.0051485285833204365 iter num 60\n",
            "loss 0.00030878045324552036 average time 0.00515302524998873 iter num 80\n",
            "loss 0.00030849035679527927 average time 0.005151534449987593 iter num 100\n",
            "loss 0.0003030329139306081 average time 0.0052120172999934765 iter num 20\n",
            "loss 0.0002982594254103445 average time 0.0051604900499938825 iter num 40\n",
            "loss 0.00029514199781322664 average time 0.005178184183326569 iter num 60\n",
            "loss 0.00029373274084041446 average time 0.005173600837493098 iter num 80\n",
            "loss 0.00029343725533064363 average time 0.005174726609996014 iter num 100\n",
            "loss 0.0002878914087438971 average time 0.005191526500010468 iter num 20\n",
            "loss 0.0002830208763360772 average time 0.005196494575000088 iter num 40\n",
            "loss 0.00027985283636748685 average time 0.005170001266668578 iter num 60\n",
            "loss 0.00027842248141380277 average time 0.005174982212507473 iter num 80\n",
            "loss 0.00027812275322115006 average time 0.005169183460006934 iter num 100\n",
            "loss 0.00031855139960220775 average time 0.005180885800018587 iter num 20\n",
            "loss 0.00026870713532623934 average time 0.005184403825006711 iter num 40\n",
            "loss 0.00026603048634643914 average time 0.005190067100001746 iter num 60\n",
            "loss 0.0002646002876711303 average time 0.005187569687501536 iter num 80\n",
            "loss 0.0002643420878684296 average time 0.005182707080001592 iter num 100\n",
            "loss 0.0002596226147345539 average time 0.005201173550011618 iter num 20\n",
            "loss 0.00025548351965378477 average time 0.005189320525002472 iter num 40\n",
            "loss 0.00025279013629484566 average time 0.005178132800004202 iter num 60\n",
            "loss 0.00025157326444893817 average time 0.005175694325002667 iter num 80\n",
            "loss 0.00025131818740178717 average time 0.005175973509999494 iter num 100\n",
            "loss 0.0002465224313138992 average time 0.005291737700014209 iter num 20\n",
            "loss 0.00024233310622847644 average time 0.005231090875014388 iter num 40\n",
            "loss 0.00023960054972861216 average time 0.005224145966676966 iter num 60\n",
            "loss 0.00023836604349829497 average time 0.005202238537512472 iter num 80\n",
            "loss 0.00023810726768608225 average time 0.005183153650010581 iter num 100\n",
            "loss 0.0002332402833013223 average time 0.0051005861000135155 iter num 20\n",
            "loss 0.00022898385521821307 average time 0.005111207024998521 iter num 40\n",
            "loss 0.00022620354530945253 average time 0.005119843466667362 iter num 60\n",
            "loss 0.00022494616641804957 average time 0.005145168374998832 iter num 80\n",
            "loss 0.00022468245782585617 average time 0.005141354049995926 iter num 100\n",
            "loss 0.0002199927082245342 average time 0.005174591049996025 iter num 20\n",
            "loss 0.00021538941447980589 average time 0.005192073150004717 iter num 40\n",
            "loss 0.00021252459607815975 average time 0.005193268800007899 iter num 60\n",
            "loss 0.00021123370234235578 average time 0.005193960662505504 iter num 80\n",
            "loss 0.0002109628997359235 average time 0.005186062860003631 iter num 100\n",
            "loss 0.00021875657548639784 average time 0.0051176882000049774 iter num 20\n",
            "loss 0.0002100326174006147 average time 0.005135560125012262 iter num 40\n",
            "loss 0.00020167552080951114 average time 0.005143583183337341 iter num 60\n",
            "loss 0.00020032048941400762 average time 0.005145847075003473 iter num 80\n",
            "loss 0.00020011426054658576 average time 0.005140851320005595 iter num 100\n",
            "loss 0.0001964244877376092 average time 0.005162238849987943 iter num 20\n",
            "loss 0.00019311598562179766 average time 0.005173271625000098 iter num 40\n",
            "loss 0.00019095842263811368 average time 0.0051559632499997106 iter num 60\n",
            "loss 0.00018998019993154898 average time 0.005173946437498955 iter num 80\n",
            "loss 0.00018977466033849225 average time 0.005182456339999817 iter num 100\n",
            "loss 0.00018589034803972516 average time 0.005169999650019008 iter num 20\n",
            "loss 0.0001824582675063047 average time 0.005196679575007579 iter num 40\n",
            "loss 0.00018019571609800464 average time 0.00522511441667651 iter num 60\n",
            "loss 0.00017916654662378505 average time 0.005222879025005511 iter num 80\n",
            "loss 0.00017895017405700537 average time 0.005214089450004167 iter num 100\n",
            "loss 0.00017485610969737248 average time 0.00521626519999927 iter num 20\n",
            "loss 0.0001712309475172904 average time 0.005203017499994189 iter num 40\n",
            "loss 0.00016883795855935507 average time 0.005191148299996939 iter num 60\n",
            "loss 0.00016774899729796286 average time 0.00516885384999739 iter num 80\n",
            "loss 0.00016752000738302737 average time 0.0051696982999976625 iter num 100\n",
            "loss 0.00016318744430484673 average time 0.005113083350005354 iter num 20\n",
            "loss 0.00015935185443121357 average time 0.005185221750005553 iter num 40\n",
            "loss 0.0001568214518072391 average time 0.0052017120666732804 iter num 60\n",
            "loss 0.0001556705993141234 average time 0.005210541850003381 iter num 80\n",
            "loss 0.00015542865294964036 average time 0.0052040077400045 iter num 100\n",
            "loss 0.00015085518085961809 average time 0.005200657199998205 iter num 20\n",
            "loss 0.00014681646726825092 average time 0.005175210899994909 iter num 40\n",
            "loss 0.00014415983529441403 average time 0.005166095049992237 iter num 60\n",
            "loss 0.0001429540582995418 average time 0.005155128999997771 iter num 80\n",
            "loss 0.00014270087658464973 average time 0.005170282659997838 iter num 100\n",
            "loss 0.00013792429383628464 average time 0.005155654199990067 iter num 20\n",
            "loss 0.00013372727316424672 average time 0.005152709600000094 iter num 40\n",
            "loss 0.00013098135076272023 average time 0.005169550266659447 iter num 60\n",
            "loss 0.0001297400073654787 average time 0.005187771774996008 iter num 80\n",
            "loss 0.0001294798312417537 average time 0.005190514139999322 iter num 100\n",
            "loss 0.00012524332664946072 average time 0.005141011649988059 iter num 20\n",
            "loss 0.00012038537527024005 average time 0.0051671453249980456 iter num 40\n",
            "loss 0.00011762657061260948 average time 0.0051692462499943305 iter num 60\n",
            "loss 0.00011639566627757777 average time 0.005163286512497223 iter num 80\n",
            "loss 0.00011613840011598066 average time 0.005160628849996556 iter num 100\n",
            "loss 0.00018672752392900267 average time 0.0051878100000067205 iter num 20\n",
            "loss 0.00011461590209684377 average time 0.005158488075008449 iter num 40\n",
            "loss 0.00010971878298872125 average time 0.005147648033336812 iter num 60\n",
            "loss 0.00010817265587072708 average time 0.005146529637505637 iter num 80\n",
            "loss 0.00010799469274276426 average time 0.005145945710000888 iter num 100\n",
            "loss 0.00010502303973051688 average time 0.0051450881499931714 iter num 20\n",
            "loss 0.00010246781194979186 average time 0.005137533274998418 iter num 40\n",
            "loss 0.00010083169670234618 average time 0.005155153333331933 iter num 60\n",
            "loss 0.00010009783273562842 average time 0.005148744162495689 iter num 80\n",
            "loss 9.994450719939149e-05 average time 0.005158149089993458 iter num 100\n",
            "loss 9.70792146059654e-05 average time 0.005184709249994058 iter num 20\n",
            "loss 9.460946681386778e-05 average time 0.005193120799992812 iter num 40\n",
            "loss 9.301880085611601e-05 average time 0.00514958733331999 iter num 60\n",
            "loss 9.230617334982659e-05 average time 0.005150483587493681 iter num 80\n",
            "loss 9.21573445365828e-05 average time 0.005139471939996838 iter num 100\n",
            "loss 8.93808259659042e-05 average time 0.005167263700008107 iter num 20\n",
            "loss 8.699529396401156e-05 average time 0.005158692400004839 iter num 40\n",
            "loss 8.54630454342151e-05 average time 0.00517951814999833 iter num 60\n",
            "loss 8.477785993211285e-05 average time 0.0051759583500000875 iter num 80\n",
            "loss 8.463488628678142e-05 average time 0.005178102249999483 iter num 100\n",
            "loss 8.197155047872355e-05 average time 0.00511856920001037 iter num 20\n",
            "loss 7.969137927667355e-05 average time 0.005141820775000383 iter num 40\n",
            "loss 7.823176137857304e-05 average time 0.005141196683333267 iter num 60\n",
            "loss 7.758041715252697e-05 average time 0.005135149625000679 iter num 80\n",
            "loss 7.744463160315376e-05 average time 0.005144549639999241 iter num 100\n",
            "loss 7.492007603394701e-05 average time 0.005201597249987344 iter num 20\n",
            "loss 7.276729301704387e-05 average time 0.0051796971249927996 iter num 40\n",
            "loss 7.139392739777254e-05 average time 0.005187980633326106 iter num 60\n",
            "loss 7.078245017358236e-05 average time 0.0051908304374947535 iter num 80\n",
            "loss 7.065508904245968e-05 average time 0.0051900406499953535 iter num 100\n",
            "loss 6.829218671356855e-05 average time 0.005247735550005928 iter num 20\n",
            "loss 6.628646681567688e-05 average time 0.00519840390000752 iter num 40\n",
            "loss 6.501252551561451e-05 average time 0.005186076366679042 iter num 60\n",
            "loss 6.444687316526862e-05 average time 0.005194118850010909 iter num 80\n",
            "loss 6.432922625957054e-05 average time 0.005196470620004448 iter num 100\n",
            "loss 6.215182058832717e-05 average time 0.005202519850001863 iter num 20\n",
            "loss 6.031318816350803e-05 average time 0.005142453199999864 iter num 40\n",
            "loss 5.9150424964002425e-05 average time 0.005160995300002469 iter num 60\n",
            "loss 5.863553297429307e-05 average time 0.005177566075005302 iter num 80\n",
            "loss 5.85285500099716e-05 average time 0.005185045710005625 iter num 100\n",
            "loss 5.65705548906824e-05 average time 0.005118435649995945 iter num 20\n",
            "loss 5.4891594315376826e-05 average time 0.005126543200006495 iter num 40\n",
            "loss 5.38447976170671e-05 average time 0.005117032300002696 iter num 60\n",
            "loss 5.3382277257031195e-05 average time 0.005125030187502944 iter num 80\n",
            "loss 5.328628499696279e-05 average time 0.005126599249998662 iter num 100\n",
            "loss 8.244551602088545e-05 average time 0.005079688199992915 iter num 20\n",
            "loss 5.771122611061196e-05 average time 0.005121681100001751 iter num 40\n",
            "loss 5.103465906613978e-05 average time 0.005123460766664797 iter num 60\n",
            "loss 5.003812140606834e-05 average time 0.005144838899995818 iter num 80\n",
            "loss 4.9967726020274964e-05 average time 0.00516478900999914 iter num 100\n",
            "loss 4.8774813538183716e-05 average time 0.0052403793499991025 iter num 20\n",
            "loss 4.777394388568375e-05 average time 0.005216041850002284 iter num 40\n",
            "loss 4.7138359057558e-05 average time 0.005214802383335382 iter num 60\n",
            "loss 4.6857349547556145e-05 average time 0.00520924628750663 iter num 80\n",
            "loss 4.679886373476581e-05 average time 0.005194461090004552 iter num 100\n",
            "loss 4.571633118078812e-05 average time 0.0051332955999839665 iter num 20\n",
            "loss 4.480040494423203e-05 average time 0.00513523332499517 iter num 40\n",
            "loss 4.421968013320119e-05 average time 0.005151706899994224 iter num 60\n",
            "loss 4.396198542737171e-05 average time 0.005143286549999004 iter num 80\n",
            "loss 4.3908387014580594e-05 average time 0.005156422239998619 iter num 100\n",
            "loss 4.2916163216755114e-05 average time 0.005101535649993138 iter num 20\n",
            "loss 4.207732300316734e-05 average time 0.005120106824992377 iter num 40\n",
            "loss 4.1545909454908825e-05 average time 0.005141930633330579 iter num 60\n",
            "loss 4.131021187692247e-05 average time 0.005130722937497012 iter num 80\n",
            "loss 4.1261213912627354e-05 average time 0.005129136449993439 iter num 100\n",
            "loss 4.0354303986418814e-05 average time 0.00520402590001936 iter num 20\n",
            "loss 3.9588416583032055e-05 average time 0.005176135350012601 iter num 40\n",
            "loss 3.9103662984347666e-05 average time 0.00522241218333761 iter num 60\n",
            "loss 3.888875988238432e-05 average time 0.005204552850003097 iter num 80\n",
            "loss 3.884408567917743e-05 average time 0.005218966030000729 iter num 100\n",
            "loss 3.801771053366183e-05 average time 0.005157133150004256 iter num 20\n",
            "loss 3.7320254970785935e-05 average time 0.005158629774993528 iter num 40\n",
            "loss 3.687894547007193e-05 average time 0.00516462053332513 iter num 60\n",
            "loss 3.668334156515931e-05 average time 0.005159716974992535 iter num 80\n",
            "loss 3.664267248802193e-05 average time 0.00514799461999246 iter num 100\n",
            "loss 3.589052412933243e-05 average time 0.005170109950006463 iter num 20\n",
            "loss 3.525568477461314e-05 average time 0.005184254425009272 iter num 40\n",
            "loss 3.4853923624356095e-05 average time 0.005173914333335005 iter num 60\n",
            "loss 3.4675831072008855e-05 average time 0.005182518025006288 iter num 80\n",
            "loss 3.463880217043676e-05 average time 0.005177949740005943 iter num 100\n",
            "loss 3.4798711263470045e-05 average time 0.005182907649992785 iter num 20\n",
            "loss 3.3403179659901334e-05 average time 0.005181256899999198 iter num 40\n",
            "loss 3.301950662636448e-05 average time 0.005160442783327805 iter num 60\n",
            "loss 3.2858417138428755e-05 average time 0.005150263899997754 iter num 80\n",
            "loss 3.282486579074504e-05 average time 0.005166063850000455 iter num 100\n",
            "loss 3.373859618566245e-05 average time 0.0052156403999902064 iter num 20\n",
            "loss 3.308726994789314e-05 average time 0.005155199824989154 iter num 40\n",
            "loss 3.2862770233454164e-05 average time 0.005181497449994291 iter num 60\n",
            "loss 3.207992406412e-05 average time 0.005178103049992444 iter num 80\n",
            "loss 3.2013273412895196e-05 average time 0.005193605999993451 iter num 100\n",
            "loss 3.157009172983916e-05 average time 0.005240292250005041 iter num 20\n",
            "loss 3.121201396901484e-05 average time 0.005229729525009929 iter num 40\n",
            "loss 3.098822397232219e-05 average time 0.005224590833339941 iter num 60\n",
            "loss 3.088908173143665e-05 average time 0.005233451537502276 iter num 80\n",
            "loss 3.086847507732889e-05 average time 0.005216944320002312 iter num 100\n",
            "loss 3.0486058215325497e-05 average time 0.005216278549994513 iter num 20\n",
            "loss 3.0160847319865753e-05 average time 0.005188052574993662 iter num 40\n",
            "loss 2.9953260969359068e-05 average time 0.005187053833327582 iter num 60\n",
            "loss 2.9860652480065656e-05 average time 0.005168296624995605 iter num 80\n",
            "loss 2.984135016374577e-05 average time 0.005160147570001073 iter num 100\n",
            "loss 2.9481988003576038e-05 average time 0.0051445671000010405 iter num 20\n",
            "loss 2.9174628087077216e-05 average time 0.005149754099997494 iter num 40\n",
            "loss 2.897773835888556e-05 average time 0.005153988416672443 iter num 60\n",
            "loss 2.888975939429052e-05 average time 0.005157370987508614 iter num 80\n",
            "loss 2.887140473633317e-05 average time 0.005150371290006887 iter num 100\n",
            "loss 2.8529418514881914e-05 average time 0.005241364749997502 iter num 20\n",
            "loss 2.8236378797240708e-05 average time 0.005187053674993081 iter num 40\n",
            "loss 2.804839944502571e-05 average time 0.0051897313333294426 iter num 60\n",
            "loss 2.7964352953872406e-05 average time 0.005170806212497325 iter num 80\n",
            "loss 2.794680185208702e-05 average time 0.005179658810003502 iter num 100\n",
            "loss 2.761978376570395e-05 average time 0.005174936849999767 iter num 20\n",
            "loss 2.7339243917546026e-05 average time 0.005171147524993103 iter num 40\n",
            "loss 2.7159107649230955e-05 average time 0.00514529623332957 iter num 60\n",
            "loss 2.7078515027435583e-05 average time 0.005149519924994195 iter num 80\n",
            "loss 2.70616800169274e-05 average time 0.005145403099995747 iter num 100\n",
            "loss 2.6747916368557028e-05 average time 0.005229982800011612 iter num 20\n",
            "loss 2.6478504295245265e-05 average time 0.005154881425005442 iter num 40\n",
            "loss 2.6305374326238097e-05 average time 0.00514622635000137 iter num 60\n",
            "loss 2.6227880032080592e-05 average time 0.00516356267500413 iter num 80\n",
            "loss 2.621169973037428e-05 average time 0.005161788850000448 iter num 100\n",
            "loss 2.590982303031895e-05 average time 0.005112093100001403 iter num 20\n",
            "loss 2.5650411904029423e-05 average time 0.005124317350001207 iter num 40\n",
            "loss 2.548360694970247e-05 average time 0.005103651099996872 iter num 60\n",
            "loss 2.540891205223862e-05 average time 0.005094125200001543 iter num 80\n",
            "loss 2.539331579838811e-05 average time 0.005111635720004415 iter num 100\n",
            "loss 2.5102204636587753e-05 average time 0.005135073499985765 iter num 20\n",
            "loss 2.4851841861195928e-05 average time 0.005124425249991305 iter num 40\n",
            "loss 2.4690773874854053e-05 average time 0.005146007566662547 iter num 60\n",
            "loss 2.4618604812536818e-05 average time 0.00514530800000017 iter num 80\n",
            "loss 2.4603537142557184e-05 average time 0.0051583573099992465 iter num 100\n",
            "loss 2.432216453546172e-05 average time 0.00513531445000126 iter num 20\n",
            "loss 2.40800354831441e-05 average time 0.005137065374995586 iter num 40\n",
            "loss 2.392417200931846e-05 average time 0.005157439099993629 iter num 60\n",
            "loss 2.385432887606591e-05 average time 0.005178813699991736 iter num 80\n",
            "loss 2.3839738091917216e-05 average time 0.005183330219994104 iter num 100\n",
            "loss 2.3567732010952e-05 average time 0.005260760499982098 iter num 20\n",
            "loss 2.333276570600001e-05 average time 0.005232267674986702 iter num 40\n",
            "loss 2.3181707828178574e-05 average time 0.005219723716652425 iter num 60\n",
            "loss 2.3114017975009765e-05 average time 0.005198074149987519 iter num 80\n",
            "loss 2.309987271610932e-05 average time 0.005200135099989893 iter num 100\n",
            "loss 5.316958311133744e-05 average time 0.005109614599990664 iter num 20\n",
            "loss 2.412338543836143e-05 average time 0.00514606539998681 iter num 40\n",
            "loss 2.2732632503657866e-05 average time 0.005159576333327701 iter num 60\n",
            "loss 2.2465982965217224e-05 average time 0.005170129249998467 iter num 80\n",
            "loss 2.245024483782815e-05 average time 0.005187455410000439 iter num 100\n",
            "loss 2.243028496885233e-05 average time 0.005201829400010638 iter num 20\n",
            "loss 2.2018862210930523e-05 average time 0.00517740842500416 iter num 40\n",
            "loss 2.18863123485727e-05 average time 0.005171625800003691 iter num 60\n",
            "loss 2.182792346049274e-05 average time 0.005166895575000297 iter num 80\n",
            "loss 2.1815766316244876e-05 average time 0.0051739549700027965 iter num 100\n",
            "loss 2.1997370231129188e-05 average time 0.0052486043499925476 iter num 20\n",
            "loss 2.1658948305898907e-05 average time 0.0052576001249946104 iter num 40\n",
            "loss 2.132163648860131e-05 average time 0.005299533049994428 iter num 60\n",
            "loss 2.1269768189336716e-05 average time 0.005287429449991521 iter num 80\n",
            "loss 2.1255608067474084e-05 average time 0.005272321639992015 iter num 100\n",
            "loss 2.1079403573772663e-05 average time 0.005175817249977399 iter num 20\n",
            "loss 2.0872840878543586e-05 average time 0.005133001799978843 iter num 40\n",
            "loss 2.075765234050321e-05 average time 0.005134138566650866 iter num 60\n",
            "loss 2.070589871629478e-05 average time 0.005142917137484914 iter num 80\n",
            "loss 2.0695137162206287e-05 average time 0.005140310609987182 iter num 100\n",
            "loss 2.226281202159471e-05 average time 0.005186496599986867 iter num 20\n",
            "loss 2.0400594427297645e-05 average time 0.005142010399993069 iter num 40\n",
            "loss 2.0212468812087938e-05 average time 0.005134935799994385 iter num 60\n",
            "loss 2.016141809431092e-05 average time 0.005166232174995855 iter num 80\n",
            "loss 2.0150818554600117e-05 average time 0.005170943079996278 iter num 100\n",
            "loss 2.8665157647158075e-05 average time 0.005283026350002729 iter num 20\n",
            "loss 2.301770792982375e-05 average time 0.005263404374989023 iter num 40\n",
            "loss 2.022002680963841e-05 average time 0.005253949166660732 iter num 60\n",
            "loss 1.9801776717721267e-05 average time 0.005244673674995681 iter num 80\n",
            "loss 1.978837855938781e-05 average time 0.005227108349995433 iter num 100\n",
            "loss 1.9617477851377207e-05 average time 0.0051470445000006745 iter num 20\n",
            "loss 1.9476918576617556e-05 average time 0.005131333949998406 iter num 40\n",
            "loss 1.9387620300068616e-05 average time 0.005142766783336583 iter num 60\n",
            "loss 1.9347672442582678e-05 average time 0.005141167300001826 iter num 80\n",
            "loss 1.933932799486779e-05 average time 0.005140451979995078 iter num 100\n",
            "loss 1.918341090692155e-05 average time 0.005191732100007585 iter num 20\n",
            "loss 1.904866551829127e-05 average time 0.005197998749997624 iter num 40\n",
            "loss 1.8961470402228092e-05 average time 0.005168848133337178 iter num 60\n",
            "loss 1.89222644411395e-05 average time 0.005149859787498201 iter num 80\n",
            "loss 1.891405875068198e-05 average time 0.005148260809999101 iter num 100\n",
            "loss 1.8760356035215514e-05 average time 0.005104784149995112 iter num 20\n",
            "loss 1.862707057549049e-05 average time 0.005124631399996815 iter num 40\n",
            "loss 1.8540685087607705e-05 average time 0.005119181600002775 iter num 60\n",
            "loss 1.850181307383942e-05 average time 0.0051385951250054514 iter num 80\n",
            "loss 1.8493682813036416e-05 average time 0.005140087110004288 iter num 100\n",
            "loss 1.8341164870913108e-05 average time 0.005156187749992114 iter num 20\n",
            "loss 1.82088313641122e-05 average time 0.005143803549998438 iter num 40\n",
            "loss 1.8123010865518143e-05 average time 0.005148609283332916 iter num 60\n",
            "loss 1.8084389810288254e-05 average time 0.005141900062498905 iter num 80\n",
            "loss 1.807630021413135e-05 average time 0.005154919839999366 iter num 100\n",
            "loss 1.7924719428453287e-05 average time 0.00511732190000771 iter num 20\n",
            "loss 1.7793151025393265e-05 average time 0.005193897600008768 iter num 40\n",
            "loss 1.770780422530495e-05 average time 0.005199899700001728 iter num 60\n",
            "loss 1.7669387423162273e-05 average time 0.0051996209750043935 iter num 80\n",
            "loss 1.7661349024770815e-05 average time 0.0051905641800044575 iter num 100\n",
            "loss 1.7523765247808465e-05 average time 0.005291090850022329 iter num 20\n",
            "loss 1.7379766859943274e-05 average time 0.005251940375012509 iter num 40\n",
            "loss 1.7294834078957452e-05 average time 0.005220421566669605 iter num 60\n",
            "loss 1.7256606486866796e-05 average time 0.005216560112502577 iter num 80\n",
            "loss 1.7248602516038596e-05 average time 0.00521367439000187 iter num 100\n",
            "loss 2.1108255260413713e-05 average time 0.005183318450008301 iter num 20\n",
            "loss 1.7394506257180376e-05 average time 0.005198418225012347 iter num 40\n",
            "loss 1.6928272566599612e-05 average time 0.005204441166677043 iter num 60\n",
            "loss 1.6875415420259322e-05 average time 0.0052039608750121145 iter num 80\n",
            "loss 1.6865715782914567e-05 average time 0.005204213390007908 iter num 100\n",
            "loss 0.00011153521063943285 average time 0.005214595199981886 iter num 20\n",
            "loss 2.4347891977737327e-05 average time 0.005176397249988441 iter num 40\n",
            "loss 1.7047031588922072e-05 average time 0.005161300199987787 iter num 60\n",
            "loss 1.6874050190397118e-05 average time 0.005153634912491612 iter num 80\n",
            "loss 1.683311754190217e-05 average time 0.0051681939499917465 iter num 100\n",
            "loss 1.6710980643541513e-05 average time 0.005236909099977538 iter num 20\n",
            "loss 1.657284896803278e-05 average time 0.005217078224987404 iter num 40\n",
            "loss 1.6509387986543806e-05 average time 0.005192769399993343 iter num 60\n",
            "loss 1.6482269103268585e-05 average time 0.0051927026124928945 iter num 80\n",
            "loss 1.6476702487184247e-05 average time 0.005164724919993659 iter num 100\n",
            "loss 1.6374460912360513e-05 average time 0.005116135699995539 iter num 20\n",
            "loss 1.628780467059153e-05 average time 0.0051193675749942715 iter num 40\n",
            "loss 1.6232269707543103e-05 average time 0.005113753566665006 iter num 60\n",
            "loss 1.6207381936689706e-05 average time 0.005120315849994483 iter num 80\n",
            "loss 1.6202183131276235e-05 average time 0.005124625879993801 iter num 100\n",
            "loss 1.61048388700017e-05 average time 0.005202366349988097 iter num 20\n",
            "loss 1.602053338441811e-05 average time 0.0052439376999871 iter num 40\n",
            "loss 1.5965883755472205e-05 average time 0.005218990583316933 iter num 60\n",
            "loss 1.594127214560316e-05 average time 0.005240200224983482 iter num 80\n",
            "loss 1.593612533078299e-05 average time 0.005228199159987525 iter num 100\n",
            "loss 1.583944083991852e-05 average time 0.005201415899995255 iter num 20\n",
            "loss 1.5755329147156878e-05 average time 0.00518234249999523 iter num 40\n",
            "loss 1.5700647466511445e-05 average time 0.005154497533334279 iter num 60\n",
            "loss 1.567599526022721e-05 average time 0.005141647199998545 iter num 80\n",
            "loss 1.5670833285855418e-05 average time 0.00513225282999997 iter num 100\n",
            "loss 1.5573831823245526e-05 average time 0.005177063200000021 iter num 20\n",
            "loss 1.5489328607025546e-05 average time 0.005170985750001478 iter num 40\n",
            "loss 1.543433046676292e-05 average time 0.005171264249997876 iter num 60\n",
            "loss 1.5409521095889374e-05 average time 0.005174109474999966 iter num 80\n",
            "loss 1.540432210121914e-05 average time 0.005172638049996295 iter num 100\n",
            "loss 1.530665796774253e-05 average time 0.005172976700009713 iter num 20\n",
            "loss 1.522153552131115e-05 average time 0.005157144575014172 iter num 40\n",
            "loss 1.5166114233721353e-05 average time 0.0051611227000156155 iter num 60\n",
            "loss 1.5141111009810188e-05 average time 0.005159487600015211 iter num 80\n",
            "loss 1.5135876748352538e-05 average time 0.005145058240013895 iter num 100\n",
            "loss 1.5037418189987142e-05 average time 0.005125393100001929 iter num 20\n",
            "loss 1.4951581205404384e-05 average time 0.005124817775012502 iter num 40\n",
            "loss 1.489569485978951e-05 average time 0.005161681666677017 iter num 60\n",
            "loss 1.4870473113549451e-05 average time 0.005182603975006828 iter num 80\n",
            "loss 1.486518935453267e-05 average time 0.005167976390006288 iter num 100\n",
            "loss 1.4765889870268633e-05 average time 0.00515305349999835 iter num 20\n",
            "loss 1.4679327521261722e-05 average time 0.005127153999993084 iter num 40\n",
            "loss 1.4622967069366735e-05 average time 0.005156002766661534 iter num 60\n",
            "loss 1.4597532223260099e-05 average time 0.0051459904499992605 iter num 80\n",
            "loss 1.4592201968841874e-05 average time 0.005149320740000576 iter num 100\n",
            "loss 1.4492079841556763e-05 average time 0.005213398849986106 iter num 20\n",
            "loss 1.4404792791026125e-05 average time 0.0051958098249969 iter num 40\n",
            "loss 1.434797175821865e-05 average time 0.005208759516661606 iter num 60\n",
            "loss 1.4322338910936132e-05 average time 0.005198665600002528 iter num 80\n",
            "loss 1.4316963493069262e-05 average time 0.005185523660002218 iter num 100\n",
            "loss 1.4216051661393815e-05 average time 0.005168263350003599 iter num 20\n",
            "loss 1.4128096553451101e-05 average time 0.00517410822500608 iter num 40\n",
            "loss 1.4070847170830677e-05 average time 0.005184792100004642 iter num 60\n",
            "loss 1.4045022658721655e-05 average time 0.005190491512507833 iter num 80\n",
            "loss 1.4039619057103e-05 average time 0.005191918820005412 iter num 100\n",
            "loss 1.415752363510071e-05 average time 0.005182917149988952 iter num 20\n",
            "loss 1.3857920776960849e-05 average time 0.005175531275003209 iter num 40\n",
            "loss 1.3792526018597206e-05 average time 0.005171776716664075 iter num 60\n",
            "loss 1.3766048581754115e-05 average time 0.005170326662496905 iter num 80\n",
            "loss 1.3760605637219273e-05 average time 0.005171856289998686 iter num 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dbd7c07-fa5e-4f4f-f122-9509bf766eea"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = f'jax_knock_out_{str(nstock)}stock_oldmethod_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4745999c-f7dc-4b60-aa2e-6eaebb7257cd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43e1451f-6758-4f12-bee1-35ae21ebbac6"
      },
      "source": [
        "import torch\n",
        "model_save_name = f'jax_knock_out_{str(nstock)}stock_oldmethod_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a51ed82-3802-4e38-b3ea-eb52f028779b"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net(nstock = nstock).cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=21, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (fc4): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc5): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc6): Linear(in_features=64, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moxMKMLEhJR7"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57"
      },
      "source": [
        "# # version 2, 7\n",
        "# # If memory is not enough, try changing parameters and restarting session\n",
        "# # loss will converge\n",
        "\n",
        "# from ignite.engine import Engine, Events\n",
        "# from ignite.handlers import Timer\n",
        "# from torch.nn import MSELoss\n",
        "# from torch.optim import Adam\n",
        "# from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "# from ignite.handlers import ModelCheckpoint\n",
        "# from model import Net\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from torch import Tensor\n",
        "# from torch.autograd import grad\n",
        "# timer = Timer(average=True)\n",
        "# #model = Net(nstock = nstock).cuda()\n",
        "# loss_fn = MSELoss()\n",
        "# optimizer = Adam(model.parameters(), lr=1e-3, eps=1e-4, amsgrad=True) # try using higher epsilon and amsgrad\n",
        "# dataset = OptionDataSet(max_len = 100) # Use max_len to adjust\n",
        "\n",
        "# def train_update(engine, batch):\n",
        "#     model.train()\n",
        "#     optimizer.zero_grad()\n",
        "#     x = batch[0]\n",
        "#     y = batch[1]\n",
        "#     y_pred = model(x.float())\n",
        "\n",
        "#     def compute_deltas(x):\n",
        "#       inputs = x.float()\n",
        "#       inputs.requires_grad = True\n",
        "#       first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "#       return first_order_gradient[0][[3]]\n",
        "\n",
        "#     deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "#     y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "#     loss_weight = torch.tensor([1] * (nstock + 1)).cuda()\n",
        "#     loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "#     loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#     return loss.item()\n",
        "\n",
        "# trainer = Engine(train_update)\n",
        "# log_interval = 20\n",
        "\n",
        "# scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "# trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "# timer.attach(trainer,\n",
        "#              start=Events.EPOCH_STARTED,\n",
        "#              resume=Events.ITERATION_STARTED,\n",
        "#              pause=Events.ITERATION_COMPLETED,\n",
        "#              step=Events.ITERATION_COMPLETED)    \n",
        "# @trainer.on(Events.ITERATION_COMPLETED)\n",
        "# def log_training_loss(engine):\n",
        "#     iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "#     if iter % log_interval == 0:\n",
        "#         print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "# trainer.run(dataset, max_epochs = 100)\n",
        "\n",
        "# model_save_name = f'jax_knock_out_{str(nstock)}stock_oldmethod_1.pth'\n",
        "# path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "# torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "183c0799-fda6-4449-cd69-2b5ce7e83366"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 1, 0.8, 1, 0.25, 0.02, 0.02] * nstock]).cuda() # T, K, B, S, sigma, mu, r\n",
        "print('price: ' + str(model(inputs.float())))\n",
        "\n",
        "# price, delta\n",
        "# should be around (0.10632345, 0.5543747)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: tensor([[0.066306, 0.196050, 0.195349, 0.197303]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqpasxVi0hx3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0c7b6f8-a9b0-4a27-bae7-9e903bae7953"
      },
      "source": [
        "# Knock out call\n",
        "\n",
        "# now change code such that 'numsteps' does not represent year\n",
        "# make dt = year / numsteps\n",
        "# Add r, and notice that noise must have mean 0, not drift, or else it'll give large option prices\n",
        "# (done)\n",
        "# after making the changes, the values are still correct\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        #dx =  drift + noise[t,:] # no need to multiply by sigma here because noise generated by cov not corr\n",
        "        dx2 = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx2)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T): # down-and-out call\n",
        "    return jnp.mean(jnp.maximum((1 - jnp.any(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2) < B, axis=1).astype(int))* \n",
        "                                (jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2))[:,-1]-K, 0) *\n",
        "                    jnp.exp(-r[0] * T))\n",
        "    # must use '-1' not 'numsteps', or else grad will be 0\n",
        "\n",
        "numstocks = nstock\n",
        "numsteps = 50\n",
        "numpaths = 2000000\n",
        "\n",
        "rng = jax.random.PRNGKey(1)\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.02]*numstocks)\n",
        "r = drift # let r = drift to match B-S\n",
        "\n",
        "cov = jnp.identity(numstocks)*0.25*0.25\n",
        "initial_stocks = jnp.array([1.]*numstocks) # must be float\n",
        "\n",
        "T = 1.0\n",
        "K = 1.0\n",
        "B = 0.8 # if B is set to 0, equivalent to European call\n",
        "\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "\n",
        "keys = jax.random.split(key, numpaths)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T)) # here numsteps different from T\n",
        "\n",
        "# delta\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, B, T)) # here numsteps different from T"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0678582\n",
            "[0.19399585 0.19401251 0.19391604]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lovJwXo3-YEu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "d1d13874-9602-4554-a9ff-1f2eddf4c3d4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def compute_price(S):\n",
        "    inputs = torch.tensor([[1, 1, 0.8, S, 0.25, 0.02, 0.02] * nstock]).cuda()\n",
        "    return model(inputs.float())[0][0]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_prices = []\n",
        "correct_call_prices = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*numstocks) # must be float\n",
        "    model_call_prices.append(compute_price(p).item())\n",
        "    correct_call_prices.append(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T))\n",
        "\n",
        "#plt.plot(prices, model_call_prices, label = \"model_call_prices\")\n",
        "#plt.plot(prices, correct_call_prices, label = \"correct_call_prices\")\n",
        "plt.plot(prices, np.array(model_call_prices)-np.array(correct_call_prices), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwApH0GT9bBK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "446ed3ac-05ec-4db3-d807-ac958d56724c"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, 0.8, S, 0.25, 0.02, 0.02] * nstock]).cuda()\n",
        "    return model(inputs.float())[0][1]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*nstock) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, 1.0, B, T)[0])\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"correct_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHgD1NjP7DOW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "fe0d914a-4a0e-4d8f-fbd3-d6a28e56f9a6"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 0.775, 0.8, S, 0.25, 0.02, 0.02] * nstock]).cuda()\n",
        "    return model(inputs.float())[0][1]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*nstock) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, 0.775, B, T)[0])\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"correct_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7MfujMQ7oij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "52096456-e3d2-4433-a287-47e97b54a09d"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1.225, 0.8, S, 0.25, 0.02, 0.02] * nstock]).cuda()\n",
        "    return model(inputs.float())[0][1]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*nstock) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, 1.225, B, T)[0])\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"correct_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}