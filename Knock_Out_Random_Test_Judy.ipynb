{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Knock_Out_Test",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Judy/Knock_Out_Random_Test_Judy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HV142iHY0Xmr"
      },
      "source": [
        "# Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z08iNuoQ19oX"
      },
      "source": [
        "# Knock out call\n",
        "\n",
        "# now change code such that 'numsteps' does not represent year\n",
        "# make dt = year / numsteps\n",
        "# Add r, and notice that noise must have mean 0, not drift, or else it'll give large option prices\n",
        "# (done)\n",
        "# after making the changes, the values are still correct\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        #dx =  drift + noise[t,:] # no need to multiply by sigma here because noise generated by cov not corr\n",
        "        dx2 = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx2)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T): # down-and-out call\n",
        "    return jnp.mean(jnp.maximum((1 - jnp.any(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2) < B, axis=1).astype(int))* \n",
        "                                (jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2))[:,-1]-K, 0) *\n",
        "                    jnp.exp(-r[0] * T))\n",
        "    # must use '-1' not 'numsteps', or else grad will be 0\n",
        "\n",
        "numstocks = 1\n",
        "numsteps = 50\n",
        "numpaths = 2000000\n",
        "\n",
        "rng = jax.random.PRNGKey(1)\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.0349]*numstocks)\n",
        "r = drift # let r = drift to match B-S\n",
        "\n",
        "cov = jnp.identity(numstocks)*0.1995*0.1995\n",
        "initial_stocks = jnp.array([0.8222]*numstocks) # must be float\n",
        "\n",
        "T = 1.0\n",
        "K = 0.9723\n",
        "B = 0.5088 # if B is set to 0, equivalent to European call\n",
        "\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "\n",
        "keys = jax.random.split(key, numpaths)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T)) # here numsteps different from T\n",
        "\n",
        "# delta\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, B, T)) # here numsteps different from T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhCjomZ80Wwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4e9e695-12bc-49ad-d60d-aaa46b7aeaf9"
      },
      "source": [
        "# Knock out call\n",
        "\n",
        "# now change code such that 'numsteps' does not represent year\n",
        "# make dt = year / numsteps\n",
        "# Add r, and notice that noise must have mean 0, not drift, or else it'll give large option prices\n",
        "# (done)\n",
        "# after making the changes, the values are still correct\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        #dx =  drift + noise[t,:] # no need to multiply by sigma here because noise generated by cov not corr\n",
        "        dx2 = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx2)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T): # down-and-out call\n",
        "    return jnp.mean(jnp.maximum((1 - jnp.any(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2) < B, axis=1).astype(int))* \n",
        "                                (jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2))[:,-1]-K, 0) *\n",
        "                    jnp.exp(-r[0] * T))\n",
        "    # must use '-1' not 'numsteps', or else grad will be 0\n",
        "\n",
        "numstocks = 3\n",
        "numsteps = 50\n",
        "numpaths = 2000000\n",
        "\n",
        "rng = jax.random.PRNGKey(1)\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.0124]*numstocks)\n",
        "r = drift # let r = drift to match B-S\n",
        "\n",
        "cov = jnp.array([[0.2625**2, 0, 0], [0, 0.2446**2, 0], [0, 0, 0.3074**2]])\n",
        "initial_stocks = jnp.array([1.1262, 1.0031, 1.0572]) # must be float\n",
        "\n",
        "T = 1.0\n",
        "K = 1.2482\n",
        "B = 0.9522 # if B is set to 0, equivalent to European call\n",
        "\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "\n",
        "keys = jax.random.split(key, numpaths)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T)) # here numsteps different from T\n",
        "\n",
        "# delta\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, B, T)) # here numsteps different from T\n",
        "\n",
        "# test 3 stocks\n",
        "# 1.0000, 1.2482, 0.9522, 1.1262, 0.2625, 0.0124, 0.0124, \n",
        "# 1.0000, 1.2482, 0.9522, 1.0031, 0.2446, 0.0124, 0.0124, \n",
        "# 1.0000, 1.2482, 0.9522, 1.0572, 0.3074, 0.0124, 0.0124"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.016996417\n",
            "[0.06254641 0.05926677 0.06709909]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxFUnc_iBVcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2fcb0be-d0a5-427a-d987-c1f6717a8ebc"
      },
      "source": [
        "%%writefile cupy_dataset.py\n",
        "# version 1, 2, 6\n",
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T, keys): # down-and-out call\n",
        "    return jnp.mean(jnp.maximum((1 - jnp.any(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2) < B, axis=1).astype(int))* \n",
        "                                (jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2))[:,-1]-K, 0) *\n",
        "                    jnp.exp(-r[0] * T))\n",
        "\n",
        "###################################################################################################\n",
        "# these 2 functions must be defined outside class in order to be used in 'optionvalueavg' function\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "#keys = jax.random.split(key, numpaths)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "###################################################################################################\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len, number_path, batch, seed, stocks):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 50\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = 1.0 # assume T = 1, use float here\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros((self.N_BATCH, 1 + self.N_STOCKS), dtype=cupy.float32) # output: price, delta1, delta2, delta3\n",
        "        X = cupy.zeros((self.N_BATCH, self.N_STOCKS * 7), dtype = cupy.float32)  # Add Barrier\n",
        "\n",
        "        for op in range(self.N_BATCH):\n",
        "          \n",
        "          rng = jax.random.PRNGKey(self.seed)\n",
        "          rng, key = jax.random.split(rng)\n",
        "          ################################################################################################### generate random input numbers\n",
        "\n",
        "          initial_stocks = jnp.array(0.75 + np.random.random(self.N_STOCKS) * 0.5)\n",
        "\n",
        "          corr = jnp.diag(jnp.array([1]*self.N_STOCKS)) # assume no correlation between stocks here\n",
        "          sigma = jnp.array(0.15 + np.random.random(self.N_STOCKS) * 0.3)\n",
        "          cov = (jnp.diag(sigma)).dot(corr).dot(jnp.diag(sigma))\n",
        "\n",
        "          r = jnp.repeat(jnp.array(0.01 + np.random.random(1) * 0.03), self.N_STOCKS)\n",
        "          drift = r\n",
        "\n",
        "          T = self.T\n",
        "          K = 0.75 + np.random.random(1) * 0.5\n",
        "          B = 0.6 + np.random.random(1) * 0.5\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### apply functions to compute price and deltas\n",
        "          \n",
        "          keys = jax.random.split(key, self.N_PATHS)\n",
        "\n",
        "          Knock_Call_price = optionvalueavg(key, initial_stocks, self.N_STEPS, drift, r, cov, K, B, T, keys) # need to pass 'keys'\n",
        "          gooptionvalue = jax.grad(optionvalueavg, argnums=1)\n",
        "          Deltas = gooptionvalue(keys, initial_stocks, self.N_STEPS, drift, r, cov, K, B, T, keys) # need to pass 'keys'\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### store input and output numbers in X and Y\n",
        "\n",
        "          Y[op, 0] = Knock_Call_price\n",
        "          Y[op, 1:] = cupy.array(Deltas, dtype=cupy.float32) # remember to change this!\n",
        "\n",
        "          # T, K, S, sigma, mu, r,B\n",
        "          paras = (jnp.repeat(jnp.array(T), self.N_STOCKS), jnp.repeat(jnp.array(K), self.N_STOCKS), jnp.repeat(jnp.array(B), self.N_STOCKS), initial_stocks, sigma, drift, r) # T,K,B,S,sigma,drift,r\n",
        "          paras = np.column_stack(paras).reshape(1,-1)[0]\n",
        "          X[op,] = cupy.array(paras)\n",
        "          ###################################################################################################\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "# ds = OptionDataSet(max_len = 2, number_path = 1000000, batch = 2, seed = np.random.randint(10000), stocks=3) # for testing purpose, use constant seed. When training, change to random seed\n",
        "# for i in ds:\n",
        "#     print(i)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cupy_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN6JO9OBHdvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14012d28-0084-4448-a553-8a844e4ff143"
      },
      "source": [
        "%%writefile model.py\n",
        "# version 1,2\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(7*1, 32) # remember to change this!\n",
        "        self.fc2 = nn.Linear(32, 64)\n",
        "        self.fc3 = nn.Linear(64, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 32)\n",
        "        self.fc6 = nn.Linear(32, 1) # 1 outputs: price\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1.0, 0.5, 0.5, 0.5, 0.3, 0.03, 0.03]*1)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, B, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = (x - torch.tensor([0.0, 0.75, 0.6, 0.75, 0.15, 0.01, 0.01]*1).cuda()) / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlXD80xPNVc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "889487a4-a906-4337-d385-29561d91434e"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 32.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 38.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 30.9 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 14.9 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 15.7 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 13.7 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 14.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndNUBU8Js17G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fedeb64-5f51-4b7d-f5d8-ecc560b66bf5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rb9fZ1rteqM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bf431d41-60f5-441b-9ff6-91487903b2e7"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-2)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 100000, batch = 32, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[3]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-3, 1e-5, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)\n",
        "\n",
        "model_save_name = 'jax_knock_out_1stock_MC_1_Judy.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Judy/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.06371563673019409 average time 0.1197711692999917 iter num 20\n",
            "loss 0.06781397014856339 average time 0.07624939072500184 iter num 40\n",
            "loss 0.06288399547338486 average time 0.061923091133333705 iter num 60\n",
            "loss 0.08098264783620834 average time 0.05455259308750158 iter num 80\n",
            "loss 0.05247533321380615 average time 0.05012160792999907 iter num 100\n",
            "loss 0.0672944188117981 average time 0.11639747514999499 iter num 20\n",
            "loss 0.09859946370124817 average time 0.07444887507500084 iter num 40\n",
            "loss 0.06147295609116554 average time 0.060403737966671166 iter num 60\n",
            "loss 0.07380025833845139 average time 0.05337360327500562 iter num 80\n",
            "loss 0.08411183953285217 average time 0.04913050226999985 iter num 100\n",
            "loss 0.04983098804950714 average time 0.1165583297999774 iter num 20\n",
            "loss 0.06649281084537506 average time 0.07430731454998067 iter num 40\n",
            "loss 0.04520248994231224 average time 0.06027683149999727 iter num 60\n",
            "loss 0.07142254710197449 average time 0.0533910992125044 iter num 80\n",
            "loss 0.07820318639278412 average time 0.04914628575000734 iter num 100\n",
            "loss 0.08018883317708969 average time 0.11706579594995219 iter num 20\n",
            "loss 0.04596106708049774 average time 0.07465016752497604 iter num 40\n",
            "loss 0.05339336395263672 average time 0.060597918899975414 iter num 60\n",
            "loss 0.08789084851741791 average time 0.053358859137492234 iter num 80\n",
            "loss 0.06198993697762489 average time 0.049232234039996 iter num 100\n",
            "loss 0.07145069539546967 average time 0.11633902319999834 iter num 20\n",
            "loss 0.04942756146192551 average time 0.07510327352501918 iter num 40\n",
            "loss 0.028054796159267426 average time 0.06074910723335355 iter num 60\n",
            "loss 0.03286370635032654 average time 0.053765788575014996 iter num 80\n",
            "loss 0.03580791875720024 average time 0.04944522093001069 iter num 100\n",
            "loss 0.03778354078531265 average time 0.1189587872999823 iter num 20\n",
            "loss 0.031827833503484726 average time 0.07576360727499605 iter num 40\n",
            "loss 0.0498233437538147 average time 0.06109137228332126 iter num 60\n",
            "loss 0.027302494272589684 average time 0.05395676023749729 iter num 80\n",
            "loss 0.03739679232239723 average time 0.049629671460004375 iter num 100\n",
            "loss 0.03264658898115158 average time 0.11615741250003567 iter num 20\n",
            "loss 0.04002011939883232 average time 0.0742412426250155 iter num 40\n",
            "loss 0.055091798305511475 average time 0.06021315956667195 iter num 60\n",
            "loss 0.03390931338071823 average time 0.053180438012512356 iter num 80\n",
            "loss 0.051616620272397995 average time 0.04905220928000745 iter num 100\n",
            "loss 0.029291432350873947 average time 0.11636058320003713 iter num 20\n",
            "loss 0.06555748730897903 average time 0.07424261787502359 iter num 40\n",
            "loss 0.0838983952999115 average time 0.060203530516681286 iter num 60\n",
            "loss 0.05062968656420708 average time 0.053171669062516004 iter num 80\n",
            "loss 0.04180439934134483 average time 0.04915943641000922 iter num 100\n",
            "loss 0.036074116826057434 average time 0.11589229740000065 iter num 20\n",
            "loss 0.044404540210962296 average time 0.07421667014998548 iter num 40\n",
            "loss 0.03256233036518097 average time 0.06027587409998129 iter num 60\n",
            "loss 0.07357702404260635 average time 0.05335840973748986 iter num 80\n",
            "loss 0.047976210713386536 average time 0.04910056747999533 iter num 100\n",
            "loss 0.05732228606939316 average time 0.11655403714994464 iter num 20\n",
            "loss 0.03652670979499817 average time 0.07471459229993797 iter num 40\n",
            "loss 0.031226741150021553 average time 0.06066909128330735 iter num 60\n",
            "loss 0.05824011564254761 average time 0.053637624799972625 iter num 80\n",
            "loss 0.04094846546649933 average time 0.04943172290999428 iter num 100\n",
            "loss 0.04441821202635765 average time 0.11704423140001836 iter num 20\n",
            "loss 0.03425818309187889 average time 0.0749139581000577 iter num 40\n",
            "loss 0.04218451678752899 average time 0.060828813650058086 iter num 60\n",
            "loss 0.051259562373161316 average time 0.05371978010005592 iter num 80\n",
            "loss 0.0534638911485672 average time 0.04946694638004828 iter num 100\n",
            "loss 0.057551849633455276 average time 0.11761367899996458 iter num 20\n",
            "loss 0.034891001880168915 average time 0.07476100544996597 iter num 40\n",
            "loss 0.039170023053884506 average time 0.06089771929997217 iter num 60\n",
            "loss 0.028029628098011017 average time 0.05367262891248288 iter num 80\n",
            "loss 0.05376654863357544 average time 0.049324132459983044 iter num 100\n",
            "loss 0.04642443358898163 average time 0.11745424505004394 iter num 20\n",
            "loss 0.029762184247374535 average time 0.07488431710002033 iter num 40\n",
            "loss 0.09267321974039078 average time 0.0605625401166814 iter num 60\n",
            "loss 0.07632723450660706 average time 0.053496672275025504 iter num 80\n",
            "loss 0.03381039574742317 average time 0.04929001222001261 iter num 100\n",
            "loss 0.018182937055826187 average time 0.11709027399992919 iter num 20\n",
            "loss 0.03377921134233475 average time 0.0743937975249878 iter num 40\n",
            "loss 0.04412083700299263 average time 0.06034723006666809 iter num 60\n",
            "loss 0.06324745714664459 average time 0.05328846799999951 iter num 80\n",
            "loss 0.06507155299186707 average time 0.049021486669994375 iter num 100\n",
            "loss 0.05137789994478226 average time 0.11718283164998411 iter num 20\n",
            "loss 0.04412688687443733 average time 0.07465967955000678 iter num 40\n",
            "loss 0.049459896981716156 average time 0.06059854198332838 iter num 60\n",
            "loss 0.04810573533177376 average time 0.05354599536249793 iter num 80\n",
            "loss 0.043419353663921356 average time 0.04934956860000966 iter num 100\n",
            "loss 0.08480052649974823 average time 0.11594117375000224 iter num 20\n",
            "loss 0.07156345248222351 average time 0.07389431034999916 iter num 40\n",
            "loss 0.031222593039274216 average time 0.05988697093333333 iter num 60\n",
            "loss 0.044015854597091675 average time 0.05297884922498497 iter num 80\n",
            "loss 0.0697043165564537 average time 0.048774561479986 iter num 100\n",
            "loss 0.04842430353164673 average time 0.11593205195006248 iter num 20\n",
            "loss 0.03314661979675293 average time 0.07410219900003767 iter num 40\n",
            "loss 0.01463389117270708 average time 0.060550839683340504 iter num 60\n",
            "loss 0.04213694483041763 average time 0.05353502582500482 iter num 80\n",
            "loss 0.027851425111293793 average time 0.04920608507001362 iter num 100\n",
            "loss 0.03646034002304077 average time 0.11697569089997159 iter num 20\n",
            "loss 0.04091901704668999 average time 0.07461327662501845 iter num 40\n",
            "loss 0.10526825487613678 average time 0.0603262283833601 iter num 60\n",
            "loss 0.0308445505797863 average time 0.05343714548751564 iter num 80\n",
            "loss 0.041473064571619034 average time 0.04914943047000633 iter num 100\n",
            "loss 0.06352546066045761 average time 0.11681295845000932 iter num 20\n",
            "loss 0.050051700323820114 average time 0.0744800037750224 iter num 40\n",
            "loss 0.04476507380604744 average time 0.060447196283363765 iter num 60\n",
            "loss 0.020882021635770798 average time 0.05337682887502524 iter num 80\n",
            "loss 0.029337013140320778 average time 0.04916418751001857 iter num 100\n",
            "loss 0.03590857610106468 average time 0.11615566185000717 iter num 20\n",
            "loss 0.07805667072534561 average time 0.07409704209997017 iter num 40\n",
            "loss 0.02480345219373703 average time 0.060179542266647935 iter num 60\n",
            "loss 0.07074084877967834 average time 0.05320821749996298 iter num 80\n",
            "loss 0.0462728850543499 average time 0.04896127252993665 iter num 100\n",
            "loss 0.06770820915699005 average time 0.11580939585019223 iter num 20\n",
            "loss 0.057239677757024765 average time 0.07392952502509616 iter num 40\n",
            "loss 0.06936392188072205 average time 0.06001082495004084 iter num 60\n",
            "loss 0.07336732745170593 average time 0.053014167800017734 iter num 80\n",
            "loss 0.04311159998178482 average time 0.048845511540021105 iter num 100\n",
            "loss 0.031236249953508377 average time 0.11517880080004943 iter num 20\n",
            "loss 0.05632171034812927 average time 0.07384616422502858 iter num 40\n",
            "loss 0.047068361192941666 average time 0.0599168782500783 iter num 60\n",
            "loss 0.0656207948923111 average time 0.052978439212552075 iter num 80\n",
            "loss 0.047967374324798584 average time 0.04877063762003672 iter num 100\n",
            "loss 0.06827912479639053 average time 0.1158571644499716 iter num 20\n",
            "loss 0.06590399146080017 average time 0.07410514769997008 iter num 40\n",
            "loss 0.11259777843952179 average time 0.06002877954994498 iter num 60\n",
            "loss 0.047861915081739426 average time 0.05323696292495015 iter num 80\n",
            "loss 0.05790247768163681 average time 0.04892079940995245 iter num 100\n",
            "loss 0.06736771762371063 average time 0.11543776849994174 iter num 20\n",
            "loss 0.09074375778436661 average time 0.07375640604993805 iter num 40\n",
            "loss 0.09017381072044373 average time 0.05998565533330596 iter num 60\n",
            "loss 0.06129112467169762 average time 0.052920738799980424 iter num 80\n",
            "loss 0.048845790326595306 average time 0.04887215622999065 iter num 100\n",
            "loss 0.04150011017918587 average time 0.1154485674499938 iter num 20\n",
            "loss 0.04295651614665985 average time 0.07370611574992836 iter num 40\n",
            "loss 0.0653160884976387 average time 0.06000701111658297 iter num 60\n",
            "loss 0.030442168936133385 average time 0.05293145288745791 iter num 80\n",
            "loss 0.06339440494775772 average time 0.048660069419947834 iter num 100\n",
            "loss 0.033476322889328 average time 0.11456553070006521 iter num 20\n",
            "loss 0.06524680554866791 average time 0.07308469102501931 iter num 40\n",
            "loss 0.11097794771194458 average time 0.05956761913333442 iter num 60\n",
            "loss 0.08114566653966904 average time 0.05264834615001064 iter num 80\n",
            "loss 0.023143958300352097 average time 0.04844188063000729 iter num 100\n",
            "loss 0.07725127786397934 average time 0.11563821614990957 iter num 20\n",
            "loss 0.04534398764371872 average time 0.07371850742492825 iter num 40\n",
            "loss 0.07335221767425537 average time 0.059896741333280566 iter num 60\n",
            "loss 0.038101427257061005 average time 0.05284434789995203 iter num 80\n",
            "loss 0.04179680347442627 average time 0.04883649152992803 iter num 100\n",
            "loss 0.048723675310611725 average time 0.11567742080010249 iter num 20\n",
            "loss 0.0481620691716671 average time 0.07373656362506154 iter num 40\n",
            "loss 0.03793145343661308 average time 0.05988046958336781 iter num 60\n",
            "loss 0.07284122705459595 average time 0.052801199537543655 iter num 80\n",
            "loss 0.03022908978164196 average time 0.04867109165999864 iter num 100\n",
            "loss 0.07355177402496338 average time 0.11573806400001559 iter num 20\n",
            "loss 0.06557957828044891 average time 0.07376913619998504 iter num 40\n",
            "loss 0.07330647855997086 average time 0.059842160383353375 iter num 60\n",
            "loss 0.05849439650774002 average time 0.05278982152503886 iter num 80\n",
            "loss 0.04516930133104324 average time 0.048577717980006124 iter num 100\n",
            "loss 0.06249389797449112 average time 0.1171685110000908 iter num 20\n",
            "loss 0.04536983370780945 average time 0.07480545495004662 iter num 40\n",
            "loss 0.16164633631706238 average time 0.060538094633360136 iter num 60\n",
            "loss 0.06873257458209991 average time 0.053292250037497976 iter num 80\n",
            "loss 0.062175456434488297 average time 0.04900754222002433 iter num 100\n",
            "loss 0.06898588687181473 average time 0.11552672674993118 iter num 20\n",
            "loss 0.02764493227005005 average time 0.07392539242491694 iter num 40\n",
            "loss 0.06839411705732346 average time 0.0599217571832772 iter num 60\n",
            "loss 0.06223069503903389 average time 0.05286586414993053 iter num 80\n",
            "loss 0.07785910367965698 average time 0.048601921119961845 iter num 100\n",
            "loss 0.05095408484339714 average time 0.11490101525000682 iter num 20\n",
            "loss 0.0547165721654892 average time 0.07373168992498905 iter num 40\n",
            "loss 0.048031121492385864 average time 0.05973750501663441 iter num 60\n",
            "loss 0.09007531404495239 average time 0.0527123404375061 iter num 80\n",
            "loss 0.06674273312091827 average time 0.04849701905002803 iter num 100\n",
            "loss 0.0717616006731987 average time 0.11678227314996548 iter num 20\n",
            "loss 0.05877615883946419 average time 0.07441645617502672 iter num 40\n",
            "loss 0.05568893253803253 average time 0.06023000046667827 iter num 60\n",
            "loss 0.052721571177244186 average time 0.05336630816248089 iter num 80\n",
            "loss 0.037861499935388565 average time 0.04919535357998939 iter num 100\n",
            "loss 0.02445272170007229 average time 0.11790392774992142 iter num 20\n",
            "loss 0.0416182205080986 average time 0.07487555159993917 iter num 40\n",
            "loss 0.014275548048317432 average time 0.06047148069997092 iter num 60\n",
            "loss 0.07296141982078552 average time 0.05334504081246223 iter num 80\n",
            "loss 0.041251566261053085 average time 0.04916458367994892 iter num 100\n",
            "loss 0.06510476022958755 average time 0.11522159379996992 iter num 20\n",
            "loss 0.029620736837387085 average time 0.07348016782500508 iter num 40\n",
            "loss 0.0646645575761795 average time 0.05956367533335651 iter num 60\n",
            "loss 0.053792186081409454 average time 0.05261181307503193 iter num 80\n",
            "loss 0.06845850497484207 average time 0.04866400672003692 iter num 100\n",
            "loss 0.1070784479379654 average time 0.1154677776999506 iter num 20\n",
            "loss 0.05409767106175423 average time 0.07367916007508483 iter num 40\n",
            "loss 0.04233453795313835 average time 0.05971610670001913 iter num 60\n",
            "loss 0.06340265274047852 average time 0.052805682275027264 iter num 80\n",
            "loss 0.09185941517353058 average time 0.048590354880007 iter num 100\n",
            "loss 0.06280854344367981 average time 0.11546403530010138 iter num 20\n",
            "loss 0.05995805189013481 average time 0.07358924052505245 iter num 40\n",
            "loss 0.03199328854680061 average time 0.05961038781664077 iter num 60\n",
            "loss 0.10963885486125946 average time 0.05288937754999097 iter num 80\n",
            "loss 0.05658810958266258 average time 0.048646320569960155 iter num 100\n",
            "loss 0.018184227868914604 average time 0.11477263010015122 iter num 20\n",
            "loss 0.03447530046105385 average time 0.07336630997506291 iter num 40\n",
            "loss 0.043852198868989944 average time 0.05978611701669555 iter num 60\n",
            "loss 0.06381087005138397 average time 0.05287826505002613 iter num 80\n",
            "loss 0.029264695942401886 average time 0.04864131812002597 iter num 100\n",
            "loss 0.07017659395933151 average time 0.11578416554980323 iter num 20\n",
            "loss 0.09533846378326416 average time 0.0738612357998818 iter num 40\n",
            "loss 0.03488271310925484 average time 0.05990930981659706 iter num 60\n",
            "loss 0.04786626622080803 average time 0.048834298639940245 iter num 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-9327b172451f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mmodel_save_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'jax_knock_out_1stock_MC_1_Judy.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     89\u001b[0m           \u001b[0mKnock_Call_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptionvalueavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m           \u001b[0mgooptionvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptionvalueavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m           \u001b[0mDeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgooptionvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m           \u001b[0;31m###################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mgrad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    916\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mapi_boundary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgrad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_and_grad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mvalue_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    991\u001b[0m       \u001b[0m_check_input_dtype_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholomorphic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 993\u001b[0;31m       \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_py\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdyn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m       ans, vjp_py, aux = _vjp(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, reduce_axes, *primals)\u001b[0m\n\u001b[1;32m   2311\u001b[0m     \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun_nokwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m     out_primal, out_vjp = ad.vjp(\n\u001b[0;32m-> 2313\u001b[0;31m         flat_fun, primals_flat, reduce_axes=reduce_axes)\n\u001b[0m\u001b[1;32m   2314\u001b[0m     \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2315\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux, reduce_axes)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m   \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tangents_pvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_primal_pval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout_primal_pval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    511\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJaxprTrace\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m     \u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m     \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36moptionvalueavg\u001b[0;34m(key, initial_stocks, numsteps, drift, r, cov, K, B, T, keys)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moptionvalueavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# down-and-out call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     return jnp.mean(jnp.maximum((1 - jnp.any(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2) < B, axis=1).astype(int))* \n\u001b[0;32m---> 28\u001b[0;31m                                 (jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2))[:,-1]-K, 0) *\n\u001b[0m\u001b[1;32m     29\u001b[0m                     jnp.exp(-r[0] * T))\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mbatched_fun\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1453\u001b[0m         \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_axes_flat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m         \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mflatten_axes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"vmap out_axes\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m     ).call_wrapped(*args_flat)\n\u001b[0m\u001b[1;32m   1456\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mcache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    417\u001b[0m         \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs_flat\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_fun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         donated_invars=donated_invars, inline=inline)\n\u001b[0m\u001b[1;32m    420\u001b[0m     \u001b[0mout_pytree_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_pytree_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1632\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1621\u001b[0m       params_tuple, out_axes_transforms)\n\u001b[1;32m   1622\u001b[0m   \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_todos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, trace, fun, tracers, params)\u001b[0m\n\u001b[1;32m   1633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/batching.py\u001b[0m in \u001b[0;36mprocess_call\u001b[0;34m(self, call_primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_subtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       \u001b[0mvals_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_primitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mBatchTracer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdims_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1632\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1621\u001b[0m       params_tuple, out_axes_transforms)\n\u001b[1;32m   1622\u001b[0m   \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_todos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, trace, fun, tracers, params)\u001b[0m\n\u001b[1;32m   1633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mprocess_call\u001b[0;34m(self, call_primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    321\u001b[0m     new_params = (update_params(params, nz_tangents, nz_tangents_out)\n\u001b[1;32m    322\u001b[0m                   if update_params else params)\n\u001b[0;32m--> 323\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_primitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_jvp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mnonzero_tangents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mnew_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m     \u001b[0mprimal_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtangent_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mJVPTracer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimal_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtangent_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1632\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1621\u001b[0m       params_tuple, out_axes_transforms)\n\u001b[1;32m   1622\u001b[0m   \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_todos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, trace, fun, tracers, params)\u001b[0m\n\u001b[1;32m   1633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mprocess_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m       jaxpr, out_pvals, consts, env_tracers = self.partial_eval(\n\u001b[0;32m--> 203\u001b[0;31m           f, in_pvals, app, instantiate=False)\n\u001b[0m\u001b[1;32m    204\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_primitive\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0munmapped_aval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munmapped_aval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'axis_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'axis_name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mpartial_eval\u001b[0;34m(self, f, pvals, app, instantiate)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial_eval_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_avals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m     \u001b[0mout_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0min_consts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m     \u001b[0mout_consts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_flat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjaxpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstvars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0mout_pvs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPartialVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_avals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_consts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1632\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mcall_bind\u001b[0;34m(primitive, fun, *args, **params)\u001b[0m\n\u001b[1;32m   1621\u001b[0m       params_tuple, out_axes_transforms)\n\u001b[1;32m   1622\u001b[0m   \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m   \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_todos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_trace_todo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess\u001b[0;34m(self, trace, fun, tracers, params)\u001b[0m\n\u001b[1;32m   1633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpost_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_call\u001b[0;34m(self, primitive, f, tracers, params)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m   \u001b[0mprocess_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_xla_call_impl\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    688\u001b[0m                                *unsafe_map(arg_spec, args))\n\u001b[1;32m    689\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mFloatingPointError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_nans\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_infs\u001b[0m  \u001b[0;31m# compiled_fun can only raise in this case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled\u001b[0;34m(name, compiled, output_buffer_counts, handlers, kept_var_idx, *args)\u001b[0m\n\u001b[1;32m   1098\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m           if x is not token and i in kept_var_idx))\n\u001b[0;32m-> 1100\u001b[0;31m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m   \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moutput_buffer_counts\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e0XwMvu6XvuH"
      },
      "source": [
        "# 80 min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5144650e-3b2a-4089-e776-1be0d7eedaad"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_knock_out_1stock_MC_2_Judy.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Judy/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4fb03eb-73b3-4747-bc94-938e21961238"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edb42ded-4c25-4638-f79d-7c026cf1ba1a"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_knock_out_1stock_MC_1_Judy.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Judy/{model_save_name}\"\n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "032099a0-4977-4b43-a577-40b77d74c3c2"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=7, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc5): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc6): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "outputId": "caee9d89-dffc-45b0-fee4-b8940b15473f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-2)\n",
        "#dataset = OptionDataSet(max_len = 100, number_path = 1024, batch = 32, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 100000, batch = 32, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[3]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    adjusted_y2 = (1000 * y)**2\n",
        "    loss_weight = 1/adjusted_y2.mean(axis=0)\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    \n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-3, 1e-5, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 200)\n",
        "\n",
        "model_save_name = 'jax_knock_out_1stock_MC_2_Judy.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Judy/{model_save_name}\"\n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.009837024845182896 average time 0.24631974474999083 iter num 20\n",
            "loss 0.005230747163295746 average time 0.13906275147499514 iter num 40\n",
            "loss 0.012459330260753632 average time 0.10349449058332993 iter num 60\n",
            "loss 0.006779261864721775 average time 0.08566785746249934 iter num 80\n",
            "loss 0.009595663286745548 average time 0.0749722836599983 iter num 100\n",
            "loss 0.01615658774971962 average time 0.12013206050000917 iter num 20\n",
            "loss 0.006901748012751341 average time 0.07608334497500949 iter num 40\n",
            "loss 0.014200668781995773 average time 0.06190141713333522 iter num 60\n",
            "loss 0.011151954531669617 average time 0.054412703962496776 iter num 80\n",
            "loss 0.009192717261612415 average time 0.0499799787999973 iter num 100\n",
            "loss 0.007371619343757629 average time 0.11950973005000379 iter num 20\n",
            "loss 0.016508137807250023 average time 0.07601087557499397 iter num 40\n",
            "loss 0.01232246682047844 average time 0.06134051851666224 iter num 60\n",
            "loss 0.015216751024127007 average time 0.05391117348749504 iter num 80\n",
            "loss 0.01101730577647686 average time 0.04956428862999928 iter num 100\n",
            "loss 0.013927115127444267 average time 0.11784876104999284 iter num 20\n",
            "loss 0.00925867073237896 average time 0.0748680493250106 iter num 40\n",
            "loss 0.015036550350487232 average time 0.06055064493333854 iter num 60\n",
            "loss 0.00803458970040083 average time 0.05354091212500691 iter num 80\n",
            "loss 0.01851891167461872 average time 0.04923688323000988 iter num 100\n",
            "loss 0.01752910204231739 average time 0.11909076359996788 iter num 20\n",
            "loss 0.01173301413655281 average time 0.07551886772495778 iter num 40\n",
            "loss 0.019387295469641685 average time 0.060971517816634936 iter num 60\n",
            "loss 0.008241947740316391 average time 0.05368369771247217 iter num 80\n",
            "loss 0.014772903174161911 average time 0.049261379249974195 iter num 100\n",
            "loss 0.018088871613144875 average time 0.11835646330001737 iter num 20\n",
            "loss 0.004627342335879803 average time 0.0751400328499983 iter num 40\n",
            "loss 0.01264924556016922 average time 0.060756822716666645 iter num 60\n",
            "loss 0.01109447330236435 average time 0.053526522699996804 iter num 80\n",
            "loss 0.014391972683370113 average time 0.04941805851999561 iter num 100\n",
            "loss 0.005350648891180754 average time 0.11878950795002083 iter num 20\n",
            "loss 0.011495115235447884 average time 0.07543533557501406 iter num 40\n",
            "loss 0.015372488647699356 average time 0.06102517210000921 iter num 60\n",
            "loss 0.004595993086695671 average time 0.053944310149995546 iter num 80\n",
            "loss 0.010652441531419754 average time 0.04971572809000463 iter num 100\n",
            "loss 0.005388624966144562 average time 0.11808294444998638 iter num 20\n",
            "loss 0.0077728526666760445 average time 0.07485665690000473 iter num 40\n",
            "loss 0.0070371609181165695 average time 0.060534970733340285 iter num 60\n",
            "loss 0.006876099854707718 average time 0.05346378773749905 iter num 80\n",
            "loss 0.0141369067132473 average time 0.04911080343999629 iter num 100\n",
            "loss 0.012685872614383698 average time 0.1194092098500505 iter num 20\n",
            "loss 0.004378961864858866 average time 0.07548042867501295 iter num 40\n",
            "loss 0.008407577872276306 average time 0.06099097403336297 iter num 60\n",
            "loss 0.006231147330254316 average time 0.05379757536252896 iter num 80\n",
            "loss 0.023492468520998955 average time 0.049494753010021666 iter num 100\n",
            "loss 0.004454472102224827 average time 0.11899845560001268 iter num 20\n",
            "loss 0.010688726790249348 average time 0.07590193567500592 iter num 40\n",
            "loss 0.0140613978728652 average time 0.061540788966666087 iter num 60\n",
            "loss 0.019180523231625557 average time 0.05441115586250476 iter num 80\n",
            "loss 0.014210200868546963 average time 0.05010230185999717 iter num 100\n",
            "loss 0.01314227283000946 average time 0.12044954129996768 iter num 20\n",
            "loss 0.008327801711857319 average time 0.07627344522503562 iter num 40\n",
            "loss 0.007673755753785372 average time 0.0617033596500581 iter num 60\n",
            "loss 0.01279336865991354 average time 0.05433291780004197 iter num 80\n",
            "loss 0.00980114471167326 average time 0.04998212318004789 iter num 100\n",
            "loss 0.010170764289796352 average time 0.11771240980003768 iter num 20\n",
            "loss 0.009647615253925323 average time 0.07501034202501841 iter num 40\n",
            "loss 0.010684811510145664 average time 0.0610348803000079 iter num 60\n",
            "loss 0.010316143743693829 average time 0.05379172493752549 iter num 80\n",
            "loss 0.011885716579854488 average time 0.04955466802001865 iter num 100\n",
            "loss 0.012424284592270851 average time 0.1181473646000768 iter num 20\n",
            "loss 0.007852207869291306 average time 0.07513911662500732 iter num 40\n",
            "loss 0.009172762744128704 average time 0.060729104966693134 iter num 60\n",
            "loss 0.007453916594386101 average time 0.053694332300028694 iter num 80\n",
            "loss 0.013155043125152588 average time 0.049550927900036186 iter num 100\n",
            "loss 0.008862187154591084 average time 0.11886258740000813 iter num 20\n",
            "loss 0.014081518165767193 average time 0.07525023250003642 iter num 40\n",
            "loss 0.018576156347990036 average time 0.06077398943336902 iter num 60\n",
            "loss 0.00942820031195879 average time 0.05368451912502792 iter num 80\n",
            "loss 0.01158103533089161 average time 0.049303967120013115 iter num 100\n",
            "loss 0.00869146641343832 average time 0.11926384580003742 iter num 20\n",
            "loss 0.013109663501381874 average time 0.07574337870001954 iter num 40\n",
            "loss 0.013024801388382912 average time 0.061198895050013864 iter num 60\n",
            "loss 0.019623659551143646 average time 0.053976281837503845 iter num 80\n",
            "loss 0.013931102119386196 average time 0.049588510900002804 iter num 100\n",
            "loss 0.008876112289726734 average time 0.11825143964995277 iter num 20\n",
            "loss 0.007977224886417389 average time 0.07498083592495278 iter num 40\n",
            "loss 0.013773735612630844 average time 0.06068200378329038 iter num 60\n",
            "loss 0.008569297380745411 average time 0.05354231558746392 iter num 80\n",
            "loss 0.008078697137534618 average time 0.04925027712997235 iter num 100\n",
            "loss 0.0072392611764371395 average time 0.11888121640004101 iter num 20\n",
            "loss 0.01331923808902502 average time 0.07548465510000142 iter num 40\n",
            "loss 0.012755682691931725 average time 0.06118530198334611 iter num 60\n",
            "loss 0.016561469063162804 average time 0.053981824812495915 iter num 80\n",
            "loss 0.014258116483688354 average time 0.049600999479994246 iter num 100\n",
            "loss 0.007863873615860939 average time 0.11903789934997348 iter num 20\n",
            "loss 0.013186185620725155 average time 0.07566962422503139 iter num 40\n",
            "loss 0.009253053925931454 average time 0.06119948186668201 iter num 60\n",
            "loss 0.00803766306489706 average time 0.05406455002500934 iter num 80\n",
            "loss 0.00878304522484541 average time 0.04970724726000299 iter num 100\n",
            "loss 0.00989795383065939 average time 0.1175686928000232 iter num 20\n",
            "loss 0.016798915341496468 average time 0.0746764411500294 iter num 40\n",
            "loss 0.006951094139367342 average time 0.06041912158335284 iter num 60\n",
            "loss 0.009977557696402073 average time 0.05332812478751521 iter num 80\n",
            "loss 0.008505267091095448 average time 0.04907398829001522 iter num 100\n",
            "loss 0.0067620123736560345 average time 0.1189882694499829 iter num 20\n",
            "loss 0.019214577972888947 average time 0.07534221434997335 iter num 40\n",
            "loss 0.016943763941526413 average time 0.06105421076667123 iter num 60\n",
            "loss 0.009664534591138363 average time 0.0538284338624976 iter num 80\n",
            "loss 0.009121055714786053 average time 0.04960638569001276 iter num 100\n",
            "loss 0.01818390190601349 average time 0.11988510510004743 iter num 20\n",
            "loss 0.01226468849927187 average time 0.07627116085006946 iter num 40\n",
            "loss 0.012700123712420464 average time 0.062133341866698784 iter num 60\n",
            "loss 0.021683217957615852 average time 0.05457681802502066 iter num 80\n",
            "loss 0.012194233015179634 average time 0.050246908270037235 iter num 100\n",
            "loss 0.01682952418923378 average time 0.11869877664985325 iter num 20\n",
            "loss 0.016096878796815872 average time 0.07533002934997057 iter num 40\n",
            "loss 0.01717962883412838 average time 0.060895847016642315 iter num 60\n",
            "loss 0.004113308619707823 average time 0.053722276087489716 iter num 80\n",
            "loss 0.007530760485678911 average time 0.04948312561000421 iter num 100\n",
            "loss 0.014692760072648525 average time 0.11870383985014996 iter num 20\n",
            "loss 0.011986550875008106 average time 0.07560390147507405 iter num 40\n",
            "loss 0.010073527693748474 average time 0.06102595690002393 iter num 60\n",
            "loss 0.013254135847091675 average time 0.053823602437535104 iter num 80\n",
            "loss 0.005927269347012043 average time 0.04943870689003234 iter num 100\n",
            "loss 0.013773034326732159 average time 0.11894289314996058 iter num 20\n",
            "loss 0.010735015384852886 average time 0.07575311690000035 iter num 40\n",
            "loss 0.012230541557073593 average time 0.061547629050028266 iter num 60\n",
            "loss 0.010279052890837193 average time 0.0541525935125037 iter num 80\n",
            "loss 0.021848300471901894 average time 0.049732533949982095 iter num 100\n",
            "loss 0.006989243905991316 average time 0.11785617099999399 iter num 20\n",
            "loss 0.011640089564025402 average time 0.07516532950000965 iter num 40\n",
            "loss 0.009624377824366093 average time 0.06088203715000115 iter num 60\n",
            "loss 0.010420840233564377 average time 0.05366247731250269 iter num 80\n",
            "loss 0.014216158539056778 average time 0.04937957392999124 iter num 100\n",
            "loss 0.028051307424902916 average time 0.12033424020000894 iter num 20\n",
            "loss 0.01768631301820278 average time 0.07641239890003818 iter num 40\n",
            "loss 0.002264247043058276 average time 0.0616859620833111 iter num 60\n",
            "loss 0.018101129680871964 average time 0.054101098437479324 iter num 80\n",
            "loss 0.007709953933954239 average time 0.04968683598996904 iter num 100\n",
            "loss 0.025437207892537117 average time 0.11779949010015116 iter num 20\n",
            "loss 0.014310947619378567 average time 0.07469719314999565 iter num 40\n",
            "loss 0.011033190414309502 average time 0.06039317648336085 iter num 60\n",
            "loss 0.032409682869911194 average time 0.05334891986254888 iter num 80\n",
            "loss 0.006326863542199135 average time 0.049140814590073204 iter num 100\n",
            "loss 0.01818540133535862 average time 0.12058273900011045 iter num 20\n",
            "loss 0.013763352297246456 average time 0.07634652435003772 iter num 40\n",
            "loss 0.013177195563912392 average time 0.06183208628332674 iter num 60\n",
            "loss 0.01364214438945055 average time 0.0545136290624896 iter num 80\n",
            "loss 0.02001253329217434 average time 0.05005411910997282 iter num 100\n",
            "loss 0.01085702981799841 average time 0.11777390105012273 iter num 20\n",
            "loss 0.019481496885418892 average time 0.07523791984999662 iter num 40\n",
            "loss 0.020731577649712563 average time 0.060912324133338795 iter num 60\n",
            "loss 0.020166516304016113 average time 0.054014473525000994 iter num 80\n",
            "loss 0.013215705752372742 average time 0.049714186829996836 iter num 100\n",
            "loss 0.007829397916793823 average time 0.11910821060000672 iter num 20\n",
            "loss 0.006169955246150494 average time 0.07539613070002815 iter num 40\n",
            "loss 0.011758502572774887 average time 0.06087338923336271 iter num 60\n",
            "loss 0.013135498389601707 average time 0.05363548807501957 iter num 80\n",
            "loss 0.01791013963520527 average time 0.04940019033000681 iter num 100\n",
            "loss 0.013971573673188686 average time 0.11810779349993936 iter num 20\n",
            "loss 0.015538672916591167 average time 0.07512728349997815 iter num 40\n",
            "loss 0.007987741380929947 average time 0.06083143651665826 iter num 60\n",
            "loss 0.013844601809978485 average time 0.05362186935003592 iter num 80\n",
            "loss 0.012320834212005138 average time 0.049344425920035066 iter num 100\n",
            "loss 0.009264287538826466 average time 0.12038871950003341 iter num 20\n",
            "loss 0.015741540119051933 average time 0.07644764145004501 iter num 40\n",
            "loss 0.0070910765789449215 average time 0.06175650978334488 iter num 60\n",
            "loss 0.020719824358820915 average time 0.0542547985749934 iter num 80\n",
            "loss 0.012083187699317932 average time 0.04980635779000295 iter num 100\n",
            "loss 0.014421049505472183 average time 0.11902999364988318 iter num 20\n",
            "loss 0.008015140891075134 average time 0.0757892524499539 iter num 40\n",
            "loss 0.012095092795789242 average time 0.06118308131664586 iter num 60\n",
            "loss 0.012430653907358646 average time 0.05381981404997305 iter num 80\n",
            "loss 0.01314811035990715 average time 0.04948230152995166 iter num 100\n",
            "loss 0.008183320984244347 average time 0.12033970415000113 iter num 20\n",
            "loss 0.019720520824193954 average time 0.07619253099996967 iter num 40\n",
            "loss 0.016081472858786583 average time 0.061886597766654936 iter num 60\n",
            "loss 0.023524638265371323 average time 0.054586995574982214 iter num 80\n",
            "loss 0.01558341272175312 average time 0.05023533379998298 iter num 100\n",
            "loss 0.009829972870647907 average time 0.1204791273500632 iter num 20\n",
            "loss 0.007567972876131535 average time 0.0762807309000209 iter num 40\n",
            "loss 0.017785221338272095 average time 0.061693687033357494 iter num 60\n",
            "loss 0.006505956407636404 average time 0.054253890587540356 iter num 80\n",
            "loss 0.006329961121082306 average time 0.049800494430028264 iter num 100\n",
            "loss 0.014549866318702698 average time 0.119244504649987 iter num 20\n",
            "loss 0.02078481949865818 average time 0.07581391015000918 iter num 40\n",
            "loss 0.009325169958174229 average time 0.061518024066738994 iter num 60\n",
            "loss 0.029694782570004463 average time 0.0540865780375384 iter num 80\n",
            "loss 0.017542587593197823 average time 0.04985091398001714 iter num 100\n",
            "loss 0.01164004672318697 average time 0.11863157919992773 iter num 20\n",
            "loss 0.009015255607664585 average time 0.07524485447495408 iter num 40\n",
            "loss 0.006168131250888109 average time 0.060832757916599194 iter num 60\n",
            "loss 0.008955111727118492 average time 0.05374962439994988 iter num 80\n",
            "loss 0.009194664657115936 average time 0.049335558389948346 iter num 100\n",
            "loss 0.008813238702714443 average time 0.11872406814995884 iter num 20\n",
            "loss 0.011737601831555367 average time 0.07517448510004669 iter num 40\n",
            "loss 0.010804780758917332 average time 0.060794217716753945 iter num 60\n",
            "loss 0.016277778893709183 average time 0.05372268031251224 iter num 80\n",
            "loss 0.013326105661690235 average time 0.04955281631003345 iter num 100\n",
            "loss 0.016293711960315704 average time 0.1192420178500015 iter num 20\n",
            "loss 0.014590791426599026 average time 0.0759654059249442 iter num 40\n",
            "loss 0.017664272338151932 average time 0.06136148838330276 iter num 60\n",
            "loss 0.005698572378605604 average time 0.054044091162450056 iter num 80\n",
            "loss 0.005900239106267691 average time 0.04965835296993646 iter num 100\n",
            "loss 0.011036423966288567 average time 0.1192038862499885 iter num 20\n",
            "loss 0.017253687605261803 average time 0.07582259572493513 iter num 40\n",
            "loss 0.005017463117837906 average time 0.061303286116572056 iter num 60\n",
            "loss 0.015624083578586578 average time 0.054110317437459796 iter num 80\n",
            "loss 0.013765464536845684 average time 0.04975369205999414 iter num 100\n",
            "loss 0.007655366789549589 average time 0.11831748715003414 iter num 20\n",
            "loss 0.016637932509183884 average time 0.075266514225018 iter num 40\n",
            "loss 0.016075028106570244 average time 0.06066966458338356 iter num 60\n",
            "loss 0.006520957686007023 average time 0.05356628148754226 iter num 80\n",
            "loss 0.008856398053467274 average time 0.049226335930043205 iter num 100\n",
            "loss 0.012419192120432854 average time 0.12014039260016034 iter num 20\n",
            "loss 0.016859017312526703 average time 0.07616383245008365 iter num 40\n",
            "loss 0.008626308292150497 average time 0.06156891255007698 iter num 60\n",
            "loss 0.01978711411356926 average time 0.05430823306260209 iter num 80\n",
            "loss 0.004520808812230825 average time 0.0499321987600797 iter num 100\n",
            "loss 0.020607855170965195 average time 0.11874005415011198 iter num 20\n",
            "loss 0.007162701338529587 average time 0.07565866074994573 iter num 40\n",
            "loss 0.015457753092050552 average time 0.061293770399970526 iter num 60\n",
            "loss 0.005805605091154575 average time 0.05409537142494401 iter num 80\n",
            "loss 0.019718097522854805 average time 0.04978424463994088 iter num 100\n",
            "loss 0.006925717927515507 average time 0.11835450144994866 iter num 20\n",
            "loss 0.006711017806082964 average time 0.0757622310750321 iter num 40\n",
            "loss 0.01839410699903965 average time 0.061434208166701865 iter num 60\n",
            "loss 0.01433578785508871 average time 0.05416240768747684 iter num 80\n",
            "loss 0.008320827968418598 average time 0.049850514119953004 iter num 100\n",
            "loss 0.012672807089984417 average time 0.1184388629996647 iter num 20\n",
            "loss 0.008072935976088047 average time 0.07522359569970831 iter num 40\n",
            "loss 0.014671125449240208 average time 0.06080775873312329 iter num 60\n",
            "loss 0.014774700626730919 average time 0.05377987156236941 iter num 80\n",
            "loss 0.011154253035783768 average time 0.04943550728990886 iter num 100\n",
            "loss 0.004610034171491861 average time 0.11852142510006161 iter num 20\n",
            "loss 0.009297412820160389 average time 0.07526622820009835 iter num 40\n",
            "loss 0.02156773768365383 average time 0.060975197566767746 iter num 60\n",
            "loss 0.0085320845246315 average time 0.05366295822509528 iter num 80\n",
            "loss 0.004050461575388908 average time 0.04947987440005818 iter num 100\n",
            "loss 0.011901827529072762 average time 0.1191696138500447 iter num 20\n",
            "loss 0.029934249818325043 average time 0.07584759192509409 iter num 40\n",
            "loss 0.01504344679415226 average time 0.06144458203340643 iter num 60\n",
            "loss 0.013114620000123978 average time 0.05431986241246704 iter num 80\n",
            "loss 0.005387448705732822 average time 0.04987535849995765 iter num 100\n",
            "loss 0.01441639568656683 average time 0.11928106385021238 iter num 20\n",
            "loss 0.01700793392956257 average time 0.07563185795020218 iter num 40\n",
            "loss 0.02041521854698658 average time 0.061468704350257516 iter num 60\n",
            "loss 0.008315353654325008 average time 0.05405283031266208 iter num 80\n",
            "loss 0.007958386093378067 average time 0.04970564406010453 iter num 100\n",
            "loss 0.015443315729498863 average time 0.11964488954990884 iter num 20\n",
            "loss 0.006396088283509016 average time 0.07646209212502982 iter num 40\n",
            "loss 0.008538845926523209 average time 0.061787271633238564 iter num 60\n",
            "loss 0.010466896928846836 average time 0.05433004837500448 iter num 80\n",
            "loss 0.010547167621552944 average time 0.049882142450005634 iter num 100\n",
            "loss 0.009219739586114883 average time 0.11899483280021741 iter num 20\n",
            "loss 0.007447399199008942 average time 0.07549337095006195 iter num 40\n",
            "loss 0.005652617197483778 average time 0.06113090288332993 iter num 60\n",
            "loss 0.005600116681307554 average time 0.053934934099947894 iter num 80\n",
            "loss 0.010353724472224712 average time 0.0495625428299536 iter num 100\n",
            "loss 0.009433171711862087 average time 0.120701909249874 iter num 20\n",
            "loss 0.01240587793290615 average time 0.07655427910003709 iter num 40\n",
            "loss 0.008098060265183449 average time 0.06216694754997055 iter num 60\n",
            "loss 0.017632750794291496 average time 0.05469349628745022 iter num 80\n",
            "loss 0.011330998502671719 average time 0.05020295772996178 iter num 100\n",
            "loss 0.006223256699740887 average time 0.11932659950007292 iter num 20\n",
            "loss 0.018308723345398903 average time 0.07562260230001812 iter num 40\n",
            "loss 0.013071068562567234 average time 0.061016901450057046 iter num 60\n",
            "loss 0.006225812714546919 average time 0.053940288825060634 iter num 80\n",
            "loss 0.01426667906343937 average time 0.04956999500000166 iter num 100\n",
            "loss 0.014177098870277405 average time 0.11956098894988827 iter num 20\n",
            "loss 0.016116904094815254 average time 0.07586391310001091 iter num 40\n",
            "loss 0.00958219449967146 average time 0.06148599996668054 iter num 60\n",
            "loss 0.01211873535066843 average time 0.05420953626248774 iter num 80\n",
            "loss 0.01805078238248825 average time 0.04975097585002004 iter num 100\n",
            "loss 0.019009551033377647 average time 0.11986314465002579 iter num 20\n",
            "loss 0.01210721768438816 average time 0.07639307007498246 iter num 40\n",
            "loss 0.006703334394842386 average time 0.06172407560006832 iter num 60\n",
            "loss 0.010823140852153301 average time 0.05430805337505262 iter num 80\n",
            "loss 0.012325678020715714 average time 0.04988757119004731 iter num 100\n",
            "loss 0.011068806983530521 average time 0.1195498288501767 iter num 20\n",
            "loss 0.022856369614601135 average time 0.07576130570014357 iter num 40\n",
            "loss 0.0049802567809820175 average time 0.061140639050063325 iter num 60\n",
            "loss 0.024455688893795013 average time 0.05389120966253813 iter num 80\n",
            "loss 0.004046470858156681 average time 0.04955708113997389 iter num 100\n",
            "loss 0.00974525511264801 average time 0.11868285420014217 iter num 20\n",
            "loss 0.01838713511824608 average time 0.07579199647511814 iter num 40\n",
            "loss 0.015658583492040634 average time 0.06122511120008009 iter num 60\n",
            "loss 0.003927225712686777 average time 0.05408974459999172 iter num 80\n",
            "loss 0.009528540074825287 average time 0.04957224826997844 iter num 100\n",
            "loss 0.007390336599200964 average time 0.11861747734992605 iter num 20\n",
            "loss 0.012451392598450184 average time 0.07532532657487537 iter num 40\n",
            "loss 0.001358714303933084 average time 0.060790819399911315 iter num 60\n",
            "loss 0.009498284198343754 average time 0.05354376876239257 iter num 80\n",
            "loss 0.023017631843686104 average time 0.04941890844993395 iter num 100\n",
            "loss 0.010588844306766987 average time 0.12061027295003442 iter num 20\n",
            "loss 0.01911606825888157 average time 0.07621171285013588 iter num 40\n",
            "loss 0.021855412051081657 average time 0.06144157031679545 iter num 60\n",
            "loss 0.005367398262023926 average time 0.05403811053756726 iter num 80\n",
            "loss 0.003280727658420801 average time 0.0496346669700506 iter num 100\n",
            "loss 0.00952007994055748 average time 0.11713359209988994 iter num 20\n",
            "loss 0.017664778977632523 average time 0.07479854134990091 iter num 40\n",
            "loss 0.008365513756871223 average time 0.06058325863332357 iter num 60\n",
            "loss 0.011469894088804722 average time 0.05359751627499918 iter num 80\n",
            "loss 0.016145644709467888 average time 0.04924367403998985 iter num 100\n",
            "loss 0.010329995304346085 average time 0.11877409270009594 iter num 20\n",
            "loss 0.009922616183757782 average time 0.07548266020007759 iter num 40\n",
            "loss 0.017518021166324615 average time 0.06110065558341375 iter num 60\n",
            "loss 0.01119933184236288 average time 0.05386523170004694 iter num 80\n",
            "loss 0.006703538820147514 average time 0.04945105730004798 iter num 100\n",
            "loss 0.011713533662259579 average time 0.11782186215004913 iter num 20\n",
            "loss 0.006906215101480484 average time 0.07507401535008285 iter num 40\n",
            "loss 0.01029537059366703 average time 0.06092034180004096 iter num 60\n",
            "loss 0.012739155441522598 average time 0.05366682383753414 iter num 80\n",
            "loss 0.008854711428284645 average time 0.04932182872005796 iter num 100\n",
            "loss 0.012877210974693298 average time 0.11703901339997173 iter num 20\n",
            "loss 0.007636850234121084 average time 0.07422138777496912 iter num 40\n",
            "loss 0.00851534679532051 average time 0.06034182309998262 iter num 60\n",
            "loss 0.015766598284244537 average time 0.053307149350007424 iter num 80\n",
            "loss 0.023935580626130104 average time 0.049083049550008584 iter num 100\n",
            "loss 0.012038590386509895 average time 0.11824410730014279 iter num 20\n",
            "loss 0.005875045899301767 average time 0.07531781410002622 iter num 40\n",
            "loss 0.006495512090623379 average time 0.0610429168332909 iter num 60\n",
            "loss 0.007167771924287081 average time 0.05391761813755238 iter num 80\n",
            "loss 0.030164483934640884 average time 0.04957674805000352 iter num 100\n",
            "loss 0.01290854625403881 average time 0.11910832985004163 iter num 20\n",
            "loss 0.022657174617052078 average time 0.07589543947506172 iter num 40\n",
            "loss 0.023865308612585068 average time 0.06130702756675722 iter num 60\n",
            "loss 0.023409301415085793 average time 0.054079240375017434 iter num 80\n",
            "loss 0.010266588069498539 average time 0.04954490280000755 iter num 100\n",
            "loss 0.01464852411299944 average time 0.11945580400006292 iter num 20\n",
            "loss 0.012670314870774746 average time 0.07559760542508229 iter num 40\n",
            "loss 0.013546313159167767 average time 0.06118523970001964 iter num 60\n",
            "loss 0.0052877492271363735 average time 0.054069601624951245 iter num 80\n",
            "loss 0.010502185672521591 average time 0.04960494591994575 iter num 100\n",
            "loss 0.013526993803679943 average time 0.11745493399994303 iter num 20\n",
            "loss 0.029862770810723305 average time 0.07534276297510586 iter num 40\n",
            "loss 0.016271015629172325 average time 0.060878825983430335 iter num 60\n",
            "loss 0.011393642984330654 average time 0.053723617762580035 iter num 80\n",
            "loss 0.012895853258669376 average time 0.049479273240067415 iter num 100\n",
            "loss 0.006442695390433073 average time 0.11955248789990947 iter num 20\n",
            "loss 0.02023569867014885 average time 0.07567426934992909 iter num 40\n",
            "loss 0.014510645531117916 average time 0.06110372198327241 iter num 60\n",
            "loss 0.017539648339152336 average time 0.05374858444995425 iter num 80\n",
            "loss 0.010167030617594719 average time 0.04932273036996776 iter num 100\n",
            "loss 0.007208450231701136 average time 0.11702079149972633 iter num 20\n",
            "loss 0.016573118045926094 average time 0.07442596862483697 iter num 40\n",
            "loss 0.009338942356407642 average time 0.06014656838324299 iter num 60\n",
            "loss 0.01960163004696369 average time 0.05304026856240398 iter num 80\n",
            "loss 0.01357507985085249 average time 0.04876049397991664 iter num 100\n",
            "loss 0.005882195197045803 average time 0.1187076260500362 iter num 20\n",
            "loss 0.009026688523590565 average time 0.07517014512495734 iter num 40\n",
            "loss 0.009917066432535648 average time 0.06104456200006704 iter num 60\n",
            "loss 0.009587600827217102 average time 0.05392237766247945 iter num 80\n",
            "loss 0.009008516557514668 average time 0.04961254061001455 iter num 100\n",
            "loss 0.028892120346426964 average time 0.11862013129994012 iter num 20\n",
            "loss 0.020498109981417656 average time 0.07530297384992082 iter num 40\n",
            "loss 0.011430307291448116 average time 0.06116072501660407 iter num 60\n",
            "loss 0.024227173998951912 average time 0.054035630099974696 iter num 80\n",
            "loss 0.021759673953056335 average time 0.049663096829972345 iter num 100\n",
            "loss 0.01338095124810934 average time 0.11627753120010312 iter num 20\n",
            "loss 0.006262752693146467 average time 0.07418559945003836 iter num 40\n",
            "loss 0.003937246277928352 average time 0.06013818888332025 iter num 60\n",
            "loss 0.010516192764043808 average time 0.053199616212464204 iter num 80\n",
            "loss 0.01615598425269127 average time 0.049035155229958036 iter num 100\n",
            "loss 0.01883629895746708 average time 0.11963129954992838 iter num 20\n",
            "loss 0.01609026826918125 average time 0.07575755962493531 iter num 40\n",
            "loss 0.010416580364108086 average time 0.06112534148329966 iter num 60\n",
            "loss 0.018284957855939865 average time 0.05397465750004358 iter num 80\n",
            "loss 0.0252377986907959 average time 0.049607513119990475 iter num 100\n",
            "loss 0.008758969604969025 average time 0.1178378877000796 iter num 20\n",
            "loss 0.010583927854895592 average time 0.07491899295000622 iter num 40\n",
            "loss 0.012166839092969894 average time 0.060792507766715666 iter num 60\n",
            "loss 0.021988840773701668 average time 0.053622363399927056 iter num 80\n",
            "loss 0.009614885784685612 average time 0.04931092725997587 iter num 100\n",
            "loss 0.010867362841963768 average time 0.11770341764959084 iter num 20\n",
            "loss 0.006229661870747805 average time 0.07514488619990516 iter num 40\n",
            "loss 0.009806097485125065 average time 0.061105874233301924 iter num 60\n",
            "loss 0.013195198029279709 average time 0.05401408948750941 iter num 80\n",
            "loss 0.011804254725575447 average time 0.04972355617004723 iter num 100\n",
            "loss 0.00791219063103199 average time 0.11825961994991303 iter num 20\n",
            "loss 0.02663489431142807 average time 0.07511230632517255 iter num 40\n",
            "loss 0.01285671815276146 average time 0.06071189305015044 iter num 60\n",
            "loss 0.016001181676983833 average time 0.0535802526501584 iter num 80\n",
            "loss 0.018608659505844116 average time 0.0492406675401071 iter num 100\n",
            "loss 0.014918752014636993 average time 0.11804715725029383 iter num 20\n",
            "loss 0.00962902046740055 average time 0.07525740210016921 iter num 40\n",
            "loss 0.014069889672100544 average time 0.06083195611681731 iter num 60\n",
            "loss 0.01365673914551735 average time 0.053640029712664725 iter num 80\n",
            "loss 0.008657108061015606 average time 0.0494907332501316 iter num 100\n",
            "loss 0.008521649986505508 average time 0.11667426085004991 iter num 20\n",
            "loss 0.015165685676038265 average time 0.07434620790008921 iter num 40\n",
            "loss 0.011594971641898155 average time 0.0604874126833541 iter num 60\n",
            "loss 0.0036691944114863873 average time 0.05341931116245178 iter num 80\n",
            "loss 0.014624455012381077 average time 0.049053636739918145 iter num 100\n",
            "loss 0.014418461360037327 average time 0.11814885849998973 iter num 20\n",
            "loss 0.02193685621023178 average time 0.07548534282486799 iter num 40\n",
            "loss 0.013324515894055367 average time 0.06120747661655817 iter num 60\n",
            "loss 0.014778357930481434 average time 0.05397944233743601 iter num 80\n",
            "loss 0.021829692646861076 average time 0.04961857241996768 iter num 100\n",
            "loss 0.007463573012501001 average time 0.11794239329992706 iter num 20\n",
            "loss 0.016662195324897766 average time 0.07514025097489138 iter num 40\n",
            "loss 0.011717104353010654 average time 0.06072461233322125 iter num 60\n",
            "loss 0.006183610297739506 average time 0.05352893081235379 iter num 80\n",
            "loss 0.013579667545855045 average time 0.04919545886992637 iter num 100\n",
            "loss 0.0062864660285413265 average time 0.11693797464968156 iter num 20\n",
            "loss 0.01426591258496046 average time 0.07447933554976771 iter num 40\n",
            "loss 0.012583725154399872 average time 0.06042433114986731 iter num 60\n",
            "loss 0.0070549859665334225 average time 0.05327278816246235 iter num 80\n",
            "loss 0.006091077346354723 average time 0.04902177053998457 iter num 100\n",
            "loss 0.01732337847352028 average time 0.11960887234990877 iter num 20\n",
            "loss 0.009120185859501362 average time 0.07564561744989078 iter num 40\n",
            "loss 0.004466953221708536 average time 0.061264794133270094 iter num 60\n",
            "loss 0.016321266070008278 average time 0.053924695474916004 iter num 80\n",
            "loss 0.014845382422208786 average time 0.04954596073992434 iter num 100\n",
            "loss 0.005968003533780575 average time 0.11908187564959008 iter num 20\n",
            "loss 0.004167486913502216 average time 0.07577412182486114 iter num 40\n",
            "loss 0.009983827359974384 average time 0.061155213566568514 iter num 60\n",
            "loss 0.009335898794233799 average time 0.053973049874957726 iter num 80\n",
            "loss 0.01313709281384945 average time 0.04960726598998008 iter num 100\n",
            "loss 0.009516691789031029 average time 0.11926126179996573 iter num 20\n",
            "loss 0.008051288314163685 average time 0.07572325377495873 iter num 40\n",
            "loss 0.01890835165977478 average time 0.061096049866652416 iter num 60\n",
            "loss 0.006631580181419849 average time 0.0538792210000338 iter num 80\n",
            "loss 0.01627286523580551 average time 0.04951504302007379 iter num 100\n",
            "loss 0.014499490149319172 average time 0.11979397630002495 iter num 20\n",
            "loss 0.01181026827543974 average time 0.07605431452511766 iter num 40\n",
            "loss 0.014845210127532482 average time 0.061530426583461424 iter num 60\n",
            "loss 0.01197036262601614 average time 0.05415122173758391 iter num 80\n",
            "loss 0.006511498708277941 average time 0.049726148810059385 iter num 100\n",
            "loss 0.01597808487713337 average time 0.11711751330003609 iter num 20\n",
            "loss 0.010026643984019756 average time 0.0745535075501266 iter num 40\n",
            "loss 0.01693989709019661 average time 0.060339033400062664 iter num 60\n",
            "loss 0.010407954454421997 average time 0.05323396786254762 iter num 80\n",
            "loss 0.007623440120369196 average time 0.04909382428004392 iter num 100\n",
            "loss 0.009435078129172325 average time 0.11881295595003394 iter num 20\n",
            "loss 0.00861220434308052 average time 0.07551725540020016 iter num 40\n",
            "loss 0.01197073794901371 average time 0.061129098950095793 iter num 60\n",
            "loss 0.00846122670918703 average time 0.05380417388755632 iter num 80\n",
            "loss 0.026710407808423042 average time 0.049524865220064385 iter num 100\n",
            "loss 0.006788068450987339 average time 0.11866024825012574 iter num 20\n",
            "loss 0.005640972871333361 average time 0.07534344120017522 iter num 40\n",
            "loss 0.00966745987534523 average time 0.06100181951669583 iter num 60\n",
            "loss 0.008412586525082588 average time 0.053997095000045195 iter num 80\n",
            "loss 0.009753221645951271 average time 0.04966558076001092 iter num 100\n",
            "loss 0.011096235364675522 average time 0.11867511624996041 iter num 20\n",
            "loss 0.02145460434257984 average time 0.07530302862496682 iter num 40\n",
            "loss 0.013057908974587917 average time 0.060943525699925276 iter num 60\n",
            "loss 0.016617437824606895 average time 0.05375494129996241 iter num 80\n",
            "loss 0.01920454390347004 average time 0.04928832274001252 iter num 100\n",
            "loss 0.005755229853093624 average time 0.11729455430004236 iter num 20\n",
            "loss 0.015909815207123756 average time 0.07463207779987897 iter num 40\n",
            "loss 0.003996205050498247 average time 0.060423789599917656 iter num 60\n",
            "loss 0.010692243464291096 average time 0.05334154349989149 iter num 80\n",
            "loss 0.024967364966869354 average time 0.049179515479954715 iter num 100\n",
            "loss 0.008647168055176735 average time 0.11919167160003781 iter num 20\n",
            "loss 0.01701553910970688 average time 0.07588948352508851 iter num 40\n",
            "loss 0.010867493227124214 average time 0.061122876783398776 iter num 60\n",
            "loss 0.0222827959805727 average time 0.05414780993755812 iter num 80\n",
            "loss 0.01234537921845913 average time 0.049721174990081635 iter num 100\n",
            "loss 0.03449924662709236 average time 0.11893085559959218 iter num 20\n",
            "loss 0.014011417515575886 average time 0.07536891222484883 iter num 40\n",
            "loss 0.018499890342354774 average time 0.06114043896671622 iter num 60\n",
            "loss 0.010786405764520168 average time 0.054247517237649846 iter num 80\n",
            "loss 0.007448459509760141 average time 0.049774473320121616 iter num 100\n",
            "loss 0.008328564465045929 average time 0.11733205224991253 iter num 20\n",
            "loss 0.005014421418309212 average time 0.07456278417475914 iter num 40\n",
            "loss 0.007855852134525776 average time 0.06037011521639215 iter num 60\n",
            "loss 0.004265522118657827 average time 0.05342055918722508 iter num 80\n",
            "loss 0.019157014787197113 average time 0.04912277264964359 iter num 100\n",
            "loss 0.013820260763168335 average time 0.11919335119964672 iter num 20\n",
            "loss 0.006675982382148504 average time 0.07567014387477684 iter num 40\n",
            "loss 0.013826616108417511 average time 0.0611365549160837 iter num 60\n",
            "loss 0.006097829435020685 average time 0.05383113614966532 iter num 80\n",
            "loss 0.007291961926966906 average time 0.04945901329963817 iter num 100\n",
            "loss 0.02677912265062332 average time 0.11927027700039616 iter num 20\n",
            "loss 0.01518753170967102 average time 0.07583230105001348 iter num 40\n",
            "loss 0.02185581997036934 average time 0.06121060071661001 iter num 60\n",
            "loss 0.001000597607344389 average time 0.05405423122497268 iter num 80\n",
            "loss 0.009717503562569618 average time 0.04961935302999336 iter num 100\n",
            "loss 0.016804948449134827 average time 0.1173931494991848 iter num 20\n",
            "loss 0.021404974162578583 average time 0.07503380332454981 iter num 40\n",
            "loss 0.010943315923213959 average time 0.06079793159976058 iter num 60\n",
            "loss 0.007515087723731995 average time 0.053730959299855385 iter num 80\n",
            "loss 0.016186272725462914 average time 0.04929384789986216 iter num 100\n",
            "loss 0.0052172294817864895 average time 0.1190439038004115 iter num 20\n",
            "loss 0.017849640920758247 average time 0.07560280917487035 iter num 40\n",
            "loss 0.013894488103687763 average time 0.06090963791642328 iter num 60\n",
            "loss 0.013376526534557343 average time 0.053613823999785384 iter num 80\n",
            "loss 0.014966919086873531 average time 0.049358412209840025 iter num 100\n",
            "loss 0.005848322995007038 average time 0.11869063444974018 iter num 20\n",
            "loss 0.006052934564650059 average time 0.0751806058998227 iter num 40\n",
            "loss 0.01597205176949501 average time 0.06060375228322907 iter num 60\n",
            "loss 0.010839737020432949 average time 0.05335282606238252 iter num 80\n",
            "loss 0.01729867048561573 average time 0.048993256699905036 iter num 100\n",
            "loss 0.013750679790973663 average time 0.1171949774505265 iter num 20\n",
            "loss 0.005304703023284674 average time 0.07452927337562869 iter num 40\n",
            "loss 0.007892557419836521 average time 0.06014542236698617 iter num 60\n",
            "loss 0.004260475281625986 average time 0.053068327250366566 iter num 80\n",
            "loss 0.016141647472977638 average time 0.048729495750230854 iter num 100\n",
            "loss 0.004816640168428421 average time 0.11734761010029615 iter num 20\n",
            "loss 0.015544549562036991 average time 0.07444838670016907 iter num 40\n",
            "loss 0.011570935137569904 average time 0.06010054858349274 iter num 60\n",
            "loss 0.004492005333304405 average time 0.05306494605001717 iter num 80\n",
            "loss 0.016904523596167564 average time 0.04871718142003374 iter num 100\n",
            "loss 0.012784273363649845 average time 0.11887787755022146 iter num 20\n",
            "loss 0.016568683087825775 average time 0.07537752092493974 iter num 40\n",
            "loss 0.00742307398468256 average time 0.060949020750194906 iter num 60\n",
            "loss 0.012621263042092323 average time 0.05362578163767466 iter num 80\n",
            "loss 0.010717112571001053 average time 0.049156333680220994 iter num 100\n",
            "loss 0.015285680070519447 average time 0.11739538319998247 iter num 20\n",
            "loss 0.015732698142528534 average time 0.0746379227250145 iter num 40\n",
            "loss 0.010517502203583717 average time 0.06023014458345036 iter num 60\n",
            "loss 0.012996899895370007 average time 0.05313497232505142 iter num 80\n",
            "loss 0.005222286097705364 average time 0.048844456760161845 iter num 100\n",
            "loss 0.010946870781481266 average time 0.11641489334961079 iter num 20\n",
            "loss 0.004410737659782171 average time 0.07412469519967999 iter num 40\n",
            "loss 0.013630231842398643 average time 0.060008114682993136 iter num 60\n",
            "loss 0.007046069018542767 average time 0.05287306083732801 iter num 80\n",
            "loss 0.005147810094058514 average time 0.04866408891983156 iter num 100\n",
            "loss 0.005546947475522757 average time 0.11722053775029054 iter num 20\n",
            "loss 0.012206022627651691 average time 0.07449718875004692 iter num 40\n",
            "loss 0.015293609350919724 average time 0.06011756211658697 iter num 60\n",
            "loss 0.008510559797286987 average time 0.05313388899994607 iter num 80\n",
            "loss 0.015754418447613716 average time 0.048972878899985514 iter num 100\n",
            "loss 0.021546360105276108 average time 0.1205902806495942 iter num 20\n",
            "loss 0.021552957594394684 average time 0.07611550942474424 iter num 40\n",
            "loss 0.01109723187983036 average time 0.0613003659498645 iter num 60\n",
            "loss 0.010225026868283749 average time 0.05409849093766752 iter num 80\n",
            "loss 0.0038415209855884314 average time 0.04957980698021856 iter num 100\n",
            "loss 0.015189767815172672 average time 0.11750628809986666 iter num 20\n",
            "loss 0.02211015671491623 average time 0.07470919509987653 iter num 40\n",
            "loss 0.013860424049198627 average time 0.06039674533324917 iter num 60\n",
            "loss 0.006497714668512344 average time 0.05317331931241824 iter num 80\n",
            "loss 0.0029148466419428587 average time 0.04886873646999448 iter num 100\n",
            "loss 0.01617376320064068 average time 0.11682659714970214 iter num 20\n",
            "loss 0.01337429415434599 average time 0.07437675082501301 iter num 40\n",
            "loss 0.011236919090151787 average time 0.06011485711678688 iter num 60\n",
            "loss 0.019490696489810944 average time 0.0530849128000682 iter num 80\n",
            "loss 0.007559359073638916 average time 0.04890588117010339 iter num 100\n",
            "loss 0.014198881573975086 average time 0.11875236099986068 iter num 20\n",
            "loss 0.016154125332832336 average time 0.0752054261001831 iter num 40\n",
            "loss 0.005408769939094782 average time 0.06059107405011067 iter num 60\n",
            "loss 0.0198399405926466 average time 0.05341931918774208 iter num 80\n",
            "loss 0.01389219518750906 average time 0.049081041870231275 iter num 100\n",
            "loss 0.01300077885389328 average time 0.11692202210033428 iter num 20\n",
            "loss 0.019487528130412102 average time 0.07449709282491312 iter num 40\n",
            "loss 0.007007771637290716 average time 0.060404483383293454 iter num 60\n",
            "loss 0.015386596322059631 average time 0.05325913511251201 iter num 80\n",
            "loss 0.02091086469590664 average time 0.048915099389996615 iter num 100\n",
            "loss 0.0120031563565135 average time 0.11765299629969377 iter num 20\n",
            "loss 0.005998607259243727 average time 0.07461759687503218 iter num 40\n",
            "loss 0.0041368696838617325 average time 0.06030766551642349 iter num 60\n",
            "loss 0.004817070439457893 average time 0.05319117083727178 iter num 80\n",
            "loss 0.01024085097014904 average time 0.04888867289988411 iter num 100\n",
            "loss 0.0068817343562841415 average time 0.11803868320021138 iter num 20\n",
            "loss 0.009185844101011753 average time 0.07476860237511573 iter num 40\n",
            "loss 0.005475298501551151 average time 0.06043735721680908 iter num 60\n",
            "loss 0.012205335311591625 average time 0.05324868985017019 iter num 80\n",
            "loss 0.01114062499254942 average time 0.04893806574011251 iter num 100\n",
            "loss 0.0243423730134964 average time 0.11781851150026341 iter num 20\n",
            "loss 0.008805081248283386 average time 0.07504617677504939 iter num 40\n",
            "loss 0.004692417103797197 average time 0.06068242166663064 iter num 60\n",
            "loss 0.008549568243324757 average time 0.05341730808763714 iter num 80\n",
            "loss 0.004014096688479185 average time 0.049018860020260034 iter num 100\n",
            "loss 0.008558440953493118 average time 0.11869518649946258 iter num 20\n",
            "loss 0.015116740018129349 average time 0.07566652184968917 iter num 40\n",
            "loss 0.004041583277285099 average time 0.060875928499687385 iter num 60\n",
            "loss 0.010351607576012611 average time 0.05364782571214164 iter num 80\n",
            "loss 0.0072762067429721355 average time 0.049322249779688715 iter num 100\n",
            "loss 0.020098688080906868 average time 0.11967881219934498 iter num 20\n",
            "loss 0.009915775619447231 average time 0.07564448334960616 iter num 40\n",
            "loss 0.014483850449323654 average time 0.060855897983007404 iter num 60\n",
            "loss 0.010358143597841263 average time 0.05344664959970942 iter num 80\n",
            "loss 0.006282120011746883 average time 0.04906998505979573 iter num 100\n",
            "loss 0.007069391664117575 average time 0.11706889345041419 iter num 20\n",
            "loss 0.013990316540002823 average time 0.07439610417513905 iter num 40\n",
            "loss 0.011121906340122223 average time 0.060049704350300694 iter num 60\n",
            "loss 0.005711081437766552 average time 0.053001044300253854 iter num 80\n",
            "loss 0.018219051882624626 average time 0.04880836910015205 iter num 100\n",
            "loss 0.006460063625127077 average time 0.1177917230001185 iter num 20\n",
            "loss 0.011493918485939503 average time 0.07473993737503407 iter num 40\n",
            "loss 0.013560214079916477 average time 0.060552953450072285 iter num 60\n",
            "loss 0.020524442195892334 average time 0.05330310837498473 iter num 80\n",
            "loss 0.010719879530370235 average time 0.04898847975986428 iter num 100\n",
            "loss 0.011214129626750946 average time 0.11651863374991081 iter num 20\n",
            "loss 0.01036988664418459 average time 0.07403444242490878 iter num 40\n",
            "loss 0.013529377058148384 average time 0.060024153250014936 iter num 60\n",
            "loss 0.010282857343554497 average time 0.053149092362446027 iter num 80\n",
            "loss 0.021842367947101593 average time 0.04886583287985559 iter num 100\n",
            "loss 0.007611318491399288 average time 0.11761770645007345 iter num 20\n",
            "loss 0.013983285054564476 average time 0.07461993872530001 iter num 40\n",
            "loss 0.018480831757187843 average time 0.06029425301700637 iter num 60\n",
            "loss 0.009914068505167961 average time 0.0532548073128055 iter num 80\n",
            "loss 0.012815523892641068 average time 0.04892282309014263 iter num 100\n",
            "loss 0.015112662687897682 average time 0.11744279830036249 iter num 20\n",
            "loss 0.004850062076002359 average time 0.07455711172506199 iter num 40\n",
            "loss 0.005015517584979534 average time 0.06036405814999549 iter num 60\n",
            "loss 0.010906008072197437 average time 0.05326952080004048 iter num 80\n",
            "loss 0.006157785188406706 average time 0.04900200007996318 iter num 100\n",
            "loss 0.014690760523080826 average time 0.11914461664982809 iter num 20\n",
            "loss 0.02129106968641281 average time 0.0756975595249969 iter num 40\n",
            "loss 0.013719276525080204 average time 0.06098840821669001 iter num 60\n",
            "loss 0.026148948818445206 average time 0.05359290992491879 iter num 80\n",
            "loss 0.006019464693963528 average time 0.049267397460098436 iter num 100\n",
            "loss 0.02217155508697033 average time 0.11690942379955231 iter num 20\n",
            "loss 0.012390372343361378 average time 0.0743550548746498 iter num 40\n",
            "loss 0.008198771625757217 average time 0.06004926041641738 iter num 60\n",
            "loss 0.007764708716422319 average time 0.052896610562447675 iter num 80\n",
            "loss 0.00700008450075984 average time 0.04865761781005858 iter num 100\n",
            "loss 0.00842773076146841 average time 0.11892683584974292 iter num 20\n",
            "loss 0.010148107074201107 average time 0.07543933749966528 iter num 40\n",
            "loss 0.014184452593326569 average time 0.06094132708306764 iter num 60\n",
            "loss 0.014812449924647808 average time 0.053598420887192334 iter num 80\n",
            "loss 0.02192401885986328 average time 0.04923316355980205 iter num 100\n",
            "loss 0.014900692738592625 average time 0.11884717575012474 iter num 20\n",
            "loss 0.014345958828926086 average time 0.07505321105036274 iter num 40\n",
            "loss 0.014964712783694267 average time 0.06084729723370401 iter num 60\n",
            "loss 0.01723194494843483 average time 0.05366183591268055 iter num 80\n",
            "loss 0.011821866966784 average time 0.049316922180187246 iter num 100\n",
            "loss 0.014475301839411259 average time 0.11650123124927632 iter num 20\n",
            "loss 0.01984974928200245 average time 0.07399557832441132 iter num 40\n",
            "loss 0.009573484770953655 average time 0.059903919999608965 iter num 60\n",
            "loss 0.006282039452344179 average time 0.05299277903714028 iter num 80\n",
            "loss 0.012973226606845856 average time 0.04877379496967478 iter num 100\n",
            "loss 0.009461181238293648 average time 0.11729485565028881 iter num 20\n",
            "loss 0.007656219881027937 average time 0.07460186164998958 iter num 40\n",
            "loss 0.015554164536297321 average time 0.060318608949880094 iter num 60\n",
            "loss 0.01442145835608244 average time 0.05310688476229188 iter num 80\n",
            "loss 0.017047414556145668 average time 0.04879621858988685 iter num 100\n",
            "loss 0.006778177339583635 average time 0.11737245604963391 iter num 20\n",
            "loss 0.010040071792900562 average time 0.07466332957483246 iter num 40\n",
            "loss 0.01795688085258007 average time 0.06040749454993299 iter num 60\n",
            "loss 0.008013465441763401 average time 0.053323516199907314 iter num 80\n",
            "loss 0.01603350229561329 average time 0.049010948929899316 iter num 100\n",
            "loss 0.01001640222966671 average time 0.11550658539999858 iter num 20\n",
            "loss 0.01128041185438633 average time 0.07359620165007072 iter num 40\n",
            "loss 0.010626054368913174 average time 0.0596205389167153 iter num 60\n",
            "loss 0.00916422251611948 average time 0.05275497518750853 iter num 80\n",
            "loss 0.00304579664953053 average time 0.04862835582000116 iter num 100\n",
            "loss 0.006988872773945332 average time 0.1164190844501718 iter num 20\n",
            "loss 0.013619543053209782 average time 0.07418368472499423 iter num 40\n",
            "loss 0.0079354178160429 average time 0.06002990333351287 iter num 60\n",
            "loss 0.012393767945468426 average time 0.053027094199933344 iter num 80\n",
            "loss 0.007082248106598854 average time 0.048761847929927174 iter num 100\n",
            "loss 0.011182073503732681 average time 0.11932955760003097 iter num 20\n",
            "loss 0.0064461915753781796 average time 0.07565895255002034 iter num 40\n",
            "loss 0.006277801934629679 average time 0.061013804650004506 iter num 60\n",
            "loss 0.007284965366125107 average time 0.05360480195008677 iter num 80\n",
            "loss 0.009896641597151756 average time 0.04928055658012454 iter num 100\n",
            "loss 0.01668756827712059 average time 0.11742054054993786 iter num 20\n",
            "loss 0.013614198192954063 average time 0.07493407347492394 iter num 40\n",
            "loss 0.010556567460298538 average time 0.060553982050138684 iter num 60\n",
            "loss 0.012582004070281982 average time 0.053400914975054545 iter num 80\n",
            "loss 0.011675533838570118 average time 0.04918307411018759 iter num 100\n",
            "loss 0.010502868331968784 average time 0.11766957239942713 iter num 20\n",
            "loss 0.019324885681271553 average time 0.0748081497997191 iter num 40\n",
            "loss 0.004557743202894926 average time 0.06063230414977928 iter num 60\n",
            "loss 0.017072558403015137 average time 0.05335309297483946 iter num 80\n",
            "loss 0.006677755620330572 average time 0.04911440919975576 iter num 100\n",
            "loss 0.018774790689349174 average time 0.11660051134967944 iter num 20\n",
            "loss 0.008835366927087307 average time 0.07419125429951237 iter num 40\n",
            "loss 0.006679747253656387 average time 0.06015526458316647 iter num 60\n",
            "loss 0.012541624717414379 average time 0.05315369333734452 iter num 80\n",
            "loss 0.015036317519843578 average time 0.048862434809852855 iter num 100\n",
            "loss 0.005343832075595856 average time 0.12005150409950147 iter num 20\n",
            "loss 0.018530532717704773 average time 0.07581156292480955 iter num 40\n",
            "loss 0.017293253913521767 average time 0.06100138954977107 iter num 60\n",
            "loss 0.0031200088560581207 average time 0.05371262773737726 iter num 80\n",
            "loss 0.009597002528607845 average time 0.049228086129842266 iter num 100\n",
            "loss 0.00391500536352396 average time 0.11804107270036183 iter num 20\n",
            "loss 0.009909610264003277 average time 0.07488667072539101 iter num 40\n",
            "loss 0.016718789935112 average time 0.060686224900321876 iter num 60\n",
            "loss 0.016946589574217796 average time 0.05367629072538875 iter num 80\n",
            "loss 0.01702057756483555 average time 0.049393315330307816 iter num 100\n",
            "loss 0.015986982733011246 average time 0.11674394354977266 iter num 20\n",
            "loss 0.006610635202378035 average time 0.07445214179979302 iter num 40\n",
            "loss 0.025852227583527565 average time 0.06053436923339177 iter num 60\n",
            "loss 0.008519927971065044 average time 0.05341403610013913 iter num 80\n",
            "loss 0.017890101298689842 average time 0.0491092604401274 iter num 100\n",
            "loss 0.005339214112609625 average time 0.11662319570004911 iter num 20\n",
            "loss 0.01743001863360405 average time 0.07441883692499687 iter num 40\n",
            "loss 0.009377100504934788 average time 0.06018848519997846 iter num 60\n",
            "loss 0.008721371181309223 average time 0.0531039068499922 iter num 80\n",
            "loss 0.018982551991939545 average time 0.04880632598000375 iter num 100\n",
            "loss 0.018901117146015167 average time 0.11739266225031315 iter num 20\n",
            "loss 0.0208066925406456 average time 0.07471979682513848 iter num 40\n",
            "loss 0.018003202974796295 average time 0.060674534250210854 iter num 60\n",
            "loss 0.014502559788525105 average time 0.05342534797523513 iter num 80\n",
            "loss 0.009793916717171669 average time 0.0490404667101393 iter num 100\n",
            "loss 0.011509147472679615 average time 0.11797639080014051 iter num 20\n",
            "loss 0.008284837938845158 average time 0.07511005107526217 iter num 40\n",
            "loss 0.007338179741054773 average time 0.060645167783635164 iter num 60\n",
            "loss 0.013182560913264751 average time 0.05336210318778285 iter num 80\n",
            "loss 0.012008710764348507 average time 0.04906704194017948 iter num 100\n",
            "loss 0.009640641510486603 average time 0.12112151920027828 iter num 20\n",
            "loss 0.007719927467405796 average time 0.07656391900000017 iter num 40\n",
            "loss 0.026745621114969254 average time 0.061608907933441516 iter num 60\n",
            "loss 0.007799387443810701 average time 0.054142109087752036 iter num 80\n",
            "loss 0.014189970679581165 average time 0.049627291220276676 iter num 100\n",
            "loss 0.01596701145172119 average time 0.11683727295003336 iter num 20\n",
            "loss 0.018835177645087242 average time 0.07428265820008165 iter num 40\n",
            "loss 0.01554921641945839 average time 0.060088167733435206 iter num 60\n",
            "loss 0.009487960487604141 average time 0.05307217270005822 iter num 80\n",
            "loss 0.00709264213219285 average time 0.0488947411900881 iter num 100\n",
            "loss 0.008714432828128338 average time 0.11797772649952094 iter num 20\n",
            "loss 0.018333816900849342 average time 0.07472083157490488 iter num 40\n",
            "loss 0.012709244154393673 average time 0.060453962183176675 iter num 60\n",
            "loss 0.028997164219617844 average time 0.05339755961240371 iter num 80\n",
            "loss 0.008273032493889332 average time 0.049068689619889486 iter num 100\n",
            "loss 0.011073417030274868 average time 0.1174011065000741 iter num 20\n",
            "loss 0.005098640453070402 average time 0.074689766499705 iter num 40\n",
            "loss 0.02047409676015377 average time 0.06038632111661476 iter num 60\n",
            "loss 0.009299724362790585 average time 0.0532272217249556 iter num 80\n",
            "loss 0.010646218433976173 average time 0.04888728418991377 iter num 100\n",
            "loss 0.003430619603022933 average time 0.11843677014949208 iter num 20\n",
            "loss 0.01892521046102047 average time 0.07493109297447517 iter num 40\n",
            "loss 0.007856035605072975 average time 0.06056934171635173 iter num 60\n",
            "loss 0.007367320824414492 average time 0.0533345717247812 iter num 80\n",
            "loss 0.015227449126541615 average time 0.048991297779903104 iter num 100\n",
            "loss 0.011683561839163303 average time 0.11765007635003713 iter num 20\n",
            "loss 0.007134934887290001 average time 0.07467641684988849 iter num 40\n",
            "loss 0.011524324305355549 average time 0.06030425710014242 iter num 60\n",
            "loss 0.0041260793805122375 average time 0.05306860255022912 iter num 80\n",
            "loss 0.009434240870177746 average time 0.04882339532014157 iter num 100\n",
            "loss 0.012126918882131577 average time 0.11746665015052712 iter num 20\n",
            "loss 0.016750825569033623 average time 0.07451423772554336 iter num 40\n",
            "loss 0.00992964580655098 average time 0.06038741396696423 iter num 60\n",
            "loss 0.01128234714269638 average time 0.053332120250206574 iter num 80\n",
            "loss 0.013061251491308212 average time 0.04906973040011508 iter num 100\n",
            "loss 0.016471141949295998 average time 0.11843953509924177 iter num 20\n",
            "loss 0.0040982733480632305 average time 0.07489745029970436 iter num 40\n",
            "loss 0.01803194358944893 average time 0.060582378933152846 iter num 60\n",
            "loss 0.025981375947594643 average time 0.05332899586242092 iter num 80\n",
            "loss 0.007438082247972488 average time 0.049173105569971086 iter num 100\n",
            "loss 0.0083992350846529 average time 0.11745634654980677 iter num 20\n",
            "loss 0.007259435020387173 average time 0.07460105339996517 iter num 40\n",
            "loss 0.006485250778496265 average time 0.06041437056665018 iter num 60\n",
            "loss 0.019000856205821037 average time 0.05316136778742475 iter num 80\n",
            "loss 0.013059916906058788 average time 0.048891231539964795 iter num 100\n",
            "loss 0.00898499321192503 average time 0.11720421354966674 iter num 20\n",
            "loss 0.01807153783738613 average time 0.074525554200045 iter num 40\n",
            "loss 0.006823637057095766 average time 0.060369106883263156 iter num 60\n",
            "loss 0.033700812608003616 average time 0.05312695388752218 iter num 80\n",
            "loss 0.017611581832170486 average time 0.04884293294006056 iter num 100\n",
            "loss 0.01017007790505886 average time 0.1176528102496377 iter num 20\n",
            "loss 0.018567949533462524 average time 0.0748074776998692 iter num 40\n",
            "loss 0.022228965535759926 average time 0.060442101333198175 iter num 60\n",
            "loss 0.008546103723347187 average time 0.05339303356245182 iter num 80\n",
            "loss 0.0038911111187189817 average time 0.048992365369922485 iter num 100\n",
            "loss 0.006218085065484047 average time 0.11703997984986927 iter num 20\n",
            "loss 0.011142967268824577 average time 0.07454032919986275 iter num 40\n",
            "loss 0.01904779113829136 average time 0.06019584006656563 iter num 60\n",
            "loss 0.01287668664008379 average time 0.05303858349993788 iter num 80\n",
            "loss 0.014750140719115734 average time 0.04879979628996807 iter num 100\n",
            "loss 0.012548289261758327 average time 0.11825105840071046 iter num 20\n",
            "loss 0.02052365057170391 average time 0.07498591290041076 iter num 40\n",
            "loss 0.009952062740921974 average time 0.060608468216923936 iter num 60\n",
            "loss 0.011207858100533485 average time 0.05328186677515987 iter num 80\n",
            "loss 0.01428859494626522 average time 0.04893623903004482 iter num 100\n",
            "loss 0.014146420173346996 average time 0.11783883214957314 iter num 20\n",
            "loss 0.008630776777863503 average time 0.07478720979943318 iter num 40\n",
            "loss 0.020717309787869453 average time 0.0604128032994898 iter num 60\n",
            "loss 0.007854694500565529 average time 0.05339309167470674 iter num 80\n",
            "loss 0.013030262663960457 average time 0.049077864619830505 iter num 100\n",
            "loss 0.01628400944173336 average time 0.11771199325030465 iter num 20\n",
            "loss 0.012795032933354378 average time 0.07483991784993123 iter num 40\n",
            "loss 0.021766098216176033 average time 0.06050168621665459 iter num 60\n",
            "loss 0.008577839471399784 average time 0.053326805374899776 iter num 80\n",
            "loss 0.006146893836557865 average time 0.04898249821992067 iter num 100\n",
            "loss 0.011297425255179405 average time 0.11735465269939596 iter num 20\n",
            "loss 0.007968701422214508 average time 0.074829925024369 iter num 40\n",
            "loss 0.015191239304840565 average time 0.06043281258280331 iter num 60\n",
            "loss 0.015818824991583824 average time 0.05331916997456574 iter num 80\n",
            "loss 0.006861201021820307 average time 0.04900954142965929 iter num 100\n",
            "loss 0.006081785075366497 average time 0.11750471554933029 iter num 20\n",
            "loss 0.01667916029691696 average time 0.07448344652475498 iter num 40\n",
            "loss 0.01693270355463028 average time 0.06028148908311171 iter num 60\n",
            "loss 0.029464589431881905 average time 0.05313255759979256 iter num 80\n",
            "loss 0.01640499383211136 average time 0.04892106248978962 iter num 100\n",
            "loss 0.012788133695721626 average time 0.11692199784956755 iter num 20\n",
            "loss 0.015194621868431568 average time 0.07408650899942586 iter num 40\n",
            "loss 0.019574860110878944 average time 0.06000735391626222 iter num 60\n",
            "loss 0.023532439023256302 average time 0.05296629943723019 iter num 80\n",
            "loss 0.005942352116107941 average time 0.04872458902962535 iter num 100\n",
            "loss 0.008261483162641525 average time 0.11769939920013713 iter num 20\n",
            "loss 0.017713118344545364 average time 0.07458124485019653 iter num 40\n",
            "loss 0.01471217256039381 average time 0.06033587465008168 iter num 60\n",
            "loss 0.011916722171008587 average time 0.0531975477875676 iter num 80\n",
            "loss 0.013756709173321724 average time 0.04893796085008944 iter num 100\n",
            "loss 0.004732317291200161 average time 0.1172137253000983 iter num 20\n",
            "loss 0.0077903796918690205 average time 0.07451962699997239 iter num 40\n",
            "loss 0.009000646881759167 average time 0.06018640038334221 iter num 60\n",
            "loss 0.022113993763923645 average time 0.053168278087377986 iter num 80\n",
            "loss 0.006070803850889206 average time 0.04901331367993407 iter num 100\n",
            "loss 0.013483424670994282 average time 0.11786634714990214 iter num 20\n",
            "loss 0.012637327425181866 average time 0.07480883250000261 iter num 40\n",
            "loss 0.011289277113974094 average time 0.0603029203000915 iter num 60\n",
            "loss 0.003127708099782467 average time 0.05311961635015905 iter num 80\n",
            "loss 0.03724651038646698 average time 0.0488029564401586 iter num 100\n",
            "loss 0.004622243344783783 average time 0.11679694395061233 iter num 20\n",
            "loss 0.006201020907610655 average time 0.07427598850035792 iter num 40\n",
            "loss 0.0036172049585729837 average time 0.06010298143349549 iter num 60\n",
            "loss 0.015302205458283424 average time 0.052966371075126514 iter num 80\n",
            "loss 0.02050303854048252 average time 0.04860416140010784 iter num 100\n",
            "loss 0.012136620469391346 average time 0.11518517445038015 iter num 20\n",
            "loss 0.01444571278989315 average time 0.07334711227522347 iter num 40\n",
            "loss 0.010433003306388855 average time 0.059314644466940084 iter num 60\n",
            "loss 0.01145672146230936 average time 0.05227626438772859 iter num 80\n",
            "loss 0.009764227084815502 average time 0.04810792387030233 iter num 100\n",
            "loss 0.016987374052405357 average time 0.11575978495002345 iter num 20\n",
            "loss 0.014626211486756802 average time 0.07374254619990098 iter num 40\n",
            "loss 0.01004638709127903 average time 0.05966683344983418 iter num 60\n",
            "loss 0.008224709890782833 average time 0.052707979112301476 iter num 80\n",
            "loss 0.011269156821072102 average time 0.04836250639986247 iter num 100\n",
            "loss 0.01634361408650875 average time 0.11626630569953704 iter num 20\n",
            "loss 0.010097320191562176 average time 0.07385516912490857 iter num 40\n",
            "loss 0.012106363661587238 average time 0.059767415816471235 iter num 60\n",
            "loss 0.005536457523703575 average time 0.05282760341237917 iter num 80\n",
            "loss 0.01017604861408472 average time 0.04859558083997399 iter num 100\n",
            "loss 0.01229833159595728 average time 0.11749504185027035 iter num 20\n",
            "loss 0.0059168580919504166 average time 0.07436947682499521 iter num 40\n",
            "loss 0.02393299527466297 average time 0.06006201404998137 iter num 60\n",
            "loss 0.006122895050793886 average time 0.05291358400022546 iter num 80\n",
            "loss 0.007612932939082384 average time 0.048617662220203785 iter num 100\n",
            "loss 0.008313813246786594 average time 0.11540916954927524 iter num 20\n",
            "loss 0.009414705447852612 average time 0.07334301537439387 iter num 40\n",
            "loss 0.013083511032164097 average time 0.059416999332946335 iter num 60\n",
            "loss 0.014044016599655151 average time 0.05235596666211677 iter num 80\n",
            "loss 0.00747867813333869 average time 0.04820739597958891 iter num 100\n",
            "loss 0.013599591329693794 average time 0.11623424870049348 iter num 20\n",
            "loss 0.008811593987047672 average time 0.0738859686752221 iter num 40\n",
            "loss 0.020550603047013283 average time 0.05980580955019832 iter num 60\n",
            "loss 0.016978077590465546 average time 0.05275127211275503 iter num 80\n",
            "loss 0.013112969696521759 average time 0.04851988546019129 iter num 100\n",
            "loss 0.01272310595959425 average time 0.11800534635021905 iter num 20\n",
            "loss 0.007385151460766792 average time 0.07496792552537954 iter num 40\n",
            "loss 0.02059401571750641 average time 0.06043308110013944 iter num 60\n",
            "loss 0.0029830699786543846 average time 0.0532706626502204 iter num 80\n",
            "loss 0.014179227873682976 average time 0.04897738747014955 iter num 100\n",
            "loss 0.015738900750875473 average time 0.11690541154966923 iter num 20\n",
            "loss 0.005949784070253372 average time 0.07405503602476529 iter num 40\n",
            "loss 0.009018437936902046 average time 0.05980654559971299 iter num 60\n",
            "loss 0.01374003104865551 average time 0.05276651482481611 iter num 80\n",
            "loss 0.010296428576111794 average time 0.04846591819990863 iter num 100\n",
            "loss 0.006951689254492521 average time 0.11644084919989836 iter num 20\n",
            "loss 0.01891901157796383 average time 0.0738629177749317 iter num 40\n",
            "loss 0.019146179780364037 average time 0.05985054753346049 iter num 60\n",
            "loss 0.010562950745224953 average time 0.0527876027626462 iter num 80\n",
            "loss 0.016737379133701324 average time 0.048489376970101146 iter num 100\n",
            "loss 0.011897576041519642 average time 0.11548942065019219 iter num 20\n",
            "loss 0.018326152116060257 average time 0.07354077290001441 iter num 40\n",
            "loss 0.0280554611235857 average time 0.05961825823336161 iter num 60\n",
            "loss 0.0050314986146986485 average time 0.05256224753748029 iter num 80\n",
            "loss 0.010634367354214191 average time 0.04837978560986812 iter num 100\n",
            "loss 0.0155737129971385 average time 0.11568162369985657 iter num 20\n",
            "loss 0.012249886058270931 average time 0.07377119017473888 iter num 40\n",
            "loss 0.011349327862262726 average time 0.059662364066449904 iter num 60\n",
            "loss 0.01199601124972105 average time 0.05268919709992588 iter num 80\n",
            "loss 0.008989873342216015 average time 0.04845852458987793 iter num 100\n",
            "loss 0.008978430181741714 average time 0.1170293937500901 iter num 20\n",
            "loss 0.01658722758293152 average time 0.07426421865011434 iter num 40\n",
            "loss 0.006506870500743389 average time 0.06015948581674214 iter num 60\n",
            "loss 0.006866530980914831 average time 0.053023940375123854 iter num 80\n",
            "loss 0.014613082632422447 average time 0.04884368301005452 iter num 100\n",
            "loss 0.013248085975646973 average time 0.11726789309977903 iter num 20\n",
            "loss 0.008429193869233131 average time 0.07467005902499295 iter num 40\n",
            "loss 0.009596505202353 average time 0.06023494034986167 iter num 60\n",
            "loss 0.014943930320441723 average time 0.05324077261238926 iter num 80\n",
            "loss 0.007069853134453297 average time 0.04902138315996126 iter num 100\n",
            "loss 0.029592642560601234 average time 0.11952898595027364 iter num 20\n",
            "loss 0.028988221660256386 average time 0.07593678017519778 iter num 40\n",
            "loss 0.011476834304630756 average time 0.06152043955001621 iter num 60\n",
            "loss 0.008420330472290516 average time 0.05395028792499943 iter num 80\n",
            "loss 0.02297881804406643 average time 0.04957154495990835 iter num 100\n",
            "loss 0.00920940563082695 average time 0.11597100625021994 iter num 20\n",
            "loss 0.021618397906422615 average time 0.07377838227494067 iter num 40\n",
            "loss 0.0170539952814579 average time 0.05976241796664302 iter num 60\n",
            "loss 0.010685174725949764 average time 0.05271530319992053 iter num 80\n",
            "loss 0.009529422968626022 average time 0.04846558095989167 iter num 100\n",
            "loss 0.010498158633708954 average time 0.11703495539968571 iter num 20\n",
            "loss 0.021725313737988472 average time 0.07450261372468958 iter num 40\n",
            "loss 0.011184506118297577 average time 0.06021552776637691 iter num 60\n",
            "loss 0.011891658417880535 average time 0.053138940537292 iter num 80\n",
            "loss 0.00891757570207119 average time 0.04887667564977164 iter num 100\n",
            "loss 0.01075880415737629 average time 0.11639804784972511 iter num 20\n",
            "loss 0.006996552459895611 average time 0.07430397759990229 iter num 40\n",
            "loss 0.01244827639311552 average time 0.060095831366804 iter num 60\n",
            "loss 0.00950213149189949 average time 0.053005414475092036 iter num 80\n",
            "loss 0.005458158906549215 average time 0.04875305905014102 iter num 100\n",
            "loss 0.01141608040779829 average time 0.11591918265021377 iter num 20\n",
            "loss 0.01569945737719536 average time 0.07385585124984573 iter num 40\n",
            "loss 0.006772988010197878 average time 0.05996450629997222 iter num 60\n",
            "loss 0.010128847323358059 average time 0.05283953113748794 iter num 80\n",
            "loss 0.019268779084086418 average time 0.04854175314001623 iter num 100\n",
            "loss 0.015870077535510063 average time 0.11637308100071095 iter num 20\n",
            "loss 0.014966913498938084 average time 0.07411664532528447 iter num 40\n",
            "loss 0.0032738083973526955 average time 0.06001944230022976 iter num 60\n",
            "loss 0.011729481630027294 average time 0.05293632115008222 iter num 80\n",
            "loss 0.007767534349113703 average time 0.04881147433014121 iter num 100\n",
            "loss 0.017464203760027885 average time 0.11849245870016603 iter num 20\n",
            "loss 0.018497146666049957 average time 0.07543922260001637 iter num 40\n",
            "loss 0.00756289716809988 average time 0.0609466651666177 iter num 60\n",
            "loss 0.005580624099820852 average time 0.05375759862495215 iter num 80\n",
            "loss 0.01709001138806343 average time 0.04933938592999766 iter num 100\n",
            "loss 0.012015553191304207 average time 0.11848995819982519 iter num 20\n",
            "loss 0.01289853360503912 average time 0.07527844632468259 iter num 40\n",
            "loss 0.001409803400747478 average time 0.060681476049830964 iter num 60\n",
            "loss 0.005045147147029638 average time 0.05331836964983268 iter num 80\n",
            "loss 0.012191805988550186 average time 0.049018892809872344 iter num 100\n",
            "loss 0.01479967962950468 average time 0.12013786985007754 iter num 20\n",
            "loss 0.01671583764255047 average time 0.07647568017509912 iter num 40\n",
            "loss 0.011265571229159832 average time 0.06177898324998144 iter num 60\n",
            "loss 0.006176055409014225 average time 0.05426778606251901 iter num 80\n",
            "loss 0.021350596100091934 average time 0.04969362399002421 iter num 100\n",
            "loss 0.009403527714312077 average time 0.1202442110505217 iter num 20\n",
            "loss 0.016293657943606377 average time 0.07591829247521673 iter num 40\n",
            "loss 0.01605495624244213 average time 0.061108656716957435 iter num 60\n",
            "loss 0.015230774879455566 average time 0.05380070958772194 iter num 80\n",
            "loss 0.016938041895627975 average time 0.04943663004007249 iter num 100\n",
            "loss 0.009467714466154575 average time 0.11707826365036453 iter num 20\n",
            "loss 0.00790342129766941 average time 0.07425241547534825 iter num 40\n",
            "loss 0.013515494763851166 average time 0.059936732283555706 iter num 60\n",
            "loss 0.010938786901533604 average time 0.05288928842533096 iter num 80\n",
            "loss 0.03791885823011398 average time 0.04851934701026039 iter num 100\n",
            "loss 0.0037815123796463013 average time 0.11617143644962198 iter num 20\n",
            "loss 0.00559253292158246 average time 0.07378558479967978 iter num 40\n",
            "loss 0.011091921478509903 average time 0.05961668058334908 iter num 60\n",
            "loss 0.0168271753937006 average time 0.052676674600161275 iter num 80\n",
            "loss 0.012041673995554447 average time 0.04842338879017916 iter num 100\n",
            "loss 0.01606389321386814 average time 0.11654626910039952 iter num 20\n",
            "loss 0.008431228809058666 average time 0.07383967167515948 iter num 40\n",
            "loss 0.012923866510391235 average time 0.059693641233570814 iter num 60\n",
            "loss 0.007929869927465916 average time 0.05252534077512792 iter num 80\n",
            "loss 0.016044583171606064 average time 0.048287501710110516 iter num 100\n",
            "loss 0.006266103591769934 average time 0.1154693745498662 iter num 20\n",
            "loss 0.021756622940301895 average time 0.07321675754974422 iter num 40\n",
            "loss 0.005260054022073746 average time 0.05960088213323615 iter num 60\n",
            "loss 0.013426740653812885 average time 0.052435379674625436 iter num 80\n",
            "loss 0.011292376555502415 average time 0.048171895219566066 iter num 100\n",
            "loss 0.01427589263767004 average time 0.1175101597506 iter num 20\n",
            "loss 0.012532603926956654 average time 0.07449914125027135 iter num 40\n",
            "loss 0.014945532195270061 average time 0.0604672597500515 iter num 60\n",
            "loss 0.011108406819403172 average time 0.05318974694991994 iter num 80\n",
            "loss 0.018325380980968475 average time 0.04880678622983396 iter num 100\n",
            "loss 0.004177483264356852 average time 0.11543902079938562 iter num 20\n",
            "loss 0.017585208639502525 average time 0.07363008622469351 iter num 40\n",
            "loss 0.013104121200740337 average time 0.0596073401998486 iter num 60\n",
            "loss 0.02458621747791767 average time 0.05246149968743339 iter num 80\n",
            "loss 0.0054153255186975 average time 0.04824541641988617 iter num 100\n",
            "loss 0.008333245292305946 average time 0.11674346969957697 iter num 20\n",
            "loss 0.021704746410250664 average time 0.07401224837485643 iter num 40\n",
            "loss 0.006795111112296581 average time 0.059771675700176274 iter num 60\n",
            "loss 0.004335436969995499 average time 0.05263564042525104 iter num 80\n",
            "loss 0.003460032632574439 average time 0.04830609649019607 iter num 100\n",
            "loss 0.013410406187176704 average time 0.11535438470018562 iter num 20\n",
            "loss 0.008683607913553715 average time 0.07352300822494726 iter num 40\n",
            "loss 0.006997525226324797 average time 0.059487052000016166 iter num 60\n",
            "loss 0.01028510183095932 average time 0.05237839187493591 iter num 80\n",
            "loss 0.014206843450665474 average time 0.04828746805993433 iter num 100\n",
            "loss 0.012201041914522648 average time 0.11451794890053861 iter num 20\n",
            "loss 0.012364455498754978 average time 0.07290133485039405 iter num 40\n",
            "loss 0.028521211817860603 average time 0.05910376920049506 iter num 60\n",
            "loss 0.012383604422211647 average time 0.05225118382531946 iter num 80\n",
            "loss 0.011744546703994274 average time 0.04817469071051164 iter num 100\n",
            "loss 0.010190684348344803 average time 0.11892484620038886 iter num 20\n",
            "loss 0.02205914631485939 average time 0.07526247979967593 iter num 40\n",
            "loss 0.02888522669672966 average time 0.06078133856669107 iter num 60\n",
            "loss 0.012804156169295311 average time 0.05339381130052061 iter num 80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-abd57be94152>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mmodel_save_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'jax_knock_out_1stock_MC_2_Judy.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-abd57be94152>\u001b[0m in \u001b[0;36mtrain_update\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_order_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompute_deltas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-abd57be94152>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     35\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_order_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompute_deltas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-abd57be94152>\u001b[0m in \u001b[0;36mcompute_deltas\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m       \u001b[0mfirst_order_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_order_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    234\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    235\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         inputs, allow_unused, accumulate_grad=False)\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R54lSSCkd1fm"
      },
      "source": [
        "#8hr 30min"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "outputId": "957c1389-b447-4232-eb85-109c606a802f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 1, 0.8, 1, 0.25, 0.02, 0.02]]).cuda() # T, K, B, S, sigma, mu, r\n",
        "print('price: ' + str(model(inputs.float())))\n",
        "\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient[0][[3]]\n",
        "\n",
        "# price, delta\n",
        "# should be around (0.10632345, 0.5543747)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: tensor([[0.1045]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5995], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lovJwXo3-YEu",
        "outputId": "307fe03b-cde2-4dc3-ca90-3b9b3fcc2fa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Knock out call\n",
        "\n",
        "# now change code such that 'numsteps' does not represent year\n",
        "# make dt = year / numsteps\n",
        "# Add r, and notice that noise must have mean 0, not drift, or else it'll give large option prices\n",
        "# (done)\n",
        "# after making the changes, the values are still correct\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        #dx =  drift + noise[t,:] # no need to multiply by sigma here because noise generated by cov not corr\n",
        "        dx2 = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx2)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T): # down-and-out call\n",
        "    return jnp.mean(jnp.maximum((1 - jnp.any(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2) < B, axis=1).astype(int))* \n",
        "                                (jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2))[:,-1]-K, 0) *\n",
        "                    jnp.exp(-r[0] * T))\n",
        "    # must use '-1' not 'numsteps', or else grad will be 0\n",
        "\n",
        "numstocks = 1\n",
        "numsteps = 50\n",
        "numpaths = 2000000\n",
        "\n",
        "rng = jax.random.PRNGKey(1)\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.02]*numstocks)\n",
        "r = drift # let r = drift to match B-S\n",
        "\n",
        "cov = jnp.identity(numstocks)*0.25*0.25\n",
        "initial_stocks = jnp.array([1.]*numstocks) # must be float\n",
        "\n",
        "T = 1.0\n",
        "K = 1.0\n",
        "B = 0.8 # if B is set to 0, equivalent to European call\n",
        "\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "\n",
        "keys = jax.random.split(key, numpaths)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T)) # here numsteps different from T\n",
        "\n",
        "# delta\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, B, T)) # here numsteps different from T"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10632345\n",
            "[0.5543747]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5p-DEWf49yu",
        "outputId": "9961d137-11b1-456b-c7df-396ddf785bd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def compute_price(S):\n",
        "    inputs = torch.tensor([[1, 1, 0.8, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_prices = []\n",
        "correct_call_prices = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*numstocks) # must be float\n",
        "    model_call_prices.append(compute_price(p).item())\n",
        "    correct_call_prices.append(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T))\n",
        "\n",
        "#plt.plot(prices, model_call_prices, label = \"model_call_prices\")\n",
        "#plt.plot(prices, correct_call_prices, label = \"correct_call_prices\")\n",
        "plt.plot(prices, np.array(model_call_prices)-np.array(correct_call_prices), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwApH0GT9bBK",
        "outputId": "0b5bb618-c7e7-418a-9812-b05d2765c40e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, 0.8, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][3]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*numstocks) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, 1.0, B, T))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"correct_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DeZWsZQxfTnz",
        "outputId": "a07cc9ab-8e5a-4518-80a8-b50a587ec4d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 0.775, 0.8, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][3]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*numstocks) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, 0.775, B, T))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"correct_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd3yUZbr/8c+d3hNSqKFXCSShC4gKqKCgCC52xLa4q+iedVcPHteyunt23fX8XN1VV1wRe6OJimIDEQGV3nsNLb2ROpnr98czxICBTMIkz2Tmer9e88qUJzPXE+Cbm/u5ixERlFJKNX8BdheglFLKMzTQlVLKR2igK6WUj9BAV0opH6GBrpRSPiLIrg9OTEyUTp062fXxSinVLK1ZsyZbRJJqe822QO/UqROrV6+26+OVUqpZMsYcONNr2uWilFI+os5AN8bMMsZkGmM2n+H1m4wxG40xm4wxK4wxaZ4vUymlVF3caaHPBsae5fV9wEUi0hd4EpjpgbqUUkrVU5196CKyzBjT6Syvr6jxcBWQfO5lKaWUqi9P96HfAXzq4fdUSinlBo+NcjHGjMQK9AvOcsw0YBpAhw4dPPXRSiml8FAL3RiTCvwHmCAiOWc6TkRmishAERmYlFTrMEqllFINdM6BbozpAMwDpojIznMvSdWmrLKK11bsZ3dmsd2lKKW8VJ1dLsaYd4CLgURjTAbwGBAMICL/Bh4FEoAXjDEADhEZ2FgF+6u/fbaDWd/tA2BkzyTuHNGFYV0TcP3MlVIKY9cGFwMHDhSdKeqe5buyufmV77luYHvaxoXzxqr9ZBdX0Kt1NHdc0Jmr0tsSGhRod5lKqSZgjFlzpkazBrqXKyipZMw/lhEZGsjH944gPCSQssoqFm44wqzl+9h+rIjEqFD+PLEPY1Ja212uUqqRnS3Qdeq/l3vkw81kF5fzzHXphIdYrfCw4ECuHdieT38zgjfvGELbuDDueWstn20+ZnO1Sik7aaB7sQ/XH2bhhiP8ZnR3UpPjfva6MYYLuify1p1DSE2OZfrba/li63EbKlVKeQMNdC91JL+URxZspl+HOH59cdezHhsdFszs2weT0i6Wu99aw1fbNNSV8kca6F7I6RQemLMBh1N45tp0ggLr/mOKCQvm9dsHc16bGH795lqW7MhsgkqVUt5EA90LzV6xn+925/DI+N50Sox0+/tiw4N54/Yh9GgdxV1vrOGbnVmNWKVSyttooHuZnceL+Otn2xndqyXXD2pf7++PjQjmzTuG0C0pimmvr+bjjUdwOu0ZyaSUaloa6F7kRLmDu99aS0xYEH+9JrXBk4biIkJ4884hdE2KYvrb67jkmW94Y9UBSiocHq5YKeVNNNC9hIgwY94m9mYV89wN/UiKDj2n94uPDOHD6cN59vp0okKDeGTBZob+5Wue+mw7xwrKPFS1Usqb2LanqDrV6ysP8NGGIzwwpifDuiZ65D2DAwOYkN6Oq9LasvpAHq98u4+XvtnDy8v2MrZPayYPbM8F3RIJDNDlA5TyBRroXmDdwTz+9MlWRvdqya8vOvsQxYYwxjCoUzyDOsVzKLeE2Sv2M2dNBh9vPErL6FAm9mvHNQOS6dEq2uOfrZRqOjr132a5JyoY/9y3BAQYPrl3BLERwU3yueWOKr7elsnctYdZuiMTh1Po0y6Ga/onMz617Tl3+SilGoeu5eKlqpzCbbN/ZNWeHOb+ehh9k2NtqSO7uJyPNhxh7toMNh8uJMDA8G6JXJXWljF9WhMT1jS/ZJRSddNA91L/+HIn//hyF/87sS83DvGOHZx2HS9i4YYjfLj+CAdzSwgJCmBUz5ZMSG/LxT1bVq8no5Syhwa6F1q2M4upr/7AxPR2/N+1aV63rrmIsP5QPgs3HOGjDUfJLi4nLDiAC7snMSalNaPPa0lcRIjdZSrldzTQvczuzCImvrCCdnHhzLt7GBEh3n1tusoprNqbw+Itx/h8y3GOFZYRGGA4v0s8Y1JaM7JnS9rHR9hdplJ+QQPdi2QXl3P1899RVulkwT3DSG7RvILQ6RQ2Hi5g8ZZjLN5yjL1ZJwDomBDB8G6JXNAtkaFdEmgRqa13pRqDBrqXKKus4oaXV7HtaCHvTRtKWvufL4nb3OzOLGb5riyW785h1d4cissdGAN92sYyrGsCgzvHM7BjfJON3lHK12mgewGnU7j3nXUs2nyUF28awNg+vre7UGWVk40ZBXy3O5vlu7JZfyifiionxkCv1jEM6RzP4M7WeHgdFqlUw2ige4G/fbadF5bu4X+u6MW0Cz0/ecgblVVWsf5QPj/sy+WHfbmsOZBHaWUVYHXRDOjQgv4dWzCgYwt6tIrWGatKueFsge7dV+N8xPs/HuKFpXu4cUgHfjmii93lNJmw4EDO75LA+V0SAKsFv/lwAT/uz2XtgXyW7cpm3rrDAESFBpHWPpY+7WJJaRtLStsYOidEEqAh7xXKKqvILCwnq7iMrKJysosryC4uJ6fG15JKB3HhIcRFBNMiIoQWEcG0iAyhRUQICVEhJESGkhgVQovIEILdWONf1Z8GeiP7bnc2/zN/EyO6J/LHq1K8bnhiUwoODKBfhxb069ACsIZGZuSVsuZAHmsO5LH2YB6zlu+jssr6X2NkSCDntYkhpW0M/Tu2YEjnBFrHhtl5Cj6lrLKKnBMVZBeVk1188lZR/TWrqIzMonKyCsspKq99pc4WEcEkRIWSEBlCUlQo+aWVHM4vJa+kgoLSSs7UARAXEUx8ZAiJUVbIJ0aFWoEfbQV/kutrYnQokSGBfv3vpj60y6WRXfz3JQQFBjDv7mE649INFQ4nuzKL2HK4kC1HCthypJCtRwspqbC6atrHhzO4UwJDOsczqHM8nRIi/Pofu4hQWllFcbmDknLra35JJXklFeSXVlJQUuF6XEnuiXJyT1SQc6KC3BMV1T/T00WFBpEQZQV0y5hQWkaHkRQdSlJ0KC1dX5OiQutsaVc5hYLSSnJdn5dTXE72iQpyiyvIOfHTL5Ac19eC0spa3yc0KKA6+JOiQ0mMCq2uJ6nG/ZbRYX4x8U27XGySWVTG/pwS/jDuPA1zN4UEBbi6XGIBa4MPR5WTbUeL+H5fDj/sy+Xr7ceZuzYDsFp6fdrGktIuhj5trS6bjvERXt1VU+UUyiqrrJvDSVllFSfKHRSXOyguc3CiwkFxeRXFZQ4KyyopLK2ksMxBQanrfmklReUOSsodlFRWnbEVfFJkSCBxESHER1q3rklR1v2oEOIjXK3kaKuVnRgV6rFQDAww1Z/pjgqHk7ySCrKKyqv/52AF/0//azicX8aGjAJyisupbd+W6LAgWsWE0cr1i6hlTCitosOqn2sVY/1yCgv2zeDXQG9E6w/mA1R3MaiGCQoMoG9yLH2TY7lzRBecTmFPVjE/7M9lU0YBm48UnNJVExUaRNu4MAyGk433k634AGMFjTGGQNf9AGMIDLBuQQE17wdU/2IQEeTkVwERcDgFh9NJlVOorHLiqBIqnYKjyln9uMJ1v7JKqHA4KXdUVdfp1rkHGGLDg4kNDyY6PJiYsCCSW4QTHRZEZEgQEaFBRIYEVn+NCg2iRWQIceHBxEYEExceQkhQ8+ivDgkKcAVv3d1qVU6pDv+sonIyi8rJLCojs7Cc44VlHC8s48f9uWQWllNR5fzZ98dFBJMYFerq9rF+6Zzs44+LCCHG9TOPCQsiJjyYmLDgZvFzrDPQjTGzgPFApoj0qeV1AzwLXAGUALeKyFpPF9ocrTuUT3CgIaVtjN2l+JSAAEP3VtF0bxUNQ6znanbVbD5SQGZhOYIrfF3fZwWx4BShSqyhpFVOoUqssK0S67Gj6qfnq1zNQAMYY/1iOHk/MCCA4EDrl0BQQAAhQQFEBAYQHGAICQogKNB6PSQwgGDXLSw4gLDgQEKDrK9hwQGEBllBHBkaZAV1aBBRrltYcIBfdymdSWCAcXXDhHJemzMfJyLkl1RyvKiM466wzyy07p9s/e88XkxOcTl5JbV3+ZwUHhxITHgQMWHBxIQHEx128v5Pz9V8HBt+8jnrl0JTXAh2p4U+G/gX8PoZXr8c6O66DQFepPqfmX9bdzCP3m1jffa/d96kZlfNtdR/L1blm4wx1kibyBB61TH1w1HlJLekgoKSSgrLKl1dXFa3V0GJ9biozEFRufV87okK9mefoLDMQWFpJY469u4NDw50hXwQ1w/qwO0XdPbgmVrqDHQRWWaM6XSWQyYAr4t1dXWVMSbOGNNGRI56qMZmyeGaZHPtQA0XpZqDoMAAq989uv4jqU5enD75C6Cw9KdfANXXPsqsXwQFpZXEhjfONTVP9KG3Aw7VeJzheu5ngW6MmQZMA+jQwTuWi20sO44XUVJRRb8OzX96v1Lq7IwxRIQEERESZOvQ2ibt5ReRmSIyUEQGJiUlNeVHN7l1rgui/fWCqFKqiXgi0A/DKZ2Wya7n/Nq6g/kkRoWQ3CLc7lKUUn7CE4G+ELjFWM4HCvy9/xxg3aE80tu30BEKSqkm486wxXeAi4FEY0wG8BgQDCAi/wYWYQ1Z3I01bPG2xiq2ucgvqWBv1gmu6Z9sdylKKT/iziiXG+p4XYB7PFaRD1h/6OSEIr0gqpRqOt4/9akZWncwnwADqcka6EqppqNT/xvBukP59GgVTVSo/niV8jtOJ5RkQ+ERKD4ORcdcX49C0XEoPgap18GQuzz+0Zo4HuZ0CusP5jEuta3dpSilPM3ptMK5IAMKM6yvBYeh6AgUHnWF9jFw1rKMQHg8RLeGqFYQGt0o5Wmge9he11Rg7T9XqhlyVlkt6/yDkH/A9fUg5B2AgoNWaJ8e1sGRENMWYtpAx+HW12jX4+g2VoBHtYKgxt84XQPdw9YdzAN0QpFSXqviBOTuhdx9kLffdXPdzz90WmAbK5TjOkDyYIhrDzHtILY9xCZDbDsIiwMvGZ6sge5haw/mExMWRJfESLtLUcp/VVVaAZ29E3J2Q84eK8RzdlvdIjWFt4AWnaBNOvS+Glp0hLiOVojHJkNQ89nQXAPdw9YdzCO9Qwuv3mBBKZ9RXgxZOyB7hxXe2busr7l7wVlj27yIBEjoBl1GQkJX69aisxXk4b7TPaqB7kHF5Q52Hi9iTEod63QqpeqnsgyytkPmNsjaBpmu+wUHfzomIAjiu0JiD+g13vqa2MMKbx8K7bPRQPegjRn5OEUnFCnVYCLWRcjjW6xbputrzh4Q1x6ogSGQ0B3aD4L+t0DLXpDUy2ptB/r3Vo8a6B50coXF9PYa6ErVyemE3D1wdAMcXQ9HN1r3y/J/OqZFJ2jVx+rbbpUCLXtDfBcI1Oiqjf5UPGjdwXy6JEUSF9H4w5OUalZErH7tI+t+uh3dABXF1uuBodCqN6RcDW3SoFVfq+XdSOO1fZUGuoeICOsP5XFRj5Z2l6KU/UpyIeNHOPQDHF5tBXhZgfVaUBi07gvpN1ojS9qkQVJPv+8u8QQNdA/JyCslu7hC+8+V/3E6rQuWh1bBoR8h4wdreCCACXS1vCdC237Qtj+0PE/Du5FooHvIWteEIg105fMc5XBkPRxcAQdXWbeT/d4RidB+MKTfBMmDoF1/CNE5GU1FA91D1h3MJzw4kJ6ttM9P+RhHOWSshv3fwr5vrS4UR5n1WkJ36H0VdBgKHc63xnZ7yaxJf6SB7iHrDuWTmhxLUKCuSKyauSoHHF4D+5ZZIX7oe1eAG2iTCgPvgI5DrRCPTLS7WlWDBroHlFVWsfVIAXdc0MXuUpSqv5MjUPZ8DXuXWkFeXmi91qovDLwdOl0AHYdZ0+SV19JA94DNhwuorBLtP1fNR3kR7P0Gdn9hBXm+a8ZlXAfrAmbXUdBpBEQm2FunqhcNdA9Yc8C6IDqgo7ZelJcSsdY42fU57PoCDqywVhUMiYYuF8Gw+6wQj++ifeDNmAa6B6w9mEfHhAgSo5rPqmzKD1RVWsG9/RPY+elPrfCWvWHo3dD9Mmg/RIcQ+hAN9HMkIqw5kM+F3fXikPIC5UWw+0vYvgh2LbYm8wSFQZeL4YLfQrdLrTW9lU/SQD9H1oSicvppd4uyS2ke7PgUtn5o9YdXVVjbnfUcB73GQdeROhbcT2ign6Pq/nPdoUg1pZJcqytl64fWyBRnpbWLzqA7raVj2w/RBaz8kP6Jn6O1B/OIDAmkZ2udUKQaWXmRFeKbPnCFuMMalXL+r6D3RGtWpl7Q9Gsa6OdozYE80jvEEag7FKnG4Kiw+sQ3fWB1qzhKIbYDDL3HWlK2bT8NcVXNrUA3xowFngUCgf+IyF9Pe70D8BoQ5zpmhogs8nCtXudEuYPtx4q4++KudpeifImItVLh+rdhy3xrnZSIBOh3E/SdbHWnaIirWtQZ6MaYQOB54FIgA/jRGLNQRLbWOOwPwPsi8qIxpjewCOjUCPV6lQ0Z+VQ5hf56QVR5QuER2PCOFeQ5uyE4wrqo2fda68KmDi9UdXCnhT4Y2C0iewGMMe8CE4CagS5AjOt+LHDEk0V6q5M7FPVvr4GuGshRDts+skJ87xIQJ3QYBsP/y9rsQTd4UPXgTqC3Aw7VeJwBDDntmMeBz40x9wKRwCW1vZExZhowDaBDhw71rdXrrDmQR7eWUcRGaMtJ1VP2bljzqhXkpbnWCJURv4e0661NjZVqAE9dFL0BmC0i/2eMGQq8YYzpIyLOmgeJyExgJsDAgQPFQ59tCxFh7cE8xvRubXcpqrlwVMD2j2D1q9YqhgFB0PMKGHArdBkJAbpSpzo37gT6YaDm1LJk13M13QGMBRCRlcaYMCARyPREkd5ob/YJ8ksq6d9RF+RSdSg4DKtfgTWvQUm2NdRw1CPQ72aI1gaB8hx3Av1HoLsxpjNWkF8P3HjaMQeB0cBsY8x5QBiQ5clCvY0uyKXOSsTayef7f1t95OKEnpdba4l3HaWtcdUo6gx0EXEYY6YDi7GGJM4SkS3GmCeA1SKyEPgd8LIx5rdYF0hvFZFm3aVSl3UH84gJC6JLYpTdpShvUlkGm+fA9y/BsY0QFmsthDXoTmjRye7qlI9zqw/dNaZ80WnPPVrj/lZguGdL825rDuTRv2MLAnRCkQJrKv6P/4EfZsKJLEg6D8Y/A6nX6ToqqsnoTNEGKCitZFdmMeNT29pdirJb7l5Y+QKse9OaxdntUhg2HTpfpJN/VJPTQG+A9YfyEdH+c792eA1896zVP24CrZb40HugVW+7K1N+TAO9AdYeyCPAQFp7HeHiV0TgwHew7O/W4lihsTD8NzD4LohpY3d1SmmgN8Tag3n0bB1DVKj++PyCiLVA1rKn4dAqiGwJlz5hbZ6sMzmVF9FEqqcqp7D+YD4T+mn/uc9zOmHHJ1aL/OgGazbnFU9b48eDw+2uTqmf0UCvp12ZRRSVO+ivG1r4LhHYuRiW/NkaehjfFa76l9VPHhRid3VKnZEGej2tPWAtyKUXRH2QiLVA1td/hsOroUVnmPiStWRtQKDd1SlVJw30elpzII+EyBA6xEfYXYrypP3fWS3yA99BTDJc+Ryk36hL1qpmRQO9ntYdtCYUGR1j7BuOb4EvH4ddn0NUK6uPvP8tEBRqd2VK1ZsGej3knqhgb/YJJg9sX/fByrsVZMCS/7WWrw2LgUv+CIOnQYj+z0s1Xxro9bB6fy6g/efNWmk+LH/GWjRLnNZkoBG/g4h4uytT6pxpoNfDyr05hAYFkNY+1u5SVH1VVcKPr8A3f7VCPfU6GPWwtZStUj5CA70eVu7JYVCneEKDdMRDs7LrC1j8P5C909pI4rInoXVfu6tSyuM00N2UU1zO9mNFPDBGJxQ1G1k7YPHDsPsLayz5De9BjzG6aJbyWRroblq11+o/H9Y1weZKVJ1K82DpX+GHlyEkCi77s3XBUycFKR+nge6mFXuyiQoNom877T/3Wk4nbHgbvnjUCvUBt8LIhyEy0e7KlGoSGuhuWrknh8Gd4wkK1K3DvNKxzfDJ76zFs9qfD+Oe1n5y5Xc00N1wrKCMvdknuHGIjojwOmWFVvfK9/+G8DiY8AKk3aB7diq/pIHuhpV7swEYqv3n3kMEtsyHzx6C4uNW98roR3U8ufJrGuhuWLE7h7iIYM5rHWN3KQqg4DB8cj/s/Axap8L1b0HyQLurUsp2GuhuWLEnh/M7J+iG0HZzOmHNLPjicXA6rNErQ34FgfrXWCnQQK/TodwSDueXctdFXewuxb9l7YSP7oODK6HLxTD+HxDf2e6qlPIqGuh1WLHH6j/X8ec2qaq0NmP+5ikIjrAueqbfqJODlKqFBnodVuzJISk6lK5JUXaX4n8yt8H8X8HR9dD7arj8bxDdyu6qlPJaGuhnISKs2JPDsK4Juv55U3JWwYrnrOVtQ6Ph2teh9wS7q1LK67k1WNcYM9YYs8MYs9sYM+MMx1xrjNlqjNlijHnbs2XaY09WMVlF5Qztot0tTSZ7F8waY2060WMM3P29hrlSbqqzhW6MCQSeBy4FMoAfjTELRWRrjWO6Aw8Bw0UkzxjTsrEKbkor9+QAMKyrTh1vdE6nNTnoqz9CUBhc8wr0uUb7ypWqB3e6XAYDu0VkL4Ax5l1gArC1xjG/BJ4XkTwAEcn0dKF2WLEnh3Zx4bSPD7e7FN9WeBTm3wX7voEeY+HKZyG6td1VKdXsuBPo7YBDNR5nAENOO6YHgDHmOyAQeFxEPjv9jYwx04BpAB06ePc0eqdTWLk3h0vPa6X9541px6fw4T1QUWIFef+p2ipXqoE8dVE0COgOXAwkA8uMMX1FJL/mQSIyE5gJMHDgQPHQZzeKbccKyS+pZFg37T9vFJWl1qqIP8y0FtG6ZhYk9bC7KqWaNXcC/TBQc1fkZNdzNWUA34tIJbDPGLMTK+B/9EiVNjjZfz60i/afe1zmNphzO2RuhfPvhkseh6BQu6tSqtlzZ5TLj0B3Y0xnY0wIcD2w8LRjFmC1zjHGJGJ1wez1YJ1NbuWeHLokRtI6NszuUnyHCKyZDTMvhuJMuGkOjP2LhrlSHlJnC11EHMaY6cBirP7xWSKyxRjzBLBaRBa6XrvMGLMVqAIeEJGcxiy8MTmqnHy/L5cJ6brdnMdUnICPfwsb37P29Zz4kk4SUsrD3OpDF5FFwKLTnnu0xn0B7nfdmr1NhwsoLnfocEVPydoJ798CWdvh4ofgwgcgQDfaVsrTdKZoLVa4+s/P76Jra5+zTXNg4X0QHAZT5kHXUXZXpJTP0kCvxRdbj5OWHEtClPbtNpijHBb/D/z4H2g/BH7xKsS2s7sqpXya7tN1mszCMtYfyufS3tq/22CFR+DVy60wHzodbv1Ew1ypJqAt9NN8td2a5Hppb52p2CAHV8F7U6CyRBfVUqqJaaCf5outx2kfH06PVrpcbr2tngWLHoS49jB1IbQ8z+6KlPIrGug1nCh3sHx3NjcP6ajT/evDUQGfPmCNMe92CVzzHwhvYXdVSvkdDfQavt2VRYXDqf3n9VF0zBqSeOh7uOC3MOoRHZKolE000Gv4YmsmseHBDOqkrUu3HFkP79wAZfnWKJY+k+yuSCm/poHu4qhy8vX244zq1ZKgQB38U6ctC6zt4SIT4Y7PrQW2lFK20kB3WXMgj7ySSu1uqYsILHsalvwJkgfD9W9BlE/sZ6JUs6eB7vLF1uOEBAZwYY8ku0vxXpWl8OF02DwHUq+31i8P1sXLlPIWGuhYm0F/se04w7olEBWqP5JaFR2Hd2+Ew6th9GPWBVAdCaSUV9H0AnZnFnMgp4Rfjuhidyne6fgWeOtaKM2F696E8660uyKlVC000IHPtx4H0P7z2uxbBu/eBCGRcPtn0CbN7oqUUmegwzn4aTGuVjHaH3yKjR/AG5Mgph3c+aWGuVJezu8DPbNIF+P6GRFY/g+Yd6e1UuLtn0Fsst1VKaXq4PddLl9tsxbjukQD3eKsgs9mWJs3p0yCif/WLeKUaib8PtBPLsbVs1W03aXYr7IU5t4J2z+GYffCJU9AgN//J06pZsOvA72kQhfjqlZWYE3jP7ACxj4F5//K7oqUUvXk14G+bGe2LsYFUJwFb06CzK3wi1egzzV2V6SUagC/DvTPtx7TxbjyD8EbV0PBYbjhXeh+qd0VKaUayG8DvaTCweLNxxiX2sZ/F+PK2mmFeXkx3LIAOpxvd0VKqXPgt4H++ZbjnKio4pr+fjoc78g6ePMaMIFw2ye6WqJSPsBPm6Ywd20G7ePDGdQp3u5Smt7+72D2lRDsmv2pYa6UT3Ar0I0xY40xO4wxu40xM85y3DXGGDHGDPRciZ53tKCU5buzmdgvmYAAPxvdsmeJ1TKPaQt3LIaErnZXpJTykDoD3RgTCDwPXA70Bm4wxvSu5bho4DfA954u0tMWrDuCCFzTv53dpTStnZ/D29dZIX7rJ1aoK6V8hjst9MHAbhHZKyIVwLvAhFqOexJ4CijzYH0eJyLMXZvBwI4t6JgQaXc5TWf7J9byty17wdSPIErXfVfK17gT6O2AQzUeZ7ieq2aM6Q+0F5FPzvZGxphpxpjVxpjVWVlZ9S7WEzYdLmB3ZjHXDPCji6Fb5lsbObdJg1sWQoQfXjdQyg+c80VRY0wA8P+A39V1rIjMFJGBIjIwKcmeFuLcNRmEBAVwRd82tnx+k9v4Psy5HZIHwZT5EB5nd0VKqUbiTqAfBtrXeJzseu6kaKAPsNQYsx84H1jojRdGKxxOFm44wmW9WxEbHmx3OY1v3Zswbxp0HA43z4WwGLsrUko1IncC/UeguzGmszEmBLgeWHjyRREpEJFEEekkIp2AVcBVIrK6USo+B0t2ZJJXUukf3S3r37b2/+w6Em5839qgQinl0+oMdBFxANOBxcA24H0R2WKMecIYc1VjF+hJc9dkkBQdyohuiXaX0rg2fgAL7oYuF8H1b0NIhN0VKaWagFszRUVkEbDotOcePcOxF597WZ6Xe6KCJTsyuXVYJ9+e6r9lPsyfBp0ugOvfgeBwuytSSjURH062U3204QiVVcIkX57qv+0jmHOHtcvQDe9qy1wpP+M3gT53bQa928RwXhsfvTC441P44DZo1x9u+gBCo+yuSCnVxPwi0HcdL2JjRgGTfHVm6K4vrXHmrftYo/5bWXkAABZiSURBVFlCdfclpfyRXwT63LWHCQwwTEj3wUDf9y28dxMk9bLGmYfF2l2RUsomPh/oFQ4n89dlcFGPJJKifWyz48Nr4J3roUUnmLIAwv14ow6llO8H+qJNRzleWM6U8zvaXYpnZW6zVk2MSLBa5pEJdleklLKZTwe6iPDyt3vpmhTJRT18aDGqvP3wxkQIDIVbPtRVE5VSgI8H+qq9uWw5UsidI7r4zrrnRcfg9QlQWWq1zOM7212RUspL+PQWdK8s30tCZAgT+/nIxdCSXHj9ajiRba2a2Opny9IrpfyYz7bQ92QV8+W2TG4+vyNhwYF2l3PuyovhrV9A7l644R1IHmB3RUopL+OzLfRZy/cREhTAlKE+cDG0qtIaZ35kPVz3JnS+0O6KlFJeyCcDPfdEBXPWZDCpXzsSo5r5UEURWHgv7PkKrvoX9LrC7oqUUl7KJ7tc3lp1gHKHk9sv8IELhl/9ETa8AyMfhv5T7K5GKeXFfC7Qyx1VvLbyABf1SKJHq2Y+Bf77mbD8GRhwG1z4gN3VKKW8nM8F+ofrj5BdXM4vR3Sxu5Rzs2UBfPog9BwH4/4PjI8Mu1RKNRqfCnQR4ZVv99GrdTTDuzXjmZP7v7O2jms/GH7xCgT4wCgdpVSj86lA/3ZXNjuOF3HniC6Y5tqiPb4V3rkBWnS01jTXDSqUUm7yqUD/z/J9JEWHcmVaG7tLaZjCo/DWZCvEb54LEfF2V6SUakZ8JtA3ZRSwbGcWU4d2JDSoGXZRlBfD29dCaR7c9D7EdbC7IqVUM+MT49BFhL9+to34yBCmDutkdzn1V+WAObfB8S1WN0ubNLsrUko1Qz7RQl+2K5vvdudw76huRIcF211O/YjApw/Ars9h3NPQ4zK7K1JKNVPNPtCdTuGvn26nfXw4Nw5pht0UK56D1bNg+H/BwNvtrkYp1Yw1+0BfsP4w244W8vvLeja/vvPN8+CLRyFlEox+zO5qlFLNXLMO9LLKKv7v8530bRfLlanNbJOHg6tg/q+gw1C4+kUIaNZ/FEopL9CsU+SNlQc4nF/KjMt7Na8NLHL2WGPNY5Ph+rchOMzuipRSPsCtQDfGjDXG7DDG7DbGzKjl9fuNMVuNMRuNMV8ZYxp9zdqCkkr+tWQ3F/ZIYni3xMb+OM8pybWGJwLc9IGONVdKeUydgW6MCQSeBy4HegM3GGNO3ypnHTBQRFKBOcDfPF3o6V78Zg+FZZXMGNursT/Kcxzl8N7NkH/QapkndLW7IqWUD3GnhT4Y2C0ie0WkAngXmFDzABFZIiIlroergGTPlnmqI/mlvPrdPiamt6N325jG/CjPEYGF98GB72DCC9BxqN0VKaV8jDuB3g44VONxhuu5M7kD+LS2F4wx04wxq40xq7Oystyv8jTPfLETEbj/sh4Nfo8mt+zvsPFda13z1Ml2V6OU8kEevShqjLkZGAj8vbbXRWSmiAwUkYFJSUkN+owdx4qYuzaDqcM6ktwi4hyqbUIb34clf4a0G3Rdc6VUo3Fn6v9hoH2Nx8mu505hjLkEeBi4SETKPVPez+UUl9OzdQz3jOzWWB/hWQdWwIf3QMcL4MpndV1zpVSjcSfQfwS6G2M6YwX59cCNNQ8wxvQDXgLGikimx6usYVi3RBbdd0HzWB43exe8e6O10NZ1b0BQM9/fVDWpyspKMjIyKCsrs7sUZYOwsDCSk5MJDnZ/OZM6A11EHMaY6cBiIBCYJSJbjDFPAKtFZCFWF0sU8IEraA+KyFUNOQl3NIswLzoGb06CgCAdnqgaJCMjg+joaDp16tQ8/s4rjxERcnJyyMjIoHNn9/dGdmu1RRFZBCw67blHa9y/xO1P9AdlhfDWL+BEDtz6McQ38+3wlC3Kyso0zP2UMYaEhATqO3jEJ5bP9SqOCnh/irXz0I3vQbv+dlekmjENc//VkD97DXRPEoGF98LepTDheeh+qd0VKaX8SLNey8XrfPWEa6z5H6DfzXZXo5TyMxronvLDy7D8/8GA2+DC39tdjVJep1OnTmRnZ5/zMe6aPXs206dPB+Dxxx/n6aefduv79u/fT58+fdw+Zv369SxatOisxzcV7XLxhI3vw6IHoMflcMXTOtZcedwfP9rC1iOFHn3P3m1jeOzKFI++pz9av349q1ev5oorrrC7FG2hn7Mt82H+XdDpAvjFLAjU35HKd+zfv59evXpx66230qNHD2666Sa+/PJLhg8fTvfu3fnhhx/Izc3l6quvJjU1lfPPP5+NGzcCkJOTw2WXXUZKSgp33nknIlL9vm+++SaDBw8mPT2du+66i6qqKrfqef3110lNTSUtLY0pU6YA8NFHHzFkyBD69evHJZdcwvHjx+t9nmvWrCEtLY20tDSef/756uerqqp44IEHGDRoEKmpqbz00kunfF9FRQWPPvoo7733Hunp6bz33nv88MMPDB06lH79+jFs2DB27NgBwJYtW6rPOTU1lV27dtW7zjqJiC23AQMGSLO37RORP8aL/OcykbIiu6tRPmbr1q12lyD79u2TwMBA2bhxo1RVVUn//v3ltttuE6fTKQsWLJAJEybI9OnT5fHHHxcRka+++krS0tJEROTee++VP/7xjyIi8vHHHwsgWVlZsnXrVhk/frxUVFSIiMivf/1ree2110REpGPHjpKVlVVrLZs3b5bu3btXv56TkyMiIrm5ueJ0OkVE5OWXX5b7779fREReffVVueeee0RE5LHHHpO///3vZzzPvn37yjfffCMiIr///e8lJSVFREReeuklefLJJ0VEpKysTAYMGCB79+6Vffv2VR9T83NERAoKCqSyslJERL744guZNGmSiIhMnz5d3nzzTRERKS8vl5KSkrP/8KX2vwNY839qzVVtTjbUri/hg6nQJs2aOBQaZXdFSjWKzp0707dvXwBSUlIYPXo0xhj69u3L/v37OXDgAHPnzgVg1KhR5OTkUFhYyLJly5g3bx4A48aNo0WLFgB89dVXrFmzhkGDBgFQWlpKy5Yt66zj66+/ZvLkySQmWvsfxMdbk/UyMjK47rrrOHr0KBUVFfWaiAOQn59Pfn4+F154IQBTpkzh00+t9QU///xzNm7cyJw5cwAoKChg165d9Ohx5oUBCwoKmDp1Krt27cIYQ2VlJQBDhw7lz3/+MxkZGUyaNInu3bvXq053aJdLQ+xdCu/dBEm94Oa5ENZMlvBVqgFCQ39asiIgIKD6cUBAAA6Ho97vJyJMnTqV9evXs379enbs2MHjjz/e4Pruvfdepk+fzqZNm3jppZc8ulSCiPDPf/6zutZ9+/Zx2WWXnfV7HnnkEUaOHMnmzZv56KOPquu58cYbWbhwIeHh4VxxxRV8/fXXHqvzJA30+jqwwto+Lr4LTFkA4S3srkgpW40YMYK33noLgKVLl5KYmEhMTAwXXnghb7/9NgCffvopeXl5AIwePZo5c+aQmWkt+5Sbm8uBAwfq/JxRo0bxwQcfkJOTU/19YLWI27WzVvR+7bXX6l1/XFwccXFxLF++HKD6XADGjBnDiy++WN3K3rlzJydOnDjl+6OjoykqKqp+XLOe2bNnVz+/d+9eunTpwn333ceECROqrzV4kgZ6fexfDm9Nhph2cMuHEJlgd0VK2e7xxx9nzZo1pKamMmPGjOpQfeyxx1i2bBkpKSnMmzePDh06ANC7d2/+9Kc/cdlll5Gamsqll17K0aNH6/yclJQUHn74YS666CLS0tK4//77qz9/8uTJDBgwoLo7pr5effVV7rnnHtLT00+5eHvnnXfSu3dv+vfvT58+fbjrrrt+9r+SkSNHsnXr1uqLog8++CAPPfQQ/fr1O+XY999/nz59+pCens7mzZu55ZZbGlTr2ZiaxTelgQMHyurVq2357AbZPM8azdKiM9yyAGLa2l2R8nHbtm3jvPPOs7sMZaPa/g4YY9aIyMDajtcWujtWPg9zboN2A+D2zzTMlVJeSUe5nI3TCV88Aiv/BeddBZNehuAwu6tSyqfl5OQwevTonz3/1VdfkZBwbt2c99xzD999990pz/3mN7/htttuO6f39RYa6GfiKIf5v4It82DwXTD2LxAQaHdVSvm8hIQE1q9f3yjvXXPSkC/SQK9NaR68NwX2fwuXPgHD7tPp/Eopr6eBfrp9y2D+r6H4OEz6D6ROtrsipZRyiwb6SZVl8PWTVn95Qje4fTEkD7C7KqWUcpsGOsDRjTBvGmRtg0G/tLpZQiLsrkopperFv4ctOqtg+TPw8igozYWb5sK4pzXMlbJZfn4+L7zwgkffs+aa6Lfeemv1+ix1Wbp0KePHj3f7mKVLl7JixYpzK7aB/LOF7nTCjkXwzVNwbKM1JPHKZyEi3u7KlKrdpzPg2CbPvmfrvnD5Xz37ni4Oh4OgoKAzPq7LyUC/++67G6O8RrV06VKioqIYNmxYk3+2f7XQnU7YsgBeGmEtrlVRDNe8Ate+rmGu1Bmcvgb5/v37GTVqFKmpqYwePZqDBw8CVqv3V7/6FUOGDOHBBx/82eM9e/YwduxYBgwYwIgRI9i+fTsAx48fZ+LEidXrka9YsYIZM2awZ88e0tPTeeCBB85Y21NPPUXfvn1JS0tjxowZALz88ssMGjSItLQ0rrnmGkpKSup9zp999hm9evWif//+1StGApw4cYLbb7+dwYMH069fPz788MNTvm///v38+9//5plnniE9PZ1vv/32jOu1f/PNN6Snp5Oenk6/fv1OWQ+mwc60rm5j35p0PfQqh8imOSL/GiLyWIzIcwNE1r8r4qhsuhqUqidvWA+9tjXIx48fL7NnzxYRkVdeeUUmTJggIiJTp06VcePGicPhqPXxqFGjZOfOnSIismrVKhk5cqSIiFx77bXyzDPPiIiIw+GQ/Pz8U9YbP5NFixbJ0KFD5cSJE9W1iYhkZ2dXH/Pwww/Lc889JyKnrok+depU+eCDD2p939LSUklOTpadO3eK0+mUyZMny7hx40RE5KGHHpI33nhDRETy8vKke/fuUlxcLEuWLKk+5vS118+0Xvv48eNl+fLlIiJSVFRUvYZ6Tboe+klOJxxeA9sWWre8/ZDY02qRp0zUSUJKuaG2NchXrlxZ3WqdMmUKDz74YPXxkydPJjAw8GePi4uLWbFiBZMn/zQMuLy8vPozXn/9dQACAwOJjY2tXpnxbL788ktuu+02IiIiqmsD2Lx5M3/4wx/Iz8+nuLiYMWPG1Ouct2/fTufOnavXK7/55puZOXMmYK2PvnDhwuq++LKysur/oZzJmdZrHz58OPfffz833XQTkyZNIjk5uV511sa3Ar2q0loRcfvHsP0TKDoKAcHQ+UIY/Rj0nqBBrlQjioyMrPWx0+kkLi6u0WaA1nTrrbeyYMEC0tLSmD17NkuXLvXYe4sIc+fOpWfPnqc8f7Zt7+69917uv/9+rrrqKpYuXVq99vuMGTMYN24cixYtYvjw4SxevJhevXqdU31u9aEbY8YaY3YYY3YbY2bU8nqoMeY91+vfG2M6nVNV7igvgkM/wOpZ8MnvYdbl8Lcu8MbVsP5tSB5krb3ywG6YMg/6TNIwV6qealuDfNiwYbz77ruAtXb4iBEj6nyfmJgYOnfuzAcffABYwbhhwwbAWh/9xRdfBKw9PAsKCn62xnhtLr30Ul599dXqPvKT66MXFRXRpk0bKisrT1nb3F29evVi//797NmzB4B33nmn+rUxY8bwz3/+s3qJ3XXr1v3s+8+2PnrN9dr37NlD3759+e///m8GDRpUfU3hXNQZ6MaYQOB54HKgN3CDMab3aYfdAeSJSDfgGeCpc67sTHYuhmfT4C/J8Mql8PFvYcO7IE7oOxmufxse2APXvQGp10J4XKOVopSvq20N8n/+85+8+uqrpKam8sYbb/Dss8+69V5vvfUWr7zyCmlpaaSkpFRfUHz22WdZsmQJffv2ZcCAAWzdupWEhASGDx9Onz59znhRdOzYsVx11VUMHDiQ9PT06m6QJ598kiFDhjB8+PAGtXjDwsKYOXMm48aNo3///qdsj/fII49QWVlJamoqKSkpPPLIIz/7/iuvvJL58+dXXxQ903rt//jHP+jTpw+pqakEBwdz+eWX17vW09W5HroxZijwuIiMcT1+CEBE/lLjmMWuY1YaY4KAY0CSnOXNG7we+uG1sOI5aJUCLVOsr3EddK0V5XN0PXRV3/XQ3elDbwccqvE4AxhypmNExGGMKQASgOzTCpkGTAOqdy+pt3b9YfLshn2vUkr5sCa9KCoiM4GZYLXQm/KzlVLN06ZNm5gyZcopz4WGhvL999+f83tPnDiRffv2nfLcU089Ve+RMd7CnUA/DLSv8TjZ9Vxtx2S4ulxigRyPVKiUHxMRjJ93J/bt27fRRsfMnz+/Ud7XE+rqDq+NO6NcfgS6G2M6G2NCgOuBhacdsxCY6rr/C+Drs/WfK6XqFhYWRk5OToP+YavmTUTIyckhLKx+O6TV2UJ39YlPBxYDgcAsEdlijHkCa8bSQuAV4A1jzG4gFyv0lVLnIDk5mYyMDLKysuwuRdkgLCys3pON6hzl0lgaPMpFKaX82NlGufjX4lxKKeXDNNCVUspHaKArpZSPsK0P3RiTBRyw5cPPTSKnTZjyI/567nre/sXbz7ujiCTV9oJtgd5cGWNWn+mChK/z13PX8/Yvzfm8tctFKaV8hAa6Ukr5CA30+ptpdwE28tdz1/P2L832vLUPXSmlfIS20JVSykdooCullI/QQD8DN/ZR7WCMWWKMWWeM2WiMucKOOj3NjfPuaIz5ynXOS40x575VuRcwxswyxmQaYzaf4XVjjHnO9XPZaIzp39Q1NgY3zruXMWalMabcGPP7pq6vsbhx3je5/pw3GWNWGGPSmrrGhtBAr4Wb+6j+AXhfRPphrS75QtNW6XlunvfTwOsikgo8AfwF3zAbGHuW1y8Hurtu04AXm6CmpjCbs593LnAf1p+7L5nN2c97H3CRiPQFnqSZXCjVQK/dYGC3iOwVkQrgXWDCaccIEOO6HwscacL6Gos7590b+Np1f0ktrzdLIrIMK7zOZALWLzIRkVVAnDGmTdNU13jqOm8RyRSRH4HKpquq8blx3itEJM/1cBXWxj5eTwO9drXto9rutGMeB242xmQAi4B7m6a0RuXOeW8AJrnuTwSijTEJTVCb3dz52SjfdAfwqd1FuEMDveFuAGaLSDJwBdYGH/7w8/w9cJExZh1wEdb2g1X2lqRU4zDGjMQK9P+2uxZ3NOkm0c2IO/uo3oGrD05EVhpjwrAW9clskgobR53nLSJHcLXQjTFRwDUikt9kFdrHnb8TyocYY1KB/wCXi0iz2CPZH1qUDeHOPqoHgdEAxpjzgDCgue8VVud5G2MSa/xP5CFgVhPXaJeFwC2u0S7nAwUictTuolTjMMZ0AOYBU0Rkp931uEtb6LVwcx/V3wEvG2N+i3WB9NbmvjG2m+d9MfAXY4wAy4B7bCvYg4wx72CdW6LrushjQDCAiPwb6zrJFcBuoAS4zZ5KPauu8zbGtAZWYw0AcBpj/gvoLSKFNpXsEW78eT8KJAAvGGMAHM1hBUad+q+UUj5Cu1yUUspHaKArpZSP0EBXSikfoYGulFI+QgNdKaV8hAa6Ukr5CA10pZTyEf8fu+9QhlAPpg8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwZ1fc-afcDx",
        "outputId": "6121a344-3e6c-416b-bece-7a909e780b89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1.225, 0.8, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][3]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*numstocks) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, 1.225, B, T))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"correct_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}