{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "European_Call_jax.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Pui/European_Call_jax_1stock_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1RYKgBifCYw"
      },
      "source": [
        "# Test (Skip this if not trying to test, to make sure that functions are defined correctly in cells below without running this cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWYfON_marpj",
        "outputId": "a26a00ff-9ca6-4261-afed-a527b34cc058"
      },
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T):\n",
        "  return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
        "\n",
        "numstocks = 1\n",
        "numsteps = 50\n",
        "numpaths = 1000000\n",
        "\n",
        "rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.0807]*numstocks)\n",
        "r = drift\n",
        "cov = jnp.identity(numstocks)*0.2597*0.2597\n",
        "initial_stocks = jnp.array([0.7178]*numstocks) # must be float\n",
        "T = 1.0\n",
        "K = 0.2106\n",
        "\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "keys = jax.random.split(key, numpaths)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "#%timeit optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T)\n",
        "\n",
        "# delta test\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "#%timeit goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5237006\n",
            "[1.0002406]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxFUnc_iBVcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a307b26-ad0b-4b18-8dc5-f76ddc05eda8"
      },
      "source": [
        "%%writefile cupy_dataset.py\n",
        "# version 1, 2, 6\n",
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T, keys): # need to pass 'keys'\n",
        "    return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
        "\n",
        "###################################################################################################\n",
        "# these 2 functions must be defined outside class in order to be used in 'optionvalueavg' function\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "###################################################################################################\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len, number_path, batch, seed, stocks):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 50\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = 1.0 # assume T = 1, use float here\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros((self.N_BATCH, 1 + self.N_STOCKS), dtype=cupy.float32) # output: price, delta1, delta2, delta3\n",
        "        X = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "\n",
        "        for op in range(self.N_BATCH):\n",
        "          \n",
        "          rng = jax.random.PRNGKey(self.seed)\n",
        "          rng, key = jax.random.split(rng)\n",
        "\n",
        "          ################################################################################################### generate random input numbers\n",
        "\n",
        "          initial_stocks = jnp.array(np.random.random(self.N_STOCKS) * 1.0)\n",
        "\n",
        "          corr = jnp.diag(jnp.array([1]*self.N_STOCKS)) # assume no correlation between stocks here\n",
        "          sigma = jnp.array(np.random.random(self.N_STOCKS) * 0.3)\n",
        "          cov = (jnp.diag(sigma)).dot(corr).dot(jnp.diag(sigma))\n",
        "\n",
        "          r = jnp.repeat(jnp.array(np.random.random(1) * 0.1), self.N_STOCKS)\n",
        "          drift = r\n",
        "\n",
        "          T = self.T\n",
        "          K = np.random.random(1) * 1.0\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### apply functions to compute price and deltas\n",
        "          \n",
        "          keys = jax.random.split(key, self.N_PATHS)\n",
        "\n",
        "          European_Call_price = optionvalueavg(key, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "          gooptionvalue = jax.grad(optionvalueavg, argnums=1)\n",
        "          Deltas = gooptionvalue(keys, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### store input and output numbers in X and Y\n",
        "\n",
        "          Y[op, 0] = European_Call_price\n",
        "          Y[op, 1:] = cupy.array(Deltas, dtype=cupy.float32) # remember to change this!\n",
        "\n",
        "          # T, K, S, sigma, mu, r\n",
        "          paras = (jnp.repeat(jnp.array(T), self.N_STOCKS), jnp.repeat(jnp.array(K), self.N_STOCKS), initial_stocks, sigma, drift, r)\n",
        "          paras = np.column_stack(paras).reshape(1,-1)[0]\n",
        "          X[op,] = cupy.array(paras)\n",
        "\n",
        "          ###################################################################################################\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "# ds = OptionDataSet(max_len = 2, number_path = 1000000, batch = 2, seed = 15, stocks=1) # for testing purpose, use constant seed. When training, change to random seed\n",
        "# for i in ds:\n",
        "#     print(i)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[1.0000, 0.3615, 0.8488, 0.0537, 0.0054, 0.0054],\n",
            "        [1.0000, 0.3045, 0.2754, 0.1590, 0.0306, 0.0306]], device='cuda:0'), tensor([[0.4893, 1.0000],\n",
            "        [0.0099, 0.3607]], device='cuda:0'))\n",
            "(tensor([[1.0000, 0.2641, 0.1117, 0.0750, 0.0918, 0.0918],\n",
            "        [1.0000, 0.2106, 0.7178, 0.2597, 0.0807, 0.0807]], device='cuda:0'), tensor([[0.0000, 0.0000],\n",
            "        [0.5237, 1.0002]], device='cuda:0'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mgw7IYgtcvx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42285790-a084-4db1-8306-0d6a73826459"
      },
      "source": [
        "%%writefile cupy_dataset.py\n",
        "# version 3, 4, 5, 7\n",
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        #dx =  drift + noise[t,:] # no need to multiply by sigma here because noise generated by cov not corr\n",
        "        dx2 = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx2)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T, keys): # need to pass 'keys'\n",
        "    return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
        "    # must use '-1' not 'numsteps', or else grad will be 0\n",
        "\n",
        "###################################################################################################\n",
        "# these 2 functions must be defined outside class in order to be used in 'optionvalueavg' function\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "###################################################################################################\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len, number_path, batch, seed, stocks):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 50\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = 1.0 # assume T = 1, use float here\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros((self.N_BATCH, 1 + self.N_STOCKS), dtype=cupy.float32) # output: price, delta1, delta2, delta3\n",
        "        X = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "\n",
        "        for op in range(self.N_BATCH):\n",
        "          \n",
        "          rng = jax.random.PRNGKey(self.seed)\n",
        "          rng, key = jax.random.split(rng)\n",
        "\n",
        "          ################################################################################################### generate random input numbers\n",
        "\n",
        "          initial_stocks = jnp.array(np.random.random(self.N_STOCKS) * 200.0)\n",
        "\n",
        "          corr = jnp.diag(jnp.array([1]*self.N_STOCKS)) # assume no correlation between stocks here\n",
        "          sigma = jnp.array(np.random.random(self.N_STOCKS) * 0.4)\n",
        "          cov = (jnp.diag(sigma)).dot(corr).dot(jnp.diag(sigma))\n",
        "\n",
        "          r = jnp.repeat(jnp.array(np.random.random(1) * 0.1), self.N_STOCKS)\n",
        "          drift = r # To match BS, use drift = r\n",
        "\n",
        "          T = self.T\n",
        "          K = np.random.random(1) * 200.0\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### apply functions to compute price and deltas\n",
        "          \n",
        "          keys = jax.random.split(key, self.N_PATHS)\n",
        "\n",
        "          European_Call_price = optionvalueavg(key, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "          gooptionvalue = jax.grad(optionvalueavg, argnums=1)\n",
        "          Deltas = gooptionvalue(keys, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### store input and output numbers in X and Y\n",
        "\n",
        "          Y[op, 0] = European_Call_price\n",
        "          Y[op, 1:] = cupy.array(Deltas, dtype=cupy.float32)\n",
        "\n",
        "          paras = (jnp.repeat(jnp.array(T), self.N_STOCKS), jnp.repeat(jnp.array(K), self.N_STOCKS), initial_stocks, sigma, drift, r)\n",
        "          paras = np.column_stack(paras).reshape(1,-1)[0]\n",
        "          X[op,] = cupy.array(paras)\n",
        "\n",
        "          ###################################################################################################\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "# ds = OptionDataSet(max_len = 2, number_path = 10000, batch = 2, seed = 15, stocks=3) # for testing purpose, use constant seed. When training, change to random seed\n",
        "# for i in ds:\n",
        "#     print(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cupy_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efnASCRJfH_R"
      },
      "source": [
        "# #%%writefile cupy_dataset.py\n",
        "# import cupy\n",
        "# import jax\n",
        "# import jax.numpy as jnp\n",
        "# from jax import random\n",
        "# from jax import jit\n",
        "# import numpy as np\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "#     stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "#     stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "#                             jax.ops.index[0],         # initialization of stock prices\n",
        "#                             initial_stocks)\n",
        "#     noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "#     sigma = jnp.diag(cov) ** 0.5\n",
        "#     dt = T / numsteps\n",
        "#     def time_step(t, val):\n",
        "#         dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "#         val = jax.ops.index_update(val,\n",
        "#                             jax.ops.index[t],\n",
        "#                             val[t-1] * dx)\n",
        "#         return val\n",
        "#     return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "# def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T, keys): # need to pass 'keys'\n",
        "#     return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
        "\n",
        "# ###################################################################################################\n",
        "# # these 2 functions must be defined outside class in order to be used in 'optionvalueavg' function\n",
        "# fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "# batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "# ###################################################################################################\n",
        "\n",
        "# class OptionDataSet(object):\n",
        "    \n",
        "#     def __init__(self, max_len, number_path, batch, stocks):\n",
        "#         self.num = 0\n",
        "#         self.max_length = max_len\n",
        "#         self.N_PATHS = number_path\n",
        "#         self.N_STEPS = 50\n",
        "#         self.N_BATCH = batch\n",
        "#         self.N_STOCKS = stocks\n",
        "#         self.T = 1.0 # assume T = 1, use float here\n",
        "#         # self.seed = seed\n",
        "#         # np.random.seed(seed)\n",
        "        \n",
        "#     def __len__(self):\n",
        "#         return self.max_length\n",
        "        \n",
        "#     def __iter__(self):\n",
        "#         self.num = 0\n",
        "#         return self\n",
        "    \n",
        "#     def __next__(self):\n",
        "#         if self.num >= self.max_length:\n",
        "#             raise StopIteration\n",
        "        \n",
        "#         Y = cupy.zeros((self.N_BATCH, 1 + self.N_STOCKS), dtype=cupy.float32) # output: price, delta1, delta2, delta3\n",
        "#         X = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "\n",
        "#         for op in range(self.N_BATCH):\n",
        "          \n",
        "#           np.random.seed(np.random.randint(10000))\n",
        "#           rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "#           rng, key = jax.random.split(rng)\n",
        "\n",
        "#           ################################################################################################### generate random input numbers\n",
        "\n",
        "#           initial_stocks = jnp.array(np.random.random(self.N_STOCKS) * 1.0)\n",
        "\n",
        "#           corr = jnp.diag(jnp.array([1]*self.N_STOCKS)) # assume no correlation between stocks here\n",
        "#           sigma = jnp.array(np.random.random(self.N_STOCKS) * 0.3)\n",
        "#           cov = (jnp.diag(sigma)).dot(corr).dot(jnp.diag(sigma))\n",
        "\n",
        "#           r = jnp.repeat(jnp.array(np.random.random(1) * 0.1), self.N_STOCKS)\n",
        "#           drift = jnp.array(np.random.random(self.N_STOCKS) * 0.1)\n",
        "\n",
        "#           T = self.T\n",
        "#           K = np.random.random(1) * 1.0\n",
        "\n",
        "#           ###################################################################################################\n",
        "#           ################################################################################################### apply functions to compute price and deltas\n",
        "          \n",
        "#           keys = jax.random.split(key, self.N_PATHS)\n",
        "\n",
        "#           European_Call_price = optionvalueavg(key, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "#           gooptionvalue = jax.grad(optionvalueavg, argnums=1)\n",
        "#           Deltas = gooptionvalue(keys, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "\n",
        "#           ###################################################################################################\n",
        "#           ################################################################################################### store input and output numbers in X and Y\n",
        "\n",
        "#           Y[op, 0] = European_Call_price\n",
        "#           Y[op, 1:4] = cupy.array(Deltas, dtype=cupy.float32)\n",
        "\n",
        "#           # T, K, S, sigma, mu, r\n",
        "#           paras = (jnp.repeat(jnp.array(T), self.N_STOCKS), jnp.repeat(jnp.array(K), self.N_STOCKS), initial_stocks, sigma, drift, r)\n",
        "#           paras = np.column_stack(paras).reshape(1,-1)[0]\n",
        "#           X[op,] = cupy.array(paras)\n",
        "\n",
        "#           ###################################################################################################\n",
        "\n",
        "#         self.num += 1\n",
        "#         return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "# ds = OptionDataSet(max_len = 2, number_path = 10000, batch = 2, stocks=3) # When training, change to random seed\n",
        "# for i in ds:\n",
        "#     print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6JO9OBHdvv",
        "outputId": "21ae263f-0408-4d93-f44f-a20c9fd663cf"
      },
      "source": [
        "%%writefile model.py\n",
        "# version 1,2\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*1, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 1) # 1 outputs: price\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1.0, 1.0, 1.0, 0.3, 0.1, 0.1]*1)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O0MfhTadgkO"
      },
      "source": [
        "%%writefile model.py\n",
        "# version 3,7\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*1, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 1) # 1 outputs: price\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1, 200.0, 200.0, 0.4, 0.1, 0.1]*1)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y6naGih16DQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86182e12-aca8-4eac-a404-ff7c18c1a833"
      },
      "source": [
        "# version 4, 5\n",
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*1, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 2) # 2 outputs: price, delta\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1, 200.0, 200.0, 0.4, 0.1, 0.1]*1)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyUoWsGTDQmN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d83b21d1-7492-4227-f35f-a4675618e19d"
      },
      "source": [
        "# version 6\n",
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*1, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 2) # 2 outputs: price, delta\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1.0, 1.0, 1.0, 0.3, 0.1, 0.1]*1)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlXD80xPNVc6",
        "outputId": "b2695060-13fe-44ad-c540-19f2a460976f"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 14.0 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TBEzHyv7n-z7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "161df860-1d5e-4d96-b628-381df36cff8e"
      },
      "source": [
        "# version 1 & version 3 (200)\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 1024, batch = 32, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y = y[:,0].reshape(-1,1)\n",
        "    #print(y)\n",
        "    y_pred = model(x)\n",
        "    #print(y_pred)\n",
        "    loss = loss_fn(y_pred[:,:], y[:,:]) # compute MSE between the 2 arrays\n",
        "    #print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 97.98233032226562 average time 0.050657296949999875 iter num 20\n",
            "loss 11.477714538574219 average time 0.02677511827500183 iter num 40\n",
            "loss 8.203895568847656 average time 0.018795166516666958 iter num 60\n",
            "loss 11.508925437927246 average time 0.01489475403749978 iter num 80\n",
            "loss 7.16341495513916 average time 0.012507266819999358 iter num 100\n",
            "loss 4.0047831535339355 average time 0.051545926849996704 iter num 20\n",
            "loss 9.011444091796875 average time 0.027256455625000342 iter num 40\n",
            "loss 20.87165069580078 average time 0.019207970266668893 iter num 60\n",
            "loss 4.224143981933594 average time 0.015154346012502628 iter num 80\n",
            "loss 4.319762706756592 average time 0.012694993320003505 iter num 100\n",
            "loss 19.631484985351562 average time 0.050563782799997625 iter num 20\n",
            "loss 12.390233039855957 average time 0.026728059974998074 iter num 40\n",
            "loss 6.4824748039245605 average time 0.018758720949999013 iter num 60\n",
            "loss 6.20057487487793 average time 0.014814617624999471 iter num 80\n",
            "loss 3.8055574893951416 average time 0.012455869269999198 iter num 100\n",
            "loss 10.725442886352539 average time 0.05117974394999578 iter num 20\n",
            "loss 3.785740375518799 average time 0.027069602675000227 iter num 40\n",
            "loss 10.17991828918457 average time 0.019067173366665694 iter num 60\n",
            "loss 4.480552673339844 average time 0.01504432173749919 iter num 80\n",
            "loss 6.942492485046387 average time 0.012640377999999827 iter num 100\n",
            "loss 10.839167594909668 average time 0.05103096870001309 iter num 20\n",
            "loss 20.332321166992188 average time 0.027013666424997494 iter num 40\n",
            "loss 5.277866840362549 average time 0.01900968476666852 iter num 60\n",
            "loss 5.684945106506348 average time 0.015029089987505984 iter num 80\n",
            "loss 4.054086685180664 average time 0.012596001840007602 iter num 100\n",
            "loss 6.857364654541016 average time 0.05231760040000495 iter num 20\n",
            "loss 16.446823120117188 average time 0.027676063400002705 iter num 40\n",
            "loss 5.351090431213379 average time 0.01945962901667144 iter num 60\n",
            "loss 6.941106796264648 average time 0.015319993325002201 iter num 80\n",
            "loss 7.1575188636779785 average time 0.01282054260000109 iter num 100\n",
            "loss 11.719528198242188 average time 0.05116890835000163 iter num 20\n",
            "loss 5.97934627532959 average time 0.027131269924998945 iter num 40\n",
            "loss 6.7073163986206055 average time 0.01907019789999822 iter num 60\n",
            "loss 2.6867804527282715 average time 0.015009149575003277 iter num 80\n",
            "loss 6.023691177368164 average time 0.012587140930000941 iter num 100\n",
            "loss 8.39059829711914 average time 0.05122112089999291 iter num 20\n",
            "loss 12.305534362792969 average time 0.027036945199998285 iter num 40\n",
            "loss 7.635445594787598 average time 0.018980293999991696 iter num 60\n",
            "loss 12.966785430908203 average time 0.014985076799993636 iter num 80\n",
            "loss 5.780541896820068 average time 0.012554350019991034 iter num 100\n",
            "loss 22.296480178833008 average time 0.05021250179999583 iter num 20\n",
            "loss 5.565572261810303 average time 0.026579766950001728 iter num 40\n",
            "loss 11.971918106079102 average time 0.018735242599999917 iter num 60\n",
            "loss 5.446610450744629 average time 0.014808573275001891 iter num 80\n",
            "loss 8.64036750793457 average time 0.012428975820002961 iter num 100\n",
            "loss 10.417617797851562 average time 0.050905544900007274 iter num 20\n",
            "loss 6.307798862457275 average time 0.027017290175015772 iter num 40\n",
            "loss 8.114041328430176 average time 0.018976068866677073 iter num 60\n",
            "loss 6.265964031219482 average time 0.014963100974999578 iter num 80\n",
            "loss 7.020261764526367 average time 0.012550278220002155 iter num 100\n",
            "loss 8.861515045166016 average time 0.049824580900053664 iter num 20\n",
            "loss 13.694374084472656 average time 0.026393059700018283 iter num 40\n",
            "loss 7.577152252197266 average time 0.018543607166683764 iter num 60\n",
            "loss 10.899492263793945 average time 0.01464664436250871 iter num 80\n",
            "loss 7.806272506713867 average time 0.012336425310015784 iter num 100\n",
            "loss 17.77452850341797 average time 0.05124352555002361 iter num 20\n",
            "loss 10.478300094604492 average time 0.02702788417500983 iter num 40\n",
            "loss 4.763665199279785 average time 0.018987085866676048 iter num 60\n",
            "loss 7.722769737243652 average time 0.014955170000004615 iter num 80\n",
            "loss 4.01033878326416 average time 0.012545627440001681 iter num 100\n",
            "loss 7.519257068634033 average time 0.051957283399985954 iter num 20\n",
            "loss 4.547915935516357 average time 0.0274074660999986 iter num 40\n",
            "loss 15.949867248535156 average time 0.019221829700002975 iter num 60\n",
            "loss 4.210787773132324 average time 0.015129147174999958 iter num 80\n",
            "loss 6.274507522583008 average time 0.01270035127000483 iter num 100\n",
            "loss 16.67010498046875 average time 0.05185665484999617 iter num 20\n",
            "loss 11.412662506103516 average time 0.027341346399992972 iter num 40\n",
            "loss 12.271627426147461 average time 0.019160267566663454 iter num 60\n",
            "loss 5.612636566162109 average time 0.015068231837497592 iter num 80\n",
            "loss 4.083418846130371 average time 0.012631729209999776 iter num 100\n",
            "loss 9.990506172180176 average time 0.05008768514999247 iter num 20\n",
            "loss 3.7307281494140625 average time 0.026472817649988656 iter num 40\n",
            "loss 4.064517974853516 average time 0.018677550816668522 iter num 60\n",
            "loss 2.3944530487060547 average time 0.014703115712501358 iter num 80\n",
            "loss 9.534856796264648 average time 0.012329902169999513 iter num 100\n",
            "loss 9.926819801330566 average time 0.04962320230004025 iter num 20\n",
            "loss 6.023867607116699 average time 0.026250481825013595 iter num 40\n",
            "loss 10.41681957244873 average time 0.0184847669499959 iter num 60\n",
            "loss 3.256273031234741 average time 0.014588801899992631 iter num 80\n",
            "loss 3.878518581390381 average time 0.012250242989996423 iter num 100\n",
            "loss 9.410879135131836 average time 0.04940481105001027 iter num 20\n",
            "loss 9.431563377380371 average time 0.026125075624997864 iter num 40\n",
            "loss 8.3324613571167 average time 0.018370055549996777 iter num 60\n",
            "loss 8.833610534667969 average time 0.014475961424992079 iter num 80\n",
            "loss 7.69001579284668 average time 0.012144563859990284 iter num 100\n",
            "loss 4.06801700592041 average time 0.0513807917500003 iter num 20\n",
            "loss 3.8634653091430664 average time 0.027109881124988532 iter num 40\n",
            "loss 9.561239242553711 average time 0.01899846204998236 iter num 60\n",
            "loss 5.790534496307373 average time 0.014955841112484335 iter num 80\n",
            "loss 5.411554336547852 average time 0.012528833419980855 iter num 100\n",
            "loss 7.576601982116699 average time 0.05030995809999013 iter num 20\n",
            "loss 15.13175106048584 average time 0.026531254224994427 iter num 40\n",
            "loss 11.637308120727539 average time 0.018623031399996156 iter num 60\n",
            "loss 2.984022617340088 average time 0.014670046025000261 iter num 80\n",
            "loss 2.6920247077941895 average time 0.012307698410002104 iter num 100\n",
            "loss 9.738192558288574 average time 0.05025450405001948 iter num 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-573ac0428235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m           \u001b[0mEuropean_Call_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptionvalueavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m           \u001b[0mgooptionvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptionvalueavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m           \u001b[0mDeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgooptionvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m           \u001b[0;31m###################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mgrad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mapi_boundary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgrad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_and_grad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mvalue_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0m_check_input_dtype_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholomorphic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_py\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdyn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       ans, vjp_py, aux = _vjp(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, reduce_axes, *primals)\u001b[0m\n\u001b[1;32m   2144\u001b[0m     \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun_nokwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m     out_primal, out_vjp = ad.vjp(\n\u001b[0;32m-> 2146\u001b[0;31m         flat_fun, primals_flat, reduce_axes=reduce_axes)\n\u001b[0m\u001b[1;32m   2147\u001b[0m     \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux, reduce_axes)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m   \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tangents_pvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_primal_pval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout_primal_pval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    506\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJaxprTrace\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m     \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36moptionvalueavg\u001b[0;34m(key, initial_stocks, numsteps, drift, r, cov, K, T, keys)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moptionvalueavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m# must use '-1' not 'numsteps', or else grad will be 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    540\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__rshift__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__rrshift__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rrshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices)\u001b[0m\n\u001b[1;32m   5653\u001b[0m   \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_index_for_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5654\u001b[0m   return _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[0;32m-> 5655\u001b[0;31m                  unique_indices)\n\u001b[0m\u001b[1;32m   5656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5657\u001b[0m \u001b[0;31m# TODO(phawkins): re-enable jit after fixing excessive recompilation for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices)\u001b[0m\n\u001b[1;32m   5661\u001b[0m             unique_indices):\n\u001b[1;32m   5662\u001b[0m   \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_merge_static_and_dynamic_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5663\u001b[0;31m   \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_index_to_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shared with _scatter_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5664\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_index_to_gather\u001b[0;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[1;32m   5852\u001b[0m         \u001b[0;31m# XLA gives error when indexing into an axis of size 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5853\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"index is out of bounds for axis {x_axis} with size 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5854\u001b[0;31m       \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnormalize_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5855\u001b[0m       \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_element_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5856\u001b[0m       \u001b[0mgather_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgather_indices_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_normalize_index\u001b[0;34m(index, axis_size)\u001b[0m\n\u001b[1;32m   5436\u001b[0m   return lax.select(\n\u001b[1;32m   5437\u001b[0m     \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_constant_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5438\u001b[0;31m     \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_size_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5439\u001b[0m     index)\n\u001b[1;32m   5440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m   \u001b[0;34mr\"\"\"Elementwise addition: :math:`x + y`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0madd_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         args, used_axis_names(self, params) if self._dispatch_on_params else None)\n\u001b[1;32m    266\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    274\u001b[0m   \u001b[0;34m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m   \u001b[0mcompiled_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxla_primitive_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0munsafe_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled_primitive\u001b[0;34m(prim, compiled, result_handler, *args)\u001b[0m\n\u001b[1;32m    390\u001b[0m   \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m   \u001b[0minput_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_put\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m   \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S3CyULkENYKb",
        "outputId": "33bea7b8-825b-4ef1-bbcf-28aee3909679"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 1024*50, batch = 32, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 0]).cuda()  # let delta weight = 0 for testing\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter) # print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 212.32452243566513 average time 0.4652119456500031 iter num 20\n",
            "loss 212.90656179189682 average time 0.24770194387499772 iter num 40\n",
            "loss 146.02456241846085 average time 0.17523741759999326 iter num 60\n",
            "loss 77.29139644652605 average time 0.13914908989999192 iter num 80\n",
            "loss 99.36856105923653 average time 0.11742550196999105 iter num 100\n",
            "loss 93.63853372633457 average time 0.08994308885000919 iter num 20\n",
            "loss 108.13642293214798 average time 0.06058643320001238 iter num 40\n",
            "loss 102.46463119983673 average time 0.05075252360000301 iter num 60\n",
            "loss 71.6340309008956 average time 0.045679942074994526 iter num 80\n",
            "loss 89.89550173282623 average time 0.04263956789999383 iter num 100\n",
            "loss 31.01498819887638 average time 0.08954092625000384 iter num 20\n",
            "loss 6.292710895650089 average time 0.06035732845000439 iter num 40\n",
            "loss 4.647670139092952 average time 0.05019705663332843 iter num 60\n",
            "loss 3.7061251350678504 average time 0.0454991147999948 iter num 80\n",
            "loss 2.8255413053557277 average time 0.04267173277999973 iter num 100\n",
            "loss 9.797646198421717 average time 0.09041051845001676 iter num 20\n",
            "loss 7.7153637539595366 average time 0.060317323300006366 iter num 40\n",
            "loss 4.79612936032936 average time 0.05033211445000537 iter num 60\n",
            "loss 2.9213979723863304 average time 0.045509098787508154 iter num 80\n",
            "loss 2.841456444002688 average time 0.0425067030900027 iter num 100\n",
            "loss 15.144573990255594 average time 0.09135833194997076 iter num 20\n",
            "loss 11.470748577266932 average time 0.0608753163999836 iter num 40\n",
            "loss 2.636192657519132 average time 0.05104040798331653 iter num 60\n",
            "loss 3.0222328496165574 average time 0.0458990422499852 iter num 80\n",
            "loss 2.6986855664290488 average time 0.04277877466998234 iter num 100\n",
            "loss 3.540918987710029 average time 0.09075497585002949 iter num 20\n",
            "loss 2.749415871221572 average time 0.060378966425003 iter num 40\n",
            "loss 3.341941046528518 average time 0.0506711252666643 iter num 60\n",
            "loss 1.815158611861989 average time 0.04554694186250004 iter num 80\n",
            "loss 2.883769921027124 average time 0.04272407161999354 iter num 100\n",
            "loss 6.8851851392537355 average time 0.09007364819999567 iter num 20\n",
            "loss 3.7173708551563323 average time 0.0605485581000039 iter num 40\n",
            "loss 2.31350350077264 average time 0.05103735343333256 iter num 60\n",
            "loss 1.7691135872155428 average time 0.04595687004999718 iter num 80\n",
            "loss 3.009638166986406 average time 0.04275712356000213 iter num 100\n",
            "loss 2.9565984732471406 average time 0.0894200394999757 iter num 20\n",
            "loss 2.2199215891305357 average time 0.06018903174997945 iter num 40\n",
            "loss 2.6570286718197167 average time 0.05094280143331389 iter num 60\n",
            "loss 1.8788519082590938 average time 0.04586865324998257 iter num 80\n",
            "loss 2.4132104590535164 average time 0.04276707696998756 iter num 100\n",
            "loss 6.156504969112575 average time 0.08889508810001416 iter num 20\n",
            "loss 1.6737014811951667 average time 0.05990730517501106 iter num 40\n",
            "loss 1.3324733299668878 average time 0.05013665246668021 iter num 60\n",
            "loss 2.8666621074080467 average time 0.045490055625020884 iter num 80\n",
            "loss 1.2818482355214655 average time 0.04235124541002278 iter num 100\n",
            "loss 7.620368269272149 average time 0.09086618395001551 iter num 20\n",
            "loss 2.972822403535247 average time 0.06044063110000479 iter num 40\n",
            "loss 1.7754090367816389 average time 0.05052568568332845 iter num 60\n",
            "loss 2.0370380661915988 average time 0.04547538439999812 iter num 80\n",
            "loss 1.7383277008775622 average time 0.04259329012998478 iter num 100\n",
            "loss 2.6593415532261133 average time 0.08934749044997262 iter num 20\n",
            "loss 1.933672174345702 average time 0.05989611374998276 iter num 40\n",
            "loss 1.4682741311844438 average time 0.04980075743332388 iter num 60\n",
            "loss 2.2815639385953546 average time 0.04484252797499266 iter num 80\n",
            "loss 1.4752024435438216 average time 0.04174115181998786 iter num 100\n",
            "loss 3.8886460242792964 average time 0.08869733264996285 iter num 20\n",
            "loss 3.8769893581047654 average time 0.059219793574982305 iter num 40\n",
            "loss 2.419337979517877 average time 0.04949859669998962 iter num 60\n",
            "loss 1.5953078400343657 average time 0.04480777074998628 iter num 80\n",
            "loss 1.5408717445097864 average time 0.04189849650999349 iter num 100\n",
            "loss 2.3047658032737672 average time 0.08888203789997533 iter num 20\n",
            "loss 1.3434587162919343 average time 0.05959999337501358 iter num 40\n",
            "loss 4.0098774479702115 average time 0.04975855608333859 iter num 60\n",
            "loss 2.563577436376363 average time 0.04494800477500007 iter num 80\n",
            "loss 1.375385036226362 average time 0.04190908341997783 iter num 100\n",
            "loss 5.620534066110849 average time 0.0883843725500583 iter num 20\n",
            "loss 2.4407010641880333 average time 0.05938339625002982 iter num 40\n",
            "loss 1.256493414985016 average time 0.049774042633346956 iter num 60\n",
            "loss 1.5588583482895046 average time 0.04471162783749492 iter num 80\n",
            "loss 1.1003630061168224 average time 0.041762425680003615 iter num 100\n",
            "loss 3.739722305908799 average time 0.08856416004994117 iter num 20\n",
            "loss 2.6547585730440915 average time 0.05966431944997339 iter num 40\n",
            "loss 1.653005601838231 average time 0.04965931083332483 iter num 60\n",
            "loss 1.4377835032064468 average time 0.044905340487480315 iter num 80\n",
            "loss 2.1254585590213537 average time 0.04198282479998852 iter num 100\n",
            "loss 3.9462014683522284 average time 0.08854501939993042 iter num 20\n",
            "loss 2.8792559169232845 average time 0.059138355624963876 iter num 40\n",
            "loss 3.015350957866758 average time 0.04930991304995587 iter num 60\n",
            "loss 1.8489730427972972 average time 0.044765475612462066 iter num 80\n",
            "loss 1.674325903877616 average time 0.041841384669969554 iter num 100\n",
            "loss 1.8608350364957005 average time 0.08888889749987357 iter num 20\n",
            "loss 2.7190643595531583 average time 0.05937611944991659 iter num 40\n",
            "loss 1.2084533227607608 average time 0.049443234216596466 iter num 60\n",
            "loss 1.995461352635175 average time 0.04445841139993263 iter num 80\n",
            "loss 0.7160934910643846 average time 0.041687067249959 iter num 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-4-b709b78c9cae>\", line 62, in <module>\n",
            "    trainer.run(dataset, max_epochs = 100)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 698, in run\n",
            "    return self._internal_run()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 771, in _internal_run\n",
            "    self._handle_exception(e)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 466, in _handle_exception\n",
            "    raise e\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 741, in _internal_run\n",
            "    time_taken = self._run_once_on_dataset()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\", line 798, in _run_once_on_dataset\n",
            "    self.state.batch = next(self._dataloader_iter)\n",
            "  File \"/content/cupy_dataset.py\", line 87, in __next__\n",
            "    Deltas = gooptionvalue(keys, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
            "    return fun(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 803, in grad_f\n",
            "    _, g = value_and_grad_f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
            "    return fun(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 877, in value_and_grad_f\n",
            "    ans, vjp_py = _vjp(f_partial, *dyn_args, reduce_axes=reduce_axes)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 2146, in _vjp\n",
            "    flat_fun, primals_flat, reduce_axes=reduce_axes)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\", line 116, in vjp\n",
            "    out_primals, pvals, jaxpr, consts = linearize(traceable, *primals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\", line 103, in linearize\n",
            "    jaxpr, out_pvals, consts = pe.trace_to_jaxpr(jvpfun_flat, in_pvals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\", line 508, in trace_to_jaxpr\n",
            "    jaxpr, (out_pvals, consts, env) = fun.call_wrapped(pvals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\", line 166, in call_wrapped\n",
            "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
            "  File \"/content/cupy_dataset.py\", line 26, in optionvalueavg\n",
            "    return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
            "    return fun(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 1292, in batched_fun\n",
            "    ).call_wrapped(*args_flat)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\", line 166, in call_wrapped\n",
            "    ans = self.f(*args, **dict(self.params, **kwargs))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\", line 162, in reraise_with_filtered_traceback\n",
            "    return fun(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\", line 414, in cache_miss\n",
            "    donated_invars=donated_invars, inline=inline)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1618, in bind\n",
            "    return call_bind(self, fun, *args, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1609, in call_bind\n",
            "    outs = primitive.process(top_trace, fun, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1621, in process\n",
            "    return trace.process_call(self, fun, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/batching.py\", line 177, in process_call\n",
            "    vals_out = call_primitive.bind(f, *vals, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1618, in bind\n",
            "    return call_bind(self, fun, *args, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1609, in call_bind\n",
            "    outs = primitive.process(top_trace, fun, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1621, in process\n",
            "    return trace.process_call(self, fun, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\", line 319, in process_call\n",
            "    result = call_primitive.bind(f_jvp, *primals, *nonzero_tangents, **new_params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1618, in bind\n",
            "    return call_bind(self, fun, *args, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1609, in call_bind\n",
            "    outs = primitive.process(top_trace, fun, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1621, in process\n",
            "    return trace.process_call(self, fun, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\", line 198, in process_call\n",
            "    f, in_pvals, app, instantiate=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\", line 306, in partial_eval\n",
            "    out_flat, (out_avals, jaxpr, env) = app(f, *in_consts), aux()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1618, in bind\n",
            "    return call_bind(self, fun, *args, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1609, in call_bind\n",
            "    outs = primitive.process(top_trace, fun, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 1621, in process\n",
            "    return trace.process_call(self, fun, tracers, params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/core.py\", line 615, in process_call\n",
            "    return primitive.impl(f, *tracers, **params)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\", line 625, in _xla_call_impl\n",
            "    out = compiled_fun(*args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\", line 960, in _execute_compiled\n",
            "    out_bufs = compiled.execute(input_bufs)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 742, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 395, in realpath\n",
            "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 429, in _joinrealpath\n",
            "    if not islink(newpath):\n",
            "  File \"/usr/lib/python3.7/posixpath.py\", line 171, in islink\n",
            "    st = os.lstat(path)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Z6vCaMA2JS3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "013cba60-67e5-401b-adcb-6a79f88b8ad5"
      },
      "source": [
        "# version 4\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 1024, batch = 32, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    #print(y)\n",
        "    y_pred = model(x)\n",
        "    #print(y_pred)\n",
        "    loss = loss_fn(y_pred[:,:], y[:,:]) # compute MSE between the 2 arrays\n",
        "    #print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 605.4209594726562 average time 0.05229364139999291 iter num 20\n",
            "loss 1784.724609375 average time 0.027603255849994922 iter num 40\n",
            "loss 699.6022338867188 average time 0.01937843339999006 iter num 60\n",
            "loss 438.4067077636719 average time 0.015227208274991 iter num 80\n",
            "loss 280.857666015625 average time 0.012798372289991563 iter num 100\n",
            "loss 30.755651473999023 average time 0.050733957999989344 iter num 20\n",
            "loss 12.27236270904541 average time 0.02674691677499368 iter num 40\n",
            "loss 3.4057724475860596 average time 0.01876086056666016 iter num 60\n",
            "loss 9.469303131103516 average time 0.014774990999991643 iter num 80\n",
            "loss 10.845123291015625 average time 0.012378052689994092 iter num 100\n",
            "loss 5.970004558563232 average time 0.05093526560000328 iter num 20\n",
            "loss 4.132028102874756 average time 0.026959735800005546 iter num 40\n",
            "loss 6.6139397621154785 average time 0.018893525783336904 iter num 60\n",
            "loss 2.841221809387207 average time 0.014964001250008607 iter num 80\n",
            "loss 4.092901229858398 average time 0.012543926040008273 iter num 100\n",
            "loss 4.302128314971924 average time 0.05134533375000387 iter num 20\n",
            "loss 6.3338623046875 average time 0.027085267025000803 iter num 40\n",
            "loss 4.848691940307617 average time 0.01900629288333183 iter num 60\n",
            "loss 1.3966314792633057 average time 0.014951087124997287 iter num 80\n",
            "loss 1.450437068939209 average time 0.012514380249999704 iter num 100\n",
            "loss 3.5280656814575195 average time 0.05134902180000722 iter num 20\n",
            "loss 3.434330940246582 average time 0.027056651200010152 iter num 40\n",
            "loss 9.844765663146973 average time 0.01895076303334046 iter num 60\n",
            "loss 2.5839028358459473 average time 0.01494545868750805 iter num 80\n",
            "loss 5.29036808013916 average time 0.012548486340008366 iter num 100\n",
            "loss 5.075850009918213 average time 0.05096961284999679 iter num 20\n",
            "loss 1.8821823596954346 average time 0.02689416550000203 iter num 40\n",
            "loss 7.895333290100098 average time 0.018845792533329585 iter num 60\n",
            "loss 4.74104118347168 average time 0.014839177599992582 iter num 80\n",
            "loss 1.2135111093521118 average time 0.012436433199993643 iter num 100\n",
            "loss 2.136786460876465 average time 0.05183540415000607 iter num 20\n",
            "loss 3.1692824363708496 average time 0.02728035032499747 iter num 40\n",
            "loss 2.5628061294555664 average time 0.019149377716670794 iter num 60\n",
            "loss 0.8246252536773682 average time 0.015073530912496835 iter num 80\n",
            "loss 2.3168599605560303 average time 0.012626710569995793 iter num 100\n",
            "loss 4.808444976806641 average time 0.051562698750012716 iter num 20\n",
            "loss 5.409615516662598 average time 0.027154001675012297 iter num 40\n",
            "loss 1.5289525985717773 average time 0.01901675910001283 iter num 60\n",
            "loss 1.309340000152588 average time 0.015025232762508268 iter num 80\n",
            "loss 0.5814170241355896 average time 0.01257275855000671 iter num 100\n",
            "loss 4.690345287322998 average time 0.05107352095002397 iter num 20\n",
            "loss 2.1832311153411865 average time 0.026901992525006337 iter num 40\n",
            "loss 3.4862093925476074 average time 0.01889980736666909 iter num 60\n",
            "loss 2.3951430320739746 average time 0.014884744712495035 iter num 80\n",
            "loss 1.0310401916503906 average time 0.012458532050000031 iter num 100\n",
            "loss 1.2837368249893188 average time 0.05209621620003872 iter num 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-1833c98b5dcc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m           \u001b[0mEuropean_Call_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptionvalueavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m           \u001b[0mgooptionvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptionvalueavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m           \u001b[0mDeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgooptionvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m           \u001b[0;31m###################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mgrad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mapi_boundary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgrad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_and_grad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mvalue_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0m_check_input_dtype_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholomorphic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_py\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdyn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       ans, vjp_py, aux = _vjp(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, reduce_axes, *primals)\u001b[0m\n\u001b[1;32m   2144\u001b[0m     \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun_nokwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m     out_primal, out_vjp = ad.vjp(\n\u001b[0;32m-> 2146\u001b[0;31m         flat_fun, primals_flat, reduce_axes=reduce_axes)\n\u001b[0m\u001b[1;32m   2147\u001b[0m     \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux, reduce_axes)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m   \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tangents_pvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_primal_pval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout_primal_pval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    506\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJaxprTrace\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m     \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36moptionvalueavg\u001b[0;34m(key, initial_stocks, numsteps, drift, r, cov, K, T, keys)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moptionvalueavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m# must use '-1' not 'numsteps', or else grad will be 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    540\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__rshift__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__rrshift__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rrshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices)\u001b[0m\n\u001b[1;32m   5653\u001b[0m   \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_index_for_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5654\u001b[0m   return _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[0;32m-> 5655\u001b[0;31m                  unique_indices)\n\u001b[0m\u001b[1;32m   5656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5657\u001b[0m \u001b[0;31m# TODO(phawkins): re-enable jit after fixing excessive recompilation for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices)\u001b[0m\n\u001b[1;32m   5661\u001b[0m             unique_indices):\n\u001b[1;32m   5662\u001b[0m   \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_merge_static_and_dynamic_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5663\u001b[0;31m   \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_index_to_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shared with _scatter_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5664\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_index_to_gather\u001b[0;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[1;32m   5921\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgather_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5922\u001b[0m     \u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgather_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5923\u001b[0;31m     \u001b[0mgather_indices_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5924\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5925\u001b[0m     \u001b[0mlast_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgather_indices_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(array, dimensions)\u001b[0m\n\u001b[1;32m   3923\u001b[0m     \u001b[0mresult_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3924\u001b[0m   \u001b[0mbroadcast_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndim_out\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdims_set\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3925\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mbroadcast_in_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mbroadcast_in_dim\u001b[0;34m(operand, shape, broadcast_dimensions)\u001b[0m\n\u001b[1;32m    750\u001b[0m   return broadcast_in_dim_p.bind(\n\u001b[1;32m    751\u001b[0m       \u001b[0moperand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m       broadcast_dimensions=tuple(broadcast_dimensions))\n\u001b[0m\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbroadcast_to_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         args, used_axis_names(self, params) if self._dispatch_on_params else None)\n\u001b[1;32m    266\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    274\u001b[0m   \u001b[0;34m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m   \u001b[0mcompiled_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxla_primitive_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0munsafe_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled_primitive\u001b[0;34m(prim, compiled, result_handler, *args)\u001b[0m\n\u001b[1;32m    391\u001b[0m   \u001b[0minput_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_put\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m   \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mcheck_special\u001b[0;34m(name, bufs)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mneeds_check_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbufs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m       \u001b[0m_check_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxla_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mneeds_check_special\u001b[0;34m()\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mneeds_check_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_infs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjax_debug_nans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/config.py\u001b[0m in \u001b[0;36mget_state\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    231\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_contextmanager_flags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mget_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m       \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_thread_local_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0munset\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AzWwehfQrGSm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "27dd68b0-c9d1-4ba1-ffc8-0ac68429fcc0"
      },
      "source": [
        "# version 5, 6\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 100000, batch =32, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    #print(y)\n",
        "    y_pred = model(x)\n",
        "    #print(y_pred)\n",
        "    loss = ((y_pred - y) ** 2).mean(axis=0).sum()\n",
        "    #print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output * 10000, 'average time', timer.value(), 'iter num', iter) # * 10000 for version 6\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 51222272.0 average time 0.0729838983999798 iter num 20\n",
            "loss 51352472.0 average time 0.037968114574982795 iter num 40\n",
            "loss 58849488.0 average time 0.02627112149999296 iter num 60\n",
            "loss 62303808.0 average time 0.020432651712485494 iter num 80\n",
            "loss 53211420.0 average time 0.016891290730004584 iter num 100\n",
            "loss 27532958.0 average time 0.07092350649995752 iter num 20\n",
            "loss 28572300.0 average time 0.03688633032495545 iter num 40\n",
            "loss 24224100.0 average time 0.025541296966624334 iter num 60\n",
            "loss 23608792.0 average time 0.019869637412466546 iter num 80\n",
            "loss 24285892.0 average time 0.016463919099965096 iter num 100\n",
            "loss 24764718.0 average time 0.07172510180000699 iter num 20\n",
            "loss 20503604.0 average time 0.03728955617502834 iter num 40\n",
            "loss 20455224.0 average time 0.02579590253335482 iter num 60\n",
            "loss 15537903.0 average time 0.020063273662509575 iter num 80\n",
            "loss 17011308.0 average time 0.016607255060011993 iter num 100\n",
            "loss 7308837.5 average time 0.0735671064999451 iter num 20\n",
            "loss 4744317.0 average time 0.03816436919996704 iter num 40\n",
            "loss 3872000.5 average time 0.026389138649976 iter num 60\n",
            "loss 5489359.0 average time 0.020504179462477623 iter num 80\n",
            "loss 2573915.75 average time 0.0169764424899995 iter num 100\n",
            "loss 4591020.5 average time 0.07258069295005498 iter num 20\n",
            "loss 3684995.0 average time 0.03769316675002301 iter num 40\n",
            "loss 6196192.5 average time 0.026060277549989526 iter num 60\n",
            "loss 3068676.5 average time 0.020296764150009493 iter num 80\n",
            "loss 3826124.5 average time 0.016796143000037775 iter num 100\n",
            "loss 2549401.5 average time 0.07220374185003493 iter num 20\n",
            "loss 4866777.0 average time 0.037637468725029065 iter num 40\n",
            "loss 4579855.0 average time 0.026011501966680346 iter num 60\n",
            "loss 2162352.0 average time 0.020214428950021103 iter num 80\n",
            "loss 4123637.5 average time 0.01675899786001537 iter num 100\n",
            "loss 3532109.75 average time 0.07313011249971169 iter num 20\n",
            "loss 3887622.5 average time 0.03796367622476282 iter num 40\n",
            "loss 2589738.0 average time 0.02622489606656018 iter num 60\n",
            "loss 2050615.5 average time 0.020356777424933626 iter num 80\n",
            "loss 2230940.75 average time 0.0168570147999435 iter num 100\n",
            "loss 2757767.5 average time 0.07173695270003008 iter num 20\n",
            "loss 2543884.25 average time 0.037284456049951585 iter num 40\n",
            "loss 3101310.5 average time 0.025782937849923353 iter num 60\n",
            "loss 4370668.0 average time 0.02002772004994995 iter num 80\n",
            "loss 2687325.0 average time 0.01656559121992359 iter num 100\n",
            "loss 2702638.5 average time 0.07199552920001225 iter num 20\n",
            "loss 1602173.75 average time 0.03737274755005728 iter num 40\n",
            "loss 2444443.5 average time 0.02584627456672024 iter num 60\n",
            "loss 1756741.75 average time 0.020135148050007955 iter num 80\n",
            "loss 2493786.75 average time 0.016680567659968802 iter num 100\n",
            "loss 2331409.75 average time 0.07163739430002351 iter num 20\n",
            "loss 2644944.25 average time 0.03719804337501955 iter num 40\n",
            "loss 3281012.5 average time 0.025725203583366843 iter num 60\n",
            "loss 1898402.75 average time 0.02000444910003125 iter num 80\n",
            "loss 2326988.5 average time 0.016578444360056892 iter num 100\n",
            "loss 3120540.25 average time 0.07227887340000053 iter num 20\n",
            "loss 1644848.25 average time 0.037581091199990625 iter num 40\n",
            "loss 2141485.5 average time 0.02597950233330266 iter num 60\n",
            "loss 3318794.0 average time 0.02018752893746978 iter num 80\n",
            "loss 2572074.75 average time 0.016695617719969958 iter num 100\n",
            "loss 2390195.75 average time 0.07219631995012606 iter num 20\n",
            "loss 2386787.75 average time 0.037498214100060066 iter num 40\n",
            "loss 2031695.25 average time 0.025912278933355994 iter num 60\n",
            "loss 3245913.5 average time 0.020169996537504176 iter num 80\n",
            "loss 3292562.5 average time 0.016691911630014145 iter num 100\n",
            "loss 3256943.0 average time 0.07042251404991476 iter num 20\n",
            "loss 2796806.0 average time 0.036573564174977945 iter num 40\n",
            "loss 2312681.5 average time 0.02529556135001864 iter num 60\n",
            "loss 3276764.0 average time 0.019671269549985482 iter num 80\n",
            "loss 2387777.0 average time 0.01628115866998087 iter num 100\n",
            "loss 3302884.5 average time 0.07190006599994377 iter num 20\n",
            "loss 3486043.0 average time 0.03731541977490451 iter num 40\n",
            "loss 2668437.75 average time 0.025795508516633467 iter num 60\n",
            "loss 2708334.0 average time 0.020062265312515138 iter num 80\n",
            "loss 2602580.75 average time 0.016602543410026555 iter num 100\n",
            "loss 1683376.25 average time 0.07313817104986811 iter num 20\n",
            "loss 734867.25 average time 0.03812284052494306 iter num 40\n",
            "loss 2605033.0 average time 0.026373143383307252 iter num 60\n",
            "loss 1176076.25 average time 0.020519377724974676 iter num 80\n",
            "loss 3447892.5 average time 0.016997031229957427 iter num 100\n",
            "loss 2464974.5 average time 0.07215207229992301 iter num 20\n",
            "loss 1805598.375 average time 0.03749769492492305 iter num 40\n",
            "loss 3185293.5 average time 0.02595904154997394 iter num 60\n",
            "loss 1579302.0 average time 0.020174955949983087 iter num 80\n",
            "loss 2024472.875 average time 0.016759844479975073 iter num 100\n",
            "loss 2362213.0 average time 0.0745370639999237 iter num 20\n",
            "loss 3637134.0 average time 0.03869612984997275 iter num 40\n",
            "loss 2114968.5 average time 0.026754170483294124 iter num 60\n",
            "loss 2357162.5 average time 0.020774614999936603 iter num 80\n",
            "loss 1335610.0 average time 0.017172227109949745 iter num 100\n",
            "loss 1809987.125 average time 0.0711106554500475 iter num 20\n",
            "loss 1887597.25 average time 0.036937306450045074 iter num 40\n",
            "loss 2686433.75 average time 0.025571576916672712 iter num 60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-3be477bc15cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m           \u001b[0mEuropean_Call_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptionvalueavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m           \u001b[0mgooptionvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptionvalueavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m           \u001b[0mDeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgooptionvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m           \u001b[0;31m###################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mgrad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mapi_boundary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgrad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue_and_grad_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/traceback_util.py\u001b[0m in \u001b[0;36mreraise_with_filtered_traceback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0m__tracebackhide__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m       \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltering_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36mvalue_and_grad_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    875\u001b[0m       \u001b[0m_check_input_dtype_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mholomorphic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m       \u001b[0mans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvjp_py\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdyn_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce_axes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       ans, vjp_py, aux = _vjp(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/api.py\u001b[0m in \u001b[0;36m_vjp\u001b[0;34m(fun, has_aux, reduce_axes, *primals)\u001b[0m\n\u001b[1;32m   2144\u001b[0m     \u001b[0mflat_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun_nokwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2145\u001b[0m     out_primal, out_vjp = ad.vjp(\n\u001b[0;32m-> 2146\u001b[0;31m         flat_fun, primals_flat, reduce_axes=reduce_axes)\n\u001b[0m\u001b[1;32m   2147\u001b[0m     \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2148\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(traceable, primals, has_aux, reduce_axes)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0mout_primals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraceable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_aux\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/ad.py\u001b[0m in \u001b[0;36mlinearize\u001b[0;34m(traceable, *primals, **kwargs)\u001b[0m\n\u001b[1;32m    101\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprimals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflatten_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_tree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_to_jaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjvpfun_flat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m   \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tangents_pvals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_primal_pval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mout_primal_pval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_primals_pvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/partial_eval.py\u001b[0m in \u001b[0;36mtrace_to_jaxpr\u001b[0;34m(fun, pvals, instantiate)\u001b[0m\n\u001b[1;32m    506\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJaxprTrace\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0mfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_to_subjaxpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minstantiate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 508\u001b[0;31m     \u001b[0mjaxpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout_pvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpvals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    509\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/linear_util.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m       \u001b[0mans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m       \u001b[0;31m# Some transformations yield from inside context managers, so we have to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36moptionvalueavg\u001b[0;34m(key, initial_stocks, numsteps, drift, r, cov, K, T, keys)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moptionvalueavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m###################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    540\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__rshift__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__rrshift__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rrshift\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices)\u001b[0m\n\u001b[1;32m   5653\u001b[0m   \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_index_for_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5654\u001b[0m   return _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[0;32m-> 5655\u001b[0;31m                  unique_indices)\n\u001b[0m\u001b[1;32m   5656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5657\u001b[0m \u001b[0;31m# TODO(phawkins): re-enable jit after fixing excessive recompilation for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices)\u001b[0m\n\u001b[1;32m   5661\u001b[0m             unique_indices):\n\u001b[1;32m   5662\u001b[0m   \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_merge_static_and_dynamic_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5663\u001b[0;31m   \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_index_to_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shared with _scatter_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5664\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_index_to_gather\u001b[0;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[1;32m   5852\u001b[0m         \u001b[0;31m# XLA gives error when indexing into an axis of size 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5853\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"index is out of bounds for axis {x_axis} with size 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5854\u001b[0;31m       \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnormalize_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5855\u001b[0m       \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_element_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5856\u001b[0m       \u001b[0mgather_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgather_indices_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_normalize_index\u001b[0;34m(index, axis_size)\u001b[0m\n\u001b[1;32m   5437\u001b[0m     \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_constant_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5438\u001b[0m     \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_size_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5439\u001b[0;31m     index)\n\u001b[0m\u001b[1;32m   5440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5441\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_wraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_along_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_doc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(pred, on_true, on_false)\u001b[0m\n\u001b[1;32m    841\u001b[0m   \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m   \"\"\"\n\u001b[0;32m--> 843\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mselect_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_false\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m def slice(operand: Array, start_indices: Sequence[int],\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         args, used_axis_names(self, params) if self._dispatch_on_params else None)\n\u001b[1;32m    266\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    274\u001b[0m   \u001b[0;34m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m   \u001b[0mcompiled_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxla_primitive_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0munsafe_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled_primitive\u001b[0;34m(prim, compiled, result_handler, *args)\u001b[0m\n\u001b[1;32m    390\u001b[0m   \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m   \u001b[0minput_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_put\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m   \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7875f7a-569c-4cf2-a75d-669240ba1f8c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_version6_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58206fe0-aa56-4fab-d958-de126cadc0e9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1106fd84-ad99-44b2-e245-e10d0e926348"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_version2_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f93312a3-4e05-4c8e-9851-f4a556f754e8"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=6, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc5): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc6): Linear(in_features=1024, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47719093-ab2f-44c9-d784-dd3c48fb3722"
      },
      "source": [
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "#dataset = OptionDataSet(max_len = 100, number_path = 1024, batch = 32, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 1000000, batch = 8, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 0]).cuda()  # let delta weight = 0 for testing\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output * 10000, 'average time', timer.value(), 'iter num', iter) # print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 30)\n",
        "\n",
        "model_save_name = 'jax_european_1stock_test_3.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 9.12090647034347 average time 0.09411642375007431 iter num 20\n",
            "loss 0.8995448297355324 average time 0.05216499059993111 iter num 40\n",
            "loss 0.29933053156128153 average time 0.038401626166705685 iter num 60\n",
            "loss 0.10731004294939339 average time 0.03147281592500804 iter num 80\n",
            "loss 0.226803203986492 average time 0.027255156449991772 iter num 100\n",
            "loss 0.19930361304432154 average time 0.09348549954966075 iter num 20\n",
            "loss 0.4021249696961604 average time 0.051847731474936154 iter num 40\n",
            "loss 0.43462783651193604 average time 0.03798604956658285 iter num 60\n",
            "loss 0.22722966605215333 average time 0.03106180361241968 iter num 80\n",
            "loss 0.5652793697663583 average time 0.026907684599937056 iter num 100\n",
            "loss 0.4850328332395293 average time 0.09363120119987797 iter num 20\n",
            "loss 0.3098317392868921 average time 0.05211543697491834 iter num 40\n",
            "loss 0.29846811230527237 average time 0.038207844866641 iter num 60\n",
            "loss 0.3846608888125047 average time 0.03121005851241989 iter num 80\n",
            "loss 0.2695314833545126 average time 0.027026031049917947 iter num 100\n",
            "loss 0.3438072599237785 average time 0.09383216399992307 iter num 20\n",
            "loss 0.7860939513193443 average time 0.0520288292499572 iter num 40\n",
            "loss 0.37763376894872636 average time 0.03812121866661376 iter num 60\n",
            "loss 0.32938729418674484 average time 0.031179463124885842 iter num 80\n",
            "loss 0.5110312122269534 average time 0.02701080713992269 iter num 100\n",
            "loss 0.24904114980017766 average time 0.09382771480022711 iter num 20\n",
            "loss 1.2239730858709663 average time 0.052037630200175045 iter num 40\n",
            "loss 0.6125723302830011 average time 0.0381337351833281 iter num 60\n",
            "loss 0.1748250360833481 average time 0.03117218582503938 iter num 80\n",
            "loss 0.36633966374211013 average time 0.027057584960093663 iter num 100\n",
            "loss 0.4769454972120002 average time 0.09350251610021587 iter num 20\n",
            "loss 0.13670096450368874 average time 0.05183708780014058 iter num 40\n",
            "loss 0.3230808215448633 average time 0.03797491225004705 iter num 60\n",
            "loss 0.09403138392372057 average time 0.031053102300029424 iter num 80\n",
            "loss 0.15658422853448428 average time 0.026872474270039675 iter num 100\n",
            "loss 1.594636996742338 average time 0.09321502720003991 iter num 20\n",
            "loss 3.442135639488697 average time 0.05184089762506119 iter num 40\n",
            "loss 0.29440008802339435 average time 0.0379640511332885 iter num 60\n",
            "loss 0.31858689908403903 average time 0.031126457624918658 iter num 80\n",
            "loss 0.10520911928324495 average time 0.027003680529942356 iter num 100\n",
            "loss 0.7227698370115831 average time 0.09325356089984779 iter num 20\n",
            "loss 0.27393907657824457 average time 0.05172441109993997 iter num 40\n",
            "loss 0.791247803135775 average time 0.03795140824995542 iter num 60\n",
            "loss 0.31866318749962375 average time 0.031006942262456504 iter num 80\n",
            "loss 0.4705472383648157 average time 0.026837486940003145 iter num 100\n",
            "loss 0.1837948730099015 average time 0.09319557154994981 iter num 20\n",
            "loss 0.8284892828669399 average time 0.05174526214996149 iter num 40\n",
            "loss 0.15799418179085478 average time 0.03797309109998726 iter num 60\n",
            "loss 0.10902705980697647 average time 0.03111634522490476 iter num 80\n",
            "loss 0.05857436917722225 average time 0.0269897410998783 iter num 100\n",
            "loss 0.14638680113421287 average time 0.09365075364976291 iter num 20\n",
            "loss 0.8966093446360901 average time 0.05192845457486328 iter num 40\n",
            "loss 0.4956115299137309 average time 0.03804251751650251 iter num 60\n",
            "loss 0.28606147679965943 average time 0.031098120662363726 iter num 80\n",
            "loss 0.30531355150742456 average time 0.026949755169862328 iter num 100\n",
            "loss 4.759716393891722 average time 0.09336046835014714 iter num 20\n",
            "loss 0.8193186658900231 average time 0.05189584780009682 iter num 40\n",
            "loss 0.1869282641564496 average time 0.03811958700001317 iter num 60\n",
            "loss 0.22576849005417898 average time 0.031128875362514918 iter num 80\n",
            "loss 0.6794159708078951 average time 0.026995491229990877 iter num 100\n",
            "loss 0.222443813981954 average time 0.09367545714985681 iter num 20\n",
            "loss 0.37173980672378093 average time 0.05211468492484528 iter num 40\n",
            "loss 0.34732394851744175 average time 0.03815523643315828 iter num 60\n",
            "loss 0.8294135477626696 average time 0.031205156662372245 iter num 80\n",
            "loss 0.04380408427095972 average time 0.027012110369905713 iter num 100\n",
            "loss 0.34579898056108505 average time 0.0937038111498623 iter num 20\n",
            "loss 1.1678745795506984 average time 0.05198470035006721 iter num 40\n",
            "loss 0.1579134914209135 average time 0.03819864906681687 iter num 60\n",
            "loss 0.302143507724395 average time 0.031215810687581325 iter num 80\n",
            "loss 0.18369013560004532 average time 0.027055570800039275 iter num 100\n",
            "loss 0.1107568823499605 average time 0.09330464959966775 iter num 20\n",
            "loss 1.8776344950310886 average time 0.05188521179998133 iter num 40\n",
            "loss 0.5436689389171079 average time 0.03801946703330638 iter num 60\n",
            "loss 0.21754171029897407 average time 0.031092823774952195 iter num 80\n",
            "loss 0.17179494534502737 average time 0.026935436000003393 iter num 100\n",
            "loss 0.33102711313404143 average time 0.09336609424981361 iter num 20\n",
            "loss 1.7814431339502335 average time 0.051783959799968214 iter num 40\n",
            "loss 0.6055039193597622 average time 0.03794319451656823 iter num 60\n",
            "loss 0.10201459190284368 average time 0.03101242318750792 iter num 80\n",
            "loss 0.06931536518095527 average time 0.026843592959994566 iter num 100\n",
            "loss 0.8688322850503027 average time 0.09312345179996555 iter num 20\n",
            "loss 0.5516469536814839 average time 0.05184300022492607 iter num 40\n",
            "loss 1.3833311095368117 average time 0.03794631348328039 iter num 60\n",
            "loss 0.16012496416806243 average time 0.03113244933745136 iter num 80\n",
            "loss 0.03760476374736754 average time 0.026951200919920665 iter num 100\n",
            "loss 0.21649211703334004 average time 0.09353207909980484 iter num 20\n",
            "loss 8.125554886646569 average time 0.05184920242472799 iter num 40\n",
            "loss 4.4292089296504855 average time 0.03805065834988757 iter num 60\n",
            "loss 0.2940834383480251 average time 0.031086060124926006 iter num 80\n",
            "loss 0.07673432264709845 average time 0.026903783949946955 iter num 100\n",
            "loss 0.9773058263817802 average time 0.0932809225998426 iter num 20\n",
            "loss 0.12352695193840191 average time 0.05174916147507247 iter num 40\n",
            "loss 0.3639215719886124 average time 0.03802513658338284 iter num 60\n",
            "loss 0.24802822736091912 average time 0.03107753118756591 iter num 80\n",
            "loss 0.07109385933290469 average time 0.02690281168999718 iter num 100\n",
            "loss 0.41431780118728057 average time 0.09338834814998336 iter num 20\n",
            "loss 0.3351931445649825 average time 0.05208396322509543 iter num 40\n",
            "loss 0.31133138691075146 average time 0.03819932720007273 iter num 60\n",
            "loss 0.1842238452809397 average time 0.0312689859750435 iter num 80\n",
            "loss 0.051896367949666455 average time 0.02708696249002969 iter num 100\n",
            "loss 1.7480757378507406 average time 0.0937876909500119 iter num 20\n",
            "loss 0.219899884541519 average time 0.052444480924987144 iter num 40\n",
            "loss 0.10226502126897685 average time 0.03834657649995279 iter num 60\n",
            "loss 0.24009368644328788 average time 0.03132136049991914 iter num 80\n",
            "loss 0.24014621885726228 average time 0.027140851309995925 iter num 100\n",
            "loss 2.545270835980773 average time 0.09338738250025927 iter num 20\n",
            "loss 2.5039358297362924 average time 0.05179337295016921 iter num 40\n",
            "loss 5.538453697226942 average time 0.037938236500091684 iter num 60\n",
            "loss 1.1775679013226181 average time 0.031037469312605027 iter num 80\n",
            "loss 0.30175200663506985 average time 0.02694197877004626 iter num 100\n",
            "loss 0.49741604016162455 average time 0.09339666764972207 iter num 20\n",
            "loss 0.39959719288162887 average time 0.05179196309973122 iter num 40\n",
            "loss 0.08572991646360606 average time 0.03808713129974421 iter num 60\n",
            "loss 0.28230737370904535 average time 0.031197007737250714 iter num 80\n",
            "loss 0.35906930861528963 average time 0.02704659325978355 iter num 100\n",
            "loss 0.8610064105596393 average time 0.09326738879990444 iter num 20\n",
            "loss 0.3908637154381722 average time 0.0518325238750549 iter num 40\n",
            "loss 0.1821006298996508 average time 0.03805736903338281 iter num 60\n",
            "loss 0.12010298632958438 average time 0.03109170682507738 iter num 80\n",
            "loss 0.9169136319542304 average time 0.026973948829981963 iter num 100\n",
            "loss 0.22417189029511064 average time 0.09370042225009456 iter num 20\n",
            "loss 0.3441274384385906 average time 0.0520193876000576 iter num 40\n",
            "loss 0.08118657206068747 average time 0.038079945616694505 iter num 60\n",
            "loss 0.5027064617024735 average time 0.031143596575020638 iter num 80\n",
            "loss 0.2307109025423415 average time 0.0269978685800379 iter num 100\n",
            "loss 0.2969890738313552 average time 0.0932966155000031 iter num 20\n",
            "loss 0.2546803079894744 average time 0.05181367530003626 iter num 40\n",
            "loss 0.2981583929795306 average time 0.03800279826658273 iter num 60\n",
            "loss 0.1628561585675925 average time 0.031076371649942303 iter num 80\n",
            "loss 0.2127793777617626 average time 0.02693721696994544 iter num 100\n",
            "loss 0.5230181704973802 average time 0.09370158219999211 iter num 20\n",
            "loss 0.3896653652191162 average time 0.0519950540249738 iter num 40\n",
            "loss 0.4335261837695725 average time 0.038082335616612305 iter num 60\n",
            "loss 0.5099261761642992 average time 0.03111113769991789 iter num 80\n",
            "loss 0.1505427462689113 average time 0.026963973909896594 iter num 100\n",
            "loss 0.32748313969932497 average time 0.09330768825011546 iter num 20\n",
            "loss 0.0690694514560164 average time 0.051863113100034754 iter num 40\n",
            "loss 0.07976962479006033 average time 0.03801722950001931 iter num 60\n",
            "loss 0.16954145394265652 average time 0.03112396033754976 iter num 80\n",
            "loss 0.5020621028961614 average time 0.026944275690038922 iter num 100\n",
            "loss 0.6227754784049466 average time 0.09391860665000422 iter num 20\n",
            "loss 1.5859765699133277 average time 0.052204777625001954 iter num 40\n",
            "loss 4.0154808084480464 average time 0.03821143123332149 iter num 60\n",
            "loss 0.1483701908000512 average time 0.031217580087559326 iter num 80\n",
            "loss 0.07028805612208089 average time 0.02702295696004512 iter num 100\n",
            "loss 0.8502694254275411 average time 0.09342393544984588 iter num 20\n",
            "loss 4.270700737833977 average time 0.051874880624927754 iter num 40\n",
            "loss 1.492823357693851 average time 0.03800438581668762 iter num 60\n",
            "loss 0.2453289198456332 average time 0.031053179987566182 iter num 80\n",
            "loss 0.05410070571087999 average time 0.026922446450025745 iter num 100\n",
            "loss 0.22978645574767143 average time 0.09323427789995549 iter num 20\n",
            "loss 1.9836204592138529 average time 0.05176927742513726 iter num 40\n",
            "loss 0.3630317223723978 average time 0.037932000200089536 iter num 60\n",
            "loss 0.2736523310886696 average time 0.031039595887568792 iter num 80\n",
            "loss 0.4369873204268515 average time 0.026883898500091163 iter num 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFjWBtGk7ej5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d7dd264c-0487-48b3-f612-be4ae8b0d1ca"
      },
      "source": [
        "# version 4\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "timer = Timer(average=True)\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 1000000, batch = 8, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    #print(y)\n",
        "    y_pred = model(x)\n",
        "    #print(y_pred)\n",
        "    loss = loss_fn(y_pred[:,:], y[:,:]) # compute MSE between the 2 arrays\n",
        "    #print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 50)\n",
        "\n",
        "model_save_name = 'jax_european_1stock_version4_2.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 2.046630620956421 average time 0.4740749346999905 iter num 20\n",
            "loss 1.799705147743225 average time 0.23847036637498037 iter num 40\n",
            "loss 0.7313764095306396 average time 0.15993198333332734 iter num 60\n",
            "loss 0.1241651177406311 average time 0.12063063373749117 iter num 80\n",
            "loss 0.13611027598381042 average time 0.09706118446998743 iter num 100\n",
            "loss 0.15536171197891235 average time 0.08598583745000496 iter num 20\n",
            "loss 0.5444387197494507 average time 0.04441163370000254 iter num 40\n",
            "loss 0.24326755106449127 average time 0.030551000666673645 iter num 60\n",
            "loss 0.036943838000297546 average time 0.023603397050001716 iter num 80\n",
            "loss 0.016648493707180023 average time 0.019442864039992857 iter num 100\n",
            "loss 0.2033129781484604 average time 0.08602859795000768 iter num 20\n",
            "loss 0.09743532538414001 average time 0.04441264245002117 iter num 40\n",
            "loss 0.08224725723266602 average time 0.030554118316676218 iter num 60\n",
            "loss 0.06957727670669556 average time 0.023611417975004656 iter num 80\n",
            "loss 0.019112909212708473 average time 0.019463584279999394 iter num 100\n",
            "loss 0.22075746953487396 average time 0.08635713640003359 iter num 20\n",
            "loss 1.0144895315170288 average time 0.04455155154997783 iter num 40\n",
            "loss 1.1881506443023682 average time 0.030622097683332565 iter num 60\n",
            "loss 0.17381419241428375 average time 0.02365088539999647 iter num 80\n",
            "loss 0.09927201271057129 average time 0.019480646229985722 iter num 100\n",
            "loss 5.744588851928711 average time 0.08639153199999328 iter num 20\n",
            "loss 15.84619426727295 average time 0.04458036537498629 iter num 40\n",
            "loss 1.6242320537567139 average time 0.030644938016666855 iter num 60\n",
            "loss 0.8208554983139038 average time 0.023714608587488327 iter num 80\n",
            "loss 0.5984455347061157 average time 0.019522102309979347 iter num 100\n",
            "loss 0.021888360381126404 average time 0.08609160755001995 iter num 20\n",
            "loss 0.14598149061203003 average time 0.044431460175007945 iter num 40\n",
            "loss 0.08690813183784485 average time 0.030527529950025684 iter num 60\n",
            "loss 0.1458490639925003 average time 0.02358417920000875 iter num 80\n",
            "loss 0.19769999384880066 average time 0.019427219369999874 iter num 100\n",
            "loss 0.7342912554740906 average time 0.08618182314999104 iter num 20\n",
            "loss 0.12912414968013763 average time 0.04445506792494598 iter num 40\n",
            "loss 0.07680690288543701 average time 0.030560533366641114 iter num 60\n",
            "loss 0.32654067873954773 average time 0.023608166149983845 iter num 80\n",
            "loss 0.08039585500955582 average time 0.019436860889986748 iter num 100\n",
            "loss 0.19790691137313843 average time 0.08613611444998241 iter num 20\n",
            "loss 0.0726713314652443 average time 0.044460274974937875 iter num 40\n",
            "loss 0.16514642536640167 average time 0.03064190921663036 iter num 60\n",
            "loss 0.15415889024734497 average time 0.023667996949967574 iter num 80\n",
            "loss 0.02422206848859787 average time 0.01948501291998582 iter num 100\n",
            "loss 0.32179829478263855 average time 0.08597167995005747 iter num 20\n",
            "loss 1.4025161266326904 average time 0.04437436197504212 iter num 40\n",
            "loss 0.2602796256542206 average time 0.03050576841669681 iter num 60\n",
            "loss 0.25295066833496094 average time 0.02357547551250718 iter num 80\n",
            "loss 0.1937248408794403 average time 0.019410443720007605 iter num 100\n",
            "loss 6.057653427124023 average time 0.0859042716000431 iter num 20\n",
            "loss 2.192858934402466 average time 0.04434435795006948 iter num 40\n",
            "loss 0.7066669464111328 average time 0.03049291740001081 iter num 60\n",
            "loss 0.06875449419021606 average time 0.02357745934999116 iter num 80\n",
            "loss 0.07409951090812683 average time 0.019436169199993854 iter num 100\n",
            "loss 0.23461347818374634 average time 0.08648016550000648 iter num 20\n",
            "loss 0.6547106504440308 average time 0.0446542219749972 iter num 40\n",
            "loss 0.5554633736610413 average time 0.030745409766677768 iter num 60\n",
            "loss 0.3301261365413666 average time 0.023766222075016684 iter num 80\n",
            "loss 0.023575257509946823 average time 0.019601643190007963 iter num 100\n",
            "loss 0.42610442638397217 average time 0.08657878074998279 iter num 20\n",
            "loss 0.20686042308807373 average time 0.04469666565001944 iter num 40\n",
            "loss 0.4215913414955139 average time 0.03073211530001269 iter num 60\n",
            "loss 0.05144809931516647 average time 0.023750196687495874 iter num 80\n",
            "loss 0.06979961693286896 average time 0.019575119570004063 iter num 100\n",
            "loss 0.5940374135971069 average time 0.08636419369995565 iter num 20\n",
            "loss 0.13105015456676483 average time 0.04460049794998895 iter num 40\n",
            "loss 0.35035771131515503 average time 0.030678969166645705 iter num 60\n",
            "loss 0.5290958285331726 average time 0.0237097344124777 iter num 80\n",
            "loss 0.031182903796434402 average time 0.01952968593998776 iter num 100\n",
            "loss 1.5065765380859375 average time 0.0866707876999726 iter num 20\n",
            "loss 0.5109167098999023 average time 0.04472451119995639 iter num 40\n",
            "loss 0.20249493420124054 average time 0.03079002356662386 iter num 60\n",
            "loss 0.08923927694559097 average time 0.0237905599499868 iter num 80\n",
            "loss 0.09567205607891083 average time 0.019581999059992087 iter num 100\n",
            "loss 13.340768814086914 average time 0.08661365485002079 iter num 20\n",
            "loss 7.074660778045654 average time 0.044894913500002076 iter num 40\n",
            "loss 0.8309193253517151 average time 0.030938242449989654 iter num 60\n",
            "loss 0.4084589183330536 average time 0.023897662149994402 iter num 80\n",
            "loss 0.1013433039188385 average time 0.019689694300000157 iter num 100\n",
            "loss 0.8285126090049744 average time 0.08654669585007468 iter num 20\n",
            "loss 0.4890473484992981 average time 0.04473823762505162 iter num 40\n",
            "loss 1.2273051738739014 average time 0.03076002008335005 iter num 60\n",
            "loss 0.02733023837208748 average time 0.02378641322502517 iter num 80\n",
            "loss 0.1357104629278183 average time 0.019633649290035464 iter num 100\n",
            "loss 0.3405210077762604 average time 0.08695361374993808 iter num 20\n",
            "loss 0.8063220977783203 average time 0.045050682974988376 iter num 40\n",
            "loss 0.22879186272621155 average time 0.03104509648331562 iter num 60\n",
            "loss 0.2571004331111908 average time 0.02398531733750815 iter num 80\n",
            "loss 0.1509421169757843 average time 0.019743861550005022 iter num 100\n",
            "loss 2.0877130031585693 average time 0.08636071640007685 iter num 20\n",
            "loss 0.19658775627613068 average time 0.04457773027497751 iter num 40\n",
            "loss 0.24852225184440613 average time 0.0306959212666546 iter num 60\n",
            "loss 0.08403357118368149 average time 0.023713552587469166 iter num 80\n",
            "loss 0.04471931979060173 average time 0.019552191009961462 iter num 100\n",
            "loss 0.6091890931129456 average time 0.08659467989996301 iter num 20\n",
            "loss 4.396214008331299 average time 0.04467714607499147 iter num 40\n",
            "loss 8.230131149291992 average time 0.030729175683291032 iter num 60\n",
            "loss 1.1453744173049927 average time 0.023763311074958438 iter num 80\n",
            "loss 0.43187767267227173 average time 0.01958342218996222 iter num 100\n",
            "loss 0.24107994139194489 average time 0.08614047469995967 iter num 20\n",
            "loss 0.5609993934631348 average time 0.04445247022497369 iter num 40\n",
            "loss 1.2848436832427979 average time 0.030570829233283803 iter num 60\n",
            "loss 0.9704099893569946 average time 0.02364323587499939 iter num 80\n",
            "loss 0.18917563557624817 average time 0.01945955809001134 iter num 100\n",
            "loss 2.15852952003479 average time 0.0863345108500198 iter num 20\n",
            "loss 1.4397122859954834 average time 0.04457105229998888 iter num 40\n",
            "loss 0.1489572823047638 average time 0.030625249233359377 iter num 60\n",
            "loss 0.10141292214393616 average time 0.02368006190001779 iter num 80\n",
            "loss 0.32111653685569763 average time 0.019546207260018492 iter num 100\n",
            "loss 5.501241683959961 average time 0.08643948464996357 iter num 20\n",
            "loss 8.048121452331543 average time 0.044684936700014076 iter num 40\n",
            "loss 0.16282622516155243 average time 0.030698387466736678 iter num 60\n",
            "loss 0.18046148121356964 average time 0.023788345125069554 iter num 80\n",
            "loss 0.12860818207263947 average time 0.01960158552004941 iter num 100\n",
            "loss 0.10263776779174805 average time 0.08655654615004096 iter num 20\n",
            "loss 0.4939764738082886 average time 0.04474933287506246 iter num 40\n",
            "loss 0.22013559937477112 average time 0.030778414633368813 iter num 60\n",
            "loss 0.06889026612043381 average time 0.02378627440001537 iter num 80\n",
            "loss 0.06260841339826584 average time 0.019584072590005233 iter num 100\n",
            "loss 0.20655593276023865 average time 0.0865617317500437 iter num 20\n",
            "loss 2.1892290115356445 average time 0.04479851362505087 iter num 40\n",
            "loss 0.47328028082847595 average time 0.030798922016750416 iter num 60\n",
            "loss 0.05093429237604141 average time 0.023802343437603214 iter num 80\n",
            "loss 0.07741551846265793 average time 0.0195990296500986 iter num 100\n",
            "loss 0.04199735075235367 average time 0.08649530845009394 iter num 20\n",
            "loss 0.06752274930477142 average time 0.044663368624947 iter num 40\n",
            "loss 0.1459275484085083 average time 0.03070196313327263 iter num 60\n",
            "loss 0.275885671377182 average time 0.02372787324993624 iter num 80\n",
            "loss 0.10499098896980286 average time 0.01953704714997002 iter num 100\n",
            "loss 0.4857832193374634 average time 0.0864543786500235 iter num 20\n",
            "loss 0.32370734214782715 average time 0.04463641857505536 iter num 40\n",
            "loss 0.11940015852451324 average time 0.030708891416725236 iter num 60\n",
            "loss 0.05380875989794731 average time 0.02375387110007523 iter num 80\n",
            "loss 0.1038159728050232 average time 0.01957272326006205 iter num 100\n",
            "loss 0.3131944537162781 average time 0.08649247435009784 iter num 20\n",
            "loss 1.5311360359191895 average time 0.044661081275148715 iter num 40\n",
            "loss 0.35680633783340454 average time 0.030698028533394487 iter num 60\n",
            "loss 0.2559635639190674 average time 0.023722252925040266 iter num 80\n",
            "loss 0.007164288777858019 average time 0.019582862200022647 iter num 100\n",
            "loss 0.5454408526420593 average time 0.0866016726001817 iter num 20\n",
            "loss 1.065030813217163 average time 0.04471415582515874 iter num 40\n",
            "loss 0.4988020658493042 average time 0.030729643533428923 iter num 60\n",
            "loss 0.09084124118089676 average time 0.023869763975096703 iter num 80\n",
            "loss 0.03878137841820717 average time 0.019661594260078345 iter num 100\n",
            "loss 2.1690115928649902 average time 0.08667939065003338 iter num 20\n",
            "loss 4.72645378112793 average time 0.044788433949975115 iter num 40\n",
            "loss 0.19591858983039856 average time 0.030811508449945298 iter num 60\n",
            "loss 0.02792981266975403 average time 0.02381636667496423 iter num 80\n",
            "loss 0.37137141823768616 average time 0.01961368081998444 iter num 100\n",
            "loss 0.17360517382621765 average time 0.08646782799992252 iter num 20\n",
            "loss 0.11604215204715729 average time 0.04480531162491843 iter num 40\n",
            "loss 0.23768989741802216 average time 0.030800906783269966 iter num 60\n",
            "loss 0.21672488749027252 average time 0.023814016399956017 iter num 80\n",
            "loss 0.0899648666381836 average time 0.019607417399947737 iter num 100\n",
            "loss 0.045493874698877335 average time 0.08635689889988499 iter num 20\n",
            "loss 0.7740746736526489 average time 0.04462813414993434 iter num 40\n",
            "loss 0.05061612278223038 average time 0.030735589249979968 iter num 60\n",
            "loss 0.16088107228279114 average time 0.023747661524998874 iter num 80\n",
            "loss 0.1871042549610138 average time 0.019608111859997734 iter num 100\n",
            "loss 0.17091193795204163 average time 0.08677345034998325 iter num 20\n",
            "loss 0.1262114942073822 average time 0.04478147879988228 iter num 40\n",
            "loss 0.09251551330089569 average time 0.030833453466584615 iter num 60\n",
            "loss 0.03559838980436325 average time 0.02384277518743829 iter num 80\n",
            "loss 0.09230280667543411 average time 0.019637868779982456 iter num 100\n",
            "loss 0.14252017438411713 average time 0.08658576489997358 iter num 20\n",
            "loss 0.20802611112594604 average time 0.044702494575017224 iter num 40\n",
            "loss 0.8492939472198486 average time 0.030751972833346977 iter num 60\n",
            "loss 0.16296570003032684 average time 0.02378213265000113 iter num 80\n",
            "loss 0.08731190860271454 average time 0.019591343779993622 iter num 100\n",
            "loss 0.13259494304656982 average time 0.08644672229997923 iter num 20\n",
            "loss 0.9478894472122192 average time 0.044640437825000844 iter num 40\n",
            "loss 0.1122460886836052 average time 0.03071682083335266 iter num 60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3fa149a86ccc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mmodel_save_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'jax_european_1stock_version4_2.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m           \u001b[0;31m################################################################################################### store input and output numbers in X and Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m           \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEuropean_Call_price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m           \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDeltas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.__setitem__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_routines_indexing.pyx\u001b[0m in \u001b[0;36mcupy._core._routines_indexing._ndarray_setitem\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_routines_indexing.pyx\u001b[0m in \u001b[0;36mcupy._core._routines_indexing._scatter_op\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.fill\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_forward_method\u001b[0;34m(attrname, self, fun, *args)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_forward_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0m_forward_to_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_forward_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8Lkc1HtpW7S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49bf37e1-0cec-4af5-b98c-274bf002e4ef"
      },
      "source": [
        "# version 5\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "timer = Timer(average=True)\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 1000000, batch = 8, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    #print(y)\n",
        "    y_pred = model(x)\n",
        "    #print(y_pred)\n",
        "    loss = ((y_pred - y) ** 2).mean(axis=0).sum()\n",
        "    #print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 20)\n",
        "\n",
        "model_save_name = 'jax_european_1stock_version5_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 8.121227264404297 average time 0.19850110825002504 iter num 20\n",
            "loss 1.4115912914276123 average time 0.10062621462502648 iter num 40\n",
            "loss 4.279460430145264 average time 0.068014872200024 iter num 60\n",
            "loss 1.859859824180603 average time 0.05172370921252423 iter num 80\n",
            "loss 1.0982649326324463 average time 0.041922518410010524 iter num 100\n",
            "loss 1.064512848854065 average time 0.08594591344999572 iter num 20\n",
            "loss 4.192468643188477 average time 0.044336736474974714 iter num 40\n",
            "loss 1.359633445739746 average time 0.030487323083320916 iter num 60\n",
            "loss 5.919878005981445 average time 0.02359727771249709 iter num 80\n",
            "loss 1.3565268516540527 average time 0.019426683029992092 iter num 100\n",
            "loss 1.430983543395996 average time 0.08597827774997313 iter num 20\n",
            "loss 8.961183547973633 average time 0.04433867122500033 iter num 40\n",
            "loss 4.0858235359191895 average time 0.03046528321669181 iter num 60\n",
            "loss 1.5352342128753662 average time 0.023528458975027887 iter num 80\n",
            "loss 1.5280840396881104 average time 0.019365094300023884 iter num 100\n",
            "loss 0.8710355162620544 average time 0.08600289400005749 iter num 20\n",
            "loss 1.6151518821716309 average time 0.04435583232501585 iter num 40\n",
            "loss 1.9436668157577515 average time 0.030522405450013442 iter num 60\n",
            "loss 0.279252827167511 average time 0.023570476849999977 iter num 80\n",
            "loss 4.52284049987793 average time 0.019398132489995987 iter num 100\n",
            "loss 4.3773274421691895 average time 0.0857831947500017 iter num 20\n",
            "loss 5.556689739227295 average time 0.044250923774973215 iter num 40\n",
            "loss 1.1255007982254028 average time 0.03040645839998888 iter num 60\n",
            "loss 1.2579693794250488 average time 0.023485289349997628 iter num 80\n",
            "loss 0.38194772601127625 average time 0.01933844618999956 iter num 100\n",
            "loss 3.7801666259765625 average time 0.08615091534998101 iter num 20\n",
            "loss 2.9320058822631836 average time 0.044430752799974015 iter num 40\n",
            "loss 0.758478045463562 average time 0.030545576966612014 iter num 60\n",
            "loss 2.7333602905273438 average time 0.023655806674958056 iter num 80\n",
            "loss 1.4961165189743042 average time 0.01946791724996274 iter num 100\n",
            "loss 2.886930227279663 average time 0.08609241990000101 iter num 20\n",
            "loss 17.289186477661133 average time 0.04440240092498016 iter num 40\n",
            "loss 2.459249496459961 average time 0.030552785283308972 iter num 60\n",
            "loss 0.4199572503566742 average time 0.023598815399992645 iter num 80\n",
            "loss 0.5385066866874695 average time 0.019418425759972706 iter num 100\n",
            "loss 0.8485425710678101 average time 0.08594172830003118 iter num 20\n",
            "loss 0.9170317649841309 average time 0.04434259734999842 iter num 40\n",
            "loss 1.5996121168136597 average time 0.030474996599991755 iter num 60\n",
            "loss 1.7022258043289185 average time 0.023534904862498252 iter num 80\n",
            "loss 1.1692670583724976 average time 0.019370656880000753 iter num 100\n",
            "loss 2.766956090927124 average time 0.08623889694993067 iter num 20\n",
            "loss 1.8335108757019043 average time 0.04458694527498892 iter num 40\n",
            "loss 4.749092102050781 average time 0.030656209650010167 iter num 60\n",
            "loss 2.0276520252227783 average time 0.023681644262507007 iter num 80\n",
            "loss 2.2768235206604004 average time 0.019551726680033424 iter num 100\n",
            "loss 2.7226529121398926 average time 0.08584910710010263 iter num 20\n",
            "loss 1.10483980178833 average time 0.04427705687512571 iter num 40\n",
            "loss 2.686295509338379 average time 0.030470716566772655 iter num 60\n",
            "loss 3.6656291484832764 average time 0.023555593762546324 iter num 80\n",
            "loss 0.28204870223999023 average time 0.019423022040064096 iter num 100\n",
            "loss 10.612570762634277 average time 0.08637944240003889 iter num 20\n",
            "loss 1.8788468837738037 average time 0.04457665220002127 iter num 40\n",
            "loss 0.325810045003891 average time 0.03063395093337628 iter num 60\n",
            "loss 1.2590737342834473 average time 0.02367775578754845 iter num 80\n",
            "loss 0.23557542264461517 average time 0.019526682030054872 iter num 100\n",
            "loss 45.63452911376953 average time 0.08797885860012684 iter num 20\n",
            "loss 20.33307647705078 average time 0.04561393275000682 iter num 40\n",
            "loss 1.4874191284179688 average time 0.03149444151663374 iter num 60\n",
            "loss 2.4576759338378906 average time 0.024487886887447984 iter num 80\n",
            "loss 0.9039429426193237 average time 0.020237769149962333 iter num 100\n",
            "loss 3.1655044555664062 average time 0.08804203760005294 iter num 20\n",
            "loss 1.091253399848938 average time 0.0456350865000104 iter num 40\n",
            "loss 1.1566401720046997 average time 0.03148894210001648 iter num 60\n",
            "loss 0.30871495604515076 average time 0.024402633762497315 iter num 80\n",
            "loss 1.7740631103515625 average time 0.020243101840014786 iter num 100\n",
            "loss 8.323776245117188 average time 0.08771722960000261 iter num 20\n",
            "loss 1.9280627965927124 average time 0.04547905117501614 iter num 40\n",
            "loss 0.3444431722164154 average time 0.03141435799999878 iter num 60\n",
            "loss 0.8816009759902954 average time 0.02437831293751742 iter num 80\n",
            "loss 1.8320825099945068 average time 0.020167227199999617 iter num 100\n",
            "loss 2.9997599124908447 average time 0.08766916719991968 iter num 20\n",
            "loss 0.413992702960968 average time 0.04544861012493584 iter num 40\n",
            "loss 0.691114604473114 average time 0.03135294010000204 iter num 60\n",
            "loss 1.667313814163208 average time 0.02430264257500312 iter num 80\n",
            "loss 0.38117125630378723 average time 0.020088128060006056 iter num 100\n",
            "loss 1.7331620454788208 average time 0.08736602904996289 iter num 20\n",
            "loss 6.997175216674805 average time 0.04527622342493487 iter num 40\n",
            "loss 1.2691597938537598 average time 0.03122996841658884 iter num 60\n",
            "loss 1.642198085784912 average time 0.02428010344993936 iter num 80\n",
            "loss 0.5384716391563416 average time 0.02007180916996731 iter num 100\n",
            "loss 0.5700620412826538 average time 0.08790043095009423 iter num 20\n",
            "loss 7.03632116317749 average time 0.045610568400047666 iter num 40\n",
            "loss 2.262082815170288 average time 0.03155983661670992 iter num 60\n",
            "loss 0.25104260444641113 average time 0.024459008787482618 iter num 80\n",
            "loss 0.980328381061554 average time 0.020204682139974464 iter num 100\n",
            "loss 0.38658303022384644 average time 0.08786969990005673 iter num 20\n",
            "loss 3.084851026535034 average time 0.04554537590004202 iter num 40\n",
            "loss 19.661054611206055 average time 0.03132718875002259 iter num 60\n",
            "loss 2.6815624237060547 average time 0.024177839875005703 iter num 80\n",
            "loss 0.9441738128662109 average time 0.01988899678002781 iter num 100\n",
            "loss 0.21826621890068054 average time 0.08600250475001303 iter num 20\n",
            "loss 2.5785977840423584 average time 0.04444626424997296 iter num 40\n",
            "loss 0.23355287313461304 average time 0.030555436249975778 iter num 60\n",
            "loss 0.14885301887989044 average time 0.023595993874937448 iter num 80\n",
            "loss 0.6524809002876282 average time 0.019434526599952734 iter num 100\n",
            "loss 0.8720680475234985 average time 0.08613747764998152 iter num 20\n",
            "loss 1.5272823572158813 average time 0.04447066222503508 iter num 40\n",
            "loss 1.5643812417984009 average time 0.030566591216650826 iter num 60\n",
            "loss 0.304756760597229 average time 0.023602010037484432 iter num 80\n",
            "loss 0.18532970547676086 average time 0.01945569295002315 iter num 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsadwOuJph79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7920367-254a-4440-adf4-aa471e31ea2e"
      },
      "source": [
        "a = np.array([[2.5661e+01, 9.5063e-01],\n",
        "        [6.5737e-07, 3.5066e-06]])\n",
        "b = np.array([[32.7189,  0.9209],\n",
        "        [ 1.5464,  0.3001]])\n",
        "((a-b)**2).mean(axis=0).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "26.148122557568712"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c496018d-f716-41b8-b52c-a54921b0403c"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 0.8, 0.8, 0.25, 0.05, 0.05]]).cuda() # T, K, S, sigma, mu, r\n",
        "print('price: ' + str(model(inputs.float())))\n",
        "\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient[0][[2]]\n",
        "\n",
        "# price, delta\n",
        "# should be around (0.098688, 0.627409)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: tensor([[0.0882]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.5334], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_2AXrPt7bNj",
        "outputId": "b1af42c3-0211-400e-b37a-6b56cceda831"
      },
      "source": [
        "numstocks = 1\n",
        "numsteps = 50\n",
        "numpaths = 1000000\n",
        "\n",
        "rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.05]*numstocks)\n",
        "r = drift\n",
        "cov = jnp.identity(numstocks)*0.25*0.25\n",
        "initial_stocks = jnp.array([0.8]*numstocks) # must be float\n",
        "T = 1.0\n",
        "K = 0.8\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "\n",
        "# delta test\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.09872279\n",
            "[0.62781]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMq_9z4e1OiO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302097a2-2877-4d65-8624-6535b880e7da"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 110.0, 100.0, 0.25, 0.05, 0.05]]).cuda() # T, K, S, sigma, mu, r\n",
        "print('price, delta: ' + str(model(inputs.float())))\n",
        "\n",
        "# inputs.requires_grad = True\n",
        "# x = model(inputs.float())\n",
        "# x.backward()\n",
        "# first_order_gradient = inputs.grad\n",
        "# first_order_gradient[0][[2]]\n",
        "\n",
        "# should be 8.058, 0.478"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price, delta: tensor([[7.9458, 0.5370]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKx_UH-k1o0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "708c125e-4ab0-4a73-9c89-86a05a477b94"
      },
      "source": [
        "numstocks = 1\n",
        "numsteps = 50\n",
        "numpaths = 1000000\n",
        "\n",
        "rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.05]*numstocks)\n",
        "r = drift\n",
        "cov = jnp.identity(numstocks)*0.25*0.25\n",
        "initial_stocks = jnp.array([100.0]*numstocks) # must be float\n",
        "T = 1.0\n",
        "K = 110.0\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "\n",
        "# delta test\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8.058222\n",
            "[0.47825053]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "lwApH0GT9bBK",
        "outputId": "40d6b4de-6475-48db-c73a-cd5cbf61c3b1"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 0.5, S, 0.25, 0.05, 0.05]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "prices = np.arange(0, 1, 0.01)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7efe2bbdc190>]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPT31tpTOibD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "4e3b6dfc-8f31-43e6-e6a7-dc47cb141ffc"
      },
      "source": [
        "import pylab\n",
        "import numpy as np\n",
        "prices = np.arange(0, 200, 1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    inputs = torch.tensor([[1, 110.0, p, 0.25, 0.05, 0.05]]).cuda() # T, K, S, sigma, mu, r\n",
        "    deltas.append(model(inputs.float())[0][1])\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe6d0050150>]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}