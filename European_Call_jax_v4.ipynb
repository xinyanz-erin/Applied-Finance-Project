{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "European_Call_jax.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Lilian/European_Call_jax_v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUAoeddX9Kr0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eb4fc4f-7608-4abf-ad10-1c0f27be2511"
      },
      "source": [
        "!curl https://colab.chainer.org/install |sh -\n",
        "import cupy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1580  100  1580    0     0   4501      0 --:--:-- --:--:-- --:--:--  4488\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "\u001b[K     |████████████████████████████████| 59.0 MB 54 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 57.4 MB/s \n",
            "\u001b[?25h  Building wheel for chainer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "+ set +ex\n",
            "Installation succeeded!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1RYKgBifCYw"
      },
      "source": [
        "# Test (Skip this if not trying to test, to make sure that functions are defined correctly in cells below without running this cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWYfON_marpj",
        "outputId": "fbc039f8-6e3b-450d-d8b6-bdf8eceb8137"
      },
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T):\n",
        "  return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
        "\n",
        "numstocks = 3\n",
        "# numstocks = 4\n",
        "numsteps = 50\n",
        "numpaths = 100000\n",
        "\n",
        "rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.]*numstocks)\n",
        "r = drift\n",
        "cov = jnp.identity(numstocks)*0.25*0.25\n",
        "initial_stocks = jnp.array([100.]*numstocks) # must be float\n",
        "T = 1.0\n",
        "K = 110.0\n",
        "\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "keys = jax.random.split(key, numpaths)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "%timeit optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T)\n",
        "\n",
        "# delta test\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "%timeit goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.347999\n",
            "100 loops, best of 5: 5.29 ms per loop\n",
            "[0.09289159 0.09300379 0.09274059]\n",
            "10 loops, best of 5: 45 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxFUnc_iBVcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ffd6a74-f160-4129-cad9-261e9d65a6fb"
      },
      "source": [
        "%%writefile cupy_dataset.py\n",
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T, keys): # need to pass 'keys'\n",
        "    return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
        "\n",
        "###################################################################################################\n",
        "# these 2 functions must be defined outside class in order to be used in 'optionvalueavg' function\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "###################################################################################################\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len, number_path, batch, seed, stocks):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 50\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = 1.0 # assume T = 1, use float here\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros((self.N_BATCH, 1 + self.N_STOCKS), dtype=cupy.float32) # output: price, delta1, delta2, delta3\n",
        "        X = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "\n",
        "        for op in range(self.N_BATCH):\n",
        "          \n",
        "          rng = jax.random.PRNGKey(self.seed)\n",
        "          rng, key = jax.random.split(rng)\n",
        "\n",
        "          ################################################################################################### generate random input numbers\n",
        "\n",
        "          initial_stocks = jnp.array(np.random.random(self.N_STOCKS) * 200.0)\n",
        "\n",
        "          corr = jnp.diag(jnp.array([1]*self.N_STOCKS)) # assume no correlation between stocks here\n",
        "          sigma = jnp.array(np.random.random(self.N_STOCKS) * 0.4)\n",
        "          cov = (jnp.diag(sigma)).dot(corr).dot(jnp.diag(sigma))\n",
        "\n",
        "          r = jnp.repeat(jnp.array(np.random.random(1) * 0.1), self.N_STOCKS)\n",
        "          drift = r # To match BS, use drift = r\n",
        "\n",
        "          T = self.T\n",
        "          K = np.random.random(1) * 200.0\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### apply functions to compute price and deltas\n",
        "          \n",
        "          keys = jax.random.split(key, self.N_PATHS)\n",
        "\n",
        "          European_Call_price = optionvalueavg(key, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "          gooptionvalue = jax.grad(optionvalueavg, argnums=1)\n",
        "          Deltas = gooptionvalue(keys, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### store input and output numbers in X and Y\n",
        "\n",
        "          Y[op, 0] = European_Call_price\n",
        "          Y[op, 1:4] = cupy.array(Deltas, dtype=cupy.float32)\n",
        "\n",
        "          paras = (jnp.repeat(jnp.array(T), self.N_STOCKS), jnp.repeat(jnp.array(K), self.N_STOCKS), initial_stocks, sigma, drift, r)\n",
        "          paras = np.column_stack(paras).reshape(1,-1)[0]\n",
        "          X[op,] = cupy.array(paras)\n",
        "\n",
        "          ###################################################################################################\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "ds = OptionDataSet(max_len = 2, number_path = 10000, batch = 2, seed = 15, stocks=3) # for testing purpose, use constant seed. When training, change to random seed\n",
        "for i in ds:\n",
        "    print(i)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cupy_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6JO9OBHdvv",
        "outputId": "b5928199-f4ec-4ced-ee22-9edddb039311"
      },
      "source": [
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*3, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 4) # 4 outputs: price, delta1, delta2, delta3\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1, 200.0, 200.0, 0.4, 0.1, 0.1]*3)) # don't use numpy here - will give error later\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlXD80xPNVc6",
        "outputId": "d31ac109-afe0-4604-e5db-160c64d8eba8"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 4.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S3CyULkENYKb",
        "outputId": "e20701c9-6531-4d54-833d-57fd3390d7b3"
      },
      "source": [
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 1024, batch = 32, seed = np.random.randint(10000), stocks = 3) # must have random seed\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    y_pred = model(x)\n",
        "    # print(y_pred)\n",
        "    # print(y.mean(axis=0))\n",
        "    loss_weight = y.mean(axis=0)[0]/y.mean(axis=0)\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    # print(loss_weight)\n",
        "    # print(loss_weight_normalized)\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean() # compute weighted MSE between the 2 arrays\n",
        "    # print((y_pred - y) ** 2)\n",
        "    # print((y_pred - y) ** 2 * loss_weight_normalized)\n",
        "    # print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(tensor([[1.0000e+00, 6.0895e+01, 1.6976e+02, 1.4462e-01, 3.0592e-02, 3.0592e-02,\n",
            "         1.0000e+00, 6.0895e+01, 3.5779e+01, 1.1016e-01, 3.0592e-02, 3.0592e-02,\n",
            "         1.0000e+00, 6.0895e+01, 1.0873e+01, 2.1200e-01, 3.0592e-02, 3.0592e-02],\n",
            "        [1.0000e+00, 4.2110e+01, 2.2348e+01, 1.0566e-01, 8.0708e-02, 8.0708e-02,\n",
            "         1.0000e+00, 4.2110e+01, 4.9980e+01, 2.8711e-01, 8.0708e-02, 8.0708e-02,\n",
            "         1.0000e+00, 4.2110e+01, 1.8353e+02, 3.4629e-01, 8.0708e-02, 8.0708e-02]],\n",
            "       device='cuda:0'), tensor([[13.0921,  0.3222,  0.3202,  0.3194],\n",
            "        [46.3468,  0.3328,  0.3346,  0.3325]], device='cuda:0'))\n",
            "(tensor([[1.0000e+00, 9.4695e+01, 3.3449e+01, 8.0092e-02, 7.6051e-02, 7.6051e-02,\n",
            "         1.0000e+00, 9.4695e+01, 9.3413e+00, 3.9942e-01, 7.6051e-02, 7.6051e-02,\n",
            "         1.0000e+00, 9.4695e+01, 7.8845e+00, 1.4911e-01, 7.6051e-02, 7.6051e-02],\n",
            "        [1.0000e+00, 1.0755e+02, 1.0194e+02, 1.8604e-01, 2.9900e-02, 2.9900e-02,\n",
            "         1.0000e+00, 1.0755e+02, 1.8901e+02, 5.6622e-02, 2.9900e-02, 2.9900e-02,\n",
            "         1.0000e+00, 1.0755e+02, 2.1889e+01, 2.1534e-01, 2.9900e-02, 2.9900e-02]],\n",
            "       device='cuda:0'), tensor([[0.0000, 0.0000, 0.0000, 0.0000],\n",
            "        [2.8591, 0.1765, 0.1600, 0.1622]], device='cuda:0'))\n",
            "loss 0.707373321056366 average time 0.17401717455001062 iter num 20\n",
            "loss 0.8547555208206177 average time 0.08867870160000421 iter num 40\n",
            "loss 0.7555112242698669 average time 0.06008871416666845 iter num 60\n",
            "loss 0.4473172426223755 average time 0.0457764607625009 iter num 80\n",
            "loss 0.4839034974575043 average time 0.037188271889999666 iter num 100\n",
            "loss 0.09129669517278671 average time 0.053970814150000025 iter num 20\n",
            "loss 0.024101918563246727 average time 0.02841295652500122 iter num 40\n",
            "loss 0.011782379820942879 average time 0.019909920533333056 iter num 60\n",
            "loss 0.010000393725931644 average time 0.015641773762500578 iter num 80\n",
            "loss 0.010667210444808006 average time 0.013083218010001474 iter num 100\n",
            "loss 0.005583001766353846 average time 0.053941901200005304 iter num 20\n",
            "loss 0.004098751116544008 average time 0.028392897950007524 iter num 40\n",
            "loss 0.0033262509386986494 average time 0.019917204833340443 iter num 60\n",
            "loss 0.001763652660883963 average time 0.0156896859375081 iter num 80\n",
            "loss 0.003071390325203538 average time 0.013128155760009577 iter num 100\n",
            "loss 0.0019999099895358086 average time 0.0539805971499959 iter num 20\n",
            "loss 0.0006026664050295949 average time 0.028478623974996252 iter num 40\n",
            "loss 0.0009551363764330745 average time 0.019937610049998965 iter num 60\n",
            "loss 0.000987542443908751 average time 0.015668096762502158 iter num 80\n",
            "loss 0.0010377446888014674 average time 0.013104845070004104 iter num 100\n",
            "loss 0.0009073317050933838 average time 0.053998791349982866 iter num 20\n",
            "loss 0.0005871556932106614 average time 0.028422145924989196 iter num 40\n",
            "loss 0.000269104668404907 average time 0.019908763816662636 iter num 60\n",
            "loss 0.0006713225739076734 average time 0.015646979287497233 iter num 80\n",
            "loss 0.0010686877649277449 average time 0.013089618829998245 iter num 100\n",
            "loss 0.002191687934100628 average time 0.053676239399999305 iter num 20\n",
            "loss 0.0016194103518500924 average time 0.028282004925000593 iter num 40\n",
            "loss 0.00032581129926256835 average time 0.019899070599999884 iter num 60\n",
            "loss 0.0005504153668880463 average time 0.0156376465749986 iter num 80\n",
            "loss 0.00023478367074858397 average time 0.013094789159997617 iter num 100\n",
            "loss 0.001123788533732295 average time 0.05382521525000925 iter num 20\n",
            "loss 0.001268207561224699 average time 0.02840404197500277 iter num 40\n",
            "loss 0.00045293039875105023 average time 0.01988481630000365 iter num 60\n",
            "loss 0.0003670801525004208 average time 0.015620764725004222 iter num 80\n",
            "loss 0.0004493330779951066 average time 0.013059034549995659 iter num 100\n",
            "loss 0.0004885224625468254 average time 0.05335689675004005 iter num 20\n",
            "loss 0.0006648364360444248 average time 0.028104049675033594 iter num 40\n",
            "loss 0.0006655367906205356 average time 0.01968634016668981 iter num 60\n",
            "loss 0.0005446800496429205 average time 0.015472025562522163 iter num 80\n",
            "loss 0.00031879020389169455 average time 0.012942535450017658 iter num 100\n",
            "loss 0.0008911804761737585 average time 0.05319379284999286 iter num 20\n",
            "loss 0.0008052870398387313 average time 0.028035609899978907 iter num 40\n",
            "loss 0.00039163866313174367 average time 0.019632845816651447 iter num 60\n",
            "loss 0.0003363906289450824 average time 0.015429368287487932 iter num 80\n",
            "loss 0.00038156312075443566 average time 0.01292440387998795 iter num 100\n",
            "loss 0.001434427686035633 average time 0.05332782220000354 iter num 20\n",
            "loss 0.0012263788376003504 average time 0.028073047600014434 iter num 40\n",
            "loss 0.0004996228381060064 average time 0.019653994116682345 iter num 60\n",
            "loss 0.00038089664303697646 average time 0.015443962350008177 iter num 80\n",
            "loss 0.000363346392987296 average time 0.012959996610006783 iter num 100\n",
            "loss 0.0008445872808806598 average time 0.053320743350025165 iter num 20\n",
            "loss 0.0009495591511949897 average time 0.02808376787500606 iter num 40\n",
            "loss 0.00028985811513848603 average time 0.019668577683338146 iter num 60\n",
            "loss 0.00038298784056678414 average time 0.015497010975008153 iter num 80\n",
            "loss 0.0005946832243353128 average time 0.013006839070005754 iter num 100\n",
            "loss 0.0002751633001025766 average time 0.05336327235000908 iter num 20\n",
            "loss 0.0007526775007136166 average time 0.028109266749993367 iter num 40\n",
            "loss 0.0008064055582508445 average time 0.01968151728333017 iter num 60\n",
            "loss 0.0005349297425709665 average time 0.015471860762494316 iter num 80\n",
            "loss 0.00020048738224431872 average time 0.012945805179992931 iter num 100\n",
            "loss 0.0006339766550809145 average time 0.053237544499995695 iter num 20\n",
            "loss 0.0004494219901971519 average time 0.028044472624986837 iter num 40\n",
            "loss 0.0006540631875395775 average time 0.019645980616659623 iter num 60\n",
            "loss 0.0004446487291716039 average time 0.01544265139999652 iter num 80\n",
            "loss 0.0004303822061046958 average time 0.012916699359991526 iter num 100\n",
            "loss 0.0012503182515501976 average time 0.05388762190000307 iter num 20\n",
            "loss 0.0009202073561027646 average time 0.02838937822500611 iter num 40\n",
            "loss 0.0005712085403501987 average time 0.019867543966677205 iter num 60\n",
            "loss 0.00036468697362579405 average time 0.01561745762500948 iter num 80\n",
            "loss 0.0002457379305269569 average time 0.013055238490019293 iter num 100\n",
            "loss 0.0008897897787392139 average time 0.05346275504997493 iter num 20\n",
            "loss 0.0017081632977351546 average time 0.02813964107499487 iter num 40\n",
            "loss 0.00025854705017991364 average time 0.019703277533335496 iter num 60\n",
            "loss 0.00020934540953021497 average time 0.01549041755000644 iter num 80\n",
            "loss 0.0001632545463507995 average time 0.012971868199997516 iter num 100\n",
            "loss 0.000661662605125457 average time 0.05409143155004585 iter num 20\n",
            "loss 0.0005208142101764679 average time 0.028505197475016075 iter num 40\n",
            "loss 0.00029288584482856095 average time 0.020087528283344605 iter num 60\n",
            "loss 0.0008612294332124293 average time 0.015778392287506902 iter num 80\n",
            "loss 0.0004957488272339106 average time 0.013194953200002146 iter num 100\n",
            "loss 0.0006298944354057312 average time 0.05324060825001879 iter num 20\n",
            "loss 0.0013421638868749142 average time 0.02806149872499759 iter num 40\n",
            "loss 0.00040470363455824554 average time 0.01967932391667849 iter num 60\n",
            "loss 0.00012506039638537914 average time 0.015477061275001347 iter num 80\n",
            "loss 0.0003955563879571855 average time 0.012946941870011415 iter num 100\n",
            "loss 0.000516386644449085 average time 0.05351142854997306 iter num 20\n",
            "loss 0.0001950470032170415 average time 0.028165419974982342 iter num 40\n",
            "loss 0.0007998822256922722 average time 0.019722891233300288 iter num 60\n",
            "loss 0.0001675244711805135 average time 0.015510511624984246 iter num 80\n",
            "loss 0.0004011421697214246 average time 0.012978326299980835 iter num 100\n",
            "loss 0.0007689808262512088 average time 0.05284647644996312 iter num 20\n",
            "loss 0.0007474649464711547 average time 0.027860175199987226 iter num 40\n",
            "loss 0.00043939496390521526 average time 0.019517217566658474 iter num 60\n",
            "loss 0.00022885450744070113 average time 0.015351520087489235 iter num 80\n",
            "loss 0.0008877408690750599 average time 0.012847412319988507 iter num 100\n",
            "loss 0.0005125938914716244 average time 0.052361342900007914 iter num 20\n",
            "loss 0.001002538949251175 average time 0.027867293950021122 iter num 40\n",
            "loss 0.00019789407087955624 average time 0.019516144933353036 iter num 60\n",
            "loss 0.0007479777559638023 average time 0.01534434188751561 iter num 80\n",
            "loss 0.00025693673524074256 average time 0.012842995550004161 iter num 100\n",
            "loss 0.00889663491398096 average time 0.05359626219992606 iter num 20\n",
            "loss 0.0012064697220921516 average time 0.02820334852495989 iter num 40\n",
            "loss 0.0008489023894071579 average time 0.019735179349959255 iter num 60\n",
            "loss 9.880313882604241e-05 average time 0.015502215237466999 iter num 80\n",
            "loss 0.00023895315825939178 average time 0.012963331009973444 iter num 100\n",
            "loss 0.0006548319361172616 average time 0.05318716025003596 iter num 20\n",
            "loss 0.00024348910665139556 average time 0.02798771205000321 iter num 40\n",
            "loss 0.0005150688230060041 average time 0.019591430383328164 iter num 60\n",
            "loss 0.0003726693685166538 average time 0.015400699562485442 iter num 80\n",
            "loss 0.00039385646232403815 average time 0.01288178693998816 iter num 100\n",
            "loss 0.005785826593637466 average time 0.053040607999992065 iter num 20\n",
            "loss 0.007135422900319099 average time 0.027953708449945224 iter num 40\n",
            "loss 0.0013367347419261932 average time 0.01957637934996607 iter num 60\n",
            "loss 0.0005224986816756427 average time 0.015398776574966178 iter num 80\n",
            "loss 0.00028431069222278893 average time 0.0128833721799856 iter num 100\n",
            "loss 0.0007951700827106833 average time 0.054313913550026884 iter num 20\n",
            "loss 0.0004285043687559664 average time 0.028577593000022716 iter num 40\n",
            "loss 0.000447960221208632 average time 0.01999937678334239 iter num 60\n",
            "loss 0.00043385621393099427 average time 0.015695370300005607 iter num 80\n",
            "loss 0.000345944135915488 average time 0.013120040229996448 iter num 100\n",
            "loss 0.00052567821694538 average time 0.057045856300032935 iter num 20\n",
            "loss 0.00041571189649403095 average time 0.02992413987500413 iter num 40\n",
            "loss 0.0003254070761613548 average time 0.02087784548334639 iter num 60\n",
            "loss 0.00040816652472130954 average time 0.016353668225008278 iter num 80\n",
            "loss 0.0003560631303116679 average time 0.013661619259996769 iter num 100\n",
            "loss 0.000541581423021853 average time 0.05520867690001978 iter num 20\n",
            "loss 0.0013687459286302328 average time 0.029042827150010452 iter num 40\n",
            "loss 0.0012546549551188946 average time 0.02029745360001319 iter num 60\n",
            "loss 0.0007382827461697161 average time 0.015941396875001602 iter num 80\n",
            "loss 0.0002891701878979802 average time 0.013314849500006857 iter num 100\n",
            "loss 0.0017155484529212117 average time 0.05661762049992376 iter num 20\n",
            "loss 0.0013306507607921958 average time 0.029729789474959033 iter num 40\n",
            "loss 0.001218191348016262 average time 0.020780695216634133 iter num 60\n",
            "loss 0.00047714271931909025 average time 0.01628992401248297 iter num 80\n",
            "loss 0.00022363362950272858 average time 0.013604207170001246 iter num 100\n",
            "loss 0.0011756456224247813 average time 0.05267165454997667 iter num 20\n",
            "loss 0.0005673074629157782 average time 0.02774096579998968 iter num 40\n",
            "loss 0.0004627663001883775 average time 0.019428080649997053 iter num 60\n",
            "loss 0.00041743251495063305 average time 0.015280440562492004 iter num 80\n",
            "loss 0.00020332098938524723 average time 0.01278520330999072 iter num 100\n",
            "loss 0.0003998414322268218 average time 0.05350117335001414 iter num 20\n",
            "loss 0.0009361223201267421 average time 0.02815727249995916 iter num 40\n",
            "loss 0.0003893583489116281 average time 0.019702386166621486 iter num 60\n",
            "loss 0.0003319694078527391 average time 0.015478304974976709 iter num 80\n",
            "loss 0.00021772776381112635 average time 0.012956952189979347 iter num 100\n",
            "loss 0.0005463401903398335 average time 0.053461621249994096 iter num 20\n",
            "loss 0.000354273768607527 average time 0.02820479332500554 iter num 40\n",
            "loss 0.0002024588466156274 average time 0.019759641533316122 iter num 60\n",
            "loss 0.0002980268909595907 average time 0.015529055512490685 iter num 80\n",
            "loss 0.0003303928824607283 average time 0.013014827480001259 iter num 100\n",
            "loss 0.0003267478314228356 average time 0.05291651064992493 iter num 20\n",
            "loss 0.0005226710345596075 average time 0.027929028749986172 iter num 40\n",
            "loss 0.00037888126098550856 average time 0.019570958066674395 iter num 60\n",
            "loss 0.00017526389274280518 average time 0.015385632012498717 iter num 80\n",
            "loss 0.000632129842415452 average time 0.012878391130002456 iter num 100\n",
            "loss 0.02982308343052864 average time 0.0527058129000352 iter num 20\n",
            "loss 0.0007820224855095148 average time 0.027809166375050154 iter num 40\n",
            "loss 0.0009511886164546013 average time 0.019527270900046762 iter num 60\n",
            "loss 0.0004144733538851142 average time 0.015342710200053488 iter num 80\n",
            "loss 0.00026190344942733645 average time 0.012837762690041927 iter num 100\n",
            "loss 0.00029089339659549296 average time 0.05480636464999407 iter num 20\n",
            "loss 0.0002917081583291292 average time 0.028825410200010993 iter num 40\n",
            "loss 0.00027483803569339216 average time 0.0201577985666745 iter num 60\n",
            "loss 0.00022821297170594335 average time 0.01581570063748927 iter num 80\n",
            "loss 0.0004380108439363539 average time 0.013221720549986458 iter num 100\n",
            "loss 0.00039989821380004287 average time 0.05364543835003133 iter num 20\n",
            "loss 0.00024105676857288927 average time 0.02822103292501197 iter num 40\n",
            "loss 0.000260677479673177 average time 0.019753600300009565 iter num 60\n",
            "loss 0.0002604252949822694 average time 0.015515037112510299 iter num 80\n",
            "loss 0.00016961697838269174 average time 0.012996003080020272 iter num 100\n",
            "loss 0.0003442177549004555 average time 0.05409544974995697 iter num 20\n",
            "loss 0.00022966499091126025 average time 0.02844042337501378 iter num 40\n",
            "loss 0.00030027018510736525 average time 0.01989731283334398 iter num 60\n",
            "loss 0.00014988487237133086 average time 0.01562733963750702 iter num 80\n",
            "loss 0.0005110630299896002 average time 0.013059108190009282 iter num 100\n",
            "loss 0.0001615590590517968 average time 0.05319709945001705 iter num 20\n",
            "loss 0.0002046573063125834 average time 0.02799695310000061 iter num 40\n",
            "loss 0.00047243069275282323 average time 0.0195917076166855 iter num 60\n",
            "loss 0.00034933691495098174 average time 0.015403237737530162 iter num 80\n",
            "loss 0.0001547254651086405 average time 0.012883294300031593 iter num 100\n",
            "loss 0.0003420598804950714 average time 0.053427342950044476 iter num 20\n",
            "loss 0.0007816564757376909 average time 0.02810486124998306 iter num 40\n",
            "loss 0.0004604317364282906 average time 0.019661414049998407 iter num 60\n",
            "loss 0.0001904070086311549 average time 0.015449629624998806 iter num 80\n",
            "loss 0.00031904064235277474 average time 0.012918804199989609 iter num 100\n",
            "loss 0.00035769373062066734 average time 0.05495248835009079 iter num 20\n",
            "loss 0.0007041256176307797 average time 0.02893179550003424 iter num 40\n",
            "loss 0.0005902411649003625 average time 0.020217501916674034 iter num 60\n",
            "loss 0.00023129445617087185 average time 0.01586206033749704 iter num 80\n",
            "loss 0.0004997681244276464 average time 0.013302303340014986 iter num 100\n",
            "loss 0.00028631321038119495 average time 0.05318177614999513 iter num 20\n",
            "loss 0.0009183950023725629 average time 0.028004670399968744 iter num 40\n",
            "loss 0.0007187902228906751 average time 0.0196041419166401 iter num 60\n",
            "loss 0.00021966802887618542 average time 0.015404525849965012 iter num 80\n",
            "loss 0.0002702971105463803 average time 0.012883442779975668 iter num 100\n",
            "loss 0.0006488041253760457 average time 0.052763255450099675 iter num 20\n",
            "loss 0.0010768952779471874 average time 0.02777917697508201 iter num 40\n",
            "loss 0.00032062060199677944 average time 0.019450477466686305 iter num 60\n",
            "loss 0.0002799620560836047 average time 0.01529477840005029 iter num 80\n",
            "loss 0.00040655152406543493 average time 0.012798480260062205 iter num 100\n",
            "loss 0.00036287031252868474 average time 0.054104443750065914 iter num 20\n",
            "loss 0.0018343585543334484 average time 0.028464214774999164 iter num 40\n",
            "loss 0.00039717770414426923 average time 0.019907586866672013 iter num 60\n",
            "loss 0.00035855366149917245 average time 0.015637746900017645 iter num 80\n",
            "loss 0.0004030077834613621 average time 0.013098941630041737 iter num 100\n",
            "loss 0.0007423888891935349 average time 0.05233666134986379 iter num 20\n",
            "loss 0.000116231560241431 average time 0.027613676724968172 iter num 40\n",
            "loss 0.00032419117633253336 average time 0.01935509573328697 iter num 60\n",
            "loss 0.00016730128845665604 average time 0.015267791837527512 iter num 80\n",
            "loss 0.00025871663819998503 average time 0.012778530510004202 iter num 100\n",
            "loss 0.000296037585940212 average time 0.05323602160001428 iter num 20\n",
            "loss 0.0006268530851230025 average time 0.028009356000006848 iter num 40\n",
            "loss 0.0003684686089400202 average time 0.019609161950014217 iter num 60\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-d6c4efa88746>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m           \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDeltas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m           \u001b[0mparas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STOCKS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STOCKS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m           \u001b[0mparas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m           \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36marray\u001b[0;34m(object, dtype, copy, order, ndmin)\u001b[0m\n\u001b[1;32m   3567\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unexpected input type for array: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3569\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_element_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweak_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3571\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mndmin\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_convert_element_type\u001b[0;34m(operand, new_dtype, weak_type)\u001b[0m\n\u001b[1;32m    441\u001b[0m   \u001b[0mnew_weak_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweak_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m   if (dtypes.issubdtype(old_dtype, np.complexfloating) and\n\u001b[0m\u001b[1;32m    444\u001b[0m       not dtypes.issubdtype(new_dtype, np.complexfloating)):\n\u001b[1;32m    445\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Casting complex values to real discards the imaginary part\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/dtypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"bfloat16\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbfloat16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbfloat16\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d79d52cb-3f6e-439f-b08d-7aceb6d90e20"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\\"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_test_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Lilian/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68143c2c-f53e-456a-d1e7-8928256f5f40"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc415c28-acc7-45a8-ae5e-1caf98c0ea43"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_test_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Lilian/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87534b99-08ed-45eb-f4e1-f9d177387268"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=18, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc5): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc6): Linear(in_features=1024, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "367c5f22-e3cd-484c-91ee-fb62ac9b969d"
      },
      "source": [
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "#dataset = OptionDataSet(max_len = 100, number_path = 1024, batch = 32, seed = np.random.randint(10000), stocks = 3) # must have random seed\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 10000, batch = 8, seed = np.random.randint(10000), stocks = 3) # must have random seed\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    y_pred = model(x)\n",
        "    # print(y_pred)\n",
        "    # print(y.mean(axis=0))\n",
        "    loss_weight = y.mean(axis=0)[0]/y.mean(axis=0)\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    # print('weights', loss_weight)\n",
        "    print('y', y.mean(axis=0))\n",
        "    # print(loss_weight_normalized)\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean() # compute weighted MSE between the 2 arrays\n",
        "    # print((y_pred - y) ** 2)\n",
        "    # print((y_pred - y) ** 2 * loss_weight_normalized)\n",
        "    # print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 10)\n",
        "\n",
        "model_save_name = 'jax_european_test_2.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Lilian/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y tensor([[ 21.9164,   0.3336,   0.3334,   0.3324],\n",
            "        [ 50.4300,   0.3334,   0.3337,   0.3329],\n",
            "        [108.7805,   0.3335,   0.3337,   0.3332],\n",
            "        [ 30.1778,   0.3272,   0.3260,   0.3276],\n",
            "        [ 66.8723,   0.3337,   0.3337,   0.3325],\n",
            "        [132.2012,   0.3334,   0.3335,   0.3319],\n",
            "        [ 73.4874,   0.3335,   0.3337,   0.3328],\n",
            "        [  0.0000,   0.0000,   0.0000,   0.0000]], device='cuda:0')\n",
            "y tensor([[9.3234e-02, 5.9945e-03, 3.2655e-03, 3.2851e-03],\n",
            "        [1.9864e+01, 3.1316e-01, 3.0768e-01, 3.1353e-01],\n",
            "        [6.8331e+01, 3.3358e-01, 3.3362e-01, 3.3314e-01],\n",
            "        [5.3689e+01, 3.3363e-01, 3.3331e-01, 3.3213e-01],\n",
            "        [2.9862e+00, 1.8667e-01, 1.7602e-01, 2.1658e-01],\n",
            "        [6.9332e+01, 3.3352e-01, 3.3335e-01, 3.3089e-01],\n",
            "        [6.8121e+01, 3.3378e-01, 3.3363e-01, 3.3233e-01],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0')\n",
            "y tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [1.4892e+00, 9.4360e-02, 1.0007e-01, 1.3305e-01],\n",
            "        [1.5607e+01, 3.2969e-01, 3.2966e-01, 3.2862e-01],\n",
            "        [5.6630e+01, 3.3378e-01, 3.3354e-01, 3.3211e-01],\n",
            "        [3.2815e-02, 7.6573e-04, 7.5729e-04, 2.1101e-03],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [8.2523e-02, 2.2841e-03, 3.5349e-03, 5.3964e-03],\n",
            "        [4.7293e+01, 3.3351e-01, 3.3365e-01, 3.3235e-01]], device='cuda:0')\n",
            "y tensor([[7.5502e+00, 3.1972e-01, 3.2444e-01, 3.1977e-01],\n",
            "        [2.2376e-03, 1.5791e-04, 4.5148e-04, 1.3408e-04],\n",
            "        [3.7025e-01, 2.1072e-02, 1.0337e-02, 1.0274e-02],\n",
            "        [4.2863e+01, 3.3377e-01, 3.3365e-01, 3.3288e-01],\n",
            "        [1.1457e+02, 3.3348e-01, 3.3365e-01, 3.3177e-01],\n",
            "        [3.7241e+01, 3.3344e-01, 3.3347e-01, 3.3106e-01],\n",
            "        [3.3268e-03, 1.9367e-04, 4.0150e-04, 1.9679e-04],\n",
            "        [9.7534e-01, 2.7904e-02, 4.4671e-02, 3.0906e-02]], device='cuda:0')\n",
            "y tensor([[5.2748e-03, 4.5690e-04, 1.6736e-04, 2.5870e-04],\n",
            "        [4.4368e+00, 1.3318e-01, 1.8008e-01, 1.4095e-01],\n",
            "        [3.0280e+01, 3.2351e-01, 3.2142e-01, 3.1445e-01],\n",
            "        [4.3181e+01, 3.3174e-01, 3.3143e-01, 3.3032e-01],\n",
            "        [6.4514e+00, 1.7653e-01, 1.4254e-01, 1.3539e-01],\n",
            "        [1.0584e+02, 3.3359e-01, 3.3361e-01, 3.3082e-01],\n",
            "        [2.4614e+00, 1.0705e-01, 7.7259e-02, 7.6729e-02],\n",
            "        [1.4654e+01, 3.3307e-01, 3.3162e-01, 3.3120e-01]], device='cuda:0')\n",
            "y tensor([[1.2764e+01, 2.8748e-01, 2.7795e-01, 2.8354e-01],\n",
            "        [3.4426e-01, 1.8270e-02, 1.0484e-02, 8.3397e-03],\n",
            "        [1.3506e+00, 5.2291e-02, 2.6959e-02, 2.6755e-02],\n",
            "        [1.7101e+00, 1.9127e-01, 1.9070e-01, 2.0312e-01],\n",
            "        [1.0626e+01, 3.1743e-01, 3.2290e-01, 3.1180e-01],\n",
            "        [1.1464e+02, 3.3378e-01, 3.3365e-01, 3.3325e-01],\n",
            "        [2.6304e+01, 3.0852e-01, 2.9579e-01, 2.9805e-01],\n",
            "        [7.0203e+00, 1.5082e-01, 1.5380e-01, 1.8416e-01]], device='cuda:0')\n",
            "y tensor([[75.5300,  0.3333,  0.3336,  0.3316],\n",
            "        [60.5151,  0.3334,  0.3336,  0.3319],\n",
            "        [70.0303,  0.3334,  0.3336,  0.3329],\n",
            "        [39.6608,  0.3334,  0.3333,  0.3309],\n",
            "        [39.9718,  0.3335,  0.3336,  0.3326],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000],\n",
            "        [37.1304,  0.3215,  0.3230,  0.3144],\n",
            "        [ 0.0000,  0.0000,  0.0000,  0.0000]], device='cuda:0')\n",
            "y tensor([[1.3900e+01, 3.3375e-01, 3.3356e-01, 3.3314e-01],\n",
            "        [2.5726e+01, 3.2984e-01, 3.3051e-01, 3.2935e-01],\n",
            "        [3.9201e+01, 3.3335e-01, 3.3365e-01, 3.3305e-01],\n",
            "        [2.1691e+01, 3.3244e-01, 3.3309e-01, 3.3074e-01],\n",
            "        [7.9218e-02, 7.8861e-03, 4.7753e-03, 4.7170e-03],\n",
            "        [8.8547e+01, 3.3355e-01, 3.3352e-01, 3.3090e-01],\n",
            "        [1.1580e+02, 3.3371e-01, 3.3364e-01, 3.3268e-01],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0')\n",
            "y tensor([[4.2819e-02, 1.1364e-03, 1.2168e-03, 2.7359e-03],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [5.8880e+01, 3.3368e-01, 3.3333e-01, 3.3181e-01],\n",
            "        [1.0437e+02, 3.3335e-01, 3.3342e-01, 3.3312e-01],\n",
            "        [1.6064e+00, 3.7969e-02, 3.8087e-02, 5.9546e-02],\n",
            "        [1.8706e+01, 2.6137e-01, 2.9114e-01, 2.6070e-01],\n",
            "        [1.2558e+02, 3.3366e-01, 3.3354e-01, 3.3193e-01],\n",
            "        [4.3826e+01, 3.3316e-01, 3.3343e-01, 3.3130e-01]], device='cuda:0')\n",
            "y tensor([[1.6744e-01, 1.0380e-02, 6.1534e-03, 5.5599e-03],\n",
            "        [9.9470e-01, 3.0810e-02, 2.5834e-02, 3.7349e-02],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [8.2944e-01, 4.7151e-02, 4.9392e-02, 5.5644e-02],\n",
            "        [5.1912e-01, 1.7288e-02, 3.3500e-02, 1.7080e-02],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [5.5939e-01, 3.2909e-02, 2.0947e-02, 1.8390e-02],\n",
            "        [7.8422e+00, 1.6786e-01, 1.7783e-01, 1.9426e-01]], device='cuda:0')\n",
            "y tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [1.2259e-01, 1.2484e-02, 1.1970e-02, 9.9284e-03],\n",
            "        [5.6553e+01, 3.3084e-01, 3.3192e-01, 3.2916e-01],\n",
            "        [7.6594e+01, 3.3349e-01, 3.3350e-01, 3.3126e-01],\n",
            "        [3.1780e+01, 3.2940e-01, 3.3064e-01, 3.2805e-01],\n",
            "        [1.3662e+02, 3.3376e-01, 3.3338e-01, 3.3124e-01],\n",
            "        [8.1776e+01, 3.3367e-01, 3.3344e-01, 3.3245e-01]], device='cuda:0')\n",
            "y tensor([[3.0744e-04, 3.0402e-05, 3.4680e-05, 5.6923e-05],\n",
            "        [3.8926e+01, 3.3356e-01, 3.3365e-01, 3.3233e-01],\n",
            "        [1.0465e+02, 3.3374e-01, 3.3365e-01, 3.3299e-01],\n",
            "        [1.0047e+01, 2.8575e-01, 2.5878e-01, 2.6217e-01],\n",
            "        [1.2389e+01, 2.2695e-01, 2.3966e-01, 2.2527e-01],\n",
            "        [2.0881e+01, 3.2865e-01, 3.3173e-01, 3.2854e-01],\n",
            "        [2.6247e+01, 3.3343e-01, 3.3365e-01, 3.3097e-01],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y tensor([[9.0799e+01, 3.3350e-01, 3.3347e-01, 3.3247e-01],\n",
            "        [8.4563e+01, 3.3354e-01, 3.3362e-01, 3.3191e-01],\n",
            "        [2.1804e-04, 3.8358e-05, 5.3592e-05, 3.6533e-05],\n",
            "        [2.2041e+01, 2.9543e-01, 2.6903e-01, 2.7431e-01],\n",
            "        [9.6703e+00, 1.5667e-01, 1.6322e-01, 1.4402e-01],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
            "        [3.2991e+01, 3.0783e-01, 3.1134e-01, 2.9725e-01]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-3943cd138ca8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0mmodel_save_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'jax_european_test_2.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m           \u001b[0;31m################################################################################################### generate random input numbers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m           \u001b[0minitial_stocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STOCKS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m200.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m           \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STOCKS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# assume no correlation between stocks here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36marray\u001b[0;34m(object, dtype, copy, order, ndmin)\u001b[0m\n\u001b[1;32m   3567\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unexpected input type for array: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3569\u001b[0;31m   \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_element_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweak_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweak_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3571\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mndmin\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36m_convert_element_type\u001b[0;34m(operand, new_dtype, weak_type)\u001b[0m\n\u001b[1;32m    459\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m     return convert_element_type_p.bind(operand, new_dtype=new_dtype,\n\u001b[0;32m--> 461\u001b[0;31m                                        weak_type=new_weak_type)\n\u001b[0m\u001b[1;32m    462\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbitcast_convert_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperand\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_dtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDType\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mArray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         args, used_axis_names(self, params) if self._dispatch_on_params else None)\n\u001b[1;32m    266\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    274\u001b[0m   \u001b[0;34m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m   \u001b[0mcompiled_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxla_primitive_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0munsafe_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled_primitive\u001b[0;34m(prim, compiled, result_handler, *args)\u001b[0m\n\u001b[1;32m    390\u001b[0m   \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m   \u001b[0minput_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_put\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m   \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d47bdb02-468d-4e7f-c2e9-9b06dc55bacb"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 110.0, 100.0, 0.25, 0., 0.]*3]).cuda()\n",
        "model(inputs.float())\n",
        "\n",
        "# price, delta1, delta2, delta3\n",
        "# should be around (2.3654, 0.0937, 0.0937, 0.0937)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.4093, 0.0905, 0.0895, 0.0923]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJgMDQ3yUPWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbcb3413-b3fa-4167-aef0-1fba574ad604"
      },
      "source": [
        "model(inputs.float())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.4093, 0.0905, 0.0895, 0.0923]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vusLScDmUvvz"
      },
      "source": [
        "import pylab\n",
        "prices = np.arange(0, 200, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "  inputs = torch.tensor([[1, 110.0, p, 0.25, 0., 0.]*3]).cuda()\n",
        "  res = model(inputs.float())\n",
        "  deltas.append(res[0][1]) # delta for S1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAb3DlWqtPga"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6_Hcmn8nZZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "544eb4b0-7aa6-47e5-8172-26023d98cdcd"
      },
      "source": [
        "res"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[89.4700,  0.3305,  0.3187,  0.3186]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYYoLU_Gek7I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "70890dd6-ee14-4d51-db29-3040d19976c7"
      },
      "source": [
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fefcee58c90>]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBuv8ElbRJOP"
      },
      "source": [
        "# Gamma"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEf2H8AJQ07U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "9a612fd4-fda1-4dca-c792-671c4d6be8bc"
      },
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import grad\n",
        "from torch import nn\n",
        "# inputs = torch.tensor([[1, 110.0, p, 0.25, 0., 0.]*3]).cuda()\n",
        "# inputs.requires_grad = True\n",
        "# x = model(inputs)[0][1]\n",
        "# loss_grads = grad(x, inputs, create_graph=True)\n",
        "# loss_grads[0][0][2]\n",
        "\n",
        "\n",
        "prices = np.arange(0, 200, 0.1)\n",
        "gamma = []\n",
        "for p in prices:\n",
        "  inputs = torch.tensor([[1, 110.0, p, 0.25, 0., 0.]*3]).cuda()\n",
        "  inputs.requires_grad = True\n",
        "  x = model(inputs.float())[0][1]\n",
        "  loss_grads = grad(x, inputs, create_graph=True)\n",
        "  gamma.append(loss_grads[0][0][2]) # delta for S1\n",
        "\n",
        "fig = pylab.plot(prices, gamma)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Gamma')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fefced48f90>]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}