{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grid Test_Knock Out Call 1stock_Final Version",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Final/Grid_Test_Knock_Out_Call_1stock_Final_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYigDkiy0HU9",
        "outputId": "1c3f7bcc-263d-4ad4-967b-ef28796c3191"
      },
      "source": [
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "S_range = jnp.linspace(0.75, 1.25, 10)\n",
        "K_range = jnp.linspace(0.75, 1.25, 8)\n",
        "B_range = jnp.linspace(0.5, 1.0, 8)\n",
        "sigma_range = jnp.linspace(0.15, 0.45, 4)\n",
        "r_range = jnp.linspace(0.01, 0.04, 3)\n",
        "\n",
        "print(S_range)\n",
        "print(K_range)\n",
        "print(B_range)\n",
        "print(sigma_range)\n",
        "print(r_range)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.75       0.8055556  0.86111116 0.9166666  0.97222227 1.0277778\n",
            " 1.0833334  1.138889   1.1944445  1.25      ]\n",
            "[0.75       0.82142854 0.89285713 0.9642857  1.0357143  1.1071429\n",
            " 1.1785713  1.25      ]\n",
            "[0.5        0.5714286  0.6428572  0.71428573 0.78571427 0.85714287\n",
            " 0.92857146 1.        ]\n",
            "[0.15       0.25       0.35000002 0.45      ]\n",
            "[0.01  0.025 0.04 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIQxpJqK6OZr"
      },
      "source": [
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T): # down-and-out call\n",
        "    return jnp.mean(jnp.maximum((1 - jnp.any(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2) < B, axis=1).astype(int))* \n",
        "                                (jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2))[:,-1]-K, 0) *\n",
        "                    jnp.exp(-r[0] * T))\n",
        "\n",
        "goptionvalueavg = jax.grad(optionvalueavg, argnums=1)\n",
        "\n",
        "#################################################################### Adjust all parameters here (not inside class)\n",
        "numstocks = 1\n",
        "numsteps = 50\n",
        "numpaths = 2000000\n",
        "\n",
        "rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "rng, key = jax.random.split(rng)\n",
        "keys = jax.random.split(key, numpaths)\n",
        "\n",
        "S_range = jnp.linspace(0.75, 1.25, 10)\n",
        "K_range = jnp.linspace(0.75, 1.25, 8)\n",
        "B_range = jnp.linspace(0.5, 1.0, 8)\n",
        "sigma_range = jnp.linspace(0.15, 0.45, 4)\n",
        "r_range = jnp.linspace(0.01, 0.04, 3)\n",
        "T = 1.0\n",
        "\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "####################################################################\n",
        "\n",
        "call = []\n",
        "count = 0\n",
        "\n",
        "for S in S_range:\n",
        "  for K in K_range:\n",
        "    for B in B_range:\n",
        "      for r in r_range:\n",
        "        for sigma in sigma_range:    \n",
        "\n",
        "          initial_stocks = jnp.array([S]*numstocks) # must be float\n",
        "          r_tmp = jnp.array([r]*numstocks)\n",
        "          drift = r_tmp\n",
        "          cov = jnp.identity(numstocks)*sigma*sigma\n",
        "\n",
        "          Knock_Out_Call_price = optionvalueavg(key, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T)\n",
        "          Deltas = goptionvalueavg(keys, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T)\n",
        "          call.append([T, K, B, S, sigma, r, r, Knock_Out_Call_price] + list(Deltas)) #T, K, B, S, sigma, mu, r, price, delta\n",
        "          \n",
        "          count += 1\n",
        "          print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "e_OUtP8GUwj5",
        "outputId": "a6ef55df-7269-41e7-b14b-c7fdfbd9ef92"
      },
      "source": [
        "Thedataset = pd.DataFrame(call)\n",
        "Thedataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.048392188</td>\n",
              "      <td>0.556177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.07790985</td>\n",
              "      <td>0.564888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.10672783</td>\n",
              "      <td>0.573440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.1332959</td>\n",
              "      <td>0.571065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.054101802</td>\n",
              "      <td>0.595272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7675</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.20006092</td>\n",
              "      <td>0.472318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7676</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.10021045</td>\n",
              "      <td>0.632276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7677</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.14452648</td>\n",
              "      <td>0.584406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7678</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.180067</td>\n",
              "      <td>0.530899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7679</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.207353</td>\n",
              "      <td>0.483880</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7680 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0     1    2     3     4      5      6            7         8\n",
              "0     1.0  0.75  0.5  0.75  0.15  0.010  0.010  0.048392188  0.556177\n",
              "1     1.0  0.75  0.5  0.75  0.25  0.010  0.010   0.07790985  0.564888\n",
              "2     1.0  0.75  0.5  0.75  0.35  0.010  0.010   0.10672783  0.573440\n",
              "3     1.0  0.75  0.5  0.75  0.45  0.010  0.010    0.1332959  0.571065\n",
              "4     1.0  0.75  0.5  0.75  0.15  0.025  0.025  0.054101802  0.595272\n",
              "...   ...   ...  ...   ...   ...    ...    ...          ...       ...\n",
              "7675  1.0  1.25  1.0  1.25  0.45  0.025  0.025   0.20006092  0.472318\n",
              "7676  1.0  1.25  1.0  1.25  0.15  0.040  0.040   0.10021045  0.632276\n",
              "7677  1.0  1.25  1.0  1.25  0.25  0.040  0.040   0.14452648  0.584406\n",
              "7678  1.0  1.25  1.0  1.25  0.35  0.040  0.040     0.180067  0.530899\n",
              "7679  1.0  1.25  1.0  1.25  0.45  0.040  0.040     0.207353  0.483880\n",
              "\n",
              "[7680 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSQKnflf6peX"
      },
      "source": [
        "# save to csv\n",
        "Thedataset.to_csv('Knock_Out_Call_1stock_MC_Datset_v3.csv', index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "skGWSSsG8TGG",
        "outputId": "2333b60c-feff-4138-e533-efadcf72be78"
      },
      "source": [
        "# read csv\n",
        "import pandas as pd\n",
        "\n",
        "Thedataset = pd.read_csv('Knock_Out_Call_1stock_MC_Datset_v3.csv', header=None)\n",
        "Thedataset"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.048392</td>\n",
              "      <td>0.556177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.077910</td>\n",
              "      <td>0.564888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.106728</td>\n",
              "      <td>0.573440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.133296</td>\n",
              "      <td>0.571065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.054102</td>\n",
              "      <td>0.595272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7675</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.200061</td>\n",
              "      <td>0.472318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7676</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.100210</td>\n",
              "      <td>0.632276</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7677</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.144526</td>\n",
              "      <td>0.584406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7678</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.180067</td>\n",
              "      <td>0.530899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7679</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.207353</td>\n",
              "      <td>0.483880</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7680 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0     1    2     3     4      5      6         7         8\n",
              "0     1.0  0.75  0.5  0.75  0.15  0.010  0.010  0.048392  0.556177\n",
              "1     1.0  0.75  0.5  0.75  0.25  0.010  0.010  0.077910  0.564888\n",
              "2     1.0  0.75  0.5  0.75  0.35  0.010  0.010  0.106728  0.573440\n",
              "3     1.0  0.75  0.5  0.75  0.45  0.010  0.010  0.133296  0.571065\n",
              "4     1.0  0.75  0.5  0.75  0.15  0.025  0.025  0.054102  0.595272\n",
              "...   ...   ...  ...   ...   ...    ...    ...       ...       ...\n",
              "7675  1.0  1.25  1.0  1.25  0.45  0.025  0.025  0.200061  0.472318\n",
              "7676  1.0  1.25  1.0  1.25  0.15  0.040  0.040  0.100210  0.632276\n",
              "7677  1.0  1.25  1.0  1.25  0.25  0.040  0.040  0.144526  0.584406\n",
              "7678  1.0  1.25  1.0  1.25  0.35  0.040  0.040  0.180067  0.530899\n",
              "7679  1.0  1.25  1.0  1.25  0.45  0.040  0.040  0.207353  0.483880\n",
              "\n",
              "[7680 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4HV-G44th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "702ae632-9676-4351-ee53-65d0859166d4"
      },
      "source": [
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "import torch\n",
        "torch.set_printoptions(precision=6)\n",
        "\n",
        "Thedataset_X = Thedataset.iloc[:,:7]\n",
        "Thedataset_Y = Thedataset.iloc[:,7:]\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.X = cupy.array(Thedataset_X)\n",
        "        self.Y = cupy.array(Thedataset_Y)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(self.X.toDlpack()), from_dlpack(self.Y.toDlpack()))\n",
        "\n",
        "# print\n",
        "ds = OptionDataSet(max_len = 1)\n",
        "for i in ds:\n",
        "    print(i[0])\n",
        "    print(i[0].shape)\n",
        "    print(i[1])\n",
        "    print(i[1].shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.000000, 0.750000, 0.500000,  ..., 0.150000, 0.010000, 0.010000],\n",
            "        [1.000000, 0.750000, 0.500000,  ..., 0.250000, 0.010000, 0.010000],\n",
            "        [1.000000, 0.750000, 0.500000,  ..., 0.350000, 0.010000, 0.010000],\n",
            "        ...,\n",
            "        [1.000000, 1.250000, 1.000000,  ..., 0.250000, 0.040000, 0.040000],\n",
            "        [1.000000, 1.250000, 1.000000,  ..., 0.350000, 0.040000, 0.040000],\n",
            "        [1.000000, 1.250000, 1.000000,  ..., 0.450000, 0.040000, 0.040000]],\n",
            "       device='cuda:0', dtype=torch.float64)\n",
            "torch.Size([7680, 7])\n",
            "tensor([[0.048392, 0.556177],\n",
            "        [0.077910, 0.564888],\n",
            "        [0.106728, 0.573440],\n",
            "        ...,\n",
            "        [0.144526, 0.584406],\n",
            "        [0.180067, 0.530899],\n",
            "        [0.207353, 0.483880]], device='cuda:0', dtype=torch.float64)\n",
            "torch.Size([7680, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6JO9OBHdvv",
        "outputId": "0b345c1c-82bc-44f0-cde2-1d5e1e8781e3"
      },
      "source": [
        "%%writefile model.py\n",
        "# version 1,2\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(7*1, 64) # remember to change this!\n",
        "        self.fc2 = nn.Linear(64, 128)\n",
        "        self.fc3 = nn.Linear(128, 256)\n",
        "        self.fc4 = nn.Linear(256, 128)\n",
        "        self.fc5 = nn.Linear(128, 64)\n",
        "        self.fc6 = nn.Linear(64, 2) # 2 outputs: price, delta\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1.0, 0.5, 0.5, 0.5, 0.3, 0.03, 0.03]*1)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, B, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = (x - torch.tensor([0.0, 0.75, 0.5, 0.75, 0.15, 0.01, 0.01]*1).cuda()) / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlXD80xPNVc6",
        "outputId": "c19c7a95-81b1-4d87-83b8-9aae56f0ec4c"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 32.0 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 26.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 8.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeLVZiiaDS4y",
        "outputId": "eb1357dc-256a-45a4-e40e-6706214ea307"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3CyULkENYKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0fb7d0e-f881-4b65-b604-7f3400d2611e"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100) # Use max_len to adjust\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    # print(x)\n",
        "    # print(x.shape)\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    # print(y.shape)\n",
        "    y_pred = model(x.float())\n",
        "    # print(y_pred)\n",
        "    # print(y_pred.shape)\n",
        "\n",
        "    # def compute_deltas(x):\n",
        "    #   inputs = x.float()\n",
        "    #   inputs.requires_grad = True\n",
        "    #   first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "    #   return first_order_gradient[0][[3]]  # Now index 3 is stock price, not 2\n",
        "\n",
        "    # deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    # y_pred = torch.cat((y_pred, deltas), 1)\n",
        "    # # print(y_pred)\n",
        "    # # print(y_pred.shape)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 50\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 500)\n",
        "\n",
        "model_save_name = 'jax_knock_out_1stock_oldmethod_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.04958564573772794 average time 0.002956771420040241 iter num 50\n",
            "loss 0.04386825480778129 average time 0.0026878790000228036 iter num 100\n",
            "loss 0.01510279569442875 average time 0.002418064380008218 iter num 50\n",
            "loss 0.011590710847733582 average time 0.0025680611900043004 iter num 100\n",
            "loss 0.010161176612043951 average time 0.0026181361799899605 iter num 50\n",
            "loss 0.010085095634810094 average time 0.00255959339000583 iter num 100\n",
            "loss 0.009837692004544324 average time 0.002885395180019259 iter num 50\n",
            "loss 0.009785370374371802 average time 0.002729049430035957 iter num 100\n",
            "loss 0.009578871012534738 average time 0.002473291880050965 iter num 50\n",
            "loss 0.009526192344242632 average time 0.0024777331000268533 iter num 100\n",
            "loss 0.00930151415699861 average time 0.0024274592400342953 iter num 50\n",
            "loss 0.00924173935476411 average time 0.0024027553800306124 iter num 100\n",
            "loss 0.008984471731951878 average time 0.0024870215599912624 iter num 50\n",
            "loss 0.008915228280291794 average time 0.0025229165699920484 iter num 100\n",
            "loss 0.008615239472370537 average time 0.0025384387400117702 iter num 50\n",
            "loss 0.008533867969267176 average time 0.0024267290300076638 iter num 100\n",
            "loss 0.008181340820475506 average time 0.0023380516799807083 iter num 50\n",
            "loss 0.008085734604890133 average time 0.002487808749965552 iter num 100\n",
            "loss 0.007673225908998655 average time 0.0024443633200280602 iter num 50\n",
            "loss 0.0075613364145461805 average time 0.0024175317699882725 iter num 100\n",
            "loss 0.007077708695054445 average time 0.0023781451399827345 iter num 50\n",
            "loss 0.006945244778042573 average time 0.002408424219988774 iter num 100\n",
            "loss 0.006364934973581284 average time 0.0025997631599602757 iter num 50\n",
            "loss 0.006201983694277115 average time 0.0027146898700038946 iter num 100\n",
            "loss 0.00546986507177183 average time 0.0025516464799784444 iter num 50\n",
            "loss 0.005259248586566063 average time 0.0024957614499908232 iter num 100\n",
            "loss 0.004341598792031379 average time 0.0023835685799986094 iter num 50\n",
            "loss 0.004103669644277937 average time 0.002349295539988816 iter num 100\n",
            "loss 0.0033090485207044828 average time 0.002446688959989842 iter num 50\n",
            "loss 0.003178626540751263 average time 0.002588829089982028 iter num 100\n",
            "loss 0.00287528576088166 average time 0.002402757959989685 iter num 50\n",
            "loss 0.0028311646351982757 average time 0.002402602349998233 iter num 100\n",
            "loss 0.002680274855861328 average time 0.002360842899997806 iter num 50\n",
            "loss 0.0026446430332480067 average time 0.002361113650013067 iter num 100\n",
            "loss 0.0025003986633236348 average time 0.0025153615399631235 iter num 50\n",
            "loss 0.002462810741909909 average time 0.002462353029945916 iter num 100\n",
            "loss 0.0023104435535972767 average time 0.002436899499989522 iter num 50\n",
            "loss 0.002270244846730019 average time 0.002395273119986996 iter num 100\n",
            "loss 0.0021023986677834003 average time 0.002399520300059521 iter num 50\n",
            "loss 0.0020590411543416763 average time 0.0024068285600424132 iter num 100\n",
            "loss 0.0018875985021940475 average time 0.002692891079987021 iter num 50\n",
            "loss 0.0018465601815338556 average time 0.0027683037199994942 iter num 100\n",
            "loss 0.0016964893703984997 average time 0.0025418935600464466 iter num 50\n",
            "loss 0.0016634752078580337 average time 0.0025435593100019104 iter num 100\n",
            "loss 0.001547999018402903 average time 0.002599913980002384 iter num 50\n",
            "loss 0.001522954341776846 average time 0.0024880734499947723 iter num 100\n",
            "loss 0.001432326782240954 average time 0.002543562379969444 iter num 50\n",
            "loss 0.0014114407939702053 average time 0.0025252815099884173 iter num 100\n",
            "loss 0.0013365382395073631 average time 0.002673335780036723 iter num 50\n",
            "loss 0.0013193174559472222 average time 0.0025076042100135964 iter num 100\n",
            "loss 0.0012509624305265218 average time 0.002419097400006649 iter num 50\n",
            "loss 0.0012337831210108856 average time 0.0024389289500049926 iter num 100\n",
            "loss 0.0011644997894802145 average time 0.0024005415399915363 iter num 50\n",
            "loss 0.001146915425487144 average time 0.0023488918899829516 iter num 100\n",
            "loss 0.0010755920539344283 average time 0.0024019744400175114 iter num 50\n",
            "loss 0.0010574320395310586 average time 0.002372478290021718 iter num 100\n",
            "loss 0.000983892986129512 average time 0.0023506752199955374 iter num 50\n",
            "loss 0.0009652106577087352 average time 0.002368861310005741 iter num 100\n",
            "loss 0.0008900371744879385 average time 0.0024096757599727427 iter num 50\n",
            "loss 0.0008710943132000475 average time 0.002385340739979256 iter num 100\n",
            "loss 0.0007978812222952232 average time 0.002375413820000176 iter num 50\n",
            "loss 0.000780319217822864 average time 0.00245363089998591 iter num 100\n",
            "loss 0.0007144647681148594 average time 0.002497478779996527 iter num 50\n",
            "loss 0.0006984821881941085 average time 0.0024887955399799464 iter num 100\n",
            "loss 0.0006358738910013242 average time 0.003002207539975643 iter num 50\n",
            "loss 0.000620530085370376 average time 0.0027815502899875355 iter num 100\n",
            "loss 0.000560836272610858 average time 0.0023887675800142462 iter num 50\n",
            "loss 0.0005463871907273757 average time 0.0023704339600226377 iter num 100\n",
            "loss 0.000497347400726336 average time 0.002569042579998495 iter num 50\n",
            "loss 0.0004849176361819067 average time 0.002583903779996035 iter num 100\n",
            "loss 0.00044146070233161774 average time 0.0024764640600278653 iter num 50\n",
            "loss 0.0004309499985458382 average time 0.002446426300029998 iter num 100\n",
            "loss 0.000390437601622155 average time 0.0024004518000310783 iter num 50\n",
            "loss 0.0003807377100025009 average time 0.002366429470002913 iter num 100\n",
            "loss 0.00034383811896029 average time 0.0024180532799982757 iter num 50\n",
            "loss 0.000335149735769005 average time 0.0024715100499770413 iter num 100\n",
            "loss 0.0003026388067719984 average time 0.002462842179975269 iter num 50\n",
            "loss 0.0002951266269145939 average time 0.002424578280001697 iter num 100\n",
            "loss 0.0002679920851857158 average time 0.002553555200020128 iter num 50\n",
            "loss 0.000261937761161494 average time 0.0024982274700141717 iter num 100\n",
            "loss 0.00024326448460196753 average time 0.0025056359999780396 iter num 50\n",
            "loss 0.0002384959853072372 average time 0.0024903995300155656 iter num 100\n",
            "loss 0.00022279188213915373 average time 0.0024008938199858677 iter num 50\n",
            "loss 0.00021910014649537409 average time 0.0024136521999980685 iter num 100\n",
            "loss 0.00020507029590460514 average time 0.002446985320020758 iter num 50\n",
            "loss 0.00020173621238751355 average time 0.002368935380009134 iter num 100\n",
            "loss 0.00018895592483489994 average time 0.00246272832005161 iter num 50\n",
            "loss 0.00018589097113992333 average time 0.002451614240017079 iter num 100\n",
            "loss 0.00017404810543960824 average time 0.0024554179800088606 iter num 50\n",
            "loss 0.00017118450491946497 average time 0.0024983694200091124 iter num 100\n",
            "loss 0.00016005181406048816 average time 0.0023985612399610545 iter num 50\n",
            "loss 0.00015734336417789859 average time 0.002415686189988264 iter num 100\n",
            "loss 0.00014682050051740197 average time 0.002499345779979194 iter num 50\n",
            "loss 0.0001442694373530807 average time 0.0025039679299879935 iter num 100\n",
            "loss 0.00014145428216388913 average time 0.002711676539993277 iter num 50\n",
            "loss 0.00013569190959460088 average time 0.0025548271000252498 iter num 100\n",
            "loss 0.0001295574721248973 average time 0.0023760708199733927 iter num 50\n",
            "loss 0.00012806013621902737 average time 0.0023819230499975675 iter num 100\n",
            "loss 0.0001222144739668712 average time 0.0028088786399439415 iter num 50\n",
            "loss 0.00012079036140092724 average time 0.002707288649985458 iter num 100\n",
            "loss 0.00011524381855211522 average time 0.002561758699994243 iter num 50\n",
            "loss 0.00011389598504831483 average time 0.002457608540012188 iter num 100\n",
            "loss 0.00010865821677390727 average time 0.0024935445000210167 iter num 50\n",
            "loss 0.00010738858182200332 average time 0.002568319390011311 iter num 100\n",
            "loss 0.00010246488607462823 average time 0.00253842747994895 iter num 50\n",
            "loss 0.00010127349826942491 average time 0.002436059319961714 iter num 100\n",
            "loss 9.666317111635392e-05 average time 0.0024968276799972955 iter num 50\n",
            "loss 9.555125821994034e-05 average time 0.0025001998100015045 iter num 100\n",
            "loss 9.125667738921577e-05 average time 0.0025638190600056985 iter num 50\n",
            "loss 9.022189058774712e-05 average time 0.0025320864600098503 iter num 100\n",
            "loss 8.622799663535852e-05 average time 0.0025179921600101806 iter num 50\n",
            "loss 8.526617554885755e-05 average time 0.0025490840399788797 iter num 100\n",
            "loss 8.155728155977356e-05 average time 0.0025214878999668144 iter num 50\n",
            "loss 8.066580685706333e-05 average time 0.002454721119997885 iter num 100\n",
            "loss 7.723604879910173e-05 average time 0.0024815356399722076 iter num 50\n",
            "loss 7.641361541001718e-05 average time 0.002406440579984519 iter num 100\n",
            "loss 7.523006839564738e-05 average time 0.002580113559970414 iter num 50\n",
            "loss 7.304428877967433e-05 average time 0.0024680474399838203 iter num 100\n",
            "loss 7.062878995219748e-05 average time 0.0024644703200010555 iter num 50\n",
            "loss 7.004490050662067e-05 average time 0.002491100970005391 iter num 100\n",
            "loss 6.77803134915602e-05 average time 0.002424086679920947 iter num 50\n",
            "loss 6.723159909902101e-05 average time 0.0024671605499815997 iter num 100\n",
            "loss 6.510037185897375e-05 average time 0.002552272240018283 iter num 50\n",
            "loss 6.458327627795065e-05 average time 0.0026291784400109463 iter num 100\n",
            "loss 6.257318812993853e-05 average time 0.0024305720600114 iter num 50\n",
            "loss 6.208445091724863e-05 average time 0.002474067580019437 iter num 100\n",
            "loss 6.108465099844471e-05 average time 0.0024059022199708125 iter num 50\n",
            "loss 6.040660437336892e-05 average time 0.0024821980699925917 iter num 100\n",
            "loss 5.9051675175988416e-05 average time 0.0023422276600012994 iter num 50\n",
            "loss 5.872095616494677e-05 average time 0.0023742121699979178 iter num 100\n",
            "loss 5.742405655548805e-05 average time 0.002518765299973893 iter num 50\n",
            "loss 5.710389552310086e-05 average time 0.0024871420399995257 iter num 100\n",
            "loss 5.583844229208641e-05 average time 0.0024919204599973457 iter num 50\n",
            "loss 5.552530850843636e-05 average time 0.0024543565900194153 iter num 100\n",
            "loss 5.4286060523637705e-05 average time 0.0023854758800189303 iter num 50\n",
            "loss 5.397902339272096e-05 average time 0.002492550760011909 iter num 100\n",
            "loss 5.2762255140085065e-05 average time 0.0025807693000569998 iter num 50\n",
            "loss 5.2460357706572624e-05 average time 0.00252806094004427 iter num 100\n",
            "loss 5.126266115487875e-05 average time 0.0025355902600313128 iter num 50\n",
            "loss 5.0965238247698606e-05 average time 0.0026033538200272233 iter num 100\n",
            "loss 4.9783737531253735e-05 average time 0.0024218210800336236 iter num 50\n",
            "loss 4.9489704451673996e-05 average time 0.0024667993500270312 iter num 100\n",
            "loss 4.862784159664694e-05 average time 0.002401555759988696 iter num 50\n",
            "loss 4.825380705466209e-05 average time 0.002446501050003462 iter num 100\n",
            "loss 4.725733081473069e-05 average time 0.002446549979995325 iter num 50\n",
            "loss 4.700715853184026e-05 average time 0.0024749024199900303 iter num 100\n",
            "loss 4.6012297152504784e-05 average time 0.002603355000001102 iter num 50\n",
            "loss 4.576298123502735e-05 average time 0.0025065932700090343 iter num 100\n",
            "loss 4.476496821813431e-05 average time 0.0024620406400390495 iter num 50\n",
            "loss 4.451463541802535e-05 average time 0.0025115992600240134 iter num 100\n",
            "loss 4.403427331114726e-05 average time 0.0028532376200018916 iter num 50\n",
            "loss 4.343336617560426e-05 average time 0.0027484952399890973 iter num 100\n",
            "loss 4.254743585175663e-05 average time 0.002419008359993313 iter num 50\n",
            "loss 4.232509546028328e-05 average time 0.0025357652600041546 iter num 100\n",
            "loss 4.14341990898073e-05 average time 0.002439335199978814 iter num 50\n",
            "loss 4.1210029480520517e-05 average time 0.002424846649973915 iter num 100\n",
            "loss 4.129478251476034e-05 average time 0.0023808407400156286 iter num 50\n",
            "loss 4.019217506058113e-05 average time 0.002405083540029409 iter num 100\n",
            "loss 3.941048923399238e-05 average time 0.0024330988400015486 iter num 50\n",
            "loss 3.916962442894467e-05 average time 0.0023911014199984493 iter num 100\n",
            "loss 3.8929501098933946e-05 average time 0.0024035421399730694 iter num 50\n",
            "loss 3.822289183854357e-05 average time 0.0025123194299794703 iter num 100\n",
            "loss 3.744185952524641e-05 average time 0.0026411527200525596 iter num 50\n",
            "loss 3.724519971828476e-05 average time 0.0026905880000549585 iter num 100\n",
            "loss 3.744892124893211e-05 average time 0.002544562960001713 iter num 50\n",
            "loss 3.6373399705148664e-05 average time 0.002452188609991026 iter num 100\n",
            "loss 3.5644936988141894e-05 average time 0.0024865290399975495 iter num 50\n",
            "loss 3.546076242636263e-05 average time 0.002518347440004618 iter num 100\n",
            "loss 3.4806446520310607e-05 average time 0.0023778703199604932 iter num 50\n",
            "loss 3.455170505508256e-05 average time 0.002423816699965755 iter num 100\n",
            "loss 3.5640038036349445e-05 average time 0.0026808955199976482 iter num 50\n",
            "loss 3.4088119972980704e-05 average time 0.002565861859989127 iter num 100\n",
            "loss 3.3496397064584465e-05 average time 0.0025291288399876067 iter num 50\n",
            "loss 3.335435076268288e-05 average time 0.002634203939996951 iter num 100\n",
            "loss 3.278853580139282e-05 average time 0.0024938814799679676 iter num 50\n",
            "loss 3.2646428321070986e-05 average time 0.002649099709979055 iter num 100\n",
            "loss 3.20755832028342e-05 average time 0.0029076261200225418 iter num 50\n",
            "loss 3.193182952015127e-05 average time 0.002626928479999151 iter num 100\n",
            "loss 3.135412067964728e-05 average time 0.002386197559972061 iter num 50\n",
            "loss 3.120863365266486e-05 average time 0.002468448899976465 iter num 100\n",
            "loss 3.062396716275683e-05 average time 0.0024918927999988227 iter num 50\n",
            "loss 3.047677960007265e-05 average time 0.0024677008800108526 iter num 100\n",
            "loss 2.988556028127876e-05 average time 0.002424456540065876 iter num 50\n",
            "loss 2.9736813060898472e-05 average time 0.002415352810007789 iter num 100\n",
            "loss 2.9139619696686276e-05 average time 0.00252245207996566 iter num 50\n",
            "loss 2.898943658508517e-05 average time 0.0025009965899789677 iter num 100\n",
            "loss 3.02000468130373e-05 average time 0.0023794358800023475 iter num 50\n",
            "loss 2.852499037262898e-05 average time 0.0024657966399809082 iter num 100\n",
            "loss 2.8027596372102825e-05 average time 0.0026231224599905546 iter num 50\n",
            "loss 2.790648139115564e-05 average time 0.002601448039990828 iter num 100\n",
            "loss 2.7424080686474477e-05 average time 0.0026738740000109827 iter num 50\n",
            "loss 2.7302693153404998e-05 average time 0.0025271440700089442 iter num 100\n",
            "loss 2.681474115335481e-05 average time 0.0024385706599969127 iter num 50\n",
            "loss 2.6691789316139158e-05 average time 0.0023944872400034002 iter num 100\n",
            "loss 2.619748017772394e-05 average time 0.002416699619998326 iter num 50\n",
            "loss 2.6072964157960478e-05 average time 0.002418757959994764 iter num 100\n",
            "loss 2.5575902827799698e-05 average time 0.002417912660012007 iter num 50\n",
            "loss 2.5446704385768687e-05 average time 0.002475460899972859 iter num 100\n",
            "loss 2.914650340477281e-05 average time 0.0024035897599969758 iter num 50\n",
            "loss 2.5389262145738348e-05 average time 0.0023870159300213344 iter num 100\n",
            "loss 2.4955626191993668e-05 average time 0.0024115996199725485 iter num 50\n",
            "loss 2.4863618792462978e-05 average time 0.0023953342099821383 iter num 100\n",
            "loss 2.450347747390274e-05 average time 0.0024622797000392895 iter num 50\n",
            "loss 2.441376716706407e-05 average time 0.0024236088600355287 iter num 100\n",
            "loss 2.4053660693299212e-05 average time 0.0026665033799963566 iter num 50\n",
            "loss 2.396295531205881e-05 average time 0.0027468406499883712 iter num 100\n",
            "loss 2.3597742852975538e-05 average time 0.002637612599992281 iter num 50\n",
            "loss 2.3505550348060828e-05 average time 0.002500702999996065 iter num 100\n",
            "loss 2.313408694468877e-05 average time 0.002592489899980137 iter num 50\n",
            "loss 2.30402836727453e-05 average time 0.0024792834599929848 iter num 100\n",
            "loss 2.2662349244778653e-05 average time 0.0026177767400258744 iter num 50\n",
            "loss 2.2566921949116118e-05 average time 0.0026063726400207088 iter num 100\n",
            "loss 2.2182521712025163e-05 average time 0.002571040700058802 iter num 50\n",
            "loss 2.208550729836254e-05 average time 0.002585605480026061 iter num 100\n",
            "loss 2.1694924867896904e-05 average time 0.0026353328399727617 iter num 50\n",
            "loss 2.1596430947695953e-05 average time 0.0026800717499781967 iter num 100\n",
            "loss 2.120017227838418e-05 average time 0.002498426539959837 iter num 50\n",
            "loss 2.1100303866855138e-05 average time 0.002469013329982772 iter num 100\n",
            "loss 2.320978847644632e-05 average time 0.0024637094199806597 iter num 50\n",
            "loss 2.0829860203605232e-05 average time 0.0024557522500117555 iter num 100\n",
            "loss 2.0491189146707775e-05 average time 0.0026330032000078064 iter num 50\n",
            "loss 2.0404094667249825e-05 average time 0.002589752020026026 iter num 100\n",
            "loss 2.007673836067287e-05 average time 0.0023384896400330036 iter num 50\n",
            "loss 1.9994351932637016e-05 average time 0.0023604456600332924 iter num 100\n",
            "loss 1.966296241577354e-05 average time 0.002752804779984217 iter num 50\n",
            "loss 1.9579376770781204e-05 average time 0.002977364509997642 iter num 100\n",
            "loss 1.9243012685357395e-05 average time 0.0027209253999899373 iter num 50\n",
            "loss 1.915821312584591e-05 average time 0.0025771156499740755 iter num 100\n",
            "loss 1.896440408296131e-05 average time 0.00236795726003038 iter num 50\n",
            "loss 1.877729678856092e-05 average time 0.002453892469989114 iter num 100\n",
            "loss 2.0427565995715464e-05 average time 0.0025255286399442412 iter num 50\n",
            "loss 1.868458686394055e-05 average time 0.0025853049499619373 iter num 100\n",
            "loss 1.8387005123676337e-05 average time 0.002413512380035172 iter num 50\n",
            "loss 1.831890256130243e-05 average time 0.0023782381200226155 iter num 100\n",
            "loss 1.8048579837791463e-05 average time 0.0023742612799924246 iter num 50\n",
            "loss 1.7980844071057136e-05 average time 0.002394019019998268 iter num 100\n",
            "loss 1.770868565612976e-05 average time 0.002747848679982781 iter num 50\n",
            "loss 1.7640097012454856e-05 average time 0.0025572763799982566 iter num 100\n",
            "loss 1.736396572807632e-05 average time 0.00250208064004255 iter num 50\n",
            "loss 1.7294260552936523e-05 average time 0.00242350091001299 iter num 100\n",
            "loss 1.701368630864094e-05 average time 0.0024589783600094963 iter num 50\n",
            "loss 1.6942872201026472e-05 average time 0.002521989559995745 iter num 100\n",
            "loss 1.6658899407787317e-05 average time 0.00252455809996718 iter num 50\n",
            "loss 1.6586662900064522e-05 average time 0.0025652612100111583 iter num 100\n",
            "loss 1.929474377754522e-05 average time 0.002540421300000162 iter num 50\n",
            "loss 1.6453763611926563e-05 average time 0.0024606070400113823 iter num 100\n",
            "loss 1.6220960015237926e-05 average time 0.002700767959959194 iter num 50\n",
            "loss 1.616642440752879e-05 average time 0.0025656881899703875 iter num 100\n",
            "loss 1.5948557766648546e-05 average time 0.0024713935000090716 iter num 50\n",
            "loss 1.589368369508462e-05 average time 0.002418246529996395 iter num 100\n",
            "loss 1.567254031187687e-05 average time 0.0024077797799782275 iter num 50\n",
            "loss 1.5616707131176084e-05 average time 0.002468320659982055 iter num 100\n",
            "loss 1.539148905759348e-05 average time 0.0024706085200068627 iter num 50\n",
            "loss 1.533457745239978e-05 average time 0.00242115953999928 iter num 100\n",
            "loss 1.510713696456057e-05 average time 0.0024319938399912644 iter num 50\n",
            "loss 1.504746470828731e-05 average time 0.002386406169998736 iter num 100\n",
            "loss 2.1162855087508502e-05 average time 0.0025010090999694513 iter num 50\n",
            "loss 1.50130797256474e-05 average time 0.0024487607499804652 iter num 100\n",
            "loss 1.4785088304256968e-05 average time 0.0026684989799741743 iter num 50\n",
            "loss 1.4736205694842435e-05 average time 0.002615695439949377 iter num 100\n",
            "loss 1.4547212237591937e-05 average time 0.002488129519942959 iter num 50\n",
            "loss 1.4499868054038285e-05 average time 0.0025166610699579907 iter num 100\n",
            "loss 1.4309609782195822e-05 average time 0.002535255259981568 iter num 50\n",
            "loss 1.426161823523459e-05 average time 0.002485702329981905 iter num 100\n",
            "loss 1.4068265314619192e-05 average time 0.0024267066600168617 iter num 50\n",
            "loss 1.4019471097980093e-05 average time 0.0024162860900105443 iter num 100\n",
            "loss 1.382284805621261e-05 average time 0.002503261339998062 iter num 50\n",
            "loss 1.377323575838856e-05 average time 0.0024661503499964965 iter num 100\n",
            "loss 1.3573421275701603e-05 average time 0.002362463879962888 iter num 50\n",
            "loss 1.352300506735989e-05 average time 0.00239783868998984 iter num 100\n",
            "loss 1.7132397266855332e-05 average time 0.002463881180037788 iter num 50\n",
            "loss 1.3523690048937867e-05 average time 0.002438412470037292 iter num 100\n",
            "loss 1.3320166649139458e-05 average time 0.0026439370599473477 iter num 50\n",
            "loss 1.3278187697246484e-05 average time 0.00263629509997827 iter num 100\n",
            "loss 1.311264941349454e-05 average time 0.0025390914399667963 iter num 50\n",
            "loss 1.3071311407279518e-05 average time 0.0026555664999978034 iter num 100\n",
            "loss 1.2905399403605515e-05 average time 0.0025897860600070997 iter num 50\n",
            "loss 1.2863587560000128e-05 average time 0.0025119848500162333 iter num 100\n",
            "loss 1.2695485575516817e-05 average time 0.002717539960003705 iter num 50\n",
            "loss 1.2653091759333027e-05 average time 0.0025466956500076778 iter num 100\n",
            "loss 1.2482445037865086e-05 average time 0.00242369226003575 iter num 50\n",
            "loss 1.2439389208081012e-05 average time 0.0024854236000328455 iter num 100\n",
            "loss 1.2266206497898005e-05 average time 0.002400386299996171 iter num 50\n",
            "loss 1.222243723636289e-05 average time 0.002400997100003224 iter num 100\n",
            "loss 1.6373318166620695e-05 average time 0.0026010875400061194 iter num 50\n",
            "loss 1.2190601689892661e-05 average time 0.002516744230006225 iter num 100\n",
            "loss 1.202433068848386e-05 average time 0.0024007873599566666 iter num 50\n",
            "loss 1.1983705484932629e-05 average time 0.002426822559973516 iter num 100\n",
            "loss 1.183566836011943e-05 average time 0.0026488467400395165 iter num 50\n",
            "loss 1.1798618614703038e-05 average time 0.0026071742800240828 iter num 100\n",
            "loss 1.1649694713336821e-05 average time 0.0024784319600166783 iter num 50\n",
            "loss 1.1612176219542273e-05 average time 0.00266340483001386 iter num 100\n",
            "loss 1.1461163854518074e-05 average time 0.0029256855599760455 iter num 50\n",
            "loss 1.1423094880570755e-05 average time 0.002614013379975404 iter num 100\n",
            "loss 1.127272941496345e-05 average time 0.002446729500024958 iter num 50\n",
            "loss 1.1231895632278097e-05 average time 0.002464053500020782 iter num 100\n",
            "loss 1.3725016927969824e-05 average time 0.002398194719989988 iter num 50\n",
            "loss 1.115503316479603e-05 average time 0.0024497924399747716 iter num 100\n",
            "loss 1.1026401324990844e-05 average time 0.0024157100200136485 iter num 50\n",
            "loss 1.0996264153213706e-05 average time 0.0025810656699695755 iter num 100\n",
            "loss 1.0875732144553663e-05 average time 0.002560778820043197 iter num 50\n",
            "loss 1.084534561857492e-05 average time 0.002522220390005714 iter num 100\n",
            "loss 1.0722913433643597e-05 average time 0.002561487840011978 iter num 50\n",
            "loss 1.0691872187522171e-05 average time 0.002493678480000199 iter num 100\n",
            "loss 1.088991901628159e-05 average time 0.00275823943999967 iter num 50\n",
            "loss 1.0659828171187113e-05 average time 0.0026772289199971057 iter num 100\n",
            "loss 1.0536206292896621e-05 average time 0.0023292442999809284 iter num 50\n",
            "loss 1.0506302589854334e-05 average time 0.0023758062100068854 iter num 100\n",
            "loss 1.0395814954640546e-05 average time 0.002477649520014893 iter num 50\n",
            "loss 1.0368069509170106e-05 average time 0.0023964289500190716 iter num 100\n",
            "loss 1.0256360414631823e-05 average time 0.002911507579992758 iter num 50\n",
            "loss 1.0228161577421952e-05 average time 0.0027906407000182296 iter num 100\n",
            "loss 1.011444037779657e-05 average time 0.00238559203998193 iter num 50\n",
            "loss 1.0085717496951903e-05 average time 0.002464453609991324 iter num 100\n",
            "loss 1.002311716573362e-05 average time 0.0025346588399861505 iter num 50\n",
            "loss 9.943862379282391e-06 average time 0.0024070635500038407 iter num 100\n",
            "loss 1.3598010669332823e-05 average time 0.0024626908599566376 iter num 50\n",
            "loss 1.0097715653202536e-05 average time 0.0024646451999706187 iter num 100\n",
            "loss 9.938066987809294e-06 average time 0.002839553540043198 iter num 50\n",
            "loss 9.90847584387298e-06 average time 0.002816420100025425 iter num 100\n",
            "loss 9.812570987429657e-06 average time 0.0027108271199813316 iter num 50\n",
            "loss 9.789291971492328e-06 average time 0.0025856390799981455 iter num 100\n",
            "loss 9.696686606052678e-06 average time 0.002385154519961361 iter num 50\n",
            "loss 9.673494365727915e-06 average time 0.002430938690004041 iter num 100\n",
            "loss 9.580450855606016e-06 average time 0.0027138715800174395 iter num 50\n",
            "loss 9.557009981125959e-06 average time 0.002688215550010682 iter num 100\n",
            "loss 9.462636772567274e-06 average time 0.002572348619996774 iter num 50\n",
            "loss 9.438806100187336e-06 average time 0.0026355812199881255 iter num 100\n",
            "loss 9.342776457190308e-06 average time 0.0025727396000092993 iter num 50\n",
            "loss 9.318510361372144e-06 average time 0.002615511149992926 iter num 100\n",
            "loss 9.220688317108432e-06 average time 0.0025445583200144027 iter num 50\n",
            "loss 9.195973164363114e-06 average time 0.0025101974899871494 iter num 100\n",
            "loss 9.096264110308873e-06 average time 0.0027065456999753224 iter num 50\n",
            "loss 9.071078255933113e-06 average time 0.0025417333399855124 iter num 100\n",
            "loss 9.166777784396428e-06 average time 0.002483567720037172 iter num 50\n",
            "loss 8.95005080861335e-06 average time 0.0024809446100061906 iter num 100\n",
            "loss 1.0650414149362285e-05 average time 0.0025118043399925227 iter num 50\n",
            "loss 9.190963273183407e-06 average time 0.0024508212299906517 iter num 100\n",
            "loss 9.021223926312714e-06 average time 0.002379775999988851 iter num 50\n",
            "loss 8.998357648753159e-06 average time 0.0024073324199753187 iter num 100\n",
            "loss 8.916653997723915e-06 average time 0.0025401795799643878 iter num 50\n",
            "loss 8.897347865420896e-06 average time 0.002526891009974861 iter num 100\n",
            "loss 8.82145433601966e-06 average time 0.0025338273599936657 iter num 50\n",
            "loss 8.80263027327146e-06 average time 0.0025003037400028916 iter num 100\n",
            "loss 8.727318145328071e-06 average time 0.0025786218399389328 iter num 50\n",
            "loss 8.708416177017414e-06 average time 0.00254485313999794 iter num 100\n",
            "loss 8.632387771755032e-06 average time 0.002873752980012796 iter num 50\n",
            "loss 8.613212083165315e-06 average time 0.002745319940004265 iter num 100\n",
            "loss 8.536002452885508e-06 average time 0.0025475767399984763 iter num 50\n",
            "loss 8.516496389231344e-06 average time 0.002473482830009743 iter num 100\n",
            "loss 8.43784290667285e-06 average time 0.0027013720200193348 iter num 50\n",
            "loss 8.41798254836856e-06 average time 0.0025533779400302593 iter num 100\n",
            "loss 8.337751054445747e-06 average time 0.0023617096400175798 iter num 50\n",
            "loss 8.317470260496917e-06 average time 0.0023539031200016324 iter num 100\n",
            "loss 8.246994152614049e-06 average time 0.002415557699996498 iter num 50\n",
            "loss 8.216167550917087e-06 average time 0.00237300434998815 iter num 100\n",
            "loss 8.541634849141398e-06 average time 0.0025131305400009295 iter num 50\n",
            "loss 8.179774714462687e-06 average time 0.0024227327400194554 iter num 100\n",
            "loss 8.107455667280328e-06 average time 0.00259787393996703 iter num 50\n",
            "loss 8.089093280503547e-06 average time 0.00249816947999534 iter num 100\n",
            "loss 8.01875889816639e-06 average time 0.0024176266400263557 iter num 50\n",
            "loss 8.001020883842676e-06 average time 0.002400594500036277 iter num 100\n",
            "loss 7.9295711745836e-06 average time 0.0028071148399612866 iter num 50\n",
            "loss 7.911217599426726e-06 average time 0.0026756797599637137 iter num 100\n",
            "loss 9.566232921310604e-06 average time 0.002561090300068827 iter num 50\n",
            "loss 7.912819029839251e-06 average time 0.0025385809800309287 iter num 100\n",
            "loss 7.83309543531947e-06 average time 0.0029472596000050546 iter num 50\n",
            "loss 7.8162049985963e-06 average time 0.0026725805499881973 iter num 100\n",
            "loss 7.749531417850075e-06 average time 0.0023802757799967367 iter num 50\n",
            "loss 7.732816955641994e-06 average time 0.0024729858700129627 iter num 100\n",
            "loss 7.665595159448953e-06 average time 0.003001104699987991 iter num 50\n",
            "loss 7.648620028311823e-06 average time 0.002897515539980304 iter num 100\n",
            "loss 7.580150702796108e-06 average time 0.002445511419973627 iter num 50\n",
            "loss 7.562827398285508e-06 average time 0.00259773386998404 iter num 100\n",
            "loss 7.5747047264940905e-06 average time 0.002619493739985046 iter num 50\n",
            "loss 7.477461736254096e-06 average time 0.0025026451199619258 iter num 100\n",
            "loss 9.461872845427588e-06 average time 0.002430635720038481 iter num 50\n",
            "loss 7.682136798115035e-06 average time 0.002594390670019493 iter num 100\n",
            "loss 7.546052514283453e-06 average time 0.0026851250000254367 iter num 50\n",
            "loss 7.526635246951574e-06 average time 0.002754433310024069 iter num 100\n",
            "loss 7.462964252701668e-06 average time 0.00278217113998835 iter num 50\n",
            "loss 7.448054308017273e-06 average time 0.002735833899987483 iter num 100\n",
            "loss 7.3896991158405295e-06 average time 0.002477466699965589 iter num 50\n",
            "loss 7.375275755359451e-06 average time 0.0024199834699811617 iter num 100\n",
            "loss 7.317729497040643e-06 average time 0.0024411810400124523 iter num 50\n",
            "loss 7.303292295302402e-06 average time 0.0024540158000127123 iter num 100\n",
            "loss 7.24535177809672e-06 average time 0.003114041179978813 iter num 50\n",
            "loss 7.2307745730041355e-06 average time 0.002918123729996296 iter num 100\n",
            "loss 7.1720017228332985e-06 average time 0.0025983277799878123 iter num 50\n",
            "loss 7.157166929086396e-06 average time 0.0025897993099943052 iter num 100\n",
            "loss 7.0973466077665555e-06 average time 0.0028120902600403497 iter num 50\n",
            "loss 7.082245673663908e-06 average time 0.0026148999599990928 iter num 100\n",
            "loss 7.02123462231474e-06 average time 0.00253640998002993 iter num 50\n",
            "loss 7.005819390866168e-06 average time 0.002484055200034163 iter num 100\n",
            "loss 6.945052013622112e-06 average time 0.002349680259985689 iter num 50\n",
            "loss 6.928037915711869e-06 average time 0.002372103199995763 iter num 100\n",
            "loss 7.184644088202624e-06 average time 0.0025549327800217726 iter num 50\n",
            "loss 6.874765301405124e-06 average time 0.0024932998200119984 iter num 100\n",
            "loss 6.903442602504957e-06 average time 0.002929436500016891 iter num 50\n",
            "loss 6.842768701954748e-06 average time 0.0028448364700216187 iter num 100\n",
            "loss 6.786925047901905e-06 average time 0.0027961474599942446 iter num 50\n",
            "loss 6.773506085726907e-06 average time 0.0025714120799875673 iter num 100\n",
            "loss 6.719627433563683e-06 average time 0.0023444097399988096 iter num 50\n",
            "loss 6.706040009182621e-06 average time 0.0023589860200081605 iter num 100\n",
            "loss 6.656708786797017e-06 average time 0.0029146813599800225 iter num 50\n",
            "loss 6.6380034787787485e-06 average time 0.002747915859981731 iter num 100\n",
            "loss 9.18701170991115e-06 average time 0.0025593952599683688 iter num 50\n",
            "loss 6.769393466752565e-06 average time 0.002526164969972342 iter num 100\n",
            "loss 6.67128392786808e-06 average time 0.0023667794599987247 iter num 50\n",
            "loss 6.654992432280356e-06 average time 0.002351007089982886 iter num 100\n",
            "loss 6.60378534182494e-06 average time 0.0024658944599923417 iter num 50\n",
            "loss 6.591597235318342e-06 average time 0.0024456576199918343 iter num 100\n",
            "loss 6.543514589774241e-06 average time 0.0024127791200317006 iter num 50\n",
            "loss 6.53157010867284e-06 average time 0.002428853200026424 iter num 100\n",
            "loss 6.483734061482049e-06 average time 0.0025533273800010647 iter num 50\n",
            "loss 6.471707823636295e-06 average time 0.0025025342400022054 iter num 100\n",
            "loss 6.423330090711923e-06 average time 0.0024652566399618082 iter num 50\n",
            "loss 6.41114045225808e-06 average time 0.0024304496899640073 iter num 100\n",
            "loss 6.361922818395669e-06 average time 0.0026594114599902243 iter num 50\n",
            "loss 6.349487573217665e-06 average time 0.0026191522599901874 iter num 100\n",
            "loss 6.299297479281478e-06 average time 0.0024156068799766218 iter num 50\n",
            "loss 6.286594387483911e-06 average time 0.002610128829996938 iter num 100\n",
            "loss 6.235305561454684e-06 average time 0.0025438047999614354 iter num 50\n",
            "loss 6.222311139608751e-06 average time 0.002574558229966897 iter num 100\n",
            "loss 6.19207142046972e-06 average time 0.0026494656000159013 iter num 50\n",
            "loss 6.157716845518145e-06 average time 0.0025827294399914536 iter num 100\n",
            "loss 9.611444281543453e-06 average time 0.002399210059966208 iter num 50\n",
            "loss 6.27665638710157e-06 average time 0.0024347737700145446 iter num 100\n",
            "loss 6.182168667450258e-06 average time 0.002903180940011225 iter num 50\n",
            "loss 6.170291215465866e-06 average time 0.002738983620020008 iter num 100\n",
            "loss 6.127983780657697e-06 average time 0.002798860240027352 iter num 50\n",
            "loss 6.117891324317165e-06 average time 0.0027283304300271993 iter num 100\n",
            "loss 6.078013126528177e-06 average time 0.002777525120000064 iter num 50\n",
            "loss 6.068086141080489e-06 average time 0.0026233956499800114 iter num 100\n",
            "loss 6.028241206590507e-06 average time 0.002871358379989033 iter num 50\n",
            "loss 6.018222412528049e-06 average time 0.002639324939996186 iter num 100\n",
            "loss 5.977779378569787e-06 average time 0.0023811404199295793 iter num 50\n",
            "loss 5.9675712457963855e-06 average time 0.0024080853499663137 iter num 100\n",
            "loss 5.926317708308062e-06 average time 0.0023783894799908013 iter num 50\n",
            "loss 5.915876832074397e-06 average time 0.002386167639974701 iter num 100\n",
            "loss 5.873682593967586e-06 average time 0.0027688084399960645 iter num 50\n",
            "loss 5.862990097933854e-06 average time 0.00266937032999067 iter num 100\n",
            "loss 5.820286367994102e-06 average time 0.0026466068199715665 iter num 50\n",
            "loss 5.809081386817645e-06 average time 0.0025540530999842302 iter num 100\n",
            "loss 8.140036090642636e-06 average time 0.002937546140019549 iter num 50\n",
            "loss 5.865733774204901e-06 average time 0.002745424580039071 iter num 100\n",
            "loss 5.8006435617496e-06 average time 0.0026593528199464343 iter num 50\n",
            "loss 5.789919846173862e-06 average time 0.002632752359963888 iter num 100\n",
            "loss 5.749145184129498e-06 average time 0.00276547252004093 iter num 50\n",
            "loss 5.739200417281716e-06 average time 0.0027416891300117642 iter num 100\n",
            "loss 5.699490468737009e-06 average time 0.0026074669999889013 iter num 50\n",
            "loss 5.689542337891077e-06 average time 0.0025603369400050723 iter num 100\n",
            "loss 5.64952563287451e-06 average time 0.002528615079972951 iter num 50\n",
            "loss 5.639428584490183e-06 average time 0.0024397941599909245 iter num 100\n",
            "loss 5.598710758968307e-06 average time 0.0026119231400025455 iter num 50\n",
            "loss 5.5884083837959545e-06 average time 0.0025863396799832117 iter num 100\n",
            "loss 5.546853106275165e-06 average time 0.002500983720037766 iter num 50\n",
            "loss 5.5362969438559525e-06 average time 0.0025886286400282187 iter num 100\n",
            "loss 5.51912847003479e-06 average time 0.00299532354002622 iter num 50\n",
            "loss 5.502341619690691e-06 average time 0.002722363810016759 iter num 100\n",
            "loss 5.518940322478298e-06 average time 0.0025227527399692916 iter num 50\n",
            "loss 5.4773756864041384e-06 average time 0.0025893388599706668 iter num 100\n",
            "loss 5.434649262156751e-06 average time 0.002505970839947622 iter num 50\n",
            "loss 5.424336186570293e-06 average time 0.0025774159399725247 iter num 100\n",
            "loss 5.383126386380177e-06 average time 0.0026259991800088754 iter num 50\n",
            "loss 5.3727125547363815e-06 average time 0.002522106519995759 iter num 100\n",
            "loss 5.3849753770725975e-06 average time 0.0024496990400075446 iter num 50\n",
            "loss 5.324707207816407e-06 average time 0.0024555023200127837 iter num 100\n",
            "loss 8.490415117403876e-06 average time 0.0027502814000581566 iter num 50\n",
            "loss 5.43877276350697e-06 average time 0.0026915882600314946 iter num 100\n",
            "loss 5.361891446163652e-06 average time 0.002496046340038447 iter num 50\n",
            "loss 5.351524762023517e-06 average time 0.002507685490018048 iter num 100\n",
            "loss 5.31551235804353e-06 average time 0.0024094678400069826 iter num 50\n",
            "loss 5.307055342258708e-06 average time 0.0024168037600293246 iter num 100\n",
            "loss 5.273960331971817e-06 average time 0.002707410979983251 iter num 50\n",
            "loss 5.2657775192562104e-06 average time 0.0025585848099854047 iter num 100\n",
            "loss 5.233125344544764e-06 average time 0.0026856863600369252 iter num 50\n",
            "loss 5.224938529866155e-06 average time 0.0025394996400063975 iter num 100\n",
            "loss 5.192034771572842e-06 average time 0.0028089455199824444 iter num 50\n",
            "loss 5.183744112006369e-06 average time 0.0026750629499701973 iter num 100\n",
            "loss 5.150286225880638e-06 average time 0.0025411043999974937 iter num 50\n",
            "loss 5.141842504911686e-06 average time 0.002630616310007099 iter num 100\n",
            "loss 5.107700105215963e-06 average time 0.0025156540399893855 iter num 50\n",
            "loss 5.0990559295721205e-06 average time 0.002435660680007459 iter num 100\n",
            "loss 5.065389672328828e-06 average time 0.0026195260800068354 iter num 50\n",
            "loss 5.055316913780884e-06 average time 0.0026912901899913775 iter num 100\n",
            "loss 6.592290989811689e-06 average time 0.0024997658800202773 iter num 50\n",
            "loss 5.115279324492838e-06 average time 0.0025265933600257997 iter num 100\n",
            "loss 5.057174309770522e-06 average time 0.002401974419990438 iter num 50\n",
            "loss 5.047664774690776e-06 average time 0.0024066647899962847 iter num 100\n",
            "loss 5.013556489069331e-06 average time 0.002512848659989686 iter num 50\n",
            "loss 5.005295441772075e-06 average time 0.0024483590499903584 iter num 100\n",
            "loss 4.972448290660278e-06 average time 0.0025220943000022087 iter num 50\n",
            "loss 4.964251638579257e-06 average time 0.002554369080003198 iter num 100\n",
            "loss 4.9312999015629255e-06 average time 0.0024145137399955276 iter num 50\n",
            "loss 4.922994125208878e-06 average time 0.002719860430029257 iter num 100\n",
            "loss 4.889550007034461e-06 average time 0.002611674919999132 iter num 50\n",
            "loss 4.8810899721804004e-06 average time 0.0025401167699828876 iter num 100\n",
            "loss 4.846978813836116e-06 average time 0.0025406337199729025 iter num 50\n",
            "loss 4.838344036703797e-06 average time 0.002487675549996311 iter num 100\n",
            "loss 4.815565915625065e-06 average time 0.003075713159978477 iter num 50\n",
            "loss 4.795146686592015e-06 average time 0.0030207618399708735 iter num 100\n",
            "loss 1.2049984099966813e-05 average time 0.0026144295599806354 iter num 50\n",
            "loss 4.907594210012345e-06 average time 0.0027200568100033706 iter num 100\n",
            "loss 4.827565566690443e-06 average time 0.002475733539986322 iter num 50\n",
            "loss 4.8176339051898445e-06 average time 0.0024901749799983008 iter num 100\n",
            "loss 4.783627511535443e-06 average time 0.0024176576400077466 iter num 50\n",
            "loss 4.775712444972527e-06 average time 0.002507736759994259 iter num 100\n",
            "loss 4.744803698405081e-06 average time 0.0024106442000083918 iter num 50\n",
            "loss 4.737183434589848e-06 average time 0.0024895776099901922 iter num 100\n",
            "loss 4.706818843976072e-06 average time 0.00269949849999648 iter num 50\n",
            "loss 4.6992250787366455e-06 average time 0.002589736360018833 iter num 100\n",
            "loss 4.668685569649577e-06 average time 0.0025612382599956617 iter num 50\n",
            "loss 4.661002217766405e-06 average time 0.002608380500009844 iter num 100\n",
            "loss 4.630049155238977e-06 average time 0.002577035300018906 iter num 50\n",
            "loss 4.622233020445139e-06 average time 0.002482166260001577 iter num 100\n",
            "loss 4.590694780120323e-06 average time 0.002445945940016827 iter num 50\n",
            "loss 4.582725817231065e-06 average time 0.002496838359998037 iter num 100\n",
            "loss 4.647464175971246e-06 average time 0.002509150719997706 iter num 50\n",
            "loss 4.547658779460632e-06 average time 0.0025216323500217184 iter num 100\n",
            "loss 6.403819645207832e-06 average time 0.0025248517400086714 iter num 50\n",
            "loss 4.594756726887511e-06 average time 0.0025179129000116518 iter num 100\n",
            "loss 4.5479780524194345e-06 average time 0.002499701999986428 iter num 50\n",
            "loss 4.540168634208685e-06 average time 0.0024169581999922227 iter num 100\n",
            "loss 4.510552008654611e-06 average time 0.002583950999969602 iter num 50\n",
            "loss 4.503336001371616e-06 average time 0.0026009491399781835 iter num 100\n",
            "loss 4.474651026461937e-06 average time 0.0025721011600398926 iter num 50\n",
            "loss 4.467486721098666e-06 average time 0.002499054289992273 iter num 100\n",
            "loss 4.438655018537929e-06 average time 0.002620051820013032 iter num 50\n",
            "loss 4.431396823343537e-06 average time 0.00261245805001181 iter num 100\n",
            "loss 4.4021298872787105e-06 average time 0.0028321142000095278 iter num 50\n",
            "loss 4.394721878366237e-06 average time 0.002709798659993794 iter num 100\n",
            "loss 4.365413395171019e-06 average time 0.0026184031599768786 iter num 50\n",
            "loss 4.357342110710843e-06 average time 0.0025397361399791406 iter num 100\n",
            "loss 7.837868604035899e-06 average time 0.0025656248399991456 iter num 50\n",
            "loss 4.4274934900927555e-06 average time 0.0026345983800001704 iter num 100\n",
            "loss 4.370399673421462e-06 average time 0.002619996479998008 iter num 50\n",
            "loss 4.3621581710124365e-06 average time 0.0025967947399976763 iter num 100\n",
            "loss 4.332250637919843e-06 average time 0.002447209859992654 iter num 50\n",
            "loss 4.325107669066844e-06 average time 0.0025814254099987013 iter num 100\n",
            "loss 4.296938049307737e-06 average time 0.0027365018599630276 iter num 50\n",
            "loss 4.289938956016768e-06 average time 0.0025945640999816533 iter num 100\n",
            "loss 4.261924877037287e-06 average time 0.002361939500005974 iter num 50\n",
            "loss 4.254880120158582e-06 average time 0.0023735525499796496 iter num 100\n",
            "loss 4.226854743509131e-06 average time 0.0024716947599790727 iter num 50\n",
            "loss 4.219483566196155e-06 average time 0.0024459085699572824 iter num 100\n",
            "loss 4.444308160673125e-06 average time 0.002538908020023882 iter num 50\n",
            "loss 4.191095932652322e-06 average time 0.0024863025400190964 iter num 100\n",
            "loss 4.167776743721092e-06 average time 0.0024308778799695574 iter num 50\n",
            "loss 4.160950611984346e-06 average time 0.002489542859998437 iter num 100\n",
            "loss 5.257811321231731e-06 average time 0.0025009667599624665 iter num 50\n",
            "loss 4.1887231893554e-06 average time 0.0024767034199840053 iter num 100\n",
            "loss 4.152397207534535e-06 average time 0.0023776592999911372 iter num 50\n",
            "loss 4.144814037759243e-06 average time 0.002369337339964659 iter num 100\n",
            "loss 4.118877663043827e-06 average time 0.0024277409799833547 iter num 50\n",
            "loss 4.1125107500310745e-06 average time 0.002476426799989895 iter num 100\n",
            "loss 4.08705780400174e-06 average time 0.0024537697400501203 iter num 50\n",
            "loss 4.0806768373476896e-06 average time 0.0024201969400155575 iter num 100\n",
            "loss 4.054991257348568e-06 average time 0.00256712029996379 iter num 50\n",
            "loss 4.048512207646164e-06 average time 0.0026827685799935353 iter num 100\n",
            "loss 4.022864452570915e-06 average time 0.0028209326399974088 iter num 50\n",
            "loss 4.015772291900175e-06 average time 0.0026637975699850356 iter num 100\n",
            "loss 5.786190953669721e-06 average time 0.0025528761999885317 iter num 50\n",
            "loss 4.066331741686262e-06 average time 0.002484158669985845 iter num 100\n",
            "loss 4.020921808343326e-06 average time 0.0025560333800331136 iter num 50\n",
            "loss 4.013767130054951e-06 average time 0.002478187540032195 iter num 100\n",
            "loss 3.987465717732453e-06 average time 0.002445528660000491 iter num 50\n",
            "loss 3.981119530377449e-06 average time 0.0024113317199908123 iter num 100\n",
            "loss 3.955991493156663e-06 average time 0.0024164055999972333 iter num 50\n",
            "loss 3.949728195486636e-06 average time 0.002558996790003221 iter num 100\n",
            "loss 3.924612224016278e-06 average time 0.0026963197400255014 iter num 50\n",
            "loss 3.918295592198364e-06 average time 0.002600923060012974 iter num 100\n",
            "loss 3.8938671887769495e-06 average time 0.00262425307999365 iter num 50\n",
            "loss 3.886524529262159e-06 average time 0.0025839027600022746 iter num 100\n",
            "loss 3.9979878633270905e-06 average time 0.0026006051000058506 iter num 50\n",
            "loss 3.86332758590096e-06 average time 0.0027235750099953294 iter num 100\n",
            "loss 4.385149602137837e-06 average time 0.0027407154199772777 iter num 50\n",
            "loss 3.870411165160547e-06 average time 0.0026383543899873986 iter num 100\n",
            "loss 3.843027803247485e-06 average time 0.0026575385399792138 iter num 50\n",
            "loss 3.836280894676708e-06 average time 0.0024895139199816187 iter num 100\n",
            "loss 3.8135251205562436e-06 average time 0.0025044754199825547 iter num 50\n",
            "loss 3.8078535128777687e-06 average time 0.0024328250599819513 iter num 100\n",
            "loss 3.7851134991513736e-06 average time 0.002430978239999604 iter num 50\n",
            "loss 3.779383302719753e-06 average time 0.0026509202399984133 iter num 100\n",
            "loss 3.7596823928835166e-06 average time 0.0025836139199782336 iter num 50\n",
            "loss 3.750942553317187e-06 average time 0.0025004880200003754 iter num 100\n",
            "loss 5.135851878834435e-06 average time 0.0024558101600359807 iter num 50\n",
            "loss 3.8502532947650575e-06 average time 0.002468170139995891 iter num 100\n",
            "loss 3.7870773758599658e-06 average time 0.0026600817399958033 iter num 50\n",
            "loss 3.7797759371126813e-06 average time 0.0025580816799902093 iter num 100\n",
            "loss 3.754487659263342e-06 average time 0.002734944420008105 iter num 50\n",
            "loss 3.7486664009159987e-06 average time 0.002629688630026976 iter num 100\n",
            "loss 3.726094026953155e-06 average time 0.002360704380016614 iter num 50\n",
            "loss 3.720560504826118e-06 average time 0.002423472380014573 iter num 100\n",
            "loss 3.6986115331316898e-06 average time 0.0026473468200128992 iter num 50\n",
            "loss 3.6931333080225696e-06 average time 0.002530193650000001 iter num 100\n",
            "loss 3.671204949095873e-06 average time 0.0026684530199963773 iter num 50\n",
            "loss 3.665698559738494e-06 average time 0.002545573229976981 iter num 100\n",
            "loss 3.6435488488440807e-06 average time 0.0024317057599910186 iter num 50\n",
            "loss 3.637967738349448e-06 average time 0.002438317629989797 iter num 100\n",
            "loss 3.6154756079695093e-06 average time 0.0023778715200023725 iter num 50\n",
            "loss 3.609787019997389e-06 average time 0.0024009784699956073 iter num 100\n",
            "loss 3.6022246518019337e-06 average time 0.002323529059995053 iter num 50\n",
            "loss 3.5817935845632347e-06 average time 0.0023454865299800077 iter num 100\n",
            "loss 4.540419881203036e-06 average time 0.0024287878399991314 iter num 50\n",
            "loss 3.610534013703349e-06 average time 0.002395262080012799 iter num 100\n",
            "loss 3.5790189481370047e-06 average time 0.0024249650000092516 iter num 50\n",
            "loss 3.5734047682287047e-06 average time 0.002439242769996781 iter num 100\n",
            "loss 3.553207270613855e-06 average time 0.002594912820031823 iter num 50\n",
            "loss 3.548255647498775e-06 average time 0.002499063900013425 iter num 100\n",
            "loss 3.5285296533984867e-06 average time 0.0023543004200200814 iter num 50\n",
            "loss 3.5235826709518737e-06 average time 0.0024499807300207978 iter num 100\n",
            "loss 3.5036909507789675e-06 average time 0.0027422249199935324 iter num 50\n",
            "loss 3.4986712409956215e-06 average time 0.002626462159996663 iter num 100\n",
            "loss 3.478569937637782e-06 average time 0.002710434600021472 iter num 50\n",
            "loss 3.4733799824974634e-06 average time 0.0026652508300094267 iter num 100\n",
            "loss 4.692315434856873e-06 average time 0.002595463859997835 iter num 50\n",
            "loss 3.533031269394595e-06 average time 0.002559932340004707 iter num 100\n",
            "loss 3.4899613571720984e-06 average time 0.0026844535599957454 iter num 50\n",
            "loss 3.4826448071404274e-06 average time 0.0025965257999951063 iter num 100\n",
            "loss 3.461400865190765e-06 average time 0.0025505904399960853 iter num 50\n",
            "loss 3.4563628149678296e-06 average time 0.0027613390199985586 iter num 100\n",
            "loss 3.436554189685475e-06 average time 0.0025593704199764035 iter num 50\n",
            "loss 3.431636807816657e-06 average time 0.00263517122000394 iter num 100\n",
            "loss 3.412024128263127e-06 average time 0.002465300980002212 iter num 50\n",
            "loss 3.407112524383978e-06 average time 0.0025972313099964593 iter num 100\n",
            "loss 3.3873421405003353e-06 average time 0.0027855461000217473 iter num 50\n",
            "loss 3.382370771286392e-06 average time 0.002559943900014332 iter num 100\n",
            "loss 3.3622984861907884e-06 average time 0.002644149180005115 iter num 50\n",
            "loss 3.35723231988551e-06 average time 0.0025375593800026765 iter num 100\n",
            "loss 3.350878407566941e-06 average time 0.0025615998800549277 iter num 50\n",
            "loss 3.33246452066911e-06 average time 0.0024580675100241934 iter num 100\n",
            "loss 4.623198776200874e-06 average time 0.00247945337996498 iter num 50\n",
            "loss 3.4443349173502855e-06 average time 0.002480910400004177 iter num 100\n",
            "loss 3.3816905168478496e-06 average time 0.0025419767599851183 iter num 50\n",
            "loss 3.374816523951855e-06 average time 0.0024387593499750437 iter num 100\n",
            "loss 3.3518897220380324e-06 average time 0.002840731899932507 iter num 50\n",
            "loss 3.3467486978244024e-06 average time 0.0028616827899713825 iter num 100\n",
            "loss 3.3271382193767888e-06 average time 0.0024889507399802825 iter num 50\n",
            "loss 3.3223944298633783e-06 average time 0.0024433807399918805 iter num 100\n",
            "loss 3.3036697226152613e-06 average time 0.0028235107799628166 iter num 50\n",
            "loss 3.2990377225454146e-06 average time 0.0025974663499710006 iter num 100\n",
            "loss 3.2805408125280865e-06 average time 0.0028235479600152756 iter num 50\n",
            "loss 3.2759169668952594e-06 average time 0.002587512750019414 iter num 100\n",
            "loss 3.257616697994907e-06 average time 0.0023989079400143967 iter num 50\n",
            "loss 3.252715040385412e-06 average time 0.0023898423500077117 iter num 100\n",
            "loss 3.2742250916804957e-06 average time 0.002368078820009032 iter num 50\n",
            "loss 3.2343520149022456e-06 average time 0.0023805622600184505 iter num 100\n",
            "loss 3.2165941540345204e-06 average time 0.0023579496000638756 iter num 50\n",
            "loss 3.2121939998937073e-06 average time 0.002367284050001217 iter num 100\n",
            "loss 3.1944746881909256e-06 average time 0.0024257838999801606 iter num 50\n",
            "loss 3.189997535550223e-06 average time 0.002396360859975175 iter num 100\n",
            "loss 3.231190311295619e-06 average time 0.0023426126999947883 iter num 50\n",
            "loss 3.1683292565791986e-06 average time 0.0023286812300239036 iter num 100\n",
            "loss 5.586313027123068e-06 average time 0.0024843787200006773 iter num 50\n",
            "loss 3.2980693465360704e-06 average time 0.0025257737199808616 iter num 100\n",
            "loss 3.2268891717658543e-06 average time 0.002781436080013009 iter num 50\n",
            "loss 3.218561689551632e-06 average time 0.002660374869997213 iter num 100\n",
            "loss 3.195996678406518e-06 average time 0.0028045966600166138 iter num 50\n",
            "loss 3.191047868522799e-06 average time 0.002588041920012074 iter num 100\n",
            "loss 3.172299327054318e-06 average time 0.0025212434400418717 iter num 50\n",
            "loss 3.1678081172223776e-06 average time 0.0025322750900249958 iter num 100\n",
            "loss 3.150137507069273e-06 average time 0.0026190962000328 iter num 50\n",
            "loss 3.1457808904167105e-06 average time 0.002589572610036157 iter num 100\n",
            "loss 3.128430162121938e-06 average time 0.0026290418799999314 iter num 50\n",
            "loss 3.1241052057082525e-06 average time 0.002507609809990754 iter num 100\n",
            "loss 3.1067718668730825e-06 average time 0.002443609360007031 iter num 50\n",
            "loss 3.102425140878956e-06 average time 0.002390013610001915 iter num 100\n",
            "loss 3.0849467701783906e-06 average time 0.00265011845999652 iter num 50\n",
            "loss 3.080544313712482e-06 average time 0.0025837668700069115 iter num 100\n",
            "loss 3.0701594199816275e-06 average time 0.0024896095599706313 iter num 50\n",
            "loss 3.0589852509474474e-06 average time 0.002475753719986642 iter num 100\n",
            "loss 3.0910690796271382e-06 average time 0.0025267924799936736 iter num 50\n",
            "loss 3.040539953216596e-06 average time 0.0025326272099982818 iter num 100\n",
            "loss 3.0884475875109687e-06 average time 0.0025148880799588367 iter num 50\n",
            "loss 3.0234513765083186e-06 average time 0.0025365921599859575 iter num 100\n",
            "loss 4.041472142441212e-06 average time 0.002535562780003602 iter num 50\n",
            "loss 3.0402550613587242e-06 average time 0.002502581070011729 iter num 100\n",
            "loss 3.0183253248923563e-06 average time 0.00233549653998125 iter num 50\n",
            "loss 3.0129699069089e-06 average time 0.002486746339995989 iter num 100\n",
            "loss 2.995705476710921e-06 average time 0.002300969559992154 iter num 50\n",
            "loss 2.991472449264738e-06 average time 0.002357901229979689 iter num 100\n",
            "loss 2.9745463275074507e-06 average time 0.00237551368003551 iter num 50\n",
            "loss 2.970316449873355e-06 average time 0.0024426995000203532 iter num 100\n",
            "loss 2.9532756723616983e-06 average time 0.0024658814200302004 iter num 50\n",
            "loss 2.94898693673476e-06 average time 0.0024323345700213396 iter num 100\n",
            "loss 2.965741204582607e-06 average time 0.0024383918199600884 iter num 50\n",
            "loss 2.928010930481576e-06 average time 0.0024181443199813657 iter num 100\n",
            "loss 4.878362529418805e-06 average time 0.002464053059993603 iter num 50\n",
            "loss 3.0212497016797526e-06 average time 0.002466880790007053 iter num 100\n",
            "loss 2.970547344264243e-06 average time 0.002723433800010753 iter num 50\n",
            "loss 2.964497449915852e-06 average time 0.0025780354599964994 iter num 100\n",
            "loss 2.9475135325077917e-06 average time 0.002494199259990637 iter num 50\n",
            "loss 2.9437363433816685e-06 average time 0.0024321917299948838 iter num 100\n",
            "loss 2.9293670494794313e-06 average time 0.002492881279995345 iter num 50\n",
            "loss 2.925895877186829e-06 average time 0.002485412959972564 iter num 100\n",
            "loss 2.912257686223881e-06 average time 0.002409771919992636 iter num 50\n",
            "loss 2.908883870228769e-06 average time 0.00248612071000025 iter num 100\n",
            "loss 2.895407999819705e-06 average time 0.0025161885199850077 iter num 50\n",
            "loss 2.8920416915631894e-06 average time 0.0024076020499751395 iter num 100\n",
            "loss 2.8785088371345146e-06 average time 0.0025991061000058837 iter num 50\n",
            "loss 2.8751098325650835e-06 average time 0.002582788510003411 iter num 100\n",
            "loss 2.8614032221130415e-06 average time 0.0026589274800153362 iter num 50\n",
            "loss 2.8579433013066535e-06 average time 0.002522141820008983 iter num 100\n",
            "loss 2.84398918566897e-06 average time 0.002473971379959039 iter num 50\n",
            "loss 2.8404604617415708e-06 average time 0.0025122991299758725 iter num 100\n",
            "loss 2.828109451262667e-06 average time 0.0025882705399817496 iter num 50\n",
            "loss 2.822631014826003e-06 average time 0.002599940459977006 iter num 100\n",
            "loss 7.656227949648638e-06 average time 0.002385001640022892 iter num 50\n",
            "loss 2.9283039853800403e-06 average time 0.002451301610021801 iter num 100\n",
            "loss 2.8699059091605496e-06 average time 0.0027294417400207747 iter num 50\n",
            "loss 2.864165329283946e-06 average time 0.0025437246500177933 iter num 100\n",
            "loss 2.845975826634151e-06 average time 0.002493860820031841 iter num 50\n",
            "loss 2.841997350710946e-06 average time 0.002454659840036584 iter num 100\n",
            "loss 2.8269425032993564e-06 average time 0.0023606971200206316 iter num 50\n",
            "loss 2.823343293217832e-06 average time 0.0023939854000263948 iter num 100\n",
            "loss 2.8091963969306997e-06 average time 0.0024824905800323906 iter num 50\n",
            "loss 2.80571067824383e-06 average time 0.0024616668800263143 iter num 100\n",
            "loss 2.7918377951659076e-06 average time 0.0023994729400055805 iter num 50\n",
            "loss 2.788372641697921e-06 average time 0.002436267380012396 iter num 100\n",
            "loss 2.7745047481894518e-06 average time 0.0024341848799849684 iter num 50\n",
            "loss 2.7710325894621104e-06 average time 0.0025407411899732325 iter num 100\n",
            "loss 2.7570387945564794e-06 average time 0.002832745339956091 iter num 50\n",
            "loss 2.753527893932848e-06 average time 0.0027484161599659273 iter num 100\n",
            "loss 2.7393411018469975e-06 average time 0.0025750631199844064 iter num 50\n",
            "loss 2.7357611420608966e-06 average time 0.002482168549945527 iter num 100\n",
            "loss 2.721315636866759e-06 average time 0.0023295741200308837 iter num 50\n",
            "loss 2.71767885711802e-06 average time 0.002314540079987637 iter num 100\n",
            "loss 2.7443902147947365e-06 average time 0.0024343644000236965 iter num 50\n",
            "loss 2.6998184424594554e-06 average time 0.0024320157100282814 iter num 100\n",
            "loss 5.441633159020978e-06 average time 0.002469531900042057 iter num 50\n",
            "loss 2.8111494769146744e-06 average time 0.0024224359200525213 iter num 100\n",
            "loss 2.753778806699508e-06 average time 0.0024805405599909137 iter num 50\n",
            "loss 2.7475349372757015e-06 average time 0.0026106258599793365 iter num 100\n",
            "loss 2.7291265975104903e-06 average time 0.002700159040014114 iter num 50\n",
            "loss 2.72509165403391e-06 average time 0.002578079370018713 iter num 100\n",
            "loss 2.709811230770873e-06 average time 0.002478896579959837 iter num 50\n",
            "loss 2.7061637613020466e-06 average time 0.0027311150300056396 iter num 100\n",
            "loss 2.6917971521285246e-06 average time 0.0027993925599639623 iter num 50\n",
            "loss 2.6882698880731203e-06 average time 0.002611576809977123 iter num 100\n",
            "loss 2.674203220519903e-06 average time 0.002503374300003998 iter num 50\n",
            "loss 2.6707138908429705e-06 average time 0.0025351947999843107 iter num 100\n",
            "loss 2.6567045685566353e-06 average time 0.0023729808799907914 iter num 50\n",
            "loss 2.653204270314066e-06 average time 0.0023624404800148113 iter num 100\n",
            "loss 2.639114913139368e-06 average time 0.002502749940040303 iter num 50\n",
            "loss 2.6355717902823688e-06 average time 0.0024610742200184177 iter num 100\n",
            "loss 2.628510790456658e-06 average time 0.0024304816799849503 iter num 50\n",
            "loss 2.6187406737973685e-06 average time 0.002384171679996143 iter num 100\n",
            "loss 2.7207866480017298e-06 average time 0.002383829520031213 iter num 50\n",
            "loss 2.610093681378666e-06 average time 0.0024376276800194318 iter num 100\n",
            "loss 2.596501332180781e-06 average time 0.0026253132800047752 iter num 50\n",
            "loss 2.5925956469036237e-06 average time 0.0025823666099813636 iter num 100\n",
            "loss 2.5790246729030383e-06 average time 0.002467072039989944 iter num 50\n",
            "loss 2.57543857697058e-06 average time 0.002496588239991979 iter num 100\n",
            "loss 4.1593046073985e-06 average time 0.0026019139400068527 iter num 50\n",
            "loss 2.61827500370179e-06 average time 0.00260685810000723 iter num 100\n",
            "loss 2.5892694629531127e-06 average time 0.0025570595799763395 iter num 50\n",
            "loss 2.584621808307803e-06 average time 0.0025589748599986707 iter num 100\n",
            "loss 2.570110277136297e-06 average time 0.002378095160029261 iter num 50\n",
            "loss 2.566691621067709e-06 average time 0.0023971180500166156 iter num 100\n",
            "loss 2.5532449956147107e-06 average time 0.0025752989600096045 iter num 50\n",
            "loss 2.5499392492380716e-06 average time 0.0024808897399907436 iter num 100\n",
            "loss 2.536691637401359e-06 average time 0.002519332379970365 iter num 50\n",
            "loss 2.53338850851872e-06 average time 0.0024506161799899926 iter num 100\n",
            "loss 2.5200814661713998e-06 average time 0.0023995892799302965 iter num 50\n",
            "loss 2.5167399619988217e-06 average time 0.0023641659999702825 iter num 100\n",
            "loss 2.503263968332308e-06 average time 0.0024471330800315627 iter num 50\n",
            "loss 2.49986327548028e-06 average time 0.002591682020033659 iter num 100\n",
            "loss 3.103540541851899e-06 average time 0.002477087440001924 iter num 50\n",
            "loss 2.498620707147626e-06 average time 0.0024393718399915087 iter num 100\n",
            "loss 2.4872444459282933e-06 average time 0.002794295920029981 iter num 50\n",
            "loss 2.4814371437184455e-06 average time 0.0026478484699919134 iter num 100\n",
            "loss 2.4854711241620633e-06 average time 0.0025629318399842307 iter num 50\n",
            "loss 2.4683241214949894e-06 average time 0.002477387049993922 iter num 100\n",
            "loss 2.874713503678682e-06 average time 0.002343638900019869 iter num 50\n",
            "loss 2.48901091486594e-06 average time 0.002434363110000959 iter num 100\n",
            "loss 2.469432053844306e-06 average time 0.0027990318599859167 iter num 50\n",
            "loss 2.465966096504755e-06 average time 0.0027272825100226328 iter num 100\n",
            "loss 2.4528101954540337e-06 average time 0.002559964579977532 iter num 50\n",
            "loss 2.4496313239756333e-06 average time 0.0024762486399959017 iter num 100\n",
            "loss 2.436985067417103e-06 average time 0.00249332407995098 iter num 50\n",
            "loss 2.4338316730094642e-06 average time 0.0025015923599630697 iter num 100\n",
            "loss 2.4212110098656145e-06 average time 0.0024389163200157784 iter num 50\n",
            "loss 2.418036782049385e-06 average time 0.0024315516500064403 iter num 100\n",
            "loss 2.4063842451680817e-06 average time 0.0023250444600216723 iter num 50\n",
            "loss 2.402115389527994e-06 average time 0.0023585548000255585 iter num 100\n",
            "loss 3.616809145561173e-06 average time 0.0024700571000084892 iter num 50\n",
            "loss 2.421953140098465e-06 average time 0.0024504108100290977 iter num 100\n",
            "loss 2.40389194802155e-06 average time 0.002416656339992187 iter num 50\n",
            "loss 2.400045875767421e-06 average time 0.002400361379977767 iter num 100\n",
            "loss 2.3883211632720215e-06 average time 0.002736552219967052 iter num 50\n",
            "loss 2.385493231378214e-06 average time 0.0025562653399902047 iter num 100\n",
            "loss 2.374244859028165e-06 average time 0.0023882244200012794 iter num 50\n",
            "loss 2.371450399545166e-06 average time 0.0025870704100088913 iter num 100\n",
            "loss 2.3602979500284523e-06 average time 0.0024208254199766088 iter num 50\n",
            "loss 2.3573930770660252e-06 average time 0.002376107909963139 iter num 100\n",
            "loss 5.471105167087733e-06 average time 0.0024800918399796503 iter num 50\n",
            "loss 2.391834813854644e-06 average time 0.0024968306399887298 iter num 100\n",
            "loss 2.3680292110573185e-06 average time 0.0025958618599815964 iter num 50\n",
            "loss 2.363385131855221e-06 average time 0.002480999789963789 iter num 100\n",
            "loss 2.3512981189161356e-06 average time 0.0024623452599917073 iter num 50\n",
            "loss 2.348419274632823e-06 average time 0.00240905928999382 iter num 100\n",
            "loss 2.3370860463358948e-06 average time 0.002657982999962769 iter num 50\n",
            "loss 2.334285615914716e-06 average time 0.002565083100012089 iter num 100\n",
            "loss 2.3230912788833115e-06 average time 0.00249646194001798 iter num 50\n",
            "loss 2.3202870431238495e-06 average time 0.002472063150007671 iter num 100\n",
            "loss 2.309016865542723e-06 average time 0.0023636852799972987 iter num 50\n",
            "loss 2.3061850285527974e-06 average time 0.0023583773499831293 iter num 100\n",
            "loss 2.294842090569861e-06 average time 0.0023620314599702395 iter num 50\n",
            "loss 2.2918815898193524e-06 average time 0.002338913559992761 iter num 100\n",
            "loss 5.485804229311609e-06 average time 0.0024127956999654998 iter num 50\n",
            "loss 2.330482782875875e-06 average time 0.0024330471799657973 iter num 100\n",
            "loss 2.3039320231793845e-06 average time 0.0025484334399607177 iter num 50\n",
            "loss 2.3002571801724202e-06 average time 0.002494497659990884 iter num 100\n",
            "loss 2.2877404690862244e-06 average time 0.0028441276399826165 iter num 50\n",
            "loss 2.2847805493977347e-06 average time 0.002672675719986728 iter num 100\n",
            "loss 2.273137707198881e-06 average time 0.0028374112600340596 iter num 50\n",
            "loss 2.270270098434432e-06 average time 0.002640671900012421 iter num 100\n",
            "loss 2.2588099231206967e-06 average time 0.0026379215200176987 iter num 50\n",
            "loss 2.2559413447579953e-06 average time 0.0028007131900312744 iter num 100\n",
            "loss 2.2444442977499063e-06 average time 0.002900582940046661 iter num 50\n",
            "loss 2.2415475223778435e-06 average time 0.002635896400006459 iter num 100\n",
            "loss 2.2893562541360064e-06 average time 0.00274609237995719 iter num 50\n",
            "loss 2.2277833177221282e-06 average time 0.0027296592299944676 iter num 100\n",
            "loss 2.803279407300525e-06 average time 0.0024928454999917447 iter num 50\n",
            "loss 2.2335884232315116e-06 average time 0.002499639239977114 iter num 100\n",
            "loss 2.220291295664059e-06 average time 0.002460833739978625 iter num 50\n",
            "loss 2.2175048206482797e-06 average time 0.0025634879400013235 iter num 100\n",
            "loss 2.2069401657232064e-06 average time 0.0023600835199977157 iter num 50\n",
            "loss 2.204312273370638e-06 average time 0.0023761568800000532 iter num 100\n",
            "loss 2.2040410303308875e-06 average time 0.0025094185600573835 iter num 50\n",
            "loss 2.1913506990109537e-06 average time 0.0024312493200159225 iter num 100\n",
            "loss 3.861761643839885e-06 average time 0.0025035576799746196 iter num 50\n",
            "loss 2.2875296537810732e-06 average time 0.0024218080399850805 iter num 100\n",
            "loss 2.238016012676215e-06 average time 0.002397170959966388 iter num 50\n",
            "loss 2.2318235089305086e-06 average time 0.002422438299990972 iter num 100\n",
            "loss 2.2171528077426147e-06 average time 0.0026360422799916704 iter num 50\n",
            "loss 2.2139881747905833e-06 average time 0.002552380339998308 iter num 100\n",
            "loss 2.202172636425268e-06 average time 0.0024648164399695815 iter num 50\n",
            "loss 2.1993706391012327e-06 average time 0.002440001949998987 iter num 100\n",
            "loss 2.188471584482702e-06 average time 0.0025552365399562405 iter num 50\n",
            "loss 2.1858097033696876e-06 average time 0.002498591439989468 iter num 100\n",
            "loss 2.1752742631465618e-06 average time 0.0024998637799853894 iter num 50\n",
            "loss 2.1726608227966937e-06 average time 0.0026570254500120427 iter num 100\n",
            "loss 2.1622465870278152e-06 average time 0.00243309948001297 iter num 50\n",
            "loss 2.1596470877753785e-06 average time 0.0023974401600116834 iter num 100\n",
            "loss 2.149229169718206e-06 average time 0.002469157220057241 iter num 50\n",
            "loss 2.146622225346347e-06 average time 0.002717757220025305 iter num 100\n",
            "loss 2.1361309970431164e-06 average time 0.0027948598399962065 iter num 50\n",
            "loss 2.1334847484826937e-06 average time 0.0026923801499833646 iter num 100\n",
            "loss 2.122981261789163e-06 average time 0.0026453855399995517 iter num 50\n",
            "loss 2.120174770603738e-06 average time 0.0027399288999913553 iter num 100\n",
            "loss 2.178222233595249e-06 average time 0.0026683746000253448 iter num 50\n",
            "loss 2.113374202873276e-06 average time 0.0027866043900348814 iter num 100\n",
            "loss 2.3193975910306855e-06 average time 0.002544591660016522 iter num 50\n",
            "loss 2.110736411723355e-06 average time 0.002443562450016543 iter num 100\n",
            "loss 2.0995772087557805e-06 average time 0.0024786411800596397 iter num 50\n",
            "loss 2.0970641763342043e-06 average time 0.0024299169600544702 iter num 100\n",
            "loss 2.088226380564323e-06 average time 0.00233451763994708 iter num 50\n",
            "loss 2.0846464629890114e-06 average time 0.0023086308599704355 iter num 100\n",
            "loss 3.0742654712223294e-06 average time 0.0024111140799413988 iter num 50\n",
            "loss 2.130602141360391e-06 average time 0.002428520069984188 iter num 100\n",
            "loss 2.1047614532348577e-06 average time 0.0024620048599717846 iter num 50\n",
            "loss 2.100709330438628e-06 average time 0.0026573709399599467 iter num 100\n",
            "loss 2.089012980954706e-06 average time 0.0026971835200129135 iter num 50\n",
            "loss 2.0863123851801895e-06 average time 0.0025282367600311774 iter num 100\n",
            "loss 2.0758731155684327e-06 average time 0.0024004699200486355 iter num 50\n",
            "loss 2.0733264470441783e-06 average time 0.002550663050028561 iter num 100\n",
            "loss 2.063245171658876e-06 average time 0.0026727406600093673 iter num 50\n",
            "loss 2.0607432619465946e-06 average time 0.0026002368600165937 iter num 100\n",
            "loss 2.05074026378356e-06 average time 0.002492274499973064 iter num 50\n",
            "loss 2.0482363919279882e-06 average time 0.002483790299984321 iter num 100\n",
            "loss 2.0381930673788187e-06 average time 0.002511833739990834 iter num 50\n",
            "loss 2.035670148319858e-06 average time 0.002645638889989641 iter num 100\n",
            "loss 2.0390534752728005e-06 average time 0.0025533832399742096 iter num 50\n",
            "loss 2.0233733662421757e-06 average time 0.0025603644399870974 iter num 100\n",
            "loss 2.877542905471639e-06 average time 0.003048316660015189 iter num 50\n",
            "loss 2.0468632851598363e-06 average time 0.002830194879998089 iter num 100\n",
            "loss 2.0301941531253244e-06 average time 0.002388033240004006 iter num 50\n",
            "loss 2.027087879550286e-06 average time 0.002365344019995064 iter num 100\n",
            "loss 2.017618623375941e-06 average time 0.0024014280600204076 iter num 50\n",
            "loss 2.0153661957050436e-06 average time 0.002394751580004595 iter num 100\n",
            "loss 2.0065025444326086e-06 average time 0.002470948180016421 iter num 50\n",
            "loss 2.0043110260284167e-06 average time 0.0024173450900070747 iter num 100\n",
            "loss 1.995546966950429e-06 average time 0.0024555785000029574 iter num 50\n",
            "loss 1.993351817875687e-06 average time 0.002478276280016871 iter num 100\n",
            "loss 1.99127870044485e-06 average time 0.0025246689199684624 iter num 50\n",
            "loss 1.9823756266085124e-06 average time 0.002513078949982628 iter num 100\n",
            "loss 3.7792795797016445e-06 average time 0.002400699639965751 iter num 50\n",
            "loss 2.0725858082932505e-06 average time 0.0025582263899696046 iter num 100\n",
            "loss 2.0264752513538642e-06 average time 0.0026426723999793465 iter num 50\n",
            "loss 2.021254741538686e-06 average time 0.002592512979995263 iter num 100\n",
            "loss 2.0082226178052927e-06 average time 0.00269090586002676 iter num 50\n",
            "loss 2.0054264574735033e-06 average time 0.0026158954600077776 iter num 100\n",
            "loss 1.995009813489595e-06 average time 0.0025312260600003356 iter num 50\n",
            "loss 1.992558396257916e-06 average time 0.002610055649993228 iter num 100\n",
            "loss 1.9830144758366238e-06 average time 0.0026591495200591455 iter num 50\n",
            "loss 1.980693563120631e-06 average time 0.0026468146100523883 iter num 100\n",
            "loss 1.971529914463193e-06 average time 0.0024027696200300853 iter num 50\n",
            "loss 1.9692721312582207e-06 average time 0.002529725100030191 iter num 100\n",
            "loss 1.960258764535094e-06 average time 0.0025232698400213848 iter num 50\n",
            "loss 1.958013429323938e-06 average time 0.0024902164800096214 iter num 100\n",
            "loss 1.9490390132084348e-06 average time 0.0023613109400412212 iter num 50\n",
            "loss 1.9467928441170862e-06 average time 0.0024531272600324884 iter num 100\n",
            "loss 1.9377724296161374e-06 average time 0.0023677079000208323 iter num 50\n",
            "loss 1.9355142231571013e-06 average time 0.002387848830016992 iter num 100\n",
            "loss 1.92639356722584e-06 average time 0.0024566734000563886 iter num 50\n",
            "loss 1.9241017123879934e-06 average time 0.002474465380055335 iter num 100\n",
            "loss 1.9159790201974104e-06 average time 0.0024299836799764308 iter num 50\n",
            "loss 1.912639170095579e-06 average time 0.0026987558299924786 iter num 100\n",
            "loss 4.356941864754453e-06 average time 0.002440592920011113 iter num 50\n",
            "loss 1.9474585887750204e-06 average time 0.0024408446399911553 iter num 100\n",
            "loss 1.927317591367944e-06 average time 0.0023550588200123455 iter num 50\n",
            "loss 1.9244566148990885e-06 average time 0.002414447260034649 iter num 100\n",
            "loss 1.915416148453448e-06 average time 0.002622804399979941 iter num 50\n",
            "loss 1.9133243082876245e-06 average time 0.0025080347299899584 iter num 100\n",
            "loss 1.9051861595022012e-06 average time 0.003019089579966021 iter num 50\n",
            "loss 1.9031980990071465e-06 average time 0.0028515481999875194 iter num 100\n",
            "loss 1.895290566652387e-06 average time 0.0023768542400193836 iter num 50\n",
            "loss 1.8933226746026807e-06 average time 0.00238412060004066 iter num 100\n",
            "loss 1.8854310113211739e-06 average time 0.0023390722799558716 iter num 50\n",
            "loss 1.8834507284770933e-06 average time 0.0023569670299821155 iter num 100\n",
            "loss 1.8755659123721747e-06 average time 0.0023719286599953194 iter num 50\n",
            "loss 1.8734831722181274e-06 average time 0.0024051993900093293 iter num 100\n",
            "loss 2.4831242751758708e-06 average time 0.002547763520014996 iter num 50\n",
            "loss 1.9051611851397783e-06 average time 0.0024647419499933677 iter num 100\n",
            "loss 1.886093904243068e-06 average time 0.0024335015200267662 iter num 50\n",
            "loss 1.883446139800639e-06 average time 0.0024939619499946275 iter num 100\n",
            "loss 1.8741525233017763e-06 average time 0.0027881503999833512 iter num 50\n",
            "loss 1.8719791407203411e-06 average time 0.0027006138600199846 iter num 100\n",
            "loss 1.8634936350361905e-06 average time 0.002775128200037216 iter num 50\n",
            "loss 1.8614157476113034e-06 average time 0.0027282388200137574 iter num 100\n",
            "loss 1.8531463594977333e-06 average time 0.002480801540013999 iter num 50\n",
            "loss 1.8510941948017068e-06 average time 0.0025022367300243788 iter num 100\n",
            "loss 1.8428467368857047e-06 average time 0.0023999653799910447 iter num 50\n",
            "loss 1.8407819508770139e-06 average time 0.0024422997799638324 iter num 100\n",
            "loss 1.8324770035079751e-06 average time 0.0024600179600474804 iter num 50\n",
            "loss 1.8303899311258406e-06 average time 0.0025202540500322357 iter num 100\n",
            "loss 1.822161937103416e-06 average time 0.0025507295800161955 iter num 50\n",
            "loss 1.8198912795504162e-06 average time 0.002598683409996738 iter num 100\n",
            "loss 4.125503949585644e-06 average time 0.002406455679965802 iter num 50\n",
            "loss 1.9172794234352473e-06 average time 0.0023912660699852493 iter num 100\n",
            "loss 1.8686429907162422e-06 average time 0.0026226859600137686 iter num 50\n",
            "loss 1.8641258355892328e-06 average time 0.0025007419500207104 iter num 100\n",
            "loss 1.8506174363778939e-06 average time 0.0024774006600273425 iter num 50\n",
            "loss 1.8477800301328185e-06 average time 0.0024633455200228126 iter num 100\n",
            "loss 1.8373556222700266e-06 average time 0.0025753681999776744 iter num 50\n",
            "loss 1.8349280416336827e-06 average time 0.0025395546699928675 iter num 100\n",
            "loss 1.8255806539044198e-06 average time 0.0026503904800028975 iter num 50\n",
            "loss 1.823317738958092e-06 average time 0.0027156644600199796 iter num 100\n",
            "loss 1.814456526340555e-06 average time 0.002523216500030685 iter num 50\n",
            "loss 1.8122871518897533e-06 average time 0.0025100575600208687 iter num 100\n",
            "loss 1.803659225113029e-06 average time 0.002656681980024587 iter num 50\n",
            "loss 1.8015222284033198e-06 average time 0.0027848918800100365 iter num 100\n",
            "loss 1.8033653102797999e-06 average time 0.002757904520003649 iter num 50\n",
            "loss 1.7911131576886224e-06 average time 0.0026168886799950997 iter num 100\n",
            "loss 1.814610136286375e-06 average time 0.002495659199994407 iter num 50\n",
            "loss 1.7861669739305871e-06 average time 0.0024732824099919525 iter num 100\n",
            "loss 1.7779994730925695e-06 average time 0.0026041734800037377 iter num 50\n",
            "loss 1.7758689523711345e-06 average time 0.002502834879992406 iter num 100\n",
            "loss 1.768001735239292e-06 average time 0.002457757779984604 iter num 50\n",
            "loss 1.7660408117691356e-06 average time 0.0024278207500083226 iter num 100\n",
            "loss 1.7584333870475292e-06 average time 0.002714027880001595 iter num 50\n",
            "loss 1.7561635845324244e-06 average time 0.002590281950001554 iter num 100\n",
            "loss 3.2441212809783024e-06 average time 0.0028635209199910604 iter num 50\n",
            "loss 1.7921513590915071e-06 average time 0.002734276729984231 iter num 100\n",
            "loss 1.7724756688232601e-06 average time 0.002455625879983927 iter num 50\n",
            "loss 1.7689617438752471e-06 average time 0.0025277721099928384 iter num 100\n",
            "loss 1.7599946820594393e-06 average time 0.0024968419799824915 iter num 50\n",
            "loss 1.75791527922074e-06 average time 0.0025038022399985495 iter num 100\n",
            "loss 1.7498737920792916e-06 average time 0.002343902960010382 iter num 50\n",
            "loss 1.7479096054794442e-06 average time 0.0024414934000151333 iter num 100\n",
            "loss 1.7401241026646833e-06 average time 0.0024382761000651954 iter num 50\n",
            "loss 1.7381891943431791e-06 average time 0.002449198140006956 iter num 100\n",
            "loss 1.7304594684648893e-06 average time 0.0024524040799678913 iter num 50\n",
            "loss 1.7285329241378928e-06 average time 0.002445573819973106 iter num 100\n",
            "loss 1.7207778110192552e-06 average time 0.0024599796399888876 iter num 50\n",
            "loss 1.7188178200005608e-06 average time 0.0024733011800026363 iter num 100\n",
            "loss 1.7216954449296296e-06 average time 0.002470123179991788 iter num 50\n",
            "loss 1.7091236135648684e-06 average time 0.00245368320999205 iter num 100\n",
            "loss 3.1498809541588223e-06 average time 0.0025336088400035807 iter num 50\n",
            "loss 1.7281623947934837e-06 average time 0.0024473393899916117 iter num 100\n",
            "loss 1.7149337521565532e-06 average time 0.0027416999200340795 iter num 50\n",
            "loss 1.7126707287264852e-06 average time 0.002689262470007634 iter num 100\n",
            "loss 1.7048506603838789e-06 average time 0.0027803596800094967 iter num 50\n",
            "loss 1.7030110754707122e-06 average time 0.0027176077600097413 iter num 100\n",
            "loss 1.6957778266382774e-06 average time 0.0029239758399944547 iter num 50\n",
            "loss 1.6939962858019797e-06 average time 0.0028000152599952344 iter num 100\n",
            "loss 1.6874236334554032e-06 average time 0.002458656700009669 iter num 50\n",
            "loss 1.6851027063855972e-06 average time 0.0024246477800079448 iter num 100\n",
            "loss 1.7850255450210025e-06 average time 0.0023837271399679595 iter num 50\n",
            "loss 1.7335287753236258e-06 average time 0.0025003753199780475 iter num 100\n",
            "loss 1.707376378660871e-06 average time 0.0028701355399880415 iter num 50\n",
            "loss 1.7044361582929557e-06 average time 0.002631581799992091 iter num 100\n",
            "loss 1.695283798288187e-06 average time 0.002575123819979126 iter num 50\n",
            "loss 1.693225477786261e-06 average time 0.002673526190001212 iter num 100\n",
            "loss 1.6853680910964957e-06 average time 0.003015103539974007 iter num 50\n",
            "loss 1.6834805241174294e-06 average time 0.0027446888100121215 iter num 100\n",
            "loss 1.6760652274856575e-06 average time 0.002537325020020944 iter num 50\n",
            "loss 1.6742444318578103e-06 average time 0.0024491718400258835 iter num 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b3be0cc-7ec7-4b6f-f8b8-dc8109dcbf5e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_knock_out_1stock_oldmethod_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fceb619b-afdc-456f-c986-b85fb5321f4a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf5758c-f1a7-4310-c0a9-8e568f340d51"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_knock_out_1stock_oldmethod_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0519f05-071c-4043-934a-e6c1cac30c21"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=7, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (fc4): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc5): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc6): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "626245d6-cd81-4004-9766-4c8ac5588923"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3, eps=1e-4, amsgrad=True) # try using higher epsilon and amsgrad\n",
        "dataset = OptionDataSet(max_len = 100) # Use max_len to adjust\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    # print(x)\n",
        "    # print(x.shape)\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    # print(y.shape)\n",
        "    y_pred = model(x.float())\n",
        "    # print(y_pred)\n",
        "    # print(y_pred.shape)\n",
        "\n",
        "    # def compute_deltas(x):\n",
        "    #   inputs = x.float()\n",
        "    #   inputs.requires_grad = True\n",
        "    #   first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "    #   return first_order_gradient[0][[3]]  # Now index 3 is stock price, not 2\n",
        "\n",
        "    # deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    # y_pred = torch.cat((y_pred, deltas), 1)\n",
        "    # # print(y_pred)\n",
        "    # # print(y_pred.shape)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 50\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 500)\n",
        "\n",
        "model_save_name = 'jax_knock_out_1stock_oldmethod_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 1.3407199008631148e-06 average time 0.003193879139926139 iter num 50\n",
            "loss 1.3206834663197942e-06 average time 0.003108112319987413 iter num 100\n",
            "loss 1.3201458205059402e-06 average time 0.0027091525999821896 iter num 50\n",
            "loss 1.3200664583748351e-06 average time 0.0027878850000070086 iter num 100\n",
            "loss 1.3197210074136667e-06 average time 0.0028368348000003605 iter num 50\n",
            "loss 1.3196450904599096e-06 average time 0.0027496826699461964 iter num 100\n",
            "loss 1.3192882166101852e-06 average time 0.0024544070800220654 iter num 50\n",
            "loss 1.3192052165533085e-06 average time 0.0024724965500172403 iter num 100\n",
            "loss 1.3188423792227456e-06 average time 0.0026407354599541576 iter num 50\n",
            "loss 1.3187612357383517e-06 average time 0.002569998129984015 iter num 100\n",
            "loss 1.3183907525366272e-06 average time 0.002567306640048628 iter num 50\n",
            "loss 1.3183061485738813e-06 average time 0.0027504652300376618 iter num 100\n",
            "loss 1.3179345063198787e-06 average time 0.0026580105000175536 iter num 50\n",
            "loss 1.3178490174481824e-06 average time 0.0026237977499749834 iter num 100\n",
            "loss 1.3174730242373893e-06 average time 0.0025328799399903803 iter num 50\n",
            "loss 1.3173854490988872e-06 average time 0.0025218460999985835 iter num 100\n",
            "loss 1.3170143042001628e-06 average time 0.0025747366400901226 iter num 50\n",
            "loss 1.3169263182958496e-06 average time 0.0025466071200298756 iter num 100\n",
            "loss 1.3165488310750323e-06 average time 0.0025771720599186664 iter num 50\n",
            "loss 1.3164598363212358e-06 average time 0.002640725499986729 iter num 100\n",
            "loss 1.3160787915955692e-06 average time 0.002707934000009118 iter num 50\n",
            "loss 1.3159915718085287e-06 average time 0.0026342100300007585 iter num 100\n",
            "loss 1.315603262858171e-06 average time 0.0025339828799769747 iter num 50\n",
            "loss 1.3155169526126657e-06 average time 0.0025392773099429176 iter num 100\n",
            "loss 1.3151323625690543e-06 average time 0.002908259360028751 iter num 50\n",
            "loss 1.315042942868496e-06 average time 0.0027468140799919638 iter num 100\n",
            "loss 1.3146615145700829e-06 average time 0.002473190359924047 iter num 50\n",
            "loss 1.3145695136475778e-06 average time 0.002546026449999772 iter num 100\n",
            "loss 1.3141844820267657e-06 average time 0.0024861337800393814 iter num 50\n",
            "loss 1.3140955899860506e-06 average time 0.002481963780037404 iter num 100\n",
            "loss 1.313707220442146e-06 average time 0.002594226659984997 iter num 50\n",
            "loss 1.3136232103887696e-06 average time 0.0026083148699672164 iter num 100\n",
            "loss 1.3132372306578152e-06 average time 0.0024755085799915834 iter num 50\n",
            "loss 1.3131442191353298e-06 average time 0.0025348118599868032 iter num 100\n",
            "loss 1.312759837821333e-06 average time 0.0028234340400013023 iter num 50\n",
            "loss 1.3126657956598063e-06 average time 0.002789897700004076 iter num 100\n",
            "loss 1.3122781616996825e-06 average time 0.0025291242000275815 iter num 50\n",
            "loss 1.3121905545949711e-06 average time 0.002503165500047544 iter num 100\n",
            "loss 1.311802934964695e-06 average time 0.00249584600000162 iter num 50\n",
            "loss 1.31171457682915e-06 average time 0.0024705486000402743 iter num 100\n",
            "loss 1.3113261927428004e-06 average time 0.0024860681000609475 iter num 50\n",
            "loss 1.3112422560986275e-06 average time 0.00261520409001605 iter num 100\n",
            "loss 1.31084897909547e-06 average time 0.002552717000053235 iter num 50\n",
            "loss 1.3107622601696653e-06 average time 0.002542682000030254 iter num 100\n",
            "loss 1.3103714892304887e-06 average time 0.003165731839999353 iter num 50\n",
            "loss 1.31027892637812e-06 average time 0.0028784492599424993 iter num 100\n",
            "loss 1.3098934455400866e-06 average time 0.0025173629600249115 iter num 50\n",
            "loss 1.3098018779359725e-06 average time 0.00247345318999578 iter num 100\n",
            "loss 1.3094125443155571e-06 average time 0.002993507899955148 iter num 50\n",
            "loss 1.3093237364898741e-06 average time 0.0027583409099406707 iter num 100\n",
            "loss 1.3089335287232903e-06 average time 0.002596363320026285 iter num 50\n",
            "loss 1.3088494954156718e-06 average time 0.002600297699973453 iter num 100\n",
            "loss 1.3084601939984614e-06 average time 0.0026953615198908663 iter num 50\n",
            "loss 1.3083681496127295e-06 average time 0.0026664904799326905 iter num 100\n",
            "loss 1.3079788185947197e-06 average time 0.002520994620099373 iter num 50\n",
            "loss 1.3078911447886479e-06 average time 0.002530147570032568 iter num 100\n",
            "loss 1.3074988391881005e-06 average time 0.002528878520042781 iter num 50\n",
            "loss 1.3074135307922453e-06 average time 0.002572422279981765 iter num 100\n",
            "loss 1.3070265144156664e-06 average time 0.0025876018399139866 iter num 50\n",
            "loss 1.3069384858140002e-06 average time 0.0025771440999596963 iter num 100\n",
            "loss 1.3065496762607486e-06 average time 0.0027014725799926966 iter num 50\n",
            "loss 1.3064606215777022e-06 average time 0.0026014487000338704 iter num 100\n",
            "loss 1.3060711835310713e-06 average time 0.0027678381000441734 iter num 50\n",
            "loss 1.3059828751107416e-06 average time 0.002775547290020768 iter num 100\n",
            "loss 1.3055958063014528e-06 average time 0.002491702020070079 iter num 50\n",
            "loss 1.3055029753121413e-06 average time 0.0025100389700128288 iter num 100\n",
            "loss 1.3051205019011716e-06 average time 0.002603491079935338 iter num 50\n",
            "loss 1.3050299364005288e-06 average time 0.002635901929970714 iter num 100\n",
            "loss 1.3046404448462993e-06 average time 0.002572848939907999 iter num 50\n",
            "loss 1.3045506175845515e-06 average time 0.0025512593099574587 iter num 100\n",
            "loss 1.3041645256805132e-06 average time 0.002785751040028117 iter num 50\n",
            "loss 1.3040760495202622e-06 average time 0.00267565509004271 iter num 100\n",
            "loss 1.3036883516535036e-06 average time 0.002748826119950536 iter num 50\n",
            "loss 1.3036017264216469e-06 average time 0.0026801868100028515 iter num 100\n",
            "loss 1.303214505105934e-06 average time 0.0031491606400049933 iter num 50\n",
            "loss 1.3031263097571986e-06 average time 0.0028731876599704265 iter num 100\n",
            "loss 1.3027419832962193e-06 average time 0.0027486414799750493 iter num 50\n",
            "loss 1.3026530132140248e-06 average time 0.0026146491599502043 iter num 100\n",
            "loss 1.3022668458714803e-06 average time 0.0024998198401044646 iter num 50\n",
            "loss 1.3021811818958572e-06 average time 0.0025168258600751867 iter num 100\n",
            "loss 1.3017996415367854e-06 average time 0.0025920255399796586 iter num 50\n",
            "loss 1.3017057237631302e-06 average time 0.0025827498100170487 iter num 100\n",
            "loss 1.30131698696689e-06 average time 0.002594140120090742 iter num 50\n",
            "loss 1.3012347958176219e-06 average time 0.00262065641008121 iter num 100\n",
            "loss 1.300846227581246e-06 average time 0.0027222187600091275 iter num 50\n",
            "loss 1.300758617007134e-06 average time 0.002629391760010549 iter num 100\n",
            "loss 1.300376220480598e-06 average time 0.0026629445599610337 iter num 50\n",
            "loss 1.3002865136426292e-06 average time 0.0025660197099387004 iter num 100\n",
            "loss 1.2999012224241657e-06 average time 0.0024605815000177246 iter num 50\n",
            "loss 1.2998118070433244e-06 average time 0.0025723262000246906 iter num 100\n",
            "loss 1.2994308611602229e-06 average time 0.0025569283199547497 iter num 50\n",
            "loss 1.2993429501386222e-06 average time 0.0025013673299963558 iter num 100\n",
            "loss 1.2989552754620923e-06 average time 0.002610084860025381 iter num 50\n",
            "loss 1.2988700483190493e-06 average time 0.0025966179000079135 iter num 100\n",
            "loss 1.2984871783533269e-06 average time 0.002684752260120149 iter num 50\n",
            "loss 1.2983992557281289e-06 average time 0.0026358246900872475 iter num 100\n",
            "loss 1.2980168881938462e-06 average time 0.0024718479600596764 iter num 50\n",
            "loss 1.2979281023090675e-06 average time 0.0026151057100469188 iter num 100\n",
            "loss 1.2975441191223267e-06 average time 0.002778546179906698 iter num 50\n",
            "loss 1.29745800016858e-06 average time 0.002643702149907767 iter num 100\n",
            "loss 1.297076850708512e-06 average time 0.002450524059950112 iter num 50\n",
            "loss 1.2969901960353213e-06 average time 0.0024561264000021767 iter num 100\n",
            "loss 1.2966076901543e-06 average time 0.002642881000047055 iter num 50\n",
            "loss 1.2965193184892593e-06 average time 0.002574920490023942 iter num 100\n",
            "loss 1.2961390305323175e-06 average time 0.0024971579600241967 iter num 50\n",
            "loss 1.2960504921615747e-06 average time 0.002485743549987092 iter num 100\n",
            "loss 1.2956710759320475e-06 average time 0.0024909655400188056 iter num 50\n",
            "loss 1.2955838139377053e-06 average time 0.0024887041300007697 iter num 100\n",
            "loss 1.2952045216269946e-06 average time 0.002480041399903712 iter num 50\n",
            "loss 1.2951134305896367e-06 average time 0.002564930589933283 iter num 100\n",
            "loss 1.294736100656469e-06 average time 0.002552571340038412 iter num 50\n",
            "loss 1.294644813252854e-06 average time 0.0025937039600376012 iter num 100\n",
            "loss 1.2942664328063229e-06 average time 0.0026336213600370684 iter num 50\n",
            "loss 1.2941817111176762e-06 average time 0.0026077683600124147 iter num 100\n",
            "loss 1.2938021068943825e-06 average time 0.0031457669800147416 iter num 50\n",
            "loss 1.293715342249269e-06 average time 0.003193842830023641 iter num 100\n",
            "loss 1.293336447490887e-06 average time 0.002672324480063253 iter num 50\n",
            "loss 1.2932448128951557e-06 average time 0.0026657308300127623 iter num 100\n",
            "loss 1.2928713366113455e-06 average time 0.002507569740027975 iter num 50\n",
            "loss 1.2927804455112505e-06 average time 0.0025457052400815884 iter num 100\n",
            "loss 1.2924018032294695e-06 average time 0.002550989559986192 iter num 50\n",
            "loss 1.2923113445631644e-06 average time 0.0025072239100063596 iter num 100\n",
            "loss 1.2919330169120203e-06 average time 0.0030048115001227414 iter num 50\n",
            "loss 1.2918521950361084e-06 average time 0.002774984330035295 iter num 100\n",
            "loss 1.2914745634572146e-06 average time 0.0027420973999869604 iter num 50\n",
            "loss 1.2913881187166216e-06 average time 0.0026968741299697287 iter num 100\n",
            "loss 1.291003695786733e-06 average time 0.002532213819958997 iter num 50\n",
            "loss 1.290919186371596e-06 average time 0.0025214252499608848 iter num 100\n",
            "loss 1.2905400362968803e-06 average time 0.002858770999991975 iter num 50\n",
            "loss 1.2904611322344246e-06 average time 0.002658271899999818 iter num 100\n",
            "loss 1.2900775267197336e-06 average time 0.0025453795399334924 iter num 50\n",
            "loss 1.2899935822685594e-06 average time 0.002600646549972225 iter num 100\n",
            "loss 1.2896167298575899e-06 average time 0.0026639092399818763 iter num 50\n",
            "loss 1.2895280847881683e-06 average time 0.0026021997399948305 iter num 100\n",
            "loss 1.2891544939418414e-06 average time 0.0025342826599808175 iter num 50\n",
            "loss 1.2890687211601657e-06 average time 0.002538037069998609 iter num 100\n",
            "loss 1.288692787619875e-06 average time 0.002537584460042126 iter num 50\n",
            "loss 1.2886098299526222e-06 average time 0.0025491362800221396 iter num 100\n",
            "loss 1.2882312831850812e-06 average time 0.0026105195598938734 iter num 50\n",
            "loss 1.2881447814370147e-06 average time 0.0025883258899557404 iter num 100\n",
            "loss 1.2877710964866375e-06 average time 0.002508155699888448 iter num 50\n",
            "loss 1.2876860853651737e-06 average time 0.0024745734499083483 iter num 100\n",
            "loss 1.2873102626474467e-06 average time 0.0026758502598931955 iter num 50\n",
            "loss 1.287222896439207e-06 average time 0.00255809442991449 iter num 100\n",
            "loss 1.2868501342051925e-06 average time 0.002683072820018424 iter num 50\n",
            "loss 1.2867598230327888e-06 average time 0.0026257631400312675 iter num 100\n",
            "loss 1.2863873017108428e-06 average time 0.0026847731399357146 iter num 50\n",
            "loss 1.2863043605497487e-06 average time 0.002600586959952125 iter num 100\n",
            "loss 1.285932027591146e-06 average time 0.0029962579200582696 iter num 50\n",
            "loss 1.2858406182537857e-06 average time 0.0027542803500273296 iter num 100\n",
            "loss 1.2854694710335647e-06 average time 0.0030633272000159194 iter num 50\n",
            "loss 1.2853853291206002e-06 average time 0.0028048827999737113 iter num 100\n",
            "loss 1.2850122006477053e-06 average time 0.0024991748399952485 iter num 50\n",
            "loss 1.2849225250188355e-06 average time 0.0026353424599710705 iter num 100\n",
            "loss 1.2845510038498967e-06 average time 0.002676209860073868 iter num 50\n",
            "loss 1.2844670592405834e-06 average time 0.0027159492800456066 iter num 100\n",
            "loss 1.2840881798220183e-06 average time 0.002547123240092333 iter num 50\n",
            "loss 1.2840075679280764e-06 average time 0.002565021060045183 iter num 100\n",
            "loss 1.283638334155671e-06 average time 0.002655155999982526 iter num 50\n",
            "loss 1.2835506559923187e-06 average time 0.0027284637699995073 iter num 100\n",
            "loss 1.283174542859042e-06 average time 0.0026102191401150775 iter num 50\n",
            "loss 1.283092491998454e-06 average time 0.0026134875200841635 iter num 100\n",
            "loss 1.2827219243453283e-06 average time 0.0025924090000444266 iter num 50\n",
            "loss 1.2826375354564446e-06 average time 0.002744378779998442 iter num 100\n",
            "loss 1.2822652299218634e-06 average time 0.0025142322599640467 iter num 50\n",
            "loss 1.2821785258031974e-06 average time 0.002517028999964168 iter num 100\n",
            "loss 1.2818080697720075e-06 average time 0.0031635362799897846 iter num 50\n",
            "loss 1.2817230182677308e-06 average time 0.0029725854799471565 iter num 100\n",
            "loss 1.2813530341368102e-06 average time 0.0030839932599337773 iter num 50\n",
            "loss 1.2812694113799167e-06 average time 0.0029093475399804445 iter num 100\n",
            "loss 1.28089982549372e-06 average time 0.0026995435599928897 iter num 50\n",
            "loss 1.2808139725638846e-06 average time 0.002631907150034749 iter num 100\n",
            "loss 1.2804404892115603e-06 average time 0.0029272231399590965 iter num 50\n",
            "loss 1.2803582161319704e-06 average time 0.002722384169946963 iter num 100\n",
            "loss 1.2799897087717444e-06 average time 0.00282374707996496 iter num 50\n",
            "loss 1.2799044353215974e-06 average time 0.002668487129931236 iter num 100\n",
            "loss 1.2795358546251828e-06 average time 0.0025408656199942927 iter num 50\n",
            "loss 1.2794499073645313e-06 average time 0.0026538994800193905 iter num 100\n",
            "loss 1.279082350013183e-06 average time 0.003222490399966773 iter num 50\n",
            "loss 1.2789929833735574e-06 average time 0.003196535609931743 iter num 100\n",
            "loss 1.2786283994766796e-06 average time 0.0025055845800306996 iter num 50\n",
            "loss 1.2785436301142188e-06 average time 0.002501403720016242 iter num 100\n",
            "loss 1.2781768363119116e-06 average time 0.0026364309399468768 iter num 50\n",
            "loss 1.2780938993263318e-06 average time 0.0025879874099791777 iter num 100\n",
            "loss 1.277724255650293e-06 average time 0.002632514340093621 iter num 50\n",
            "loss 1.2776403912626335e-06 average time 0.0026395576900449668 iter num 100\n",
            "loss 1.2772718047051905e-06 average time 0.0026023109200104953 iter num 50\n",
            "loss 1.2771909501594688e-06 average time 0.0026718680399972074 iter num 100\n",
            "loss 1.276821923782272e-06 average time 0.00249620220003635 iter num 50\n",
            "loss 1.2767386563140597e-06 average time 0.0024641962000077912 iter num 100\n",
            "loss 1.2763696168683063e-06 average time 0.002530012959978194 iter num 50\n",
            "loss 1.2762900756853118e-06 average time 0.002556429539981764 iter num 100\n",
            "loss 1.2759207951025783e-06 average time 0.0026252967399886984 iter num 50\n",
            "loss 1.275838081328396e-06 average time 0.002539804310008549 iter num 100\n",
            "loss 1.2754701595171295e-06 average time 0.002529981840034452 iter num 50\n",
            "loss 1.2753843276123217e-06 average time 0.0025076354299926606 iter num 100\n",
            "loss 1.275019169487681e-06 average time 0.002519913600026484 iter num 50\n",
            "loss 1.2749369854258146e-06 average time 0.002527572039971346 iter num 100\n",
            "loss 1.2745701922745966e-06 average time 0.0025609824599632704 iter num 50\n",
            "loss 1.2744891913320355e-06 average time 0.0025620716799858202 iter num 100\n",
            "loss 1.2741197948007881e-06 average time 0.0025769001999105968 iter num 50\n",
            "loss 1.2740395873485536e-06 average time 0.002530257039961725 iter num 100\n",
            "loss 1.2736686781515618e-06 average time 0.0025347630000214848 iter num 50\n",
            "loss 1.2735888140673697e-06 average time 0.002577147919992058 iter num 100\n",
            "loss 1.2732207521570279e-06 average time 0.002658776919979573 iter num 50\n",
            "loss 1.2731353455663041e-06 average time 0.0027022886400118297 iter num 100\n",
            "loss 1.272777402653523e-06 average time 0.0026078942000094685 iter num 50\n",
            "loss 1.2726915609600187e-06 average time 0.0025381867800297188 iter num 100\n",
            "loss 1.2723319317345313e-06 average time 0.0024948770799710475 iter num 50\n",
            "loss 1.2722470631059592e-06 average time 0.0024855706800008194 iter num 100\n",
            "loss 1.2718837582302227e-06 average time 0.0025142719399082127 iter num 50\n",
            "loss 1.27179558872062e-06 average time 0.0025173372999415734 iter num 100\n",
            "loss 1.2714355552224687e-06 average time 0.0025719700600348007 iter num 50\n",
            "loss 1.2713534565679917e-06 average time 0.0027548723700419942 iter num 100\n",
            "loss 1.2709902387455454e-06 average time 0.00282085463995827 iter num 50\n",
            "loss 1.270907093606763e-06 average time 0.002775861710006211 iter num 100\n",
            "loss 1.2705414403318952e-06 average time 0.002620257200032938 iter num 50\n",
            "loss 1.2704589207066781e-06 average time 0.002648316649992921 iter num 100\n",
            "loss 1.2700977796730914e-06 average time 0.0026363165600378127 iter num 50\n",
            "loss 1.2700152491431707e-06 average time 0.0026669194900296135 iter num 100\n",
            "loss 1.2696530757880788e-06 average time 0.00270518955992884 iter num 50\n",
            "loss 1.2695711060007694e-06 average time 0.0025877349099482673 iter num 100\n",
            "loss 1.2692079620767634e-06 average time 0.0030338923599811094 iter num 50\n",
            "loss 1.2691252973547129e-06 average time 0.00290758393996839 iter num 100\n",
            "loss 1.268761295372918e-06 average time 0.0025064538999686192 iter num 50\n",
            "loss 1.2686852148138087e-06 average time 0.0025757288899967536 iter num 100\n",
            "loss 1.268319208142136e-06 average time 0.002660997159928229 iter num 50\n",
            "loss 1.2682341505773715e-06 average time 0.0026765378499476354 iter num 100\n",
            "loss 1.267874122446547e-06 average time 0.0027961641599722497 iter num 50\n",
            "loss 1.26779207222549e-06 average time 0.002833702639964031 iter num 100\n",
            "loss 1.2674360988358146e-06 average time 0.002538765679946664 iter num 50\n",
            "loss 1.2673491009988826e-06 average time 0.002577473130013459 iter num 100\n",
            "loss 1.2669914261156826e-06 average time 0.0026053152199892794 iter num 50\n",
            "loss 1.2669089479545272e-06 average time 0.0025399654199554787 iter num 100\n",
            "loss 1.2665488230975187e-06 average time 0.002567586520071927 iter num 50\n",
            "loss 1.2664664574933241e-06 average time 0.0025245907099997566 iter num 100\n",
            "loss 1.2661073485186192e-06 average time 0.002615905040038342 iter num 50\n",
            "loss 1.2660260268170448e-06 average time 0.0026681617100439326 iter num 100\n",
            "loss 1.265663717990909e-06 average time 0.00255937152001934 iter num 50\n",
            "loss 1.2655837239216461e-06 average time 0.0025227658200492444 iter num 100\n",
            "loss 1.26522534635575e-06 average time 0.0025479342198559607 iter num 50\n",
            "loss 1.2651434635188028e-06 average time 0.002528440839951145 iter num 100\n",
            "loss 1.2647820889632852e-06 average time 0.0027580926599694066 iter num 50\n",
            "loss 1.2647005378625452e-06 average time 0.002601255189993026 iter num 100\n",
            "loss 1.2643445021709172e-06 average time 0.0029858707200219213 iter num 50\n",
            "loss 1.2642619957943778e-06 average time 0.0027476681800089864 iter num 100\n",
            "loss 1.2639014793297932e-06 average time 0.0024488759999439936 iter num 50\n",
            "loss 1.2638195814378337e-06 average time 0.0025484242199490838 iter num 100\n",
            "loss 1.2634651286816491e-06 average time 0.002832270179933403 iter num 50\n",
            "loss 1.2633820120559923e-06 average time 0.002839796230018692 iter num 100\n",
            "loss 1.2630259331493207e-06 average time 0.002754599719974067 iter num 50\n",
            "loss 1.2629386444309894e-06 average time 0.0026983940200170763 iter num 100\n",
            "loss 1.2625852078587512e-06 average time 0.0025480847598919353 iter num 50\n",
            "loss 1.2625069880123156e-06 average time 0.0025077899799634904 iter num 100\n",
            "loss 1.2621455372563878e-06 average time 0.0026087082999401903 iter num 50\n",
            "loss 1.2620693538132544e-06 average time 0.0026155521899909216 iter num 100\n",
            "loss 1.2617107379230487e-06 average time 0.0025495348199001456 iter num 50\n",
            "loss 1.2616296385869986e-06 average time 0.002541934889914046 iter num 100\n",
            "loss 1.2612658286719174e-06 average time 0.002699349980102852 iter num 50\n",
            "loss 1.2611883798805155e-06 average time 0.002764822230046775 iter num 100\n",
            "loss 1.2608345279432977e-06 average time 0.002579915320038708 iter num 50\n",
            "loss 1.2607524935886839e-06 average time 0.00254103242002202 iter num 100\n",
            "loss 1.2603983553943598e-06 average time 0.00285533147989554 iter num 50\n",
            "loss 1.2603165902500855e-06 average time 0.002779049799955828 iter num 100\n",
            "loss 1.2599591664483e-06 average time 0.002495044980005332 iter num 50\n",
            "loss 1.259878430606002e-06 average time 0.0025106534299993654 iter num 100\n",
            "loss 1.2595244962336948e-06 average time 0.00256243245994483 iter num 50\n",
            "loss 1.2594394253249116e-06 average time 0.002560033769968868 iter num 100\n",
            "loss 1.25908423925455e-06 average time 0.0027193059599449044 iter num 50\n",
            "loss 1.259004837528091e-06 average time 0.0026411574699704943 iter num 100\n",
            "loss 1.2586565801380399e-06 average time 0.0026148793200081854 iter num 50\n",
            "loss 1.2585679140939476e-06 average time 0.0025243592400420313 iter num 100\n",
            "loss 1.2582198402819053e-06 average time 0.002477256420079357 iter num 50\n",
            "loss 1.2581402844252926e-06 average time 0.002487115800031461 iter num 100\n",
            "loss 1.25778366867335e-06 average time 0.0025912736199461507 iter num 50\n",
            "loss 1.2577003171277885e-06 average time 0.002672074239981157 iter num 100\n",
            "loss 1.2573450749220087e-06 average time 0.0025516488800531078 iter num 50\n",
            "loss 1.2572640870841731e-06 average time 0.002664014490046611 iter num 100\n",
            "loss 1.2569162411646883e-06 average time 0.0025369160400259714 iter num 50\n",
            "loss 1.256833890600896e-06 average time 0.0025615990700225666 iter num 100\n",
            "loss 1.2564786384026335e-06 average time 0.002484626380064583 iter num 50\n",
            "loss 1.256398291680332e-06 average time 0.0026917982300346923 iter num 100\n",
            "loss 1.2560458535938236e-06 average time 0.0026351976199839554 iter num 50\n",
            "loss 1.2559673791556947e-06 average time 0.0025628110999605267 iter num 100\n",
            "loss 1.2556114606307255e-06 average time 0.0025383568399956857 iter num 50\n",
            "loss 1.255534853291708e-06 average time 0.0025404901599722506 iter num 100\n",
            "loss 1.2551797847579732e-06 average time 0.002525909599989973 iter num 50\n",
            "loss 1.2551034474158593e-06 average time 0.0024816726699737044 iter num 100\n",
            "loss 1.25475202487113e-06 average time 0.002607970620101696 iter num 50\n",
            "loss 1.2546680575876813e-06 average time 0.0025637853700118283 iter num 100\n",
            "loss 1.2543147515843628e-06 average time 0.00251138761992479 iter num 50\n",
            "loss 1.2542394842560943e-06 average time 0.002482005189958727 iter num 100\n",
            "loss 1.253887497655716e-06 average time 0.002577262160011742 iter num 50\n",
            "loss 1.2538054504614583e-06 average time 0.0026467955299722236 iter num 100\n",
            "loss 1.2534578118324779e-06 average time 0.0024814130800950808 iter num 50\n",
            "loss 1.25337902222541e-06 average time 0.0025020020100873807 iter num 100\n",
            "loss 1.2530225851878433e-06 average time 0.0025232335799410064 iter num 50\n",
            "loss 1.2529433880758621e-06 average time 0.00254537436996543 iter num 100\n",
            "loss 1.2525954918359943e-06 average time 0.002689798659957887 iter num 50\n",
            "loss 1.252516197139197e-06 average time 0.0026813107199450317 iter num 100\n",
            "loss 1.2521658027618262e-06 average time 0.0025130987798911517 iter num 50\n",
            "loss 1.2520861395284667e-06 average time 0.0025698441599342915 iter num 100\n",
            "loss 1.2517378410715317e-06 average time 0.002689506220031035 iter num 50\n",
            "loss 1.2516517113040364e-06 average time 0.0026303861399810556 iter num 100\n",
            "loss 1.251308915926819e-06 average time 0.0026688050600023414 iter num 50\n",
            "loss 1.251224939718096e-06 average time 0.0026121224599683045 iter num 100\n",
            "loss 1.2508761231245772e-06 average time 0.002567516719955165 iter num 50\n",
            "loss 1.2508010596026098e-06 average time 0.0025983718700535972 iter num 100\n",
            "loss 1.2504542494630817e-06 average time 0.002552055939922866 iter num 50\n",
            "loss 1.2503689833912637e-06 average time 0.0025476988799709942 iter num 100\n",
            "loss 1.2500191888838668e-06 average time 0.0025206032800087997 iter num 50\n",
            "loss 1.24993827239414e-06 average time 0.002649132610013112 iter num 100\n",
            "loss 1.2495910964020067e-06 average time 0.002620418379938201 iter num 50\n",
            "loss 1.2495160322442748e-06 average time 0.002613166269975409 iter num 100\n",
            "loss 1.2491658342502823e-06 average time 0.0026186653599870624 iter num 50\n",
            "loss 1.2490883342006474e-06 average time 0.0026209496399860655 iter num 100\n",
            "loss 1.2487402493682205e-06 average time 0.0025401779399908263 iter num 50\n",
            "loss 1.248663411655144e-06 average time 0.00251273652997952 iter num 100\n",
            "loss 1.2483158130185043e-06 average time 0.002561887320025562 iter num 50\n",
            "loss 1.2482293244258772e-06 average time 0.0026162508199922743 iter num 100\n",
            "loss 1.247884343976003e-06 average time 0.003049864679996972 iter num 50\n",
            "loss 1.247808739329754e-06 average time 0.0027999428800285385 iter num 100\n",
            "loss 1.2474615798900186e-06 average time 0.002829670300016005 iter num 50\n",
            "loss 1.2473803834021323e-06 average time 0.00264948615998037 iter num 100\n",
            "loss 1.2470336823012834e-06 average time 0.002558741819975694 iter num 50\n",
            "loss 1.2469537135339558e-06 average time 0.002539173879968075 iter num 100\n",
            "loss 1.2466091276867341e-06 average time 0.0024506178200317664 iter num 50\n",
            "loss 1.2465337448081487e-06 average time 0.002525572009981261 iter num 100\n",
            "loss 1.246188328882042e-06 average time 0.002529538479993789 iter num 50\n",
            "loss 1.246105445825637e-06 average time 0.002745656679962849 iter num 100\n",
            "loss 1.2457609563013591e-06 average time 0.0026842054600092523 iter num 50\n",
            "loss 1.2456839983470313e-06 average time 0.002710805050082854 iter num 100\n",
            "loss 1.2453369313491883e-06 average time 0.0025887141398743554 iter num 50\n",
            "loss 1.2452592324662286e-06 average time 0.0025852284399570636 iter num 100\n",
            "loss 1.2449153063886642e-06 average time 0.002679464119974 iter num 50\n",
            "loss 1.244834726267575e-06 average time 0.002621560369980216 iter num 100\n",
            "loss 1.2444917745997198e-06 average time 0.0028499758399266285 iter num 50\n",
            "loss 1.2444118584025572e-06 average time 0.002786669510005595 iter num 100\n",
            "loss 1.2440633451007535e-06 average time 0.002789654500011238 iter num 50\n",
            "loss 1.2439901710457587e-06 average time 0.002815610329989795 iter num 100\n",
            "loss 1.2436420038996731e-06 average time 0.0026942469399546098 iter num 50\n",
            "loss 1.2435687473923722e-06 average time 0.0026655256600042775 iter num 100\n",
            "loss 1.2432249522158423e-06 average time 0.002610734380050417 iter num 50\n",
            "loss 1.2431430348916973e-06 average time 0.0025212029599879313 iter num 100\n",
            "loss 1.2427971845574914e-06 average time 0.0026383143999191816 iter num 50\n",
            "loss 1.24271911601255e-06 average time 0.0026538529799836398 iter num 100\n",
            "loss 1.242376302931194e-06 average time 0.002731354259976797 iter num 50\n",
            "loss 1.2422999345711555e-06 average time 0.0026178555200385744 iter num 100\n",
            "loss 1.241952955814327e-06 average time 0.002495857479989354 iter num 50\n",
            "loss 1.24187774230482e-06 average time 0.0025287786399712784 iter num 100\n",
            "loss 1.2415387322597484e-06 average time 0.002548599620095047 iter num 50\n",
            "loss 1.241457584057323e-06 average time 0.0025590268900123193 iter num 100\n",
            "loss 1.2411133007628805e-06 average time 0.0026511690400366204 iter num 50\n",
            "loss 1.2410374568192784e-06 average time 0.002613239970023642 iter num 100\n",
            "loss 1.2406918453401828e-06 average time 0.0025232041999879583 iter num 50\n",
            "loss 1.240613594548097e-06 average time 0.002503892139993695 iter num 100\n",
            "loss 1.2402731703372153e-06 average time 0.0025762757400116243 iter num 50\n",
            "loss 1.2401978629450788e-06 average time 0.002528363900000841 iter num 100\n",
            "loss 1.2398542926469862e-06 average time 0.0025625642399609207 iter num 50\n",
            "loss 1.2397761236679722e-06 average time 0.0025534318299742153 iter num 100\n",
            "loss 1.239433392092467e-06 average time 0.002506349479954224 iter num 50\n",
            "loss 1.2393587866260443e-06 average time 0.0024875510999754625 iter num 100\n",
            "loss 1.239012653261868e-06 average time 0.002529240279945952 iter num 50\n",
            "loss 1.2389432385266995e-06 average time 0.0025126745099896654 iter num 100\n",
            "loss 1.2386019656237385e-06 average time 0.002574095620002481 iter num 50\n",
            "loss 1.2385178250995495e-06 average time 0.002569629050040021 iter num 100\n",
            "loss 1.2381807678671238e-06 average time 0.0025886556399382244 iter num 50\n",
            "loss 1.2381050528300285e-06 average time 0.0026235124499999073 iter num 100\n",
            "loss 1.2377623695279802e-06 average time 0.002529008600031375 iter num 50\n",
            "loss 1.2376838382861803e-06 average time 0.002518776590040943 iter num 100\n",
            "loss 1.2373477265467374e-06 average time 0.0025195538999651036 iter num 50\n",
            "loss 1.2372656806471433e-06 average time 0.0026115044400194165 iter num 100\n",
            "loss 1.2369280657300723e-06 average time 0.0027250441800606494 iter num 50\n",
            "loss 1.2368519582285644e-06 average time 0.0027215759500722925 iter num 100\n",
            "loss 1.2365115164321187e-06 average time 0.0026003834000039206 iter num 50\n",
            "loss 1.2364351312399617e-06 average time 0.002535754430000452 iter num 100\n",
            "loss 1.2360933077199194e-06 average time 0.002661680080109363 iter num 50\n",
            "loss 1.2360190588107162e-06 average time 0.0026099304600029427 iter num 100\n",
            "loss 1.2356776894338225e-06 average time 0.0027434722800171586 iter num 50\n",
            "loss 1.2356002608522606e-06 average time 0.0026049161499850015 iter num 100\n",
            "loss 1.2352653274604494e-06 average time 0.0025536018200909894 iter num 50\n",
            "loss 1.235189908415469e-06 average time 0.002584342930022103 iter num 100\n",
            "loss 1.2348470199831556e-06 average time 0.0026027259200418484 iter num 50\n",
            "loss 1.2347728714756784e-06 average time 0.0026283311900169794 iter num 100\n",
            "loss 1.2344327393858087e-06 average time 0.002488893200006714 iter num 50\n",
            "loss 1.2343592787928333e-06 average time 0.002503221040005883 iter num 100\n",
            "loss 1.234019423235467e-06 average time 0.0025054390199511544 iter num 50\n",
            "loss 1.2339430423803701e-06 average time 0.002539650540002185 iter num 100\n",
            "loss 1.2336088947187689e-06 average time 0.002488926640016871 iter num 50\n",
            "loss 1.2335269116377294e-06 average time 0.0024869968000439256 iter num 100\n",
            "loss 1.2331921503946797e-06 average time 0.0025768306001009477 iter num 50\n",
            "loss 1.2331136278767766e-06 average time 0.002687298000046212 iter num 100\n",
            "loss 1.2327795367341543e-06 average time 0.0025944132799850194 iter num 50\n",
            "loss 1.2327029477642097e-06 average time 0.002674875900020197 iter num 100\n",
            "loss 1.2323667545118046e-06 average time 0.0026169723000384693 iter num 50\n",
            "loss 1.2322925229977322e-06 average time 0.00263891607003643 iter num 100\n",
            "loss 1.2319505576018353e-06 average time 0.0026798861600582312 iter num 50\n",
            "loss 1.231878585531958e-06 average time 0.0026514839499850494 iter num 100\n",
            "loss 1.2315353284084482e-06 average time 0.0025267741800053044 iter num 50\n",
            "loss 1.2314636882537863e-06 average time 0.002516127380031321 iter num 100\n",
            "loss 1.2311253981295736e-06 average time 0.0025735653600349904 iter num 50\n",
            "loss 1.2310527137993702e-06 average time 0.0026085990200408558 iter num 100\n",
            "loss 1.2307136610232598e-06 average time 0.00256803532003687 iter num 50\n",
            "loss 1.2306394621462363e-06 average time 0.002521534529987548 iter num 100\n",
            "loss 1.2303034724401012e-06 average time 0.0025666498599457555 iter num 50\n",
            "loss 1.2302284707046614e-06 average time 0.002682662499983053 iter num 100\n",
            "loss 1.2298899127740322e-06 average time 0.002509988819947466 iter num 50\n",
            "loss 1.2298213557194149e-06 average time 0.0025058740199801833 iter num 100\n",
            "loss 1.2294824685006892e-06 average time 0.002566396059901308 iter num 50\n",
            "loss 1.229408003894341e-06 average time 0.0025535133999346725 iter num 100\n",
            "loss 1.2290696511569301e-06 average time 0.002576193599979888 iter num 50\n",
            "loss 1.2289934952462401e-06 average time 0.002676829049960361 iter num 100\n",
            "loss 1.228660876056891e-06 average time 0.0026886902201658813 iter num 50\n",
            "loss 1.2285855929780734e-06 average time 0.002637606710104592 iter num 100\n",
            "loss 1.2282506429197614e-06 average time 0.00255881502000193 iter num 50\n",
            "loss 1.2281777808922715e-06 average time 0.0025079862600068735 iter num 100\n",
            "loss 1.227841040505656e-06 average time 0.0027370450000307757 iter num 50\n",
            "loss 1.2277646136735538e-06 average time 0.002600639910015161 iter num 100\n",
            "loss 1.2274343485048392e-06 average time 0.00265605778004101 iter num 50\n",
            "loss 1.2273511991827325e-06 average time 0.0025912626100034687 iter num 100\n",
            "loss 1.2270187218250098e-06 average time 0.002569798379900021 iter num 50\n",
            "loss 1.2269493453261687e-06 average time 0.002579175649952958 iter num 100\n",
            "loss 1.2266147967758124e-06 average time 0.002492940039956011 iter num 50\n",
            "loss 1.2265382943356936e-06 average time 0.0025671201500153985 iter num 100\n",
            "loss 1.226204273695378e-06 average time 0.0025913084599778814 iter num 50\n",
            "loss 1.2261289372852316e-06 average time 0.002548726710037954 iter num 100\n",
            "loss 1.225797589471627e-06 average time 0.002591722080069303 iter num 50\n",
            "loss 1.2257222451176271e-06 average time 0.0026173396900594525 iter num 100\n",
            "loss 1.2253907357172973e-06 average time 0.0026448468200760545 iter num 50\n",
            "loss 1.225315137745819e-06 average time 0.0025852039700021124 iter num 100\n",
            "loss 1.2249818726342428e-06 average time 0.0024964169600389143 iter num 50\n",
            "loss 1.224909356372162e-06 average time 0.0025090650799847935 iter num 100\n",
            "loss 1.2245779810387869e-06 average time 0.002514749519905308 iter num 50\n",
            "loss 1.2245040626262068e-06 average time 0.0025656785299725017 iter num 100\n",
            "loss 1.2241719960950262e-06 average time 0.0024660273199515357 iter num 50\n",
            "loss 1.2240981856449956e-06 average time 0.0024781360199813206 iter num 100\n",
            "loss 1.223764185231033e-06 average time 0.0026448004999656406 iter num 50\n",
            "loss 1.2236928546619693e-06 average time 0.0026146390000121754 iter num 100\n",
            "loss 1.2233638970532987e-06 average time 0.0024891170799492103 iter num 50\n",
            "loss 1.2232842537204343e-06 average time 0.002536054699958186 iter num 100\n",
            "loss 1.2229544520399553e-06 average time 0.0025897350799641574 iter num 50\n",
            "loss 1.2228811710024892e-06 average time 0.0026090071199541855 iter num 100\n",
            "loss 1.2225482361891054e-06 average time 0.002710023780091433 iter num 50\n",
            "loss 1.222475931768745e-06 average time 0.0027679941200676695 iter num 100\n",
            "loss 1.2221433956101861e-06 average time 0.0029784317000667217 iter num 50\n",
            "loss 1.2220655442790752e-06 average time 0.0027417163400241407 iter num 100\n",
            "loss 1.2217435315332652e-06 average time 0.0025524350999876332 iter num 50\n",
            "loss 1.2216667271830887e-06 average time 0.002583691999943767 iter num 100\n",
            "loss 1.2213344599991965e-06 average time 0.002544766039991373 iter num 50\n",
            "loss 1.2212640054663683e-06 average time 0.0027098457199554106 iter num 100\n",
            "loss 1.220929597975595e-06 average time 0.002968708259977575 iter num 50\n",
            "loss 1.2208580391388518e-06 average time 0.0030507364200093433 iter num 100\n",
            "loss 1.2205298815340988e-06 average time 0.0026743925400114677 iter num 50\n",
            "loss 1.2204516664649057e-06 average time 0.0026715764400341868 iter num 100\n",
            "loss 1.2201226026201687e-06 average time 0.0026127537399952415 iter num 50\n",
            "loss 1.220056630225029e-06 average time 0.002641544449979847 iter num 100\n",
            "loss 1.2197232226741018e-06 average time 0.0024564936600290823 iter num 50\n",
            "loss 1.219644763206e-06 average time 0.0025570419400355606 iter num 100\n",
            "loss 1.2193164508715184e-06 average time 0.0024764198400407623 iter num 50\n",
            "loss 1.2192420443492782e-06 average time 0.0025969814699965356 iter num 100\n",
            "loss 1.218916210980276e-06 average time 0.002524637000024086 iter num 50\n",
            "loss 1.2188409892913645e-06 average time 0.0026008861500304192 iter num 100\n",
            "loss 1.2185125561331784e-06 average time 0.002564063440040627 iter num 50\n",
            "loss 1.2184392565907171e-06 average time 0.0025505924099979895 iter num 100\n",
            "loss 1.2181194768285716e-06 average time 0.0029486052799802564 iter num 50\n",
            "loss 1.2180395369108466e-06 average time 0.0030255557500004217 iter num 100\n",
            "loss 1.2177144582826072e-06 average time 0.0028417511400039073 iter num 50\n",
            "loss 1.217638399139392e-06 average time 0.0027144179699644154 iter num 100\n",
            "loss 1.2173110808208771e-06 average time 0.0026473393601008865 iter num 50\n",
            "loss 1.2172384351876637e-06 average time 0.0027011401100298827 iter num 100\n",
            "loss 1.216907686669512e-06 average time 0.002646001399971283 iter num 50\n",
            "loss 1.2168365063892045e-06 average time 0.002593402270003935 iter num 100\n",
            "loss 1.216512007687359e-06 average time 0.0026631473599991297 iter num 50\n",
            "loss 1.2164362806806558e-06 average time 0.0026003831600519335 iter num 100\n",
            "loss 1.2161097168329622e-06 average time 0.002461732160063548 iter num 50\n",
            "loss 1.2160364290998114e-06 average time 0.0024507226200330477 iter num 100\n",
            "loss 1.215709498269933e-06 average time 0.0025058875800095847 iter num 50\n",
            "loss 1.215641256235317e-06 average time 0.002604584340015208 iter num 100\n",
            "loss 1.2153122773681142e-06 average time 0.0025973416999840993 iter num 50\n",
            "loss 1.2152379387391807e-06 average time 0.0025412366399814347 iter num 100\n",
            "loss 1.2149125291300704e-06 average time 0.002709957779970864 iter num 50\n",
            "loss 1.2148426160369093e-06 average time 0.002621900359999927 iter num 100\n",
            "loss 1.214513348966311e-06 average time 0.0026572060200123816 iter num 50\n",
            "loss 1.2144380197359993e-06 average time 0.002603980199965008 iter num 100\n",
            "loss 1.2141180330602239e-06 average time 0.0025906785799816134 iter num 50\n",
            "loss 1.214045135704419e-06 average time 0.002549167960005434 iter num 100\n",
            "loss 1.2137203062814319e-06 average time 0.002623788639994018 iter num 50\n",
            "loss 1.2136438424859332e-06 average time 0.0025229707999733365 iter num 100\n",
            "loss 1.2133234919733028e-06 average time 0.002861303380032041 iter num 50\n",
            "loss 1.2132529975236294e-06 average time 0.0027946681000321407 iter num 100\n",
            "loss 1.2129196531514733e-06 average time 0.0026461879399539614 iter num 50\n",
            "loss 1.2128456184129906e-06 average time 0.002572395029983454 iter num 100\n",
            "loss 1.2125247621682295e-06 average time 0.002551330920050532 iter num 50\n",
            "loss 1.212454451994647e-06 average time 0.0025779935200080217 iter num 100\n",
            "loss 1.2121327521477185e-06 average time 0.0027957210400018084 iter num 50\n",
            "loss 1.2120576874398694e-06 average time 0.0027616447899890774 iter num 100\n",
            "loss 1.2117331415306418e-06 average time 0.002512789980009984 iter num 50\n",
            "loss 1.2116609399364047e-06 average time 0.002516472290026286 iter num 100\n",
            "loss 1.2113365670306477e-06 average time 0.0025195877800433665 iter num 50\n",
            "loss 1.2112629979966766e-06 average time 0.002538324009992721 iter num 100\n",
            "loss 1.2109434026989765e-06 average time 0.0027576368800873753 iter num 50\n",
            "loss 1.2108735217599439e-06 average time 0.002655923400006941 iter num 100\n",
            "loss 1.2105437972119946e-06 average time 0.002646948519977741 iter num 50\n",
            "loss 1.2104737428979976e-06 average time 0.0026059356299538193 iter num 100\n",
            "loss 1.210148244663574e-06 average time 0.002605003620028583 iter num 50\n",
            "loss 1.2100813197444274e-06 average time 0.0026679781500206444 iter num 100\n",
            "loss 1.2097601514674652e-06 average time 0.002783703279965266 iter num 50\n",
            "loss 1.2096800316301192e-06 average time 0.002764114879973931 iter num 100\n",
            "loss 1.2093591627005648e-06 average time 0.0026624852999339054 iter num 50\n",
            "loss 1.209286814445384e-06 average time 0.0026048566499503067 iter num 100\n",
            "loss 1.2089671779270374e-06 average time 0.002771978940036206 iter num 50\n",
            "loss 1.2088931069900398e-06 average time 0.0027735532300084743 iter num 100\n",
            "loss 1.208574023322858e-06 average time 0.002714171259976865 iter num 50\n",
            "loss 1.2085056334120438e-06 average time 0.0027688349000072774 iter num 100\n",
            "loss 1.2081762792302925e-06 average time 0.0027296126799592458 iter num 50\n",
            "loss 1.208111650107782e-06 average time 0.00269181969993042 iter num 100\n",
            "loss 1.2077832403816098e-06 average time 0.0025932704799924975 iter num 50\n",
            "loss 1.2077115857010975e-06 average time 0.002553542970017588 iter num 100\n",
            "loss 1.2073958956420725e-06 average time 0.0025357294200148315 iter num 50\n",
            "loss 1.2073152955602885e-06 average time 0.002793216089985435 iter num 100\n",
            "loss 1.2069970660548947e-06 average time 0.002792166500039457 iter num 50\n",
            "loss 1.2069280546351557e-06 average time 0.002802435150006204 iter num 100\n",
            "loss 1.2066096562995836e-06 average time 0.002545707980025327 iter num 50\n",
            "loss 1.2065382629578735e-06 average time 0.0027000832800786155 iter num 100\n",
            "loss 1.2062155954563626e-06 average time 0.002712542039935215 iter num 50\n",
            "loss 1.2061471815772486e-06 average time 0.00260132897994481 iter num 100\n",
            "loss 1.2058245250476218e-06 average time 0.002537700540051446 iter num 50\n",
            "loss 1.2057542104298615e-06 average time 0.0026102535200334385 iter num 100\n",
            "loss 1.2054323280891958e-06 average time 0.002863895560021774 iter num 50\n",
            "loss 1.2053659435581377e-06 average time 0.002886905879995538 iter num 100\n",
            "loss 1.2050417637489659e-06 average time 0.0029996406600002958 iter num 50\n",
            "loss 1.2049720137150014e-06 average time 0.0028593287999956374 iter num 100\n",
            "loss 1.2046499181667604e-06 average time 0.0026141277200258627 iter num 50\n",
            "loss 1.2045777422342315e-06 average time 0.002684296169991285 iter num 100\n",
            "loss 1.2042610724327134e-06 average time 0.0029995673999110295 iter num 50\n",
            "loss 1.204188696713859e-06 average time 0.0029821663099482976 iter num 100\n",
            "loss 1.2038709077932968e-06 average time 0.002855473479903594 iter num 50\n",
            "loss 1.2038025494611735e-06 average time 0.002959080389937299 iter num 100\n",
            "loss 1.203477034263161e-06 average time 0.002985254220038769 iter num 50\n",
            "loss 1.2034114569421342e-06 average time 0.0027668176200677406 iter num 100\n",
            "loss 1.203088638622047e-06 average time 0.0025299067799824117 iter num 50\n",
            "loss 1.2030231409846854e-06 average time 0.0025495604099978666 iter num 100\n",
            "loss 1.202704070953841e-06 average time 0.002612617639970267 iter num 50\n",
            "loss 1.202633071677519e-06 average time 0.002718271490002735 iter num 100\n",
            "loss 1.2023162980014333e-06 average time 0.002660856080001395 iter num 50\n",
            "loss 1.202242631197243e-06 average time 0.0026933861499674095 iter num 100\n",
            "loss 1.201928986943793e-06 average time 0.0028372994800884045 iter num 50\n",
            "loss 1.2018518815015533e-06 average time 0.0026843168700179374 iter num 100\n",
            "loss 1.2015393477528526e-06 average time 0.0025282416199661384 iter num 50\n",
            "loss 1.201470198179747e-06 average time 0.002541754919984669 iter num 100\n",
            "loss 1.2011518130942202e-06 average time 0.0025771857999643544 iter num 50\n",
            "loss 1.201077519555835e-06 average time 0.0026821168099741043 iter num 100\n",
            "loss 1.2007573366393513e-06 average time 0.0026791722599591593 iter num 50\n",
            "loss 1.2006896023484253e-06 average time 0.0027034902300329122 iter num 100\n",
            "loss 1.2003777501876186e-06 average time 0.002510288240009686 iter num 50\n",
            "loss 1.2003051433691021e-06 average time 0.0026080607900439644 iter num 100\n",
            "loss 1.199986956282792e-06 average time 0.002959234319987445 iter num 50\n",
            "loss 1.1999203881135105e-06 average time 0.0027763863599830074 iter num 100\n",
            "loss 1.1996005975076176e-06 average time 0.0026590254999791798 iter num 50\n",
            "loss 1.1995321384764918e-06 average time 0.0026310740600092686 iter num 100\n",
            "loss 1.199212998939827e-06 average time 0.002774160560038581 iter num 50\n",
            "loss 1.1991425373128234e-06 average time 0.0026767486600238043 iter num 100\n",
            "loss 1.1988274590770574e-06 average time 0.0025283183600913616 iter num 50\n",
            "loss 1.1987607856160574e-06 average time 0.0025144579400330257 iter num 100\n",
            "loss 1.1984425470664204e-06 average time 0.0025424296000528556 iter num 50\n",
            "loss 1.1983690479710313e-06 average time 0.002718939320038771 iter num 100\n",
            "loss 1.1980558368733252e-06 average time 0.002713041500064719 iter num 50\n",
            "loss 1.1979897258527277e-06 average time 0.002631126230007794 iter num 100\n",
            "loss 1.1976735424789293e-06 average time 0.00266704903991922 iter num 50\n",
            "loss 1.1975998996691598e-06 average time 0.0026440116799494717 iter num 100\n",
            "loss 1.197285569117674e-06 average time 0.0028618076999373443 iter num 50\n",
            "loss 1.197215416047822e-06 average time 0.0027555650099384365 iter num 100\n",
            "loss 1.1969032239614788e-06 average time 0.0025466603200220562 iter num 50\n",
            "loss 1.1968314177891824e-06 average time 0.0026091830499899516 iter num 100\n",
            "loss 1.1965162600716344e-06 average time 0.0025012778599011656 iter num 50\n",
            "loss 1.1964473930267283e-06 average time 0.0025518880399613406 iter num 100\n",
            "loss 1.1961315371257668e-06 average time 0.002489681679962814 iter num 50\n",
            "loss 1.196065182975399e-06 average time 0.0025510733999726653 iter num 100\n",
            "loss 1.1957491633716213e-06 average time 0.002855960279975989 iter num 50\n",
            "loss 1.195678950416442e-06 average time 0.0026923132900083147 iter num 100\n",
            "loss 1.1953653464500863e-06 average time 0.0026362904599773174 iter num 50\n",
            "loss 1.1952965958927664e-06 average time 0.0025975118399583154 iter num 100\n",
            "loss 1.194983152588596e-06 average time 0.0026481052600502153 iter num 50\n",
            "loss 1.1949126133169073e-06 average time 0.0025645734100271512 iter num 100\n",
            "loss 1.1945993961452434e-06 average time 0.002667802359937923 iter num 50\n",
            "loss 1.1945285754620302e-06 average time 0.00257264583995493 iter num 100\n",
            "loss 1.194214368470766e-06 average time 0.002498296359954111 iter num 50\n",
            "loss 1.194145730409569e-06 average time 0.002497056620022704 iter num 100\n",
            "loss 1.193837311829849e-06 average time 0.0027549665199694574 iter num 50\n",
            "loss 1.1937641317407747e-06 average time 0.002651443969934917 iter num 100\n",
            "loss 1.193452361453864e-06 average time 0.002611551359987061 iter num 50\n",
            "loss 1.1933777525474394e-06 average time 0.0025741426599597615 iter num 100\n",
            "loss 1.1930704814735279e-06 average time 0.0025020915199274896 iter num 50\n",
            "loss 1.1929989247427028e-06 average time 0.002493925699945976 iter num 100\n",
            "loss 1.1926851843738988e-06 average time 0.0025257704599971477 iter num 50\n",
            "loss 1.1926172547062666e-06 average time 0.0026384341799621323 iter num 100\n",
            "loss 1.1923093748086398e-06 average time 0.0027815109199218566 iter num 50\n",
            "loss 1.1922383739768816e-06 average time 0.00283637686993643 iter num 100\n",
            "loss 1.1919270533427692e-06 average time 0.0025848809600392997 iter num 50\n",
            "loss 1.1918606123899878e-06 average time 0.0026257237800291476 iter num 100\n",
            "loss 1.1915461869006338e-06 average time 0.0027556628398997416 iter num 50\n",
            "loss 1.1914793414379684e-06 average time 0.002638332059932509 iter num 100\n",
            "loss 1.1911668637967049e-06 average time 0.0029203806599434755 iter num 50\n",
            "loss 1.1910997106648746e-06 average time 0.002740752080007951 iter num 100\n",
            "loss 1.1907877033918074e-06 average time 0.002853321179954946 iter num 50\n",
            "loss 1.1907149060399897e-06 average time 0.0027147409299413993 iter num 100\n",
            "loss 1.190408772705456e-06 average time 0.0026251820201650842 iter num 50\n",
            "loss 1.1903393286020697e-06 average time 0.00257281704012712 iter num 100\n",
            "loss 1.1900315817201984e-06 average time 0.0024459071999081063 iter num 50\n",
            "loss 1.1899575978979598e-06 average time 0.002452796119987397 iter num 100\n",
            "loss 1.1896503297685837e-06 average time 0.002627376780073973 iter num 50\n",
            "loss 1.1895837705281303e-06 average time 0.0028266392599925892 iter num 100\n",
            "loss 1.1892672515841051e-06 average time 0.002584496079998644 iter num 50\n",
            "loss 1.1891994031658775e-06 average time 0.0029055711300134137 iter num 100\n",
            "loss 1.18889448774835e-06 average time 0.0027614039599393437 iter num 50\n",
            "loss 1.1888194295640198e-06 average time 0.0028475159199751942 iter num 100\n",
            "loss 1.188511219576304e-06 average time 0.002954686319972097 iter num 50\n",
            "loss 1.1884420111435775e-06 average time 0.0029001867899933133 iter num 100\n",
            "loss 1.1881371075408383e-06 average time 0.0030141505999927176 iter num 50\n",
            "loss 1.1880703559337897e-06 average time 0.0028687035299572016 iter num 100\n",
            "loss 1.187760834251432e-06 average time 0.002819724140008475 iter num 50\n",
            "loss 1.1876900749862541e-06 average time 0.0026213547499901323 iter num 100\n",
            "loss 1.1873788257668835e-06 average time 0.002580424879979546 iter num 50\n",
            "loss 1.187312600971452e-06 average time 0.0025143716399816185 iter num 100\n",
            "loss 1.1870045438282755e-06 average time 0.0025416192200100342 iter num 50\n",
            "loss 1.1869365536384908e-06 average time 0.002576884300005986 iter num 100\n",
            "loss 1.1866290025195304e-06 average time 0.0024919687999863526 iter num 50\n",
            "loss 1.186557971904108e-06 average time 0.0026095322399760333 iter num 100\n",
            "loss 1.186249737260836e-06 average time 0.0026831956199566773 iter num 50\n",
            "loss 1.1861784828028378e-06 average time 0.0026215828000113106 iter num 100\n",
            "loss 1.1858777144576962e-06 average time 0.0024675204799677886 iter num 50\n",
            "loss 1.185801172892996e-06 average time 0.0025171493399375323 iter num 100\n",
            "loss 1.1854993865765853e-06 average time 0.0026416772000266067 iter num 50\n",
            "loss 1.18542992611098e-06 average time 0.0025722108800255226 iter num 100\n",
            "loss 1.1851250695352597e-06 average time 0.0025398840399793697 iter num 50\n",
            "loss 1.1850507259839196e-06 average time 0.0025287381899761385 iter num 100\n",
            "loss 1.184747053855164e-06 average time 0.0026479592199029865 iter num 50\n",
            "loss 1.1846823415521497e-06 average time 0.0026979256799859286 iter num 100\n",
            "loss 1.1843744517452372e-06 average time 0.002669151799964311 iter num 50\n",
            "loss 1.1843047124226167e-06 average time 0.0026223431599555623 iter num 100\n",
            "loss 1.1840012622352936e-06 average time 0.002511430740050855 iter num 50\n",
            "loss 1.1839338720875127e-06 average time 0.002549860519993672 iter num 100\n",
            "loss 1.1836254893701017e-06 average time 0.002708809900050255 iter num 50\n",
            "loss 1.1835549720540207e-06 average time 0.0028495138300695545 iter num 100\n",
            "loss 1.1832550737396022e-06 average time 0.0027622414599863987 iter num 50\n",
            "loss 1.183184294965429e-06 average time 0.0026878396199663257 iter num 100\n",
            "loss 1.1828780642826314e-06 average time 0.0025295894199916804 iter num 50\n",
            "loss 1.182805816858695e-06 average time 0.0025232233599945175 iter num 100\n",
            "loss 1.1825039093010865e-06 average time 0.002506221160019777 iter num 50\n",
            "loss 1.1824353241987562e-06 average time 0.0026763830100208 iter num 100\n",
            "loss 1.1821274491334837e-06 average time 0.0026970164000522344 iter num 50\n",
            "loss 1.1820612597324777e-06 average time 0.00262367524003821 iter num 100\n",
            "loss 1.181761954742494e-06 average time 0.0025776710400168667 iter num 50\n",
            "loss 1.1816882895243916e-06 average time 0.002621535080006652 iter num 100\n",
            "loss 1.1813830760378571e-06 average time 0.002982045040025696 iter num 50\n",
            "loss 1.1813175555256e-06 average time 0.0027821351399597914 iter num 100\n",
            "loss 1.181014910691443e-06 average time 0.0025746718400296233 iter num 50\n",
            "loss 1.1809452452808572e-06 average time 0.002559541309983615 iter num 100\n",
            "loss 1.180641660537104e-06 average time 0.002530106340018392 iter num 50\n",
            "loss 1.1805754451246787e-06 average time 0.002526864020019275 iter num 100\n",
            "loss 1.180266484527299e-06 average time 0.0024952567800028192 iter num 50\n",
            "loss 1.1802022513966164e-06 average time 0.0025015776500185894 iter num 100\n",
            "loss 1.1798943222856026e-06 average time 0.002575719679971371 iter num 50\n",
            "loss 1.179827675242805e-06 average time 0.0025753584199537725 iter num 100\n",
            "loss 1.1795253726261539e-06 average time 0.0024975527599963242 iter num 50\n",
            "loss 1.1794557837460824e-06 average time 0.002468673090006632 iter num 100\n",
            "loss 1.1791542214247889e-06 average time 0.0029909094199319954 iter num 50\n",
            "loss 1.1790870711779371e-06 average time 0.002909122329974707 iter num 100\n",
            "loss 1.178783303923778e-06 average time 0.002641608420017292 iter num 50\n",
            "loss 1.1787150005849692e-06 average time 0.002623542930050462 iter num 100\n",
            "loss 1.178417696271579e-06 average time 0.0025723465200826467 iter num 50\n",
            "loss 1.1783479366698566e-06 average time 0.002516616930024611 iter num 100\n",
            "loss 1.1780463471638423e-06 average time 0.0025125749000108042 iter num 50\n",
            "loss 1.1779747979608548e-06 average time 0.0026790830699883372 iter num 100\n",
            "loss 1.1776783431850022e-06 average time 0.002519953660048486 iter num 50\n",
            "loss 1.1776085554259277e-06 average time 0.002488863520002269 iter num 100\n",
            "loss 1.1773056762759957e-06 average time 0.0029642312600117295 iter num 50\n",
            "loss 1.177237203393154e-06 average time 0.0028774779600189504 iter num 100\n",
            "loss 1.1769312245303312e-06 average time 0.002511133299940411 iter num 50\n",
            "loss 1.176864153367399e-06 average time 0.0026090322799973364 iter num 100\n",
            "loss 1.1765627347423242e-06 average time 0.0026127142000041204 iter num 50\n",
            "loss 1.1764986035594869e-06 average time 0.00255412167999566 iter num 100\n",
            "loss 1.1761982182485317e-06 average time 0.0025289480799438025 iter num 50\n",
            "loss 1.1761306360172098e-06 average time 0.002513468629986164 iter num 100\n",
            "loss 1.1758324113503453e-06 average time 0.0026470175600297806 iter num 50\n",
            "loss 1.1757625075597669e-06 average time 0.0028068186400105333 iter num 100\n",
            "loss 1.1754596467785984e-06 average time 0.002526605939947331 iter num 50\n",
            "loss 1.175396057323579e-06 average time 0.002538483719981741 iter num 100\n",
            "loss 1.1750946716878333e-06 average time 0.0031319860800249444 iter num 50\n",
            "loss 1.1750229439194366e-06 average time 0.0028986181600430426 iter num 100\n",
            "loss 1.1747269002718793e-06 average time 0.0026351314199018817 iter num 50\n",
            "loss 1.174654593942163e-06 average time 0.002586594279982819 iter num 100\n",
            "loss 1.1743557358298725e-06 average time 0.002659550920070615 iter num 50\n",
            "loss 1.1742917933418476e-06 average time 0.0026005145700128194 iter num 100\n",
            "loss 1.1739906832132967e-06 average time 0.0025526712201099145 iter num 50\n",
            "loss 1.1739231830162436e-06 average time 0.0025317740800710454 iter num 100\n",
            "loss 1.173623627487121e-06 average time 0.0025700473598772077 iter num 50\n",
            "loss 1.1735586885902733e-06 average time 0.0025216465699395485 iter num 100\n",
            "loss 1.1732631561189296e-06 average time 0.002711922879989288 iter num 50\n",
            "loss 1.1731916875786949e-06 average time 0.002682061130008151 iter num 100\n",
            "loss 1.1728925527407838e-06 average time 0.0030095401799371756 iter num 50\n",
            "loss 1.1728228686820942e-06 average time 0.0027763869099817384 iter num 100\n",
            "loss 1.1725251384910419e-06 average time 0.002633583639999415 iter num 50\n",
            "loss 1.1724614158924145e-06 average time 0.002685697180013449 iter num 100\n",
            "loss 1.1721617182413303e-06 average time 0.002571727579961589 iter num 50\n",
            "loss 1.1720947300203895e-06 average time 0.002726917659983883 iter num 100\n",
            "loss 1.1717949473390037e-06 average time 0.0025652451000314613 iter num 50\n",
            "loss 1.171725560277614e-06 average time 0.002567181990007157 iter num 100\n",
            "loss 1.1714318697348775e-06 average time 0.0024950815399279237 iter num 50\n",
            "loss 1.17136300583053e-06 average time 0.002527223999895796 iter num 100\n",
            "loss 1.1710635435631876e-06 average time 0.0027898941800049214 iter num 50\n",
            "loss 1.1710002366673276e-06 average time 0.0026499522499671 iter num 100\n",
            "loss 1.1706993187139443e-06 average time 0.002720224439926824 iter num 50\n",
            "loss 1.1706354815262784e-06 average time 0.0028129806499873665 iter num 100\n",
            "loss 1.1703387358527556e-06 average time 0.00268793901992467 iter num 50\n",
            "loss 1.1702732783788836e-06 average time 0.002560294989962131 iter num 100\n",
            "loss 1.1699709575711361e-06 average time 0.0024991757200950814 iter num 50\n",
            "loss 1.1699044863370443e-06 average time 0.0024859332000778524 iter num 100\n",
            "loss 1.1696063648732177e-06 average time 0.0029545865800719184 iter num 50\n",
            "loss 1.1695452880492545e-06 average time 0.0029402789800224128 iter num 100\n",
            "loss 1.169245254804408e-06 average time 0.002463915219905175 iter num 50\n",
            "loss 1.1691772736663655e-06 average time 0.0026228858099511853 iter num 100\n",
            "loss 1.1688803476827034e-06 average time 0.002901732300106232 iter num 50\n",
            "loss 1.1688170229420157e-06 average time 0.0028208098000413882 iter num 100\n",
            "loss 1.1685198201227198e-06 average time 0.0026299191799989785 iter num 50\n",
            "loss 1.1684551275877323e-06 average time 0.0026035827600026096 iter num 100\n",
            "loss 1.1681558326862546e-06 average time 0.002928363400078524 iter num 50\n",
            "loss 1.1680862259123165e-06 average time 0.002885604430048261 iter num 100\n",
            "loss 1.1677941755767204e-06 average time 0.0025355750999733573 iter num 50\n",
            "loss 1.167727586379702e-06 average time 0.002552179639988026 iter num 100\n",
            "loss 1.1674336418502127e-06 average time 0.0026006104999214586 iter num 50\n",
            "loss 1.1673642005610399e-06 average time 0.0026512973398803296 iter num 100\n",
            "loss 1.1670727118688189e-06 average time 0.002567590160015243 iter num 50\n",
            "loss 1.1670034118273024e-06 average time 0.002525632039951233 iter num 100\n",
            "loss 1.166705491717502e-06 average time 0.0024942750199261356 iter num 50\n",
            "loss 1.1666393073210928e-06 average time 0.002524586499976067 iter num 100\n",
            "loss 1.166345018825602e-06 average time 0.002911389540131495 iter num 50\n",
            "loss 1.1662803655501542e-06 average time 0.0027447516600568635 iter num 100\n",
            "loss 1.165988417599624e-06 average time 0.0030108940800346318 iter num 50\n",
            "loss 1.1659231229867002e-06 average time 0.0027354281400312173 iter num 100\n",
            "loss 1.16562169486528e-06 average time 0.0025396881400411076 iter num 50\n",
            "loss 1.1655614027065884e-06 average time 0.0025995188700017025 iter num 100\n",
            "loss 1.1652633171157501e-06 average time 0.0027490956600013305 iter num 50\n",
            "loss 1.1651988712969229e-06 average time 0.00267008148001878 iter num 100\n",
            "loss 1.1649018418282028e-06 average time 0.00269207903986171 iter num 50\n",
            "loss 1.1648398636564752e-06 average time 0.0026194272599059333 iter num 100\n",
            "loss 1.1645431515865353e-06 average time 0.002525566340009391 iter num 50\n",
            "loss 1.1644776716132407e-06 average time 0.002634001489968796 iter num 100\n",
            "loss 1.1641832947078351e-06 average time 0.0025573258400254416 iter num 50\n",
            "loss 1.164118575355813e-06 average time 0.002658583000038561 iter num 100\n",
            "loss 1.1638240800296706e-06 average time 0.002975578960013081 iter num 50\n",
            "loss 1.1637580843939982e-06 average time 0.0030001760699633452 iter num 100\n",
            "loss 1.1634670117387286e-06 average time 0.0026743364600042697 iter num 50\n",
            "loss 1.1633975729550655e-06 average time 0.002737200309993568 iter num 100\n",
            "loss 1.163104229064234e-06 average time 0.002627818980035954 iter num 50\n",
            "loss 1.1630387425856516e-06 average time 0.002529726770017078 iter num 100\n",
            "loss 1.16275125600719e-06 average time 0.0024959352400401257 iter num 50\n",
            "loss 1.162683734300094e-06 average time 0.0025012591500035344 iter num 100\n",
            "loss 1.1623957295544372e-06 average time 0.0027545972800180605 iter num 50\n",
            "loss 1.1623215812677781e-06 average time 0.002638774100023511 iter num 100\n",
            "loss 1.1620306146972427e-06 average time 0.002566301159949944 iter num 50\n",
            "loss 1.1619649492089826e-06 average time 0.0025909367999702227 iter num 100\n",
            "loss 1.161674989971728e-06 average time 0.0027949791999890296 iter num 50\n",
            "loss 1.1616094019539706e-06 average time 0.002905200919976778 iter num 100\n",
            "loss 1.1613150260254284e-06 average time 0.0031172714400236144 iter num 50\n",
            "loss 1.161251558751648e-06 average time 0.0029115051900043907 iter num 100\n",
            "loss 1.1609617233104276e-06 average time 0.0027075293999587304 iter num 50\n",
            "loss 1.160893225966967e-06 average time 0.00265944351995131 iter num 100\n",
            "loss 1.160601933785994e-06 average time 0.002692249159972562 iter num 50\n",
            "loss 1.160537563729957e-06 average time 0.0027663867000319443 iter num 100\n",
            "loss 1.1602435784910176e-06 average time 0.0025836992799850122 iter num 50\n",
            "loss 1.1601814354732807e-06 average time 0.002541228959971704 iter num 100\n",
            "loss 1.1598906227255788e-06 average time 0.0026460759199653694 iter num 50\n",
            "loss 1.1598244764968396e-06 average time 0.0026946604599470446 iter num 100\n",
            "loss 1.159534232950912e-06 average time 0.0025660725001216632 iter num 50\n",
            "loss 1.1594704587580647e-06 average time 0.0025183256900072593 iter num 100\n",
            "loss 1.1591744420201444e-06 average time 0.002772448300092947 iter num 50\n",
            "loss 1.159112314480703e-06 average time 0.0027672695600540463 iter num 100\n",
            "loss 1.1588205978613413e-06 average time 0.0027423527400060265 iter num 50\n",
            "loss 1.1587556363206018e-06 average time 0.002629335980054748 iter num 100\n",
            "loss 1.1584642647782712e-06 average time 0.0029315724399930332 iter num 50\n",
            "loss 1.1584040520394659e-06 average time 0.0027884459299639276 iter num 100\n",
            "loss 1.1581109803563218e-06 average time 0.0027616487599516405 iter num 50\n",
            "loss 1.158046200900308e-06 average time 0.0026543129199853867 iter num 100\n",
            "loss 1.1577563287494593e-06 average time 0.0025577951999184736 iter num 50\n",
            "loss 1.1576919322821398e-06 average time 0.002564187649968517 iter num 100\n",
            "loss 1.1574033517247243e-06 average time 0.0025058051399719262 iter num 50\n",
            "loss 1.1573369400804623e-06 average time 0.002520233380000718 iter num 100\n",
            "loss 1.1570479191485433e-06 average time 0.0025313393600299603 iter num 50\n",
            "loss 1.1569829502921814e-06 average time 0.0024980971600143675 iter num 100\n",
            "loss 1.1566933748497885e-06 average time 0.0025539923600626934 iter num 50\n",
            "loss 1.1566265799698674e-06 average time 0.002507215140003609 iter num 100\n",
            "loss 1.1563400157210561e-06 average time 0.0024576860199704243 iter num 50\n",
            "loss 1.1562776766164312e-06 average time 0.0025335913399976563 iter num 100\n",
            "loss 1.1559876796196267e-06 average time 0.00248977012002797 iter num 50\n",
            "loss 1.1559200038440961e-06 average time 0.0025957210500382644 iter num 100\n",
            "loss 1.1556334078818957e-06 average time 0.0025973492600678584 iter num 50\n",
            "loss 1.15556681321092e-06 average time 0.002542346179989181 iter num 100\n",
            "loss 1.1552820292788872e-06 average time 0.002522430640019593 iter num 50\n",
            "loss 1.1552151394317574e-06 average time 0.002486914329992942 iter num 100\n",
            "loss 1.1549226522663637e-06 average time 0.0025288033200195057 iter num 50\n",
            "loss 1.154861021888725e-06 average time 0.002552638979996118 iter num 100\n",
            "loss 1.1545713316536043e-06 average time 0.002616394180113275 iter num 50\n",
            "loss 1.1545082738711185e-06 average time 0.0025774953700602055 iter num 100\n",
            "loss 1.1542185588438427e-06 average time 0.002476272600088123 iter num 50\n",
            "loss 1.1541568954844934e-06 average time 0.002493937850022121 iter num 100\n",
            "loss 1.1538705419427052e-06 average time 0.002744174219933484 iter num 50\n",
            "loss 1.1538074568959246e-06 average time 0.0026201664100244672 iter num 100\n",
            "loss 1.153518422111003e-06 average time 0.002756983619965467 iter num 50\n",
            "loss 1.1534535391179923e-06 average time 0.0026582214899372046 iter num 100\n",
            "loss 1.1531665874675332e-06 average time 0.0025236973200298963 iter num 50\n",
            "loss 1.1531010500107167e-06 average time 0.0025044371200146995 iter num 100\n",
            "loss 1.1528164313266364e-06 average time 0.0026610570000048027 iter num 50\n",
            "loss 1.1527536463862466e-06 average time 0.002710612569944715 iter num 100\n",
            "loss 1.152462626868611e-06 average time 0.002638657779989444 iter num 50\n",
            "loss 1.1524010161793368e-06 average time 0.002746376769964627 iter num 100\n",
            "loss 1.1521112507141819e-06 average time 0.0025448948800112703 iter num 50\n",
            "loss 1.1520467283677595e-06 average time 0.00254571916999339 iter num 100\n",
            "loss 1.1517611262662277e-06 average time 0.002611096420096146 iter num 50\n",
            "loss 1.151698091733477e-06 average time 0.0026228407200687798 iter num 100\n",
            "loss 1.1514149787265785e-06 average time 0.0024997429200811893 iter num 50\n",
            "loss 1.1513480213695752e-06 average time 0.0026060339200193994 iter num 100\n",
            "loss 1.151063880927444e-06 average time 0.0027816991400504776 iter num 50\n",
            "loss 1.1509991028612565e-06 average time 0.002739425330009908 iter num 100\n",
            "loss 1.1507127879822568e-06 average time 0.002634832159947109 iter num 50\n",
            "loss 1.1506469708915648e-06 average time 0.002610992729978534 iter num 100\n",
            "loss 1.1503624818149389e-06 average time 0.002557520279988239 iter num 50\n",
            "loss 1.1502998848903445e-06 average time 0.0025825082300070788 iter num 100\n",
            "loss 1.1500114909648366e-06 average time 0.002723305520048598 iter num 50\n",
            "loss 1.1499505748602073e-06 average time 0.0026922023899987836 iter num 100\n",
            "loss 1.1496633677304818e-06 average time 0.0025846806200752327 iter num 50\n",
            "loss 1.1495990048926416e-06 average time 0.002581684540036804 iter num 100\n",
            "loss 1.1493168224804438e-06 average time 0.0031304785400971015 iter num 50\n",
            "loss 1.1492526507812737e-06 average time 0.0029160459100330627 iter num 100\n",
            "loss 1.1489674964061792e-06 average time 0.00274845316003848 iter num 50\n",
            "loss 1.148901344310653e-06 average time 0.00264089796000917 iter num 100\n",
            "loss 1.148618886142541e-06 average time 0.0025210737599263666 iter num 50\n",
            "loss 1.14855698379863e-06 average time 0.002499820769971848 iter num 100\n",
            "loss 1.1482706114372377e-06 average time 0.0025128594000307205 iter num 50\n",
            "loss 1.148207936467321e-06 average time 0.002501021509933707 iter num 100\n",
            "loss 1.147922673342964e-06 average time 0.002545061480013828 iter num 50\n",
            "loss 1.1478640645450248e-06 average time 0.0025872769299894573 iter num 100\n",
            "loss 1.1475765051551523e-06 average time 0.0025371446399549314 iter num 50\n",
            "loss 1.1475140240790736e-06 average time 0.002512638229964068 iter num 100\n",
            "loss 1.1472279465108447e-06 average time 0.0025239732800037018 iter num 50\n",
            "loss 1.1471652906355067e-06 average time 0.0025372892299765225 iter num 100\n",
            "loss 1.1468825784286924e-06 average time 0.0025025537801047905 iter num 50\n",
            "loss 1.1468206440864119e-06 average time 0.0025577666000481257 iter num 100\n",
            "loss 1.1465350780016127e-06 average time 0.002627253800019389 iter num 50\n",
            "loss 1.1464686144233816e-06 average time 0.0027230793500348225 iter num 100\n",
            "loss 1.1461889977939265e-06 average time 0.002598367179980414 iter num 50\n",
            "loss 1.1461275735939212e-06 average time 0.0025346434099901673 iter num 100\n",
            "loss 1.1458401724633439e-06 average time 0.00249520607996601 iter num 50\n",
            "loss 1.1457794569974136e-06 average time 0.0026164494599925092 iter num 100\n",
            "loss 1.1454979013941287e-06 average time 0.002654169860015827 iter num 50\n",
            "loss 1.1454332366917677e-06 average time 0.002563614169985158 iter num 100\n",
            "loss 1.145151680768666e-06 average time 0.0025896252600978186 iter num 50\n",
            "loss 1.1450852449735008e-06 average time 0.002536407510033314 iter num 100\n",
            "loss 1.1448068543836095e-06 average time 0.0026307540200650693 iter num 50\n",
            "loss 1.1447399310318873e-06 average time 0.0027591318200393287 iter num 100\n",
            "loss 1.1444610052278867e-06 average time 0.0027096964200063666 iter num 50\n",
            "loss 1.1443984658505984e-06 average time 0.002586796060004417 iter num 100\n",
            "loss 1.1441153492262536e-06 average time 0.0026073319199895195 iter num 50\n",
            "loss 1.144051434172208e-06 average time 0.0027825096700507855 iter num 100\n",
            "loss 1.1437671663117196e-06 average time 0.0026246765799805873 iter num 50\n",
            "loss 1.1437071882611345e-06 average time 0.0026017050999325875 iter num 100\n",
            "loss 1.1434292291205076e-06 average time 0.0025373693998881207 iter num 50\n",
            "loss 1.143364728189761e-06 average time 0.0025183652198757043 iter num 100\n",
            "loss 1.1430859442036127e-06 average time 0.002782027939974796 iter num 50\n",
            "loss 1.1430174275355695e-06 average time 0.0026979372599998898 iter num 100\n",
            "loss 1.1427380976279215e-06 average time 0.002785697040017112 iter num 50\n",
            "loss 1.142678828028755e-06 average time 0.0026720757199836954 iter num 100\n",
            "loss 1.1423928763847358e-06 average time 0.0029247010600920477 iter num 50\n",
            "loss 1.1423371944006441e-06 average time 0.002978673930037985 iter num 100\n",
            "loss 1.1420484150482828e-06 average time 0.0026765296399389625 iter num 50\n",
            "loss 1.1419884200858959e-06 average time 0.0026371575399571157 iter num 100\n",
            "loss 1.1417099555596633e-06 average time 0.0025473564599633393 iter num 50\n",
            "loss 1.141641618746836e-06 average time 0.002524359810013266 iter num 100\n",
            "loss 1.1413636433390486e-06 average time 0.0025400732799971595 iter num 50\n",
            "loss 1.1413022703695871e-06 average time 0.0026109127599829663 iter num 100\n",
            "loss 1.1410179302387798e-06 average time 0.0026834659799715153 iter num 50\n",
            "loss 1.1409599272190958e-06 average time 0.002578766109991193 iter num 100\n",
            "loss 1.1406809492326691e-06 average time 0.002657618879966321 iter num 50\n",
            "loss 1.1406191219876044e-06 average time 0.002660471889985274 iter num 100\n",
            "loss 1.1403395519034779e-06 average time 0.002627176560126827 iter num 50\n",
            "loss 1.1402737877649671e-06 average time 0.0027311437600656065 iter num 100\n",
            "loss 1.1399954118726325e-06 average time 0.002825094999934663 iter num 50\n",
            "loss 1.139933304978312e-06 average time 0.002687066439957562 iter num 100\n",
            "loss 1.1396498902290563e-06 average time 0.002521298859919625 iter num 50\n",
            "loss 1.1395912456568823e-06 average time 0.00250646478996714 iter num 100\n",
            "loss 1.1393105859076032e-06 average time 0.0025084469800276564 iter num 50\n",
            "loss 1.1392538503237753e-06 average time 0.0027823183800410336 iter num 100\n",
            "loss 1.1389698053613075e-06 average time 0.0025258168799337 iter num 50\n",
            "loss 1.1389082690656087e-06 average time 0.0026630703499904485 iter num 100\n",
            "loss 1.1386284935433726e-06 average time 0.0026247656199484483 iter num 50\n",
            "loss 1.1385687666836369e-06 average time 0.0025677783499759243 iter num 100\n",
            "loss 1.1382927531265326e-06 average time 0.002533629099943937 iter num 50\n",
            "loss 1.1382260415896502e-06 average time 0.0025143627399393156 iter num 100\n",
            "loss 1.1379503282458782e-06 average time 0.002663906000016141 iter num 50\n",
            "loss 1.1378869918934593e-06 average time 0.0026301569199858933 iter num 100\n",
            "loss 1.1376093707159866e-06 average time 0.0025024962400675577 iter num 50\n",
            "loss 1.1375463634654068e-06 average time 0.0025178833600148207 iter num 100\n",
            "loss 1.1372689815513182e-06 average time 0.002827313439975114 iter num 50\n",
            "loss 1.1372053620480683e-06 average time 0.0026402215699454245 iter num 100\n",
            "loss 1.1369265916008944e-06 average time 0.0024967149399162734 iter num 50\n",
            "loss 1.1368680944005906e-06 average time 0.0024931455699606885 iter num 100\n",
            "loss 1.1365891331687676e-06 average time 0.002612989659955929 iter num 50\n",
            "loss 1.1365282522032627e-06 average time 0.002691608359946258 iter num 100\n",
            "loss 1.1362502668202803e-06 average time 0.0025619952200031547 iter num 50\n",
            "loss 1.1361880501628504e-06 average time 0.0025615265899796213 iter num 100\n",
            "loss 1.135906736396921e-06 average time 0.0025423888798832197 iter num 50\n",
            "loss 1.135850660048667e-06 average time 0.002496046279966322 iter num 100\n",
            "loss 1.1355709221098229e-06 average time 0.003075135219933145 iter num 50\n",
            "loss 1.1355105143680102e-06 average time 0.0029350887600139686 iter num 100\n",
            "loss 1.1352328647390176e-06 average time 0.0025682994799535665 iter num 50\n",
            "loss 1.1351698941285457e-06 average time 0.0025772550100009537 iter num 100\n",
            "loss 1.1348939591875453e-06 average time 0.0028284961599820235 iter num 50\n",
            "loss 1.134829316000931e-06 average time 0.0027299674399728245 iter num 100\n",
            "loss 1.1345555796248361e-06 average time 0.0025378165999973136 iter num 50\n",
            "loss 1.1344957377747175e-06 average time 0.0025823387199852732 iter num 100\n",
            "loss 1.134222059731159e-06 average time 0.0028354707401013 iter num 50\n",
            "loss 1.1341556022078244e-06 average time 0.002849704530035524 iter num 100\n",
            "loss 1.133880008026047e-06 average time 0.0025681771200288493 iter num 50\n",
            "loss 1.133824168158023e-06 average time 0.002564353240040873 iter num 100\n",
            "loss 1.1335426448206054e-06 average time 0.0025028806399677705 iter num 50\n",
            "loss 1.1334808329397343e-06 average time 0.0024933071199575354 iter num 100\n",
            "loss 1.133204792318841e-06 average time 0.002986069660018984 iter num 50\n",
            "loss 1.1331481864022092e-06 average time 0.0029816769400531485 iter num 100\n",
            "loss 1.1328700615700493e-06 average time 0.002532901599897741 iter num 50\n",
            "loss 1.1328109799362243e-06 average time 0.0025454659199385787 iter num 100\n",
            "loss 1.132531382903127e-06 average time 0.0025633735000155865 iter num 50\n",
            "loss 1.132470064829373e-06 average time 0.002595587580017309 iter num 100\n",
            "loss 1.1321976250076175e-06 average time 0.0027188166600353725 iter num 50\n",
            "loss 1.132134686683918e-06 average time 0.0026180962500802706 iter num 100\n",
            "loss 1.1318569596444516e-06 average time 0.0024981659200057037 iter num 50\n",
            "loss 1.1317998931046893e-06 average time 0.002486228630041296 iter num 100\n",
            "loss 1.1315271924593587e-06 average time 0.0025210876200071654 iter num 50\n",
            "loss 1.1314624620799293e-06 average time 0.0025176271999771418 iter num 100\n",
            "loss 1.1311885243862086e-06 average time 0.002545233179971547 iter num 50\n",
            "loss 1.1311335294909702e-06 average time 0.0026277976099845545 iter num 100\n",
            "loss 1.1308522418686468e-06 average time 0.002984783780066209 iter num 50\n",
            "loss 1.1307911908331641e-06 average time 0.002827931230003742 iter num 100\n",
            "loss 1.1305214948478254e-06 average time 0.0025696632800645603 iter num 50\n",
            "loss 1.1304586682502913e-06 average time 0.0025349506800921517 iter num 100\n",
            "loss 1.1301826714167226e-06 average time 0.0024945533599202464 iter num 50\n",
            "loss 1.130122218505159e-06 average time 0.0025154417499743432 iter num 100\n",
            "loss 1.129850219500014e-06 average time 0.0025629854399994655 iter num 50\n",
            "loss 1.1297889556768065e-06 average time 0.0025737435300015933 iter num 100\n",
            "loss 1.1295126022109804e-06 average time 0.002799315940064844 iter num 50\n",
            "loss 1.1294517871545713e-06 average time 0.0026676142800079105 iter num 100\n",
            "loss 1.1291761238881463e-06 average time 0.0024939658999392125 iter num 50\n",
            "loss 1.129114524717326e-06 average time 0.002493604320034137 iter num 100\n",
            "loss 1.1288471100022214e-06 average time 0.0026150254600543123 iter num 50\n",
            "loss 1.1287844819638928e-06 average time 0.002685928130049433 iter num 100\n",
            "loss 1.128515826255526e-06 average time 0.002494337679927412 iter num 50\n",
            "loss 1.1284507246556224e-06 average time 0.0026038761699965106 iter num 100\n",
            "loss 1.1281763696530419e-06 average time 0.002812628960109578 iter num 50\n",
            "loss 1.1281152694253734e-06 average time 0.002728518240073754 iter num 100\n",
            "loss 1.1278430837337318e-06 average time 0.0027098146199023175 iter num 50\n",
            "loss 1.1277848366514734e-06 average time 0.00262793545990462 iter num 100\n",
            "loss 1.1275101559558795e-06 average time 0.002612839259909379 iter num 50\n",
            "loss 1.127449887993263e-06 average time 0.002555011039967212 iter num 100\n",
            "loss 1.1271766726543965e-06 average time 0.0025246663000507395 iter num 50\n",
            "loss 1.1271158712850192e-06 average time 0.002562732480082559 iter num 100\n",
            "loss 1.1268472859849852e-06 average time 0.0026323580600910645 iter num 50\n",
            "loss 1.1267877265487292e-06 average time 0.0025695334799820556 iter num 100\n",
            "loss 1.1265116508919467e-06 average time 0.002511806280017481 iter num 50\n",
            "loss 1.126447824737545e-06 average time 0.0025472377500227595 iter num 100\n",
            "loss 1.1261829948632429e-06 average time 0.0031010358200001063 iter num 50\n",
            "loss 1.1261234634994273e-06 average time 0.0028760445499756314 iter num 100\n",
            "loss 1.125849100541161e-06 average time 0.0026726485600011072 iter num 50\n",
            "loss 1.1257908674428162e-06 average time 0.0027863712099770056 iter num 100\n",
            "loss 1.125520012273633e-06 average time 0.0026215605799916374 iter num 50\n",
            "loss 1.125459046270146e-06 average time 0.0025939049300450277 iter num 100\n",
            "loss 1.1251897827172474e-06 average time 0.00253772772011871 iter num 50\n",
            "loss 1.1251255360832982e-06 average time 0.00252898875003666 iter num 100\n",
            "loss 1.1248593090744761e-06 average time 0.002544898699998157 iter num 50\n",
            "loss 1.1247983205524644e-06 average time 0.002510137669978576 iter num 100\n",
            "loss 1.1245240960117544e-06 average time 0.002712859559978824 iter num 50\n",
            "loss 1.1244669869939846e-06 average time 0.002624651249934686 iter num 100\n",
            "loss 1.1241916735241803e-06 average time 0.002442853640022804 iter num 50\n",
            "loss 1.1241341845596894e-06 average time 0.002475314480088855 iter num 100\n",
            "loss 1.1238641864886788e-06 average time 0.00248409397991054 iter num 50\n",
            "loss 1.1238022196177405e-06 average time 0.00251135845990575 iter num 100\n",
            "loss 1.1235352343073995e-06 average time 0.002493577200020809 iter num 50\n",
            "loss 1.1234748693763572e-06 average time 0.002476349800008393 iter num 100\n",
            "loss 1.1232028137282747e-06 average time 0.0025810538799487404 iter num 50\n",
            "loss 1.123141775827678e-06 average time 0.0025969059099406875 iter num 100\n",
            "loss 1.1228694010210284e-06 average time 0.0026046583999413996 iter num 50\n",
            "loss 1.1228136839040868e-06 average time 0.002588461269997424 iter num 100\n",
            "loss 1.1225452032292031e-06 average time 0.002571069419991545 iter num 50\n",
            "loss 1.1224859718068149e-06 average time 0.002601726609937032 iter num 100\n",
            "loss 1.1222158052594196e-06 average time 0.002513386840055318 iter num 50\n",
            "loss 1.1221565536992357e-06 average time 0.002590410990032979 iter num 100\n",
            "loss 1.1218821191957125e-06 average time 0.0025287120599750777 iter num 50\n",
            "loss 1.1218233701042e-06 average time 0.0025452826299806473 iter num 100\n",
            "loss 1.121556547356911e-06 average time 0.0026577684600852082 iter num 50\n",
            "loss 1.1214974698430462e-06 average time 0.0027607769599762833 iter num 100\n",
            "loss 1.121224329429902e-06 average time 0.002765096920011274 iter num 50\n",
            "loss 1.1211716162546917e-06 average time 0.0026738584699705827 iter num 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqpasxVi0hx3"
      },
      "source": [
        "# Knock out call\n",
        "\n",
        "# now change code such that 'numsteps' does not represent year\n",
        "# make dt = year / numsteps\n",
        "# Add r, and notice that noise must have mean 0, not drift, or else it'll give large option prices\n",
        "# (done)\n",
        "# after making the changes, the values are still correct\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        #dx =  drift + noise[t,:] # no need to multiply by sigma here because noise generated by cov not corr\n",
        "        dx2 = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx2)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T): # down-and-out call\n",
        "    return jnp.mean(jnp.maximum((1 - jnp.any(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2) < B, axis=1).astype(int))* \n",
        "                                (jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2))[:,-1]-K, 0) *\n",
        "                    jnp.exp(-r[0] * T))\n",
        "    # must use '-1' not 'numsteps', or else grad will be 0\n",
        "\n",
        "numstocks = 1\n",
        "numsteps = 50\n",
        "numpaths = 2000000\n",
        "\n",
        "rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.02]*numstocks)\n",
        "r = drift # let r = drift to match B-S\n",
        "\n",
        "cov = jnp.identity(numstocks)*0.25*0.25\n",
        "initial_stocks = jnp.array([1.]*numstocks) # must be float\n",
        "\n",
        "T = 1.0\n",
        "K = 1.0\n",
        "B = 0.8 # if B is set to 0, equivalent to European call\n",
        "\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "\n",
        "keys = jax.random.split(key, numpaths)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "# # option price\n",
        "# print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T)) # here numsteps different from T\n",
        "\n",
        "# # delta\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "# print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, B, T)) # here numsteps different from T"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zkzUgfoXrO8h",
        "outputId": "be975388-bb33-4e83-d2b0-e238e684b870"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def compute_price(S):\n",
        "    inputs = torch.tensor([[1, 1, 0.8, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())[0][0]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_prices = []\n",
        "correct_call_prices = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*numstocks) # must be float\n",
        "    model_call_prices.append(compute_price(p).item())\n",
        "    correct_call_prices.append(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T))\n",
        "\n",
        "plt.plot(prices, model_call_prices, label = \"model_call_prices\")\n",
        "plt.plot(prices, correct_call_prices, label = \"JAX_call_prices\")\n",
        "# plt.plot(prices, np.array(model_call_prices)-np.array(correct_call_prices), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwApH0GT9bBK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ff08c610-3124-403d-d469-e044069974c5"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, 0.8, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())[0][1]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*numstocks) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, 1.0, B, T))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"JAX_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHgD1NjP7DOW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "581e7222-d3b2-49c6-f581-cdb38db6ca88"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 0.775, 0.8, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())[0][1]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*numstocks) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, 0.775, B, T))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"JAX_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7MfujMQ7oij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "23290b7c-6224-4d71-8615-a869ea5f5f64"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1.225, 0.8, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())[0][1]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*numstocks) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, 1.225, B, T))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"JAX_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWPtmiEVr77L",
        "outputId": "57409260-5814-48fb-9b07-cb9c7dbf16e8"
      },
      "source": [
        "# time difference for computing delta\n",
        "%timeit goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, B, T)\n",
        "%timeit compute_delta(1).item()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 415 ms per loop\n",
            "The slowest run took 997.21 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 344 µs per loop\n"
          ]
        }
      ]
    }
  ]
}