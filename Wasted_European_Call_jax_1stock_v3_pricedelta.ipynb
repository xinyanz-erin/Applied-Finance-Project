{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "European_Call_jax.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Erin/Wasted_European_Call_jax_1stock_v3_pricedelta.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1RYKgBifCYw"
      },
      "source": [
        "# Test (Skip this if not trying to test, to make sure that functions are defined correctly in cells below without running this cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roUDUYYZP26i"
      },
      "source": [
        "# import jax\n",
        "# import jax.numpy as jnp\n",
        "# from jax import random\n",
        "# from jax import jit\n",
        "# import numpy as np\n",
        "# from torch.utils.dlpack import from_dlpack"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hasj6aP7e5x"
      },
      "source": [
        "# mylist = []\n",
        "# for j in range(4):\n",
        "#   mylist.append(j)\n",
        "\n",
        "# mylist"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3Lif2aA7kWw"
      },
      "source": [
        "# mylist = []\n",
        "# for j in range(4):\n",
        "#   mylist.append([j, j+1])\n",
        "\n",
        "# mylist"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zP5vWxIs7p6i"
      },
      "source": [
        "# mylist = []\n",
        "# for j in range(4):\n",
        "#   mylist_tmp = []\n",
        "#   for i in range(2):\n",
        "#     mylist_tmp.append(j+i)\n",
        "#   mylist.append(mylist_tmp)\n",
        "\n",
        "# mylist"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWYfON_marpj",
        "outputId": "ec99a04e-8b1e-4f7e-bede-f1258959ba37"
      },
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T):\n",
        "  return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
        "\n",
        "numstocks = 1\n",
        "numsteps = 50\n",
        "numpaths = 1000000\n",
        "\n",
        "rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.0807]*numstocks)\n",
        "r = drift\n",
        "cov = jnp.identity(numstocks)*0.2597*0.2597\n",
        "initial_stocks = jnp.array([0.7178]*numstocks) # must be float\n",
        "T = 1.0\n",
        "K = 0.2106\n",
        "\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "keys = jax.random.split(key, numpaths)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "#%timeit optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T)\n",
        "\n",
        "# delta test\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "#%timeit goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5233102\n",
            "[0.9996969]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxFUnc_iBVcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea20505-38f8-43a9-f08c-c621d847f9d7"
      },
      "source": [
        "%%writefile cupy_dataset.py\n",
        "# version 1, 2, 6\n",
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T, keys): # need to pass 'keys'\n",
        "    return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
        "\n",
        "###################################################################################################\n",
        "# these 2 functions must be defined outside class in order to be used in 'optionvalueavg' function\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "###################################################################################################\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len, number_path, batch, seed, stocks):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 50\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = 1.0 # assume T = 1, use float here\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros((self.N_BATCH, 1 + self.N_STOCKS), dtype=cupy.float32) # output: price, delta1, delta2, delta3\n",
        "        X = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "\n",
        "        for op in range(self.N_BATCH):\n",
        "          \n",
        "          rng = jax.random.PRNGKey(self.seed)\n",
        "          rng, key = jax.random.split(rng)\n",
        "\n",
        "          ################################################################################################### generate random input numbers\n",
        "\n",
        "          initial_stocks = jnp.array(0.75 + np.random.random(self.N_STOCKS) * 0.5)\n",
        "\n",
        "          corr = jnp.diag(jnp.array([1]*self.N_STOCKS)) # assume no correlation between stocks here\n",
        "          sigma = jnp.array(0.15 + np.random.random(self.N_STOCKS) * 0.3)\n",
        "          cov = (jnp.diag(sigma)).dot(corr).dot(jnp.diag(sigma))\n",
        "\n",
        "          r = jnp.repeat(jnp.array(0.25 + np.random.random(1) * 0.35), self.N_STOCKS)\n",
        "          drift = r\n",
        "\n",
        "          T = self.T\n",
        "          K = 0.75 + np.random.random(1) * 0.5\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### apply functions to compute price and deltas\n",
        "          \n",
        "          keys = jax.random.split(key, self.N_PATHS)\n",
        "\n",
        "          European_Call_price = optionvalueavg(key, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "          gooptionvalue = jax.grad(optionvalueavg, argnums=1)\n",
        "          Deltas = gooptionvalue(keys, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### store input and output numbers in X and Y\n",
        "\n",
        "          Y[op, 0] = European_Call_price\n",
        "          Y[op, 1:] = cupy.array(Deltas, dtype=cupy.float32) # remember to change this!\n",
        "\n",
        "          # T, K, S, sigma, mu, r\n",
        "          paras = (jnp.repeat(jnp.array(T), self.N_STOCKS), jnp.repeat(jnp.array(K), self.N_STOCKS), initial_stocks, sigma, drift, r)\n",
        "          paras = np.column_stack(paras).reshape(1,-1)[0]\n",
        "          X[op,] = cupy.array(paras)\n",
        "\n",
        "          ###################################################################################################\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "# ds = OptionDataSet(max_len = 2, number_path = 1000000, batch = 2, seed = np.random.randint(10000), stocks=1) # for testing purpose, use constant seed. When training, change to random seed\n",
        "# for i in ds:\n",
        "#     print(i)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting cupy_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6JO9OBHdvv",
        "outputId": "7d23a111-aa9c-4c5f-ee7c-022b799b66e7"
      },
      "source": [
        "%%writefile model.py\n",
        "# version 1,2\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*1, 32) # remember to change this!\n",
        "        self.fc2 = nn.Linear(32, 64)\n",
        "        self.fc3 = nn.Linear(64, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 32)\n",
        "        self.fc6 = nn.Linear(32, 1) # 1 outputs: price\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1.0, 0.5, 0.5, 0.3, 0.35, 0.35]*1)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = (x - torch.tensor([0.0, 0.75, 0.75, 0.15, 0.25, 0.25]*1).cuda()) / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlXD80xPNVc6",
        "outputId": "1a61f1d0-bd9b-4ddb-cf63-b3cac3dd90d5"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-ignite in /usr/local/lib/python3.7/dist-packages (0.4.7)\n",
            "Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S3CyULkENYKb",
        "outputId": "4e553626-9fe0-4c61-f4a7-834cd1f5daa8"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 1000000, batch = 8, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 3]).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter) # print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.6531068086624146 average time 0.10094824725019862 iter num 20\n",
            "loss 0.5204014778137207 average time 0.05834397722483118 iter num 40\n",
            "loss 0.5402433276176453 average time 0.044020107066595905 iter num 60\n",
            "loss 0.5824537873268127 average time 0.036989746537528845 iter num 80\n",
            "loss 0.5137979388237 average time 0.03273940778002725 iter num 100\n",
            "loss 0.4186602234840393 average time 0.10036550120003085 iter num 20\n",
            "loss 0.41672831773757935 average time 0.05796865584979969 iter num 40\n",
            "loss 0.4737706482410431 average time 0.0438817424999191 iter num 60\n",
            "loss 0.3606874644756317 average time 0.036901925224947264 iter num 80\n",
            "loss 0.33376845717430115 average time 0.03272845099989354 iter num 100\n",
            "loss 0.36386844515800476 average time 0.10084672904995387 iter num 20\n",
            "loss 0.27255499362945557 average time 0.05840950184974645 iter num 40\n",
            "loss 0.178409606218338 average time 0.044336197383260396 iter num 60\n",
            "loss 0.2089894860982895 average time 0.03724570077483804 iter num 80\n",
            "loss 0.17559798061847687 average time 0.03294524085984449 iter num 100\n",
            "loss 0.0963856503367424 average time 0.10079837600042083 iter num 20\n",
            "loss 0.06374163180589676 average time 0.05818777470012719 iter num 40\n",
            "loss 0.04443562030792236 average time 0.04405467186685807 iter num 60\n",
            "loss 0.043322011828422546 average time 0.03710275952521443 iter num 80\n",
            "loss 0.05202110856771469 average time 0.032929755940203906 iter num 100\n",
            "loss 0.033650726079940796 average time 0.10062805784982629 iter num 20\n",
            "loss 0.03325829654932022 average time 0.058124190799571804 iter num 40\n",
            "loss 0.017596570774912834 average time 0.04391109488315124 iter num 60\n",
            "loss 0.03226670250296593 average time 0.03683448204988053 iter num 80\n",
            "loss 0.05129435285925865 average time 0.03262649015996431 iter num 100\n",
            "loss 0.03007911518216133 average time 0.10058207625061186 iter num 20\n",
            "loss 0.006078477017581463 average time 0.05817300295038876 iter num 40\n",
            "loss 0.006121422164142132 average time 0.04404857865016917 iter num 60\n",
            "loss 0.022362640127539635 average time 0.03696243603753828 iter num 80\n",
            "loss 0.023215532302856445 average time 0.032690264910088446 iter num 100\n",
            "loss 0.037885893136262894 average time 0.10109537389944308 iter num 20\n",
            "loss 0.014924123883247375 average time 0.05844235364957058 iter num 40\n",
            "loss 0.008238090202212334 average time 0.044171333382716206 iter num 60\n",
            "loss 0.007878384552896023 average time 0.03698014764945583 iter num 80\n",
            "loss 0.01270483061671257 average time 0.0327370283795608 iter num 100\n",
            "loss 0.022123640403151512 average time 0.10124486560016521 iter num 20\n",
            "loss 0.014129413291811943 average time 0.05866623840001921 iter num 40\n",
            "loss 0.05059581249952316 average time 0.04439954538344561 iter num 60\n",
            "loss 0.009726211428642273 average time 0.037350188162417905 iter num 80\n",
            "loss 0.014154534786939621 average time 0.03299930839992157 iter num 100\n",
            "loss 0.013563890941441059 average time 0.10070856129987078 iter num 20\n",
            "loss 0.034484971314668655 average time 0.05811548660003609 iter num 40\n",
            "loss 0.018431758508086205 average time 0.04410547924993201 iter num 60\n",
            "loss 0.020822010934352875 average time 0.03706727864987443 iter num 80\n",
            "loss 0.032157544046640396 average time 0.03288612753982306 iter num 100\n",
            "loss 0.06001950055360794 average time 0.10076203879998502 iter num 20\n",
            "loss 0.03349639102816582 average time 0.0581811412249408 iter num 40\n",
            "loss 0.02239726483821869 average time 0.04399343686660965 iter num 60\n",
            "loss 0.02549031563103199 average time 0.03698039345003963 iter num 80\n",
            "loss 0.014457235112786293 average time 0.03274257461005618 iter num 100\n",
            "loss 0.04022388532757759 average time 0.10030093684981693 iter num 20\n",
            "loss 0.006790841463953257 average time 0.0580265734495697 iter num 40\n",
            "loss 0.006584263406693935 average time 0.043994055133104365 iter num 60\n",
            "loss 0.028980791568756104 average time 0.03694177237484837 iter num 80\n",
            "loss 0.059159841388463974 average time 0.03263575741995737 iter num 100\n",
            "loss 0.016861356794834137 average time 0.10082433090046834 iter num 20\n",
            "loss 0.02782607264816761 average time 0.05822992517523744 iter num 40\n",
            "loss 0.038617588579654694 average time 0.04413039898360391 iter num 60\n",
            "loss 0.03468486666679382 average time 0.03706189473759878 iter num 80\n",
            "loss 0.03300788626074791 average time 0.032864933329983616 iter num 100\n",
            "loss 0.03282982483506203 average time 0.10098842555016745 iter num 20\n",
            "loss 0.028853099793195724 average time 0.058354177799992614 iter num 40\n",
            "loss 0.012188117019832134 average time 0.044183309866396785 iter num 60\n",
            "loss 0.009097620844841003 average time 0.037077916912312506 iter num 80\n",
            "loss 0.011885547079145908 average time 0.03285989977972349 iter num 100\n",
            "loss 0.015608852729201317 average time 0.10106938179978897 iter num 20\n",
            "loss 0.05068114399909973 average time 0.0588961132748409 iter num 40\n",
            "loss 0.007142817601561546 average time 0.04447144433312739 iter num 60\n",
            "loss 0.003671660553663969 average time 0.03726952553715819 iter num 80\n",
            "loss 0.034797001630067825 average time 0.03304249243974482 iter num 100\n",
            "loss 0.005257405340671539 average time 0.10020122830010222 iter num 20\n",
            "loss 0.053506214171648026 average time 0.05787907312487732 iter num 40\n",
            "loss 0.02369719371199608 average time 0.043951663933148664 iter num 60\n",
            "loss 0.02762804552912712 average time 0.036909295212262806 iter num 80\n",
            "loss 0.013875521719455719 average time 0.03272790879986132 iter num 100\n",
            "loss 0.0170738585293293 average time 0.10075670905007428 iter num 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-800ef2729017>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m           \u001b[0;31m################################################################################################### store input and output numbers in X and Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m           \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEuropean_Call_price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m           \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDeltas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# remember to change this!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.__setitem__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_routines_indexing.pyx\u001b[0m in \u001b[0;36mcupy._core._routines_indexing._ndarray_setitem\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_routines_indexing.pyx\u001b[0m in \u001b[0;36mcupy._core._routines_indexing._scatter_op\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.fill\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_forward_method\u001b[0;34m(attrname, self, fun, *args)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_forward_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0m_forward_to_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_forward_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_pricedelta_3.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d56d113-1f47-49a2-c1c8-8b00f86d16b6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cfb2be9-7eec-442a-fee1-7716ad6a1e50"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_pricedelta_3.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 936
        },
        "outputId": "8eb7b234-cefb-4003-f116-9df73c0e7e58"
      },
      "source": [
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "#dataset = OptionDataSet(max_len = 100, number_path = 1024, batch = 32, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 2000000, batch = 8, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 3]).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 10\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter) # print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 30)\n",
        "\n",
        "# model_save_name = 'jax_european_1stock_pricedelta_2.pth'\n",
        "# path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "# torch.save(model.state_dict(), path)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.012777091935276985 average time 0.6390614108997397 iter num 10\n",
            "loss 0.03996242210268974 average time 0.3276098110998646 iter num 20\n",
            "loss 0.03505583852529526 average time 0.22382047176639996 iter num 30\n",
            "loss 0.003653594059869647 average time 0.17177793257478696 iter num 40\n",
            "loss 0.006702820770442486 average time 0.14054995393998979 iter num 50\n",
            "loss 0.015506142750382423 average time 0.11995558269991306 iter num 60\n",
            "loss 0.015156666748225689 average time 0.10509438035712394 iter num 70\n",
            "loss 0.008086547255516052 average time 0.09393434113744661 iter num 80\n",
            "loss 0.00683393981307745 average time 0.08530658661107332 iter num 90\n",
            "loss 0.007387408055365086 average time 0.07837861602998601 iter num 100\n",
            "loss 0.014143883250653744 average time 0.34100242049898954 iter num 10\n",
            "loss 0.00963977724313736 average time 0.17844244629959577 iter num 20\n",
            "loss 0.007412024773657322 average time 0.12421809286618858 iter num 30\n",
            "loss 0.010265884920954704 average time 0.09711491717444005 iter num 40\n",
            "loss 0.00300259655341506 average time 0.08083956421942276 iter num 50\n",
            "loss 0.004810526967048645 average time 0.0700262991828519 iter num 60\n",
            "loss 0.009742984548211098 average time 0.06244764471386069 iter num 70\n",
            "loss 0.006592887919396162 average time 0.056608364237217754 iter num 80\n",
            "loss 0.004837809596210718 average time 0.052137313377493735 iter num 90\n",
            "loss 0.024351846426725388 average time 0.04846936783971614 iter num 100\n",
            "loss 0.008009929209947586 average time 0.3415783266995277 iter num 10\n",
            "loss 0.013964952901005745 average time 0.17860196314977655 iter num 20\n",
            "loss 0.008964496664702892 average time 0.1242730826332263 iter num 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-f8d838bc3e95>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;31m# model_save_name = 'jax_european_1stock_pricedelta_2.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m           \u001b[0;31m################################################################################################### store input and output numbers in X and Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m           \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEuropean_Call_price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m           \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDeltas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# remember to change this!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.__setitem__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_routines_indexing.pyx\u001b[0m in \u001b[0;36mcupy._core._routines_indexing._ndarray_setitem\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_routines_indexing.pyx\u001b[0m in \u001b[0;36mcupy._core._routines_indexing._scatter_op\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.fill\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_forward_method\u001b[0;34m(attrname, self, fun, *args)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_forward_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0m_forward_to_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_forward_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jguFNjHXdukN"
      },
      "source": [
        "model_save_name = 'jax_european_1stock_pricedelta_3.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "365d423f-6979-452e-b872-be9ba6d0ba29"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 1, 1, 0.25, 0.3, 0.3]]).cuda() # T, K, S, sigma, mu, r\n",
        "print('price: ' + str(model(inputs.float())))\n",
        "\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient[0][[2]]\n",
        "\n",
        "# price, delta\n",
        "# should be around (0.27130044, 0.90763223)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: tensor([[0.2823]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9324], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_2AXrPt7bNj",
        "outputId": "5eb7950c-6bcc-4995-f7f8-519fd575ba8b"
      },
      "source": [
        "numstocks = 1\n",
        "numsteps = 50\n",
        "numpaths = 1000000\n",
        "\n",
        "rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.3]*numstocks)\n",
        "r = drift\n",
        "cov = jnp.identity(numstocks)*0.25*0.25\n",
        "initial_stocks = jnp.array([1.0]*numstocks) # must be float\n",
        "T = 1.0\n",
        "K = 1.0\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "\n",
        "# delta test\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27089724\n",
            "[0.90711933]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "lovJwXo3-YEu",
        "outputId": "bde0f1ed-5d8a-4be8-d01e-240332ba8e0e"
      },
      "source": [
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "\n",
        "def compute_price(S):\n",
        "    inputs = torch.tensor([[1, 1, S, 0.25, 0.3, 0.3]]).cuda()\n",
        "    return model(inputs.float())\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_prices = []\n",
        "BS_call_prices = []\n",
        "for p in prices:\n",
        "    model_call_prices.append(compute_price(p).item())\n",
        "    BS_call_prices.append(bs_call(p, 1, 1, 0.3, 0.25))\n",
        "\n",
        "#plt.plot(prices, model_call_prices, label = \"model_call_prices\")\n",
        "#plt.plot(prices, BS_call_prices, label = \"BS_call_prices\")\n",
        "plt.plot(prices, np.array(model_call_prices)-np.array(BS_call_prices), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "lwApH0GT9bBK",
        "outputId": "6454f8d7-8377-40d5-d667-c50221bc3f26"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, S, 0.25, 0.3, 0.3]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 1, 1, 0.3, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfaudUehQE7u"
      },
      "source": [
        ""
      ],
      "execution_count": 25,
      "outputs": []
    }
  ]
}