{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of European_Call_jax.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Erin/Copy_of_European_Call_jax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1RYKgBifCYw"
      },
      "source": [
        "# Test (Skip this if not trying to test, to make sure that functions are defined correctly in cells below without running this cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWYfON_marpj",
        "outputId": "bd7e4e1d-7f6e-428c-9425-c422c39757c5"
      },
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "#     stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "#     stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "#                             jax.ops.index[0],         # initialization of stock prices\n",
        "#                             initial_stocks)\n",
        "#     noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "#     sigma = jnp.diag(cov) ** 0.5\n",
        "#     dt = T / numsteps\n",
        "#     def time_step(t, val):\n",
        "#         dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "#         val = jax.ops.index_update(val,\n",
        "#                             jax.ops.index[t],\n",
        "#                             val[t-1] * dx)\n",
        "#         return val\n",
        "#     return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "# def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T):\n",
        "#   return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
        "\n",
        "# numstocks = 1\n",
        "# numsteps = 50\n",
        "# numpaths = 1000000\n",
        "\n",
        "# rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "# rng, key = jax.random.split(rng)\n",
        "\n",
        "# drift = jnp.array([0.0807]*numstocks)\n",
        "# r = drift\n",
        "# cov = jnp.identity(numstocks)*0.2597*0.2597\n",
        "# initial_stocks = jnp.array([0.7178]*numstocks) # must be float\n",
        "# T = 1.0\n",
        "# K = 0.2106\n",
        "\n",
        "# fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "# keys = jax.random.split(key, numpaths)\n",
        "# batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "# # option price\n",
        "# print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "# #%timeit optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T)\n",
        "\n",
        "# # delta test\n",
        "# goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "# print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "# #%timeit goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.52336884\n",
            "[0.9997784]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxFUnc_iBVcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd012765-fdc5-4d05-ffeb-7e929ff81d5b"
      },
      "source": [
        "%%writefile cupy_dataset.py\n",
        "# version 1, 2, 6\n",
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T, keys): # need to pass 'keys'\n",
        "    return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
        "\n",
        "###################################################################################################\n",
        "# these 2 functions must be defined outside class in order to be used in 'optionvalueavg' function\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "###################################################################################################\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len, number_path, batch, seed, stocks):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 50\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = 1.0 # assume T = 1, use float here\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros((self.N_BATCH, 1 + self.N_STOCKS), dtype=cupy.float32) # output: price, delta1, delta2, delta3\n",
        "        X = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "\n",
        "        for op in range(self.N_BATCH):\n",
        "          \n",
        "          rng = jax.random.PRNGKey(self.seed)\n",
        "          rng, key = jax.random.split(rng)\n",
        "\n",
        "          ################################################################################################### generate random input numbers\n",
        "\n",
        "          iv_s0 = (1.25-0.75)/10\n",
        "          iv_sigma = (0.45-0.15)/5\n",
        "          iv_r = (0.6-0.25)/3\n",
        "          iv_K = (1.25-0.75)/10\n",
        "\n",
        "          # initial_stocks = np.array(np.random.randint(75,125,self.N_STOCKS)/100)\n",
        "          # iv_s0 = 0.005\n",
        "          rnd_s0 = np.arange(0.75, 1.25 + iv_s0, iv_s0)\n",
        "          initial_stocks = np.array([rnd_s0[i] for i in np.random.randint(0, len(rnd_s0), self.N_STOCKS)])\n",
        "\n",
        "          corr = np.diag(np.array([1]*self.N_STOCKS)) # assume no correlation between stocks here\n",
        "\n",
        "          # sigma = np.array(np.random.randint(15,45,self.N_STOCKS)/100)\n",
        "\n",
        "          # iv_sigma = 0.005\n",
        "          rnd_sigma = np.arange(0.15, 0.45 + iv_sigma, iv_sigma)\n",
        "          sigma = np.array([rnd_sigma[i] for i in np.random.randint(0, len(rnd_sigma), self.N_STOCKS)])\n",
        "\n",
        "          cov = (np.diag(sigma)).dot(corr).dot(np.diag(sigma))\n",
        "\n",
        "          # r = np.repeat(np.array(np.random.randint(25,60)/100), self.N_STOCKS)\n",
        "          # iv_r = 0.005\n",
        "          rnd_r = np.arange(0.25, 0.6 + iv_r, iv_r)\n",
        "          r = np.repeat(rnd_r[np.random.randint(0,len(rnd_r), 1)], self.N_STOCKS)\n",
        "\n",
        "          drift = r\n",
        "\n",
        "          T = self.T\n",
        "          # K = np.random.randint(75,125)/100\n",
        "          # iv_K = 0.005\n",
        "          rnd_K = np.arange(0.75, 1.25 + iv_K, iv_K)\n",
        "          K = rnd_K[np.random.randint(0, len(rnd_K), 1)]\n",
        "\n",
        "          # initial_stocks = jnp.array(0.75 + np.random.random(self.N_STOCKS) * 0.5)\n",
        "\n",
        "          # corr = jnp.diag(jnp.array([1]*self.N_STOCKS)) # assume no correlation between stocks here\n",
        "          # sigma = jnp.array(0.15 + np.random.random(self.N_STOCKS) * 0.3)\n",
        "          # cov = (jnp.diag(sigma)).dot(corr).dot(jnp.diag(sigma))\n",
        "\n",
        "          # r = jnp.repeat(jnp.array(0.25 + np.random.random(1) * 0.35), self.N_STOCKS)\n",
        "          # drift = r\n",
        "\n",
        "          # T = self.T\n",
        "          # K = 0.75 + np.random.random(1) * 0.5\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### apply functions to compute price and deltas\n",
        "          \n",
        "          keys = jax.random.split(key, self.N_PATHS)\n",
        "\n",
        "          European_Call_price = optionvalueavg(key, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "          gooptionvalue = jax.grad(optionvalueavg, argnums=1)\n",
        "          Deltas = gooptionvalue(keys, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### store input and output numbers in X and Y\n",
        "\n",
        "          Y[op, 0] = European_Call_price\n",
        "          Y[op, 1:] = cupy.array(Deltas, dtype=cupy.float32) # remember to change this!\n",
        "\n",
        "          # T, K, S, sigma, mu, r\n",
        "          paras = (jnp.repeat(jnp.array(T), self.N_STOCKS), jnp.repeat(jnp.array(K), self.N_STOCKS), initial_stocks, sigma, drift, r)\n",
        "          paras = np.column_stack(paras).reshape(1,-1)[0]\n",
        "          X[op,] = cupy.array(paras)\n",
        "\n",
        "          ###################################################################################################\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "# ds = OptionDataSet(max_len = 2, number_path = 1000000, batch = 2, seed = np.random.randint(10000), stocks=1) # for testing purpose, use constant seed. When training, change to random seed\n",
        "# for i in ds:\n",
        "#     print(i)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cupy_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6JO9OBHdvv",
        "outputId": "5efa0962-0a7c-4089-9500-8b8262b61188"
      },
      "source": [
        "%%writefile model.py\n",
        "# version 1,2\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*1, 32) # remember to change this!\n",
        "        self.fc2 = nn.Linear(32, 64)\n",
        "        self.fc3 = nn.Linear(64, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 32)\n",
        "        self.fc6 = nn.Linear(32, 1) # 1 outputs: price\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1.0, 0.5, 0.5, 0.3, 0.35, 0.35]*1)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = (x - torch.tensor([0.0, 0.75, 0.75, 0.15, 0.25, 0.25]*1).cuda()) / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlXD80xPNVc6",
        "outputId": "8f5eb1c3-27e4-4c24-d0f7-26e5ac5ca278"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 33.0 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 17.1 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 15.5 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 7.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S3CyULkENYKb",
        "outputId": "636cac96-2e43-418b-f3f2-93399b32fbf1"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 100000, batch = 32, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter) # print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.44993579387664795 average time 0.09509219434999068 iter num 20\n",
            "loss 0.37701886892318726 average time 0.06407374587498679 iter num 40\n",
            "loss 0.3426636755466461 average time 0.05365934558332697 iter num 60\n",
            "loss 0.35238248109817505 average time 0.04863266008749889 iter num 80\n",
            "loss 0.3117091655731201 average time 0.045362062539998076 iter num 100\n",
            "loss 0.2912866771221161 average time 0.09329350405000128 iter num 20\n",
            "loss 0.26461440324783325 average time 0.06274173109999026 iter num 40\n",
            "loss 0.20713448524475098 average time 0.05289703196665793 iter num 60\n",
            "loss 0.23352718353271484 average time 0.047919822412495705 iter num 80\n",
            "loss 0.2006729394197464 average time 0.04503796053999281 iter num 100\n",
            "loss 0.13694539666175842 average time 0.09445089759998951 iter num 20\n",
            "loss 0.11217367649078369 average time 0.0634651903499929 iter num 40\n",
            "loss 0.08703170716762543 average time 0.053236741416664776 iter num 60\n",
            "loss 0.05504954233765602 average time 0.04810309597499725 iter num 80\n",
            "loss 0.07432571798563004 average time 0.044936814090000325 iter num 100\n",
            "loss 0.0321364551782608 average time 0.09292091870000832 iter num 20\n",
            "loss 0.024503221735358238 average time 0.06290732277499558 iter num 40\n",
            "loss 0.01696135103702545 average time 0.05268852488332906 iter num 60\n",
            "loss 0.01486586220562458 average time 0.04775569668749711 iter num 80\n",
            "loss 0.011822286061942577 average time 0.044819195980003314 iter num 100\n",
            "loss 0.015464258380234241 average time 0.09359887250000157 iter num 20\n",
            "loss 0.01224762573838234 average time 0.06303973427500864 iter num 40\n",
            "loss 0.019640788435935974 average time 0.052985163500015156 iter num 60\n",
            "loss 0.017022257670760155 average time 0.047952261162518536 iter num 80\n",
            "loss 0.013087507337331772 average time 0.044893060420008624 iter num 100\n",
            "loss 0.02136516012251377 average time 0.09120657269997992 iter num 20\n",
            "loss 0.017377233132719994 average time 0.0619596516999934 iter num 40\n",
            "loss 0.01049040723592043 average time 0.051950601616658786 iter num 60\n",
            "loss 0.019332727417349815 average time 0.04710735129999364 iter num 80\n",
            "loss 0.021512562409043312 average time 0.044055834259997935 iter num 100\n",
            "loss 0.017753958702087402 average time 0.09259817849998626 iter num 20\n",
            "loss 0.014344559982419014 average time 0.06253033177500242 iter num 40\n",
            "loss 0.010679294355213642 average time 0.0527531184499973 iter num 60\n",
            "loss 0.01138860359787941 average time 0.04763580752499763 iter num 80\n",
            "loss 0.021309589967131615 average time 0.04483404721999022 iter num 100\n",
            "loss 0.014950788579881191 average time 0.09130374399998117 iter num 20\n",
            "loss 0.016147589311003685 average time 0.06177776939999262 iter num 40\n",
            "loss 0.010109350085258484 average time 0.05189763191666543 iter num 60\n",
            "loss 0.013973377645015717 average time 0.04711052112499488 iter num 80\n",
            "loss 0.015524878166615963 average time 0.04408365516998629 iter num 100\n",
            "loss 0.013573492877185345 average time 0.09245616769999287 iter num 20\n",
            "loss 0.011294756084680557 average time 0.06255654344998333 iter num 40\n",
            "loss 0.01620667614042759 average time 0.052740223266653175 iter num 60\n",
            "loss 0.020140673965215683 average time 0.047661223974992596 iter num 80\n",
            "loss 0.015618186444044113 average time 0.04461757872999669 iter num 100\n",
            "loss 0.01185876876115799 average time 0.0922278583499633 iter num 20\n",
            "loss 0.011278516612946987 average time 0.062164872274979646 iter num 40\n",
            "loss 0.015073147602379322 average time 0.05229917951665281 iter num 60\n",
            "loss 0.012469705194234848 average time 0.047251158862491136 iter num 80\n",
            "loss 0.007628681603819132 average time 0.044267454229993744 iter num 100\n",
            "loss 0.008508117869496346 average time 0.09192650310001227 iter num 20\n",
            "loss 0.01245942059904337 average time 0.062106840425002474 iter num 40\n",
            "loss 0.0151771055534482 average time 0.05215081610000425 iter num 60\n",
            "loss 0.007159498520195484 average time 0.047084640000005604 iter num 80\n",
            "loss 0.012184234336018562 average time 0.04407777534000843 iter num 100\n",
            "loss 0.0155478585511446 average time 0.09216534360000424 iter num 20\n",
            "loss 0.00914782751351595 average time 0.06211600782500568 iter num 40\n",
            "loss 0.014760606922209263 average time 0.05235217486667807 iter num 60\n",
            "loss 0.015165754593908787 average time 0.0474554498250086 iter num 80\n",
            "loss 0.010989240370690823 average time 0.044544244880005406 iter num 100\n",
            "loss 0.01065234187990427 average time 0.09078315349993318 iter num 20\n",
            "loss 0.014322438277304173 average time 0.06135569279994115 iter num 40\n",
            "loss 0.011437155306339264 average time 0.05177691739996438 iter num 60\n",
            "loss 0.014204881154000759 average time 0.04698638409996079 iter num 80\n",
            "loss 0.013320500031113625 average time 0.04405502065996643 iter num 100\n",
            "loss 0.010053923353552818 average time 0.09207543254995017 iter num 20\n",
            "loss 0.011455100029706955 average time 0.06283822952497076 iter num 40\n",
            "loss 0.016231967136263847 average time 0.052802544349970046 iter num 60\n",
            "loss 0.009650751948356628 average time 0.04761483257497616 iter num 80\n",
            "loss 0.006508208345621824 average time 0.044811980359982045 iter num 100\n",
            "loss 0.013700952753424644 average time 0.09206892614997741 iter num 20\n",
            "loss 0.010772761888802052 average time 0.06216247347499575 iter num 40\n",
            "loss 0.016181278973817825 average time 0.05214690884999982 iter num 60\n",
            "loss 0.01678747870028019 average time 0.04715608192499872 iter num 80\n",
            "loss 0.018043983727693558 average time 0.044207070840002416 iter num 100\n",
            "loss 0.010810382664203644 average time 0.09176731795002979 iter num 20\n",
            "loss 0.014048242010176182 average time 0.06227005597501147 iter num 40\n",
            "loss 0.01414140872657299 average time 0.05220968658334944 iter num 60\n",
            "loss 0.012518147937953472 average time 0.04716459990002022 iter num 80\n",
            "loss 0.008168521337211132 average time 0.04416518117001942 iter num 100\n",
            "loss 0.014085670001804829 average time 0.09252263284997753 iter num 20\n",
            "loss 0.012375589460134506 average time 0.0624776943999791 iter num 40\n",
            "loss 0.011128176935017109 average time 0.05236793256663077 iter num 60\n",
            "loss 0.01330539770424366 average time 0.04768494924995821 iter num 80\n",
            "loss 0.016317356377840042 average time 0.044515628139961336 iter num 100\n",
            "loss 0.009554875083267689 average time 0.09141013760001897 iter num 20\n",
            "loss 0.014338823966681957 average time 0.062192333050018075 iter num 40\n",
            "loss 0.004233798012137413 average time 0.052275936350019946 iter num 60\n",
            "loss 0.009928197599947453 average time 0.047321025112523785 iter num 80\n",
            "loss 0.008109970949590206 average time 0.044551298920023324 iter num 100\n",
            "loss 0.011127905920147896 average time 0.09328591789999337 iter num 20\n",
            "loss 0.0071401712484657764 average time 0.06294534565001868 iter num 40\n",
            "loss 0.00643234234303236 average time 0.05304578916664771 iter num 60\n",
            "loss 0.007013709284365177 average time 0.047733902424982946 iter num 80\n",
            "loss 0.010678988881409168 average time 0.0448333847199774 iter num 100\n",
            "loss 0.014282294549047947 average time 0.09167802044999007 iter num 20\n",
            "loss 0.006624264642596245 average time 0.06187789607499781 iter num 40\n",
            "loss 0.011913402937352657 average time 0.05216591016668038 iter num 60\n",
            "loss 0.01303289644420147 average time 0.04715174956248802 iter num 80\n",
            "loss 0.016048114746809006 average time 0.0442452993599818 iter num 100\n",
            "loss 0.006863607093691826 average time 0.09201572694996685 iter num 20\n",
            "loss 0.01332188956439495 average time 0.061836480950000806 iter num 40\n",
            "loss 0.009251377545297146 average time 0.05218542355000864 iter num 60\n",
            "loss 0.00853620283305645 average time 0.047217376737512494 iter num 80\n",
            "loss 0.00739273289218545 average time 0.0441961215800211 iter num 100\n",
            "loss 0.010804449208080769 average time 0.09167679540005338 iter num 20\n",
            "loss 0.004215031396597624 average time 0.061903530025051626 iter num 40\n",
            "loss 0.00547978887334466 average time 0.051980433266696005 iter num 60\n",
            "loss 0.00611637718975544 average time 0.047113804600036245 iter num 80\n",
            "loss 0.009476348757743835 average time 0.044242140770029435 iter num 100\n",
            "loss 0.008748764172196388 average time 0.09354311905003669 iter num 20\n",
            "loss 0.009735843166708946 average time 0.0627318868500197 iter num 40\n",
            "loss 0.012031705118715763 average time 0.05265530018333872 iter num 60\n",
            "loss 0.00608220836147666 average time 0.04767883626250295 iter num 80\n",
            "loss 0.007407625205814838 average time 0.04450171390000832 iter num 100\n",
            "loss 0.008029031567275524 average time 0.09270449085001928 iter num 20\n",
            "loss 0.005473422352224588 average time 0.06268653742499737 iter num 40\n",
            "loss 0.01091994158923626 average time 0.05248968413334296 iter num 60\n",
            "loss 0.009035810828208923 average time 0.04763561455002332 iter num 80\n",
            "loss 0.006924450397491455 average time 0.04468163784002627 iter num 100\n",
            "loss 0.006017108913511038 average time 0.0923790120500371 iter num 20\n",
            "loss 0.009280083701014519 average time 0.06237889347501095 iter num 40\n",
            "loss 0.005393181461840868 average time 0.05227336754999972 iter num 60\n",
            "loss 0.005320915952324867 average time 0.047171427499989704 iter num 80\n",
            "loss 0.0058993203565478325 average time 0.04412377273999027 iter num 100\n",
            "loss 0.006120824255049229 average time 0.0914822199500577 iter num 20\n",
            "loss 0.011090144515037537 average time 0.06213543942501474 iter num 40\n",
            "loss 0.004195218440145254 average time 0.05222160711666675 iter num 60\n",
            "loss 0.004825506825000048 average time 0.04729720836249385 iter num 80\n",
            "loss 0.009079874493181705 average time 0.044407465130002495 iter num 100\n",
            "loss 0.01378441322594881 average time 0.09074891685002058 iter num 20\n",
            "loss 0.007265898399055004 average time 0.061486089975051075 iter num 40\n",
            "loss 0.0035082323011010885 average time 0.05173765726667625 iter num 60\n",
            "loss 0.004949306603521109 average time 0.047007491050015913 iter num 80\n",
            "loss 0.006202090997248888 average time 0.04417786280001565 iter num 100\n",
            "loss 0.006325004156678915 average time 0.09105954775004647 iter num 20\n",
            "loss 0.009227908216416836 average time 0.06205671547502334 iter num 40\n",
            "loss 0.0022440566681325436 average time 0.052018975400020886 iter num 60\n",
            "loss 0.004174539819359779 average time 0.04719765077500711 iter num 80\n",
            "loss 0.0037846898194402456 average time 0.044200570560001325 iter num 100\n",
            "loss 0.003539453027769923 average time 0.09119411540002602 iter num 20\n",
            "loss 0.004339545499533415 average time 0.061834435949981524 iter num 40\n",
            "loss 0.00508815236389637 average time 0.05211171099998258 iter num 60\n",
            "loss 0.006222199648618698 average time 0.047143306287489396 iter num 80\n",
            "loss 0.004947889130562544 average time 0.0442654614599951 iter num 100\n",
            "loss 0.004281498491764069 average time 0.09369109614999616 iter num 20\n",
            "loss 0.005095702596008778 average time 0.06328760387500551 iter num 40\n",
            "loss 0.00506179966032505 average time 0.053204923350009876 iter num 60\n",
            "loss 0.0016503200167790055 average time 0.04785541911249993 iter num 80\n",
            "loss 0.007680671289563179 average time 0.04467319703000612 iter num 100\n",
            "loss 0.00368894194252789 average time 0.09156263475001651 iter num 20\n",
            "loss 0.0010457170428708196 average time 0.0618951350000998 iter num 40\n",
            "loss 0.0067261457443237305 average time 0.05204608346674225 iter num 60\n",
            "loss 0.0036273638252168894 average time 0.04707909782501929 iter num 80\n",
            "loss 0.005558626260608435 average time 0.044346841750038946 iter num 100\n",
            "loss 0.00448371609672904 average time 0.09285057990000496 iter num 20\n",
            "loss 0.0014995801029726863 average time 0.06245165160003126 iter num 40\n",
            "loss 0.005034917499870062 average time 0.0523959432500457 iter num 60\n",
            "loss 0.004979624878615141 average time 0.047354520937494725 iter num 80\n",
            "loss 0.0028815255500376225 average time 0.04434848012997463 iter num 100\n",
            "loss 0.004665501415729523 average time 0.09199102644993218 iter num 20\n",
            "loss 0.00471652764827013 average time 0.062419545999887305 iter num 40\n",
            "loss 0.0016819521551951766 average time 0.052211589483264716 iter num 60\n",
            "loss 0.005293081980198622 average time 0.047318812037474345 iter num 80\n",
            "loss 0.0019399072043597698 average time 0.04433149736995801 iter num 100\n",
            "loss 0.007117354776710272 average time 0.09161884549989736 iter num 20\n",
            "loss 0.0025318018160760403 average time 0.061925906949886665 iter num 40\n",
            "loss 0.001307690516114235 average time 0.05199340578327186 iter num 60\n",
            "loss 0.005094221793115139 average time 0.047138511699961326 iter num 80\n",
            "loss 0.0026606516912579536 average time 0.044301810409961034 iter num 100\n",
            "loss 0.003088374389335513 average time 0.09211118564990102 iter num 20\n",
            "loss 0.007876834832131863 average time 0.06188468992490925 iter num 40\n",
            "loss 0.004677633289247751 average time 0.05208623643329702 iter num 60\n",
            "loss 0.005297140218317509 average time 0.04699429467499385 iter num 80\n",
            "loss 0.0024800298269838095 average time 0.04395637694998186 iter num 100\n",
            "loss 0.001569212879985571 average time 0.09117911379985344 iter num 20\n",
            "loss 0.0009820898994803429 average time 0.06215927352495783 iter num 40\n",
            "loss 0.003988412208855152 average time 0.05208552173327614 iter num 60\n",
            "loss 0.0030647250823676586 average time 0.047190638187487366 iter num 80\n",
            "loss 0.0012936568818986416 average time 0.04434225160998721 iter num 100\n",
            "loss 0.0029675918631255627 average time 0.0917754784501085 iter num 20\n",
            "loss 0.005092431791126728 average time 0.06216547217509287 iter num 40\n",
            "loss 0.004770854488015175 average time 0.052270508883414855 iter num 60\n",
            "loss 0.000746513600461185 average time 0.04731452442506452 iter num 80\n",
            "loss 0.0025813295505940914 average time 0.04428503227005422 iter num 100\n",
            "loss 0.0027656902093440294 average time 0.09198115325011713 iter num 20\n",
            "loss 0.002228260738775134 average time 0.06205639992497254 iter num 40\n",
            "loss 0.0013219983084127307 average time 0.052170996416680285 iter num 60\n",
            "loss 0.0011141574941575527 average time 0.04729299484999956 iter num 80\n",
            "loss 0.0013681806158274412 average time 0.04428593737997289 iter num 100\n",
            "loss 0.003403864800930023 average time 0.09186704769986136 iter num 20\n",
            "loss 0.0007067478727549314 average time 0.06189909694990092 iter num 40\n",
            "loss 0.0011993874795734882 average time 0.05187442878321538 iter num 60\n",
            "loss 0.000788831792306155 average time 0.047002934774877755 iter num 80\n",
            "loss 0.002271044533699751 average time 0.04400922681988959 iter num 100\n",
            "loss 0.0008633389370515943 average time 0.09123800074994506 iter num 20\n",
            "loss 0.0013742325827479362 average time 0.06185292104999007 iter num 40\n",
            "loss 0.004130648449063301 average time 0.051878104199977314 iter num 60\n",
            "loss 0.0021309421863406897 average time 0.04700745259997348 iter num 80\n",
            "loss 0.0004588695301208645 average time 0.04409462367998458 iter num 100\n",
            "loss 0.0024241695646196604 average time 0.0927090161000251 iter num 20\n",
            "loss 0.0006795921945013106 average time 0.06263908275000177 iter num 40\n",
            "loss 0.0012775365030393004 average time 0.052642533049932654 iter num 60\n",
            "loss 0.0009050732478499413 average time 0.04741689882495166 iter num 80\n",
            "loss 0.002340801991522312 average time 0.04432976256995971 iter num 100\n",
            "loss 0.002339970786124468 average time 0.0925093654000193 iter num 20\n",
            "loss 0.0006998036988079548 average time 0.06242858154998885 iter num 40\n",
            "loss 0.0005742215435020626 average time 0.05252643776663414 iter num 60\n",
            "loss 0.0035162209533154964 average time 0.04734236844994939 iter num 80\n",
            "loss 0.0025342577137053013 average time 0.04456068065995169 iter num 100\n",
            "loss 0.0007273548981174827 average time 0.09299939909997193 iter num 20\n",
            "loss 0.0007041008211672306 average time 0.062766002425019 iter num 40\n",
            "loss 0.0017362853977829218 average time 0.05256927523335738 iter num 60\n",
            "loss 0.0004132977337576449 average time 0.04762340932502411 iter num 80\n",
            "loss 0.0008130344795063138 average time 0.04461502245001611 iter num 100\n",
            "loss 0.0019508256809785962 average time 0.0912064182999984 iter num 20\n",
            "loss 0.0009373265202157199 average time 0.061987057075020856 iter num 40\n",
            "loss 0.0012834696099162102 average time 0.05204756319999433 iter num 60\n",
            "loss 0.0007040300988592207 average time 0.047122329949991125 iter num 80\n",
            "loss 0.002303629880771041 average time 0.04411273640998843 iter num 100\n",
            "loss 0.002951844595372677 average time 0.09127118649989825 iter num 20\n",
            "loss 0.0007298175478354096 average time 0.06145035329991515 iter num 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-9251a825839c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m           \u001b[0;31m################################################################################################### store input and output numbers in X and Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m           \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEuropean_Call_price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m           \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDeltas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# remember to change this!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.__setitem__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_routines_indexing.pyx\u001b[0m in \u001b[0;36mcupy._core._routines_indexing._ndarray_setitem\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_routines_indexing.pyx\u001b[0m in \u001b[0;36mcupy._core._routines_indexing._scatter_op\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.fill\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_forward_method\u001b[0;34m(attrname, self, fun, *args)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_forward_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0m_forward_to_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_forward_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c07ada-e916-4342-b7a0-2a7d71ea9629"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_pricedelta_grid_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a379315-c4c9-4c17-c5a8-2762d43b8a20"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c5fcb1-e280-4bb4-a7d2-ed2050957d60"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_pricedelta_grid_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "108c9ead-79df-4521-e5ff-ecc4dd91491a"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=6, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc5): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc6): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0e84bef0-f353-48a6-ab71-03a4657d128f"
      },
      "source": [
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "#dataset = OptionDataSet(max_len = 100, number_path = 1024, batch = 32, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 2000000, batch = 8, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 10\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter) # print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)\n",
        "\n",
        "model_save_name = 'jax_european_1stock_pricedelta_grid_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.00063907919684425 average time 0.3314194293001492 iter num 10\n",
            "loss 0.000858944549690932 average time 0.17118208174988467 iter num 20\n",
            "loss 0.011773267760872841 average time 0.11760957503314179 iter num 30\n",
            "loss 0.003528893692418933 average time 0.09090262622494265 iter num 40\n",
            "loss 0.0002975306997541338 average time 0.07482596553989423 iter num 50\n",
            "loss 0.0009403961594216526 average time 0.0641359110832127 iter num 60\n",
            "loss 0.0011340834898874164 average time 0.05660051882841799 iter num 70\n",
            "loss 0.00020314088033046573 average time 0.05084071332487383 iter num 80\n",
            "loss 0.0003697046486195177 average time 0.04637916583324113 iter num 90\n",
            "loss 0.0008275659056380391 average time 0.04280346818992257 iter num 100\n",
            "loss 0.0021193097345530987 average time 0.3310484775998702 iter num 10\n",
            "loss 0.0013322740560397506 average time 0.17073044074995777 iter num 20\n",
            "loss 0.0012229513376951218 average time 0.11729710106659089 iter num 30\n",
            "loss 0.007902507670223713 average time 0.09060303027486043 iter num 40\n",
            "loss 0.0006572201964445412 average time 0.07459133185984683 iter num 50\n",
            "loss 0.00034343809238635004 average time 0.06390658148329749 iter num 60\n",
            "loss 0.0006606813403777778 average time 0.056274797528489476 iter num 70\n",
            "loss 0.0012228289851918817 average time 0.050540849212416104 iter num 80\n",
            "loss 0.0003380709094926715 average time 0.0461142894666207 iter num 90\n",
            "loss 0.0005119410925544798 average time 0.04258063548999416 iter num 100\n",
            "loss 0.0005439703818410635 average time 0.33045732980026515 iter num 10\n",
            "loss 0.0007633018540218472 average time 0.17048599045028823 iter num 20\n",
            "loss 0.0026707041542977095 average time 0.11714007700029469 iter num 30\n",
            "loss 0.0006657863268628716 average time 0.0904942828251933 iter num 40\n",
            "loss 0.002809209283441305 average time 0.07445838080020621 iter num 50\n",
            "loss 0.0003022165910806507 average time 0.06385580590012978 iter num 60\n",
            "loss 0.00034442025935277343 average time 0.05623883541445269 iter num 70\n",
            "loss 0.0001493702584411949 average time 0.05051870502516067 iter num 80\n",
            "loss 0.0006124615902081132 average time 0.04613545195572644 iter num 90\n",
            "loss 0.0004177420341875404 average time 0.042553331020153566 iter num 100\n",
            "loss 0.000582153326831758 average time 0.33032502150017534 iter num 10\n",
            "loss 0.0002611075760796666 average time 0.17057690285000718 iter num 20\n",
            "loss 0.00026184911257587373 average time 0.11718570890006959 iter num 30\n",
            "loss 0.0004528170684352517 average time 0.09058169892505248 iter num 40\n",
            "loss 0.0008999747806228697 average time 0.07456908834006754 iter num 50\n",
            "loss 0.0002355964679736644 average time 0.06389105598339787 iter num 60\n",
            "loss 0.00035775176365859807 average time 0.05625094885713874 iter num 70\n",
            "loss 0.0005480648251250386 average time 0.050542425787466524 iter num 80\n",
            "loss 0.00022017951414454728 average time 0.046088148444404294 iter num 90\n",
            "loss 0.0006281475070863962 average time 0.04252913391994298 iter num 100\n",
            "loss 0.0004874564765486866 average time 0.3307617959002528 iter num 10\n",
            "loss 0.0012597930617630482 average time 0.17064828095008125 iter num 20\n",
            "loss 0.0008620750159025192 average time 0.1172088445334642 iter num 30\n",
            "loss 0.000310934497974813 average time 0.09060469600008218 iter num 40\n",
            "loss 0.0003702824469655752 average time 0.0745743992401549 iter num 50\n",
            "loss 0.00036298102349974215 average time 0.06388592531684481 iter num 60\n",
            "loss 0.00019538748892955482 average time 0.056340154985835916 iter num 70\n",
            "loss 0.0025521712377667427 average time 0.0506111077001151 iter num 80\n",
            "loss 0.006274321582168341 average time 0.04616558812233254 iter num 90\n",
            "loss 0.00037518783938139677 average time 0.042591394430110084 iter num 100\n",
            "loss 0.0013157549547031522 average time 0.33131320509965007 iter num 10\n",
            "loss 0.00044705308391712606 average time 0.17086553604967775 iter num 20\n",
            "loss 0.00042362092062830925 average time 0.11747292306651312 iter num 30\n",
            "loss 0.0003618276969064027 average time 0.09074636424988966 iter num 40\n",
            "loss 0.0005320797790773213 average time 0.07471953755990399 iter num 50\n",
            "loss 0.0006443558959290385 average time 0.06407201733324351 iter num 60\n",
            "loss 0.0021472210064530373 average time 0.05639780139988163 iter num 70\n",
            "loss 0.0002714983420446515 average time 0.05065395626238569 iter num 80\n",
            "loss 0.0004118286888115108 average time 0.04617846072214889 iter num 90\n",
            "loss 0.0003146572271361947 average time 0.042613389219914095 iter num 100\n",
            "loss 0.0002521580900065601 average time 0.33055828619981187 iter num 10\n",
            "loss 0.0008595701074227691 average time 0.17051755779993982 iter num 20\n",
            "loss 0.0002958083350677043 average time 0.11716840830007035 iter num 30\n",
            "loss 0.000334480544552207 average time 0.0906402885499574 iter num 40\n",
            "loss 0.000721348449587822 average time 0.07461592253996059 iter num 50\n",
            "loss 0.0004403314087539911 average time 0.06392652286661663 iter num 60\n",
            "loss 0.010989884845912457 average time 0.05633211669994905 iter num 70\n",
            "loss 0.0002484518336132169 average time 0.05059580676247606 iter num 80\n",
            "loss 0.00043211854062974453 average time 0.04615890056664082 iter num 90\n",
            "loss 0.00048105698078870773 average time 0.04263044603001617 iter num 100\n",
            "loss 0.0005774835008196533 average time 0.3303529509001237 iter num 10\n",
            "loss 0.0007474932936020195 average time 0.17036553440011631 iter num 20\n",
            "loss 0.0006197109469212592 average time 0.11707941206659597 iter num 30\n",
            "loss 0.00020441912056412548 average time 0.09045566824988782 iter num 40\n",
            "loss 0.0020539110992103815 average time 0.07445635579988448 iter num 50\n",
            "loss 0.0008106730529107153 average time 0.06381932256663277 iter num 60\n",
            "loss 0.0005610776133835316 average time 0.05618605204282565 iter num 70\n",
            "loss 0.0018363262061029673 average time 0.050465017287478986 iter num 80\n",
            "loss 0.0005283101345412433 average time 0.046067783733370664 iter num 90\n",
            "loss 0.0015460551949217916 average time 0.04250046306999138 iter num 100\n",
            "loss 0.00019708026957232505 average time 0.33079348399969605 iter num 10\n",
            "loss 0.0009241394582204521 average time 0.1708550909499536 iter num 20\n",
            "loss 0.0030109204817563295 average time 0.11740106676679715 iter num 30\n",
            "loss 0.000700790376868099 average time 0.09070909500010202 iter num 40\n",
            "loss 0.000366252294043079 average time 0.07485940588005179 iter num 50\n",
            "loss 0.0003345821751281619 average time 0.06413549010000376 iter num 60\n",
            "loss 0.0004686795873567462 average time 0.05648193835718952 iter num 70\n",
            "loss 0.000381998426746577 average time 0.05071844082503958 iter num 80\n",
            "loss 0.00038557418156415224 average time 0.046363571444493976 iter num 90\n",
            "loss 0.0005738346371799707 average time 0.042780325430067025 iter num 100\n",
            "loss 0.0014074918581172824 average time 0.33127888589988286 iter num 10\n",
            "loss 0.00016103326925076544 average time 0.17087206760006665 iter num 20\n",
            "loss 0.0004957549972459674 average time 0.11772472980010207 iter num 30\n",
            "loss 0.00033071867073886096 average time 0.09090404055000363 iter num 40\n",
            "loss 0.0003133425198029727 average time 0.07486374355994485 iter num 50\n",
            "loss 0.000645834777969867 average time 0.06412429771659542 iter num 60\n",
            "loss 0.00016984388639684767 average time 0.05648650668569774 iter num 70\n",
            "loss 0.0006155426381155849 average time 0.050766407999958574 iter num 80\n",
            "loss 0.002198305446654558 average time 0.04635438002223964 iter num 90\n",
            "loss 0.00029928478761576116 average time 0.04277429827001469 iter num 100\n",
            "loss 0.00037532130954787135 average time 0.33064389070004835 iter num 10\n",
            "loss 0.001433062949217856 average time 0.1705150619000051 iter num 20\n",
            "loss 0.002780045848339796 average time 0.11718339533332861 iter num 30\n",
            "loss 0.00024319530348293483 average time 0.09054459885001051 iter num 40\n",
            "loss 0.00044855716987513006 average time 0.07453640266005096 iter num 50\n",
            "loss 0.0007245989399962127 average time 0.06399166738344017 iter num 60\n",
            "loss 0.00023855434847064316 average time 0.05636315361438652 iter num 70\n",
            "loss 0.0001669159100856632 average time 0.050619963625081255 iter num 80\n",
            "loss 0.0003664742107503116 average time 0.046152167266720626 iter num 90\n",
            "loss 0.0003462150343693793 average time 0.04257520299999669 iter num 100\n",
            "loss 0.002421185141429305 average time 0.33112034770019816 iter num 10\n",
            "loss 0.00047065093531273305 average time 0.17076290190007057 iter num 20\n",
            "loss 0.0007432377897202969 average time 0.11736476540014944 iter num 30\n",
            "loss 0.00046001223381608725 average time 0.09066611002513128 iter num 40\n",
            "loss 0.0004595080390572548 average time 0.07466242788006638 iter num 50\n",
            "loss 0.00030007175519131124 average time 0.06411819260010816 iter num 60\n",
            "loss 0.0011337213218212128 average time 0.05644150168575704 iter num 70\n",
            "loss 0.00046787323663011193 average time 0.05069715221250135 iter num 80\n",
            "loss 0.00017901071987580508 average time 0.046236555055596304 iter num 90\n",
            "loss 0.00028888083761557937 average time 0.04264748674999282 iter num 100\n",
            "loss 0.004565270151942968 average time 0.3308968314997401 iter num 10\n",
            "loss 0.000394708476960659 average time 0.17072494449985243 iter num 20\n",
            "loss 0.0007308879285119474 average time 0.11731625093331483 iter num 30\n",
            "loss 0.00043742419802583754 average time 0.09060667510002532 iter num 40\n",
            "loss 0.00021158198069315404 average time 0.07457833209991804 iter num 50\n",
            "loss 0.0019677304662764072 average time 0.06390336329992957 iter num 60\n",
            "loss 0.0009027956984937191 average time 0.05634612150001236 iter num 70\n",
            "loss 0.0003602825745474547 average time 0.05062194048753099 iter num 80\n",
            "loss 0.00019489617261569947 average time 0.04616935743336702 iter num 90\n",
            "loss 0.00288247037678957 average time 0.04264427518004595 iter num 100\n",
            "loss 0.0010266350582242012 average time 0.33081000370020774 iter num 10\n",
            "loss 0.00024879674310795963 average time 0.1706182978999095 iter num 20\n",
            "loss 0.00011180184810655192 average time 0.11732646296677558 iter num 30\n",
            "loss 0.00037422426976263523 average time 0.09062670205016729 iter num 40\n",
            "loss 0.000582957873120904 average time 0.07463579350020154 iter num 50\n",
            "loss 0.002201901748776436 average time 0.06393968921678 iter num 60\n",
            "loss 0.0002855061611626297 average time 0.056307280085820824 iter num 70\n",
            "loss 0.00029137093224562705 average time 0.0505777109626024 iter num 80\n",
            "loss 0.0003723546105902642 average time 0.04610841496673351 iter num 90\n",
            "loss 0.00026116330991499126 average time 0.04256522178004161 iter num 100\n",
            "loss 0.00036262901267036796 average time 0.3305385394998666 iter num 10\n",
            "loss 0.00030737280030734837 average time 0.17058028444998855 iter num 20\n",
            "loss 0.00020102101552765816 average time 0.11727262156643216 iter num 30\n",
            "loss 0.00030238699400797486 average time 0.09063958182473471 iter num 40\n",
            "loss 0.0002413148758932948 average time 0.0746896904197638 iter num 50\n",
            "loss 0.0003227547276765108 average time 0.06403473966641589 iter num 60\n",
            "loss 0.0015109465457499027 average time 0.056378634899816205 iter num 70\n",
            "loss 0.0031207266729325056 average time 0.05063176149978972 iter num 80\n",
            "loss 0.0008149616769514978 average time 0.046180735988693614 iter num 90\n",
            "loss 0.00028783330344595015 average time 0.04260966508982165 iter num 100\n",
            "loss 0.0015114668058231473 average time 0.33101514679947286 iter num 10\n",
            "loss 0.00033603268093429506 average time 0.1708282955498362 iter num 20\n",
            "loss 0.0006836381508037448 average time 0.11743740796658433 iter num 30\n",
            "loss 0.007971884682774544 average time 0.09069589544992596 iter num 40\n",
            "loss 0.00026487550348974764 average time 0.07463290423995204 iter num 50\n",
            "loss 0.00041341251926496625 average time 0.06396222949994505 iter num 60\n",
            "loss 0.0004809554957319051 average time 0.056330810442809055 iter num 70\n",
            "loss 0.00043436704436317086 average time 0.050603962312447945 iter num 80\n",
            "loss 0.0003930467355530709 average time 0.04617531045548983 iter num 90\n",
            "loss 0.00034346015308983624 average time 0.042599727469969366 iter num 100\n",
            "loss 0.000105662016721908 average time 0.33108857320003154 iter num 10\n",
            "loss 0.00031370713259093463 average time 0.17077561604983202 iter num 20\n",
            "loss 0.00027735732146538794 average time 0.11741409743317491 iter num 30\n",
            "loss 0.00030738909845240414 average time 0.09074800087491894 iter num 40\n",
            "loss 0.00023756826703902334 average time 0.07467757759990491 iter num 50\n",
            "loss 0.00023201668227557093 average time 0.06395555013323247 iter num 60\n",
            "loss 0.0002658969024196267 average time 0.05632890988565902 iter num 70\n",
            "loss 0.0003573282156139612 average time 0.050604695237507255 iter num 80\n",
            "loss 0.00041171832708641887 average time 0.046165438266628674 iter num 90\n",
            "loss 0.0001753875840222463 average time 0.04260802395996507 iter num 100\n",
            "loss 0.004232116974890232 average time 0.33065749639990827 iter num 10\n",
            "loss 0.002757546491920948 average time 0.17060117099999844 iter num 20\n",
            "loss 0.0008305495721288025 average time 0.11724190376662591 iter num 30\n",
            "loss 0.0007074599270708859 average time 0.09053026690007755 iter num 40\n",
            "loss 0.0031527711544185877 average time 0.07451482632011902 iter num 50\n",
            "loss 0.0003116782463621348 average time 0.06388579396677112 iter num 60\n",
            "loss 0.0006835502572357655 average time 0.056274041928710564 iter num 70\n",
            "loss 0.0005786585388705134 average time 0.05053259932512901 iter num 80\n",
            "loss 0.0009162156493403018 average time 0.046090927811201256 iter num 90\n",
            "loss 0.004500719252973795 average time 0.042524756470083955 iter num 100\n",
            "loss 0.00045188888907432556 average time 0.33127141690019923 iter num 10\n",
            "loss 0.0003973034326918423 average time 0.1709234863000347 iter num 20\n",
            "loss 0.001328822923824191 average time 0.11750241336661323 iter num 30\n",
            "loss 0.0005605893675237894 average time 0.09077436507500351 iter num 40\n",
            "loss 0.000608159345574677 average time 0.07472621512002661 iter num 50\n",
            "loss 0.0003495965793263167 average time 0.06409805454992844 iter num 60\n",
            "loss 0.001449831761419773 average time 0.05641608809998745 iter num 70\n",
            "loss 0.0012683146633207798 average time 0.050674746287495506 iter num 80\n",
            "loss 0.00011956693197134882 average time 0.04621220343332324 iter num 90\n",
            "loss 8.575708488933742e-05 average time 0.04266716820999136 iter num 100\n",
            "loss 0.0006263337563723326 average time 0.3305982659005167 iter num 10\n",
            "loss 0.00022022973280400038 average time 0.1707215631503459 iter num 20\n",
            "loss 0.0008518583490513265 average time 0.11732291106691264 iter num 30\n",
            "loss 0.0003214812313672155 average time 0.09060135462532344 iter num 40\n",
            "loss 9.279744699597359e-05 average time 0.0746225083801255 iter num 50\n",
            "loss 0.00022712632198818028 average time 0.06395520108350562 iter num 60\n",
            "loss 0.00015471293590962887 average time 0.056318904228776646 iter num 70\n",
            "loss 0.00015149438695516437 average time 0.050584460512664006 iter num 80\n",
            "loss 0.000535565079189837 average time 0.04616043903345902 iter num 90\n",
            "loss 0.0006088890368118882 average time 0.042627188710212066 iter num 100\n",
            "loss 0.0007662785355933011 average time 0.33087153489941556 iter num 10\n",
            "loss 0.01325099729001522 average time 0.17057795110031293 iter num 20\n",
            "loss 0.00026949107996188104 average time 0.11719564603348166 iter num 30\n",
            "loss 0.0003681510570459068 average time 0.09049992757509244 iter num 40\n",
            "loss 0.0009262557723559439 average time 0.07446862460019474 iter num 50\n",
            "loss 0.0002777388144750148 average time 0.06382305316692509 iter num 60\n",
            "loss 0.0004046650428790599 average time 0.05619725877165495 iter num 70\n",
            "loss 0.0007103928364813328 average time 0.050523762050215734 iter num 80\n",
            "loss 0.0029525512363761663 average time 0.04607018222236042 iter num 90\n",
            "loss 0.00037974989390932024 average time 0.04251920107013575 iter num 100\n",
            "loss 0.0004338854632806033 average time 0.330499899500137 iter num 10\n",
            "loss 0.0004681901482399553 average time 0.1704574135503208 iter num 20\n",
            "loss 0.000503694114740938 average time 0.11717197800026043 iter num 30\n",
            "loss 0.00038856404717080295 average time 0.090499855975213 iter num 40\n",
            "loss 0.0005058665410615504 average time 0.07448862325989467 iter num 50\n",
            "loss 0.0002785967371892184 average time 0.06379847956662464 iter num 60\n",
            "loss 0.0003629427228588611 average time 0.05616502639989319 iter num 70\n",
            "loss 0.00022071351122576743 average time 0.050460207812420776 iter num 80\n",
            "loss 0.00013736292021349072 average time 0.04602774948879313 iter num 90\n",
            "loss 0.0004666122258640826 average time 0.04246702951997577 iter num 100\n",
            "loss 0.00038260463043116033 average time 0.3309006846993725 iter num 10\n",
            "loss 0.0014540947740897536 average time 0.17069629114957935 iter num 20\n",
            "loss 0.0010035232407972217 average time 0.11733956559971072 iter num 30\n",
            "loss 0.00021095830015838146 average time 0.09060236329987674 iter num 40\n",
            "loss 0.0033217277377843857 average time 0.07463745049994032 iter num 50\n",
            "loss 0.00041902612429112196 average time 0.06395084483337996 iter num 60\n",
            "loss 0.0021614080760627985 average time 0.0562843494428567 iter num 70\n",
            "loss 0.00033904306474141777 average time 0.050581166675101485 iter num 80\n",
            "loss 0.00023021279776003212 average time 0.046144967266728704 iter num 90\n",
            "loss 0.00029673310928046703 average time 0.04257592003003083 iter num 100\n",
            "loss 0.00035401390050537884 average time 0.33019957890028306 iter num 10\n",
            "loss 0.005010840483009815 average time 0.17048655309990862 iter num 20\n",
            "loss 0.000438358576502651 average time 0.1171474066999508 iter num 30\n",
            "loss 0.0002394824696239084 average time 0.09050792209991414 iter num 40\n",
            "loss 0.0002143978199455887 average time 0.07467918588008615 iter num 50\n",
            "loss 0.0005637092981487513 average time 0.06399104211680727 iter num 60\n",
            "loss 0.00046322058187797666 average time 0.05635195078575635 iter num 70\n",
            "loss 0.00015042551967781037 average time 0.05067932276260763 iter num 80\n",
            "loss 0.002721909899264574 average time 0.04625550568897678 iter num 90\n",
            "loss 0.006788934115320444 average time 0.0426867354701244 iter num 100\n",
            "loss 0.00044586180592887104 average time 0.33060191580007087 iter num 10\n",
            "loss 0.00021964525512885302 average time 0.17048846764992048 iter num 20\n",
            "loss 0.00016263283032458276 average time 0.11713729099974443 iter num 30\n",
            "loss 0.00036157923750579357 average time 0.090579805699781 iter num 40\n",
            "loss 0.00019806114141829312 average time 0.0746052192998468 iter num 50\n",
            "loss 0.0003634609456639737 average time 0.06391352203305965 iter num 60\n",
            "loss 0.0003635194734670222 average time 0.056278824614024156 iter num 70\n",
            "loss 0.0001500418729847297 average time 0.05055180294971251 iter num 80\n",
            "loss 0.0003111115947831422 average time 0.04611381655530648 iter num 90\n",
            "loss 0.0013981421943753958 average time 0.04254565442977764 iter num 100\n",
            "loss 0.0010383239714428782 average time 0.3305319594008324 iter num 10\n",
            "loss 0.00038137927185744047 average time 0.1704896667508365 iter num 20\n",
            "loss 0.00074417470023036 average time 0.11720563853402079 iter num 30\n",
            "loss 0.00019689144392032176 average time 0.09049634787561445 iter num 40\n",
            "loss 0.0004264003655407578 average time 0.0744845797605376 iter num 50\n",
            "loss 0.0003068940422963351 average time 0.0638171064838995 iter num 60\n",
            "loss 0.00013742473674938083 average time 0.05621816232898189 iter num 70\n",
            "loss 0.004932959098368883 average time 0.050511727962839356 iter num 80\n",
            "loss 0.00026122076087631285 average time 0.0461171188336367 iter num 90\n",
            "loss 0.0002423595724394545 average time 0.04256475180030975 iter num 100\n",
            "loss 0.0008695891592651606 average time 0.3306085086001985 iter num 10\n",
            "loss 0.00016824668273329735 average time 0.17050026615015668 iter num 20\n",
            "loss 0.0010740639409050345 average time 0.11729458409996975 iter num 30\n",
            "loss 0.00013118216884322464 average time 0.09059075829982248 iter num 40\n",
            "loss 0.0003633746528066695 average time 0.07455337245977717 iter num 50\n",
            "loss 0.00020513315394055098 average time 0.06385982014974918 iter num 60\n",
            "loss 0.00044943526154384017 average time 0.05634868021417268 iter num 70\n",
            "loss 0.00016271507774945349 average time 0.0506190353873535 iter num 80\n",
            "loss 0.0007217315142042935 average time 0.046161757766498744 iter num 90\n",
            "loss 0.00010852062405319884 average time 0.04260295910986315 iter num 100\n",
            "loss 0.00021954963449388742 average time 0.3313372681990586 iter num 10\n",
            "loss 0.0006378571852110326 average time 0.17091611354971975 iter num 20\n",
            "loss 0.0003871582157444209 average time 0.11745627149975917 iter num 30\n",
            "loss 0.005171771161258221 average time 0.09076334734982083 iter num 40\n",
            "loss 0.0001443829678464681 average time 0.07468808509991504 iter num 50\n",
            "loss 0.00023766675440128893 average time 0.06397739248313883 iter num 60\n",
            "loss 0.0002152751258108765 average time 0.05633686868563278 iter num 70\n",
            "loss 0.0005335623864084482 average time 0.050640779249897606 iter num 80\n",
            "loss 0.0001793024130165577 average time 0.04617514112218891 iter num 90\n",
            "loss 0.0010455201845616102 average time 0.04260460383993632 iter num 100\n",
            "loss 0.0004927281988784671 average time 0.3305574322999746 iter num 10\n",
            "loss 0.0009206195827573538 average time 0.17053415664977364 iter num 20\n",
            "loss 0.00035405479138717055 average time 0.11715592356655785 iter num 30\n",
            "loss 0.000788519624620676 average time 0.09046681769978022 iter num 40\n",
            "loss 0.00031784476595930755 average time 0.07448029849976592 iter num 50\n",
            "loss 0.000199566813535057 average time 0.06388125443306004 iter num 60\n",
            "loss 0.00028073450084775686 average time 0.05626014715692561 iter num 70\n",
            "loss 0.00010104793909704313 average time 0.05054945119977674 iter num 80\n",
            "loss 0.0007998069631867111 average time 0.04613331058854884 iter num 90\n",
            "loss 0.000779976777266711 average time 0.04259640850967116 iter num 100\n",
            "loss 0.0003967550292145461 average time 0.33064103410069945 iter num 10\n",
            "loss 0.0008857676875777543 average time 0.17049769130044296 iter num 20\n",
            "loss 0.0002677773591130972 average time 0.11721640523355745 iter num 30\n",
            "loss 0.0008849960286170244 average time 0.0905715728749783 iter num 40\n",
            "loss 0.0004002998466603458 average time 0.0745549661199766 iter num 50\n",
            "loss 0.00032189968624152243 average time 0.06387956621668613 iter num 60\n",
            "loss 0.0002571153163444251 average time 0.056412410985805246 iter num 70\n",
            "loss 0.000642953731585294 average time 0.05068281213757473 iter num 80\n",
            "loss 0.00034408882493153214 average time 0.046212563544516645 iter num 90\n",
            "loss 0.0014673396944999695 average time 0.04263790910012176 iter num 100\n",
            "loss 0.00021779989765491337 average time 0.3311561341997731 iter num 10\n",
            "loss 0.000528923177625984 average time 0.1709872829997039 iter num 20\n",
            "loss 0.00034552140277810395 average time 0.11746968353327247 iter num 30\n",
            "loss 0.005060392897576094 average time 0.09071124189977127 iter num 40\n",
            "loss 0.000901266816072166 average time 0.07469838943979994 iter num 50\n",
            "loss 0.0001556774805067107 average time 0.06397881101650758 iter num 60\n",
            "loss 0.0021561835892498493 average time 0.05643182832853719 iter num 70\n",
            "loss 0.0004078363417647779 average time 0.050683121524980376 iter num 80\n",
            "loss 0.0006916812271811068 average time 0.046287341433303986 iter num 90\n",
            "loss 0.002945080865174532 average time 0.04269721662993106 iter num 100\n",
            "loss 0.0028184857219457626 average time 0.3303504515999521 iter num 10\n",
            "loss 0.0032617836259305477 average time 0.17045823925018339 iter num 20\n",
            "loss 8.625004556961358e-05 average time 0.11712499296700116 iter num 30\n",
            "loss 0.00013000759645365179 average time 0.09054849312524312 iter num 40\n",
            "loss 0.00031954224687069654 average time 0.07454099716000201 iter num 50\n",
            "loss 0.0002151057997252792 average time 0.06386571400010628 iter num 60\n",
            "loss 0.0016632963670417666 average time 0.056245243443014 iter num 70\n",
            "loss 0.00016721856081858277 average time 0.050558749450101456 iter num 80\n",
            "loss 0.00036523849121294916 average time 0.04608856865561393 iter num 90\n",
            "loss 0.01119664404541254 average time 0.042550827100058086 iter num 100\n",
            "loss 0.00020188785856589675 average time 0.33056255300034537 iter num 10\n",
            "loss 0.0004064291133545339 average time 0.1706934863499555 iter num 20\n",
            "loss 0.0003381134301889688 average time 0.11738793540013527 iter num 30\n",
            "loss 0.001694760168902576 average time 0.09067058450027617 iter num 40\n",
            "loss 0.00034352982765994966 average time 0.07462942654034123 iter num 50\n",
            "loss 0.0012624490773305297 average time 0.06395173788368994 iter num 60\n",
            "loss 0.001240894547663629 average time 0.056310605171737346 iter num 70\n",
            "loss 0.0005185927147977054 average time 0.050604751175251296 iter num 80\n",
            "loss 0.00023753324057906866 average time 0.046134068855826625 iter num 90\n",
            "loss 0.0002459390088915825 average time 0.042611580390257586 iter num 100\n",
            "loss 0.00029500946402549744 average time 0.3321242779005843 iter num 10\n",
            "loss 0.00043471393291838467 average time 0.17132111705013814 iter num 20\n",
            "loss 0.0017661586171016097 average time 0.11767941313325234 iter num 30\n",
            "loss 0.00017875149205792695 average time 0.09089198017481977 iter num 40\n",
            "loss 0.0006393905496224761 average time 0.07485042275991872 iter num 50\n",
            "loss 0.00028624251717701554 average time 0.06420900093319991 iter num 60\n",
            "loss 0.00014721654588356614 average time 0.05655473471410265 iter num 70\n",
            "loss 0.00031630718149244785 average time 0.05078689344982194 iter num 80\n",
            "loss 0.0002382033271715045 average time 0.04631912984421231 iter num 90\n",
            "loss 0.000523060851264745 average time 0.04272046922978916 iter num 100\n",
            "loss 0.0014623820316046476 average time 0.33043852290029463 iter num 10\n",
            "loss 0.0004945348482578993 average time 0.17052003415028594 iter num 20\n",
            "loss 0.0005738172912970185 average time 0.11727152286669783 iter num 30\n",
            "loss 0.00021299107174854726 average time 0.09059617492484903 iter num 40\n",
            "loss 0.00018490036018192768 average time 0.07463784623978427 iter num 50\n",
            "loss 0.00014545703015755862 average time 0.0640059324664738 iter num 60\n",
            "loss 0.002331815892830491 average time 0.05636637528561031 iter num 70\n",
            "loss 0.0009386891033500433 average time 0.05062899358740651 iter num 80\n",
            "loss 0.00035147747257724404 average time 0.04619482835551025 iter num 90\n",
            "loss 0.00020968442549929023 average time 0.042665974859955894 iter num 100\n",
            "loss 0.00038249584031291306 average time 0.3305240268997295 iter num 10\n",
            "loss 0.0004222704446874559 average time 0.17058121859972744 iter num 20\n",
            "loss 0.0002671517722774297 average time 0.11724056773309713 iter num 30\n",
            "loss 0.0002064432919723913 average time 0.09052916264990926 iter num 40\n",
            "loss 0.00017782852228265256 average time 0.07460649760003435 iter num 50\n",
            "loss 0.0005532221985049546 average time 0.06405417846666145 iter num 60\n",
            "loss 0.0003922356409020722 average time 0.05641238867143069 iter num 70\n",
            "loss 0.0012700160732492805 average time 0.050686559800124084 iter num 80\n",
            "loss 0.0004149188462179154 average time 0.04626004824458505 iter num 90\n",
            "loss 0.00042485876474529505 average time 0.04271779650007375 iter num 100\n",
            "loss 0.0017307440284639597 average time 0.3306671157995879 iter num 10\n",
            "loss 0.0003642754163593054 average time 0.17065886685013537 iter num 20\n",
            "loss 0.0004476038448046893 average time 0.11733410546682231 iter num 30\n",
            "loss 0.009702605195343494 average time 0.09067748132520137 iter num 40\n",
            "loss 0.000326840381603688 average time 0.07473260362014117 iter num 50\n",
            "loss 0.0002664572966750711 average time 0.06402106691687853 iter num 60\n",
            "loss 0.000832141493447125 average time 0.0563829800716381 iter num 70\n",
            "loss 0.00019558920757845044 average time 0.05063592617516406 iter num 80\n",
            "loss 0.002210692735388875 average time 0.04617426906681633 iter num 90\n",
            "loss 0.0007320289150811732 average time 0.04259619314019801 iter num 100\n",
            "loss 0.0004027394752483815 average time 0.3310436313993705 iter num 10\n",
            "loss 0.0008229787927120924 average time 0.17146752164953796 iter num 20\n",
            "loss 0.0004819873720407486 average time 0.11782284273310022 iter num 30\n",
            "loss 0.00017194949032273144 average time 0.09103245837486611 iter num 40\n",
            "loss 0.0006585629307664931 average time 0.07491197019997343 iter num 50\n",
            "loss 0.00042853568447753787 average time 0.06420748513319267 iter num 60\n",
            "loss 0.00023410169524140656 average time 0.056543725757053055 iter num 70\n",
            "loss 0.0003622653312049806 average time 0.05079284311250376 iter num 80\n",
            "loss 0.0027485608588904142 average time 0.04634037547778765 iter num 90\n",
            "loss 0.00013919509365223348 average time 0.04276253660998918 iter num 100\n",
            "loss 0.0004922967636957765 average time 0.33127189739971075 iter num 10\n",
            "loss 0.0006567490054294467 average time 0.1711212438498478 iter num 20\n",
            "loss 0.00028751580975949764 average time 0.11766451126677566 iter num 30\n",
            "loss 0.0001236348325619474 average time 0.09096248372516129 iter num 40\n",
            "loss 0.0006835506064817309 average time 0.07485812194034225 iter num 50\n",
            "loss 0.0005250500398688018 average time 0.06424364983370955 iter num 60\n",
            "loss 0.00011030962923541665 average time 0.05657187160042148 iter num 70\n",
            "loss 0.0003332410124130547 average time 0.050809913675311694 iter num 80\n",
            "loss 0.00019471380801405758 average time 0.046347818689133014 iter num 90\n",
            "loss 0.00013606564607471228 average time 0.042807161250239006 iter num 100\n",
            "loss 0.0001400304608978331 average time 0.3307866282008035 iter num 10\n",
            "loss 0.004497157875448465 average time 0.1711450954006068 iter num 20\n",
            "loss 0.0005788592388853431 average time 0.11766140470026584 iter num 30\n",
            "loss 0.0002559683925937861 average time 0.09094321032516746 iter num 40\n",
            "loss 0.00024328978906851262 average time 0.07487389736015757 iter num 50\n",
            "loss 0.004305229987949133 average time 0.0641838519833982 iter num 60\n",
            "loss 0.0004550907760858536 average time 0.05651045597145899 iter num 70\n",
            "loss 0.00026536243967711926 average time 0.05076748623750973 iter num 80\n",
            "loss 0.0002547907060943544 average time 0.04631778817783925 iter num 90\n",
            "loss 0.000394061062252149 average time 0.042753968730066844 iter num 100\n",
            "loss 0.00017022996325977147 average time 0.3315013182000257 iter num 10\n",
            "loss 0.0001713264937279746 average time 0.17110381150050671 iter num 20\n",
            "loss 0.0026967234443873167 average time 0.11760687516701486 iter num 30\n",
            "loss 0.0008004370611160994 average time 0.09091128460031542 iter num 40\n",
            "loss 0.0004519151116255671 average time 0.07492101866031589 iter num 50\n",
            "loss 0.0005322137731127441 average time 0.06426427631698364 iter num 60\n",
            "loss 0.0004366571956779808 average time 0.05662372002895739 iter num 70\n",
            "loss 0.0008780385833233595 average time 0.05087719796279089 iter num 80\n",
            "loss 0.00031428245711140335 average time 0.04641317736685677 iter num 90\n",
            "loss 0.00023752982087899 average time 0.04284666597020987 iter num 100\n",
            "loss 0.0007026068633422256 average time 0.3310759643001802 iter num 10\n",
            "loss 0.00020906358258798718 average time 0.170911553300175 iter num 20\n",
            "loss 0.00023739015159662813 average time 0.11753575926668418 iter num 30\n",
            "loss 0.0003327949671074748 average time 0.09086169574993619 iter num 40\n",
            "loss 0.00025149760767817497 average time 0.07481546348004485 iter num 50\n",
            "loss 0.0003234897740185261 average time 0.06414202198332836 iter num 60\n",
            "loss 0.000206267592147924 average time 0.05652587655713433 iter num 70\n",
            "loss 0.000337740610120818 average time 0.05079221431246879 iter num 80\n",
            "loss 0.00048688860260881484 average time 0.04634832445553912 iter num 90\n",
            "loss 0.0004688396875280887 average time 0.04282551021995459 iter num 100\n",
            "loss 0.000837618310470134 average time 0.33073618579983305 iter num 10\n",
            "loss 0.0008495697402395308 average time 0.1708845241504605 iter num 20\n",
            "loss 0.0002249549434054643 average time 0.11754154540030867 iter num 30\n",
            "loss 0.00027495247195474803 average time 0.09084844602521117 iter num 40\n",
            "loss 0.00046659712097607553 average time 0.07477706638019299 iter num 50\n",
            "loss 0.00038304508780129254 average time 0.06414855340020344 iter num 60\n",
            "loss 0.00024507628404535353 average time 0.05652018467158736 iter num 70\n",
            "loss 0.0006132506532594562 average time 0.05089665003756636 iter num 80\n",
            "loss 0.00017847974959295243 average time 0.04641122608898311 iter num 90\n",
            "loss 0.000863278575707227 average time 0.0428573759100982 iter num 100\n",
            "loss 0.00040492715197615325 average time 0.3311166716004664 iter num 10\n",
            "loss 0.0005237055011093616 average time 0.17089768660025584 iter num 20\n",
            "loss 0.0002805048425216228 average time 0.11748690623341342 iter num 30\n",
            "loss 0.00031658727675676346 average time 0.09096389637497851 iter num 40\n",
            "loss 0.0004516306216828525 average time 0.07489865725998243 iter num 50\n",
            "loss 0.000618233229033649 average time 0.06420770953330551 iter num 60\n",
            "loss 0.00026380131021142006 average time 0.05653855448571059 iter num 70\n",
            "loss 0.00020584491721820086 average time 0.05083019692497146 iter num 80\n",
            "loss 0.001172935706563294 average time 0.04637691567772385 iter num 90\n",
            "loss 0.0001794419513316825 average time 0.04285708334991796 iter num 100\n",
            "loss 0.0004882166103925556 average time 0.3311555360996863 iter num 10\n",
            "loss 0.00016250790213234723 average time 0.17090759069978959 iter num 20\n",
            "loss 0.0002936968521680683 average time 0.11755630640012289 iter num 30\n",
            "loss 0.0004999779630452394 average time 0.09086046175034426 iter num 40\n",
            "loss 0.0003813343355432153 average time 0.07491858782035705 iter num 50\n",
            "loss 0.00033733612508513033 average time 0.0643112229337324 iter num 60\n",
            "loss 0.00014184466272126883 average time 0.056732757986070026 iter num 70\n",
            "loss 0.0011858177604153752 average time 0.05099790940030289 iter num 80\n",
            "loss 0.0006369443144649267 average time 0.04652088242251517 iter num 90\n",
            "loss 0.00010001012560678646 average time 0.04293810299026518 iter num 100\n",
            "loss 0.00034220205270685256 average time 0.3315802485009044 iter num 10\n",
            "loss 0.0002514538646209985 average time 0.1711996423005985 iter num 20\n",
            "loss 0.0003045699268113822 average time 0.1177647723336122 iter num 30\n",
            "loss 0.0008699488244019449 average time 0.091022705125215 iter num 40\n",
            "loss 0.00023459944350179285 average time 0.07496167902012531 iter num 50\n",
            "loss 0.0012207794934511185 average time 0.06424269506672621 iter num 60\n",
            "loss 0.00018852477660402656 average time 0.0565967708716406 iter num 70\n",
            "loss 0.0003506464709062129 average time 0.05087377401268896 iter num 80\n",
            "loss 0.00037041687755845487 average time 0.04642535030009943 iter num 90\n",
            "loss 0.0004668465699069202 average time 0.042886938950068725 iter num 100\n",
            "loss 0.00013488199329003692 average time 0.3314634452992323 iter num 10\n",
            "loss 8.435054769506678e-05 average time 0.17123778549976124 iter num 20\n",
            "loss 0.00015739002265036106 average time 0.1177573618329916 iter num 30\n",
            "loss 0.0005044182762503624 average time 0.09103814749951197 iter num 40\n",
            "loss 0.00032851332798600197 average time 0.07500931189948461 iter num 50\n",
            "loss 0.00014903831470292062 average time 0.06431123804959497 iter num 60\n",
            "loss 0.0002598713035695255 average time 0.056644401171174 iter num 70\n",
            "loss 0.00018746005662251264 average time 0.05091157397482675 iter num 80\n",
            "loss 0.00025310023920610547 average time 0.04646208193318873 iter num 90\n",
            "loss 0.0003840209392365068 average time 0.042914687039847195 iter num 100\n",
            "loss 0.0015583925414830446 average time 0.33194167009969533 iter num 10\n",
            "loss 0.00020501029212027788 average time 0.17163936479992117 iter num 20\n",
            "loss 0.0005263729835860431 average time 0.11801325833330338 iter num 30\n",
            "loss 0.004175192676484585 average time 0.09113054819999888 iter num 40\n",
            "loss 0.0013073133304715157 average time 0.07500910811992072 iter num 50\n",
            "loss 0.0005021465476602316 average time 0.06426988736663285 iter num 60\n",
            "loss 0.00032083914265967906 average time 0.056590373442876235 iter num 70\n",
            "loss 0.0007542529492639005 average time 0.050866065937543684 iter num 80\n",
            "loss 0.00018513650866225362 average time 0.04640678298892453 iter num 90\n",
            "loss 0.0002313161821803078 average time 0.042874884659977394 iter num 100\n",
            "loss 0.00032332248520106077 average time 0.33070807500043886 iter num 10\n",
            "loss 0.00012415989476721734 average time 0.1706645115998981 iter num 20\n",
            "loss 0.0005134784150868654 average time 0.11730047706647989 iter num 30\n",
            "loss 0.0028656276408582926 average time 0.09061049532501783 iter num 40\n",
            "loss 0.00036420972901396453 average time 0.07470669686008477 iter num 50\n",
            "loss 0.00038849227712489665 average time 0.06408989840007659 iter num 60\n",
            "loss 0.00022594601614400744 average time 0.05651881851429477 iter num 70\n",
            "loss 0.0003795072843786329 average time 0.05085489149992099 iter num 80\n",
            "loss 0.0006655947072431445 average time 0.04641442534440204 iter num 90\n",
            "loss 0.00016523239901289344 average time 0.04285647225999128 iter num 100\n",
            "loss 0.0007493087905459106 average time 0.33086882030074777 iter num 10\n",
            "loss 0.0036530429497361183 average time 0.17084997320034745 iter num 20\n",
            "loss 0.00032424720120616257 average time 0.11772808686703987 iter num 30\n",
            "loss 0.0005734292790293694 average time 0.09098283717539743 iter num 40\n",
            "loss 0.00022765714675188065 average time 0.07491037354026048 iter num 50\n",
            "loss 0.0003274658229202032 average time 0.0643081341836781 iter num 60\n",
            "loss 0.0020535881631076336 average time 0.05669258374322713 iter num 70\n",
            "loss 0.00034011562820523977 average time 0.050948281687851704 iter num 80\n",
            "loss 0.0003163660585414618 average time 0.04651635220030181 iter num 90\n",
            "loss 0.0004007642564829439 average time 0.04299164718024258 iter num 100\n",
            "loss 0.0004318700812291354 average time 0.33131685899970764 iter num 10\n",
            "loss 0.0005198112921789289 average time 0.17101828614995612 iter num 20\n",
            "loss 0.00022291005006991327 average time 0.11757063260023036 iter num 30\n",
            "loss 0.00032887194538488984 average time 0.09087419777506511 iter num 40\n",
            "loss 0.00013039300392847508 average time 0.07483772308005428 iter num 50\n",
            "loss 0.0005197690916247666 average time 0.06419735793345656 iter num 60\n",
            "loss 0.00011990957136731595 average time 0.05660530032868597 iter num 70\n",
            "loss 0.0002205364580731839 average time 0.05086262935014929 iter num 80\n",
            "loss 0.00025370350340381265 average time 0.046427368022341396 iter num 90\n",
            "loss 0.0003096237778663635 average time 0.042876416740073184 iter num 100\n",
            "loss 0.0006681897211819887 average time 0.3314014911004051 iter num 10\n",
            "loss 0.00036480711423791945 average time 0.1710784376504307 iter num 20\n",
            "loss 0.0008880866225808859 average time 0.11756461396726081 iter num 30\n",
            "loss 0.0002608566137496382 average time 0.09096651847548856 iter num 40\n",
            "loss 0.007189497817307711 average time 0.0749034248404496 iter num 50\n",
            "loss 0.0004536491760518402 average time 0.0642120334670229 iter num 60\n",
            "loss 0.00033750382135622203 average time 0.056546142043069784 iter num 70\n",
            "loss 0.0002060658880509436 average time 0.05083328155010349 iter num 80\n",
            "loss 0.0004164951096754521 average time 0.04637517862231309 iter num 90\n",
            "loss 0.0003265531559009105 average time 0.042786468590056755 iter num 100\n",
            "loss 0.00014803436351940036 average time 0.33172735900006955 iter num 10\n",
            "loss 0.0005593139794655144 average time 0.17113713970011304 iter num 20\n",
            "loss 8.509276813128963e-05 average time 0.11768417483326629 iter num 30\n",
            "loss 0.0004425709485076368 average time 0.09092108967497552 iter num 40\n",
            "loss 0.000605348264798522 average time 0.07487566362004144 iter num 50\n",
            "loss 0.00020153293735347688 average time 0.06414699661666722 iter num 60\n",
            "loss 0.00034612821764312685 average time 0.056505137314213374 iter num 70\n",
            "loss 0.0003068164805881679 average time 0.05076174922487553 iter num 80\n",
            "loss 0.0016027465462684631 average time 0.046310946599906956 iter num 90\n",
            "loss 0.00031636585481464863 average time 0.0427409928400084 iter num 100\n",
            "loss 0.00020971480989828706 average time 0.3306951739003125 iter num 10\n",
            "loss 0.000380790006602183 average time 0.1709892263999791 iter num 20\n",
            "loss 0.0001728006318444386 average time 0.11756594636644876 iter num 30\n",
            "loss 0.00196970347315073 average time 0.09078728224985752 iter num 40\n",
            "loss 0.009955055080354214 average time 0.07473674169974402 iter num 50\n",
            "loss 0.00032190841739065945 average time 0.06411164668315905 iter num 60\n",
            "loss 0.00028910464607179165 average time 0.0564741858427234 iter num 70\n",
            "loss 0.0005489920149557292 average time 0.050754889637300946 iter num 80\n",
            "loss 0.0001052346924552694 average time 0.0462937507666033 iter num 90\n",
            "loss 0.0006254086620174348 average time 0.04276985759999661 iter num 100\n",
            "loss 0.00016471736307721585 average time 0.33099023290051266 iter num 10\n",
            "loss 0.00018736234051175416 average time 0.170937953250359 iter num 20\n",
            "loss 0.00027116542332805693 average time 0.11742668003353174 iter num 30\n",
            "loss 0.000137739596539177 average time 0.09067664250014787 iter num 40\n",
            "loss 0.00015232310397550464 average time 0.07472937204023765 iter num 50\n",
            "loss 0.0006864216993562877 average time 0.06403353561684828 iter num 60\n",
            "loss 0.0003074132837355137 average time 0.05642731121442921 iter num 70\n",
            "loss 0.00027465360471978784 average time 0.050685699187715726 iter num 80\n",
            "loss 0.0023030296433717012 average time 0.046223797266833976 iter num 90\n",
            "loss 0.000367051106877625 average time 0.04267962466019526 iter num 100\n",
            "loss 9.918953583110124e-05 average time 0.3302440659004787 iter num 10\n",
            "loss 0.0003628018603194505 average time 0.17051000550000026 iter num 20\n",
            "loss 0.00011086109589086846 average time 0.11715221589996266 iter num 30\n",
            "loss 0.0002260106266476214 average time 0.09044142299999294 iter num 40\n",
            "loss 0.0005039116949774325 average time 0.07458157004002715 iter num 50\n",
            "loss 0.001020202413201332 average time 0.06389968045004935 iter num 60\n",
            "loss 0.00041435883031226695 average time 0.05629082064302306 iter num 70\n",
            "loss 0.00017142793512903154 average time 0.05056059086264213 iter num 80\n",
            "loss 0.0001348776713712141 average time 0.04612953115570741 iter num 90\n",
            "loss 0.0005208639777265489 average time 0.04259020395020343 iter num 100\n",
            "loss 0.00046433586976490915 average time 0.330632024699662 iter num 10\n",
            "loss 9.053435496753082e-05 average time 0.17066803779998735 iter num 20\n",
            "loss 0.0003634312597569078 average time 0.11732264493366529 iter num 30\n",
            "loss 6.617591861868277e-05 average time 0.09070155135004825 iter num 40\n",
            "loss 0.00023762402997817844 average time 0.07465404612004932 iter num 50\n",
            "loss 0.00019485160009935498 average time 0.06400989436685146 iter num 60\n",
            "loss 0.00021837229724042118 average time 0.05640656115740837 iter num 70\n",
            "loss 0.00014353881124407053 average time 0.05066406641276444 iter num 80\n",
            "loss 0.001943822717294097 average time 0.04620515114466899 iter num 90\n",
            "loss 0.00015431700740009546 average time 0.042635964060209516 iter num 100\n",
            "loss 0.0001515831536380574 average time 0.3308443343008548 iter num 10\n",
            "loss 0.0012986983638256788 average time 0.17067211020039394 iter num 20\n",
            "loss 0.0020800279453396797 average time 0.11728947636705318 iter num 30\n",
            "loss 0.00017801289504859596 average time 0.09063023035032529 iter num 40\n",
            "loss 0.0002278931497130543 average time 0.07459460578022117 iter num 50\n",
            "loss 0.00027241065981797874 average time 0.06390891156679572 iter num 60\n",
            "loss 0.00026751437690109015 average time 0.05630982641430039 iter num 70\n",
            "loss 0.00017664926417637616 average time 0.05059063317507935 iter num 80\n",
            "loss 0.00020856854098383337 average time 0.046137715688908225 iter num 90\n",
            "loss 0.0004964367253705859 average time 0.04258036426002945 iter num 100\n",
            "loss 0.00012433005031198263 average time 0.3308980427998904 iter num 10\n",
            "loss 0.0002240302274003625 average time 0.17093641514984484 iter num 20\n",
            "loss 0.00015367350715678185 average time 0.1174318928332165 iter num 30\n",
            "loss 0.0013848042581230402 average time 0.09067457567516612 iter num 40\n",
            "loss 0.0002634334668982774 average time 0.07463707176015305 iter num 50\n",
            "loss 6.380332342814654e-05 average time 0.06399431361672517 iter num 60\n",
            "loss 0.00014727706729900092 average time 0.05636588597148407 iter num 70\n",
            "loss 0.0001614256325410679 average time 0.050637078362433384 iter num 80\n",
            "loss 0.004610962234437466 average time 0.04619695006670857 iter num 90\n",
            "loss 0.00031677086371928453 average time 0.042635547730023975 iter num 100\n",
            "loss 0.00019331400108058006 average time 0.3308634209999582 iter num 10\n",
            "loss 0.00015433429507538676 average time 0.17068926640022256 iter num 20\n",
            "loss 0.0004432203422766179 average time 0.11732407700025457 iter num 30\n",
            "loss 0.0003938644949812442 average time 0.09065836097515785 iter num 40\n",
            "loss 0.00040713284397497773 average time 0.07466069893998792 iter num 50\n",
            "loss 0.00021235192252788693 average time 0.06404208405007618 iter num 60\n",
            "loss 0.0007074088207446039 average time 0.05641450975719116 iter num 70\n",
            "loss 0.0005066235898993909 average time 0.05068399125002543 iter num 80\n",
            "loss 0.00027941478765569627 average time 0.04624712702215119 iter num 90\n",
            "loss 0.00024093753017950803 average time 0.04268355805997999 iter num 100\n",
            "loss 0.00032758491579443216 average time 0.3304511324997293 iter num 10\n",
            "loss 0.00010262261639581993 average time 0.17063219205010682 iter num 20\n",
            "loss 0.0002743217337410897 average time 0.11734678093368227 iter num 30\n",
            "loss 0.0004193433851469308 average time 0.09066457745029766 iter num 40\n",
            "loss 0.0006767334416508675 average time 0.07462343422026606 iter num 50\n",
            "loss 0.00010473825386725366 average time 0.06394589785019586 iter num 60\n",
            "loss 0.0002292267163284123 average time 0.0563310217002124 iter num 70\n",
            "loss 0.00018563361663836986 average time 0.050623727775200675 iter num 80\n",
            "loss 0.00026373477885499597 average time 0.046159185811241815 iter num 90\n",
            "loss 0.00023764118668623269 average time 0.042589483050105625 iter num 100\n",
            "loss 0.00042838536319322884 average time 0.3305640107999352 iter num 10\n",
            "loss 0.0002080761332763359 average time 0.17049504984988745 iter num 20\n",
            "loss 0.0012340863468125463 average time 0.11719321416652141 iter num 30\n",
            "loss 0.00034827718627639115 average time 0.09052342364993819 iter num 40\n",
            "loss 0.00020976980158593506 average time 0.07457648152005276 iter num 50\n",
            "loss 0.0002807114797178656 average time 0.06393477793323352 iter num 60\n",
            "loss 8.891156176105142e-05 average time 0.056283260471328894 iter num 70\n",
            "loss 0.0001645539450692013 average time 0.05056906654986051 iter num 80\n",
            "loss 0.00010387616930529475 average time 0.04612155354435446 iter num 90\n",
            "loss 0.00041528468136675656 average time 0.04257600740995258 iter num 100\n",
            "loss 0.00019646687724161893 average time 0.3304147737999301 iter num 10\n",
            "loss 0.0004846816009376198 average time 0.1704411386001084 iter num 20\n",
            "loss 0.0003611156134866178 average time 0.11708528723344595 iter num 30\n",
            "loss 8.566475298721343e-05 average time 0.09050752242492308 iter num 40\n",
            "loss 0.00015145978250075132 average time 0.07452422834001482 iter num 50\n",
            "loss 0.0003741088730748743 average time 0.06387532703326239 iter num 60\n",
            "loss 5.380914808483794e-05 average time 0.05625930489986786 iter num 70\n",
            "loss 2.7312475140206516e-05 average time 0.05053981308738002 iter num 80\n",
            "loss 0.00029845660901628435 average time 0.04609495413319059 iter num 90\n",
            "loss 0.00010264915181323886 average time 0.04253690497986099 iter num 100\n",
            "loss 0.00039320066571235657 average time 0.33088251260014656 iter num 10\n",
            "loss 0.00040758593240752816 average time 0.17066904260009325 iter num 20\n",
            "loss 0.00017101089179050177 average time 0.11732291036666236 iter num 30\n",
            "loss 0.00033966285991482437 average time 0.09062294532495799 iter num 40\n",
            "loss 0.0002617892751004547 average time 0.07459086609967926 iter num 50\n",
            "loss 0.000497009779792279 average time 0.06390791016638105 iter num 60\n",
            "loss 0.0002439627714920789 average time 0.05629329294268765 iter num 70\n",
            "loss 0.00023069178860168904 average time 0.05055853252483757 iter num 80\n",
            "loss 0.00022367680503521115 average time 0.04610554088871544 iter num 90\n",
            "loss 0.0001268384512513876 average time 0.042561665049906876 iter num 100\n",
            "loss 0.00017472448234912008 average time 0.3310602901005041 iter num 10\n",
            "loss 0.0003133921418339014 average time 0.17082529595008963 iter num 20\n",
            "loss 0.00024422755814157426 average time 0.11738148436682726 iter num 30\n",
            "loss 0.00021390497568063438 average time 0.09066059445040082 iter num 40\n",
            "loss 0.0015254562022164464 average time 0.07464501362024749 iter num 50\n",
            "loss 7.930251740617678e-05 average time 0.06394647016677482 iter num 60\n",
            "loss 0.0002595555270090699 average time 0.05632571411437571 iter num 70\n",
            "loss 0.00020791224960703403 average time 0.05058674056267591 iter num 80\n",
            "loss 0.00034004618646577 average time 0.04616166753350828 iter num 90\n",
            "loss 0.00012115637946408242 average time 0.04258424581017607 iter num 100\n",
            "loss 0.0003628329432103783 average time 0.33073930620012104 iter num 10\n",
            "loss 0.0002440000098431483 average time 0.17077012960016874 iter num 20\n",
            "loss 0.0007035968010313809 average time 0.11732213410020147 iter num 30\n",
            "loss 0.00020269924425520003 average time 0.09066331050034933 iter num 40\n",
            "loss 0.00020670548838097602 average time 0.07464349712012336 iter num 50\n",
            "loss 0.0003015214460901916 average time 0.06395328688334606 iter num 60\n",
            "loss 0.0001780438469722867 average time 0.05635630228566047 iter num 70\n",
            "loss 0.0003172948199789971 average time 0.050647096462262196 iter num 80\n",
            "loss 0.0007340600132010877 average time 0.04631233875544341 iter num 90\n",
            "loss 0.001014259527437389 average time 0.042771196029971176 iter num 100\n",
            "loss 0.00030747026903554797 average time 0.33074690739995277 iter num 10\n",
            "loss 0.0001241506397491321 average time 0.17065707890014892 iter num 20\n",
            "loss 0.00018257689953316003 average time 0.11728900320013054 iter num 30\n",
            "loss 0.0001391390396747738 average time 0.09061888269998235 iter num 40\n",
            "loss 0.0004930574796162546 average time 0.07463046223994751 iter num 50\n",
            "loss 0.0005518302787095308 average time 0.06393137919985747 iter num 60\n",
            "loss 0.00046540104085579515 average time 0.05634656825703652 iter num 70\n",
            "loss 0.00017899434897117317 average time 0.050628415150004005 iter num 80\n",
            "loss 0.00029639259446412325 average time 0.04617016986663253 iter num 90\n",
            "loss 0.0022364978212863207 average time 0.042610316039936154 iter num 100\n",
            "loss 0.0006751534529030323 average time 0.3306922140003735 iter num 10\n",
            "loss 0.00010113364987773821 average time 0.17063723115043103 iter num 20\n",
            "loss 0.00021955309784971178 average time 0.11727720750022855 iter num 30\n",
            "loss 0.00013483723159879446 average time 0.0907093393751893 iter num 40\n",
            "loss 0.0002260244364151731 average time 0.07470830818012474 iter num 50\n",
            "loss 0.00025983559316955507 average time 0.06402379471674066 iter num 60\n",
            "loss 0.0002700525219552219 average time 0.056367697999927 iter num 70\n",
            "loss 0.00040595250902697444 average time 0.050628045137364096 iter num 80\n",
            "loss 0.0006473383400589228 average time 0.04619010185540699 iter num 90\n",
            "loss 0.0003169483388774097 average time 0.042653360209842506 iter num 100\n",
            "loss 0.0002891025796998292 average time 0.3312873482998839 iter num 10\n",
            "loss 0.00180839654058218 average time 0.17089371264955844 iter num 20\n",
            "loss 0.0005281858611851931 average time 0.11745297639960578 iter num 30\n",
            "loss 0.00037345930468291044 average time 0.09071331867471599 iter num 40\n",
            "loss 0.0006968614179641008 average time 0.07499242725978547 iter num 50\n",
            "loss 0.0002443300618324429 average time 0.06440497801656117 iter num 60\n",
            "loss 0.0005225982167758048 average time 0.056775147885543574 iter num 70\n",
            "loss 0.00011792071018135175 average time 0.05100369846245485 iter num 80\n",
            "loss 0.00040418640128336847 average time 0.046516754088952436 iter num 90\n",
            "loss 0.00031849934021010995 average time 0.042911518200053254 iter num 100\n",
            "loss 0.000559252395760268 average time 0.3312743424994551 iter num 10\n",
            "loss 5.803095700684935e-05 average time 0.1708730154496152 iter num 20\n",
            "loss 0.00021304114488884807 average time 0.11744539626658176 iter num 30\n",
            "loss 0.0005025345017202199 average time 0.09072146599992266 iter num 40\n",
            "loss 0.00014720438048243523 average time 0.0746892422199744 iter num 50\n",
            "loss 0.0002708389947656542 average time 0.06399584443333879 iter num 60\n",
            "loss 0.0016298620030283928 average time 0.05636185374288678 iter num 70\n",
            "loss 8.635631820652634e-05 average time 0.05068764492502851 iter num 80\n",
            "loss 0.00023059692466631532 average time 0.046234268711203994 iter num 90\n",
            "loss 0.00046028997167013586 average time 0.04267017625006701 iter num 100\n",
            "loss 0.00011642871686490253 average time 0.3311579515997437 iter num 10\n",
            "loss 0.00046381037100218236 average time 0.17096994654930314 iter num 20\n",
            "loss 0.0005229751695878804 average time 0.11761830406612717 iter num 30\n",
            "loss 0.00013818965817335993 average time 0.09090750547438801 iter num 40\n",
            "loss 0.001188578549772501 average time 0.07486601587967016 iter num 50\n",
            "loss 0.00012432133371476084 average time 0.06417725584979053 iter num 60\n",
            "loss 0.0001188242167700082 average time 0.05651707359980459 iter num 70\n",
            "loss 0.0005092074279673398 average time 0.050785762949817584 iter num 80\n",
            "loss 0.00019601501116994768 average time 0.04636234232198654 iter num 90\n",
            "loss 0.0001807097578421235 average time 0.04285028099977353 iter num 100\n",
            "loss 0.0005007214494980872 average time 0.3309279715998855 iter num 10\n",
            "loss 0.00026898193755187094 average time 0.17100846604989783 iter num 20\n",
            "loss 0.0007933816523291171 average time 0.11756776820014542 iter num 30\n",
            "loss 0.00106869509909302 average time 0.09087909632489755 iter num 40\n",
            "loss 0.00045684902579523623 average time 0.07482702306006103 iter num 50\n",
            "loss 0.00024058049893938005 average time 0.06420194036654721 iter num 60\n",
            "loss 0.0005244247731752694 average time 0.05657639082855894 iter num 70\n",
            "loss 0.00032829769770614803 average time 0.05083261478748682 iter num 80\n",
            "loss 0.0015868843765929341 average time 0.046375822255666006 iter num 90\n",
            "loss 0.000276418577414006 average time 0.042843305540300206 iter num 100\n",
            "loss 0.00028160744113847613 average time 0.3307667515007779 iter num 10\n",
            "loss 0.00021659267076756805 average time 0.17070672905065293 iter num 20\n",
            "loss 0.002886819886043668 average time 0.11739541870022853 iter num 30\n",
            "loss 0.00014682604523841292 average time 0.09079621559994848 iter num 40\n",
            "loss 0.00029065285343676805 average time 0.0747523353199358 iter num 50\n",
            "loss 0.00019590320880524814 average time 0.06412691768321868 iter num 60\n",
            "loss 0.00014860379451420158 average time 0.05656260197148575 iter num 70\n",
            "loss 0.00013218382082413882 average time 0.050803681475099435 iter num 80\n",
            "loss 0.00027367513393983245 average time 0.04633947530011129 iter num 90\n",
            "loss 0.000180060975253582 average time 0.042774599170152215 iter num 100\n",
            "loss 0.0003353912616148591 average time 0.33134840079874267 iter num 10\n",
            "loss 0.0005373413441702724 average time 0.17107987474773836 iter num 20\n",
            "loss 0.0002328684931853786 average time 0.11767575313157673 iter num 30\n",
            "loss 0.0005441943649202585 average time 0.09090755809793336 iter num 40\n",
            "loss 0.0004621528787538409 average time 0.07485058847814799 iter num 50\n",
            "loss 0.00011094594083260745 average time 0.06411308641484842 iter num 60\n",
            "loss 0.00020546278392430395 average time 0.05646905561245928 iter num 70\n",
            "loss 0.0002140867873094976 average time 0.05076100282331027 iter num 80\n",
            "loss 0.00019963894737884402 average time 0.046290136154291554 iter num 90\n",
            "loss 0.00021952035604044795 average time 0.04282557412887399 iter num 100\n",
            "loss 0.0003305423306301236 average time 0.3315573731000768 iter num 10\n",
            "loss 0.000411750195780769 average time 0.1710552791995724 iter num 20\n",
            "loss 0.00031657348154112697 average time 0.11755265016666575 iter num 30\n",
            "loss 0.0001070100988727063 average time 0.0908051103751859 iter num 40\n",
            "loss 0.0005888491868972778 average time 0.07473761254004785 iter num 50\n",
            "loss 0.00024084615870378911 average time 0.06403645928318534 iter num 60\n",
            "loss 0.00015424414596054703 average time 0.056400772256893106 iter num 70\n",
            "loss 0.00026486036949791014 average time 0.05071006579983077 iter num 80\n",
            "loss 0.0002214355336036533 average time 0.0463134495888274 iter num 90\n",
            "loss 0.0003535259747877717 average time 0.042723037229807234 iter num 100\n",
            "loss 0.0001737696147756651 average time 0.3309288639000442 iter num 10\n",
            "loss 0.00013438917812891304 average time 0.17079370360079338 iter num 20\n",
            "loss 0.0003270758024882525 average time 0.1174383056005657 iter num 30\n",
            "loss 0.0004854169092141092 average time 0.09075338960046793 iter num 40\n",
            "loss 0.0019094798481091857 average time 0.07484381702030078 iter num 50\n",
            "loss 8.437707583652809e-05 average time 0.06414208490023157 iter num 60\n",
            "loss 7.056233152979985e-05 average time 0.056617799185707036 iter num 70\n",
            "loss 0.0001968669384950772 average time 0.050859138025043646 iter num 80\n",
            "loss 0.00014857992937322706 average time 0.04639849607798775 iter num 90\n",
            "loss 0.0001985997660085559 average time 0.042818628570166765 iter num 100\n",
            "loss 0.010810312815010548 average time 0.3314015072020993 iter num 10\n",
            "loss 0.0005658170557580888 average time 0.1709700823012099 iter num 20\n",
            "loss 0.0005238282028585672 average time 0.11778924123427714 iter num 30\n",
            "loss 0.00022450032702181488 average time 0.09094772475091303 iter num 40\n",
            "loss 7.516297046095133e-05 average time 0.07487926456087735 iter num 50\n",
            "loss 0.00020412495359778404 average time 0.06415957588421103 iter num 60\n",
            "loss 0.00044413760770112276 average time 0.05651929428640869 iter num 70\n",
            "loss 0.00044762142351828516 average time 0.05080043323823702 iter num 80\n",
            "loss 0.00013933378795627505 average time 0.046329198433927056 iter num 90\n",
            "loss 0.0006196862086653709 average time 0.04275034588048584 iter num 100\n",
            "loss 0.00020546597079373896 average time 0.3309552889993938 iter num 10\n",
            "loss 0.00017476305947639048 average time 0.17080747975014673 iter num 20\n",
            "loss 0.00026785311638377607 average time 0.11739855350048553 iter num 30\n",
            "loss 0.00033116532722488046 average time 0.0907153887252207 iter num 40\n",
            "loss 0.000238983950112015 average time 0.07480809230022714 iter num 50\n",
            "loss 0.0003774582000914961 average time 0.06424309701687889 iter num 60\n",
            "loss 0.00016087516269180924 average time 0.05656889825757909 iter num 70\n",
            "loss 0.0006307193543761969 average time 0.05081885853787753 iter num 80\n",
            "loss 0.00018053737585432827 average time 0.046357823100293495 iter num 90\n",
            "loss 0.0002667545631993562 average time 0.0427924479702051 iter num 100\n",
            "loss 0.0003293676709290594 average time 0.3309842172995559 iter num 10\n",
            "loss 0.00023378546757157892 average time 0.17108055974968012 iter num 20\n",
            "loss 7.50409672036767e-05 average time 0.1176588905332513 iter num 30\n",
            "loss 8.693696145201102e-05 average time 0.0909310114746404 iter num 40\n",
            "loss 0.00037816265830770135 average time 0.07482178503967589 iter num 50\n",
            "loss 0.0004403744824230671 average time 0.06412126809967351 iter num 60\n",
            "loss 0.00022191170137375593 average time 0.056489044171134345 iter num 70\n",
            "loss 0.00022771554358769208 average time 0.05078742243722445 iter num 80\n",
            "loss 0.00028323009610176086 average time 0.04631975582184775 iter num 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-0acd40c8c302>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mmodel_save_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'jax_european_1stock_pricedelta_grid_1.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m           \u001b[0;31m################################################################################################### store input and output numbers in X and Y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m           \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEuropean_Call_price\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m           \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDeltas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# remember to change this!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.__setitem__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_routines_indexing.pyx\u001b[0m in \u001b[0;36mcupy._core._routines_indexing._ndarray_setitem\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/_routines_indexing.pyx\u001b[0m in \u001b[0;36mcupy._core._routines_indexing._scatter_op\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mcupy/_core/core.pyx\u001b[0m in \u001b[0;36mcupy._core.core.ndarray.fill\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_forward_method\u001b[0;34m(attrname, self, fun, *args)\u001b[0m\n\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_forward_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattrname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1144\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0m_forward_to_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_forward_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_value\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdb3e3fb-9d65-4084-a67f-663af3e25c90"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 1, 1, 0.25, 0.3, 0.3]]).cuda() # T, K, S, sigma, mu, r\n",
        "print('price: ' + str(model(inputs.float())))\n",
        "\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient[0][[2]]\n",
        "\n",
        "# price, delta\n",
        "# should be around (0.27130044, 0.90763223)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: tensor([[0.2692]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9062], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_2AXrPt7bNj",
        "outputId": "8d907b12-c273-45e7-9158-0e92eb4a37df"
      },
      "source": [
        "numstocks = 1\n",
        "numsteps = 50\n",
        "numpaths = 1000000\n",
        "\n",
        "rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.3]*numstocks)\n",
        "r = drift\n",
        "cov = jnp.identity(numstocks)*0.25*0.25\n",
        "initial_stocks = jnp.array([1.0]*numstocks) # must be float\n",
        "T = 1.0\n",
        "K = 1.0\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "\n",
        "# delta test\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.27095357\n",
            "[0.90713716]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "lovJwXo3-YEu",
        "outputId": "357bcdb6-d66b-4212-a980-4dc62aee3695"
      },
      "source": [
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "\n",
        "def compute_price(S):\n",
        "    inputs = torch.tensor([[1, 1, S, 0.25, 0.3, 0.3]]).cuda()\n",
        "    return model(inputs.float())\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_prices = []\n",
        "BS_call_prices = []\n",
        "for p in prices:\n",
        "    model_call_prices.append(compute_price(p).item())\n",
        "    BS_call_prices.append(bs_call(p, 1, 1, 0.3, 0.25))\n",
        "\n",
        "#plt.plot(prices, model_call_prices, label = \"model_call_prices\")\n",
        "#plt.plot(prices, BS_call_prices, label = \"BS_call_prices\")\n",
        "plt.plot(prices, np.array(model_call_prices)-np.array(BS_call_prices), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "lwApH0GT9bBK",
        "outputId": "30c17709-7d11-4531-cef3-962df1d2d836"
      },
      "source": [
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, S, 0.25, 0.3, 0.3]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 1, 1, 0.3, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "uaFXDgd4LRoU",
        "outputId": "64647274-a393-4f82-fd5d-675df80d6e5c"
      },
      "source": [
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 0.75, S, 0.25, 0.3, 0.3]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 0.75, 1, 0.3, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Y17ZjgTJLdIP",
        "outputId": "6c4ff6c9-f094-44d9-d376-fa901e61349a"
      },
      "source": [
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1.25, S, 0.25, 0.3, 0.3]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 1.25, 1, 0.3, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deVxU9f7H8deXRVFxBVwBQcUFFZdw33HX1NJyTU0tu92sbt26v/b8de3abbndSrPMXHPLrTRNzdDc0AC33EUEARcQVET2me/vjyF/ZCqjDpyZ4fN8PHo8mJnDzPuIvjt8z/d8j9JaI4QQwvG5GB1ACCGEbUihCyGEk5BCF0IIJyGFLoQQTkIKXQghnISbUR/s7e2tAwICjPp4IYRwSNHR0Ze01j63es2wQg8ICCAqKsqojxdCCIeklIq/3Wsy5CKEEE5CCl0IIZyEFLoQQjgJw8bQbyUvL4/ExESys7ONjiJKgIeHB76+vri7uxsdRQinYFeFnpiYSMWKFQkICEApZXQcUYy01qSmppKYmEhgYKDRcYRwCnY15JKdnY2Xl5eUeSmglMLLy0t+GxPChuyq0AEp81JEftZC2JbdFboQQjir0ykZfPzTSU5cuFYs729XY+hCCOFszl/N4oeD5/n+YBKHk9JRCrwrlqVRzYo2/yw5Qi9GAQEBXLp06b63sdb8+fOZMmUKAFOnTuXDDz+06vvi4uJo1qyZ1dscOHCADRs23F9YIZzY1cw8luw9y4gvI+j4XjjvbjiGq1K8MbAJe17tydj2dYvlc+UIXdy1AwcOEBUVxYABA4yOIoTdMJk1u2IusSI6kU1HLpCbb6a+TwVe6NWQwS1qE+BdodgzWFXoSql+wCeAKzBHa/3eTa/XBeYCPkAa8JjWOvF+gv3vuiMcPZd+P2/xJ8G1K/H2oKZ33CYuLo5+/frRvn17du/eTZs2bZgwYQJvv/02ycnJLF68mAYNGjBx4kRiY2MpX748s2fPJiQkhNTUVEaNGkVSUhIdOnSg8O39vvnmGz799FNyc3Np164dn3/+Oa6urkVmXrhwIR9++CFKKUJCQli0aBHr1q1j2rRp5Obm4uXlxeLFi6lRo8Zd/VlER0czceJEAPr06XPjeZPJxCuvvMK2bdvIycnhmWee4amnnrrxem5uLm+99RZZWVns3LmTV199lcDAQJ5//nmys7MpV64c8+bNo1GjRhw5coQJEyaQm5uL2Wxm1apVBAUF3VVOIexd3KXrrIxOZNW+RM5fzaZKeXdGtfHj0VA/mtauVKIn/4ssdKWUKzAT6A0kApFKqbVa66OFNvsQWKi1XqCUCgOmA2OLI3BJiImJYcWKFcydO5c2bdqwZMkSdu7cydq1a/nXv/6Fn58frVq14rvvviM8PJxx48Zx4MAB/vd//5fOnTvz1ltvsX79er7++msAjh07xvLly9m1axfu7u789a9/ZfHixYwbN+6OOY4cOcK0adPYvXs33t7epKWlAdC5c2f27NmDUoo5c+bw/vvv89FHH93VPk6YMIEZM2bQtWtXXn755RvPf/3111SuXJnIyEhycnLo1KkTffr0ufGXskyZMrzzzjtERUUxY8YMANLT09mxYwdubm5s2bKF1157jVWrVvHFF1/w/PPPM2bMGHJzczGZTHeVUQh7lZNvYuPhCyz99Sx7YtNwUdC1oQ9vDAymV3B1yrrd5mAtOx3idkLNZlDF3+a5rDlCbwvEaK1jAZRSy4AhQOFCDwZeLPh6K/Dd/QYr6ki6OAUGBtK8eXMAmjZtSs+ePVFK0bx5c+Li4oiPj2fVqlUAhIWFkZqaSnp6Otu3b2f16tUADBw4kKpVqwLw888/Ex0dTZs2bQDIysqievXqReYIDw/n0UcfxdvbG4Bq1aoBlguwRowYwfnz58nNzb3rC3OuXLnClStX6Nq1KwBjx47lxx9/BGDz5s0cOnSIlStXAnD16lVOnTpFw4YNb/t+V69eZfz48Zw6dQqlFHl5eQB06NCBd999l8TERIYOHSpH58LhnU7JYOnes6zal8jlzDz8q5Xn5b6NGNbal5qVPf78Dfm5kBQFsdss/yVGgTZBn2nQ8Vmb57Om0OsACYUeJwLtbtrmIDAUy7DMw0BFpZSX1jq18EZKqcnAZAB/f9v/38lWypYte+NrFxeXG49dXFzIz8+/60vVtdaMHz+e6dOn2yTfs88+y4svvsjgwYPZtm0bU6dOtcn7giXrZ599Rt++ff/wfFxc3G2/580336RHjx6sWbOGuLg4unfvDsDo0aNp164d69evZ8CAAXz55ZeEhYXZLKsQJSE338zGIxdYvCeevWfScHNR9Glag1Ft/elU3xsXl0JDKlpDagzE/Aynf4a4XZB3HZQL1G4NnV+Aet3Br22xZLXVLJeXgG5Kqf1ANyAJ+NPv11rr2VrrUK11qI/PLddndwhdunRh8eLFAGzbtg1vb28qVapE165dWbJkCQA//vgjly9fBqBnz56sXLmS5ORkANLS0oiPv+2SxjeEhYWxYsUKUlNTb3wfWI6I69SpA8CCBQvuOn+VKlWoUqUKO3fuBLixLwB9+/Zl1qxZN46yT548yfXr1//w/RUrVuTatf+fR1s4z/z58288HxsbS7169XjuuecYMmQIhw4duuusQhjlwtVs/rP5BB3fC+e5pfs5dzWLf/RrxO5Xw/h8zAN0CfKxlHl2Ohz7Adb9DT4JgRmhsPF/IPU0tBwNIxbDP87Akz9DzzchsAu4lS06wD2w5gg9CfAr9Ni34LkbtNbnsByho5TyBIZpra/YKqS9mTp1KhMnTiQkJITy5cvfKNW3336bUaNG0bRpUzp27Hjjt5Dg4GCmTZtGnz59MJvNuLu7M3PmTOrWvfPUpaZNm/L666/TrVs3XF1dadWqFfPnz2fq1Kk8+uijVK1albCwMM6cOXPX+zBv3jwmTpyIUuoPJ0WfeOIJ4uLiaN26NVprfHx8+O67P46g9ejRg/fee4+WLVvy6quv8o9//IPx48czbdo0Bg4ceGO7b7/9lkWLFuHu7k7NmjV57bXX7jqnECVJa82e2DQW7Ylj05GLmLWmR6PqjO1Ql26/F7jWkHICTm6CU5vhbASY86GMJwR2g05/gwY9oWpAiedXhWdi3HIDpdyAk0BPLEUeCYzWWh8ptI03kKa1Niul3gVMWuu37vS+oaGh+uY7Fh07dowmTZrc044IxyQ/c2EPsvNMfLc/iXm74jhx8RqVy7kzoo0fj7Wri79XecjLhvidcHIznNwIVwp+w67eFIJ6W/7zbQtuZYo9q1IqWmsdeqvXijxC11rnK6WmAJuwTFucq7U+opR6B4jSWq8FugPTlVIa2A48Y7P0QghRTC6mZ7MoIp7Fe+O5nJlHk1qVeH9YCINa1KZc/lU4tRa2rLeMieddB7dyUK8bdHoegvpAFb+iP6QEWTUPXWu9Adhw03NvFfp6JbDSttFKj9TUVHr27Pmn53/++We8vLzu672feeYZdu3a9Yfnnn/+eSZMmHBf7yuEIzuUeIW5O8/ww6HzmLSmd5MaTOwcSLsq6agTa2HxBstQijZBxVrQYgQ07G8Z/3YvZ3T825IrRe2Al5cXBw4cKJb3njlzZrG8rxCOxmzWhB9PZvaOWH49k4ZnWTfGdQjgicY51D73E2xeCxd+s2xcvSl0eREa9YdarcDFMVZJkUIXQji17DwTa/Yn8dWOWGJTrlO7Ulk+7gID3CIoe+oNiD5p2dCvHfR5FxoPhGqOedMVKXQhhFO6mpnHgog4FkbEcSkjh0E1Uvki5DeCUragIs+AcoWATtB2MjR+ECrVMjryfZNCF0I4les5+czfHceXv5ymZs4Z3qx+iN7lIyh/NRbSXSGwq+UCn8YPQoX7O0dlb6TQhRBOITvPxOK9Z1mzNYIu2b+wofxefDkD6S4Q0Bm6PgtNBkMFb6OjFhsp9Ju4urrSvHlztNa4uroyY8YMOnbsSGZmJk8++SSHDh1Ca02VKlXYuHEjnp6e9/2Z8+fPv7HY1dSpU/H09OSll14q8vvi4uJ48MEHOXz4sFXbHDhwgHPnzsmyt8Kp5JnMrI04zOlt39A9dxuTXE6AO1CzHTT7KwQPgYp3txqpo5JCv0m5cuVuzDjZtGkTr776Kr/88guffPIJNWrU4LffLGfBT5w4cddruhhN1jEXzsSUm82vm5di2r+EwfnRuCsTmVWD4IE3ofkjhlypaTT7LfQfX/n/KUS2UrM59H+v6O0KpKen31gx8fz583+4VL9Ro0Z3/F5Zx1yIYqA15sRo4sPnUO3MD3TgGqmqGucaP45/9/GUrxkCpfjm4/Zb6AbJysqiZcuWZGdnc/78ecLDwwGYOHEiffr0YeXKlfTs2ZPx48fftuRkHXMhbOzaBfSBJVz/dRGe12Kppd2JKNOBiu3G0rr7w3i5OdZvy8XFfgv9Lo6kbanwkEtERATjxo3j8OHDtGzZktjYWDZv3syWLVto06YNERERt1yHRNYxF8IGTHlwajN630L0qZ9w0SaOmRvyS7lnCO49nn6tG/5x6Vphx4VuBzp06MClS5dISUmhevXqeHp6MnToUIYOHYqLiwsbNmy4q4WlZB1zIaxwKQb2L0QfWIq6nsxlVZXleQPYWbEfQ3t1528ta+Pm6hhXbpY0+VO5g+PHj2MymfDy8mLXrl031jfPzc3l6NGjt13+VtYxF+Iu5efAbyth/oMw4wHMu2ewN68ek3L/zjCPOXg/NJ0FL41m2AO+UuZ3IEfoN/l9DB0sR70LFizA1dWV06dP8/TTT6O1xmw2M3DgQIYNG3bL95B1zIWwUlosRM+H/Ysh8xLZnn58W+FxPktti0e5Wjw7NIiHW9XBXUrcKkWuh15cZD10AfIzL5XMJsua4r9+BbFbQblyxb8Xs651Zfa5utSuUoHnejZgaGtfKfJbuK/10IUQwiaup8L+hRD5NVxNgEp1uNTmJd672IaVJ0x4e5bhrUENGN3On7JurkandUhS6PdB1jEXwgpJ+yxH44dXgSkHArqQ3PFt/n0mkNU7L+JZRvFSn4ZM6BRIhbJSSffD7v70tNY35k7bO1nH/P4YNdwnSoApH46vg4jPIfFXcK8ArceS0vgxPj7kxrffJ+DmmsLkrvV4ult9qpQv/lu3lQZ2VegeHh6kpqbi5eXlMKUu7o3WmtTUVDw8PIyOImwp6zLsWwh7Z0N6IlQNhH7vkRr0CJ9HpLBoXjxaa0a382dKjwZUryQ/f1uyq0L39fUlMTGRlJQUo6OIEuDh4YGvr6/RMYQtpJ6GPbPgwBLLvTcDusCAD7jqF8ZXO+OZ+0k02XkmhrX25bmeQfhVK290YqdkV4Xu7u5+11dPCiEMlBAJuz+BYz+Aqzs0ewTaP831asGWNcmX/UJ6dj4PhtTihd4Nqe9z/6uTituzqtCVUv2ATwBXYI7W+r2bXvcHFgBVCrZ5peDG0kIIZ2M2W6Yd7v7UciNlj8qW+2+2fYpsD28W7z3LrK+3cikjl15NqvNi70YE165kdOpSochCV0q5AjOB3kAiEKmUWqu1PlposzeAb7XWs5RSwcAGIKAY8gohjJKfC4eWwe7P4NJJqOwP/d6DVmPJcyvPt1EJfPbzNi6kZ9OpgRez+zSitX9Vo1OXKtYcobcFYrTWsQBKqWXAEKBwoWvg9/8FVwbO2TKkEMJAudchegFEzID0JKgZAsO+huCHMClX1h08x39+iuRsWiat/avwnxEt6Fjfee8KZM+sKfQ6QEKhx4lAu5u2mQpsVko9C1QAet3qjZRSk4HJAP7+/nebVQhRkrIuw69zYM/nkJUGdTvD4M+gfhga+OnoRT7afJITF6/RpFYlvh4fSljj6jJDzUC2Oik6Cpivtf5IKdUBWKSUaqa1NhfeSGs9G5gNlkv/bfTZQghbykiBiM8gci7kXoOgvpYxcv/2AOyOucT7m05wIOEKgd4V+GxUKwY2ryVL2doBawo9CfAr9Ni34LnCJgH9ALTWEUopD8AbSLZFSCFECbh20XKiM/JryxWdwQ9B5xegVggA+89e5sPNJ9gVk0rtyh78e1hzhrWW1Q/tiTWFHgkEKaUCsRT5SGD0TducBXoC85VSTQAPQCaTC+EIrl2AXZ9A1Fww5ULz4dD1JfC23Njk+IV0Ptp8kp+OXsSrQhnefDCYMe388XCX9VbsTZGFrrXOV0pNATZhmZI4V2t9RCn1DhCltV4L/B34Sin1ApYTpI9rua5bCPt27QLs/NiyfK0pD1qMhC5/B6/6AMRdus5/t5zk+4Pn8CzrJuutOACrfjIFc8o33PTcW4W+Pgp0sm00IUSxyEiBXf+FyDlgzv//Iq9WD4BzV7L4LDyGFVEJuLkq/tKtPk91rSfrrTgA+V+tEKVFZpplDvneLyE/C0JGQrd/QDXL1dnJ6dl8vu00S/aeRVOw3kpYA6pXlPVWHIUUuhDOLjvdMvUwYibkXINmQ6HbK+BjuYF4akYOX26PZWFEHHkmzaMP+DIlrAG+VWW9FUcjhS6Es8rLhqivYfuHlnnkjR+EHq9BjaYAXM3M46sdsczbdYbMPBMPt6zDcz2DCPCuYHBwca+k0IVwNmYTHFwKW6dblrCt1wN6vgV1WgNwLTuPebvi+GpHLNey8xkYUosXegXRoHpFg4OL+yWFLoSz0BqOr4fwf0LKcajdGh6aCfW6A5CVa2JhRBxf/HKay5l59A6uwQu9GsrCWU5ECl0IZ3B2L/z0JiTsBa8gGL4QmgwGpcjOM7Hs17PM2HqaSxk5dGvow4u9G9LCr4rRqYWNSaEL4chST8OWqXBsLXjWhEGfQssx4OpGTr6Jb6MSmRkew4X0bNoFVmPWY61pE1DN6NSimEihC+GIrqfC9vctl+m7loHur0HHKVCmAnkmMyt/PcuM8BiSrmQRWrcqHw1vQcf6cmtHZyeFLoQjyc+BvV/A9o8sC2e1Hmcp84o1yDOZWROZwKfhp0i8nEVLvypMH9qcLkHeUuSlhBS6EI5Aazi2zjJOfjkOgvpA73egehNLkUclMHNrDPGpmYT4VuafQ5rRvZGPFHkpI4UuhL07fwg2vQZxO8CnCYxdA/XDbhyRz9gaw9m0TJrVqcRX40Lp1UTWJC+tpNCFsFcZyZYpiPsWQbmqMPAjaP04ebiwJjKBz7aeIiEti+Z1KsvNJQQghS6E/cnPhV+/hG3/tqy50uEZ6Poyue6VWB2dyMxtMSSkZRHiW5mpg5pKkYsbpNCFsCenw+HH/7HchDmoD/SdTm6VeqyMTmTm1n0kXZEiF7cnhS6EPbgcbxknP/4DVA2EUcvJqd+bFVGJzNq2jaQrllkr0x5uRveGcrJT3JoUuhBGysuCnf+1rE+uXCDsTbLbPM2KAynMWr2Nc1ezae1fhX8NbU5XmX4oiiCFLoRRTv0EG16yTENsOpTssKksPW7mi48juJieQ2jdqvz7kRA6N5AiF9aRQheipF1NhI2vWOaVezcke/QavrkYwBezTnEpI4d2gdX4eERLOtSTKzvF3ZFCF6KkmPJgzyzY9h5oMznd3mABg/hyeQKp14/RqYEXM8Ja0b6el9FJhYOSQheiJMRHwA8vQMox8hr0Y3HVv/LfHTlcyTxN14Y+PBfWgFBZNEvcJ6sKXSnVD/gEcAXmaK3fu+n1j4EeBQ/LA9W11rI2pxBZly2rIUbPx1zJj7WNP+TN4/5cy86gZ+PqPNsziJayjK2wkSILXSnlCswEegOJQKRSaq3W+ujv22itXyi0/bNAq2LIKoTj0BqOrIYfX0FnphJZazTPnOtHSrIb/Zp6MyWsAc3qVDY6pXAy1hyhtwVitNaxAEqpZcAQ4Ohtth8FvG2beEI4oMvxsP7vEPMT58o35pn8FzgQV5eBzWsxJawBjWvKHYJE8bCm0OsACYUeJwLtbrWhUqouEAiE3+b1ycBkAH9//7sKKoTdM+XD3lmYw98lzwwfmMax8EpfhrTy46Pu9ann42l0QuHkbH1SdCSwUmttutWLWuvZwGyA0NBQbePPFsI4F4+QveqveCQfYKupFe/oSXQNbUV4t3r4Vi1vdDpRSlhT6EmAX6HHvgXP3cpI4Jn7DSWEw8jPIW3ju1SOmkGGrsCr+m94tR3Oim71qV7Jw+h0opSxptAjgSClVCCWIh8JjL55I6VUY6AqEGHThELYqYSD23Bb/xy1cuP5XnfhzANv8HpYK7w9yxodTZRSRRa61jpfKTUF2IRl2uJcrfURpdQ7QJTWem3BpiOBZVprGUoRTu342QucW/0a3S+v5iLVWNH4Y8IGjWGIFLkwmDKqf0NDQ3VUVJQhny3EvTiUeIWN61czPOk9Alwusq/GMAJGfki1qnJBkCg5SqlorXXorV6TK0WFKEJ0fBpf/HSYDnEzecltE9fK1SLj4e9o3bhH0d8sRAmSQhfiFrTWRJxO5bPwGPLP7OI/ZWfj53aB3NaTqNz3HSgrUxCF/ZFCF6IQs1nz8/FkZm6N4VhCMm+XX8mosuvRVfxhyDrKBHY1OqIQtyWFLgSQbzKz/rfzfL71NCcuXqNP5QQWeM2i8vU4aPMkqtdUOSoXdk8KXZRq2XkmVu9L4svtp4lPzaSxjwcbQ7bT6NRXqLK1YNz3UK+70TGFsIoUuiiV0rPzWLznLF/vPMOljBxCfCvzzaBKdDr8OurkQWgxGvq/Bx6ygJZwHFLoolRJTs9m7q44Fu+J51pOPl2CvHm6awgdkpehwqdB2Yow4htoMsjoqELcNSl0USqcTslgzo5YVu1LIt9kpn/zWjzdrT7NKqTDdxMhbgc0fhAe/C94+hgdV4h7IoUunFp0fBpf/hLLT8cu4u7qwrDWvjzVtR4B3hXgt5Ww8EXQJhgyE1qOAbmHp3BgUujC6ZjNmi3HLvLl9lii4y9TuZw7U3o0YFyHAHwqloWsK7DqCfhtBfi1g4e/hGqBRscW4r5JoQunkZVrYtW+RObuPEPspev4Vi3H1EHBDG/jR/kyBX/Vz+yANX+Ba+ehx+vQ+UVwlX8GwjnI32Th8JKvZbMoIp5v9sRzOTOP5nUq8+moVgxoVhM3VxfLRvm5sPVd2PWJ5Wh80k/g+4CxwYWwMSl04bBOXLjG1ztj+W7/OfLMZno1qcETnQNpG1gNVXgsPPU0rJoE5/ZD63HQd7pcJCSckhS6cChms+aXkynM3XWGHacu4eHuwog2fkzoFPDnW7xpDQeXwoaXwcUNhi+E4CHGBBeiBEihC4eQmZvPqn1JzNt1htiU69SoVJaX+zZidFt/qlYo8+dvyL4KP7wIh1dC3U4wdDZU9i354EKUICl0YdeSrmSxKCKepb+e5WpWHiG+lflkZEsGNK+F++/j4zdLiIRVE+FqEvR4A7q8CC6uJRtcCANIoQu7o7Xm1zNpLIiIY9ORi2it6desJhM7BfJA3ap/HB8vzGyGXf+F8GlQuQ5M3Ah+bUs0uxBGkkIXdiM7z8TaA+eYtzuOY+fTqVzOnSe6BDK2fV18q5a/8zdnJMOap+B0OAQ/BIM/lXVYRKkjhS4Ml3g5k8V7z7I8MoG067k0qlGR6UOb81DLOpQrY8VQSew2WD3ZMm7+4H/hgcflik9RKkmhC0OYzZqdMZdYGBFP+PGLAPRqUoPHOwXQoZ7X7YdVCjPlw7bpsOMj8G4IY9dAjabFnFwI+2VVoSul+gGfAK7AHK31e7fYZjgwFdDAQa31aBvmFE4iPTuPlVGJfLMnnthL1/GqUIa/dKvPmPZ1qVOlnPVvdDXJMrf8bAS0egz6vw9lKhRfcCEcQJGFrpRyBWYCvYFEIFIptVZrfbTQNkHAq0AnrfVlpVT14gosHNPhpKt8syee7w+cIyvPRCv/Knw8ogUDmteirNtdzkA5tQXWTIa8bHh4NrQYUTyhhXAw1hyhtwVitNaxAEqpZcAQ4GihbZ4EZmqtLwNorZNtHVQ4nqxcE+sOnWPxnngOJl7Fw92FIS3q8Fj7ujT3vYcTljeGWD6E6sHw6ALwaWj74EI4KGsKvQ6QUOhxItDupm0aAiildmEZlpmqtd548xsppSYDkwH8/f3vJa9wADHJ11iyN4GV0QmkZ+fToLonUwcF83BrXyqXc7+3N712AVZOgvid0GpswRBLETNfhChlbHVS1A0IAroDvsB2pVRzrfWVwhtprWcDswFCQ0O1jT5b2IHsPBM/Hj7P0r0J/BqXhrurom/TmjzWvi7tbl5b5W7FbrMsd5t7HR76AlqOslluIZyJNYWeBPgVeuxb8FxhicBerXUecEYpdRJLwUfaJKWwW6cuXmPJr2dZvS+Jq1l5BHiV59X+jRn2gC/enmXv783NZtj+gWWYxacRjP8Bqje2TXAhnJA1hR4JBCmlArEU+Ujg5hks3wGjgHlKKW8sQzCxtgwq7Edmbj4/HDrP8sgEouMv4+6q6NesFqPa+lk/5bDID0mD1U9CzBYIGQEPfiyzWIQoQpGFrrXOV0pNATZhGR+fq7U+opR6B4jSWq8teK2PUuooYAJe1lqnFmdwUbK01vyWdJVlkQmsPXCOjJx86vtU4LUBjRnW2hev+z0aLywxGlaMh4yLliJ/YIJcKCSEFZTWxgxlh4aG6qioKEM+W1jvSmYu3x84x/LIBI6eT8fD3YWBzWszsq0foXdaV+VeaA2Rc2Djq1CxFgxfAHVa2+79hXACSqlorXXorV6TK0XFn5jNmt2nU1kelcCmIxfIzTfTtHYl/vlQMwa3qH3vM1XuJPc6rHvecp/PoD6W+3yWr2b7zxHCiUmhixsSL2eyKjqJFdEJJF7OonI5d0a18WN4Gz+a1i7Gha5ST8PyxyD5GIS9AZ3/Di63WRpXCHFbUuil3PWcfH48fIFV0YlExFpOe3Ru4M0/+jWmT3ANPNyLeR3x4xssqyS6uMHY1VA/rHg/TwgnJoVeCpnNmj2xqazcl8jGwxfIzDVR16s8L/ZuyMOt6uBXrQQu2DGbYOu/LFd91moJIxZBFbnYTIj7IYVeipxOyWDNviTW7E8i6UoWFcu6MbhFbR55wPfON46wtcw0y8Jap8MtV30O+BDcPUrms4VwYlLoTu5KZi7rDp1nVXQiBxKu4KKgS5AP/+jXiL5Naxb/kMrNzh2A5WMh4yfGTbQAABIzSURBVAIM+sSydrkQwiak0J1QTr6JbSdSWLMvifDjyeSazDSqUZHXBjRmSMs61Khk0NHwwWWWmSzlvS23h6vzgDE5hHBSUuhOQmtNdPxl1uxP4odD57malYe3ZxnGtPdnWGtfmtauVHJDKjcz5cHmN2DvFxDQBR6dDxW8jckihBOTQndwcZeus3p/Et/tT+JsWiYe7i70bVqTh1rVoUsDb9xcDZ7+l5EMKx6H+F3Q/hno/Q64yl87IYqD/MtyQL+Pi6/Zl8i+s1dQCjrV9+b5nkH0bVYTz7J28mNNjLbML8+6DEO/gpDhRicSwqnZyb98UZTcfDPbTiSzutC4eMManrza3zIuXrOync0S2f8N/PACeNaESZugVgujEwnh9KTQ7VjhcfH1v53nSqZlXHxsh7o83KqOsePit2PKg02vwa+zIbAbPDIPKngZnUqIUkEK3Q7FJGfw/YEkvjuQREJaFh7uLvQJrsnDrerQJcgOxsVv5/oly3h53A4ZLxfCAPKvzU6cv5rFDwfP8/3BJA4npeOioFMDb17o1ZA+Te1oXPx2zh+CZWMsS97KXYWEMISdt4Rzu5KZy4bfLvD9gSR+jUtDawjxrcwbA5swuEVtqhs1X/xuHV4F3z0D5arCxB9lfrkQBpFCL2EZOflsOXqRdQfPsf1UCnkmTT2fCvytZ0MGt6xNoLcD3ZXHbILwabDzP+DXDoYvgoo1jE4lRKklhV4CsnJNbD2RzLqD5wg/nkxOvplalT14vGMAQ1ra6cnNomSnW24Rd3IjtB4PAz4ANxvetUgIcdek0ItJdp6J7SdTWP/bebYcvcj1XBPenmUZ2caPQS1q09q/Ki4uDlbiv0s9DUtHQWqMZWGtNk/ILeKEsANS6Db0e4lv+O08W44lk5GTT9Xy7gxuWZtBIbVpV88LV0ct8d+d3mqZyaIUjF0D9boZnUgIUUAK/T7dqsSrlHfnwZBaDAypRft6Xrjb6zTDu6E17P3SMsfcpxGMXALVAo1OJYQoxKpCV0r1Az4BXIE5Wuv3bnr9ceADIKngqRla6zk2zGlXMnPz+eVEChsOXyD8mGU4pXI5dwY2r8WAkFp0rO8kJf67/FxY/yLsXwSNBsLQL6FsRaNTCSFuUmShK6VcgZlAbyARiFRKrdVaH71p0+Va6ynFkNEuXMvOI/x4MpuOXGDr8RSy8kx4VSjD4JZ1GNC8pvMcid/s+iXL+uVnd0PXl6H7a3K/TyHslDVH6G2BGK11LIBSahkwBLi50J1OakYOW45dZOPhC+yKSSXXZManYlkeecCX/s1r0jagmv1etWkLF4/A0pGWFRMfmQvNhhmdSAhxB9YUeh0godDjRKDdLbYbppTqCpwEXtBaJ9y8gVJqMjAZwN/fPu8fmXQli81HLrDpyAV+PZOGWYNv1XKM71iXfs1q0srPgWen3I0TP8KqJ6CMJ0zYIBcLCeEAbHVSdB2wVGudo5R6ClgA/On27Vrr2cBsgNDQUG2jz74vWmtOJWew6fAFNh29wOGkdACCqnvyTI8G9GtWk+BaDjhP/F5pDbs+gS1ToXZLy8nPSrWNTiWEsII1hZ4E+BV67Mv/n/wEQGudWujhHOD9+49WfExmzYGEy2w+cpHNRy9y5tJ1AFr5V+GV/o3pE1yDej6eBqc0QF42/PA3OLgUmg6FITOhTHmjUwkhrGRNoUcCQUqpQCxFPhIYXXgDpVQtrfX5goeDgWM2TWkD2Xkmdp++xOYjF9ly7CKXMnJxd1W0r+fFpM6B9Amu4ThrpxSHjBRYPgYS9kKP1y0nQEvLbyVCOIkiC11rna+UmgJswjJtca7W+ohS6h0gSmu9FnhOKTUYyAfSgMeLMbPV0q7nsvV4MluOXeSXkylk5prwLOtG90Y+9Glak+6NfKjk4W50TONdPAJLRsL1FHh0ATR9yOhEQoh7oLQ2Zig7NDRUR0VF2fx9T6dksOWo5Sg8Ov4yZg01KpWlV5Ma9Glak/b1qlHWzdXmn+uwTmyEVZMs88pHLYXarYxOJIS4A6VUtNY69FavOfyVonkmM5FxaYQfSyb8eDKxBePhwbUqMSUsiN5NatCsTik6qWktrSFiJmx+w3J7uFFL5eSnEA7OIQs9NSOHbSdSCD+ezPaTKVzLyaeMqwvt6lXj8U4B9GxSgzpVyhkd034VvvIzeIjlhhRy8lMIh+dwhT57+2mm/3gcraF6xbIMDKlFWOPqdGrgTQV7v6uPPchMs1z5Gb9TrvwUwsk4XAM+ULcaf+vZkLDG1Wlau1LpuMjHVi6dgiXD4WoiDP0KQoYbnUgIYUMOWOhVeaBuVaNjOJ7YX+DbseDiDuN/AP9bXewrhHBk8rt2aRC9AL4ZChVrwZM/S5kL4aQc7ghd3AWzCX56CyJmQINelgW2PCobnUoIUUyk0J1VToblnp8nNkDbydB3OrjKj1sIZyb/wp3R1SRYOsJyBWj/D6DdZKMTCSFKgBS6szm333IZf+51GL0CgnoZnUgIUULkpKgzObYO5g0A1zIwabOUuRCljBS6M/h9DfPlY6F6sGUmS41go1MJIUqYDLk4OlOe5TL+fQuh6cPw0Cxwl2UPhCiNpNAdWdZl+HYcnNkul/ELIaTQHVZaLCweDpfjLItrtRxldCIhhMGk0B3R2T2wbDRoM4z7HgI6GZ1ICGEH5PdzR3NoBSwYBB5V4ImfpcyFEDfIEbqj0Bp+eR+2/QvqdoYRi6B8NaNTCSHsiBS6I8jPgbXPwqHl0GI0DPoE3MoYnUoIYWesGnJRSvVTSp1QSsUopV65w3bDlFJaKXXL+92Je3A9FRYOsZR52Bvw0OdS5kKIWyryCF0p5QrMBHoDiUCkUmqt1vroTdtVBJ4H9hZH0FLp0ilY/Cikn7OslNhsmNGJhBB2zJoj9LZAjNY6VmudCywDhtxiu38C/waybZiv9DqzA+b0gpxr8PgPUuZCiCJZU+h1gIRCjxMLnrtBKdUa8NNar7dhttJr/2JY9DB41rBcxu/X1uhEQggHcN8nRZVSLsB/gMet2HYyMBnA39//fj/a+ZjNsHUa7PgI6nWHRxdAuSpGpxJCOAhrjtCTAL9Cj30LnvtdRaAZsE0pFQe0B9be6sSo1nq21jpUax3q4+Nz76mdUV4WrJpoKfPW42HMSilzIcRdseYIPRIIUkoFYinykcDo31/UWl8FvH9/rJTaBryktY6ybVQnlpEMS0dBUjT0/id0fBaUMjqVEMLBFFnoWut8pdQUYBPgCszVWh9RSr0DRGmt1xZ3SKeWfAyWDIeMFMvFQk0GGZ1ICOGgrBpD11pvADbc9Nxbt9m2+/3HKiVOh8O34y3L3U7YAHVaG51ICOHAZC0Xo0TNg28egSr+8GS4lLkQ4r7Jpf8lzWyCn96CiBnQoDc8Og/KVjQ6lRDCCUihl6Tc67DqSTixHto+BX3/Ba7yIxBC2Ia0SUlJPwdLRsDFw9D/A2g32ehEQggnI4VeEs4dgKUjLZfxj1oODfsYnUgI4YSk0Ivb8fWw6gkoVw0mboKazYxOJIRwUjLLpbhoDbs/g2VjwKexZSaLlLkQohjJEXpxMOXB+r/DvgUQPMRyE+cy5Y1OJYRwclLotpZ1Gb4dB2e2Q5eXoMfr4CK/CAkhip8Uui2lnrZcxn853nJU3nKU0YmEEKWIFLqtxO2E5Y8BCsavhbodjU4khChlZCzAFvZ/Awsfggo+lhtSSJkLIQwgR+j3w2yCLVNh96cQ2A2GL4ByVY1OJYQopaTQ71VOBqx+Ek5sgNBJ0P/f4OpudCohRCkmhX4vriRYbkiRfMRyGX/bJ+WGFEIIw0mh363EKEuZ52fDmBXQoJfRiYQQApCTonfnt5Uwb4DlIqFJP0mZCyHsihyhW8Nshm3/gu0fgH9HGPENVPAyOpUQQvyBFHpRcjJgzVNw/AdoNRYG/gfcyhidSggh/kQK/U4Kn/zsOx3aPy0nP4UQdsuqMXSlVD+l1AmlVIxS6pVbvP4XpdRvSqkDSqmdSqlg20ctYQm/wlc94Eo8jP4WOvxVylwIYdeKLHSllCswE+gPBAOjblHYS7TWzbXWLYH3gf/YPGlJOrAU5g+EMp7wxBYI6m10IiGEKJI1R+htgRitdazWOhdYBgwpvIHWOr3QwwqAtl3EEmQ2weY34Lu/gF87yxrmPo2MTiWEEFaxZgy9DpBQ6HEi0O7mjZRSzwAvAmWAsFu9kVJqMjAZwN/f/26zFq+sK7BqEsRsgTZPQr/pcuWnEMKh2GweutZ6pta6PvA/wBu32Wa21jpUax3q4+Njq4++f5dOwZyeELsNHvwvDPxQylwI4XCsOUJPAvwKPfYteO52lgGz7idUiYrZAismgqsbjFsLAZ2MTiSEEPfEmiP0SCBIKRWolCoDjATWFt5AKRVU6OFA4JTtIhYTrWH3DFj8KFTxgye3SpkLIRxakUfoWut8pdQUYBPgCszVWh9RSr0DRGmt1wJTlFK9gDzgMjC+OEPft7wsWPc8HFoOTQZZ7i5U1tPoVEIIcV+surBIa70B2HDTc28V+vp5G+cqPlcSYPkYOH8QerwBXf4u9/wUQjiF0nWlaNwuyw2c83Ng1DJo1N/oREIIYTOlo9C1hsg5sPEVqBoAI5eCT0OjUwkhhE05f6Hn58CGl2DfQgjqC8O+Ao/KRqcSQgibc+5Cv5oE346FpGjLWHmP18HF1ehUQghRLJy30ON2worHLTNaRnxjmc0ihBBOzPkKXWvYM8uyJku1evD4elmPRQhRKjhXoedmwrrn4LcV0GggPPwFeFQyOpUQQpQI5yn0tDOwfCxcPAxhb0BnmV8uhChdnKPQT/wIq58CBYxZIeuXCyFKJccudLMJtr4LOz6CWi1g+ELLPHMhhCiFHLfQM1Is65ef+QVaj4P+H4C7h9GphBDCMI5Z6AmRlkv4s9Jg8AxoPdboREIIYTjHK/QDS2Dtc1CpNkzabBlqEUII4YCFXq0+NOwLQ2ZAuapGpxFCCLvheIXu3w78FxudQggh7I5M1BZCCCchhS6EEE5CCl0IIZyEFLoQQjgJKXQhhHASUuhCCOEkpNCFEMJJSKELIYSTUFprYz5YqRQg3pAPvz/ewCWjQxigtO43lN59l/22T3W11j63esGwQndUSqkorXWo0TlKWmndbyi9+y777XhkyEUIIZyEFLoQQjgJKfS7N9voAAYprfsNpXffZb8djIyhCyGEk5AjdCGEcBJS6EII4SSk0G9DKdVPKXVCKRWjlHrlFq/7K6W2KqX2K6UOKaUGGJHT1qzY77pKqZ8L9nmbUsrXiJy2ppSaq5RKVkodvs3rSin1acGfyyGlVOuSzlgcrNjvxkqpCKVUjlLqpZLOV1ys2O8xBT/n35RSu5VSDnGvSyn0W1BKuQIzgf5AMDBKKRV802ZvAN9qrVsBI4HPSzal7Vm53x8CC7XWIcA7wPSSTVls5gP97vB6fyCo4L/JwKwSyFQS5nPn/U4DnsPyc3cm87nzfp8BummtmwP/xEFOlEqh31pbIEZrHau1zgWWAUNu2kYDlQq+rgycK8F8xcWa/Q4Gwgu+3nqL1x2S1no7lvK6nSFY/kemtdZ7gCpKqVolk674FLXfWutkrXUkkFdyqYqfFfu9W2t9ueDhHsAhfhOVQr+1OkBCoceJBc8VNhV4TCmVCGwAni2ZaMXKmv0+CAwt+PphoKJSyqsEshnNmj8b4ZwmAT8aHcIaUuj3bhQwX2vtCwwAFimlSsOf50tAN6XUfqAbkASYjI0kRPFQSvXAUuj/Y3QWa7gZHcBOJQF+hR77FjxX2CQKxuC01hFKKQ8si/okl0jC4lHkfmutz1FwhK6U8gSGaa2vlFhC41jzd0I4EaVUCDAH6K+1TjU6jzVKwxHlvYgEgpRSgUqpMlhOeq69aZuzQE8ApVQTwANIKdGUtlfkfiulvAv9JvIqMLeEMxplLTCuYLZLe+Cq1vq80aFE8VBK+QOrgbFa65NG57GWHKHfgtY6Xyk1BdgEuAJztdZHlFLvAFFa67XA34GvlFIvYDlB+rh28Mturdzv7sB0pZQGtgPPGBbYhpRSS7Hsm3fBeZG3AXcArfUXWM6TDABigExggjFJbauo/VZK1QSisEwAMCul/gYEa63TDYpsE1b8vN8CvIDPlVIA+Y6wAqNc+i+EEE5ChlyEEMJJSKELIYSTkEIXQggnIYUuhBBOQgpdCCGchBS6EEI4CSl0IYRwEv8HspZmhmYKNIEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ5KjZp6LgRG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}