{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "European_Call_jax.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Judy/European_Call_jax_1stock_v3_BStest_Judy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daFzpNueawfe"
      },
      "source": [
        "# Use Black-Scholes to Generate Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxFUnc_iBVcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb55aa0-3c0f-4cea-b74f-c19acf1ea527"
      },
      "source": [
        "%%writefile cupy_dataset.py\n",
        "import cupy\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "    return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len, number_path, batch, seed, stocks):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 50\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = 1.0 # assume T = 1, use float here\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros((self.N_BATCH, 1 + self.N_STOCKS), dtype=cupy.float32) # output: price, delta1, delta2, delta3\n",
        "        X = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "\n",
        "        for op in range(self.N_BATCH):\n",
        "\n",
        "          ################################################################################################### generate random input numbers\n",
        "\n",
        "          initial_stocks = np.array(0.75 + np.random.random(self.N_STOCKS) * 0.5)\n",
        "\n",
        "          corr = np.diag(np.array([1]*self.N_STOCKS)) # assume no correlation between stocks here\n",
        "          sigma = np.array(0.15 + np.random.random(self.N_STOCKS) * 0.3)\n",
        "          cov = (np.diag(sigma)).dot(corr).dot(np.diag(sigma))\n",
        "\n",
        "          r = np.repeat(np.array(0.25 + np.random.random(1) * 0.35), self.N_STOCKS)\n",
        "          drift = r\n",
        "\n",
        "          T = self.T\n",
        "          K = 0.75 + np.random.random(1) * 0.5\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### apply functions to compute price and deltas\n",
        "\n",
        "          European_Call_price = bs_call(initial_stocks,K,T,r,sigma)\n",
        "          Deltas = bs_delta(initial_stocks,K,T,r,sigma)\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### store input and output numbers in X and Y\n",
        "\n",
        "          Y[op, 0] = European_Call_price[0]\n",
        "          Y[op, 1:4] = cupy.array(Deltas, dtype=cupy.float32)\n",
        "\n",
        "          # T, K, S, sigma, mu, r\n",
        "          paras = (np.repeat(np.array(T), self.N_STOCKS), np.repeat(np.array(K), self.N_STOCKS), initial_stocks, sigma, drift, r)\n",
        "          paras = np.column_stack(paras).reshape(1,-1)[0]\n",
        "          X[op,] = cupy.array(paras)\n",
        "\n",
        "          ###################################################################################################\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "\n",
        "# ds = OptionDataSet(max_len = 2, number_path = 1000000, batch = 2, seed = np.random.randint(10000), stocks=1) # for testing purpose, use constant seed. When training, change to random seed\n",
        "# for i in ds:\n",
        "#     print(i)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cupy_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6JO9OBHdvv",
        "outputId": "ca1b567b-ae09-4765-bcc3-3fe14ce3b18f"
      },
      "source": [
        "%%writefile model.py\n",
        "# version 1,2\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*1, 32) # remember to change this!\n",
        "        self.fc2 = nn.Linear(32, 64)\n",
        "        self.fc3 = nn.Linear(64, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 32)\n",
        "        self.fc6 = nn.Linear(32, 1) # 1 outputs: price\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1.0, 0.5, 0.5, 0.3, 0.35, 0.35]*1)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = (x - torch.tensor([0.0, 0.75, 0.75, 0.15, 0.25, 0.25]*1).cuda()) / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlXD80xPNVc6",
        "outputId": "571c4bdf-9c6c-4935-fc88-1a808c15d55a"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3CyULkENYKb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "ca69148a-1c44-4a91-c7c0-f265c090e6e9"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 100000, batch = 32, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()  # let delta weight = 0 for testing\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter) # print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-18b86d18c3e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-18b86d18c3e9>\u001b[0m in \u001b[0;36mtrain_update\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_order_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompute_deltas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-18b86d18c3e9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_order_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompute_deltas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-18b86d18c3e9>\u001b[0m in \u001b[0;36mcompute_deltas\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m       \u001b[0mfirst_order_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_order_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    226\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    227\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         inputs, allow_unused, accumulate_grad=False)\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e235a978-e797-4587-c88b-1fcca8f0fb93"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_BStest_J_4.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Judy/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a39e95d0-f511-4bf6-e080-043efeb97622"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e42922-a2a5-461c-80b2-fd7946745acb"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_BStest_J_3.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Judy/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "289e2071-a678-474d-a3a8-85b638e56dcc"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=6, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc5): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc6): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72804807-d131-42c9-b359-a879caca6bc9"
      },
      "source": [
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "#dataset = OptionDataSet(max_len = 100, number_path = 1024, batch = 32, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 1000000, batch = 16, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()  # let delta weight = 0 for testing\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 10\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter) # print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 200)\n",
        "\n",
        "# model_save_name = 'jax_european_1stock_BStest_1.pth'\n",
        "# path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "# torch.save(model.state_dict(), path)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.0001330466620856896 average time 0.01917633870007194 iter num 10\n",
            "loss 5.5323998822132125e-05 average time 0.01823368209993532 iter num 20\n",
            "loss 0.0002923841238953173 average time 0.017588785766626338 iter num 30\n",
            "loss 7.895172166172415e-05 average time 0.017527836624958583 iter num 40\n",
            "loss 6.241541996132582e-05 average time 0.017146043679967988 iter num 50\n",
            "loss 6.573673454113305e-05 average time 0.017115697249967827 iter num 60\n",
            "loss 7.52700652810745e-05 average time 0.016900589942828708 iter num 70\n",
            "loss 6.359367398545146e-05 average time 0.01685932756248576 iter num 80\n",
            "loss 0.0010812522377818823 average time 0.016802491811096033 iter num 90\n",
            "loss 6.805021985201165e-05 average time 0.016803004049988884 iter num 100\n",
            "loss 0.0009673457825556397 average time 0.017150354399927892 iter num 10\n",
            "loss 0.00012419576523825526 average time 0.016603708999946322 iter num 20\n",
            "loss 6.48801724310033e-05 average time 0.016520811200007302 iter num 30\n",
            "loss 6.69734290568158e-05 average time 0.016480394199993496 iter num 40\n",
            "loss 7.196479418780655e-05 average time 0.016590753680011405 iter num 50\n",
            "loss 0.0002576187835074961 average time 0.016960255833343277 iter num 60\n",
            "loss 0.0001033379667205736 average time 0.016842805971451266 iter num 70\n",
            "loss 0.0006307968287728727 average time 0.016777080600024873 iter num 80\n",
            "loss 5.68026298424229e-05 average time 0.016654990466698414 iter num 90\n",
            "loss 0.0011893052142113447 average time 0.01671148332005032 iter num 100\n",
            "loss 9.338564268546179e-05 average time 0.01687697079996724 iter num 10\n",
            "loss 2.993339512613602e-05 average time 0.016470858699995004 iter num 20\n",
            "loss 0.00010170237510465086 average time 0.016283262500019192 iter num 30\n",
            "loss 7.00518285157159e-05 average time 0.01675017042498439 iter num 40\n",
            "loss 4.202653872198425e-05 average time 0.016749936420019367 iter num 50\n",
            "loss 5.5195956520037726e-05 average time 0.016818842566696426 iter num 60\n",
            "loss 5.545250678551383e-05 average time 0.016659292814321297 iter num 70\n",
            "loss 5.186483031138778e-05 average time 0.016727135125040603 iter num 80\n",
            "loss 0.00031232103356160223 average time 0.01663789240005321 iter num 90\n",
            "loss 0.0007864731014706194 average time 0.016576435030074207 iter num 100\n",
            "loss 3.664386895252392e-05 average time 0.017150596599822165 iter num 10\n",
            "loss 6.366922025335953e-05 average time 0.017541327399976582 iter num 20\n",
            "loss 0.00010212837514700368 average time 0.016829138266621156 iter num 30\n",
            "loss 0.00014449989248532802 average time 0.016836509574955017 iter num 40\n",
            "loss 0.0002730889536906034 average time 0.016750242599955528 iter num 50\n",
            "loss 6.345789734041318e-05 average time 0.016557230533286806 iter num 60\n",
            "loss 5.571341171162203e-05 average time 0.01663164264281087 iter num 70\n",
            "loss 7.563033432234079e-05 average time 0.016698939212471942 iter num 80\n",
            "loss 0.00012147548113716766 average time 0.016788980133292677 iter num 90\n",
            "loss 0.00012576910376083106 average time 0.016693910499971026 iter num 100\n",
            "loss 8.96436395123601e-05 average time 0.018233012600103394 iter num 10\n",
            "loss 9.636330651119351e-05 average time 0.01759088174999306 iter num 20\n",
            "loss 6.462945748353377e-05 average time 0.01798428363329852 iter num 30\n",
            "loss 6.885279435664415e-05 average time 0.01748535257495405 iter num 40\n",
            "loss 0.00013674180081579834 average time 0.017239517319976586 iter num 50\n",
            "loss 4.365686618257314e-05 average time 0.01704013313330203 iter num 60\n",
            "loss 3.722475958056748e-05 average time 0.017128735699991793 iter num 70\n",
            "loss 7.525427645305172e-05 average time 0.017185362675013492 iter num 80\n",
            "loss 0.00010324098548153415 average time 0.017088097200000145 iter num 90\n",
            "loss 2.8704156648018397e-05 average time 0.017099584670013428 iter num 100\n",
            "loss 0.00011516828089952469 average time 0.018463429400071618 iter num 10\n",
            "loss 2.8514332370832562e-05 average time 0.01711724890005826 iter num 20\n",
            "loss 2.1770560124423355e-05 average time 0.01664969503335669 iter num 30\n",
            "loss 2.2771891963202506e-05 average time 0.01666739492504803 iter num 40\n",
            "loss 0.00016564890393055975 average time 0.016827442280045943 iter num 50\n",
            "loss 6.404025771189481e-05 average time 0.016836376933330635 iter num 60\n",
            "loss 9.781508560990915e-05 average time 0.016784662399991896 iter num 70\n",
            "loss 3.92749861930497e-05 average time 0.017014810787497937 iter num 80\n",
            "loss 7.219203689601272e-05 average time 0.016942611644460866 iter num 90\n",
            "loss 4.153651025262661e-05 average time 0.016830776210017575 iter num 100\n",
            "loss 4.4989807065576315e-05 average time 0.017023714700007984 iter num 10\n",
            "loss 0.0005972058279439807 average time 0.01647532629995112 iter num 20\n",
            "loss 7.535183249274269e-05 average time 0.017166116033301173 iter num 30\n",
            "loss 3.269730950705707e-05 average time 0.016784190399948783 iter num 40\n",
            "loss 6.565690273419023e-05 average time 0.01684070367999084 iter num 50\n",
            "loss 8.713007264304906e-05 average time 0.016843256166688057 iter num 60\n",
            "loss 0.0004951843875460327 average time 0.016945785657195043 iter num 70\n",
            "loss 2.6771049306262285e-05 average time 0.0168026764000615 iter num 80\n",
            "loss 0.0006505495985038579 average time 0.01672971875559597 iter num 90\n",
            "loss 2.891848089348059e-05 average time 0.016661945260048015 iter num 100\n",
            "loss 0.00013321821461431682 average time 0.01775296869991507 iter num 10\n",
            "loss 8.842781244311482e-05 average time 0.01669878539992169 iter num 20\n",
            "loss 2.2076113964430988e-05 average time 0.016880004199962665 iter num 30\n",
            "loss 7.898454350652173e-05 average time 0.016959236799971224 iter num 40\n",
            "loss 4.209702819935046e-05 average time 0.017288382360002286 iter num 50\n",
            "loss 5.7840152294375e-05 average time 0.017078355100011322 iter num 60\n",
            "loss 0.0006776273949071765 average time 0.01696919687142976 iter num 70\n",
            "loss 5.841829624841921e-05 average time 0.017121761900000365 iter num 80\n",
            "loss 8.897594670997933e-05 average time 0.016994911911115195 iter num 90\n",
            "loss 4.513056774158031e-05 average time 0.01698846796001817 iter num 100\n",
            "loss 6.598934123758227e-05 average time 0.017779316600353923 iter num 10\n",
            "loss 8.83990214788355e-05 average time 0.01709452215013698 iter num 20\n",
            "loss 9.705043339636177e-05 average time 0.016712821266780035 iter num 30\n",
            "loss 0.0018624039366841316 average time 0.016594625750076374 iter num 40\n",
            "loss 8.518701361026615e-05 average time 0.016681780680100927 iter num 50\n",
            "loss 7.543199171777815e-05 average time 0.016982398033390685 iter num 60\n",
            "loss 4.829341560252942e-05 average time 0.0169442695286047 iter num 70\n",
            "loss 0.00010203683632425964 average time 0.016967202500040912 iter num 80\n",
            "loss 8.64011308294721e-05 average time 0.016846747377803693 iter num 90\n",
            "loss 0.00017503729031886905 average time 0.01676305041001797 iter num 100\n",
            "loss 4.1710256482474506e-05 average time 0.01698230700003478 iter num 10\n",
            "loss 6.689316069241613e-05 average time 0.016397901250002178 iter num 20\n",
            "loss 8.576063555665314e-05 average time 0.016816001066642154 iter num 30\n",
            "loss 8.542796422261745e-05 average time 0.016930283800002145 iter num 40\n",
            "loss 4.0726648876443505e-05 average time 0.0166470780599775 iter num 50\n",
            "loss 3.905934499925934e-05 average time 0.016511107633323262 iter num 60\n",
            "loss 9.962433250620961e-05 average time 0.016481689871384982 iter num 70\n",
            "loss 0.0007974728941917419 average time 0.016401484324956073 iter num 80\n",
            "loss 6.186940299812704e-05 average time 0.016316266777751783 iter num 90\n",
            "loss 4.037455437355675e-05 average time 0.016437315449984453 iter num 100\n",
            "loss 9.716016938909888e-05 average time 0.018685578599979637 iter num 10\n",
            "loss 6.39442732790485e-05 average time 0.01870285849990978 iter num 20\n",
            "loss 5.908283492317423e-05 average time 0.017748623166577698 iter num 30\n",
            "loss 5.2547460654750466e-05 average time 0.017411863674919915 iter num 40\n",
            "loss 8.285448711831123e-05 average time 0.017188203879904905 iter num 50\n",
            "loss 9.522782784188166e-05 average time 0.017024874866607812 iter num 60\n",
            "loss 5.874836278962903e-05 average time 0.016936881614245586 iter num 70\n",
            "loss 3.88538210245315e-05 average time 0.01683003683745028 iter num 80\n",
            "loss 4.658929174183868e-05 average time 0.016756663588815477 iter num 90\n",
            "loss 7.507791451644152e-05 average time 0.016709746729948165 iter num 100\n",
            "loss 5.08562006871216e-05 average time 0.01723630119995505 iter num 10\n",
            "loss 5.3725336329080164e-05 average time 0.016801619300031233 iter num 20\n",
            "loss 7.06327919033356e-05 average time 0.016690053400058483 iter num 30\n",
            "loss 6.113846757216379e-05 average time 0.016412380025076344 iter num 40\n",
            "loss 0.00012840515410061926 average time 0.016485065440028847 iter num 50\n",
            "loss 0.0006136746378615499 average time 0.01704783606667964 iter num 60\n",
            "loss 0.00020779432088602334 average time 0.01713585738571055 iter num 70\n",
            "loss 0.00010134647891391069 average time 0.016951414274979017 iter num 80\n",
            "loss 0.0012749690795317292 average time 0.016825219122185646 iter num 90\n",
            "loss 3.9990281948121265e-05 average time 0.016810927589976928 iter num 100\n",
            "loss 0.0001084970572264865 average time 0.016926032199990004 iter num 10\n",
            "loss 4.666648237616755e-05 average time 0.01637452964992008 iter num 20\n",
            "loss 9.577483433531597e-05 average time 0.016143730499940525 iter num 30\n",
            "loss 0.00016815389972180128 average time 0.0165666993999821 iter num 40\n",
            "loss 7.581427780678496e-05 average time 0.01688035963999937 iter num 50\n",
            "loss 0.0001282316807191819 average time 0.016658824616691468 iter num 60\n",
            "loss 7.375424320343882e-05 average time 0.016616801985700088 iter num 70\n",
            "loss 8.00152265583165e-05 average time 0.01654984804999913 iter num 80\n",
            "loss 0.0001032446016324684 average time 0.016478341144425535 iter num 90\n",
            "loss 6.7362685513217e-05 average time 0.016476552249987435 iter num 100\n",
            "loss 6.408258195733652e-05 average time 0.017386414999873524 iter num 10\n",
            "loss 0.0002117267285939306 average time 0.016563899149878124 iter num 20\n",
            "loss 0.002379130572080612 average time 0.016974603333286115 iter num 30\n",
            "loss 0.0007946291007101536 average time 0.016623910899966177 iter num 40\n",
            "loss 0.0017796331085264683 average time 0.01666469841995422 iter num 50\n",
            "loss 8.902548142941669e-05 average time 0.016889558016570543 iter num 60\n",
            "loss 0.0006481214659288526 average time 0.016808093799954803 iter num 70\n",
            "loss 0.00015509608783759177 average time 0.01674271407496235 iter num 80\n",
            "loss 4.172393892076798e-05 average time 0.016746290644419383 iter num 90\n",
            "loss 7.793767872499302e-05 average time 0.016736417679994703 iter num 100\n",
            "loss 0.001401576679199934 average time 0.018265261099804773 iter num 10\n",
            "loss 9.71084155025892e-05 average time 0.018003465199899437 iter num 20\n",
            "loss 3.927051511709578e-05 average time 0.01760354313331239 iter num 30\n",
            "loss 4.8755631723906845e-05 average time 0.017645753700048773 iter num 40\n",
            "loss 0.00028357908013276756 average time 0.017785302240044983 iter num 50\n",
            "loss 6.054310506442562e-05 average time 0.018037100950065603 iter num 60\n",
            "loss 7.06646460457705e-05 average time 0.017908388371493597 iter num 70\n",
            "loss 6.968907837290317e-05 average time 0.01792648897504705 iter num 80\n",
            "loss 0.0016743968008086085 average time 0.01778842406668749 iter num 90\n",
            "loss 5.938224421697669e-05 average time 0.01758584010000959 iter num 100\n",
            "loss 0.0006168209947645664 average time 0.018420527500074967 iter num 10\n",
            "loss 0.0001651474740356207 average time 0.018101902450052876 iter num 20\n",
            "loss 0.00011562901636352763 average time 0.01763507533335845 iter num 30\n",
            "loss 4.25440157414414e-05 average time 0.01743874222499926 iter num 40\n",
            "loss 0.00017606290930416435 average time 0.017429197620003833 iter num 50\n",
            "loss 9.044659964274615e-05 average time 0.017291657483322828 iter num 60\n",
            "loss 7.164278213167563e-05 average time 0.017330686657130303 iter num 70\n",
            "loss 3.170851414324716e-05 average time 0.01753841222500796 iter num 80\n",
            "loss 5.583033635048196e-05 average time 0.01769552964445514 iter num 90\n",
            "loss 1.94965487025911e-05 average time 0.017488505010014706 iter num 100\n",
            "loss 0.00011773807636927813 average time 0.01686123649988076 iter num 10\n",
            "loss 0.002469082595780492 average time 0.016946753749834897 iter num 20\n",
            "loss 3.2256062695523724e-05 average time 0.01646421156656288 iter num 30\n",
            "loss 0.0014213075628504157 average time 0.016311304374994506 iter num 40\n",
            "loss 6.255684274947271e-05 average time 0.0165832127000067 iter num 50\n",
            "loss 0.0018993510166183114 average time 0.016802560050018657 iter num 60\n",
            "loss 2.6431218429934233e-05 average time 0.016793195757158434 iter num 70\n",
            "loss 8.620775042800233e-05 average time 0.016767507350004963 iter num 80\n",
            "loss 6.466898776125163e-05 average time 0.016705835022225477 iter num 90\n",
            "loss 8.191515371436253e-05 average time 0.01690579936998802 iter num 100\n",
            "loss 5.2770687034353614e-05 average time 0.021288777199879406 iter num 10\n",
            "loss 0.0001380396424792707 average time 0.018955496499893344 iter num 20\n",
            "loss 3.8440190110122785e-05 average time 0.01848226389993215 iter num 30\n",
            "loss 4.382063707453199e-05 average time 0.018827830024929427 iter num 40\n",
            "loss 0.0001590727042639628 average time 0.01843902631993842 iter num 50\n",
            "loss 5.5435753893107176e-05 average time 0.0181134211499284 iter num 60\n",
            "loss 0.0002702654746826738 average time 0.018104032257087965 iter num 70\n",
            "loss 5.018663068767637e-05 average time 0.017936333549926076 iter num 80\n",
            "loss 6.907938950462267e-05 average time 0.01773889263326459 iter num 90\n",
            "loss 3.971232581534423e-05 average time 0.017652144739940923 iter num 100\n",
            "loss 5.931815758231096e-05 average time 0.01919472110002971 iter num 10\n",
            "loss 0.00016997926286421716 average time 0.01858508835007342 iter num 20\n",
            "loss 7.643832941539586e-05 average time 0.017760088333307066 iter num 30\n",
            "loss 3.20995386573486e-05 average time 0.01749977620002028 iter num 40\n",
            "loss 6.20646751485765e-05 average time 0.01797237862001566 iter num 50\n",
            "loss 6.884061440359801e-05 average time 0.01777645768330937 iter num 60\n",
            "loss 0.0005769197014160454 average time 0.01752525444283362 iter num 70\n",
            "loss 4.236437598592602e-05 average time 0.017482201449990954 iter num 80\n",
            "loss 0.00010651144839357585 average time 0.017648346644424842 iter num 90\n",
            "loss 2.1179057512199506e-05 average time 0.01752766169996903 iter num 100\n",
            "loss 0.00010759313590824604 average time 0.019069719100116345 iter num 10\n",
            "loss 0.00032957279472611845 average time 0.018440621900117547 iter num 20\n",
            "loss 4.031710705021396e-05 average time 0.017868024466739976 iter num 30\n",
            "loss 2.6297278964193538e-05 average time 0.01746355212508206 iter num 40\n",
            "loss 0.00014353211736306548 average time 0.01722092010006236 iter num 50\n",
            "loss 5.327173857949674e-05 average time 0.017566142050039465 iter num 60\n",
            "loss 6.284367555053905e-05 average time 0.01736968411430228 iter num 70\n",
            "loss 0.00013576231140177697 average time 0.017192443975022797 iter num 80\n",
            "loss 0.00010507529077585787 average time 0.017159068388910882 iter num 90\n",
            "loss 0.0003519921738188714 average time 0.01724909976003801 iter num 100\n",
            "loss 0.0007960677030496299 average time 0.018940377800026907 iter num 10\n",
            "loss 3.644710159278475e-05 average time 0.0181259780500568 iter num 20\n",
            "loss 4.732155866804533e-05 average time 0.01798721176667944 iter num 30\n",
            "loss 0.00019659841200336814 average time 0.017711510274966712 iter num 40\n",
            "loss 0.0006342098931781948 average time 0.01733285045997036 iter num 50\n",
            "loss 5.8602912758942693e-05 average time 0.017130994749989744 iter num 60\n",
            "loss 7.358707080129534e-05 average time 0.01720451855713431 iter num 70\n",
            "loss 8.034146594582126e-05 average time 0.017180396862454473 iter num 80\n",
            "loss 0.0001304081524722278 average time 0.01714084627773344 iter num 90\n",
            "loss 0.00044489119318313897 average time 0.016982291359954615 iter num 100\n",
            "loss 3.862523954012431e-05 average time 0.016937856699951227 iter num 10\n",
            "loss 8.827176498016343e-05 average time 0.016503968049983088 iter num 20\n",
            "loss 0.00013228670286480337 average time 0.01647010333332825 iter num 30\n",
            "loss 8.137741679092869e-05 average time 0.016271823149941154 iter num 40\n",
            "loss 0.0020770877599716187 average time 0.016311879039931226 iter num 50\n",
            "loss 4.601796899805777e-05 average time 0.016591777533282462 iter num 60\n",
            "loss 0.0006356066442094743 average time 0.016616938799974636 iter num 70\n",
            "loss 6.476135604316369e-05 average time 0.01650900564999347 iter num 80\n",
            "loss 3.905684934579767e-05 average time 0.016486524677788515 iter num 90\n",
            "loss 0.0012158596655353904 average time 0.016491631880026034 iter num 100\n",
            "loss 4.921332583762705e-05 average time 0.01696868489989356 iter num 10\n",
            "loss 0.0005535506643354893 average time 0.016664123849932367 iter num 20\n",
            "loss 5.884815618628636e-05 average time 0.016478751133308833 iter num 30\n",
            "loss 5.533092189580202e-05 average time 0.016519938074998207 iter num 40\n",
            "loss 0.000150282823597081 average time 0.016376527100001113 iter num 50\n",
            "loss 7.391469262074679e-05 average time 0.01622014284995809 iter num 60\n",
            "loss 3.4412852983223274e-05 average time 0.016253008585681527 iter num 70\n",
            "loss 6.261379166971892e-05 average time 0.016341266662448107 iter num 80\n",
            "loss 9.939951996784657e-05 average time 0.01624645141107774 iter num 90\n",
            "loss 4.7773850383237004e-05 average time 0.016181383069988443 iter num 100\n",
            "loss 5.417427746579051e-05 average time 0.01956450789994051 iter num 10\n",
            "loss 0.00013489359116647393 average time 0.01881721435001964 iter num 20\n",
            "loss 6.060381201677956e-05 average time 0.017829789499986266 iter num 30\n",
            "loss 5.016052818973549e-05 average time 0.017362076349968447 iter num 40\n",
            "loss 9.691558807389811e-05 average time 0.017113270039972123 iter num 50\n",
            "loss 4.2581472371239215e-05 average time 0.017056294333375868 iter num 60\n",
            "loss 7.922843360574916e-05 average time 0.016871478742892316 iter num 70\n",
            "loss 5.4786698456155136e-05 average time 0.01672174268754816 iter num 80\n",
            "loss 0.00016000888717826456 average time 0.016684436711158115 iter num 90\n",
            "loss 2.959403173008468e-05 average time 0.016589367630031118 iter num 100\n",
            "loss 7.440826448146254e-05 average time 0.01678525580000496 iter num 10\n",
            "loss 0.0002552221994847059 average time 0.01669612379996579 iter num 20\n",
            "loss 4.134960545343347e-05 average time 0.01755070413331244 iter num 30\n",
            "loss 4.8076304665300995e-05 average time 0.017077684599962596 iter num 40\n",
            "loss 6.65289699099958e-05 average time 0.016857651979953515 iter num 50\n",
            "loss 0.0001231641654158011 average time 0.017146320033301285 iter num 60\n",
            "loss 7.31815307517536e-05 average time 0.01739696268571476 iter num 70\n",
            "loss 4.1424253140576184e-05 average time 0.017165407812501598 iter num 80\n",
            "loss 0.0001417105522705242 average time 0.01713178535555926 iter num 90\n",
            "loss 0.0001206665692734532 average time 0.017096145599998634 iter num 100\n",
            "loss 0.000246159645030275 average time 0.018039190899980895 iter num 10\n",
            "loss 0.00012112680269638076 average time 0.016915367049978158 iter num 20\n",
            "loss 0.0004485845856834203 average time 0.016446177166684114 iter num 30\n",
            "loss 4.280048233340494e-05 average time 0.016379534925067673 iter num 40\n",
            "loss 3.120035398751497e-05 average time 0.016285998879993713 iter num 50\n",
            "loss 5.245139982434921e-05 average time 0.016225227033358654 iter num 60\n",
            "loss 3.2776486477814615e-05 average time 0.016261828371443698 iter num 70\n",
            "loss 0.00015761767281219363 average time 0.016388268424998388 iter num 80\n",
            "loss 0.00010796235437737778 average time 0.016420029488906748 iter num 90\n",
            "loss 3.645697142928839e-05 average time 0.016393312390027857 iter num 100\n",
            "loss 3.3827229344751686e-05 average time 0.017592163699919183 iter num 10\n",
            "loss 4.189792525721714e-05 average time 0.01733732285001679 iter num 20\n",
            "loss 9.310770110459998e-05 average time 0.01708285423334625 iter num 30\n",
            "loss 0.00012087226059520617 average time 0.016951802250014227 iter num 40\n",
            "loss 3.774459764827043e-05 average time 0.01692148238003938 iter num 50\n",
            "loss 0.00010512349399505183 average time 0.016811047900030948 iter num 60\n",
            "loss 9.33687697397545e-05 average time 0.016890599542901848 iter num 70\n",
            "loss 0.0014367481926456094 average time 0.016722769337536646 iter num 80\n",
            "loss 0.00010328732605557889 average time 0.01663196100003511 iter num 90\n",
            "loss 7.868117972975597e-05 average time 0.016636382200040316 iter num 100\n",
            "loss 8.69540890562348e-05 average time 0.017667919600080496 iter num 10\n",
            "loss 6.788557948311791e-05 average time 0.01674287744990579 iter num 20\n",
            "loss 2.9017739507253282e-05 average time 0.016540362366564903 iter num 30\n",
            "loss 7.779168663546443e-05 average time 0.016772255224941544 iter num 40\n",
            "loss 9.125692304223776e-05 average time 0.01667946857993229 iter num 50\n",
            "loss 6.4853134972509e-05 average time 0.016597658849968867 iter num 60\n",
            "loss 7.944610842969269e-05 average time 0.01660396068568194 iter num 70\n",
            "loss 3.0042485377634875e-05 average time 0.016756434687454202 iter num 80\n",
            "loss 6.018960630171932e-05 average time 0.016814662155492342 iter num 90\n",
            "loss 0.00028094727895222604 average time 0.016808108849936616 iter num 100\n",
            "loss 0.0005636063870042562 average time 0.018120375599937687 iter num 10\n",
            "loss 3.905796984327026e-05 average time 0.017366197049977928 iter num 20\n",
            "loss 0.0004296906990930438 average time 0.016794771599961678 iter num 30\n",
            "loss 2.6040501325041987e-05 average time 0.01658374040000581 iter num 40\n",
            "loss 8.285007788799703e-05 average time 0.01653789185997084 iter num 50\n",
            "loss 0.0002603530010674149 average time 0.016386710883307388 iter num 60\n",
            "loss 0.00013057846808806062 average time 0.01629604821425476 iter num 70\n",
            "loss 5.1199618610553443e-05 average time 0.01649374862498689 iter num 80\n",
            "loss 8.544544107280672e-05 average time 0.01642142390001027 iter num 90\n",
            "loss 2.1058694983366877e-05 average time 0.01639863070001411 iter num 100\n",
            "loss 7.472268771380186e-05 average time 0.0169503062998956 iter num 10\n",
            "loss 3.629855200415477e-05 average time 0.01624913174996436 iter num 20\n",
            "loss 6.042447057552636e-05 average time 0.01693577789998623 iter num 30\n",
            "loss 4.882283246843144e-05 average time 0.01675721177498417 iter num 40\n",
            "loss 3.888133505824953e-05 average time 0.016590130539971142 iter num 50\n",
            "loss 3.9904894947540015e-05 average time 0.016385522266667372 iter num 60\n",
            "loss 0.00010198362724622712 average time 0.016436600871423124 iter num 70\n",
            "loss 0.00015575492579955608 average time 0.016441824337482557 iter num 80\n",
            "loss 0.0001025120509439148 average time 0.016351299999991575 iter num 90\n",
            "loss 3.315102730994113e-05 average time 0.01639121110000815 iter num 100\n",
            "loss 2.9618020562338643e-05 average time 0.017406745699918246 iter num 10\n",
            "loss 6.665053660981357e-05 average time 0.017339215599895395 iter num 20\n",
            "loss 7.550125155830756e-05 average time 0.016863577599936737 iter num 30\n",
            "loss 5.071505074738525e-05 average time 0.016584066074938165 iter num 40\n",
            "loss 0.0016175579512491822 average time 0.016767431159914848 iter num 50\n",
            "loss 0.000394722621422261 average time 0.016882179649943888 iter num 60\n",
            "loss 3.317493246868253e-05 average time 0.016781111442807223 iter num 70\n",
            "loss 0.0001350184465991333 average time 0.016835702724961266 iter num 80\n",
            "loss 7.605783321196213e-05 average time 0.01670292695553144 iter num 90\n",
            "loss 3.1814466638024896e-05 average time 0.01662717177999184 iter num 100\n",
            "loss 5.333338413038291e-05 average time 0.017839221800113592 iter num 10\n",
            "loss 4.678701589000411e-05 average time 0.016714157150090614 iter num 20\n",
            "loss 4.53698230558075e-05 average time 0.016515111599983357 iter num 30\n",
            "loss 6.595799641218036e-05 average time 0.016354663474976404 iter num 40\n",
            "loss 0.00013459504407364875 average time 0.016399812759991618 iter num 50\n",
            "loss 4.7298370191128924e-05 average time 0.01685968213335703 iter num 60\n",
            "loss 4.4504467950901017e-05 average time 0.016720617128612503 iter num 70\n",
            "loss 0.00011351664579706267 average time 0.016621286575013983 iter num 80\n",
            "loss 0.00010345359623897821 average time 0.016609141622241926 iter num 90\n",
            "loss 7.483080844394863e-05 average time 0.016638215120019596 iter num 100\n",
            "loss 0.0003665026160888374 average time 0.016916582100020606 iter num 10\n",
            "loss 9.318792581325397e-05 average time 0.016535182999905373 iter num 20\n",
            "loss 0.00017391217988915741 average time 0.016319221399953676 iter num 30\n",
            "loss 7.293930684681982e-05 average time 0.016867409499968743 iter num 40\n",
            "loss 0.0015039154095575213 average time 0.016998872679960187 iter num 50\n",
            "loss 5.911878906772472e-05 average time 0.01690471438332679 iter num 60\n",
            "loss 0.0001647296012379229 average time 0.01675495769999803 iter num 70\n",
            "loss 9.399418195243925e-05 average time 0.01713670142501087 iter num 80\n",
            "loss 0.00010306042531738058 average time 0.017157240955556416 iter num 90\n",
            "loss 0.00014852482127025723 average time 0.017080562020000797 iter num 100\n",
            "loss 7.347684004344046e-05 average time 0.016973150899957545 iter num 10\n",
            "loss 4.571501995087601e-05 average time 0.016376314799936155 iter num 20\n",
            "loss 0.00011147867189720273 average time 0.016430023133337576 iter num 30\n",
            "loss 6.32954397588037e-05 average time 0.01637358577502255 iter num 40\n",
            "loss 0.0003634447930380702 average time 0.01633884052000212 iter num 50\n",
            "loss 5.8229255955666304e-05 average time 0.016211219183348172 iter num 60\n",
            "loss 0.0002449928433634341 average time 0.016136523771430284 iter num 70\n",
            "loss 6.576224404852837e-05 average time 0.016207836662488262 iter num 80\n",
            "loss 9.097290603676811e-05 average time 0.016336663900003462 iter num 90\n",
            "loss 8.67400158313103e-05 average time 0.01628982408999036 iter num 100\n",
            "loss 4.289461503503844e-05 average time 0.01676053600031082 iter num 10\n",
            "loss 7.868680404499173e-05 average time 0.01674220120021346 iter num 20\n",
            "loss 3.682896203827113e-05 average time 0.016682130566762984 iter num 30\n",
            "loss 7.438210013788193e-05 average time 0.016711655800099832 iter num 40\n",
            "loss 6.34883253951557e-05 average time 0.016641757660072472 iter num 50\n",
            "loss 4.718554555438459e-05 average time 0.016856719800049783 iter num 60\n",
            "loss 0.0003946700016967952 average time 0.016894931428617255 iter num 70\n",
            "loss 3.389375706319697e-05 average time 0.016870891712540016 iter num 80\n",
            "loss 2.8302083592279814e-05 average time 0.016792484988925733 iter num 90\n",
            "loss 7.355381239904091e-05 average time 0.0166777754800205 iter num 100\n",
            "loss 1.8564342099125497e-05 average time 0.016895192799893266 iter num 10\n",
            "loss 2.441870492475573e-05 average time 0.01648197679992336 iter num 20\n",
            "loss 7.694937812630087e-05 average time 0.01627576123328254 iter num 30\n",
            "loss 0.0019399268785491586 average time 0.016174359274941708 iter num 40\n",
            "loss 7.14377747499384e-05 average time 0.01601588573996196 iter num 50\n",
            "loss 0.0001901845243992284 average time 0.015922831749958278 iter num 60\n",
            "loss 2.959217999887187e-05 average time 0.01596671148567371 iter num 70\n",
            "loss 5.491747288033366e-05 average time 0.0162253184499491 iter num 80\n",
            "loss 6.0831927839899436e-05 average time 0.016368057777759126 iter num 90\n",
            "loss 4.0785878809401765e-05 average time 0.01658449887997449 iter num 100\n",
            "loss 3.9634185668546706e-05 average time 0.018785090900018987 iter num 10\n",
            "loss 6.290199962677434e-05 average time 0.017981658250027975 iter num 20\n",
            "loss 0.00019835105922538787 average time 0.017737847333319224 iter num 30\n",
            "loss 4.637759775505401e-05 average time 0.017278773849875508 iter num 40\n",
            "loss 4.40574403910432e-05 average time 0.01713316211991696 iter num 50\n",
            "loss 5.6337190471822396e-05 average time 0.016918731766584944 iter num 60\n",
            "loss 3.227372144465335e-05 average time 0.017103706385634205 iter num 70\n",
            "loss 9.463813330512494e-05 average time 0.016958081162431426 iter num 80\n",
            "loss 2.1016699975007214e-05 average time 0.016970170677743427 iter num 90\n",
            "loss 6.662979285465553e-05 average time 0.016901984699961757 iter num 100\n",
            "loss 5.4917218221817166e-05 average time 0.01864090989993201 iter num 10\n",
            "loss 9.144057548837736e-05 average time 0.01712379079999664 iter num 20\n",
            "loss 0.00014540630218107253 average time 0.016815380066661115 iter num 30\n",
            "loss 7.30781612219289e-05 average time 0.01697933572497732 iter num 40\n",
            "loss 2.9369241019594483e-05 average time 0.017204266639982962 iter num 50\n",
            "loss 0.00035425214446149766 average time 0.017572237350001765 iter num 60\n",
            "loss 0.00012340217654127628 average time 0.017507274557166445 iter num 70\n",
            "loss 6.066586865927093e-05 average time 0.01752779950003287 iter num 80\n",
            "loss 0.00013120417133904994 average time 0.017296665044452514 iter num 90\n",
            "loss 0.0018211231799796224 average time 0.01722704151000471 iter num 100\n",
            "loss 2.9242344680824317e-05 average time 0.016815994500120723 iter num 10\n",
            "loss 5.9022713685408235e-05 average time 0.017166217750036593 iter num 20\n",
            "loss 0.00012436954420991242 average time 0.016746860566672694 iter num 30\n",
            "loss 0.0003747672599274665 average time 0.01651872950001234 iter num 40\n",
            "loss 0.000341211591148749 average time 0.016756503520027763 iter num 50\n",
            "loss 3.966795338783413e-05 average time 0.01664189640000586 iter num 60\n",
            "loss 5.336598405847326e-05 average time 0.01662531147142415 iter num 70\n",
            "loss 3.7927409721305594e-05 average time 0.016596415074991454 iter num 80\n",
            "loss 3.9997376006795093e-05 average time 0.016652172900002267 iter num 90\n",
            "loss 2.5238743546651676e-05 average time 0.016641635480000333 iter num 100\n",
            "loss 8.658793376525864e-05 average time 0.017092105999927297 iter num 10\n",
            "loss 0.00011075044312747195 average time 0.016766024099979404 iter num 20\n",
            "loss 4.5256525481818244e-05 average time 0.017701723866654598 iter num 30\n",
            "loss 4.651836206903681e-05 average time 0.01722038749996955 iter num 40\n",
            "loss 4.290078140911646e-05 average time 0.016955821520004976 iter num 50\n",
            "loss 4.947326669935137e-05 average time 0.01675118508334587 iter num 60\n",
            "loss 6.137009768281132e-05 average time 0.016764989071465865 iter num 70\n",
            "loss 3.90155146305915e-05 average time 0.01678241958752551 iter num 80\n",
            "loss 0.0004105374973732978 average time 0.016826338133361988 iter num 90\n",
            "loss 4.0594553865958005e-05 average time 0.016786386150024556 iter num 100\n",
            "loss 3.548730455804616e-05 average time 0.018454213099903426 iter num 10\n",
            "loss 7.077934424160048e-05 average time 0.019058701399944766 iter num 20\n",
            "loss 8.979652920970693e-05 average time 0.01814418483327245 iter num 30\n",
            "loss 0.0021173059940338135 average time 0.017805977274952055 iter num 40\n",
            "loss 3.9390637539327145e-05 average time 0.018612302979981905 iter num 50\n",
            "loss 3.317969458294101e-05 average time 0.018421518566644104 iter num 60\n",
            "loss 3.50936570612248e-05 average time 0.018200338585692016 iter num 70\n",
            "loss 4.657420140574686e-05 average time 0.018267459874971338 iter num 80\n",
            "loss 2.836021303664893e-05 average time 0.018157615855529406 iter num 90\n",
            "loss 2.7016152671421878e-05 average time 0.017981877149977663 iter num 100\n",
            "loss 0.00017516748630441725 average time 0.016579041099885217 iter num 10\n",
            "loss 0.0008493406348861754 average time 0.01699202765003065 iter num 20\n",
            "loss 0.00010192902846029028 average time 0.016884618599912454 iter num 30\n",
            "loss 3.285839920863509e-05 average time 0.016593181599932904 iter num 40\n",
            "loss 5.789007627754472e-05 average time 0.016921912759953556 iter num 50\n",
            "loss 2.9557108064182103e-05 average time 0.016922660866612205 iter num 60\n",
            "loss 0.00032719774753786623 average time 0.016890428342802417 iter num 70\n",
            "loss 0.0001897008769446984 average time 0.016714174949947848 iter num 80\n",
            "loss 4.8666504881111905e-05 average time 0.016708954288848568 iter num 90\n",
            "loss 9.003067680168897e-05 average time 0.01681808636993992 iter num 100\n",
            "loss 5.6718439736869186e-05 average time 0.017845641300118585 iter num 10\n",
            "loss 6.546727672684938e-05 average time 0.01757980465008586 iter num 20\n",
            "loss 0.00010358997678849846 average time 0.017642349633448854 iter num 30\n",
            "loss 0.00022967930999584496 average time 0.017241968325060954 iter num 40\n",
            "loss 0.001923808129504323 average time 0.01712259946005361 iter num 50\n",
            "loss 6.517147994600236e-05 average time 0.016920161966678886 iter num 60\n",
            "loss 2.868729643523693e-05 average time 0.016860388014291468 iter num 70\n",
            "loss 0.0008312570280395448 average time 0.016747854125003413 iter num 80\n",
            "loss 3.40181723004207e-05 average time 0.016681537888881496 iter num 90\n",
            "loss 3.118611857644282e-05 average time 0.01665936905998933 iter num 100\n",
            "loss 1.786419488780666e-05 average time 0.01898521749981228 iter num 10\n",
            "loss 4.7157893277471885e-05 average time 0.017321113199886894 iter num 20\n",
            "loss 0.000463565083919093 average time 0.016749691966682197 iter num 30\n",
            "loss 6.377204408636317e-05 average time 0.01640570667498196 iter num 40\n",
            "loss 2.647841211000923e-05 average time 0.016432494660020894 iter num 50\n",
            "loss 2.2257894670474343e-05 average time 0.016770360533367543 iter num 60\n",
            "loss 5.1416434871498495e-05 average time 0.017083245614334632 iter num 70\n",
            "loss 3.309498788439669e-05 average time 0.017185157375024573 iter num 80\n",
            "loss 0.0003165719972457737 average time 0.017163299300015446 iter num 90\n",
            "loss 4.516346598393284e-05 average time 0.017158433860031436 iter num 100\n",
            "loss 4.714332317234948e-05 average time 0.016895009800009575 iter num 10\n",
            "loss 6.155015580588952e-05 average time 0.016462019800064807 iter num 20\n",
            "loss 6.64624385535717e-05 average time 0.016378222666662622 iter num 30\n",
            "loss 5.707595846615732e-05 average time 0.016430441799957406 iter num 40\n",
            "loss 2.8253763957764022e-05 average time 0.01628733879995707 iter num 50\n",
            "loss 0.0005277947639115155 average time 0.016328723499994643 iter num 60\n",
            "loss 0.00028354665846563876 average time 0.016300567657123923 iter num 70\n",
            "loss 0.0004909589770250022 average time 0.01619792702497307 iter num 80\n",
            "loss 5.35018443770241e-05 average time 0.01614661485552157 iter num 90\n",
            "loss 4.891481876256876e-05 average time 0.016126067249961126 iter num 100\n",
            "loss 7.270473724929616e-05 average time 0.017665709799985052 iter num 10\n",
            "loss 6.344514258671552e-05 average time 0.0168816104000598 iter num 20\n",
            "loss 5.6087435950757936e-05 average time 0.0165462770333761 iter num 30\n",
            "loss 9.646511898608878e-05 average time 0.016593667050074146 iter num 40\n",
            "loss 3.789030961343087e-05 average time 0.01661232688000382 iter num 50\n",
            "loss 4.120767334825359e-05 average time 0.016519110950002868 iter num 60\n",
            "loss 2.2516032913699746e-05 average time 0.016432545485687504 iter num 70\n",
            "loss 5.3007206588517874e-05 average time 0.016418663524950715 iter num 80\n",
            "loss 5.3722560551250353e-05 average time 0.016353687466633144 iter num 90\n",
            "loss 4.088919740752317e-05 average time 0.016360736119977445 iter num 100\n",
            "loss 3.9585640479344875e-05 average time 0.017056414600028803 iter num 10\n",
            "loss 2.7554109692573547e-05 average time 0.01657745679999607 iter num 20\n",
            "loss 2.0007808416266926e-05 average time 0.01634140836667939 iter num 30\n",
            "loss 0.00038393298746086657 average time 0.01614204852505736 iter num 40\n",
            "loss 4.816811269847676e-05 average time 0.016252040840045084 iter num 50\n",
            "loss 0.00011486117728054523 average time 0.016258947816701643 iter num 60\n",
            "loss 3.7939553294563666e-05 average time 0.01618522394288188 iter num 70\n",
            "loss 2.5502649805275723e-05 average time 0.01612255867504473 iter num 80\n",
            "loss 3.088384255534038e-05 average time 0.016112600488920888 iter num 90\n",
            "loss 7.926290709292516e-05 average time 0.016305515940020995 iter num 100\n",
            "loss 0.00042770057916641235 average time 0.017286301599688157 iter num 10\n",
            "loss 0.0005056331865489483 average time 0.016597165999792197 iter num 20\n",
            "loss 5.9980327932862565e-05 average time 0.016686269533208058 iter num 30\n",
            "loss 4.2794599721673876e-05 average time 0.01695282562486682 iter num 40\n",
            "loss 6.140629557194188e-05 average time 0.01679093387989269 iter num 50\n",
            "loss 5.2444851462496445e-05 average time 0.016596257899891498 iter num 60\n",
            "loss 3.547902451828122e-05 average time 0.01675646098563967 iter num 70\n",
            "loss 0.000586998532526195 average time 0.0167845775874639 iter num 80\n",
            "loss 5.167063500266522e-05 average time 0.01674491735552187 iter num 90\n",
            "loss 0.00010949595889542252 average time 0.016709882239965737 iter num 100\n",
            "loss 7.789998198859394e-05 average time 0.018673382800079706 iter num 10\n",
            "loss 2.9122915293555707e-05 average time 0.0176115786500759 iter num 20\n",
            "loss 6.132123962743208e-05 average time 0.017041685266667626 iter num 30\n",
            "loss 2.4113858671626076e-05 average time 0.017180651675016635 iter num 40\n",
            "loss 4.124141560168937e-05 average time 0.01710506626001006 iter num 50\n",
            "loss 5.773767043137923e-05 average time 0.01715627221668304 iter num 60\n",
            "loss 5.0636837841011584e-05 average time 0.017131742785698276 iter num 70\n",
            "loss 4.134585469728336e-05 average time 0.017086026449965173 iter num 80\n",
            "loss 0.00010404094791738316 average time 0.017090868199991543 iter num 90\n",
            "loss 6.289622251642868e-05 average time 0.017252275879982334 iter num 100\n",
            "loss 0.000374256371287629 average time 0.01711568090004221 iter num 10\n",
            "loss 0.00011105801968369633 average time 0.016948641000044517 iter num 20\n",
            "loss 5.5522094044135883e-05 average time 0.017129604733357458 iter num 30\n",
            "loss 3.695829218486324e-05 average time 0.017247339724985978 iter num 40\n",
            "loss 1.816029180190526e-05 average time 0.016890003679982328 iter num 50\n",
            "loss 2.312504693691153e-05 average time 0.016672852916644842 iter num 60\n",
            "loss 9.253471944248304e-05 average time 0.016705058042849226 iter num 70\n",
            "loss 8.682134648552164e-05 average time 0.016691410475004886 iter num 80\n",
            "loss 7.473832374671474e-05 average time 0.016644079755557564 iter num 90\n",
            "loss 3.019989890162833e-05 average time 0.01675172486001429 iter num 100\n",
            "loss 0.0011208353098481894 average time 0.018717312599710566 iter num 10\n",
            "loss 3.7954803701722994e-05 average time 0.01783269909988121 iter num 20\n",
            "loss 3.1931791454553604e-05 average time 0.01715384383323908 iter num 30\n",
            "loss 5.0363603804726154e-05 average time 0.017283572674978133 iter num 40\n",
            "loss 3.686073250719346e-05 average time 0.01816077863995815 iter num 50\n",
            "loss 5.243167470325716e-05 average time 0.018437283266636465 iter num 60\n",
            "loss 1.3567600944952574e-05 average time 0.018303796999979177 iter num 70\n",
            "loss 0.00010887683311011642 average time 0.01803093094997621 iter num 80\n",
            "loss 0.0003109989338554442 average time 0.018068061055550463 iter num 90\n",
            "loss 3.975774598075077e-05 average time 0.017837635469995804 iter num 100\n",
            "loss 7.218523387564346e-05 average time 0.01690733640016333 iter num 10\n",
            "loss 9.272935130866244e-05 average time 0.016423226150118354 iter num 20\n",
            "loss 5.146458715898916e-05 average time 0.016218501466786012 iter num 30\n",
            "loss 2.9633520171046257e-05 average time 0.016306642175095476 iter num 40\n",
            "loss 5.244743442744948e-05 average time 0.016207475940100267 iter num 50\n",
            "loss 4.5469929318642244e-05 average time 0.01616475553343359 iter num 60\n",
            "loss 3.901708259945735e-05 average time 0.016150810185782963 iter num 70\n",
            "loss 6.870395736768842e-05 average time 0.016104812037553984 iter num 80\n",
            "loss 9.93146313703619e-05 average time 0.016168062366674955 iter num 90\n",
            "loss 2.0440493244677782e-05 average time 0.016171685930012246 iter num 100\n",
            "loss 3.4838081774068996e-05 average time 0.01689773649986819 iter num 10\n",
            "loss 0.00010669828770915046 average time 0.016287987149917173 iter num 20\n",
            "loss 0.0001343844342045486 average time 0.016926495266610195 iter num 30\n",
            "loss 7.255720265675336e-05 average time 0.01676653057495514 iter num 40\n",
            "loss 3.566409577615559e-05 average time 0.016658775679952668 iter num 50\n",
            "loss 3.198229387635365e-05 average time 0.01647810919997331 iter num 60\n",
            "loss 2.1749779989477247e-05 average time 0.01640977291429278 iter num 70\n",
            "loss 4.687514956458472e-05 average time 0.01646627099997886 iter num 80\n",
            "loss 4.473277658689767e-05 average time 0.016353379511090477 iter num 90\n",
            "loss 2.8714635845972225e-05 average time 0.01631295311000031 iter num 100\n",
            "loss 0.0001627471938263625 average time 0.016911159500068607 iter num 10\n",
            "loss 5.9640144172590226e-05 average time 0.018688794450099522 iter num 20\n",
            "loss 8.924947906052694e-05 average time 0.01783316310002192 iter num 30\n",
            "loss 5.452008917927742e-05 average time 0.017559231125051155 iter num 40\n",
            "loss 7.244018343044445e-05 average time 0.017448112160036545 iter num 50\n",
            "loss 6.317932275123894e-05 average time 0.01767748424999809 iter num 60\n",
            "loss 0.00012066471390426159 average time 0.01740337721429179 iter num 70\n",
            "loss 0.0004919799976050854 average time 0.017563258262498493 iter num 80\n",
            "loss 6.912093522259966e-05 average time 0.01749173994442875 iter num 90\n",
            "loss 5.129960482008755e-05 average time 0.01746234564000588 iter num 100\n",
            "loss 6.202418444445357e-05 average time 0.017033463900224886 iter num 10\n",
            "loss 5.285899169393815e-05 average time 0.01649870874998669 iter num 20\n",
            "loss 4.96406210004352e-05 average time 0.016562893099974947 iter num 30\n",
            "loss 5.2155653975205496e-05 average time 0.01656930899996496 iter num 40\n",
            "loss 5.9758916904684156e-05 average time 0.016679665239971653 iter num 50\n",
            "loss 8.900621469365433e-05 average time 0.016735426016642425 iter num 60\n",
            "loss 5.6014319852693006e-05 average time 0.016600620414257198 iter num 70\n",
            "loss 5.789465649286285e-05 average time 0.01658241387498265 iter num 80\n",
            "loss 5.585757389781065e-05 average time 0.016501134233324895 iter num 90\n",
            "loss 4.711364090326242e-05 average time 0.016430871159982416 iter num 100\n",
            "loss 0.0003843053709715605 average time 0.018118276900167984 iter num 10\n",
            "loss 3.0095034162513912e-05 average time 0.017370491800056696 iter num 20\n",
            "loss 3.762807318707928e-05 average time 0.016860917399996348 iter num 30\n",
            "loss 0.00010178638331126422 average time 0.016773358349951195 iter num 40\n",
            "loss 5.3555537306237966e-05 average time 0.01714272469991556 iter num 50\n",
            "loss 0.0004285113827791065 average time 0.016980751599930954 iter num 60\n",
            "loss 2.9454646210069768e-05 average time 0.016836456785651016 iter num 70\n",
            "loss 3.886114063789137e-05 average time 0.017072328699941863 iter num 80\n",
            "loss 6.905431655468419e-05 average time 0.017235325566626773 iter num 90\n",
            "loss 5.0068490963894874e-05 average time 0.017217673169971023 iter num 100\n",
            "loss 3.768245005630888e-05 average time 0.01740413299994543 iter num 10\n",
            "loss 6.377646059263498e-05 average time 0.017111480399944413 iter num 20\n",
            "loss 0.0002724608639255166 average time 0.01809669163333941 iter num 30\n",
            "loss 5.177461571292952e-05 average time 0.01756179660003454 iter num 40\n",
            "loss 3.710174860316329e-05 average time 0.017181548060052593 iter num 50\n",
            "loss 8.22301153675653e-05 average time 0.016978263583359875 iter num 60\n",
            "loss 0.00025510418345220387 average time 0.016977605757165292 iter num 70\n",
            "loss 3.3826869184849784e-05 average time 0.016882366325023667 iter num 80\n",
            "loss 4.807200821232982e-05 average time 0.016873452888881327 iter num 90\n",
            "loss 6.592031422769651e-05 average time 0.01686860144000093 iter num 100\n",
            "loss 0.0008294457802549005 average time 0.017192850999708752 iter num 10\n",
            "loss 0.00013254646910354495 average time 0.01639469289984845 iter num 20\n",
            "loss 6.550110992975533e-05 average time 0.017262831466572 iter num 30\n",
            "loss 3.510701935738325e-05 average time 0.017265648924899325 iter num 40\n",
            "loss 5.026162398280576e-05 average time 0.01699253023991332 iter num 50\n",
            "loss 3.492744144750759e-05 average time 0.017111035666615256 iter num 60\n",
            "loss 7.456356979673728e-05 average time 0.01720291388570071 iter num 70\n",
            "loss 3.3679159969324246e-05 average time 0.01702333551247648 iter num 80\n",
            "loss 8.080431871348992e-05 average time 0.016913493122198513 iter num 90\n",
            "loss 1.5551406249869615e-05 average time 0.01680569422998815 iter num 100\n",
            "loss 0.0013682943535968661 average time 0.01971799029997783 iter num 10\n",
            "loss 7.26644866517745e-05 average time 0.019482904049937133 iter num 20\n",
            "loss 0.0005086278542876244 average time 0.01826329416662702 iter num 30\n",
            "loss 4.683910810854286e-05 average time 0.017970453399948384 iter num 40\n",
            "loss 0.00045806230627931654 average time 0.018080114939930354 iter num 50\n",
            "loss 7.117942732293159e-05 average time 0.01794531361662545 iter num 60\n",
            "loss 5.120815694681369e-05 average time 0.01760288057139405 iter num 70\n",
            "loss 0.0002382706297794357 average time 0.017349951112487362 iter num 80\n",
            "loss 0.00017028315050993115 average time 0.01733679261109905 iter num 90\n",
            "loss 6.140337063698098e-05 average time 0.017268546649984274 iter num 100\n",
            "loss 8.669080852996558e-05 average time 0.01762269370001377 iter num 10\n",
            "loss 5.701942791347392e-05 average time 0.016805358550072924 iter num 20\n",
            "loss 0.00023344397777691483 average time 0.016572026000054998 iter num 30\n",
            "loss 2.8653394110733643e-05 average time 0.01642353822505811 iter num 40\n",
            "loss 4.846154115512036e-05 average time 0.01624517582002227 iter num 50\n",
            "loss 4.9515478167450055e-05 average time 0.016406063583341773 iter num 60\n",
            "loss 5.791164585389197e-05 average time 0.016467878128579676 iter num 70\n",
            "loss 0.00010470936103956774 average time 0.016488441700005296 iter num 80\n",
            "loss 0.0005074613727629185 average time 0.016386863144452944 iter num 90\n",
            "loss 5.1841892855009064e-05 average time 0.016537740900021164 iter num 100\n",
            "loss 4.53824432042893e-05 average time 0.017001954399984243 iter num 10\n",
            "loss 4.21491677116137e-05 average time 0.017030065449898758 iter num 20\n",
            "loss 0.0001236783864442259 average time 0.016535303499858857 iter num 30\n",
            "loss 6.0931401094421744e-05 average time 0.016570031199944425 iter num 40\n",
            "loss 4.415586590766907e-05 average time 0.016766417759972684 iter num 50\n",
            "loss 3.5872351872967556e-05 average time 0.016687264349987647 iter num 60\n",
            "loss 5.7766694226302207e-05 average time 0.016569579514297012 iter num 70\n",
            "loss 7.156599167501554e-05 average time 0.016589777587500975 iter num 80\n",
            "loss 2.8200454835314304e-05 average time 0.016513334055566195 iter num 90\n",
            "loss 2.7758642318076454e-05 average time 0.016435181189999638 iter num 100\n",
            "loss 3.845237006316893e-05 average time 0.017649941299805506 iter num 10\n",
            "loss 0.00012422326835803688 average time 0.01709123474993248 iter num 20\n",
            "loss 4.3000334699172527e-05 average time 0.016801826966699688 iter num 30\n",
            "loss 5.2495299314614385e-05 average time 0.016811325400021816 iter num 40\n",
            "loss 6.57553828204982e-05 average time 0.01672046705998582 iter num 50\n",
            "loss 5.848957516718656e-05 average time 0.01694450239995907 iter num 60\n",
            "loss 5.250091999187134e-05 average time 0.016934120828539432 iter num 70\n",
            "loss 5.376050467020832e-05 average time 0.01683549293749138 iter num 80\n",
            "loss 0.00010896436288021505 average time 0.016871912588865397 iter num 90\n",
            "loss 3.721557368407957e-05 average time 0.016956651539967425 iter num 100\n",
            "loss 3.467051647021435e-05 average time 0.018223859800218633 iter num 10\n",
            "loss 5.18388842465356e-05 average time 0.017331252800113363 iter num 20\n",
            "loss 0.00012232019798830152 average time 0.017199645966805597 iter num 30\n",
            "loss 1.82955373020377e-05 average time 0.017193647375074762 iter num 40\n",
            "loss 5.304934165906161e-05 average time 0.01699968124006773 iter num 50\n",
            "loss 2.642136678332463e-05 average time 0.016792841916700732 iter num 60\n",
            "loss 0.00012797850649803877 average time 0.016817035271443664 iter num 70\n",
            "loss 3.555347939254716e-05 average time 0.01681366787498746 iter num 80\n",
            "loss 5.495565346791409e-05 average time 0.01672235232221687 iter num 90\n",
            "loss 9.993678395403549e-05 average time 0.016621006279983704 iter num 100\n",
            "loss 5.997508924338035e-05 average time 0.018325265899966324 iter num 10\n",
            "loss 3.727632065420039e-05 average time 0.016935916099964744 iter num 20\n",
            "loss 5.081641938886605e-05 average time 0.0166405802333126 iter num 30\n",
            "loss 7.960089715197682e-05 average time 0.01690388444999371 iter num 40\n",
            "loss 5.2957169828005135e-05 average time 0.01688369003995831 iter num 50\n",
            "loss 2.969640991068445e-05 average time 0.01671311723331807 iter num 60\n",
            "loss 5.392821185523644e-05 average time 0.016752173114257727 iter num 70\n",
            "loss 7.471621211152524e-05 average time 0.016620421287461794 iter num 80\n",
            "loss 3.9479389670304954e-05 average time 0.016718915755528644 iter num 90\n",
            "loss 0.0003254686889704317 average time 0.016794942999986233 iter num 100\n",
            "loss 8.519609400536865e-05 average time 0.01715791509977862 iter num 10\n",
            "loss 4.748276842292398e-05 average time 0.016602249100014888 iter num 20\n",
            "loss 0.00010143021063413471 average time 0.016606376733246483 iter num 30\n",
            "loss 2.81931679637637e-05 average time 0.016588938699942445 iter num 40\n",
            "loss 9.974184649763629e-05 average time 0.01675809975997254 iter num 50\n",
            "loss 6.128600216470659e-05 average time 0.01663885836665031 iter num 60\n",
            "loss 7.571416790597141e-05 average time 0.016878745357111518 iter num 70\n",
            "loss 1.5370331311714835e-05 average time 0.016744236524982626 iter num 80\n",
            "loss 4.2263243813067675e-05 average time 0.01669796082219869 iter num 90\n",
            "loss 7.708424527663738e-05 average time 0.016696550229980858 iter num 100\n",
            "loss 9.564673382556066e-05 average time 0.017960418699931324 iter num 10\n",
            "loss 4.4476812036009505e-05 average time 0.017639704199973495 iter num 20\n",
            "loss 3.87809268431738e-05 average time 0.017777135166700948 iter num 30\n",
            "loss 4.7530826122965664e-05 average time 0.017542354250031165 iter num 40\n",
            "loss 3.7756220990559086e-05 average time 0.01810131102003652 iter num 50\n",
            "loss 0.00015977054135873914 average time 0.01827164278336871 iter num 60\n",
            "loss 5.6455963203916326e-05 average time 0.018010339857171077 iter num 70\n",
            "loss 4.973621980752796e-05 average time 0.01788720711250562 iter num 80\n",
            "loss 6.634373858105391e-05 average time 0.017711939233322482 iter num 90\n",
            "loss 0.0001489627902628854 average time 0.017596884220001812 iter num 100\n",
            "loss 5.8338708186056465e-05 average time 0.019048145999931876 iter num 10\n",
            "loss 0.0021235281601548195 average time 0.019737815999951634 iter num 20\n",
            "loss 7.492373697459698e-05 average time 0.01923342913332817 iter num 30\n",
            "loss 0.000478310976177454 average time 0.018502809775009156 iter num 40\n",
            "loss 5.904204590478912e-05 average time 0.0185381120600141 iter num 50\n",
            "loss 9.8509801318869e-05 average time 0.018315613116692477 iter num 60\n",
            "loss 4.1571671317797154e-05 average time 0.018133067928608526 iter num 70\n",
            "loss 7.98508626758121e-05 average time 0.018209016762511965 iter num 80\n",
            "loss 6.219532951945439e-05 average time 0.018044306277786543 iter num 90\n",
            "loss 8.173448441084474e-05 average time 0.017809147510015465 iter num 100\n",
            "loss 3.066265708184801e-05 average time 0.01720640680014185 iter num 10\n",
            "loss 6.907291390234604e-05 average time 0.01850861835014257 iter num 20\n",
            "loss 4.161848846706562e-05 average time 0.018235744166668157 iter num 30\n",
            "loss 7.425499643431976e-05 average time 0.01754668032497193 iter num 40\n",
            "loss 0.0004538091889116913 average time 0.01729832055996667 iter num 50\n",
            "loss 5.737834726460278e-05 average time 0.017180185966617502 iter num 60\n",
            "loss 0.00026605851599015296 average time 0.017693046228552185 iter num 70\n",
            "loss 6.487831706181169e-05 average time 0.017792593787487477 iter num 80\n",
            "loss 6.222580122994259e-05 average time 0.017655221988883973 iter num 90\n",
            "loss 0.0002561189467087388 average time 0.017738253040006383 iter num 100\n",
            "loss 0.00039499939884990454 average time 0.017364872799862496 iter num 10\n",
            "loss 6.070860763429664e-05 average time 0.01655326805007462 iter num 20\n",
            "loss 7.68321260693483e-05 average time 0.01663181543341731 iter num 30\n",
            "loss 6.274181941989809e-05 average time 0.016527438550087935 iter num 40\n",
            "loss 9.664901881478727e-05 average time 0.016436874800056102 iter num 50\n",
            "loss 2.5178518626489677e-05 average time 0.016307764883398097 iter num 60\n",
            "loss 0.00020541224512271583 average time 0.016290282714362548 iter num 70\n",
            "loss 2.8355405447655357e-05 average time 0.01634166602506184 iter num 80\n",
            "loss 3.231777373002842e-05 average time 0.016405769088921968 iter num 90\n",
            "loss 0.0003704007249325514 average time 0.016340199530050087 iter num 100\n",
            "loss 9.327528096036986e-05 average time 0.01951252779981587 iter num 10\n",
            "loss 6.542386836372316e-05 average time 0.019448477799733153 iter num 20\n",
            "loss 3.5629578633233905e-05 average time 0.018201582199768987 iter num 30\n",
            "loss 3.601692515076138e-05 average time 0.0179887118748411 iter num 40\n",
            "loss 5.699658140656538e-05 average time 0.01756706051992296 iter num 50\n",
            "loss 9.10514936549589e-05 average time 0.017286489716601256 iter num 60\n",
            "loss 3.7861111195525154e-05 average time 0.01704764831425304 iter num 70\n",
            "loss 4.402124977787025e-05 average time 0.017099305687474954 iter num 80\n",
            "loss 1.89235397556331e-05 average time 0.01710438272217895 iter num 90\n",
            "loss 0.00024397946253884584 average time 0.016965811869958998 iter num 100\n",
            "loss 2.9433667805278674e-05 average time 0.017108952399848932 iter num 10\n",
            "loss 4.355793134891428e-05 average time 0.016588280249925445 iter num 20\n",
            "loss 6.076944919186644e-05 average time 0.016428691233340943 iter num 30\n",
            "loss 2.9367016395553946e-05 average time 0.016287427400038725 iter num 40\n",
            "loss 2.019588282564655e-05 average time 0.016163455740042992 iter num 50\n",
            "loss 2.376320662733633e-05 average time 0.016156009949994162 iter num 60\n",
            "loss 8.398567297263071e-05 average time 0.016353349885698015 iter num 70\n",
            "loss 3.323507189634256e-05 average time 0.016258648999985324 iter num 80\n",
            "loss 5.314727968652733e-05 average time 0.016181925377754345 iter num 90\n",
            "loss 8.296689338749275e-05 average time 0.01619527632997233 iter num 100\n",
            "loss 4.549635195871815e-05 average time 0.016899342999931833 iter num 10\n",
            "loss 0.001048321952112019 average time 0.01690855434990226 iter num 20\n",
            "loss 7.311795343412086e-05 average time 0.016532614399875457 iter num 30\n",
            "loss 3.759916944545694e-05 average time 0.01664457864990254 iter num 40\n",
            "loss 9.948109072865918e-05 average time 0.01685143901990159 iter num 50\n",
            "loss 2.1856141756870784e-05 average time 0.017002488899925082 iter num 60\n",
            "loss 2.2892623746884055e-05 average time 0.01702224197133546 iter num 70\n",
            "loss 5.1869497838197276e-05 average time 0.01688849562494852 iter num 80\n",
            "loss 2.419583688606508e-05 average time 0.016790037844404852 iter num 90\n",
            "loss 0.00023074675118550658 average time 0.016671945259986387 iter num 100\n",
            "loss 6.0062338889110833e-05 average time 0.01671361730004719 iter num 10\n",
            "loss 7.309720240300521e-05 average time 0.01778522274998977 iter num 20\n",
            "loss 5.8180270571028814e-05 average time 0.017758138766748744 iter num 30\n",
            "loss 5.809297363157384e-05 average time 0.017666940375056582 iter num 40\n",
            "loss 1.86568868230097e-05 average time 0.0172896183800367 iter num 50\n",
            "loss 4.636506855604239e-05 average time 0.01721703670000352 iter num 60\n",
            "loss 5.769349809270352e-05 average time 0.017004425485720277 iter num 70\n",
            "loss 7.40892646717839e-05 average time 0.016824145275018056 iter num 80\n",
            "loss 6.358213431667536e-05 average time 0.01671710722223199 iter num 90\n",
            "loss 1.5144625649554655e-05 average time 0.016815236059983363 iter num 100\n",
            "loss 4.1522849642205983e-05 average time 0.01826881790002517 iter num 10\n",
            "loss 0.0007686239550821483 average time 0.01708789090002938 iter num 20\n",
            "loss 7.243516301969066e-05 average time 0.01660195940006209 iter num 30\n",
            "loss 8.398743375437334e-05 average time 0.01702523542498966 iter num 40\n",
            "loss 4.3636344344122335e-05 average time 0.016795532820015068 iter num 50\n",
            "loss 2.5997500415542163e-05 average time 0.016671903016701132 iter num 60\n",
            "loss 7.162502151913941e-05 average time 0.01658330607143788 iter num 70\n",
            "loss 9.406842582393438e-05 average time 0.016996768862486532 iter num 80\n",
            "loss 4.180152609478682e-05 average time 0.016860298522189825 iter num 90\n",
            "loss 3.9159531297627836e-05 average time 0.01672047469998688 iter num 100\n",
            "loss 0.00010046881652669981 average time 0.01711597020002955 iter num 10\n",
            "loss 1.8924240066553466e-05 average time 0.01792520890007836 iter num 20\n",
            "loss 4.6668727009091526e-05 average time 0.017265817166692916 iter num 30\n",
            "loss 3.568716419977136e-05 average time 0.01686385022496779 iter num 40\n",
            "loss 9.793379285838455e-05 average time 0.016650560699963533 iter num 50\n",
            "loss 0.0001269759377464652 average time 0.01681855329999659 iter num 60\n",
            "loss 4.2262679926352575e-05 average time 0.01664656518571844 iter num 70\n",
            "loss 2.9631724828504957e-05 average time 0.01650950043750754 iter num 80\n",
            "loss 0.0002959236444439739 average time 0.01671240708889551 iter num 90\n",
            "loss 2.1859317712369375e-05 average time 0.01664777286001481 iter num 100\n",
            "loss 5.5272801546379924e-05 average time 0.01858187560010265 iter num 10\n",
            "loss 3.425546674407087e-05 average time 0.01710736100003487 iter num 20\n",
            "loss 0.0003041727177333087 average time 0.017123545466711222 iter num 30\n",
            "loss 6.776759983040392e-05 average time 0.017094504775013775 iter num 40\n",
            "loss 0.0003034278051927686 average time 0.01706023203996665 iter num 50\n",
            "loss 3.055375054827891e-05 average time 0.017097356300003714 iter num 60\n",
            "loss 0.0004595000355038792 average time 0.01713769645712091 iter num 70\n",
            "loss 0.000222841787035577 average time 0.016963730949976254 iter num 80\n",
            "loss 3.439806096139364e-05 average time 0.01685171188886064 iter num 90\n",
            "loss 8.101200364762917e-05 average time 0.016844739839971225 iter num 100\n",
            "loss 3.9234662835951895e-05 average time 0.01871575329996631 iter num 10\n",
            "loss 6.585194205399603e-05 average time 0.017359770399980334 iter num 20\n",
            "loss 4.004092625109479e-05 average time 0.0168202006999915 iter num 30\n",
            "loss 5.9476627939147875e-05 average time 0.016927764474962713 iter num 40\n",
            "loss 5.554320159717463e-05 average time 0.017061370800001897 iter num 50\n",
            "loss 4.236701352056116e-05 average time 0.01682456806667384 iter num 60\n",
            "loss 3.974451465182938e-05 average time 0.016644768571482668 iter num 70\n",
            "loss 3.601609205361456e-05 average time 0.0166688742125757 iter num 80\n",
            "loss 3.643277887022123e-05 average time 0.016731617200073542 iter num 90\n",
            "loss 0.0010705433087423444 average time 0.0166963433800629 iter num 100\n",
            "loss 3.0499282729579136e-05 average time 0.016965402100140636 iter num 10\n",
            "loss 0.00011711483239196241 average time 0.016500420200100053 iter num 20\n",
            "loss 0.0006274023908190429 average time 0.016773460633460975 iter num 30\n",
            "loss 5.1258997700642794e-05 average time 0.016488169750073212 iter num 40\n",
            "loss 7.650952466065064e-05 average time 0.01631831766007963 iter num 50\n",
            "loss 0.0007078586495481431 average time 0.016561423250095686 iter num 60\n",
            "loss 4.05338651034981e-05 average time 0.01690708705724059 iter num 70\n",
            "loss 0.00015008283662609756 average time 0.01684555802509067 iter num 80\n",
            "loss 1.7224383555003442e-05 average time 0.016755555622310365 iter num 90\n",
            "loss 3.449513314990327e-05 average time 0.01669370180009537 iter num 100\n",
            "loss 0.0001740847364999354 average time 0.018320278099872668 iter num 10\n",
            "loss 3.381975693628192e-05 average time 0.017615330899934632 iter num 20\n",
            "loss 6.68774955556728e-05 average time 0.01699539266658879 iter num 30\n",
            "loss 6.411086360458285e-05 average time 0.01684410864995698 iter num 40\n",
            "loss 0.00010367214417783543 average time 0.016833559419992525 iter num 50\n",
            "loss 5.483004861162044e-05 average time 0.01696424350000901 iter num 60\n",
            "loss 0.0002695396251510829 average time 0.016977834457117882 iter num 70\n",
            "loss 6.287782161962241e-05 average time 0.0170679119124884 iter num 80\n",
            "loss 8.433423499809578e-05 average time 0.0173390245333394 iter num 90\n",
            "loss 2.3126494852476753e-05 average time 0.0172886769500019 iter num 100\n",
            "loss 3.674832623801194e-05 average time 0.017800286900092034 iter num 10\n",
            "loss 8.183366298908368e-05 average time 0.018422452100139708 iter num 20\n",
            "loss 4.6981989726191387e-05 average time 0.017778065600153544 iter num 30\n",
            "loss 2.1486706828000024e-05 average time 0.01831428997511466 iter num 40\n",
            "loss 4.273802551324479e-05 average time 0.01832876586004204 iter num 50\n",
            "loss 0.0008377785561606288 average time 0.018121156933390618 iter num 60\n",
            "loss 9.803793363971636e-05 average time 0.017996963442900388 iter num 70\n",
            "loss 5.686428630724549e-05 average time 0.017885277600032622 iter num 80\n",
            "loss 6.970480171730742e-05 average time 0.017953173733349103 iter num 90\n",
            "loss 4.265455936547369e-05 average time 0.017747695970001587 iter num 100\n",
            "loss 6.23670348431915e-05 average time 0.018830651599819247 iter num 10\n",
            "loss 5.340667848940939e-05 average time 0.017361807099950964 iter num 20\n",
            "loss 3.032842323591467e-05 average time 0.01735806029998154 iter num 30\n",
            "loss 0.00014439356164075434 average time 0.017109258374966886 iter num 40\n",
            "loss 3.5841279895976186e-05 average time 0.016823574979953265 iter num 50\n",
            "loss 2.3105105356080458e-05 average time 0.016814195949958352 iter num 60\n",
            "loss 0.0007330544758588076 average time 0.01697345097136349 iter num 70\n",
            "loss 5.119365232530981e-05 average time 0.016883727649963022 iter num 80\n",
            "loss 7.431042467942461e-05 average time 0.016765020722201977 iter num 90\n",
            "loss 3.1452895200345665e-05 average time 0.016733876419993975 iter num 100\n",
            "loss 4.464664380066097e-05 average time 0.01949360360013088 iter num 10\n",
            "loss 0.001227284548804164 average time 0.017616057500117677 iter num 20\n",
            "loss 2.8251466574147344e-05 average time 0.01697819923338102 iter num 30\n",
            "loss 5.0804021157091483e-05 average time 0.01681564122504824 iter num 40\n",
            "loss 0.00011612945672823116 average time 0.01693450834007308 iter num 50\n",
            "loss 0.0006384217413142323 average time 0.017089194516726518 iter num 60\n",
            "loss 8.05436066002585e-05 average time 0.01691177135718525 iter num 70\n",
            "loss 6.639835191890597e-05 average time 0.016766834625036607 iter num 80\n",
            "loss 0.00015283933316823095 average time 0.016742171788903054 iter num 90\n",
            "loss 7.489996642107144e-05 average time 0.016634111900011704 iter num 100\n",
            "loss 3.556563751772046e-05 average time 0.017637526400176285 iter num 10\n",
            "loss 0.00014857643691357225 average time 0.01713321590000305 iter num 20\n",
            "loss 3.165541420457885e-05 average time 0.0166216713333597 iter num 30\n",
            "loss 1.4004226613906212e-05 average time 0.016379731725055535 iter num 40\n",
            "loss 5.132079968461767e-05 average time 0.01633053198005655 iter num 50\n",
            "loss 0.00027889106422662735 average time 0.01682678595005503 iter num 60\n",
            "loss 0.0005232860567048192 average time 0.017169139557154267 iter num 70\n",
            "loss 0.0008034591446630657 average time 0.017147938699997665 iter num 80\n",
            "loss 0.00018017149704974145 average time 0.017005100588903588 iter num 90\n",
            "loss 9.930448140949011e-05 average time 0.017133019060020162 iter num 100\n",
            "loss 6.133670103736222e-05 average time 0.017704123099883874 iter num 10\n",
            "loss 7.402521441690624e-05 average time 0.01686192659999506 iter num 20\n",
            "loss 8.233813423430547e-05 average time 0.017142131266670427 iter num 30\n",
            "loss 6.649508577538654e-05 average time 0.01765175824996277 iter num 40\n",
            "loss 5.121586218592711e-05 average time 0.01739481913999043 iter num 50\n",
            "loss 4.8032034101197496e-05 average time 0.01714292946664197 iter num 60\n",
            "loss 6.356154335662723e-05 average time 0.016982640571391778 iter num 70\n",
            "loss 4.377111326903105e-05 average time 0.017116434874958487 iter num 80\n",
            "loss 2.706491795834154e-05 average time 0.017024985611068487 iter num 90\n",
            "loss 3.8667029002681375e-05 average time 0.017111778469952696 iter num 100\n",
            "loss 4.062934749526903e-05 average time 0.020362902200031386 iter num 10\n",
            "loss 0.00014560011913999915 average time 0.018744746599941207 iter num 20\n",
            "loss 0.000644440355245024 average time 0.018048500233271626 iter num 30\n",
            "loss 0.00022782593441661447 average time 0.018163658699904772 iter num 40\n",
            "loss 0.00022264810104388744 average time 0.01813218645993402 iter num 50\n",
            "loss 5.14512685185764e-05 average time 0.017993261499926423 iter num 60\n",
            "loss 3.656707485788502e-05 average time 0.01768477157138477 iter num 70\n",
            "loss 3.131118501187302e-05 average time 0.017407105324957685 iter num 80\n",
            "loss 7.838709279894829e-05 average time 0.017275939277755645 iter num 90\n",
            "loss 4.4748245272785425e-05 average time 0.01728330299997651 iter num 100\n",
            "loss 3.300200114608742e-05 average time 0.016723143699891807 iter num 10\n",
            "loss 2.1053057935205288e-05 average time 0.016749308149928765 iter num 20\n",
            "loss 2.9341961635509506e-05 average time 0.017200654499993105 iter num 30\n",
            "loss 4.346331479609944e-05 average time 0.017001384899958793 iter num 40\n",
            "loss 0.00039797203498892486 average time 0.01674097699997219 iter num 50\n",
            "loss 5.8128505770582706e-05 average time 0.01666530999996212 iter num 60\n",
            "loss 7.660123083041981e-05 average time 0.016648853785656163 iter num 70\n",
            "loss 5.2140294428681955e-05 average time 0.016589938012452878 iter num 80\n",
            "loss 2.4570648747612722e-05 average time 0.01651246112217753 iter num 90\n",
            "loss 0.00011834426550194621 average time 0.01649171552997359 iter num 100\n",
            "loss 0.00016243610298261046 average time 0.01700576089979222 iter num 10\n",
            "loss 8.640483429189771e-05 average time 0.016407690699907107 iter num 20\n",
            "loss 5.4399370128521696e-05 average time 0.016115869100000662 iter num 30\n",
            "loss 1.9629884263849817e-05 average time 0.01607126610006162 iter num 40\n",
            "loss 4.019681364297867e-05 average time 0.01624156228004722 iter num 50\n",
            "loss 4.4012289436068386e-05 average time 0.016183727149988652 iter num 60\n",
            "loss 3.9116439438657835e-05 average time 0.016289251485730866 iter num 70\n",
            "loss 2.819349720084574e-05 average time 0.016256605187493278 iter num 80\n",
            "loss 3.512454350129701e-05 average time 0.01626561739998983 iter num 90\n",
            "loss 4.625819201464765e-05 average time 0.016212694619971445 iter num 100\n",
            "loss 5.208213769947179e-05 average time 0.016604994099907344 iter num 10\n",
            "loss 4.1119543311651796e-05 average time 0.016704401749984756 iter num 20\n",
            "loss 3.4164546377724037e-05 average time 0.01736844936667694 iter num 30\n",
            "loss 3.7915662687737495e-05 average time 0.016936097250004424 iter num 40\n",
            "loss 3.0065877581364475e-05 average time 0.017003328999981023 iter num 50\n",
            "loss 3.455243131611496e-05 average time 0.01697053766662672 iter num 60\n",
            "loss 0.00025162851670756936 average time 0.016765093857104927 iter num 70\n",
            "loss 5.338995106285438e-05 average time 0.016624210474935806 iter num 80\n",
            "loss 4.612801785697229e-05 average time 0.016613974944367428 iter num 90\n",
            "loss 0.00010710558126447722 average time 0.01682651327992062 iter num 100\n",
            "loss 4.4477499614004046e-05 average time 0.017851886700009346 iter num 10\n",
            "loss 0.00010544726683292538 average time 0.017646386400065238 iter num 20\n",
            "loss 3.267250576755032e-05 average time 0.017808072533383287 iter num 30\n",
            "loss 4.047971742693335e-05 average time 0.017560573750029108 iter num 40\n",
            "loss 6.749579188181087e-05 average time 0.017279004720039667 iter num 50\n",
            "loss 0.00034669239539653063 average time 0.01704948566666644 iter num 60\n",
            "loss 3.635128814494237e-05 average time 0.016987118085697667 iter num 70\n",
            "loss 5.3600506362272426e-05 average time 0.01704741712497935 iter num 80\n",
            "loss 0.00030304756364785135 average time 0.016999717844434294 iter num 90\n",
            "loss 0.00010885074152611196 average time 0.01695317569998224 iter num 100\n",
            "loss 3.479284350760281e-05 average time 0.01861621650004963 iter num 10\n",
            "loss 6.855276296846569e-05 average time 0.01829168795006808 iter num 20\n",
            "loss 3.266335988882929e-05 average time 0.017421998600063184 iter num 30\n",
            "loss 4.996942152502015e-05 average time 0.017072839150023354 iter num 40\n",
            "loss 0.00037655216874554753 average time 0.01718708450001941 iter num 50\n",
            "loss 6.914907862665132e-05 average time 0.017544180183343392 iter num 60\n",
            "loss 7.703310257056728e-05 average time 0.017418668600034184 iter num 70\n",
            "loss 0.0002887594164349139 average time 0.017364064412504376 iter num 80\n",
            "loss 8.921111293602735e-05 average time 0.017341467322229517 iter num 90\n",
            "loss 4.563055335893296e-05 average time 0.017260571160022664 iter num 100\n",
            "loss 3.5573226341512054e-05 average time 0.017110479999973904 iter num 10\n",
            "loss 5.9619054809445515e-05 average time 0.01673753085001408 iter num 20\n",
            "loss 7.41677067708224e-05 average time 0.016510445633321068 iter num 30\n",
            "loss 0.00014826342521701008 average time 0.016388508149998416 iter num 40\n",
            "loss 5.056181180407293e-05 average time 0.016504038020011647 iter num 50\n",
            "loss 5.461783803184517e-05 average time 0.016423831583339658 iter num 60\n",
            "loss 3.119654138572514e-05 average time 0.01631718411428145 iter num 70\n",
            "loss 2.8302893042564392e-05 average time 0.016300492424988988 iter num 80\n",
            "loss 5.678316665580496e-05 average time 0.016244530322213298 iter num 90\n",
            "loss 1.3983886674395762e-05 average time 0.016340712809987962 iter num 100\n",
            "loss 4.388431625557132e-05 average time 0.016968567700041605 iter num 10\n",
            "loss 0.0001184753273264505 average time 0.01717039120003392 iter num 20\n",
            "loss 6.978593592066318e-05 average time 0.016944568066689196 iter num 30\n",
            "loss 0.0004476937174331397 average time 0.017079014775026734 iter num 40\n",
            "loss 0.00012284822878427804 average time 0.01710391234004419 iter num 50\n",
            "loss 0.0011334901209920645 average time 0.016860613283385343 iter num 60\n",
            "loss 5.3189949539955705e-05 average time 0.016764046957177925 iter num 70\n",
            "loss 4.4750460801878944e-05 average time 0.01689883246252748 iter num 80\n",
            "loss 0.0001293850946240127 average time 0.016948635511087357 iter num 90\n",
            "loss 6.509572267532349e-05 average time 0.01687384955998823 iter num 100\n",
            "loss 0.000995580106973648 average time 0.01665913400001955 iter num 10\n",
            "loss 3.724271300598048e-05 average time 0.017770031849977386 iter num 20\n",
            "loss 2.276237319165375e-05 average time 0.017853405133306903 iter num 30\n",
            "loss 3.388827826711349e-05 average time 0.0174032518499871 iter num 40\n",
            "loss 6.068889706511982e-05 average time 0.017163789460009866 iter num 50\n",
            "loss 5.3379524615593255e-05 average time 0.01701387310001034 iter num 60\n",
            "loss 7.571850437670946e-05 average time 0.01697847138572927 iter num 70\n",
            "loss 9.651909931562841e-05 average time 0.01690001288752683 iter num 80\n",
            "loss 2.621523708512541e-05 average time 0.0167648869444545 iter num 90\n",
            "loss 2.4864310034899972e-05 average time 0.016662125860020752 iter num 100\n",
            "loss 3.594428562792018e-05 average time 0.016484449099789345 iter num 10\n",
            "loss 4.675643140217289e-05 average time 0.01620335759989757 iter num 20\n",
            "loss 3.032970016647596e-05 average time 0.016449206233210133 iter num 30\n",
            "loss 6.880306318635121e-05 average time 0.016364437549896138 iter num 40\n",
            "loss 7.167019793996587e-05 average time 0.016273099959907996 iter num 50\n",
            "loss 2.0882527678622864e-05 average time 0.01626569369994589 iter num 60\n",
            "loss 4.177265509497374e-05 average time 0.016328346442826713 iter num 70\n",
            "loss 3.916001514880918e-05 average time 0.016332431787486713 iter num 80\n",
            "loss 4.083503154106438e-05 average time 0.01634240603332526 iter num 90\n",
            "loss 4.532809543889016e-05 average time 0.016380032300021413 iter num 100\n",
            "loss 5.9698613767977804e-05 average time 0.01745790389995818 iter num 10\n",
            "loss 3.124778959318064e-05 average time 0.01763538534996769 iter num 20\n",
            "loss 4.819456808036193e-05 average time 0.017041041400079848 iter num 30\n",
            "loss 4.977178468834609e-05 average time 0.016826489700042656 iter num 40\n",
            "loss 0.0008868254371918738 average time 0.01703964921998704 iter num 50\n",
            "loss 8.672199328429997e-05 average time 0.01708262915000584 iter num 60\n",
            "loss 3.9205253415275365e-05 average time 0.016947770600030967 iter num 70\n",
            "loss 0.0009045975748449564 average time 0.016804500312525762 iter num 80\n",
            "loss 5.451044489745982e-05 average time 0.016988410711140507 iter num 90\n",
            "loss 5.463491834234446e-05 average time 0.016981727640022655 iter num 100\n",
            "loss 5.929534381721169e-05 average time 0.01812450239995087 iter num 10\n",
            "loss 5.539363337447867e-05 average time 0.01859770675000618 iter num 20\n",
            "loss 0.00014611972437705845 average time 0.01864468919996701 iter num 30\n",
            "loss 3.404088056413457e-05 average time 0.018457056374973035 iter num 40\n",
            "loss 0.00017452298197895288 average time 0.017980804679973518 iter num 50\n",
            "loss 1.7600443243281916e-05 average time 0.017632245150010325 iter num 60\n",
            "loss 6.388152542058378e-05 average time 0.017467165771436807 iter num 70\n",
            "loss 6.890784425195307e-05 average time 0.01724648978749883 iter num 80\n",
            "loss 9.317725925939158e-05 average time 0.017555218788887335 iter num 90\n",
            "loss 6.499294249806553e-05 average time 0.017775569640025423 iter num 100\n",
            "loss 3.433401070651598e-05 average time 0.017010246900008498 iter num 10\n",
            "loss 4.376330252853222e-05 average time 0.01667321679997258 iter num 20\n",
            "loss 4.3159139750059694e-05 average time 0.01679724599992672 iter num 30\n",
            "loss 3.327606100356206e-05 average time 0.016564207124952192 iter num 40\n",
            "loss 2.8000758902635425e-05 average time 0.01638975177993416 iter num 50\n",
            "loss 6.852656224509701e-05 average time 0.01658658983327162 iter num 60\n",
            "loss 0.0002551421639509499 average time 0.01665878639991466 iter num 70\n",
            "loss 2.3130291083361953e-05 average time 0.016998745512421466 iter num 80\n",
            "loss 0.0006865240866318345 average time 0.017083959511031328 iter num 90\n",
            "loss 3.6666900996351615e-05 average time 0.0171168458799184 iter num 100\n",
            "loss 3.789230322581716e-05 average time 0.018543453799975396 iter num 10\n",
            "loss 4.581886969390325e-05 average time 0.017483425049977085 iter num 20\n",
            "loss 5.297330062603578e-05 average time 0.016900034933284284 iter num 30\n",
            "loss 2.5399349397048354e-05 average time 0.016590887624965946 iter num 40\n",
            "loss 6.979225145187229e-05 average time 0.016842186520007088 iter num 50\n",
            "loss 4.810782411368564e-05 average time 0.016714119916681133 iter num 60\n",
            "loss 0.00022749061463400722 average time 0.01660455728573912 iter num 70\n",
            "loss 4.0665592678124085e-05 average time 0.016620109774999038 iter num 80\n",
            "loss 3.911956082447432e-05 average time 0.016699084422220442 iter num 90\n",
            "loss 0.0008206479833461344 average time 0.0165988996499982 iter num 100\n",
            "loss 3.763688437175006e-05 average time 0.016727700700084825 iter num 10\n",
            "loss 7.536471093771979e-05 average time 0.01775102465003329 iter num 20\n",
            "loss 4.5632721594301984e-05 average time 0.01819083403333934 iter num 30\n",
            "loss 4.6867633500369266e-05 average time 0.017684384575022704 iter num 40\n",
            "loss 5.0669161282712594e-05 average time 0.017326221320054173 iter num 50\n",
            "loss 0.00017345428932458162 average time 0.017239363800035788 iter num 60\n",
            "loss 1.8366845324635506e-05 average time 0.01732160471431468 iter num 70\n",
            "loss 7.584481500089169e-05 average time 0.01717005566252965 iter num 80\n",
            "loss 2.6359412004239857e-05 average time 0.01705239215556907 iter num 90\n",
            "loss 4.4581363908946514e-05 average time 0.017251934260011693 iter num 100\n",
            "loss 2.6438914574100636e-05 average time 0.016915241300102933 iter num 10\n",
            "loss 3.5247354389866814e-05 average time 0.01631899349995365 iter num 20\n",
            "loss 2.8169464712846093e-05 average time 0.016125772033228715 iter num 30\n",
            "loss 3.2553063647355884e-05 average time 0.016157909574963013 iter num 40\n",
            "loss 3.771777483052574e-05 average time 0.016100755899951764 iter num 50\n",
            "loss 5.229080852586776e-05 average time 0.01605999923329667 iter num 60\n",
            "loss 4.1229897760786116e-05 average time 0.01598925869996362 iter num 70\n",
            "loss 7.461740460712463e-05 average time 0.016032354474987187 iter num 80\n",
            "loss 3.8878970372024924e-05 average time 0.016042681988872372 iter num 90\n",
            "loss 2.584040157671552e-05 average time 0.016007797479996953 iter num 100\n",
            "loss 0.0007450521807186306 average time 0.016681625100045495 iter num 10\n",
            "loss 2.3771917767589912e-05 average time 0.01656778410001607 iter num 20\n",
            "loss 2.7788888473878615e-05 average time 0.01669468530002026 iter num 30\n",
            "loss 1.879859519249294e-05 average time 0.016476062150013605 iter num 40\n",
            "loss 0.0006445742328651249 average time 0.016315485580016685 iter num 50\n",
            "loss 0.00015279225772246718 average time 0.016513578433341537 iter num 60\n",
            "loss 3.211411603842862e-05 average time 0.016530400257150697 iter num 70\n",
            "loss 4.099503348697908e-05 average time 0.016467203199999857 iter num 80\n",
            "loss 4.147783693042584e-05 average time 0.016386576255556267 iter num 90\n",
            "loss 3.084394847974181e-05 average time 0.016470164250004016 iter num 100\n",
            "loss 2.4142127585946582e-05 average time 0.01714546399998653 iter num 10\n",
            "loss 7.467640534741804e-05 average time 0.016620128900058262 iter num 20\n",
            "loss 4.833584898733534e-05 average time 0.016818899133340892 iter num 30\n",
            "loss 4.313891622587107e-05 average time 0.016851878374995976 iter num 40\n",
            "loss 7.998313958523795e-05 average time 0.016656488640019233 iter num 50\n",
            "loss 2.6906898710876703e-05 average time 0.016580436200047188 iter num 60\n",
            "loss 2.1210960767348297e-05 average time 0.016600310514292817 iter num 70\n",
            "loss 3.324692079331726e-05 average time 0.01654552055001659 iter num 80\n",
            "loss 4.092064773431048e-05 average time 0.016452936422259274 iter num 90\n",
            "loss 2.7876934836967848e-05 average time 0.016386876900041897 iter num 100\n",
            "loss 8.59817155287601e-05 average time 0.019130249299996648 iter num 10\n",
            "loss 8.015293133212253e-05 average time 0.0181410443999539 iter num 20\n",
            "loss 7.453311991412193e-05 average time 0.01743638783324665 iter num 30\n",
            "loss 3.949419624404982e-05 average time 0.017020959149976988 iter num 40\n",
            "loss 6.843003939138725e-05 average time 0.017052631660008047 iter num 50\n",
            "loss 0.00010652795754140243 average time 0.01698051041666986 iter num 60\n",
            "loss 4.212387284496799e-05 average time 0.016846884442877907 iter num 70\n",
            "loss 0.0002367811684962362 average time 0.016729959862527722 iter num 80\n",
            "loss 0.0002873227058444172 average time 0.016947544222259442 iter num 90\n",
            "loss 4.8430458264192566e-05 average time 0.016985965140011102 iter num 100\n",
            "loss 5.557881013373844e-05 average time 0.018483481600196684 iter num 10\n",
            "loss 2.6528650778345764e-05 average time 0.017157920950103288 iter num 20\n",
            "loss 6.172538996906951e-05 average time 0.017212055833442718 iter num 30\n",
            "loss 4.6809254854451865e-05 average time 0.0169156698000279 iter num 40\n",
            "loss 2.7602991394815035e-05 average time 0.016817502039993996 iter num 50\n",
            "loss 3.306502912892029e-05 average time 0.01689344303335929 iter num 60\n",
            "loss 6.569013930857182e-05 average time 0.01705711498574861 iter num 70\n",
            "loss 6.615475285798311e-05 average time 0.016960896150021654 iter num 80\n",
            "loss 3.8856214814586565e-05 average time 0.016824722311119127 iter num 90\n",
            "loss 7.356373680522665e-05 average time 0.016729737900022884 iter num 100\n",
            "loss 3.278470830991864e-05 average time 0.018391950400018686 iter num 10\n",
            "loss 5.766217509517446e-05 average time 0.01798504884995964 iter num 20\n",
            "loss 3.117294909316115e-05 average time 0.01755996469995201 iter num 30\n",
            "loss 5.053519271314144e-05 average time 0.017261057924997658 iter num 40\n",
            "loss 6.4161627960857e-05 average time 0.01765438735998032 iter num 50\n",
            "loss 4.355284181656316e-05 average time 0.017358639266649333 iter num 60\n",
            "loss 0.00010848998499568552 average time 0.017153936428556855 iter num 70\n",
            "loss 4.5337608753470704e-05 average time 0.017189289812472454 iter num 80\n",
            "loss 7.527539855800569e-05 average time 0.017064441266645896 iter num 90\n",
            "loss 2.9490101951523684e-05 average time 0.016960249929989003 iter num 100\n",
            "loss 4.7826539230300114e-05 average time 0.016632449599819667 iter num 10\n",
            "loss 0.00027693872107192874 average time 0.017719973049861438 iter num 20\n",
            "loss 7.363634358625859e-05 average time 0.017407422299887305 iter num 30\n",
            "loss 1.1733101928257383e-05 average time 0.017006398424905457 iter num 40\n",
            "loss 4.2873733036685735e-05 average time 0.016971128519926423 iter num 50\n",
            "loss 5.206483547226526e-05 average time 0.017122109433269847 iter num 60\n",
            "loss 0.00010559715883573517 average time 0.017140935514232427 iter num 70\n",
            "loss 3.604583616834134e-05 average time 0.01696073129994602 iter num 80\n",
            "loss 2.350242175452877e-05 average time 0.017031197977727668 iter num 90\n",
            "loss 4.0101011109072715e-05 average time 0.017112315869944723 iter num 100\n",
            "loss 4.940699363942258e-05 average time 0.01662775819995659 iter num 10\n",
            "loss 5.80081032239832e-05 average time 0.01618501540001489 iter num 20\n",
            "loss 1.205887929245364e-05 average time 0.01634461326663465 iter num 30\n",
            "loss 4.1040886571863666e-05 average time 0.016379684224966697 iter num 40\n",
            "loss 1.1273003110545687e-05 average time 0.016309780499996124 iter num 50\n",
            "loss 6.263288378249854e-05 average time 0.01634078370000983 iter num 60\n",
            "loss 3.139470572932623e-05 average time 0.016349995700017772 iter num 70\n",
            "loss 3.840337012661621e-05 average time 0.016559300799997345 iter num 80\n",
            "loss 6.311349716270342e-05 average time 0.01652646797775661 iter num 90\n",
            "loss 3.790171831496991e-05 average time 0.016463342069955617 iter num 100\n",
            "loss 3.2721283787395805e-05 average time 0.017480822299876308 iter num 10\n",
            "loss 9.227192640537396e-05 average time 0.01720526419990165 iter num 20\n",
            "loss 6.946407665964216e-05 average time 0.01681076069996076 iter num 30\n",
            "loss 2.4806548026390374e-05 average time 0.016569067175009878 iter num 40\n",
            "loss 0.00017235951963812113 average time 0.016609170579995405 iter num 50\n",
            "loss 7.58497481001541e-05 average time 0.016657720250032072 iter num 60\n",
            "loss 3.186508547514677e-05 average time 0.016559004900045693 iter num 70\n",
            "loss 3.35613040078897e-05 average time 0.016496607325041168 iter num 80\n",
            "loss 7.972414459800348e-05 average time 0.0164762490222731 iter num 90\n",
            "loss 2.7763111575040966e-05 average time 0.01654107138004292 iter num 100\n",
            "loss 5.893757042940706e-05 average time 0.016766697000184648 iter num 10\n",
            "loss 0.00114145886618644 average time 0.017135999250149324 iter num 20\n",
            "loss 4.593819903675467e-05 average time 0.01679837330002556 iter num 30\n",
            "loss 2.9270424420246854e-05 average time 0.016575240325005326 iter num 40\n",
            "loss 2.6046851417049766e-05 average time 0.016738187160026428 iter num 50\n",
            "loss 9.083107579499483e-05 average time 0.016637481150019083 iter num 60\n",
            "loss 2.09093759622192e-05 average time 0.016545664685704002 iter num 70\n",
            "loss 0.00022616039495915174 average time 0.01701180088749652 iter num 80\n",
            "loss 4.1936182242352515e-05 average time 0.017084184922219317 iter num 90\n",
            "loss 3.2964158890536055e-05 average time 0.01707050863999939 iter num 100\n",
            "loss 3.511238901410252e-05 average time 0.019244191999950998 iter num 10\n",
            "loss 2.255599247291684e-05 average time 0.017617789300084043 iter num 20\n",
            "loss 5.903458077227697e-05 average time 0.017340659700100028 iter num 30\n",
            "loss 5.248737215879373e-05 average time 0.017125765600030717 iter num 40\n",
            "loss 3.939644739148207e-05 average time 0.017694464640007936 iter num 50\n",
            "loss 0.00026423740200698376 average time 0.017395159483354898 iter num 60\n",
            "loss 0.0002361721999477595 average time 0.01725047865718027 iter num 70\n",
            "loss 7.195290527306497e-05 average time 0.01723980828751337 iter num 80\n",
            "loss 0.00011106868623755872 average time 0.01727704582224558 iter num 90\n",
            "loss 2.6231959054712206e-05 average time 0.01709842265001498 iter num 100\n",
            "loss 3.7956055166432634e-05 average time 0.01711516590003157 iter num 10\n",
            "loss 2.6677305868361145e-05 average time 0.017106703049967108 iter num 20\n",
            "loss 2.631689676491078e-05 average time 0.017323199133382636 iter num 30\n",
            "loss 3.080059832427651e-05 average time 0.016927843724988633 iter num 40\n",
            "loss 0.00019657539087347686 average time 0.016934004060003643 iter num 50\n",
            "loss 0.0001203545689349994 average time 0.017144508116659078 iter num 60\n",
            "loss 3.560518234735355e-05 average time 0.01767631617141368 iter num 70\n",
            "loss 0.00010103659587912261 average time 0.017427979637500358 iter num 80\n",
            "loss 9.038795542437583e-05 average time 0.017421512588882453 iter num 90\n",
            "loss 0.0013558596838265657 average time 0.017492201039985958 iter num 100\n",
            "loss 3.05931425828021e-05 average time 0.017185824399984995 iter num 10\n",
            "loss 2.809134457493201e-05 average time 0.017597567450093266 iter num 20\n",
            "loss 0.00015194850857369602 average time 0.017628335966704375 iter num 30\n",
            "loss 5.6341556046390906e-05 average time 0.017986094625007353 iter num 40\n",
            "loss 9.306771244155243e-05 average time 0.01754798022000614 iter num 50\n",
            "loss 1.8062753952108324e-05 average time 0.01731791463331926 iter num 60\n",
            "loss 3.802801438723691e-05 average time 0.0172530483571271 iter num 70\n",
            "loss 0.0002503220457583666 average time 0.017337637674972938 iter num 80\n",
            "loss 7.306998304557055e-05 average time 0.017165166111095056 iter num 90\n",
            "loss 1.3719251001020893e-05 average time 0.01704122590999759 iter num 100\n",
            "loss 3.301326069049537e-05 average time 0.02020526009991954 iter num 10\n",
            "loss 4.127873035031371e-05 average time 0.018651538799895208 iter num 20\n",
            "loss 7.161965186242014e-05 average time 0.017721784433282057 iter num 30\n",
            "loss 6.460037548094988e-05 average time 0.017188825249968433 iter num 40\n",
            "loss 4.088458445039578e-05 average time 0.017282627439963106 iter num 50\n",
            "loss 4.527670535026118e-05 average time 0.017253026283287908 iter num 60\n",
            "loss 3.0110893931123428e-05 average time 0.01707141051425164 iter num 70\n",
            "loss 4.6147091779857874e-05 average time 0.017276817212450623 iter num 80\n",
            "loss 2.882613080146257e-05 average time 0.017121038744385766 iter num 90\n",
            "loss 6.992885755607858e-05 average time 0.016969138629920052 iter num 100\n",
            "loss 0.0005972490180283785 average time 0.016769439800009424 iter num 10\n",
            "loss 4.2345003748778254e-05 average time 0.017185168300193253 iter num 20\n",
            "loss 0.00011947190796490759 average time 0.017420639466824164 iter num 30\n",
            "loss 6.41393635305576e-05 average time 0.017128668775126244 iter num 40\n",
            "loss 5.0198970711790025e-05 average time 0.016898920300081954 iter num 50\n",
            "loss 3.690188896143809e-05 average time 0.01666254700009328 iter num 60\n",
            "loss 5.673381019732915e-05 average time 0.01678759602864375 iter num 70\n",
            "loss 2.743452751019504e-05 average time 0.016653839312550645 iter num 80\n",
            "loss 1.63879831234226e-05 average time 0.016572651244506333 iter num 90\n",
            "loss 2.806459815474227e-05 average time 0.01668489988004694 iter num 100\n",
            "loss 3.688601282192394e-05 average time 0.016863841700069316 iter num 10\n",
            "loss 7.570809975732118e-05 average time 0.016332608000038818 iter num 20\n",
            "loss 6.606199167435989e-05 average time 0.016236087066772598 iter num 30\n",
            "loss 7.146500138333067e-05 average time 0.016422076025082787 iter num 40\n",
            "loss 7.87034587119706e-05 average time 0.016402822980071504 iter num 50\n",
            "loss 1.5556084690615535e-05 average time 0.01667973360005514 iter num 60\n",
            "loss 4.7045810788404197e-05 average time 0.016719444957197994 iter num 70\n",
            "loss 3.806919266935438e-05 average time 0.016702197512540807 iter num 80\n",
            "loss 1.9787508790614083e-05 average time 0.016632024588933644 iter num 90\n",
            "loss 5.2836534450761974e-05 average time 0.016538073460023953 iter num 100\n",
            "loss 0.0010553384199738503 average time 0.020233574699977906 iter num 10\n",
            "loss 4.311156226322055e-05 average time 0.019423246449969157 iter num 20\n",
            "loss 5.297615280142054e-05 average time 0.018313676966621038 iter num 30\n",
            "loss 4.062430889462121e-05 average time 0.01762514254992311 iter num 40\n",
            "loss 3.494449993013404e-05 average time 0.01788721311992049 iter num 50\n",
            "loss 4.925708708469756e-05 average time 0.017635675333258403 iter num 60\n",
            "loss 2.441351898596622e-05 average time 0.017467188099960496 iter num 70\n",
            "loss 6.614177254959941e-05 average time 0.017247902099961722 iter num 80\n",
            "loss 2.837885585904587e-05 average time 0.017271569188859658 iter num 90\n",
            "loss 7.265897875186056e-05 average time 0.017462251599963566 iter num 100\n",
            "loss 3.008792373293545e-05 average time 0.018118892799975583 iter num 10\n",
            "loss 0.00031856403802521527 average time 0.01708848249991206 iter num 20\n",
            "loss 6.167623359942809e-05 average time 0.01704266873330198 iter num 30\n",
            "loss 4.5995504478923976e-05 average time 0.016970676200003254 iter num 40\n",
            "loss 0.00010837055742740631 average time 0.016779203079986472 iter num 50\n",
            "loss 7.595400529680774e-05 average time 0.016911162033329673 iter num 60\n",
            "loss 4.375202115625143e-05 average time 0.016770603771432694 iter num 70\n",
            "loss 5.206623245612718e-05 average time 0.0169103673625159 iter num 80\n",
            "loss 9.195462189381942e-05 average time 0.016864176611114896 iter num 90\n",
            "loss 2.1364960048231296e-05 average time 0.01683778727999197 iter num 100\n",
            "loss 6.313354970188811e-05 average time 0.01812191109966079 iter num 10\n",
            "loss 0.0005342566291801631 average time 0.017287680049821574 iter num 20\n",
            "loss 5.085842349217273e-05 average time 0.016875945099945965 iter num 30\n",
            "loss 4.234170773997903e-05 average time 0.016854801374938687 iter num 40\n",
            "loss 3.084985291934572e-05 average time 0.016847296459927746 iter num 50\n",
            "loss 2.0577217583195306e-05 average time 0.0171276587332765 iter num 60\n",
            "loss 4.228530451655388e-05 average time 0.017089672642785964 iter num 70\n",
            "loss 2.6084175260621123e-05 average time 0.01713733956243004 iter num 80\n",
            "loss 5.1059691031696275e-05 average time 0.01704432058881543 iter num 90\n",
            "loss 5.483914355863817e-05 average time 0.017057331269934365 iter num 100\n",
            "loss 4.487885962589644e-05 average time 0.017049362499892595 iter num 10\n",
            "loss 2.8331427529337816e-05 average time 0.01699321324995253 iter num 20\n",
            "loss 7.771896343911067e-05 average time 0.017106265800005835 iter num 30\n",
            "loss 0.00011409729631850496 average time 0.017026915150040622 iter num 40\n",
            "loss 4.0565759263699874e-05 average time 0.01697763202004353 iter num 50\n",
            "loss 4.164678466622718e-05 average time 0.016781101833339564 iter num 60\n",
            "loss 2.0683806724264286e-05 average time 0.01676694664286385 iter num 70\n",
            "loss 2.5278590328525752e-05 average time 0.016772231900006318 iter num 80\n",
            "loss 1.6901818526093848e-05 average time 0.0168228693666606 iter num 90\n",
            "loss 3.9026886952342466e-05 average time 0.01685011773998667 iter num 100\n",
            "loss 7.941839430714026e-05 average time 0.0175234966998687 iter num 10\n",
            "loss 4.9011905502993613e-05 average time 0.016773778500055413 iter num 20\n",
            "loss 4.0892467950470746e-05 average time 0.016560050933367165 iter num 30\n",
            "loss 5.872498149983585e-05 average time 0.017012098200029867 iter num 40\n",
            "loss 5.8447712945053354e-05 average time 0.017680684400020255 iter num 50\n",
            "loss 0.00010747565102064982 average time 0.017556093316701056 iter num 60\n",
            "loss 2.5608876967453398e-05 average time 0.0174119780286024 iter num 70\n",
            "loss 0.00010295239189872518 average time 0.017459420400007274 iter num 80\n",
            "loss 3.9563659811392426e-05 average time 0.01731038756667355 iter num 90\n",
            "loss 0.0001495997712481767 average time 0.017182733090012333 iter num 100\n",
            "loss 6.69679866405204e-05 average time 0.018640640499597794 iter num 10\n",
            "loss 0.00014066709263715893 average time 0.017227298699845052 iter num 20\n",
            "loss 0.0017183873569592834 average time 0.01699271629983438 iter num 30\n",
            "loss 5.754416633863002e-05 average time 0.016766070899893747 iter num 40\n",
            "loss 4.6480188757414e-05 average time 0.016659961079894856 iter num 50\n",
            "loss 0.00015849994088057429 average time 0.01649737488325324 iter num 60\n",
            "loss 3.213971285731532e-05 average time 0.01644831691420612 iter num 70\n",
            "loss 3.139906402793713e-05 average time 0.016464927287415776 iter num 80\n",
            "loss 1.656005588301923e-05 average time 0.01657499586659065 iter num 90\n",
            "loss 5.55013793928083e-05 average time 0.01647516110992001 iter num 100\n",
            "loss 0.00011831772280856967 average time 0.01786973139987822 iter num 10\n",
            "loss 1.5630810594302602e-05 average time 0.016970211299940273 iter num 20\n",
            "loss 1.7728920283843763e-05 average time 0.017643684733320696 iter num 30\n",
            "loss 9.505865455139428e-05 average time 0.017735326100000746 iter num 40\n",
            "loss 8.5162311734166e-05 average time 0.017450798339978063 iter num 50\n",
            "loss 6.65452316752635e-05 average time 0.017394485250012318 iter num 60\n",
            "loss 3.697770443977788e-05 average time 0.01735425071430135 iter num 70\n",
            "loss 1.89630900422344e-05 average time 0.01715557963751735 iter num 80\n",
            "loss 4.2874184146057814e-05 average time 0.01710515911113867 iter num 90\n",
            "loss 5.66423186683096e-05 average time 0.0171417452100377 iter num 100\n",
            "loss 1.8411043129162863e-05 average time 0.019623279600091338 iter num 10\n",
            "loss 6.918850704096258e-05 average time 0.017664873600006105 iter num 20\n",
            "loss 9.213953308062628e-05 average time 0.01696903866665404 iter num 30\n",
            "loss 0.00012633051665034145 average time 0.017142457299951275 iter num 40\n",
            "loss 6.748132727807388e-05 average time 0.016919810179988417 iter num 50\n",
            "loss 4.664114021579735e-05 average time 0.016780886949982234 iter num 60\n",
            "loss 9.001762373372912e-05 average time 0.01668578229999704 iter num 70\n",
            "loss 3.962020855396986e-05 average time 0.016862128262494024 iter num 80\n",
            "loss 7.555296178907156e-05 average time 0.016756063911109068 iter num 90\n",
            "loss 5.575484101427719e-05 average time 0.016664869140022347 iter num 100\n",
            "loss 6.240336369955912e-05 average time 0.017278562700175824 iter num 10\n",
            "loss 3.437250416027382e-05 average time 0.0170519327501097 iter num 20\n",
            "loss 2.143942219845485e-05 average time 0.017151742400074 iter num 30\n",
            "loss 3.8008027331670746e-05 average time 0.016966262550090504 iter num 40\n",
            "loss 4.098195495316759e-05 average time 0.016906026920059956 iter num 50\n",
            "loss 1.4828838175162673e-05 average time 0.016861490633345966 iter num 60\n",
            "loss 2.0622630472644232e-05 average time 0.01683579124285513 iter num 70\n",
            "loss 2.049024260486476e-05 average time 0.016845365637504984 iter num 80\n",
            "loss 4.1887698898790404e-05 average time 0.01686118874444623 iter num 90\n",
            "loss 0.00011872416507685557 average time 0.016852220660002786 iter num 100\n",
            "loss 3.643879244918935e-05 average time 0.017235142000026828 iter num 10\n",
            "loss 0.00017595416284166276 average time 0.017439655399948607 iter num 20\n",
            "loss 2.1714735339628533e-05 average time 0.017504475433330904 iter num 30\n",
            "loss 1.2152521776442882e-05 average time 0.01720610802497049 iter num 40\n",
            "loss 3.8301841414067894e-05 average time 0.01689875952002694 iter num 50\n",
            "loss 1.9390583474887535e-05 average time 0.016872014400026576 iter num 60\n",
            "loss 2.8020913305226713e-05 average time 0.016832984100009135 iter num 70\n",
            "loss 0.0003598191251512617 average time 0.01671451742499812 iter num 80\n",
            "loss 7.345222547883168e-05 average time 0.016644053111091732 iter num 90\n",
            "loss 2.627109279274009e-05 average time 0.016563409700002012 iter num 100\n",
            "loss 5.675119246006943e-05 average time 0.018799338599819748 iter num 10\n",
            "loss 6.956130528124049e-05 average time 0.017312158199956684 iter num 20\n",
            "loss 6.430517532862723e-05 average time 0.017005421433320105 iter num 30\n",
            "loss 6.21084836893715e-05 average time 0.017102547500053335 iter num 40\n",
            "loss 1.627832534722984e-05 average time 0.017303111020009965 iter num 50\n",
            "loss 4.717003685072996e-05 average time 0.017199985633321074 iter num 60\n",
            "loss 0.0003010187647305429 average time 0.016998745771421193 iter num 70\n",
            "loss 2.8014306735713035e-05 average time 0.016890927162512524 iter num 80\n",
            "loss 2.086424683511723e-05 average time 0.017007229922233413 iter num 90\n",
            "loss 2.9152390197850764e-05 average time 0.016883832190023894 iter num 100\n",
            "loss 3.164123700116761e-05 average time 0.016853888300101972 iter num 10\n",
            "loss 2.1529695004574023e-05 average time 0.016675839850040574 iter num 20\n",
            "loss 0.00012333394261077046 average time 0.01717229343339568 iter num 30\n",
            "loss 0.00036156305577605963 average time 0.017015351850068326 iter num 40\n",
            "loss 8.057225204538554e-05 average time 0.0169807243600917 iter num 50\n",
            "loss 4.71912971988786e-05 average time 0.017038910283402705 iter num 60\n",
            "loss 5.013320333091542e-05 average time 0.017310978600081788 iter num 70\n",
            "loss 2.422717989247758e-05 average time 0.01728220345006548 iter num 80\n",
            "loss 8.061913104029372e-05 average time 0.01724245331119568 iter num 90\n",
            "loss 0.00012202281504869461 average time 0.017204675350076287 iter num 100\n",
            "loss 5.664419222739525e-05 average time 0.01692708499986111 iter num 10\n",
            "loss 0.00019888974202331156 average time 0.016360628799930055 iter num 20\n",
            "loss 7.758169522276148e-05 average time 0.016332815666586006 iter num 30\n",
            "loss 6.302154361037537e-05 average time 0.016664807674965233 iter num 40\n",
            "loss 7.324598846025765e-05 average time 0.0166217520999453 iter num 50\n",
            "loss 0.0006485960329882801 average time 0.016593463566611413 iter num 60\n",
            "loss 3.49881847796496e-05 average time 0.01656360381425007 iter num 70\n",
            "loss 0.0005344843375496566 average time 0.01681332286248107 iter num 80\n",
            "loss 2.8797754566767253e-05 average time 0.016922883711100036 iter num 90\n",
            "loss 5.223175321589224e-05 average time 0.016807974339990324 iter num 100\n",
            "loss 5.7548390032025054e-05 average time 0.017917315600061556 iter num 10\n",
            "loss 4.392091796034947e-05 average time 0.01684535939998568 iter num 20\n",
            "loss 6.334579666145146e-05 average time 0.01636865606669744 iter num 30\n",
            "loss 2.355499418627005e-05 average time 0.016311660425049012 iter num 40\n",
            "loss 3.484548506094143e-05 average time 0.01645188202006466 iter num 50\n",
            "loss 0.0001887346588773653 average time 0.016364354833361478 iter num 60\n",
            "loss 3.264555198256858e-05 average time 0.016476370785754365 iter num 70\n",
            "loss 0.00020207703346386552 average time 0.01652813732503091 iter num 80\n",
            "loss 4.6513880079146475e-05 average time 0.01665042607781086 iter num 90\n",
            "loss 3.31726623699069e-05 average time 0.016578805890048898 iter num 100\n",
            "loss 9.304505510954186e-05 average time 0.019529910400069638 iter num 10\n",
            "loss 3.7927122320979834e-05 average time 0.01854739875006999 iter num 20\n",
            "loss 3.910367740900256e-05 average time 0.017947381800089108 iter num 30\n",
            "loss 1.6343006791430525e-05 average time 0.018019366575026653 iter num 40\n",
            "loss 6.508806109195575e-05 average time 0.01765454451999176 iter num 50\n",
            "loss 4.8773581511341035e-05 average time 0.01771321719996498 iter num 60\n",
            "loss 3.2195079256780446e-05 average time 0.017856009242807756 iter num 70\n",
            "loss 2.2062842617742717e-05 average time 0.017764619149954797 iter num 80\n",
            "loss 4.432946661836468e-05 average time 0.017596796633299366 iter num 90\n",
            "loss 2.2302170691546053e-05 average time 0.017708421869965605 iter num 100\n",
            "loss 4.352234464022331e-05 average time 0.018458358100087936 iter num 10\n",
            "loss 1.93189007404726e-05 average time 0.018177281300040704 iter num 20\n",
            "loss 8.691121911397204e-05 average time 0.017386558333419087 iter num 30\n",
            "loss 4.56432462669909e-05 average time 0.017307172250070835 iter num 40\n",
            "loss 5.745377711718902e-05 average time 0.017310442159996456 iter num 50\n",
            "loss 5.0019891205010936e-05 average time 0.017164016150006015 iter num 60\n",
            "loss 2.2220097889658064e-05 average time 0.016940519499985384 iter num 70\n",
            "loss 0.00016102188965305686 average time 0.016994604637511658 iter num 80\n",
            "loss 7.919389463495463e-05 average time 0.016916831577782433 iter num 90\n",
            "loss 2.0519653844530694e-05 average time 0.016784788249997292 iter num 100\n",
            "loss 1.105910814658273e-05 average time 0.018575917900034256 iter num 10\n",
            "loss 4.5407559809973463e-05 average time 0.017730880149974836 iter num 20\n",
            "loss 0.0002961674763355404 average time 0.017187704399960542 iter num 30\n",
            "loss 2.641987521201372e-05 average time 0.01675257602498732 iter num 40\n",
            "loss 3.617574111558497e-05 average time 0.01675136342002588 iter num 50\n",
            "loss 0.0001349976664641872 average time 0.016756232133335894 iter num 60\n",
            "loss 0.00018444958550389856 average time 0.0166796107142935 iter num 70\n",
            "loss 6.481981108663604e-05 average time 0.01667049038750292 iter num 80\n",
            "loss 4.211775740259327e-05 average time 0.01671945266667131 iter num 90\n",
            "loss 5.7409226428717375e-05 average time 0.01665283721998094 iter num 100\n",
            "loss 0.00011088771134382114 average time 0.01705507890010267 iter num 10\n",
            "loss 4.057623300468549e-05 average time 0.01639102965004895 iter num 20\n",
            "loss 0.0006432136869989336 average time 0.01669536043333816 iter num 30\n",
            "loss 3.811009446508251e-05 average time 0.016575351374967795 iter num 40\n",
            "loss 0.00021439831471070647 average time 0.01661994346000938 iter num 50\n",
            "loss 2.213558582297992e-05 average time 0.016575968999965576 iter num 60\n",
            "loss 3.1432042305823416e-05 average time 0.016586095842857113 iter num 70\n",
            "loss 0.00013872933050151914 average time 0.016653458812504594 iter num 80\n",
            "loss 3.079757880186662e-05 average time 0.01658904524445259 iter num 90\n",
            "loss 5.2427749324124306e-05 average time 0.01653229258000465 iter num 100\n",
            "loss 0.00011007953435182571 average time 0.01729314090016487 iter num 10\n",
            "loss 5.4080177505966276e-05 average time 0.016935417000149756 iter num 20\n",
            "loss 8.644095214549452e-05 average time 0.01678969996676945 iter num 30\n",
            "loss 3.1346942705567926e-05 average time 0.016588307275083026 iter num 40\n",
            "loss 4.427934254636057e-05 average time 0.016617002340080945 iter num 50\n",
            "loss 0.00036047649336978793 average time 0.016544187800082 iter num 60\n",
            "loss 3.758196908165701e-05 average time 0.01658439662863072 iter num 70\n",
            "loss 4.246699973009527e-05 average time 0.016633929475051445 iter num 80\n",
            "loss 4.598531450028531e-05 average time 0.016669403033402988 iter num 90\n",
            "loss 1.4959575310058426e-05 average time 0.01665129011006684 iter num 100\n",
            "loss 4.357802026788704e-05 average time 0.019920124799864426 iter num 10\n",
            "loss 1.618289388716221e-05 average time 0.018599347399958787 iter num 20\n",
            "loss 0.00010706140892580152 average time 0.018061982166636882 iter num 30\n",
            "loss 0.00019594487093854696 average time 0.017521200449982642 iter num 40\n",
            "loss 0.00012034323299303651 average time 0.017183463179990213 iter num 50\n",
            "loss 4.4499589421320707e-05 average time 0.01737588255001962 iter num 60\n",
            "loss 7.285550964297727e-05 average time 0.01731090720004431 iter num 70\n",
            "loss 3.49099027516786e-05 average time 0.017146682212535326 iter num 80\n",
            "loss 4.701345460489392e-05 average time 0.01698871506671114 iter num 90\n",
            "loss 0.00010642947017913684 average time 0.016957748250033548 iter num 100\n",
            "loss 0.0005978302797302604 average time 0.01793002290005461 iter num 10\n",
            "loss 3.103449853369966e-05 average time 0.016902685849981936 iter num 20\n",
            "loss 5.367739504436031e-05 average time 0.01639366526666587 iter num 30\n",
            "loss 0.0002637690049596131 average time 0.01680454189995544 iter num 40\n",
            "loss 6.076658610254526e-05 average time 0.017233932519957307 iter num 50\n",
            "loss 0.0003675535263027996 average time 0.01733045916662377 iter num 60\n",
            "loss 4.795292261405848e-05 average time 0.017187664571390218 iter num 70\n",
            "loss 7.475161692127585e-05 average time 0.01719127873745947 iter num 80\n",
            "loss 5.568735650740564e-05 average time 0.017169557066649254 iter num 90\n",
            "loss 3.5117183870170265e-05 average time 0.017083800139980666 iter num 100\n",
            "loss 0.00013224083522800356 average time 0.017853829199884784 iter num 10\n",
            "loss 2.310976014996413e-05 average time 0.0179040413499024 iter num 20\n",
            "loss 3.847500556730665e-05 average time 0.017823363333294158 iter num 30\n",
            "loss 8.537023677490652e-05 average time 0.017450676375028708 iter num 40\n",
            "loss 4.047223774250597e-05 average time 0.01727973542001564 iter num 50\n",
            "loss 1.4945365364837926e-05 average time 0.017318170616681526 iter num 60\n",
            "loss 0.0004585387359838933 average time 0.01737421138573804 iter num 70\n",
            "loss 0.00013946351828053594 average time 0.01735493758754956 iter num 80\n",
            "loss 3.9653077692491934e-05 average time 0.01735261210003753 iter num 90\n",
            "loss 7.034504233160987e-05 average time 0.017399639150025906 iter num 100\n",
            "loss 5.035330468672328e-05 average time 0.016944010600127513 iter num 10\n",
            "loss 5.921462070546113e-05 average time 0.016991784300125802 iter num 20\n",
            "loss 4.491201616474427e-05 average time 0.017084403133412706 iter num 30\n",
            "loss 3.8734364352421835e-05 average time 0.017245441350019063 iter num 40\n",
            "loss 6.387017492670566e-05 average time 0.017246221079985843 iter num 50\n",
            "loss 5.158545172889717e-05 average time 0.017179903616670343 iter num 60\n",
            "loss 1.781239734555129e-05 average time 0.0172084122142873 iter num 70\n",
            "loss 2.760229654086288e-05 average time 0.017208912550006516 iter num 80\n",
            "loss 2.4112505343509838e-05 average time 0.017336988844454025 iter num 90\n",
            "loss 2.1584215573966503e-05 average time 0.01729413416002899 iter num 100\n",
            "loss 2.7268844860373065e-05 average time 0.019701741600056267 iter num 10\n",
            "loss 3.920517337974161e-05 average time 0.01783177720008098 iter num 20\n",
            "loss 6.027646304573864e-05 average time 0.017561814566670365 iter num 30\n",
            "loss 5.678794332197867e-05 average time 0.017224934224964274 iter num 40\n",
            "loss 3.341268529766239e-05 average time 0.017200797739969857 iter num 50\n",
            "loss 0.00010966727859340608 average time 0.017154934349976732 iter num 60\n",
            "loss 0.00014712220581714064 average time 0.017143099942820428 iter num 70\n",
            "loss 7.005366933299229e-05 average time 0.017155505762445955 iter num 80\n",
            "loss 8.979131234809756e-05 average time 0.017157063633274246 iter num 90\n",
            "loss 2.502903043932747e-05 average time 0.017038524009958565 iter num 100\n",
            "loss 9.122434857999906e-05 average time 0.018494633700083796 iter num 10\n",
            "loss 3.918825677828863e-05 average time 0.019185263350073 iter num 20\n",
            "loss 0.00019305961905047297 average time 0.01825403940004738 iter num 30\n",
            "loss 3.980099063483067e-05 average time 0.01771266767502766 iter num 40\n",
            "loss 5.275697185425088e-05 average time 0.017287254660077453 iter num 50\n",
            "loss 2.9279000955284573e-05 average time 0.017319953266693725 iter num 60\n",
            "loss 3.969094541389495e-05 average time 0.01720241002858529 iter num 70\n",
            "loss 6.588498945347965e-05 average time 0.017048127025009307 iter num 80\n",
            "loss 3.8749261875636876e-05 average time 0.016983315311103475 iter num 90\n",
            "loss 2.439633863104973e-05 average time 0.017096149540011537 iter num 100\n",
            "loss 2.590828444226645e-05 average time 0.017426781399808532 iter num 10\n",
            "loss 2.422079887764994e-05 average time 0.016614330699849234 iter num 20\n",
            "loss 0.00044525653356686234 average time 0.01670498599990727 iter num 30\n",
            "loss 3.964384086430073e-05 average time 0.01691854857490398 iter num 40\n",
            "loss 0.00011884920968441293 average time 0.01671363739993467 iter num 50\n",
            "loss 5.598612915491685e-05 average time 0.016539840366643452 iter num 60\n",
            "loss 4.83076655655168e-05 average time 0.01647033647141143 iter num 70\n",
            "loss 3.199664206476882e-05 average time 0.01658993297494362 iter num 80\n",
            "loss 3.658670902950689e-05 average time 0.016492639755496283 iter num 90\n",
            "loss 7.176312647061422e-05 average time 0.016403570469947226 iter num 100\n",
            "loss 0.00047229608753696084 average time 0.016979280399937124 iter num 10\n",
            "loss 3.061857569264248e-05 average time 0.017468691000067336 iter num 20\n",
            "loss 9.132584818871692e-05 average time 0.017239703266720124 iter num 30\n",
            "loss 2.8931031920365058e-05 average time 0.01688070992502162 iter num 40\n",
            "loss 3.483846376184374e-05 average time 0.016781080380060303 iter num 50\n",
            "loss 2.754631896095816e-05 average time 0.017089978683407024 iter num 60\n",
            "loss 2.0837589545408264e-05 average time 0.017104299142933346 iter num 70\n",
            "loss 1.8840570191969164e-05 average time 0.017161219850072483 iter num 80\n",
            "loss 2.8130531063652597e-05 average time 0.017334769866738497 iter num 90\n",
            "loss 3.074426422244869e-05 average time 0.01735765069003719 iter num 100\n",
            "loss 9.279800724470988e-05 average time 0.017651427499913552 iter num 10\n",
            "loss 3.737276347237639e-05 average time 0.016741678149901417 iter num 20\n",
            "loss 1.9969666027463973e-05 average time 0.017015426733238807 iter num 30\n",
            "loss 0.0015649441629648209 average time 0.01713246404990514 iter num 40\n",
            "loss 9.573584975441918e-05 average time 0.017030393599907257 iter num 50\n",
            "loss 6.297804793575779e-05 average time 0.01714613218323393 iter num 60\n",
            "loss 2.6282119506504387e-05 average time 0.017037781199932007 iter num 70\n",
            "loss 3.855156319332309e-05 average time 0.016902793587451014 iter num 80\n",
            "loss 0.00015856420213822275 average time 0.016790014822193673 iter num 90\n",
            "loss 2.1952138922642916e-05 average time 0.016821961309979087 iter num 100\n",
            "loss 4.733676178148016e-05 average time 0.020472006499858253 iter num 10\n",
            "loss 0.0002602227032184601 average time 0.018938576100026694 iter num 20\n",
            "loss 5.938827962381765e-05 average time 0.018059804100054557 iter num 30\n",
            "loss 8.67117487359792e-05 average time 0.018563284675065007 iter num 40\n",
            "loss 5.767509719589725e-05 average time 0.01803227616008371 iter num 50\n",
            "loss 2.3216511181090027e-05 average time 0.017709182100073426 iter num 60\n",
            "loss 0.0003219627251382917 average time 0.017556290742894425 iter num 70\n",
            "loss 0.0005446489085443318 average time 0.017696004750041537 iter num 80\n",
            "loss 0.00012005018652416766 average time 0.01755117815559465 iter num 90\n",
            "loss 6.306987052084878e-05 average time 0.01742044524002267 iter num 100\n",
            "loss 4.04372694902122e-05 average time 0.01881548519986609 iter num 10\n",
            "loss 2.2648195226793177e-05 average time 0.01839154284994038 iter num 20\n",
            "loss 4.5857657823944464e-05 average time 0.017906788633263206 iter num 30\n",
            "loss 0.001431718235835433 average time 0.017609161274981487 iter num 40\n",
            "loss 3.1066254450706765e-05 average time 0.017744167000000744 iter num 50\n",
            "loss 0.00018150582036469132 average time 0.017793675366692695 iter num 60\n",
            "loss 4.6543449570890516e-05 average time 0.017500100185744875 iter num 70\n",
            "loss 9.017942647915334e-05 average time 0.01751916959999562 iter num 80\n",
            "loss 0.0006913596298545599 average time 0.017487381011101713 iter num 90\n",
            "loss 0.00014875155466143042 average time 0.017398411239983032 iter num 100\n",
            "loss 3.565583028830588e-05 average time 0.016858159900039027 iter num 10\n",
            "loss 6.161992496345192e-05 average time 0.017049710999981472 iter num 20\n",
            "loss 2.8428732548491098e-05 average time 0.016799486233291343 iter num 30\n",
            "loss 0.002197558293119073 average time 0.016943605149958785 iter num 40\n",
            "loss 4.307039125706069e-05 average time 0.016736027839961025 iter num 50\n",
            "loss 0.0002390709996689111 average time 0.016707095049938895 iter num 60\n",
            "loss 3.333511631353758e-05 average time 0.016864099242840373 iter num 70\n",
            "loss 1.3733291780226864e-05 average time 0.016851633574981408 iter num 80\n",
            "loss 6.1624072259292e-05 average time 0.016756332888881946 iter num 90\n",
            "loss 4.1156759834848344e-05 average time 0.016698539229983 iter num 100\n",
            "loss 5.649710146826692e-05 average time 0.017643518300064897 iter num 10\n",
            "loss 3.16160949296318e-05 average time 0.01699440660017899 iter num 20\n",
            "loss 3.361502967891283e-05 average time 0.016609240666730328 iter num 30\n",
            "loss 0.0002911875781137496 average time 0.016815831575081576 iter num 40\n",
            "loss 2.6140090994886123e-05 average time 0.016811184480084194 iter num 50\n",
            "loss 2.68918156507425e-05 average time 0.016991333933431937 iter num 60\n",
            "loss 2.603214124974329e-05 average time 0.01681058188580989 iter num 70\n",
            "loss 2.848243275366258e-05 average time 0.016738461800082406 iter num 80\n",
            "loss 0.0006263258401304483 average time 0.016713877311192643 iter num 90\n",
            "loss 2.382774982834235e-05 average time 0.01669688955008496 iter num 100\n",
            "loss 7.9589597589802e-05 average time 0.017063976899953558 iter num 10\n",
            "loss 3.0316627089632675e-05 average time 0.017667809999966266 iter num 20\n",
            "loss 3.123529677395709e-05 average time 0.017798525433378624 iter num 30\n",
            "loss 8.00071720732376e-05 average time 0.017483325425018847 iter num 40\n",
            "loss 1.6017056623240933e-05 average time 0.017180981100027568 iter num 50\n",
            "loss 6.87070787535049e-05 average time 0.017240399316718443 iter num 60\n",
            "loss 0.00013037718599662185 average time 0.01706428222860268 iter num 70\n",
            "loss 1.9918687030440196e-05 average time 0.01705990163752631 iter num 80\n",
            "loss 2.1345502318581566e-05 average time 0.017127240266654555 iter num 90\n",
            "loss 9.142029011854902e-05 average time 0.017063826829999015 iter num 100\n",
            "loss 5.959424379398115e-05 average time 0.017242116600027658 iter num 10\n",
            "loss 2.9989929316798225e-05 average time 0.01675535234999188 iter num 20\n",
            "loss 5.5958669690880924e-05 average time 0.016765711966581876 iter num 30\n",
            "loss 3.872540037264116e-05 average time 0.01681618964989866 iter num 40\n",
            "loss 0.00044455024180933833 average time 0.01662145739992411 iter num 50\n",
            "loss 2.991846668010112e-05 average time 0.016459475349953814 iter num 60\n",
            "loss 6.62029706290923e-05 average time 0.016559514814239912 iter num 70\n",
            "loss 5.427749783848412e-05 average time 0.017025624124960358 iter num 80\n",
            "loss 1.3260307241580449e-05 average time 0.016984781422191494 iter num 90\n",
            "loss 0.0003375657252036035 average time 0.01686734867996165 iter num 100\n",
            "loss 0.00018052187806461006 average time 0.01706740700010414 iter num 10\n",
            "loss 3.939196540159173e-05 average time 0.01693785115007813 iter num 20\n",
            "loss 4.099967918591574e-05 average time 0.016607653600052192 iter num 30\n",
            "loss 4.139980592299253e-05 average time 0.01749547625008745 iter num 40\n",
            "loss 2.7037460313295014e-05 average time 0.017452863460075605 iter num 50\n",
            "loss 4.763432662002742e-05 average time 0.017131202550035595 iter num 60\n",
            "loss 2.9750648536719382e-05 average time 0.01691737671430279 iter num 70\n",
            "loss 2.164410580007825e-05 average time 0.016791058350008825 iter num 80\n",
            "loss 4.087963679921813e-05 average time 0.01672875470000387 iter num 90\n",
            "loss 3.751911935978569e-05 average time 0.016633371600000828 iter num 100\n",
            "loss 9.761910769157112e-05 average time 0.016598959200200623 iter num 10\n",
            "loss 4.0603208617540076e-05 average time 0.016325566300156424 iter num 20\n",
            "loss 8.179856376955286e-05 average time 0.016234538500126898 iter num 30\n",
            "loss 3.544226274243556e-05 average time 0.01633164610007043 iter num 40\n",
            "loss 3.032331369468011e-05 average time 0.016421929220068705 iter num 50\n",
            "loss 6.844892777735367e-05 average time 0.016287896000054994 iter num 60\n",
            "loss 7.620338146807626e-05 average time 0.01625314368577944 iter num 70\n",
            "loss 1.4563443983206525e-05 average time 0.01624172256258589 iter num 80\n",
            "loss 0.00013074555317871273 average time 0.016335574133386724 iter num 90\n",
            "loss 3.6963465390726924e-05 average time 0.016303933760063956 iter num 100\n",
            "loss 2.3361677449429408e-05 average time 0.01763633549990118 iter num 10\n",
            "loss 2.2532012735609896e-05 average time 0.01668872369996279 iter num 20\n",
            "loss 0.00011959367111558095 average time 0.016706280933279534 iter num 30\n",
            "loss 7.887209358159453e-05 average time 0.01649950070000159 iter num 40\n",
            "loss 4.036684549646452e-05 average time 0.016482010820000143 iter num 50\n",
            "loss 1.9545675968402065e-05 average time 0.016541714866677163 iter num 60\n",
            "loss 7.848623499739915e-05 average time 0.01657678052857331 iter num 70\n",
            "loss 3.521727194311097e-05 average time 0.016719646562489743 iter num 80\n",
            "loss 4.9350182962371036e-05 average time 0.016686815711091187 iter num 90\n",
            "loss 0.00010966669651679695 average time 0.016590849769982013 iter num 100\n",
            "loss 2.3794716980773956e-05 average time 0.018659597500118252 iter num 10\n",
            "loss 2.194334774685558e-05 average time 0.017650546750019203 iter num 20\n",
            "loss 1.5932568203425035e-05 average time 0.017021755533399605 iter num 30\n",
            "loss 5.003195838071406e-05 average time 0.01670970730008321 iter num 40\n",
            "loss 4.1476927435724065e-05 average time 0.016826430360088126 iter num 50\n",
            "loss 0.000324991880916059 average time 0.016878767933379397 iter num 60\n",
            "loss 8.814446482574567e-05 average time 0.01683073598576032 iter num 70\n",
            "loss 4.027440809295513e-05 average time 0.016700701600041157 iter num 80\n",
            "loss 5.4802210797788575e-05 average time 0.016654556266712462 iter num 90\n",
            "loss 0.0010824059136211872 average time 0.016771033290042398 iter num 100\n",
            "loss 3.252732858527452e-05 average time 0.016772957399825827 iter num 10\n",
            "loss 4.3352065404178575e-05 average time 0.016431432499894073 iter num 20\n",
            "loss 1.75027107616188e-05 average time 0.017178919999969365 iter num 30\n",
            "loss 2.3972759663593024e-05 average time 0.01692571134994978 iter num 40\n",
            "loss 6.295392813626677e-05 average time 0.01693070754001383 iter num 50\n",
            "loss 4.1525086999172345e-05 average time 0.01668470020002436 iter num 60\n",
            "loss 3.253517206758261e-05 average time 0.016717894214317703 iter num 70\n",
            "loss 2.5826740966294892e-05 average time 0.016746501850025197 iter num 80\n",
            "loss 0.0003693720209412277 average time 0.01665277887780879 iter num 90\n",
            "loss 3.316084257676266e-05 average time 0.01664382468004078 iter num 100\n",
            "loss 4.3752839701483026e-05 average time 0.018525945000237697 iter num 10\n",
            "loss 0.0008373779128305614 average time 0.017334543700144422 iter num 20\n",
            "loss 5.412879545474425e-05 average time 0.016928186200099542 iter num 30\n",
            "loss 8.78868522704579e-05 average time 0.016827012025078147 iter num 40\n",
            "loss 3.8824393413960934e-05 average time 0.016941988740036322 iter num 50\n",
            "loss 5.958104884484783e-05 average time 0.01699620483339762 iter num 60\n",
            "loss 7.224902947200462e-05 average time 0.016908996071470027 iter num 70\n",
            "loss 8.123677980620414e-05 average time 0.016910766050045822 iter num 80\n",
            "loss 4.704420643975027e-05 average time 0.016869975922256548 iter num 90\n",
            "loss 9.649602361605503e-06 average time 0.016956464680033603 iter num 100\n",
            "loss 4.607347000273876e-05 average time 0.016866260300048452 iter num 10\n",
            "loss 4.3454037950141355e-05 average time 0.016253590899941626 iter num 20\n",
            "loss 0.0002375246403971687 average time 0.016710008133244022 iter num 30\n",
            "loss 4.3498021113919094e-05 average time 0.01669323707492367 iter num 40\n",
            "loss 8.644904301036149e-05 average time 0.0167195150999396 iter num 50\n",
            "loss 4.302894012653269e-05 average time 0.016808304883276528 iter num 60\n",
            "loss 3.055102934013121e-05 average time 0.01668496271423854 iter num 70\n",
            "loss 2.2591955712414347e-05 average time 0.016737767662471016 iter num 80\n",
            "loss 3.8471076550194994e-05 average time 0.01661932925552618 iter num 90\n",
            "loss 5.785638131783344e-05 average time 0.01663507528998707 iter num 100\n",
            "loss 0.0005964887677691877 average time 0.017552958600026612 iter num 10\n",
            "loss 7.629932224517688e-05 average time 0.016933572199968695 iter num 20\n",
            "loss 5.9638681705109775e-05 average time 0.01669043203334392 iter num 30\n",
            "loss 7.98758992459625e-05 average time 0.016805759775024853 iter num 40\n",
            "loss 2.6021374651463702e-05 average time 0.016679528660006326 iter num 50\n",
            "loss 1.949218312802259e-05 average time 0.01669687050001206 iter num 60\n",
            "loss 1.900558163470123e-05 average time 0.016661698714285324 iter num 70\n",
            "loss 0.00017244268383365124 average time 0.01665444599999546 iter num 80\n",
            "loss 4.815337524632923e-05 average time 0.01668802114445498 iter num 90\n",
            "loss 4.075449760421179e-05 average time 0.016616430150024827 iter num 100\n",
            "loss 3.290023232693784e-05 average time 0.018837277099919447 iter num 10\n",
            "loss 2.7033674996346235e-05 average time 0.01816853464997621 iter num 20\n",
            "loss 5.723074355046265e-05 average time 0.01848206863332962 iter num 30\n",
            "loss 1.9684517610585317e-05 average time 0.01805355745002544 iter num 40\n",
            "loss 0.00022477445600088686 average time 0.01770035182002175 iter num 50\n",
            "loss 3.424784154049121e-05 average time 0.017910739583354977 iter num 60\n",
            "loss 5.726325616706163e-05 average time 0.018053188171441952 iter num 70\n",
            "loss 2.7846230295835994e-05 average time 0.01814021143750324 iter num 80\n",
            "loss 3.359712354722433e-05 average time 0.018327559233340354 iter num 90\n",
            "loss 2.004820817091968e-05 average time 0.018101516819997415 iter num 100\n",
            "loss 4.390618050820194e-05 average time 0.017210141700070382 iter num 10\n",
            "loss 4.9713835323927924e-05 average time 0.01665145114989173 iter num 20\n",
            "loss 3.647890480351634e-05 average time 0.01711893226659716 iter num 30\n",
            "loss 7.004949293332174e-05 average time 0.017087164774943632 iter num 40\n",
            "loss 0.00016382562171202153 average time 0.0170801637799741 iter num 50\n",
            "loss 4.65185112261679e-05 average time 0.017122916483306955 iter num 60\n",
            "loss 2.6784004148794338e-05 average time 0.01707229619996724 iter num 70\n",
            "loss 5.602445889962837e-05 average time 0.016978761774976193 iter num 80\n",
            "loss 2.33732662309194e-05 average time 0.016992329044438117 iter num 90\n",
            "loss 7.805707718944177e-05 average time 0.01697149245998844 iter num 100\n",
            "loss 0.0001357836736133322 average time 0.018010741699981736 iter num 10\n",
            "loss 1.793558112694882e-05 average time 0.01698593979999714 iter num 20\n",
            "loss 0.00018072874809149653 average time 0.016687995066604344 iter num 30\n",
            "loss 3.5220582503825426e-05 average time 0.016802652424985354 iter num 40\n",
            "loss 7.374810229521245e-05 average time 0.016743752300026244 iter num 50\n",
            "loss 4.1545587009750307e-05 average time 0.01667237318338266 iter num 60\n",
            "loss 6.335656507872045e-05 average time 0.016617827057182566 iter num 70\n",
            "loss 9.113752639677841e-06 average time 0.016649251550018108 iter num 80\n",
            "loss 3.3487598557258025e-05 average time 0.01665188717779529 iter num 90\n",
            "loss 6.439613207476214e-05 average time 0.016637193980013763 iter num 100\n",
            "loss 7.913677109172568e-05 average time 0.016753485199842544 iter num 10\n",
            "loss 6.243259849725291e-05 average time 0.016850351000039156 iter num 20\n",
            "loss 2.4839437173795886e-05 average time 0.01717659940007555 iter num 30\n",
            "loss 6.115949508966878e-05 average time 0.016909416000044076 iter num 40\n",
            "loss 0.0001019742849166505 average time 0.01666670630005683 iter num 50\n",
            "loss 5.204735498409718e-05 average time 0.01672345175005224 iter num 60\n",
            "loss 1.4843001736153383e-05 average time 0.016667348171488683 iter num 70\n",
            "loss 3.058143920497969e-05 average time 0.01656241417505271 iter num 80\n",
            "loss 3.657949127955362e-05 average time 0.016472852900056345 iter num 90\n",
            "loss 3.61969432560727e-05 average time 0.016537775770038933 iter num 100\n",
            "loss 7.017057941993698e-05 average time 0.017958687800000917 iter num 10\n",
            "loss 1.9986073311883956e-05 average time 0.017503591200011215 iter num 20\n",
            "loss 0.00013709736231248826 average time 0.01697002436664358 iter num 30\n",
            "loss 5.230887109064497e-05 average time 0.01766570009995121 iter num 40\n",
            "loss 4.2297317122574896e-05 average time 0.017330429719986568 iter num 50\n",
            "loss 4.094986798008904e-05 average time 0.01704975013329507 iter num 60\n",
            "loss 0.0016018536407500505 average time 0.016900811628537276 iter num 70\n",
            "loss 1.718659041216597e-05 average time 0.016982203912459682 iter num 80\n",
            "loss 3.3198215533047915e-05 average time 0.016889773699949727 iter num 90\n",
            "loss 4.9689617299009115e-05 average time 0.01677212597996004 iter num 100\n",
            "loss 4.895309393759817e-05 average time 0.017576432599889814 iter num 10\n",
            "loss 2.37345138884848e-05 average time 0.01727270219989805 iter num 20\n",
            "loss 1.287657050852431e-05 average time 0.016671009766620653 iter num 30\n",
            "loss 2.555395803938154e-05 average time 0.016476761874923796 iter num 40\n",
            "loss 2.488951759005431e-05 average time 0.01641510823998033 iter num 50\n",
            "loss 7.022387580946088e-05 average time 0.01685366228333199 iter num 60\n",
            "loss 3.386145181139e-05 average time 0.016808047442827954 iter num 70\n",
            "loss 3.4849665098590776e-05 average time 0.016704783974978453 iter num 80\n",
            "loss 4.4560722017195076e-05 average time 0.016741677411088556 iter num 90\n",
            "loss 3.7122354115126655e-05 average time 0.016722986509967085 iter num 100\n",
            "loss 3.462964014033787e-05 average time 0.018534380300025077 iter num 10\n",
            "loss 0.00011668963998090476 average time 0.017214912250119598 iter num 20\n",
            "loss 3.103856579400599e-05 average time 0.017160907366693814 iter num 30\n",
            "loss 3.2021656807046384e-05 average time 0.017505261900009828 iter num 40\n",
            "loss 5.5560194596182555e-05 average time 0.017154730220045166 iter num 50\n",
            "loss 0.0001102932874346152 average time 0.017051123550042274 iter num 60\n",
            "loss 9.096163012145553e-06 average time 0.016953697785746565 iter num 70\n",
            "loss 2.197505091316998e-05 average time 0.016901980962506967 iter num 80\n",
            "loss 0.00026682455791160464 average time 0.01680841351112071 iter num 90\n",
            "loss 0.0002449154853820801 average time 0.016728715390017898 iter num 100\n",
            "loss 3.61354868800845e-05 average time 0.017616443899896694 iter num 10\n",
            "loss 1.7918697267305106e-05 average time 0.01705320909995862 iter num 20\n",
            "loss 5.864221748197451e-05 average time 0.016620140066606837 iter num 30\n",
            "loss 5.638992297463119e-05 average time 0.01675381792490498 iter num 40\n",
            "loss 5.7352724979864433e-05 average time 0.016914468179893446 iter num 50\n",
            "loss 4.7667712351540104e-05 average time 0.01684401391657957 iter num 60\n",
            "loss 3.142585410387255e-05 average time 0.016694747999905044 iter num 70\n",
            "loss 8.198335126508027e-05 average time 0.016676924812406922 iter num 80\n",
            "loss 4.091313894605264e-05 average time 0.01674479047769637 iter num 90\n",
            "loss 2.8722997740260325e-05 average time 0.016722281839911375 iter num 100\n",
            "loss 2.9755483410554007e-05 average time 0.01701826919997984 iter num 10\n",
            "loss 2.7580435926211067e-05 average time 0.01856793795009253 iter num 20\n",
            "loss 5.5521581089124084e-05 average time 0.018422150300132976 iter num 30\n",
            "loss 5.845100531587377e-05 average time 0.018000908400131264 iter num 40\n",
            "loss 6.266978016356006e-05 average time 0.017512687520084 iter num 50\n",
            "loss 2.7196616429137066e-05 average time 0.017612802066742005 iter num 60\n",
            "loss 3.20816834573634e-05 average time 0.017982579028648617 iter num 70\n",
            "loss 2.0371426217025146e-05 average time 0.017713137275075043 iter num 80\n",
            "loss 1.7571752323419787e-05 average time 0.017537229822260594 iter num 90\n",
            "loss 5.860760575160384e-05 average time 0.01778421239004274 iter num 100\n",
            "loss 2.9592172722914256e-05 average time 0.018066396200083545 iter num 10\n",
            "loss 3.851232031593099e-05 average time 0.017541229999915232 iter num 20\n",
            "loss 4.3354055378586054e-05 average time 0.017445370333310468 iter num 30\n",
            "loss 5.7060464314417914e-05 average time 0.01810356909998063 iter num 40\n",
            "loss 4.661045750253834e-05 average time 0.017902160119938344 iter num 50\n",
            "loss 4.983253893442452e-05 average time 0.017628551383313606 iter num 60\n",
            "loss 6.108660454628989e-05 average time 0.017408681100031183 iter num 70\n",
            "loss 3.636675319285132e-05 average time 0.017359116825036835 iter num 80\n",
            "loss 9.738711378304288e-05 average time 0.017234388666697163 iter num 90\n",
            "loss 3.671567537821829e-05 average time 0.01721623396002542 iter num 100\n",
            "loss 4.3989060941385105e-05 average time 0.020350809899991874 iter num 10\n",
            "loss 0.0002389200235484168 average time 0.0192375641999206 iter num 20\n",
            "loss 0.00029350793920457363 average time 0.01861046009992909 iter num 30\n",
            "loss 5.2364692237460986e-05 average time 0.018352887474929958 iter num 40\n",
            "loss 0.00010473228758201003 average time 0.01808506553988991 iter num 50\n",
            "loss 2.4709017452551052e-05 average time 0.017803329199872073 iter num 60\n",
            "loss 7.184677087934688e-05 average time 0.017645820885601488 iter num 70\n",
            "loss 2.1851457859156653e-05 average time 0.01773965769989445 iter num 80\n",
            "loss 6.404890882549807e-05 average time 0.01770017719992312 iter num 90\n",
            "loss 2.858619518519845e-05 average time 0.017500022559925128 iter num 100\n",
            "loss 0.0002850775490514934 average time 0.016651959299815645 iter num 10\n",
            "loss 2.821221642079763e-05 average time 0.01657355184993321 iter num 20\n",
            "loss 3.221206497983076e-05 average time 0.016591853899990384 iter num 30\n",
            "loss 9.603892249288037e-05 average time 0.01637016112499623 iter num 40\n",
            "loss 5.2277457143645734e-05 average time 0.01622815504002574 iter num 50\n",
            "loss 3.0232769859139808e-05 average time 0.016460676533354975 iter num 60\n",
            "loss 2.5222348995157517e-05 average time 0.01661093340000142 iter num 70\n",
            "loss 0.00010519471834413707 average time 0.016514757850006844 iter num 80\n",
            "loss 0.000680864613968879 average time 0.016409425822227302 iter num 90\n",
            "loss 4.385437205201015e-05 average time 0.01656681057001151 iter num 100\n",
            "loss 5.3909210691927e-05 average time 0.01849407509980665 iter num 10\n",
            "loss 5.4334501328412443e-05 average time 0.017041712399986864 iter num 20\n",
            "loss 1.9705810700543225e-05 average time 0.017135495133334188 iter num 30\n",
            "loss 0.0003296486975159496 average time 0.017544363974980114 iter num 40\n",
            "loss 6.328077870421112e-05 average time 0.01760283419998814 iter num 50\n",
            "loss 3.0296399927465245e-05 average time 0.017498661283298134 iter num 60\n",
            "loss 0.001077015302143991 average time 0.017347497199963462 iter num 70\n",
            "loss 3.895405097864568e-05 average time 0.01735035379997498 iter num 80\n",
            "loss 8.96636483957991e-05 average time 0.017287903422210447 iter num 90\n",
            "loss 2.8973188818781637e-05 average time 0.0171730719199968 iter num 100\n",
            "loss 3.884163743350655e-05 average time 0.017870317899814837 iter num 10\n",
            "loss 2.819151086441707e-05 average time 0.017034667399821048 iter num 20\n",
            "loss 0.00013967153790872544 average time 0.016777290633247805 iter num 30\n",
            "loss 1.983200854738243e-05 average time 0.01722703047498726 iter num 40\n",
            "loss 7.458967593265697e-05 average time 0.01705664560000514 iter num 50\n",
            "loss 8.720277401152998e-05 average time 0.01716367618334213 iter num 60\n",
            "loss 4.0417926356894895e-05 average time 0.017172606800029046 iter num 70\n",
            "loss 5.53738500457257e-05 average time 0.01740592156253342 iter num 80\n",
            "loss 2.264150680275634e-05 average time 0.01768972590002199 iter num 90\n",
            "loss 1.4162757906888146e-05 average time 0.017628762890017243 iter num 100\n",
            "loss 4.390853428049013e-05 average time 0.017038717699870178 iter num 10\n",
            "loss 4.235325104673393e-05 average time 0.016821184299942615 iter num 20\n",
            "loss 0.00023234020045492798 average time 0.016470917099953415 iter num 30\n",
            "loss 4.384083513286896e-05 average time 0.01650734937497873 iter num 40\n",
            "loss 4.676435128203593e-05 average time 0.01655284054000731 iter num 50\n",
            "loss 4.3654847104335204e-05 average time 0.016940560233342693 iter num 60\n",
            "loss 9.086885256692767e-05 average time 0.01701186035714792 iter num 70\n",
            "loss 5.210989183979109e-05 average time 0.01695914267501166 iter num 80\n",
            "loss 4.9025587941287085e-05 average time 0.01700130713334147 iter num 90\n",
            "loss 0.0012517235008999705 average time 0.017006058280003344 iter num 100\n",
            "loss 0.0001490029681008309 average time 0.01888743469980909 iter num 10\n",
            "loss 2.5492776330793276e-05 average time 0.017344336999940424 iter num 20\n",
            "loss 7.04676567693241e-05 average time 0.017545065499931903 iter num 30\n",
            "loss 4.100096339243464e-05 average time 0.017624544099976446 iter num 40\n",
            "loss 8.344342495547608e-05 average time 0.01738240501998007 iter num 50\n",
            "loss 2.516200765967369e-05 average time 0.01715069536661152 iter num 60\n",
            "loss 1.8373919374425896e-05 average time 0.017264516142807093 iter num 70\n",
            "loss 5.4403812100645155e-05 average time 0.017663541774948045 iter num 80\n",
            "loss 0.0004610311589203775 average time 0.017779044477720163 iter num 90\n",
            "loss 1.0613634003675543e-05 average time 0.017676404129952063 iter num 100\n",
            "loss 3.621290670707822e-05 average time 0.020752730000094744 iter num 10\n",
            "loss 0.00015392339264508337 average time 0.01887292320002416 iter num 20\n",
            "loss 2.511654565751087e-05 average time 0.01811820720004107 iter num 30\n",
            "loss 8.896395593183115e-05 average time 0.017927866675040604 iter num 40\n",
            "loss 2.7702484658220783e-05 average time 0.017532851680061867 iter num 50\n",
            "loss 3.025169098691549e-05 average time 0.017370869933392895 iter num 60\n",
            "loss 5.09592609887477e-05 average time 0.01739060282864427 iter num 70\n",
            "loss 0.00013832631520926952 average time 0.01735717111256463 iter num 80\n",
            "loss 2.5297089450759813e-05 average time 0.01717861495562829 iter num 90\n",
            "loss 3.32915733451955e-05 average time 0.017054008830054954 iter num 100\n",
            "loss 1.7993885194300674e-05 average time 0.018800192599883303 iter num 10\n",
            "loss 2.7506506739882752e-05 average time 0.018244458399885845 iter num 20\n",
            "loss 2.276761551911477e-05 average time 0.0174387410998861 iter num 30\n",
            "loss 3.700478919199668e-05 average time 0.01716634429990336 iter num 40\n",
            "loss 4.419233664521016e-05 average time 0.017274677899949895 iter num 50\n",
            "loss 4.311037264415063e-05 average time 0.017832013516620768 iter num 60\n",
            "loss 2.696975388971623e-05 average time 0.01809520588568765 iter num 70\n",
            "loss 8.973695003078319e-06 average time 0.017845144512477873 iter num 80\n",
            "loss 5.176494596526027e-05 average time 0.01770066489997488 iter num 90\n",
            "loss 2.5038983949343674e-05 average time 0.017498755709984836 iter num 100\n",
            "loss 5.174453690415248e-05 average time 0.017135644600148225 iter num 10\n",
            "loss 2.3214515749714337e-05 average time 0.016639897250070135 iter num 20\n",
            "loss 3.054521221201867e-05 average time 0.017195703333315274 iter num 30\n",
            "loss 0.0006274909828789532 average time 0.01730776527499529 iter num 40\n",
            "loss 2.9146234737709165e-05 average time 0.017071263419966273 iter num 50\n",
            "loss 2.4052422304521315e-05 average time 0.016878907816665862 iter num 60\n",
            "loss 3.317136361147277e-05 average time 0.016924642900007062 iter num 70\n",
            "loss 2.2690479454468004e-05 average time 0.016837691875014115 iter num 80\n",
            "loss 1.847427847678773e-05 average time 0.016806299466659565 iter num 90\n",
            "loss 3.607798498705961e-05 average time 0.01674201255999833 iter num 100\n",
            "loss 4.3926778744207695e-05 average time 0.018619513199791982 iter num 10\n",
            "loss 3.0971987143857405e-05 average time 0.017212390399799916 iter num 20\n",
            "loss 1.0945935173367616e-05 average time 0.016788650466454176 iter num 30\n",
            "loss 4.632079799193889e-05 average time 0.016898200649779937 iter num 40\n",
            "loss 6.301933171926066e-05 average time 0.0167895734798185 iter num 50\n",
            "loss 0.0013479605549946427 average time 0.01660578676652828 iter num 60\n",
            "loss 4.072843148605898e-05 average time 0.01674849389985736 iter num 70\n",
            "loss 0.00011496762454044074 average time 0.016630197174890782 iter num 80\n",
            "loss 2.320513522136025e-05 average time 0.01666225789992192 iter num 90\n",
            "loss 2.7192414563614875e-05 average time 0.016553925419930237 iter num 100\n",
            "loss 2.3608112314832397e-05 average time 0.017912728400006017 iter num 10\n",
            "loss 5.433575279312208e-05 average time 0.01697089175004294 iter num 20\n",
            "loss 5.0643979193409905e-05 average time 0.016683195233357158 iter num 30\n",
            "loss 2.6070891181007028e-05 average time 0.016587382174998312 iter num 40\n",
            "loss 1.93466530618025e-05 average time 0.01658702455999446 iter num 50\n",
            "loss 0.0005385702243074775 average time 0.01645654944997356 iter num 60\n",
            "loss 3.1922660127747804e-05 average time 0.017007480471420422 iter num 70\n",
            "loss 0.0001293578970944509 average time 0.017396004599982008 iter num 80\n",
            "loss 0.00014200950681697577 average time 0.017356993188877824 iter num 90\n",
            "loss 0.00015038919809740037 average time 0.017255010629987737 iter num 100\n",
            "loss 3.233495954191312e-05 average time 0.018608716400103732 iter num 10\n",
            "loss 5.3633495554095134e-05 average time 0.017346237250058037 iter num 20\n",
            "loss 1.75697587110335e-05 average time 0.017244863200054774 iter num 30\n",
            "loss 4.620496474672109e-05 average time 0.017143886649978412 iter num 40\n",
            "loss 5.5741562391631305e-05 average time 0.017637919599983433 iter num 50\n",
            "loss 3.8056412449805066e-05 average time 0.017529924100002366 iter num 60\n",
            "loss 2.1727018975070678e-05 average time 0.01724545485714251 iter num 70\n",
            "loss 5.3440155170392245e-05 average time 0.017219357700003 iter num 80\n",
            "loss 5.055156725575216e-05 average time 0.01709644838887875 iter num 90\n",
            "loss 2.2928867110749707e-05 average time 0.01697548628999357 iter num 100\n",
            "loss 5.526921449927613e-05 average time 0.0169913168997482 iter num 10\n",
            "loss 9.273971954826266e-05 average time 0.016798959749894492 iter num 20\n",
            "loss 2.2883283236296847e-05 average time 0.016389340733257995 iter num 30\n",
            "loss 4.123805774725042e-05 average time 0.01620844759997908 iter num 40\n",
            "loss 7.81112103140913e-05 average time 0.016375242159956543 iter num 50\n",
            "loss 2.0717059669550508e-05 average time 0.01672218379997806 iter num 60\n",
            "loss 0.0003942596958950162 average time 0.016845300128547284 iter num 70\n",
            "loss 2.2404810806619935e-05 average time 0.01699541663749642 iter num 80\n",
            "loss 0.00026088306913152337 average time 0.017038032033350546 iter num 90\n",
            "loss 2.7331727324053645e-05 average time 0.01711010926002018 iter num 100\n",
            "loss 0.001270519569516182 average time 0.01827334649997283 iter num 10\n",
            "loss 8.050198812270537e-05 average time 0.017533365850022166 iter num 20\n",
            "loss 3.260699668317102e-05 average time 0.017209176400016683 iter num 30\n",
            "loss 4.531130980467424e-05 average time 0.01682711742500942 iter num 40\n",
            "loss 3.771567571675405e-05 average time 0.016920623500027432 iter num 50\n",
            "loss 0.0011463850969448686 average time 0.01687062288336468 iter num 60\n",
            "loss 2.6436688131070696e-05 average time 0.01689149405714748 iter num 70\n",
            "loss 2.0246923668310046e-05 average time 0.017041981525028404 iter num 80\n",
            "loss 0.0003548555541783571 average time 0.016924663077831307 iter num 90\n",
            "loss 4.7525281843263656e-05 average time 0.016874373100063168 iter num 100\n",
            "loss 1.8183009160566144e-05 average time 0.01827283510019697 iter num 10\n",
            "loss 4.467188409762457e-05 average time 0.01745298225014267 iter num 20\n",
            "loss 3.037810165551491e-05 average time 0.01693381226674925 iter num 30\n",
            "loss 0.00010293429659213871 average time 0.016856727725053134 iter num 40\n",
            "loss 4.645533044822514e-05 average time 0.016882008840057097 iter num 50\n",
            "loss 7.090717554092407e-05 average time 0.016829061066725142 iter num 60\n",
            "loss 3.5422781365923584e-05 average time 0.016704748985778547 iter num 70\n",
            "loss 0.00018190215632785112 average time 0.016738278425054886 iter num 80\n",
            "loss 5.409933874034323e-05 average time 0.016679338455610884 iter num 90\n",
            "loss 1.5656765754101798e-05 average time 0.016639662690040496 iter num 100\n",
            "loss 4.040031853946857e-05 average time 0.018780774799961365 iter num 10\n",
            "loss 0.00010097982885781676 average time 0.017394989849981356 iter num 20\n",
            "loss 4.3857580749318004e-05 average time 0.016861411666650384 iter num 30\n",
            "loss 2.7226029487792403e-05 average time 0.016600552025010984 iter num 40\n",
            "loss 6.23627738605137e-06 average time 0.016498145460045636 iter num 50\n",
            "loss 3.092139013460837e-05 average time 0.01661774875001356 iter num 60\n",
            "loss 5.336614776751958e-05 average time 0.016570535242863116 iter num 70\n",
            "loss 1.9039543985854834e-05 average time 0.016539235437517164 iter num 80\n",
            "loss 2.2412927137338556e-05 average time 0.01648583073334117 iter num 90\n",
            "loss 1.5953122783685103e-05 average time 0.016493970440005796 iter num 100\n",
            "loss 1.778671685315203e-05 average time 0.01870325230001981 iter num 10\n",
            "loss 4.790418461197987e-05 average time 0.017790425300017888 iter num 20\n",
            "loss 5.2694369514938444e-05 average time 0.017191874900042117 iter num 30\n",
            "loss 1.983907714020461e-05 average time 0.017011466375060992 iter num 40\n",
            "loss 2.0075327483937144e-05 average time 0.017193912340007955 iter num 50\n",
            "loss 7.659470429643989e-05 average time 0.01694928230000793 iter num 60\n",
            "loss 3.226719127269462e-05 average time 0.016848873728564025 iter num 70\n",
            "loss 2.308956754859537e-05 average time 0.016818409112488553 iter num 80\n",
            "loss 4.4033229642082006e-05 average time 0.01680137107775105 iter num 90\n",
            "loss 5.655073618981987e-05 average time 0.016745713479958794 iter num 100\n",
            "loss 0.00011879498924827203 average time 0.01794959180015212 iter num 10\n",
            "loss 4.132630056119524e-05 average time 0.01711756005015559 iter num 20\n",
            "loss 6.0104655858594924e-05 average time 0.016977077000137796 iter num 30\n",
            "loss 2.618938742671162e-05 average time 0.01676084132507185 iter num 40\n",
            "loss 0.0006538881571032107 average time 0.016771103220016813 iter num 50\n",
            "loss 6.564884824911132e-05 average time 0.0166420392333445 iter num 60\n",
            "loss 2.2530404748977162e-05 average time 0.01663538581433386 iter num 70\n",
            "loss 1.9244849681854248e-05 average time 0.016544089175033604 iter num 80\n",
            "loss 5.087398676550947e-05 average time 0.01651541531113657 iter num 90\n",
            "loss 0.0008584229508414865 average time 0.016487409010042028 iter num 100\n",
            "loss 4.967632776242681e-05 average time 0.017844289599997863 iter num 10\n",
            "loss 2.3659426005906425e-05 average time 0.01741658590008228 iter num 20\n",
            "loss 3.6568268114933744e-05 average time 0.017718510166772224 iter num 30\n",
            "loss 4.4949039875064045e-05 average time 0.017788177725037713 iter num 40\n",
            "loss 1.5038227502373047e-05 average time 0.01806523732002461 iter num 50\n",
            "loss 1.4729273061675485e-05 average time 0.018040583816703776 iter num 60\n",
            "loss 5.835569754708558e-05 average time 0.017669343785746604 iter num 70\n",
            "loss 7.942464435473084e-05 average time 0.017444647237527987 iter num 80\n",
            "loss 5.4342381190508604e-05 average time 0.017429017611134946 iter num 90\n",
            "loss 4.397211887408048e-05 average time 0.017310973080029726 iter num 100\n",
            "loss 0.00045796012273058295 average time 0.019203540900070946 iter num 10\n",
            "loss 3.037675742234569e-05 average time 0.018037723850102338 iter num 20\n",
            "loss 3.997866951976903e-05 average time 0.017289123866733765 iter num 30\n",
            "loss 2.8414140615495853e-05 average time 0.01731146062506923 iter num 40\n",
            "loss 6.992454291321337e-05 average time 0.017421617480067653 iter num 50\n",
            "loss 0.0001533206959720701 average time 0.017163957316703695 iter num 60\n",
            "loss 5.44147624168545e-05 average time 0.017074206800056606 iter num 70\n",
            "loss 2.711362685658969e-05 average time 0.017085885287565362 iter num 80\n",
            "loss 2.7449741537566297e-05 average time 0.017109922511149813 iter num 90\n",
            "loss 0.00010826304060174152 average time 0.017076848290025738 iter num 100\n",
            "loss 2.5790350264287554e-05 average time 0.01751416929982952 iter num 10\n",
            "loss 2.8447937438613735e-05 average time 0.0166955725499065 iter num 20\n",
            "loss 0.0011261649196967483 average time 0.017014025333295043 iter num 30\n",
            "loss 5.494745710166171e-05 average time 0.016711158574912587 iter num 40\n",
            "loss 4.0859493310563266e-05 average time 0.01683239327996489 iter num 50\n",
            "loss 5.219568993197754e-05 average time 0.016999027133291142 iter num 60\n",
            "loss 2.135740032827016e-05 average time 0.0169964782142545 iter num 70\n",
            "loss 0.0001909285638248548 average time 0.0168432581999582 iter num 80\n",
            "loss 4.1782470361795276e-05 average time 0.016754421899956167 iter num 90\n",
            "loss 2.6145145966438577e-05 average time 0.016769548189977286 iter num 100\n",
            "loss 5.312115899869241e-05 average time 0.017532654299975546 iter num 10\n",
            "loss 4.2491996282478794e-05 average time 0.01711540159994911 iter num 20\n",
            "loss 2.9469634682754986e-05 average time 0.01741610159994404 iter num 30\n",
            "loss 5.459408203023486e-05 average time 0.018021379299921137 iter num 40\n",
            "loss 2.3570622943225317e-05 average time 0.01786953121991246 iter num 50\n",
            "loss 5.25382456544321e-05 average time 0.017540768316606167 iter num 60\n",
            "loss 0.0005219338345341384 average time 0.0173602790141948 iter num 70\n",
            "loss 3.343600110383704e-05 average time 0.01728002497493435 iter num 80\n",
            "loss 1.0291870239598211e-05 average time 0.017172592777721245 iter num 90\n",
            "loss 0.001360416761599481 average time 0.01704397434994462 iter num 100\n",
            "loss 4.993983748136088e-05 average time 0.019431863099998736 iter num 10\n",
            "loss 6.975458381930366e-05 average time 0.018131134949953776 iter num 20\n",
            "loss 8.612313104094937e-05 average time 0.017350629733361225 iter num 30\n",
            "loss 5.240287646302022e-05 average time 0.01696705542503878 iter num 40\n",
            "loss 0.00011771015851991251 average time 0.016841902660034977 iter num 50\n",
            "loss 2.859390042431187e-05 average time 0.01696149495002525 iter num 60\n",
            "loss 1.0448074135638308e-05 average time 0.016818347200036703 iter num 70\n",
            "loss 3.3221243938896805e-05 average time 0.016689684325035613 iter num 80\n",
            "loss 1.6602569303358905e-05 average time 0.016841303200029262 iter num 90\n",
            "loss 2.5227540390915237e-05 average time 0.016867689230057294 iter num 100\n",
            "loss 3.978534005000256e-05 average time 0.018674217000170756 iter num 10\n",
            "loss 4.531813465291634e-05 average time 0.017239424200079158 iter num 20\n",
            "loss 3.0889863410266116e-05 average time 0.01708313983338788 iter num 30\n",
            "loss 2.5058518076548353e-05 average time 0.017104643400034546 iter num 40\n",
            "loss 3.780555198318325e-05 average time 0.01696458052003436 iter num 50\n",
            "loss 2.1484886019607075e-05 average time 0.01693366336667168 iter num 60\n",
            "loss 3.355231456225738e-05 average time 0.016946830700037805 iter num 70\n",
            "loss 1.333396267000353e-05 average time 0.016918511862536435 iter num 80\n",
            "loss 2.728118488448672e-05 average time 0.016931620800035792 iter num 90\n",
            "loss 3.0173969207680784e-05 average time 0.01684202748001553 iter num 100\n",
            "loss 2.3200464056571946e-05 average time 0.018750376499883713 iter num 10\n",
            "loss 0.00016589692677371204 average time 0.01801301539985616 iter num 20\n",
            "loss 2.7468049665912986e-05 average time 0.017349409366640128 iter num 30\n",
            "loss 3.231532537029125e-05 average time 0.01736128539996571 iter num 40\n",
            "loss 7.129541336325929e-05 average time 0.017049892819959497 iter num 50\n",
            "loss 1.5294022887246683e-05 average time 0.016929552533307895 iter num 60\n",
            "loss 0.0014589742058888078 average time 0.017109108542847806 iter num 70\n",
            "loss 0.0005439470405690372 average time 0.017190276999974684 iter num 80\n",
            "loss 1.5199609151750337e-05 average time 0.017091786377750395 iter num 90\n",
            "loss 3.95221468352247e-05 average time 0.01699863932998596 iter num 100\n",
            "loss 2.758170012384653e-05 average time 0.017514800099888816 iter num 10\n",
            "loss 0.0002772337757050991 average time 0.018675459049791242 iter num 20\n",
            "loss 5.315095404512249e-05 average time 0.017798935866418713 iter num 30\n",
            "loss 1.8100488887284882e-05 average time 0.01757977392483099 iter num 40\n",
            "loss 5.618150680675171e-05 average time 0.01763418135986285 iter num 50\n",
            "loss 3.671161539386958e-05 average time 0.0175958648999161 iter num 60\n",
            "loss 4.64385339000728e-05 average time 0.017384990442769775 iter num 70\n",
            "loss 2.5561756046954542e-05 average time 0.017163041337414597 iter num 80\n",
            "loss 0.0004223852010909468 average time 0.017298157011039924 iter num 90\n",
            "loss 2.2968175471760333e-05 average time 0.01725286312995195 iter num 100\n",
            "loss 0.0003459276631474495 average time 0.016975490400000126 iter num 10\n",
            "loss 5.004500417271629e-05 average time 0.016483422199780762 iter num 20\n",
            "loss 2.4760229280218482e-05 average time 0.01625879319984354 iter num 30\n",
            "loss 1.8813878341461532e-05 average time 0.016517793199909647 iter num 40\n",
            "loss 5.9977777709718794e-05 average time 0.01639981969994551 iter num 50\n",
            "loss 4.0837516280589625e-05 average time 0.01629423969995211 iter num 60\n",
            "loss 2.1366282453527674e-05 average time 0.016432132957093667 iter num 70\n",
            "loss 1.630422775633633e-05 average time 0.01650987233746264 iter num 80\n",
            "loss 3.3678999898256734e-05 average time 0.01642950636661327 iter num 90\n",
            "loss 3.206207838957198e-05 average time 0.0164073167499555 iter num 100\n",
            "loss 5.965756281511858e-05 average time 0.017260583100141957 iter num 10\n",
            "loss 4.431929482962005e-05 average time 0.016978886350170797 iter num 20\n",
            "loss 5.960276030236855e-05 average time 0.01668320246675042 iter num 30\n",
            "loss 0.00017250655218958855 average time 0.01649267785005577 iter num 40\n",
            "loss 3.495420241961256e-05 average time 0.01658045412001229 iter num 50\n",
            "loss 3.980272595072165e-05 average time 0.016748637100014698 iter num 60\n",
            "loss 4.672260183724575e-05 average time 0.016771345928607063 iter num 70\n",
            "loss 2.3507653168053366e-05 average time 0.016717409287525697 iter num 80\n",
            "loss 1.6637677617836744e-05 average time 0.016838934622258724 iter num 90\n",
            "loss 3.257784555898979e-05 average time 0.01687470769002175 iter num 100\n",
            "loss 4.047051697853021e-05 average time 0.018161096299900238 iter num 10\n",
            "loss 7.410479884129018e-05 average time 0.017087891349910934 iter num 20\n",
            "loss 5.897830851608887e-05 average time 0.017467969399937524 iter num 30\n",
            "loss 7.943272066768259e-05 average time 0.017010415224967802 iter num 40\n",
            "loss 3.684116745716892e-05 average time 0.01678876506000961 iter num 50\n",
            "loss 0.00010886528616538271 average time 0.016820787649991568 iter num 60\n",
            "loss 0.00037916292785666883 average time 0.016870360142833565 iter num 70\n",
            "loss 2.0584651792887598e-05 average time 0.01682302333745156 iter num 80\n",
            "loss 5.077847890788689e-05 average time 0.016728857799939253 iter num 90\n",
            "loss 0.00022120038920547813 average time 0.016645736459913678 iter num 100\n",
            "loss 8.67687922436744e-05 average time 0.0215820029000497 iter num 10\n",
            "loss 1.8543945770943537e-05 average time 0.020057562500187486 iter num 20\n",
            "loss 4.4109372538514435e-05 average time 0.0188730090334199 iter num 30\n",
            "loss 1.0381429092376493e-05 average time 0.018577742000093166 iter num 40\n",
            "loss 2.5951692805392668e-05 average time 0.018206425760072305 iter num 50\n",
            "loss 0.00020741349726449698 average time 0.017868336816703353 iter num 60\n",
            "loss 2.47567495534895e-05 average time 0.017624671314310295 iter num 70\n",
            "loss 4.72985630040057e-05 average time 0.017546066225042976 iter num 80\n",
            "loss 5.57708008273039e-05 average time 0.017416739033392838 iter num 90\n",
            "loss 4.9330421461490914e-05 average time 0.01728872474005584 iter num 100\n",
            "loss 4.835207437281497e-05 average time 0.01772946330002014 iter num 10\n",
            "loss 4.387451917864382e-05 average time 0.018480399550117 iter num 20\n",
            "loss 2.5264249416068196e-05 average time 0.018423938233384736 iter num 30\n",
            "loss 2.3917171347420663e-05 average time 0.01776129260001653 iter num 40\n",
            "loss 3.36519988195505e-05 average time 0.017645889519990306 iter num 50\n",
            "loss 3.0480123314191587e-05 average time 0.017347778383297433 iter num 60\n",
            "loss 2.6865931431530043e-05 average time 0.01738536174283841 iter num 70\n",
            "loss 0.00027148419758304954 average time 0.01728715533746481 iter num 80\n",
            "loss 1.4863143405818846e-05 average time 0.017140354022164198 iter num 90\n",
            "loss 8.722180609765928e-06 average time 0.01704946456995458 iter num 100\n",
            "loss 3.439772626734339e-05 average time 0.01718590669988771 iter num 10\n",
            "loss 3.370579725014977e-05 average time 0.016339915599928645 iter num 20\n",
            "loss 5.695111758541316e-05 average time 0.0173574253333148 iter num 30\n",
            "loss 2.655592470546253e-05 average time 0.01760531844997786 iter num 40\n",
            "loss 3.7572164728771895e-05 average time 0.017204819659964413 iter num 50\n",
            "loss 0.00032127805752679706 average time 0.016989088883292425 iter num 60\n",
            "loss 5.5806460295571014e-05 average time 0.017258770399985225 iter num 70\n",
            "loss 1.1479273780423682e-05 average time 0.017200579624977765 iter num 80\n",
            "loss 8.69935829541646e-05 average time 0.01714450904442452 iter num 90\n",
            "loss 3.330999243189581e-05 average time 0.017280948089946832 iter num 100\n",
            "loss 2.871217657229863e-05 average time 0.019040806100019837 iter num 10\n",
            "loss 3.828564877039753e-05 average time 0.018349486249962865 iter num 20\n",
            "loss 2.680978286662139e-05 average time 0.0175469187666143 iter num 30\n",
            "loss 2.1656953322235495e-05 average time 0.018377131399938663 iter num 40\n",
            "loss 1.5960013115545735e-05 average time 0.018386797959974503 iter num 50\n",
            "loss 3.231896334909834e-05 average time 0.01800585484993462 iter num 60\n",
            "loss 2.5108123736572452e-05 average time 0.017760190899921976 iter num 70\n",
            "loss 2.2352127416525036e-05 average time 0.018107416287398335 iter num 80\n",
            "loss 3.3145326597150415e-05 average time 0.018130090477663747 iter num 90\n",
            "loss 1.9449500541668385e-05 average time 0.01794936379989849 iter num 100\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 20000\n",
              "\tepoch: 200\n",
              "\tepoch_length: 100\n",
              "\tmax_epochs: 200\n",
              "\toutput: 1.9449500541668385e-05\n",
              "\tbatch: <class 'tuple'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: <class 'cupy_dataset.OptionDataSet'>\n",
              "\tseed: <class 'NoneType'>\n",
              "\ttimes: <class 'dict'>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2354ad1-8359-4c8e-d59d-6eeaa18a3bb3"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 1, 1, 0.25, 0.3, 0.3]]).cuda() # T, K, S, sigma, mu, r\n",
        "print('price: ' + str(model(inputs.float())))\n",
        "\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient[0][[2]]\n",
        "\n",
        "# price, delta\n",
        "# should be around (0.27130044, 0.90763223)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: tensor([[0.2715]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9231], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lovJwXo3-YEu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "2e22105d-a861-4538-9b9b-e17d41fdb31d"
      },
      "source": [
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "\n",
        "def compute_price(S):\n",
        "    inputs = torch.tensor([[1, 1, S, 0.25, 0.3, 0.3]]).cuda()\n",
        "    return model(inputs.float())\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_prices = []\n",
        "BS_call_prices = []\n",
        "for p in prices:\n",
        "    model_call_prices.append(compute_price(p).item())\n",
        "    BS_call_prices.append(bs_call(p, 1, 1, 0.3, 0.25))\n",
        "\n",
        "#plt.plot(prices, model_call_prices, label = \"model_call_prices\")\n",
        "#plt.plot(prices, BS_call_prices, label = \"BS_call_prices\")\n",
        "plt.plot(prices, np.array(model_call_prices)-np.array(BS_call_prices), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwApH0GT9bBK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "a88e7400-6d51-4773-cd83-14f89575a841"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, S, 0.25, 0.3, 0.3]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 0.75, 1, 0.3, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHgD1NjP7DOW",
        "outputId": "e970504f-4f6f-4b5d-e106-79aa8fc7bc17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 0.75, S, 0.25, 0.3, 0.3]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 0.75, 1, 0.3, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7MfujMQ7oij",
        "outputId": "d9309dcd-df3b-4845-b5d7-c3891d7f0d97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1.25, S, 0.25, 0.3, 0.3]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 1.25, 1, 0.3, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}