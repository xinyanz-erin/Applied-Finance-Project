{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "European_Call_jax.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Judy/European_Call_jax_1stock_v3_BStest_Judy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "daFzpNueawfe"
      },
      "source": [
        "# Use Black-Scholes to Generate Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxFUnc_iBVcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5eb55aa0-3c0f-4cea-b74f-c19acf1ea527"
      },
      "source": [
        "%%writefile cupy_dataset.py\n",
        "import cupy\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "    return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len, number_path, batch, seed, stocks):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 50\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = 1.0 # assume T = 1, use float here\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros((self.N_BATCH, 1 + self.N_STOCKS), dtype=cupy.float32) # output: price, delta1, delta2, delta3\n",
        "        X = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "\n",
        "        for op in range(self.N_BATCH):\n",
        "\n",
        "          ################################################################################################### generate random input numbers\n",
        "\n",
        "          initial_stocks = np.array(0.75 + np.random.random(self.N_STOCKS) * 0.5)\n",
        "\n",
        "          corr = np.diag(np.array([1]*self.N_STOCKS)) # assume no correlation between stocks here\n",
        "          sigma = np.array(0.15 + np.random.random(self.N_STOCKS) * 0.3)\n",
        "          cov = (np.diag(sigma)).dot(corr).dot(np.diag(sigma))\n",
        "\n",
        "          r = np.repeat(np.array(0.25 + np.random.random(1) * 0.35), self.N_STOCKS)\n",
        "          drift = r\n",
        "\n",
        "          T = self.T\n",
        "          K = 0.75 + np.random.random(1) * 0.5\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### apply functions to compute price and deltas\n",
        "\n",
        "          European_Call_price = bs_call(initial_stocks,K,T,r,sigma)\n",
        "          Deltas = bs_delta(initial_stocks,K,T,r,sigma)\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### store input and output numbers in X and Y\n",
        "\n",
        "          Y[op, 0] = European_Call_price[0]\n",
        "          Y[op, 1:4] = cupy.array(Deltas, dtype=cupy.float32)\n",
        "\n",
        "          # T, K, S, sigma, mu, r\n",
        "          paras = (np.repeat(np.array(T), self.N_STOCKS), np.repeat(np.array(K), self.N_STOCKS), initial_stocks, sigma, drift, r)\n",
        "          paras = np.column_stack(paras).reshape(1,-1)[0]\n",
        "          X[op,] = cupy.array(paras)\n",
        "\n",
        "          ###################################################################################################\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "\n",
        "# ds = OptionDataSet(max_len = 2, number_path = 1000000, batch = 2, seed = np.random.randint(10000), stocks=1) # for testing purpose, use constant seed. When training, change to random seed\n",
        "# for i in ds:\n",
        "#     print(i)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cupy_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6JO9OBHdvv",
        "outputId": "ca1b567b-ae09-4765-bcc3-3fe14ce3b18f"
      },
      "source": [
        "%%writefile model.py\n",
        "# version 1,2\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*1, 32) # remember to change this!\n",
        "        self.fc2 = nn.Linear(32, 64)\n",
        "        self.fc3 = nn.Linear(64, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.fc5 = nn.Linear(64, 32)\n",
        "        self.fc6 = nn.Linear(32, 1) # 1 outputs: price\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1.0, 0.5, 0.5, 0.3, 0.35, 0.35]*1)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = (x - torch.tensor([0.0, 0.75, 0.75, 0.15, 0.25, 0.25]*1).cuda()) / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlXD80xPNVc6",
        "outputId": "571c4bdf-9c6c-4935-fc88-1a808c15d55a"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 17.8 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3CyULkENYKb",
        "outputId": "ca69148a-1c44-4a91-c7c0-f265c090e6e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 100000, batch = 32, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()  # let delta weight = 0 for testing\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter) # print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-18b86d18c3e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    829\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 831\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    832\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-18b86d18c3e9>\u001b[0m in \u001b[0;36mtrain_update\u001b[0;34m(engine, batch)\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_order_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompute_deltas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-18b86d18c3e9>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     34\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_order_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcompute_deltas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-18b86d18c3e9>\u001b[0m in \u001b[0;36mcompute_deltas\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m       \u001b[0mfirst_order_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mfirst_order_gradient\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    226\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    227\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m         inputs, allow_unused, accumulate_grad=False)\n\u001b[0m\u001b[1;32m    229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e235a978-e797-4587-c88b-1fcca8f0fb93"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_BStest_J_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Judy/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "837be963-c48b-4fdf-f679-7238d0f626e4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83641fdc-5717-4dff-cc88-6edfb76e6f85"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_1stock_BStest_J_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Judy/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83e7a128-0052-45b1-8245-6316485ce643"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=6, out_features=32, bias=True)\n",
            "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
            "  (fc3): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (fc4): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc5): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc6): Linear(in_features=32, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "outputId": "1a9e3924-c613-4deb-a953-ba1d99fd70a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "#dataset = OptionDataSet(max_len = 100, number_path = 1024, batch = 32, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 1000000, batch = 16, seed = np.random.randint(10000), stocks = 1) # must have random seed\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "\n",
        "    def compute_deltas(x):\n",
        "      inputs = x\n",
        "      inputs.requires_grad = True\n",
        "      first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "      return first_order_gradient[0][[2]]\n",
        "\n",
        "    deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()  # let delta weight = 0 for testing\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 10\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter) # print by multiplying 10000 -> easier to read (actual loss function isn't amplified)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 20)\n",
        "\n",
        "model_save_name = 'jax_european_1stock_BStest_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.00014188152272254229 average time 0.1340962895999951 iter num 10\n",
            "loss 0.0005840245285071433 average time 0.0747592005499996 iter num 20\n",
            "loss 0.0001409179822076112 average time 0.055190294200002654 iter num 30\n",
            "loss 0.00019620910461526364 average time 0.04554171700000324 iter num 40\n",
            "loss 0.0005523122963495553 average time 0.03998939272000257 iter num 50\n",
            "loss 0.00018687125702854246 average time 0.0361342912333356 iter num 60\n",
            "loss 0.00021056077093817294 average time 0.03324353284285897 iter num 70\n",
            "loss 0.00014028367877472192 average time 0.03109255251250076 iter num 80\n",
            "loss 0.00441270787268877 average time 0.029423081666667864 iter num 90\n",
            "loss 0.00044848318793810904 average time 0.028024662690001492 iter num 100\n",
            "loss 0.0009520788444206119 average time 0.01732949649999682 iter num 10\n",
            "loss 0.00020233668328728527 average time 0.017126404500004355 iter num 20\n",
            "loss 0.00021272509184200317 average time 0.01712106110000112 iter num 30\n",
            "loss 0.00015299528604373336 average time 0.01680622435000174 iter num 40\n",
            "loss 0.00011407122656237334 average time 0.016620790760000545 iter num 50\n",
            "loss 0.0001546484709251672 average time 0.01650283469999844 iter num 60\n",
            "loss 0.0021372290793806314 average time 0.016377530742855535 iter num 70\n",
            "loss 0.0001829442917369306 average time 0.016397619587500144 iter num 80\n",
            "loss 0.0002877292863558978 average time 0.016289591011112256 iter num 90\n",
            "loss 0.00023098407837096602 average time 0.016229590590000384 iter num 100\n",
            "loss 0.00018264107347931713 average time 0.017781706300002042 iter num 10\n",
            "loss 0.0002544573799241334 average time 0.01670436249999625 iter num 20\n",
            "loss 0.00013183036935515702 average time 0.01632237153333449 iter num 30\n",
            "loss 0.00035683289752341807 average time 0.016405587474997672 iter num 40\n",
            "loss 0.0012882222654297948 average time 0.016381122299999332 iter num 50\n",
            "loss 0.0010109450668096542 average time 0.016575806683333857 iter num 60\n",
            "loss 0.0006552517879754305 average time 0.016433729057143052 iter num 70\n",
            "loss 0.00021493746316991746 average time 0.01636806357499907 iter num 80\n",
            "loss 0.000447442929726094 average time 0.016448166133332304 iter num 90\n",
            "loss 0.0003914562112186104 average time 0.01645566520999864 iter num 100\n",
            "loss 0.0010238647228106856 average time 0.017704713100005164 iter num 10\n",
            "loss 0.001125212525948882 average time 0.01679981845000498 iter num 20\n",
            "loss 0.00012254105240572244 average time 0.016509425366670407 iter num 30\n",
            "loss 0.0008249253151006997 average time 0.016316538174999097 iter num 40\n",
            "loss 0.00018356677901465446 average time 0.01618642924000028 iter num 50\n",
            "loss 0.0011977865360677242 average time 0.016310360516666834 iter num 60\n",
            "loss 0.00015403014549519867 average time 0.016348711357143688 iter num 70\n",
            "loss 0.00012823044380638748 average time 0.016324109850001635 iter num 80\n",
            "loss 0.0004941538791172206 average time 0.016242161666667698 iter num 90\n",
            "loss 0.00014428235590457916 average time 0.01622516997000105 iter num 100\n",
            "loss 0.0001503480161773041 average time 0.017731366399999615 iter num 10\n",
            "loss 0.0015767667209729552 average time 0.016929159750000623 iter num 20\n",
            "loss 0.00014142863801680505 average time 0.016608256799999783 iter num 30\n",
            "loss 0.000741757801733911 average time 0.017137305575000993 iter num 40\n",
            "loss 0.00016204376879613847 average time 0.017071934419998342 iter num 50\n",
            "loss 0.0006533651612699032 average time 0.016922074599998876 iter num 60\n",
            "loss 0.00013682566350325942 average time 0.016742355928570467 iter num 70\n",
            "loss 0.0033146687783300877 average time 0.016697405687499868 iter num 80\n",
            "loss 0.000273994286544621 average time 0.01656442364444375 iter num 90\n",
            "loss 0.0005750703858211637 average time 0.016490292549999595 iter num 100\n",
            "loss 0.0003723129630088806 average time 0.017254399899996997 iter num 10\n",
            "loss 0.0006089909584261477 average time 0.016441601399992577 iter num 20\n",
            "loss 0.0004722244921140373 average time 0.016299175500002625 iter num 30\n",
            "loss 0.00014714400458615273 average time 0.01629111222500228 iter num 40\n",
            "loss 0.00016811782552395016 average time 0.016179173560003618 iter num 50\n",
            "loss 0.0002037640369962901 average time 0.016154357250001302 iter num 60\n",
            "loss 0.0005545475287362933 average time 0.01608291114286057 iter num 70\n",
            "loss 0.0006056203274056315 average time 0.016064706512502625 iter num 80\n",
            "loss 0.00035602081334218383 average time 0.016007821955557548 iter num 90\n",
            "loss 0.0006061636959202588 average time 0.016067370900003652 iter num 100\n",
            "loss 0.00022445127251558006 average time 0.019314558099989654 iter num 10\n",
            "loss 0.0001288757921429351 average time 0.017566458749993786 iter num 20\n",
            "loss 0.0006487391656264663 average time 0.016941052133328565 iter num 30\n",
            "loss 0.0003102906630374491 average time 0.016639807524997254 iter num 40\n",
            "loss 0.0001025738674798049 average time 0.016689818239999567 iter num 50\n",
            "loss 0.000268383912043646 average time 0.016667141683331957 iter num 60\n",
            "loss 0.0010736872209236026 average time 0.016568605585711438 iter num 70\n",
            "loss 0.00021860835840925574 average time 0.016635010074998034 iter num 80\n",
            "loss 0.001949291443452239 average time 0.016700117411109733 iter num 90\n",
            "loss 0.00011919168900931254 average time 0.016641325109998776 iter num 100\n",
            "loss 0.000695475609973073 average time 0.016680085400003007 iter num 10\n",
            "loss 0.0008771204156801105 average time 0.016658861350001074 iter num 20\n",
            "loss 0.00030569478985853493 average time 0.01671262973333493 iter num 30\n",
            "loss 0.0014084936119616032 average time 0.01669781224999838 iter num 40\n",
            "loss 0.00015921916929073632 average time 0.01670481642000027 iter num 50\n",
            "loss 0.00013651695917360485 average time 0.016932079733333202 iter num 60\n",
            "loss 0.0009160599438473582 average time 0.016763988414284572 iter num 70\n",
            "loss 0.00019267133029643446 average time 0.016867841074998325 iter num 80\n",
            "loss 0.000252628669841215 average time 0.016739441477775726 iter num 90\n",
            "loss 0.0001160677638836205 average time 0.016702110739998943 iter num 100\n",
            "loss 0.00022081569477450103 average time 0.01715507770001068 iter num 10\n",
            "loss 0.0025575554464012384 average time 0.016455236899997772 iter num 20\n",
            "loss 0.00019556561892386526 average time 0.0169333275666645 iter num 30\n",
            "loss 0.0007937149493955076 average time 0.017834569749999217 iter num 40\n",
            "loss 0.00022591737797483802 average time 0.01742579985999896 iter num 50\n",
            "loss 0.0003427537449169904 average time 0.01719223564999955 iter num 60\n",
            "loss 0.00017175558605231345 average time 0.016970400728571023 iter num 70\n",
            "loss 0.0011598614510148764 average time 0.017254913975000362 iter num 80\n",
            "loss 0.0002012031909544021 average time 0.017277474266666735 iter num 90\n",
            "loss 0.0019401955651119351 average time 0.01727492008000013 iter num 100\n",
            "loss 0.00018511104281060398 average time 0.017707287200016707 iter num 10\n",
            "loss 0.0001559345400892198 average time 0.01802990480000517 iter num 20\n",
            "loss 0.0003289200540166348 average time 0.017326885066667803 iter num 30\n",
            "loss 0.00034047485678456724 average time 0.017364257375000136 iter num 40\n",
            "loss 0.00014639632718171924 average time 0.018339892299997017 iter num 50\n",
            "loss 0.0001931071310536936 average time 0.017906094716665658 iter num 60\n",
            "loss 0.00013556717021856457 average time 0.01761718504285779 iter num 70\n",
            "loss 0.0005068396567367017 average time 0.017520163237500698 iter num 80\n",
            "loss 0.00018353117047809064 average time 0.017421974000000597 iter num 90\n",
            "loss 0.00016328330093529075 average time 0.017348305090001192 iter num 100\n",
            "loss 0.00034898336161859334 average time 0.016886078100003487 iter num 10\n",
            "loss 0.0001380054309265688 average time 0.0163828405500027 iter num 20\n",
            "loss 0.000395597075112164 average time 0.016583055900000924 iter num 30\n",
            "loss 0.00017465915880165994 average time 0.016338544775004495 iter num 40\n",
            "loss 0.0001509932626504451 average time 0.0166851919800024 iter num 50\n",
            "loss 0.0014033811166882515 average time 0.016638152833332736 iter num 60\n",
            "loss 0.000269305455731228 average time 0.0165546396714311 iter num 70\n",
            "loss 0.00021001802815590054 average time 0.016449519312501337 iter num 80\n",
            "loss 0.00019641240942291915 average time 0.016580304944445994 iter num 90\n",
            "loss 0.00015979335876181722 average time 0.016886457910000558 iter num 100\n",
            "loss 0.00015275554324034601 average time 0.01835227459999942 iter num 10\n",
            "loss 0.00010264718002872542 average time 0.017058972250001147 iter num 20\n",
            "loss 0.0001578236697241664 average time 0.016644594033332776 iter num 30\n",
            "loss 0.00012957565195392817 average time 0.016559864449999396 iter num 40\n",
            "loss 0.0012781989062204957 average time 0.0167231846199968 iter num 50\n",
            "loss 0.0012251458829268813 average time 0.01661991086666319 iter num 60\n",
            "loss 0.00022902805358171463 average time 0.016555021457139673 iter num 70\n",
            "loss 0.00014274989371187985 average time 0.016892342662497128 iter num 80\n",
            "loss 0.0001719928695820272 average time 0.01690436911110977 iter num 90\n",
            "loss 0.0007555994670838118 average time 0.0168813745999978 iter num 100\n",
            "loss 0.00017584687157068402 average time 0.018346033100004887 iter num 10\n",
            "loss 0.00016730160859879106 average time 0.01824731214999815 iter num 20\n",
            "loss 0.00021009698684792966 average time 0.01741013129999942 iter num 30\n",
            "loss 0.00033946099574677646 average time 0.01701582857499915 iter num 40\n",
            "loss 0.0022520404309034348 average time 0.016841785259998687 iter num 50\n",
            "loss 0.00012470601359382272 average time 0.016964694499999194 iter num 60\n",
            "loss 0.00019115385657642037 average time 0.016762323957141233 iter num 70\n",
            "loss 0.00011730573896784335 average time 0.016612024887497513 iter num 80\n",
            "loss 0.0001392396807204932 average time 0.016575598155551714 iter num 90\n",
            "loss 0.00027190055698156357 average time 0.016629886249996843 iter num 100\n",
            "loss 0.0014155990211293101 average time 0.01668420380000839 iter num 10\n",
            "loss 0.0004341188760008663 average time 0.01620021460000771 iter num 20\n",
            "loss 0.00021923804888501763 average time 0.01677558540000253 iter num 30\n",
            "loss 0.0003561171470209956 average time 0.01696752904999954 iter num 40\n",
            "loss 0.00011859886581078172 average time 0.016770508219999557 iter num 50\n",
            "loss 0.00016644208517391235 average time 0.016761230349999323 iter num 60\n",
            "loss 0.00012307291035540402 average time 0.01688593587142821 iter num 70\n",
            "loss 8.526473538950086e-05 average time 0.016718795362497475 iter num 80\n",
            "loss 0.0004587257280945778 average time 0.01659412666666324 iter num 90\n",
            "loss 0.00025939327315427363 average time 0.016571088799997257 iter num 100\n",
            "loss 0.00020052176842000335 average time 0.017996960199997147 iter num 10\n",
            "loss 8.935220103012398e-05 average time 0.01730298125000047 iter num 20\n",
            "loss 0.00016724133456591517 average time 0.016717309300001187 iter num 30\n",
            "loss 0.004046430811285973 average time 0.016666085349999093 iter num 40\n",
            "loss 0.00015532564430031925 average time 0.016719874659997913 iter num 50\n",
            "loss 0.00013573598698712885 average time 0.016638260583331052 iter num 60\n",
            "loss 0.00012794144276995212 average time 0.016573540042854315 iter num 70\n",
            "loss 0.00015004424494691193 average time 0.016474716149996738 iter num 80\n",
            "loss 0.00021343938715290278 average time 0.01652979414444139 iter num 90\n",
            "loss 0.0001543865946587175 average time 0.016495426479997376 iter num 100\n",
            "loss 0.00021822639973834157 average time 0.016874736200003328 iter num 10\n",
            "loss 0.00013712901272810996 average time 0.016220698899999775 iter num 20\n",
            "loss 0.0005612989771179855 average time 0.016488789800003664 iter num 30\n",
            "loss 0.00019818647706415504 average time 0.017234533625001804 iter num 40\n",
            "loss 0.0018224206287413836 average time 0.017128881500003672 iter num 50\n",
            "loss 0.0010193416383117437 average time 0.01698167548333629 iter num 60\n",
            "loss 0.0003831936919596046 average time 0.01700676018571536 iter num 70\n",
            "loss 0.0002299678890267387 average time 0.016922245075000574 iter num 80\n",
            "loss 0.0001586156286066398 average time 0.016880768388889716 iter num 90\n",
            "loss 0.0002883530396502465 average time 0.016908165979999695 iter num 100\n",
            "loss 0.0004320570733398199 average time 0.017370297599995865 iter num 10\n",
            "loss 0.0003048964717891067 average time 0.017041507000001843 iter num 20\n",
            "loss 0.0003848420165013522 average time 0.016834482366670046 iter num 30\n",
            "loss 0.00022519161575473845 average time 0.016602437050005393 iter num 40\n",
            "loss 0.0005149369244463742 average time 0.01648710132000474 iter num 50\n",
            "loss 0.00017231002857442945 average time 0.016555794000004197 iter num 60\n",
            "loss 0.0002820744120981544 average time 0.016739939214288922 iter num 70\n",
            "loss 0.0011403069365769625 average time 0.017186367162503303 iter num 80\n",
            "loss 0.00012602019705809653 average time 0.017276050611115402 iter num 90\n",
            "loss 0.00026547303423285484 average time 0.017290975840003286 iter num 100\n",
            "loss 0.00012638863699976355 average time 0.01787444139999934 iter num 10\n",
            "loss 0.00011502720008138567 average time 0.016790510849997987 iter num 20\n",
            "loss 0.00022794335382059216 average time 0.01683824546666794 iter num 30\n",
            "loss 0.00014048161392565817 average time 0.01676330427499977 iter num 40\n",
            "loss 0.00034153449814766645 average time 0.016601590079999368 iter num 50\n",
            "loss 0.0004532243183348328 average time 0.016472002249998733 iter num 60\n",
            "loss 0.0003609033883549273 average time 0.016504290299998763 iter num 70\n",
            "loss 0.0009349443134851754 average time 0.017635753199999726 iter num 80\n",
            "loss 0.00011957815877394751 average time 0.017611868122220483 iter num 90\n",
            "loss 0.00018033089872915298 average time 0.01756692613999917 iter num 100\n",
            "loss 0.00032907002605497837 average time 0.019075249700006226 iter num 10\n",
            "loss 0.00021083492902107537 average time 0.017950281150001503 iter num 20\n",
            "loss 0.00010161761019844562 average time 0.01765853576666435 iter num 30\n",
            "loss 0.0001419985492248088 average time 0.017490311999996778 iter num 40\n",
            "loss 8.6402207671199e-05 average time 0.01762890633999973 iter num 50\n",
            "loss 0.0016452751588076353 average time 0.017512310433333293 iter num 60\n",
            "loss 0.0009061070159077644 average time 0.017405267114286613 iter num 70\n",
            "loss 0.002838342683389783 average time 0.017657038212500708 iter num 80\n",
            "loss 8.853326289681718e-05 average time 0.017569644611110866 iter num 90\n",
            "loss 0.00012621608038898557 average time 0.017535073969999645 iter num 100\n",
            "loss 0.00026898382930085063 average time 0.01814205330001073 iter num 10\n",
            "loss 0.00014155375538393855 average time 0.01730202335000115 iter num 20\n",
            "loss 0.0002570335927885026 average time 0.017062394000004134 iter num 30\n",
            "loss 0.00011284385982435197 average time 0.01711145522500317 iter num 40\n",
            "loss 0.00010834071144927293 average time 0.017291329900003802 iter num 50\n",
            "loss 0.00018794478091876954 average time 0.01713231150000354 iter num 60\n",
            "loss 0.0004593880439642817 average time 0.016969205442861884 iter num 70\n",
            "loss 0.00024263025261461735 average time 0.017081217587503517 iter num 80\n",
            "loss 0.0001781725586624816 average time 0.016999213900004407 iter num 90\n",
            "loss 0.00019871973199769855 average time 0.017031681020004043 iter num 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "outputId": "e2354ad1-8359-4c8e-d59d-6eeaa18a3bb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 1, 1, 0.25, 0.3, 0.3]]).cuda() # T, K, S, sigma, mu, r\n",
        "print('price: ' + str(model(inputs.float())))\n",
        "\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient[0][[2]]\n",
        "\n",
        "# price, delta\n",
        "# should be around (0.27130044, 0.90763223)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: tensor([[0.2715]], device='cuda:0', grad_fn=<AddmmBackward>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9231], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lovJwXo3-YEu",
        "outputId": "5680f6c6-f50c-4e67-df4c-5b383eb3914a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "from scipy.stats import norm\n",
        "from math import log, sqrt, pi, exp\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def d1(S,K,T,r,sigma):\n",
        "    return(log(S/K)+(r+sigma**2/2.)*T)/(sigma*sqrt(T))\n",
        "def d2(S,K,T,r,sigma):\n",
        "    return d1(S,K,T,r,sigma)-sigma*sqrt(T)    \n",
        "def bs_call(S,K,T,r,sigma):\n",
        "    return S*norm.cdf(d1(S,K,T,r,sigma))-K*exp(-r*T)*norm.cdf(d2(S,K,T,r,sigma))\n",
        "\n",
        "def compute_price(S):\n",
        "    inputs = torch.tensor([[1, 1, S, 0.25, 0.3, 0.3]]).cuda()\n",
        "    return model(inputs.float())\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_prices = []\n",
        "BS_call_prices = []\n",
        "for p in prices:\n",
        "    model_call_prices.append(compute_price(p).item())\n",
        "    BS_call_prices.append(bs_call(p, 1, 1, 0.3, 0.25))\n",
        "\n",
        "#plt.plot(prices, model_call_prices, label = \"model_call_prices\")\n",
        "#plt.plot(prices, BS_call_prices, label = \"BS_call_prices\")\n",
        "plt.plot(prices, np.array(model_call_prices)-np.array(BS_call_prices), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwApH0GT9bBK",
        "outputId": "b4b4b1e1-a894-4132-ca24-b36d3934b65c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, S, 0.25, 0.3, 0.3]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "\n",
        "def bs_delta(S,K,T,r,sigma):\n",
        "  return norm.cdf(d1(S,K,T,r,sigma))\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "BS_call_deltas = []\n",
        "for p in prices:\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    BS_call_deltas.append(bs_delta(p, 1, 1, 0.3, 0.25))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, BS_call_deltas, label = \"BS_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(BS_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}