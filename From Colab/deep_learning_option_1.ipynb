{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"deep_learning_option_1.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"uEOzBi66EYup"},"source":["### Deep Learning Barrier Option\n","\n","We used Numba and CuPy in the previous notebook to run Monte Carlo simulation to determine the price of the Asian Barrier option. A Monte Carlo simulation needs millions of paths to get an accurate answer which is computationally intensive. [Ryan et al (2018)](https://arxiv.org/abs/1809.02233) showed that a deep learning model can be trained to value derivatives. The deep learning model is accurate and very fast, capable of producing valuations a million times faster than traditional models. In the this notebook, we will use a fully connected network to learn the pricing mode of the Asian Barrier option. Monte Carlo simulation is used as pricing ground truth for the training. We use the same Asian Barrier Option model as last notebook with parameters listed as following:\n","\n","```\n","T - Maturity (yrs.)\n","S - Spot (usd)\n","K - Strike (usd)\n","sigma - Volatility (per.)\n","r - Risk Free Rate (per.)\n","mu - Stock Drift Rate (per.)\n","B - Barrier (usd)\n","```\n","\n","### Batched Data generation\n","\n","The dataset is an important part of the Deep learning training. We will modify the previous single Asian Barrier Option pricing code to handle a batch of Barrier Option pricing. \n","\n","Loading all the necessary libraries:-"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rmLieKk5M0wC","executionInfo":{"status":"ok","timestamp":1622128110990,"user_tz":420,"elapsed":16924,"user":{"displayName":"Pui Ieng Lei","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUxB62djaXyekhwBWrALyZjUPepPF_29I1tV5i=s64","userId":"03446030301916229832"}},"outputId":"461ec237-2fca-4437-fc17-cf08f523574b"},"source":["!curl https://colab.chainer.org/install |sh -\n","import cupy"],"execution_count":null,"outputs":[{"output_type":"stream","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100  1580  100  1580    0     0   7214      0 --:--:-- --:--:-- --:--:--  7181\n","+ apt -y -q install cuda-libraries-dev-10-0\n","Reading package lists...\n","Building dependency tree...\n","Reading state information...\n","cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n","The following package was automatically installed and is no longer required:\n","  libnvidia-common-460\n","Use 'apt autoremove' to remove it.\n","0 upgraded, 0 newly installed, 0 to remove and 34 not upgraded.\n","+ pip install -q cupy-cuda100  chainer \n","\u001b[K     |████████████████████████████████| 58.9MB 86kB/s \n","\u001b[?25h+ set +ex\n","Installation succeeded!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IF6DPA5OEYuw"},"source":["import cupy\n","import numpy as np\n","import math\n","import time\n","import torch\n","cupy.cuda.set_allocator(None)\n","from torch.utils.dlpack import from_dlpack"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M43-u7-0EYuw"},"source":["The CuPy version of batched barrier option pricing simulation is as follows:-"]},{"cell_type":"code","metadata":{"id":"QChqz4N5EYuw"},"source":["cupy_batched_barrier_option = cupy.RawKernel(r'''\n","extern \"C\" __global__ void batched_barrier_option(\n","    float *d_s,\n","    const float T,\n","    const float * K,\n","    const float * B,\n","    const float * S0,\n","    const float * sigma,\n","    const float * mu,\n","    const float * r,\n","    const float * d_normals,\n","    const long N_STEPS,\n","    const long N_PATHS,\n","    const long N_BATCH)\n","{\n","  unsigned idx =  threadIdx.x + blockIdx.x * blockDim.x;\n","  unsigned stride = blockDim.x * gridDim.x; \n","  unsigned tid = threadIdx.x;\n","  const float tmp3 = sqrt(T/N_STEPS);\n","\n","\n","  for (unsigned i = idx; i<N_PATHS * N_BATCH; i+=stride)\n","  {\n","    int batch_id = i / N_PATHS;\n","    int path_id = i % N_PATHS;\n","    float s_curr = S0[batch_id];\n","    float tmp1 = mu[batch_id]*T/N_STEPS;\n","    float tmp2 = exp(-r[batch_id]*T);\n","    unsigned n=0;\n","    double running_average = 0.0;\n","    for(unsigned n = 0; n < N_STEPS; n++){\n","       s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH];\n","       running_average += (s_curr - running_average) / (n + 1.0);\n","       if (running_average <= B[batch_id]){\n","           break;\n","       }\n","    }\n","\n","    float payoff = (running_average>K[batch_id] ? running_average-K[batch_id] : 0.f); \n","    d_s[i] = tmp2 * payoff;\n","  }\n","}\n","\n","''', 'batched_barrier_option')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Pxm-wwZTEYux"},"source":["Note, the parameters (K, B, S0, sigma, mu, r) are passed in as an array with length of batch size. The output array is a two dimensional array flatten to 1-D. The first dimension is for Batch and the second dimension is for Path. \n","\n","Testing it out by entering two sets of option parameters:-"]},{"cell_type":"code","metadata":{"id":"Mw-DYhsnEYux"},"source":["N_PATHS = 2048000\n","N_STEPS = 365\n","N_BATCH = 2\n","T = 1.0\n","\n","K = cupy.array([110.0, 120.0], dtype=cupy.float32)\n","B = cupy.array([100.0, 90.0], dtype=cupy.float32)\n","S0 = cupy.array([120.0, 100.0], dtype=cupy.float32)\n","sigma = cupy.array([0.35, 0.2], dtype=cupy.float32)\n","mu = cupy.array([0.15, 0.1], dtype=cupy.float32)\n","r =cupy.array([0.05, 0.05], dtype=cupy.float32)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KvQRXFcJEYuy"},"source":["Put everything into a simple function to launch this GPU kernel. The option prices for each batch is the average of the corresponding path terminal values. This can be computed easily by Cupy function `mean(axis=1)`"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yn2uRjJmEYuy","executionInfo":{"status":"error","timestamp":1620876338640,"user_tz":-480,"elapsed":1099,"user":{"displayName":"YILIAN ZHANG","photoUrl":"","userId":"00778400246289834299"}},"outputId":"17bd4174-a2cd-4a5b-da58-53f73c6bad8e"},"source":["############ new\n","batch_randoms_mean = np.zeros(2) # assume 2 options\n","batch_randoms_cov = [[1, 0],[0, 1]]\n","num_of_randoms_each_batch = N_PATHS * N_STEPS\n","############ new\n","\n","def batch_run():\n","    number_of_threads = 256\n","    number_of_blocks = (N_PATHS * N_BATCH - 1) // number_of_threads + 1\n","    #randoms_gpu = cupy.random.normal(0, 1, N_BATCH*N_PATHS * N_STEPS, dtype=cupy.float32)\n","    #new\n","    ############ new\n","    randoms_gpu=np.random.multivariate_normal(batch_randoms_mean, batch_randoms_cov, N_PATHS).T.reshape(-1).tolist()*N_STEPS\n","      \n","    ############ new\n","    #new\n","    output = cupy.zeros(N_BATCH*N_PATHS, dtype=cupy.float32)\n","    cupy.cuda.stream.get_current_stream().synchronize()\n","    s = time.time()\n","    cupy_batched_barrier_option((number_of_blocks,), (number_of_threads,),\n","                       (output, np.float32(T), K, B, S0, sigma, mu, r,\n","                        randoms_gpu, N_STEPS, N_PATHS, N_BATCH))\n","    v = output.reshape(N_BATCH, N_PATHS).mean(axis=1)\n","    cupy.cuda.stream.get_current_stream().synchronize()\n","    e = time.time()\n","    print('time', e-s, 'v',v)\n","batch_run()"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-56db144feed2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m############ new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbatch_randoms_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# assume 2 options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mbatch_randoms_cov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_of_randoms_each_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mN_PATHS\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mN_STEPS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m############ new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"l3aq4CSwEYuz"},"source":["This produces the option prices $21.22$ and $0.848$ for these two sets of option parameters in $66ms$.\n","\n","It works efficiently hence we will construct an `OptionDataSet` class to wrap the above code so we can use it in Pytorch. For every `next` element, it generates uniform distributed random option parameters in the specified range, launches the GPU kernel to compute the option prices, convert the CuPy array to Pytorch tensors with zero copy via the DLPack. Note how we implemented the iterable Dataset interface:-"]},{"cell_type":"code","metadata":{"id":"PW10BqLREYuz"},"source":["class OptionDataSet(torch.utils.data.IterableDataset):\n","    \n","    def __init__(self, max_len=10, number_path = 1000, batch=2, threads=256,seed=15):\n","        self.num = 0\n","        self.max_length = max_len\n","        self.N_PATHS = number_path\n","        self.N_STEPS = 365\n","        self.N_BATCH = batch\n","        self.T = np.float32(1.0)\n","        self.output = cupy.zeros(self.N_BATCH*self.N_PATHS, dtype=cupy.float32) \n","        self.number_of_blocks = (self.N_PATHS * self.N_BATCH - 1) // threads + 1\n","        self.number_of_threads = threads\n","        cupy.random.seed(seed)\n","        \n","    def __len__(self):\n","        return self.max_length\n","        \n","    def __iter__(self):\n","        self.num = 0\n","        return self\n","    \n","    def __next__(self):\n","        if self.num > self.max_length:\n","            raise StopIteration\n","        X = cupy.random.rand(self.N_BATCH, 6, dtype=cupy.float32)\n","        # scale the [0, 1) random numbers to the correct range for each of the option parameters\n","        X = X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2], dtype=cupy.float32)\n","        # make sure the Barrier is smaller than the Strike price\n","        X[:, 1] = X[:, 0] * X[:, 1]\n","        randoms = cupy.random.normal(0, 1, self.N_BATCH * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n","        cupy_batched_barrier_option((self.number_of_blocks,), (self.number_of_threads,), (self.output, self.T, cupy.ascontiguousarray(X[:, 0]), \n","                              cupy.ascontiguousarray(X[:, 1]), cupy.ascontiguousarray(X[:, 2]), cupy.ascontiguousarray(X[:, 3]), cupy.ascontiguousarray(X[:, 4]), cupy.ascontiguousarray(X[:, 5]), randoms, self.N_STEPS, self.N_PATHS, self.N_BATCH))\n","        Y = self.output.reshape(self.N_BATCH, self.N_PATHS).mean(axis=1)\n","        self.num += 1\n","        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5gYAOpv5EYu0"},"source":["Put everything related to Pytorch dataset into a file `cupy_dataset.py`:-"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4rq4tG2XEYu0","executionInfo":{"status":"ok","timestamp":1620869283900,"user_tz":-480,"elapsed":1308,"user":{"displayName":"YILIAN ZHANG","photoUrl":"","userId":"00778400246289834299"}},"outputId":"7a52c804-d346-4014-cc68-29df974c5b15"},"source":["%%writefile cupy_dataset.py \n","import cupy\n","import numpy as np\n","import torch\n","from torch.utils.dlpack import from_dlpack\n","cupy.cuda.set_allocator(None)\n","\n","cupy_batched_barrier_option = cupy.RawKernel(r'''\n","extern \"C\" __global__ void batched_barrier_option(\n","    float *d_s,\n","    const float T,\n","    const float * K,\n","    const float * B,\n","    const float * S0,\n","    const float * sigma,\n","    const float * mu,\n","    const float * r,\n","    const float * d_normals,\n","    const long N_STEPS,\n","    const long N_PATHS,\n","    const long N_BATCH)\n","{\n","  unsigned idx =  threadIdx.x + blockIdx.x * blockDim.x;\n","  unsigned stride = blockDim.x * gridDim.x;\n","  unsigned tid = threadIdx.x;\n","  const float tmp3 = sqrt(T/N_STEPS);\n","\n","\n","  for (unsigned i = idx; i<N_PATHS * N_BATCH; i+=stride)\n","  {\n","    int batch_id = i / N_PATHS;\n","    int path_id = i % N_PATHS;\n","    float s_curr = S0[batch_id];\n","    float tmp1 = mu[batch_id]*T/N_STEPS;\n","    float tmp2 = exp(-r[batch_id]*T);\n","    unsigned n=0;\n","    double running_average = 0.0;\n","    for(unsigned n = 0; n < N_STEPS; n++){\n","       s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH];\n","       running_average += (s_curr - running_average) / (n + 1.0);\n","       if (running_average <= B[batch_id]){\n","           break;\n","       }\n","    }\n","\n","    float payoff = (running_average>K[batch_id] ? running_average-K[batch_id] : 0.f); \n","    d_s[i] = tmp2 * payoff;\n","  }\n","}\n","\n","''', 'batched_barrier_option')\n","\n","class OptionDataSet(torch.utils.data.IterableDataset):\n","    \n","    def __init__(self, max_len=10, number_path = 1000, batch=2, threads=256,seed=15):\n","        self.num = 0\n","        self.max_length = max_len\n","        self.N_PATHS = number_path\n","        self.N_STEPS = 365\n","        self.N_BATCH = batch\n","        self.T = np.float32(1.0)\n","        self.output = cupy.zeros(self.N_BATCH*self.N_PATHS, dtype=cupy.float32) \n","        self.number_of_blocks = (self.N_PATHS * self.N_BATCH - 1) // threads + 1\n","        self.number_of_threads = threads\n","        cupy.random.seed(seed)\n","        \n","    def __len__(self):\n","        return self.max_length\n","        \n","    def __iter__(self):\n","        self.num = 0\n","        return self\n","    \n","    def __next__(self):\n","        if self.num > self.max_length:\n","            raise StopIteration\n","        X = cupy.random.rand(self.N_BATCH, 6, dtype=cupy.float32)\n","        # scale the [0, 1) random numbers to the correct range for each of the option parameters\n","        X = X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2], dtype=cupy.float32)\n","        # make sure the Barrier is smaller than the Strike price\n","        X[:, 1] = X[:, 0] * X[:, 1]\n","        randoms = cupy.random.normal(0, 1, self.N_BATCH * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n","        cupy_batched_barrier_option((self.number_of_blocks,), (self.number_of_threads,), (self.output, self.T, cupy.ascontiguousarray(X[:, 0]), \n","                              cupy.ascontiguousarray(X[:, 1]), cupy.ascontiguousarray(X[:, 2]), cupy.ascontiguousarray(X[:, 3]), cupy.ascontiguousarray(X[:, 4]), cupy.ascontiguousarray(X[:, 5]), randoms, self.N_STEPS, self.N_PATHS, self.N_BATCH))\n","        Y = self.output.reshape(self.N_BATCH, self.N_PATHS).mean(axis=1)\n","        self.num += 1\n","        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing cupy_dataset.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tud-Pyv2EYu0"},"source":["Here is a test code to sample 10 data points with batch size 16:-"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PlRX91WUEYu1","executionInfo":{"status":"ok","timestamp":1620869300756,"user_tz":-480,"elapsed":13692,"user":{"displayName":"YILIAN ZHANG","photoUrl":"","userId":"00778400246289834299"}},"outputId":"064da766-2d49-409b-97a3-768c6b974d8d"},"source":["from cupy_dataset import OptionDataSet\n","ds = OptionDataSet(10, number_path=100000, batch=16, seed=15)\n","for i in ds:\n","    print(i[1])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([1.6558e+02, 0.0000e+00, 8.0069e+01, 1.0866e+02, 7.7740e-03, 0.0000e+00,\n","        2.7772e+01, 0.0000e+00, 0.0000e+00, 6.4279e+01, 0.0000e+00, 5.1346e+00,\n","        0.0000e+00, 1.4733e+02, 4.1851e+01, 0.0000e+00], device='cuda:0')\n","tensor([ 57.1285,   0.0000,   0.0000, 151.9433,   0.0000,   0.0000,   0.0000,\n","          9.3306,   0.0000,   0.7246, 157.0885,  10.7096,   0.0000,   0.7067,\n","         59.1110,  14.6442], device='cuda:0')\n","tensor([106.4531,   0.0000,  51.1248,  12.7823,  67.4821,   0.0000,   7.3539,\n","          0.0000, 143.2203,  66.0655,  66.5477, 129.6811,   0.0000,  13.5559,\n","         27.5546,   0.0000], device='cuda:0')\n","tensor([4.1777e+01, 0.0000e+00, 2.5890e+00, 1.4500e+02, 0.0000e+00, 1.5099e+00,\n","        1.1183e+02, 5.6967e+01, 7.5750e-05, 1.2390e+01, 0.0000e+00, 3.0183e+01,\n","        1.3890e+01, 5.0533e+01, 3.8499e+01, 8.2232e+01], device='cuda:0')\n","tensor([1.0687e+02, 3.0590e+01, 8.5428e+01, 1.9835e+01, 3.0602e+01, 1.5230e+00,\n","        0.0000e+00, 0.0000e+00, 4.0244e+01, 0.0000e+00, 3.7487e-01, 0.0000e+00,\n","        1.1777e+02, 0.0000e+00, 9.6200e+00, 4.2073e-04], device='cuda:0')\n","tensor([ 83.6088, 125.8481,   0.0000,   0.0000,   0.0000,  35.1237,  26.4887,\n","        114.6908,   1.2338, 133.6484,  84.3443,  49.0381,  33.3620,  93.0905,\n","         40.8572,  30.2684], device='cuda:0')\n","tensor([1.6068e+01, 6.8251e+01, 1.7516e+00, 6.3889e+01, 2.0682e+00, 3.0282e-01,\n","        2.3074e-04, 2.4942e+01, 1.1639e+02, 0.0000e+00, 3.0597e+01, 0.0000e+00,\n","        3.0390e+01, 2.1144e+00, 8.2769e-04, 6.3105e+01], device='cuda:0')\n","tensor([129.0360,   0.0000,   0.0000,  34.7129,  76.3240,  61.5014,  96.1047,\n","         41.5991,   0.0000,   0.0000,   1.6868,   0.0000,   0.0000, 198.8765,\n","          0.0000, 130.8935], device='cuda:0')\n","tensor([23.4824, 49.1953, 70.5731,  0.0000,  0.0000, 35.5231,  0.0000,  0.0000,\n","         0.0000, 64.7130,  0.0000, 56.6821,  3.6377,  0.0000,  0.0000, 17.6415],\n","       device='cuda:0')\n","tensor([113.4123,   0.2840,   0.0000,   9.8790,  34.9789,  62.0461,   0.0000,\n","          0.0000,  90.4281, 151.8807,   0.0000,   0.0000,  75.6426, 137.9153,\n","          0.0000,  65.4237], device='cuda:0')\n","tensor([1.1853e+02, 0.0000e+00, 0.0000e+00, 3.5182e+01, 8.2466e+01, 0.0000e+00,\n","        0.0000e+00, 1.7089e+01, 0.0000e+00, 2.8777e-02, 0.0000e+00, 0.0000e+00,\n","        6.7766e+01, 3.9360e+01, 1.2019e+02, 1.0623e+02], device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"UW1hbp9wEYu1"},"source":["We can implement the same code by using Numba to accelerate the calculation in GPU:-"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VKlTmRoFEYu1","executionInfo":{"status":"ok","timestamp":1621539594416,"user_tz":420,"elapsed":1345,"user":{"displayName":"Pui Ieng Lei","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiUxB62djaXyekhwBWrALyZjUPepPF_29I1tV5i=s64","userId":"03446030301916229832"}},"outputId":"e0bd7d36-da48-4177-a93c-36d67db147d0"},"source":["import numba\n","from numba import cuda\n","\n","@cuda.jit\n","def batch_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_BATCH):\n","    # ii - overall thread index\n","    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n","    stride = cuda.gridDim.x * cuda.blockDim.x\n","    tmp3 = math.sqrt(T/N_STEPS)\n","    for i in range(ii, N_PATHS * N_BATCH, stride):\n","        batch_id = i // N_PATHS\n","        path_id = i % N_PATHS\n","        tmp1 = mu[batch_id]*T/N_STEPS\n","        tmp2 = math.exp(-r[batch_id]*T)\n","        running_average = 0.0\n","        s_curr = S0[batch_id]\n","        for n in range(N_STEPS):\n","\n","            s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH]\n","            running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average)\n","            if i==0 and batch_id == 2:\n","                print(s_curr)\n","            if running_average <= B[batch_id]:\n","                break\n","        payoff = running_average - K[batch_id] if running_average > K[batch_id] else 0\n","        d_s[i] = tmp2 * payoff\n","\n","class NumbaOptionDataSet(object):\n","    \n","    def __init__(self, max_len=10, number_path = 1000, batch=2, threads=512, seed=15):\n","        self.num = 0\n","        self.max_length = max_len\n","        self.N_PATHS = number_path\n","        self.N_STEPS = 365\n","        self.N_BATCH = batch\n","        self.T = np.float32(1.0)\n","        self.output = cupy.zeros(self.N_BATCH*self.N_PATHS, dtype=cupy.float32) \n","        self.number_of_blocks = (self.N_PATHS * self.N_BATCH - 1) // threads + 1\n","        self.number_of_threads = threads\n","        cupy.random.seed(seed)\n","        \n","    def __len__(self):\n","        return self.max_length\n","        \n","    def __iter__(self):\n","        self.num = 0\n","        return self\n","    \n","    def __next__(self):\n","        if self.num > self.max_length:\n","            raise StopIteration\n","        X = cupy.random.rand(self.N_BATCH, 6, dtype=cupy.float32)\n","        # scale the [0, 1) random numbers to the correct range for each of the option parameters\n","        X = X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2], dtype=cupy.float32)\n","        # make sure the Barrier is smaller than the Strike price\n","        X[:, 1] = X[:, 0] * X[:, 1]\n","        randoms = cupy.random.normal(0, 1, self.N_BATCH * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n","        batch_barrier_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, self.T, X[:, 0], \n","                              X[:, 1], X[:, 2], X[:, 3], X[:, 4], X[:, 5], randoms, self.N_STEPS, self.N_PATHS, self.N_BATCH)\n","        o = self.output.reshape(self.N_BATCH, self.N_PATHS)\n","        Y = o.mean(axis = 1) \n","        self.num += 1\n","        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n","ds = NumbaOptionDataSet(10, number_path=100000, batch=16, seed=15)\n","for i in ds:\n","    print(i[0])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tensor([[1.9457e+00, 1.8871e+00, 1.7567e+02, 2.0259e-01, 8.5928e-02, 9.1372e-02],\n","        [1.7481e+02, 1.7438e+01, 3.2583e+00, 3.2982e-01, 7.5514e-02, 1.6369e-01],\n","        [3.8505e+01, 5.6858e+00, 1.1748e+02, 6.6546e-02, 1.7105e-01, 1.1292e-01],\n","        [1.1366e+01, 8.1279e+00, 1.2313e+02, 5.9031e-02, 1.5480e-01, 1.1450e-01],\n","        [7.0529e+01, 4.9136e+01, 4.7651e+01, 3.4177e-01, 1.0905e-01, 1.6616e-01],\n","        [1.5266e+02, 9.3798e+01, 2.6399e+01, 3.5824e-01, 1.7637e-01, 9.1670e-03],\n","        [7.4384e+01, 1.1629e+01, 1.0270e+02, 1.7103e-01, 4.1813e-02, 9.4083e-02],\n","        [1.9053e+02, 1.7639e+02, 4.6447e+01, 2.6284e-01, 1.0312e-01, 7.3422e-02],\n","        [1.9684e+02, 1.0813e+02, 3.0879e+01, 3.2332e-02, 1.2593e-01, 7.8122e-02],\n","        [8.8041e+01, 2.8121e+01, 1.5323e+02, 1.5107e-01, 7.0976e-02, 9.6186e-02],\n","        [9.2348e+01, 9.0936e+01, 8.4234e+01, 2.4153e-01, 1.9698e-01, 3.0116e-02],\n","        [2.6359e+00, 5.4071e-02, 7.8258e+00, 2.8392e-01, 7.2371e-02, 6.4143e-02],\n","        [5.8060e+01, 5.4487e+01, 1.5163e+01, 6.5020e-02, 1.4522e-01, 1.6333e-01],\n","        [5.4332e+01, 2.5507e+00, 1.9835e+02, 8.3308e-02, 1.3431e-01, 6.9810e-02],\n","        [5.1797e+01, 2.6331e+01, 8.7489e+01, 2.9576e-01, 1.8233e-01, 5.5179e-02],\n","        [1.0451e+02, 5.9819e+01, 1.8022e+01, 1.8580e-01, 2.5920e-02, 1.3207e-01]],\n","       device='cuda:0')\n","tensor([[3.5022e+01, 9.9263e+00, 9.0914e+01, 3.5930e-01, 1.9425e-01, 1.3542e-01],\n","        [1.4759e+02, 3.3616e+00, 6.0752e+01, 2.7982e-01, 1.9885e-01, 5.1366e-02],\n","        [1.6504e+02, 1.1523e+02, 1.8604e+01, 1.8683e-01, 1.0446e-01, 3.8722e-03],\n","        [2.9067e+01, 1.4227e+01, 1.7990e+02, 8.1958e-02, 1.6212e-01, 9.0131e-02],\n","        [1.3614e+02, 9.3947e+01, 2.2694e+01, 1.4309e-01, 1.5074e-01, 1.4069e-01],\n","        [1.7750e+02, 1.6237e+02, 8.7401e+01, 3.2359e-03, 9.4640e-02, 1.5125e-02],\n","        [1.0691e+02, 3.9452e+01, 1.5003e+01, 1.7009e-01, 9.8782e-03, 1.9020e-01],\n","        [1.9693e+02, 1.0908e+02, 1.7148e+02, 3.8268e-01, 1.3697e-01, 1.9943e-01],\n","        [1.8228e+02, 1.3349e+02, 8.3336e+01, 2.6378e-01, 4.0186e-02, 8.0285e-02],\n","        [1.2762e+02, 5.2095e+01, 9.2287e+01, 3.5893e-01, 2.2659e-02, 1.2820e-02],\n","        [1.0594e+01, 1.0291e+00, 1.8791e+02, 1.6232e-01, 1.1996e-01, 1.8582e-01],\n","        [1.1412e+02, 7.1318e+01, 1.1884e+02, 3.0230e-01, 4.0774e-02, 1.3303e-01],\n","        [4.9738e+01, 2.2303e+01, 5.2016e+00, 8.0901e-02, 8.2531e-02, 5.6355e-02],\n","        [1.4325e+02, 4.8388e+01, 1.1677e+02, 1.5825e-01, 1.8680e-01, 1.0956e-01],\n","        [1.0702e+02, 8.9584e+01, 1.6178e+02, 1.3245e-01, 1.0163e-01, 6.8488e-02],\n","        [1.3701e+02, 4.0745e+01, 1.4082e+02, 2.6370e-01, 1.4202e-01, 1.8937e-01]],\n","       device='cuda:0')\n","tensor([[3.7108e+01, 3.5167e+00, 1.3547e+02, 7.3986e-02, 1.2822e-01, 9.1710e-03],\n","        [9.6427e+01, 5.3148e+01, 1.9176e+01, 1.1781e-01, 7.8392e-02, 1.1921e-02],\n","        [5.4780e+01, 6.2535e+00, 1.0706e+02, 2.1703e-01, 1.6880e-02, 4.0795e-02],\n","        [1.1714e+02, 4.9674e+00, 1.1832e+02, 6.6108e-02, 1.9556e-01, 6.1135e-02],\n","        [7.7265e+01, 7.6328e+01, 1.3679e+02, 2.6914e-01, 1.5689e-01, 4.8453e-02],\n","        [1.7441e+02, 5.8127e+01, 1.0546e+02, 1.3194e-01, 4.6319e-02, 1.1124e-01],\n","        [1.8460e+02, 1.5904e+02, 1.8110e+02, 9.4334e-02, 1.0880e-01, 1.2393e-01],\n","        [1.6063e+02, 1.3205e+02, 5.8915e+01, 1.3403e-01, 1.9152e-02, 1.1045e-01],\n","        [3.6957e+01, 3.5431e+01, 1.8660e+02, 2.3606e-01, 1.5485e-01, 1.4053e-01],\n","        [5.2322e+01, 2.6202e-01, 1.2950e+02, 2.1214e-01, 4.5396e-02, 1.9384e-01],\n","        [7.2579e+01, 1.6338e+01, 1.3472e+02, 1.6939e-01, 8.2524e-02, 1.9133e-02],\n","        [8.4889e+00, 1.4855e+00, 1.3524e+02, 1.8337e-01, 4.3845e-02, 6.2844e-04],\n","        [8.8967e+01, 7.8096e+01, 6.1464e+00, 1.6431e-01, 8.8128e-02, 7.3566e-02],\n","        [1.6699e+02, 1.0707e+01, 1.6567e+02, 1.6999e-01, 1.4348e-01, 1.8763e-02],\n","        [1.8302e+01, 2.2578e+00, 4.5938e+01, 2.0638e-01, 6.4376e-02, 5.5828e-02],\n","        [7.1128e+01, 6.5332e+01, 4.4929e+01, 4.7258e-02, 7.1315e-03, 1.6621e-01]],\n","       device='cuda:0')\n","tensor([[9.8263e+01, 2.2049e+01, 1.3748e+02, 7.1574e-02, 7.9693e-02, 7.1093e-02],\n","        [1.6406e+02, 6.2369e+01, 5.5244e+01, 2.6218e-01, 1.1421e-01, 1.1898e-01],\n","        [1.5466e+02, 1.1565e+02, 1.3905e+02, 1.5725e-01, 1.1559e-01, 4.8343e-02],\n","        [7.6764e+00, 2.7230e+00, 1.7859e+02, 2.0232e-01, 2.5431e-02, 1.7804e-01],\n","        [1.5630e+02, 5.9037e+01, 4.3624e+01, 2.1798e-01, 1.3955e-01, 1.8747e-01],\n","        [6.6328e+01, 4.9404e+01, 6.1018e+01, 1.7380e-01, 8.7919e-02, 4.5920e-02],\n","        [1.3021e+01, 4.3907e+00, 1.3633e+02, 2.9792e-01, 1.7476e-01, 1.9556e-01],\n","        [3.7958e+01, 1.8960e+01, 1.0154e+02, 2.6965e-01, 9.1153e-02, 1.8218e-01],\n","        [1.7035e+02, 5.9673e+01, 6.8763e+01, 3.1388e-01, 6.6697e-02, 3.2803e-02],\n","        [3.3958e+01, 2.0226e+01, 4.4150e+01, 3.9757e-01, 1.1984e-01, 6.6047e-02],\n","        [1.8282e+02, 1.5117e+02, 3.2314e+01, 2.1552e-01, 9.1258e-03, 2.6192e-02],\n","        [9.4857e+01, 4.9994e+01, 1.2632e+02, 3.2121e-01, 5.1054e-02, 1.4933e-01],\n","        [8.9918e+01, 6.0348e+01, 9.8671e+01, 3.8906e-01, 3.2564e-02, 4.4774e-02],\n","        [1.3273e+02, 1.3092e+02, 1.6999e+02, 3.2097e-01, 1.5421e-01, 1.5493e-02],\n","        [6.3879e+01, 5.4797e-02, 1.0372e+02, 2.0100e-01, 8.2016e-02, 1.3971e-01],\n","        [4.4906e+01, 2.6582e+01, 1.3130e+02, 3.1603e-01, 1.1361e-01, 1.3613e-01]],\n","       device='cuda:0')\n","tensor([[7.9879e+01, 3.6920e+01, 1.9244e+02, 2.4382e-01, 4.6861e-03, 5.6001e-02],\n","        [4.1260e+01, 4.0665e+01, 7.1555e+01, 3.9575e-01, 6.2889e-02, 6.0897e-02],\n","        [2.5539e+01, 4.3579e+00, 1.2134e+02, 1.2958e-01, 7.9738e-02, 1.6472e-01],\n","        [2.4782e+01, 1.0373e+00, 4.2839e+01, 3.2207e-01, 9.4627e-02, 1.6267e-02],\n","        [1.5707e+02, 4.9527e+01, 1.7899e+02, 3.3219e-01, 9.5097e-02, 9.0771e-02],\n","        [1.8404e+02, 1.3344e+02, 1.3927e+02, 2.6941e-01, 1.9248e-01, 1.1027e-01],\n","        [1.2856e+02, 9.1225e+01, 6.0443e+01, 2.1037e-01, 1.8313e-01, 1.8781e-01],\n","        [1.3323e+02, 1.1432e+02, 6.7280e+01, 1.4611e-01, 1.1476e-01, 1.7150e-01],\n","        [2.2349e+01, 3.7437e+00, 6.7417e+01, 3.7835e-01, 2.1213e-02, 1.3120e-01],\n","        [1.9129e+02, 1.7064e+02, 8.7628e+01, 2.5364e-01, 9.2573e-04, 9.0368e-02],\n","        [7.7833e+01, 3.0231e+01, 6.3083e+01, 2.4026e-01, 2.4219e-02, 1.2128e-02],\n","        [1.3095e+02, 3.0197e+01, 2.2612e+01, 9.4758e-02, 5.6244e-02, 9.0361e-02],\n","        [1.6992e+01, 2.3132e+00, 1.4955e+02, 2.0027e-01, 1.0251e-01, 1.7709e-01],\n","        [1.3621e+02, 4.4794e+01, 1.1754e+01, 1.0231e-01, 3.1926e-02, 1.8986e-01],\n","        [9.9927e+01, 3.5905e+01, 1.0319e+02, 7.4178e-02, 1.3510e-01, 9.4677e-02],\n","        [1.2507e+02, 2.7436e+01, 6.8860e+01, 2.3074e-01, 1.2561e-01, 7.4091e-02]],\n","       device='cuda:0')\n","tensor([[9.6386e+01, 2.7783e+01, 1.6829e+02, 2.4165e-02, 1.5906e-01, 2.8872e-02],\n","        [3.3901e+01, 4.2031e+00, 1.7342e+02, 2.4054e-01, 1.3071e-01, 1.8428e-01],\n","        [1.4381e+02, 1.2906e+02, 8.5973e+00, 2.2467e-01, 1.4518e-02, 1.0094e-01],\n","        [1.7355e+02, 4.9644e+01, 4.8489e+01, 1.1409e-01, 1.7250e-01, 9.0775e-03],\n","        [7.7406e+01, 3.5695e+01, 4.5717e+01, 1.2083e-01, 1.3880e-01, 7.7192e-02],\n","        [4.0980e+01, 4.0492e+01, 7.6597e+01, 2.4864e-01, 5.5517e-02, 7.1999e-02],\n","        [2.4118e+01, 9.1543e+00, 4.8535e+01, 3.9005e-01, 1.0534e-01, 2.2646e-02],\n","        [4.2963e+01, 4.6541e+00, 1.4704e+02, 1.5694e-01, 1.7746e-01, 2.8264e-02],\n","        [5.2719e+01, 1.2539e+01, 4.8055e+01, 2.4315e-01, 2.4971e-02, 3.3786e-02],\n","        [6.1404e+01, 9.4034e+00, 1.8702e+02, 1.0827e-02, 1.6657e-01, 6.1611e-02],\n","        [3.7502e+01, 2.5769e+00, 1.2177e+02, 3.4273e-01, 1.8400e-01, 1.3204e-01],\n","        [1.4819e+02, 8.5984e+01, 1.9548e+02, 3.2946e-01, 3.7673e-02, 4.8580e-02],\n","        [1.3114e+02, 7.4097e+01, 1.6615e+02, 2.8160e-01, 4.8684e-02, 1.7142e-01],\n","        [5.4109e+01, 3.7911e+01, 1.4857e+02, 2.0324e-01, 4.0142e-02, 4.6010e-02],\n","        [1.3517e+02, 1.7369e+01, 1.6716e+02, 1.5857e-01, 1.9872e-01, 1.9730e-01],\n","        [1.6891e+02, 2.6722e+01, 1.7924e+02, 3.3832e-01, 1.7738e-01, 5.6526e-02]],\n","       device='cuda:0')\n","tensor([[1.5211e+02, 8.0205e+01, 1.5232e+02, 2.9722e-01, 1.5400e-01, 1.3155e-01],\n","        [1.2893e+02, 2.6783e+01, 1.9362e+02, 2.9002e-03, 8.9418e-02, 7.5918e-02],\n","        [1.4665e+02, 1.2333e+02, 1.3006e+02, 1.8919e-01, 6.5360e-02, 1.0409e-01],\n","        [1.2907e+01, 5.2240e+00, 7.7458e+01, 2.5826e-01, 9.6887e-02, 6.9002e-02],\n","        [6.4915e+01, 4.2354e+01, 5.5491e+01, 2.8723e-01, 1.5101e-01, 6.5384e-02],\n","        [1.0637e+02, 8.3973e-01, 8.6758e+01, 1.3315e-01, 1.8610e-01, 3.3884e-02],\n","        [4.3080e+01, 3.1063e+01, 2.9794e+01, 2.6704e-01, 7.5356e-02, 9.0123e-02],\n","        [1.8247e+02, 7.0532e+01, 1.9800e+02, 1.9554e-01, 8.2472e-02, 2.2659e-02],\n","        [7.2776e+01, 6.7741e+01, 1.9412e+02, 8.7083e-02, 1.0140e-01, 1.2229e-01],\n","        [1.4319e+02, 6.6512e+01, 5.5173e+01, 1.8622e-01, 1.4479e-01, 4.3105e-02],\n","        [1.7396e+02, 8.5033e+01, 1.9692e+02, 1.2663e-01, 8.2931e-02, 2.6303e-02],\n","        [8.2815e+01, 7.3975e+00, 1.7548e+01, 1.3947e-01, 1.0614e-01, 1.8971e-01],\n","        [8.8612e+01, 4.6073e+01, 1.1187e+02, 2.1736e-01, 1.8937e-01, 1.3055e-01],\n","        [1.3865e+02, 3.3030e+00, 1.2281e+02, 1.4041e-01, 1.5925e-01, 7.0501e-02],\n","        [1.4468e+02, 1.2736e+02, 1.2248e+02, 2.2605e-01, 1.9928e-01, 1.2308e-01],\n","        [1.7746e+01, 1.1518e+01, 7.6878e+01, 3.2556e-01, 1.9270e-01, 6.0931e-02]],\n","       device='cuda:0')\n","tensor([[1.5312e+00, 8.0837e-01, 1.3334e+02, 3.3082e-01, 1.1282e-01, 7.9543e-02],\n","        [9.9195e+01, 6.5987e+01, 4.4728e+01, 2.1638e-01, 1.4863e-01, 3.6624e-02],\n","        [1.6150e+02, 6.3966e+01, 5.7137e+01, 1.1968e-01, 5.8176e-02, 3.8569e-02],\n","        [3.5921e+01, 2.5032e-01, 6.9627e+01, 3.9104e-01, 1.7871e-01, 1.5138e-01],\n","        [2.5729e+01, 1.7975e+01, 1.0915e+02, 3.6791e-01, 1.6091e-01, 1.9442e-01],\n","        [9.4873e+01, 9.2491e+01, 1.5121e+02, 9.3700e-02, 1.3288e-01, 8.3598e-02],\n","        [5.5126e+01, 5.0103e+00, 1.4522e+02, 3.5575e-01, 9.6959e-02, 1.2755e-02],\n","        [1.1736e+02, 7.6173e+01, 1.6530e+02, 8.7051e-02, 1.0439e-02, 1.5938e-01],\n","        [1.7451e+02, 1.0768e+02, 6.2141e+01, 1.9979e-01, 1.4819e-01, 3.9253e-02],\n","        [1.8772e+02, 1.2901e+02, 8.8750e+01, 3.6020e-01, 1.0193e-01, 8.9876e-02],\n","        [1.3480e+02, 8.2261e+01, 1.2310e+02, 1.1309e-01, 1.1925e-01, 9.1944e-02],\n","        [1.3650e+02, 3.8594e+01, 6.3298e+01, 1.6908e-01, 9.7242e-02, 1.7494e-01],\n","        [1.6944e+02, 2.9022e+01, 4.0514e+01, 1.5748e-01, 1.3664e-02, 1.0257e-01],\n","        [4.5846e+00, 2.4681e+00, 1.9721e+02, 5.0246e-02, 1.0091e-01, 2.0202e-02],\n","        [1.9070e+02, 1.4579e+02, 1.3189e+02, 2.3267e-01, 2.9127e-02, 1.2578e-01],\n","        [6.8965e+01, 2.3782e+01, 1.9834e+02, 2.2574e-01, 1.5145e-01, 1.0214e-01]],\n","       device='cuda:0')\n","tensor([[1.7660e+02, 4.3807e+01, 1.8130e+02, 2.5182e-01, 1.8249e-01, 8.9705e-02],\n","        [5.1946e+01, 4.8860e+01, 1.0086e+02, 5.5533e-02, 6.7548e-02, 6.3388e-02],\n","        [1.3193e+02, 4.6011e+00, 1.9655e+02, 3.0238e-01, 1.8452e-01, 1.7436e-01],\n","        [1.4973e+02, 4.5776e+01, 1.0459e+02, 3.1774e-02, 1.6981e-01, 1.0725e-01],\n","        [1.5611e+02, 1.2653e+02, 3.0613e+01, 1.8367e-01, 6.0407e-02, 4.1658e-03],\n","        [1.8662e+01, 9.7366e+00, 5.6836e+01, 2.3052e-01, 9.6470e-02, 1.4408e-01],\n","        [4.8632e+01, 4.0103e+01, 1.1696e+01, 3.3694e-01, 7.9201e-02, 1.8789e-01],\n","        [1.4572e+02, 1.1808e+02, 4.7932e+01, 1.9505e-01, 5.6383e-02, 1.9160e-01],\n","        [8.9095e+01, 8.3449e+00, 3.2290e+01, 9.5996e-02, 1.2982e-01, 1.9622e-01],\n","        [4.0185e+01, 2.4371e+01, 1.0855e+02, 2.0811e-01, 1.6204e-01, 1.8303e-01],\n","        [1.9424e+02, 7.7573e+01, 1.3249e+01, 2.3724e-01, 1.9684e-01, 2.3938e-02],\n","        [1.1262e+02, 6.2778e+00, 1.6337e+02, 2.9696e-01, 9.6215e-02, 4.0979e-02],\n","        [1.8318e+02, 1.7116e+01, 1.6933e+02, 4.2465e-02, 1.8963e-01, 8.7015e-02],\n","        [1.3617e+02, 6.0977e+01, 8.3574e+01, 2.6051e-02, 1.6279e-01, 1.3187e-01],\n","        [2.8236e+01, 9.6169e+00, 1.9924e+01, 7.3633e-02, 1.3537e-01, 1.4639e-01],\n","        [7.9966e+01, 5.8002e-01, 9.1426e+01, 3.4707e-01, 1.2379e-01, 6.8086e-02]],\n","       device='cuda:0')\n","tensor([[6.7474e+01, 5.8134e+01, 1.9438e+02, 2.2932e-01, 7.5851e-02, 1.7019e-01],\n","        [4.6671e+01, 3.2792e+01, 3.3155e+01, 3.3867e-01, 1.9381e-01, 3.8484e-02],\n","        [6.0354e+01, 4.7478e+01, 1.7285e+01, 8.1012e-02, 1.5831e-01, 5.7411e-02],\n","        [8.2268e+01, 6.9495e+01, 8.8541e+01, 2.2995e-01, 1.0256e-01, 1.9877e-01],\n","        [1.5700e+02, 3.1519e+01, 1.8156e+02, 2.8094e-02, 1.4548e-01, 9.4924e-02],\n","        [3.2521e+01, 3.0612e+01, 8.9058e+01, 3.5451e-01, 1.9807e-01, 6.1815e-02],\n","        [1.5888e+02, 7.3747e+01, 6.3117e+01, 3.3699e-01, 1.6746e-01, 1.6036e-01],\n","        [7.2107e+01, 4.9772e+01, 4.6425e+01, 3.5996e-01, 1.6043e-01, 1.9572e-01],\n","        [9.8064e+01, 9.2753e+01, 1.8797e+02, 1.2757e-01, 9.2300e-02, 8.9379e-02],\n","        [8.0197e-01, 6.2566e-01, 1.6947e+02, 3.1765e-01, 3.2814e-02, 1.2166e-01],\n","        [7.4773e+01, 6.1934e+01, 1.4534e+01, 3.8219e-01, 7.8999e-02, 8.9795e-02],\n","        [1.6938e+02, 1.3437e+02, 1.5493e+01, 1.5126e-01, 7.6531e-02, 1.4133e-01],\n","        [3.3790e+00, 1.4676e+00, 7.6858e+01, 3.6775e-02, 1.5597e-01, 5.3604e-02],\n","        [3.2315e+01, 2.9734e+01, 1.7411e+02, 1.5374e-01, 1.9546e-01, 1.4838e-01],\n","        [1.7150e+02, 5.9318e+01, 1.3095e+02, 3.1873e-03, 3.3915e-02, 6.4895e-02],\n","        [3.2309e+01, 1.3501e+01, 1.0695e+02, 4.6057e-02, 8.0340e-02, 1.8952e-01]],\n","       device='cuda:0')\n","tensor([[4.7738e+01, 4.3669e+01, 1.6563e+02, 2.0268e-01, 1.3537e-01, 8.9590e-02],\n","        [2.2261e+01, 4.9234e+00, 1.3617e+01, 1.7209e-01, 9.0552e-02, 1.9764e-01],\n","        [1.9739e+02, 1.0645e+02, 3.7180e+01, 9.1277e-02, 1.0379e-01, 1.5668e-01],\n","        [1.8972e+01, 9.1410e+00, 5.2845e+01, 2.6373e-01, 1.3995e-01, 7.0933e-02],\n","        [1.0069e+02, 3.5175e+01, 1.8718e+02, 1.4508e-01, 1.2797e-01, 1.8290e-01],\n","        [1.8227e+02, 3.2353e+01, 1.2663e+02, 1.0586e-01, 4.0516e-04, 5.7012e-04],\n","        [1.8404e+02, 2.6516e+01, 5.8347e+01, 1.2493e-01, 2.6072e-02, 3.6336e-03],\n","        [1.9045e+02, 6.8253e+01, 1.8738e+02, 2.1984e-01, 1.7169e-01, 8.3084e-02],\n","        [1.7161e+02, 1.1605e+02, 3.2383e+01, 1.3788e-01, 1.0456e-01, 1.1301e-01],\n","        [1.0675e+02, 1.1698e+01, 8.9130e+01, 1.2311e-01, 3.6821e-02, 1.0124e-01],\n","        [7.3595e+01, 5.6769e+01, 2.5609e+01, 2.0411e-02, 1.6467e-01, 1.2885e-01],\n","        [1.3729e+02, 9.9204e+01, 9.0761e+01, 1.2442e-01, 7.9136e-02, 1.4601e-01],\n","        [1.4516e+01, 1.2663e+01, 8.8592e+01, 3.0609e-01, 8.8521e-02, 1.4309e-01],\n","        [3.1443e+01, 1.8371e+01, 6.7079e+01, 7.8899e-02, 1.5457e-01, 4.3518e-02],\n","        [2.8837e+01, 1.9166e+01, 1.5208e+02, 3.2129e-01, 2.2113e-02, 3.9432e-02],\n","        [6.6706e+01, 1.1922e+01, 1.6419e+02, 7.5485e-02, 1.5005e-01, 3.9107e-02]],\n","       device='cuda:0')\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qfLKExmaEYu2"},"source":["### Model\n","To map the option parameters to price, we use 6 layers of fully connected neural network with hidden dimension 512 as inspired by [this paper](https://arxiv.org/abs/1809.02233). Writing this DL price model into a file `model.py`:-"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m7OjEPNsEYu2","executionInfo":{"status":"ok","timestamp":1620869320567,"user_tz":-480,"elapsed":937,"user":{"displayName":"YILIAN ZHANG","photoUrl":"","userId":"00778400246289834299"}},"outputId":"8c069010-61b4-4dcc-c654-311bc730c4f8"},"source":["%%writefile model.py\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","\n","\n","class Net(nn.Module):\n","\n","    def __init__(self, hidden=1024):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(6, hidden)\n","        self.fc2 = nn.Linear(hidden, hidden)\n","        self.fc3 = nn.Linear(hidden, hidden)\n","        self.fc4 = nn.Linear(hidden, hidden)\n","        self.fc5 = nn.Linear(hidden, hidden)\n","        self.fc6 = nn.Linear(hidden, 1)\n","        self.register_buffer('norm',\n","                             torch.tensor([200.0,\n","                                           198.0,\n","                                           200.0,\n","                                           0.4,\n","                                           0.2,\n","                                           0.2]))\n","\n","    def forward(self, x):\n","        # normalize the parameter to range [0-1] \n","        x = x / self.norm\n","        x = F.elu(self.fc1(x))\n","        x = F.elu(self.fc2(x))\n","        x = F.elu(self.fc3(x))\n","        x = F.elu(self.fc4(x))\n","        x = F.elu(self.fc5(x))\n","        return self.fc6(x)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Writing model.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"bOwESpF5EYu2"},"source":["As we know the random parameters' scaling factors, the input parameters are first scaled back to a range of (0-1) by dividing them by (200.0, 198.0, 200.0, 0.4, 0.2, 0.2). Then they are projected 5 times to the hidden dimension of 512 after the `ELu` activation function. `ELu` is chosen because we need to compute the second order differentiation of the parameters. If use ReLu, the second order differentiation will always be zero. The last layer is a linear layer that maps the hidden dimension to the predicted option price. "]},{"cell_type":"markdown","metadata":{"id":"fi2qIvUvEYu2"},"source":["For training, we use [Ignite](https://github.com/pytorch/ignite) which is a high-level library to train neural networks in PyTorch. We use `MSELoss` as the loss function, `Adam` as the optimizer and `CosineAnnealingScheduler` as the learning rate scheduler. The following code is feeding the random option data to the pricing model to train it."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hq5daEvHwj9p","executionInfo":{"status":"ok","timestamp":1620869327302,"user_tz":-480,"elapsed":3846,"user":{"displayName":"YILIAN ZHANG","photoUrl":"","userId":"00778400246289834299"}},"outputId":"d8803a9b-3c16-4b12-c408-5d8a4ea095c9"},"source":["!pip install pytorch-ignite"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pytorch-ignite\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/d3/640f70d69393b415e6a29b27c735047ad86267921ad62682d1d756556d48/pytorch_ignite-0.4.4-py3-none-any.whl (200kB)\n","\r\u001b[K     |█▋                              | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |███▎                            | 20kB 27.9MB/s eta 0:00:01\r\u001b[K     |█████                           | 30kB 33.4MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 40kB 28.8MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 51kB 30.0MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 61kB 31.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 71kB 33.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 81kB 27.8MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 92kB 29.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 102kB 27.5MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 112kB 27.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 122kB 27.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 133kB 27.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 143kB 27.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 153kB 27.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 163kB 27.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 174kB 27.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 184kB 27.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 194kB 27.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 204kB 27.5MB/s \n","\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n","Installing collected packages: pytorch-ignite\n","Successfully installed pytorch-ignite-0.4.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n1BiCZP5EYu3","executionInfo":{"status":"ok","timestamp":1620869395246,"user_tz":-480,"elapsed":64439,"user":{"displayName":"YILIAN ZHANG","photoUrl":"","userId":"00778400246289834299"}},"outputId":"bc513712-efaa-419c-c3fc-266cce451492"},"source":["from ignite.engine import Engine, Events\n","from ignite.handlers import Timer\n","from torch.nn import MSELoss\n","from torch.optim import Adam\n","from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n","from ignite.handlers import ModelCheckpoint\n","from model import Net\n","from cupy_dataset import OptionDataSet\n","timer = Timer(average=True)\n","model = Net().cuda()\n","loss_fn = MSELoss()\n","optimizer = Adam(model.parameters(), lr=1e-3)\n","dataset = OptionDataSet(max_len=100, number_path = 1024, batch=48)\n","#dataset = OptionDataSet(max_len=10000, number_path = 1024, batch=4800)\n","\n","def train_update(engine, batch):\n","    model.train()\n","    optimizer.zero_grad()\n","    x = batch[0]\n","    y = batch[1]\n","    y_pred = model(x)\n","    loss = loss_fn(y_pred[:,0], y)\n","    loss.backward()\n","    optimizer.step()\n","    return loss.item()\n","\n","trainer = Engine(train_update)\n","log_interval = 100\n","\n","scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n","trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n","timer.attach(trainer,\n","             start=Events.EPOCH_STARTED,\n","             resume=Events.ITERATION_STARTED,\n","             pause=Events.ITERATION_COMPLETED,\n","             step=Events.ITERATION_COMPLETED)    \n","@trainer.on(Events.ITERATION_COMPLETED)\n","def log_training_loss(engine):\n","    iter = (engine.state.iteration - 1) % len(dataset) + 1\n","    if iter % log_interval == 0:\n","        print('loss', engine.state.output, 'average time', timer.value())\n","        \n","trainer.run(dataset, max_epochs=100)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["loss 996.52001953125 average time 0.004145796069998368\n","loss 17.881988525390625 average time 0.0032672758599991882\n","loss 3.030829906463623 average time 0.0032560889899977494\n","loss 6.951999187469482 average time 0.003331438169999501\n","loss 2.468383312225342 average time 0.003280613889999131\n","loss 3.5279769897460938 average time 0.003294879590000619\n","loss 4.213017463684082 average time 0.003406929069998057\n","loss 3.14882230758667 average time 0.003248973529998409\n","loss 1.3090626001358032 average time 0.0033271452300013492\n","loss 3.5446364879608154 average time 0.0032908031000005167\n","loss 2.1477255821228027 average time 0.0032469430099999388\n","loss 1.5451997518539429 average time 0.003292743290000146\n","loss 0.8643962740898132 average time 0.003239591439999572\n","loss 0.8346470594406128 average time 0.003299816940002245\n","loss 0.3614598214626312 average time 0.003330519380000965\n","loss 0.5406172871589661 average time 0.0032301486100001853\n","loss 0.6135584115982056 average time 0.0034736604399992644\n","loss 1.5897881984710693 average time 0.003259033849998332\n","loss 1.1447603702545166 average time 0.0032540573099996096\n","loss 0.5681999921798706 average time 0.0033427761299995497\n","loss 0.7389653921127319 average time 0.0032630290400001627\n","loss 0.9955066442489624 average time 0.0033045914999991054\n","loss 1.1134419441223145 average time 0.003269282330001033\n","loss 0.5253197550773621 average time 0.003205128220000688\n","loss 1.141722559928894 average time 0.0032790273699995964\n","loss 0.9302482604980469 average time 0.0032713727800015137\n","loss 0.8784552812576294 average time 0.0032886576499996066\n","loss 0.42282819747924805 average time 0.00327463559999984\n","loss 1.0463738441467285 average time 0.003234573570001089\n","loss 0.738848865032196 average time 0.0032626298899990046\n","loss 0.665908932685852 average time 0.0032798139399992012\n","loss 0.8167755603790283 average time 0.0032603523000017277\n","loss 0.6424980759620667 average time 0.0033045762600002605\n","loss 0.5187625885009766 average time 0.003386843019999901\n","loss 0.634178638458252 average time 0.0033347866300016448\n","loss 0.7133890986442566 average time 0.003371831850002138\n","loss 0.7593230605125427 average time 0.0032575616000013953\n","loss 0.636794924736023 average time 0.00329723680000086\n","loss 0.782871663570404 average time 0.0033020783499986806\n","loss 0.7310015559196472 average time 0.003281700619998844\n","loss 0.9847297668457031 average time 0.0032683475200013844\n","loss 0.4406345784664154 average time 0.003325196769998513\n","loss 0.5224431753158569 average time 0.0032461044799995875\n","loss 0.34809112548828125 average time 0.0033350532299988344\n","loss 0.26473528146743774 average time 0.0033271815500003753\n","loss 0.3203386068344116 average time 0.0032729066699988606\n","loss 0.5870238542556763 average time 0.003302956329999347\n","loss 0.6301119327545166 average time 0.0032385064199993963\n","loss 0.4652116894721985 average time 0.0033190198999997734\n","loss 0.33866366744041443 average time 0.0033510044100000867\n","loss 0.2128002643585205 average time 0.00330028936999895\n","loss 0.29203495383262634 average time 0.003416186930001572\n","loss 0.5669379234313965 average time 0.0032826449099985664\n","loss 0.5288329124450684 average time 0.0032595135199989045\n","loss 0.1451665759086609 average time 0.0033050241599960374\n","loss 0.3056952953338623 average time 0.0033407276299999467\n","loss 0.20978760719299316 average time 0.003252474910000842\n","loss 0.27288874983787537 average time 0.0033107206300024925\n","loss 0.479712575674057 average time 0.0033265304999991942\n","loss 0.5660412311553955 average time 0.003323055130003354\n","loss 0.2013711929321289 average time 0.0033767998699988765\n","loss 0.3773419260978699 average time 0.0033514281499998333\n","loss 0.4454472064971924 average time 0.00338903103999769\n","loss 0.4936603903770447 average time 0.0032845111300014197\n","loss 0.3259475827217102 average time 0.003307876189999206\n","loss 0.2726207375526428 average time 0.003390906660001747\n","loss 0.573322057723999 average time 0.003374929580003823\n","loss 0.19431142508983612 average time 0.0033960258000013256\n","loss 0.3272061049938202 average time 0.0032854955399972143\n","loss 0.2392805814743042 average time 0.0032983516999991027\n","loss 0.3166377544403076 average time 0.00335368172999722\n","loss 0.2297031134366989 average time 0.003347100999999952\n","loss 0.6100286841392517 average time 0.003331873380003003\n","loss 0.17441651225090027 average time 0.0032991385999946487\n","loss 0.39399176836013794 average time 0.003282024239997554\n","loss 0.25064003467559814 average time 0.0033199490799978547\n","loss 0.4015094041824341 average time 0.003366545239998686\n","loss 0.17875388264656067 average time 0.003308598039997719\n","loss 0.22404979169368744 average time 0.0032942602200006377\n","loss 0.31593453884124756 average time 0.0033764067400056776\n","loss 0.45576462149620056 average time 0.0033473499000041327\n","loss 0.13093899190425873 average time 0.003290840989999424\n","loss 0.2927677035331726 average time 0.003335179410001956\n","loss 0.21448510885238647 average time 0.003354093790001116\n","loss 0.2716101109981537 average time 0.0033629813499976534\n","loss 0.2753373384475708 average time 0.003352280680001627\n","loss 0.25540891289711 average time 0.0033352704299971945\n","loss 0.15102458000183105 average time 0.003506003149996673\n","loss 0.19284534454345703 average time 0.0033078481600000488\n","loss 0.24208062887191772 average time 0.003324221290003493\n","loss 0.5188721418380737 average time 0.0033734017499995163\n","loss 0.40673527121543884 average time 0.0033166185000015956\n","loss 0.3302968740463257 average time 0.003287283839996462\n","loss 0.20941948890686035 average time 0.003310338929998693\n","loss 0.13744884729385376 average time 0.0033555138900021575\n","loss 0.29707616567611694 average time 0.0032824015899984714\n","loss 0.43733662366867065 average time 0.003284821060006493\n","loss 0.3841148316860199 average time 0.0032863582499987843\n","loss 0.4826974868774414 average time 0.0033094822999987627\n","loss 0.17450420558452606 average time 0.0033066011599964893\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["State:\n","\titeration: 10000\n","\tepoch: 100\n","\tepoch_length: 100\n","\tmax_epochs: 100\n","\toutput: 0.17450420558452606\n","\tbatch: <class 'tuple'>\n","\tmetrics: <class 'dict'>\n","\tdataloader: <class 'cupy_dataset.OptionDataSet'>\n","\tseed: <class 'NoneType'>\n","\ttimes: <class 'dict'>"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"qDl7nWhoEYu3"},"source":["The loss is keeping decreasing which means the pricing model can predict the option prices better. It takes about $12ms$ to compute one mini-batch in average, In the following sections, we will try to expore the full potentials of the GPU to accelerate the training."]},{"cell_type":"markdown","metadata":{"id":"Emqy1rBsEYu3"},"source":["### TensorCore mixed precision training\n","\n","The V100 GPUs have 640 tensor cores that can accelerate half precision matrix multiplication calculation which is the core computation done by the DL model. [Apex library](https://github.com/NVIDIA/apex) developed by NVIDIA makes mixed precision and distributed training in Pytorch easy. By changing 3 lines of code, it can use the tensor cores to accelerate the training. "]},{"cell_type":"code","metadata":{"id":"13dB1NeN4Dcv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619706507666,"user_tz":420,"elapsed":2818,"user":{"displayName":"Judy Chu","photoUrl":"","userId":"10131513255739032089"}},"outputId":"9778a45e-1c9d-4d26-852a-4d7bea08397f"},"source":["!git clone https://github.com/NVIDIA/apex"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'apex'...\n","remote: Enumerating objects: 8038, done.\u001b[K\n","remote: Counting objects: 100% (125/125), done.\u001b[K\n","remote: Compressing objects: 100% (91/91), done.\u001b[K\n","remote: Total 8038 (delta 58), reused 68 (delta 29), pack-reused 7913\u001b[K\n","Receiving objects: 100% (8038/8038), 14.11 MiB | 23.64 MiB/s, done.\n","Resolving deltas: 100% (5457/5457), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"81KC3i9x7AjS","executionInfo":{"status":"ok","timestamp":1619706509101,"user_tz":420,"elapsed":621,"user":{"displayName":"Judy Chu","photoUrl":"","userId":"10131513255739032089"}},"outputId":"5fc6cc57-7c74-445e-b552-fbcf2e02eb19"},"source":["cd apex"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/apex\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_5tIR6ix7CfS","executionInfo":{"status":"ok","timestamp":1619706517857,"user_tz":420,"elapsed":7427,"user":{"displayName":"Judy Chu","photoUrl":"","userId":"10131513255739032089"}},"outputId":"03e76a63-6d45-47a5-b2dd-5a49e46eaa77"},"source":["!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n","  cmdoptions.check_install_build_global(options)\n","Created temporary directory: /tmp/pip-ephem-wheel-cache-rdfqqr3k\n","Created temporary directory: /tmp/pip-req-tracker-bhgvya29\n","Created requirements tracker '/tmp/pip-req-tracker-bhgvya29'\n","Created temporary directory: /tmp/pip-install-fr7sbd60\n","Processing /content/apex\n","  Created temporary directory: /tmp/pip-req-build-kjeiz50m\n","  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-bhgvya29'\n","    Running setup.py (path:/tmp/pip-req-build-kjeiz50m/setup.py) egg_info for package from file:///content/apex\n","    Running command python setup.py egg_info\n","\n","\n","    torch.__version__  = 1.8.1+cu101\n","\n","\n","    running egg_info\n","    creating /tmp/pip-req-build-kjeiz50m/pip-egg-info/apex.egg-info\n","    writing /tmp/pip-req-build-kjeiz50m/pip-egg-info/apex.egg-info/PKG-INFO\n","    writing dependency_links to /tmp/pip-req-build-kjeiz50m/pip-egg-info/apex.egg-info/dependency_links.txt\n","    writing top-level names to /tmp/pip-req-build-kjeiz50m/pip-egg-info/apex.egg-info/top_level.txt\n","    writing manifest file '/tmp/pip-req-build-kjeiz50m/pip-egg-info/apex.egg-info/SOURCES.txt'\n","    adding license file 'LICENSE' (matched pattern 'LICEN[CS]E*')\n","    writing manifest file '/tmp/pip-req-build-kjeiz50m/pip-egg-info/apex.egg-info/SOURCES.txt'\n","    /tmp/pip-req-build-kjeiz50m/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n","      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n","  Source in /tmp/pip-req-build-kjeiz50m has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n","  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-bhgvya29'\n","Skipping wheel build for apex, due to binaries being disabled for it.\n","Installing collected packages: apex\n","  Created temporary directory: /tmp/pip-record-yhxsr6p5\n","    Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-kjeiz50m/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-kjeiz50m/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-yhxsr6p5/install-record.txt --single-version-externally-managed --compile\n","\n","\n","    torch.__version__  = 1.8.1+cu101\n","\n","\n","    /tmp/pip-req-build-kjeiz50m/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n","      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n","\n","    Compiling cuda extensions with\n","    nvcc: NVIDIA (R) Cuda compiler driver\n","    Copyright (c) 2005-2020 NVIDIA Corporation\n","    Built on Wed_Jul_22_19:09:09_PDT_2020\n","    Cuda compilation tools, release 11.0, V11.0.221\n","    Build cuda_11.0_bu.TC445_37.28845127_0\n","    from /usr/local/cuda/bin\n","\n","    Traceback (most recent call last):\n","      File \"<string>\", line 1, in <module>\n","      File \"/tmp/pip-req-build-kjeiz50m/setup.py\", line 171, in <module>\n","        check_cuda_torch_binary_vs_bare_metal(torch.utils.cpp_extension.CUDA_HOME)\n","      File \"/tmp/pip-req-build-kjeiz50m/setup.py\", line 106, in check_cuda_torch_binary_vs_bare_metal\n","        \"https://github.com/NVIDIA/apex/pull/323#discussion_r287021798.  \"\n","    RuntimeError: Cuda extensions are being compiled with a version of Cuda that does not match the version used to compile Pytorch binaries.  Pytorch binaries were compiled with Cuda 10.1.\n","    In some cases, a minor-version mismatch will not cause later errors:  https://github.com/NVIDIA/apex/pull/323#discussion_r287021798.  You can try commenting out this check (at your own risk).\n","    Running setup.py install for apex ... \u001b[?25l\u001b[?25herror\n","Cleaning up...\n","  Removing source in /tmp/pip-req-build-kjeiz50m\n","Removed build tracker '/tmp/pip-req-tracker-bhgvya29'\n","\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-kjeiz50m/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-kjeiz50m/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-yhxsr6p5/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n","Exception information:\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 153, in _main\n","    status = self.run(options, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 455, in run\n","    use_user_site=options.use_user_site,\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/req/__init__.py\", line 62, in install_given_reqs\n","    **kwargs\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/req/req_install.py\", line 888, in install\n","    cwd=self.unpacked_source_directory,\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/subprocess.py\", line 275, in runner\n","    spinner=spinner,\n","  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/subprocess.py\", line 242, in call_subprocess\n","    raise InstallationError(exc_msg)\n","pip._internal.exceptions.InstallationError: Command errored out with exit status 1: /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-kjeiz50m/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-kjeiz50m/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-yhxsr6p5/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kIkv55m8EYu3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619706670745,"user_tz":420,"elapsed":149066,"user":{"displayName":"Judy Chu","photoUrl":"","userId":"10131513255739032089"}},"outputId":"2b686edc-a3a0-4deb-8f20-b80ae486dcd7"},"source":["from apex import amp\n","from ignite.engine import Engine, Events\n","from torch.nn import MSELoss\n","from ignite.handlers import Timer\n","from torch.optim import Adam\n","from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n","from ignite.handlers import ModelCheckpoint\n","from model import Net\n","from cupy_dataset import OptionDataSet\n","timer = Timer(average=True)\n","model = Net().cuda()\n","loss_fn = MSELoss()\n","optimizer = Adam(model.parameters(), lr=1e-3)\n","# set the AMP optimization level to O1\n","opt_level = 'O1'\n","# wrap the optimizer and model\n","model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n","dataset = OptionDataSet(max_len=100, number_path = 1024, batch=48)\n","\n","def train_update(engine, batch):\n","    model.train()\n","    optimizer.zero_grad()\n","    x = batch[0]\n","    y = batch[1]\n","    y_pred = model(x)\n","    loss = loss_fn(y_pred[:,0], y)\n","    # amp handles the auto loss scaling\n","    with amp.scale_loss(loss, optimizer) as scaled_loss:\n","        scaled_loss.backward()\n","    optimizer.step()\n","    return loss.item()\n","\n","trainer = Engine(train_update)\n","log_interval = 100\n","timer.attach(trainer,\n","             start=Events.EPOCH_STARTED,\n","             resume=Events.ITERATION_STARTED,\n","             pause=Events.ITERATION_COMPLETED,\n","             step=Events.ITERATION_COMPLETED)    \n","scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n","trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n","    \n","@trainer.on(Events.ITERATION_COMPLETED)\n","def log_training_loss(engine):\n","    iter = (engine.state.iteration - 1) % len(dataset) + 1\n","    if iter % log_interval == 0:\n","        print('loss', engine.state.output, 'average time', timer.value())\n","        \n","trainer.run(dataset, max_epochs=100)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n","\n","Defaults for this optimization level are:\n","enabled                : True\n","opt_level              : O1\n","cast_model_type        : None\n","patch_torch_functions  : True\n","keep_batchnorm_fp32    : None\n","master_weights         : None\n","loss_scale             : dynamic\n","Processing user overrides (additional kwargs that are not None)...\n","After processing overrides, optimization options are:\n","enabled                : True\n","opt_level              : O1\n","cast_model_type        : None\n","patch_torch_functions  : True\n","keep_batchnorm_fp32    : None\n","master_weights         : None\n","loss_scale             : dynamic\n","Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\")\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n","loss 1134.169189453125 average time 0.01229556703000071\n","loss 18.909423828125 average time 0.011692594590003864\n","loss 3.1629552841186523 average time 0.011477460099999347\n","loss 7.7707109451293945 average time 0.01152735413999892\n","loss 2.8021161556243896 average time 0.011574543000002678\n","loss 3.9839258193969727 average time 0.0114283149800076\n","loss 4.779293537139893 average time 0.01151123297999959\n","loss 3.2783994674682617 average time 0.011549435230001563\n","loss 1.3390424251556396 average time 0.011524218620000398\n","loss 3.468966484069824 average time 0.011528971690001982\n","loss 2.2454278469085693 average time 0.011533966999998597\n","loss 1.5048645734786987 average time 0.011444396510000274\n","loss 0.8895847797393799 average time 0.011522610200004238\n","loss 0.8513991236686707 average time 0.011425273500000799\n","loss 0.4479754865169525 average time 0.011556433879998735\n","loss 0.512149453163147 average time 0.011530138160001684\n","loss 0.6488336324691772 average time 0.011491828849999023\n","loss 1.4878720045089722 average time 0.011499453880001625\n","loss 1.1729942560195923 average time 0.011472194080002964\n","loss 0.5527461767196655 average time 0.011539140039996027\n","loss 0.8305851221084595 average time 0.011397637020000956\n","loss 1.207881212234497 average time 0.011644997789998114\n","loss 1.2760146856307983 average time 0.011481154899998956\n","loss 0.5720287561416626 average time 0.011544604489999983\n","loss 1.1859382390975952 average time 0.01148894066999958\n","loss 1.110229730606079 average time 0.011428861419997247\n","loss 0.9608664512634277 average time 0.011401908689997527\n","loss 0.5009467601776123 average time 0.011534109049997597\n","loss 1.067003607749939 average time 0.01146723275999932\n","loss 0.7957159876823425 average time 0.01155961048000222\n","loss 0.6226788759231567 average time 0.01142361639000569\n","loss 0.7523820400238037 average time 0.011632313410000848\n","loss 0.6182237267494202 average time 0.011511103310001545\n","loss 0.5123643279075623 average time 0.011490002219996426\n","loss 0.6380575895309448 average time 0.011499811030002433\n","loss 0.7261034846305847 average time 0.011416001199998504\n","loss 0.7739042043685913 average time 0.01149833082000157\n","loss 0.6712350845336914 average time 0.011500263849996487\n","loss 0.7197920680046082 average time 0.011501630829999386\n","loss 0.7694482207298279 average time 0.011581210329998726\n","loss 1.0529567003250122 average time 0.011514204550001067\n","loss 0.46881890296936035 average time 0.011484619259999818\n","loss 0.5651975870132446 average time 0.011450753389997886\n","loss 0.3615817427635193 average time 0.011662946939998732\n","loss 0.2695503234863281 average time 0.01153886478000004\n","loss 0.3409038186073303 average time 0.011486703329997567\n","loss 0.5534619092941284 average time 0.011542894070000215\n","loss 0.6653972864151001 average time 0.011719219400002884\n","loss 0.49162063002586365 average time 0.011512099010001862\n","loss 0.36338984966278076 average time 0.011472942589998638\n","loss 0.23972949385643005 average time 0.011497121989997937\n","loss 0.30753636360168457 average time 0.01168888392000099\n","loss 0.5631099343299866 average time 0.011480509539994159\n","loss 0.5256228446960449 average time 0.011496630230001302\n","loss 0.13349828124046326 average time 0.011483465890003118\n","loss 0.31807464361190796 average time 0.011525780599999393\n","loss 0.20398186147212982 average time 0.011534874930002275\n","loss 0.28375935554504395 average time 0.011461454890000482\n","loss 0.5350102186203003 average time 0.011545455980001975\n","loss 0.5456535220146179 average time 0.011519727689997695\n","loss 0.18668542802333832 average time 0.011476608210001018\n","loss 0.3960425853729248 average time 0.011624797900000771\n","loss 0.4603835344314575 average time 0.0115206470000021\n","loss 0.48216313123703003 average time 0.011452088179999577\n","loss 0.310099720954895 average time 0.011453764069998443\n","loss 0.2910865545272827 average time 0.011433561219997728\n","loss 0.5935916900634766 average time 0.01151212695999618\n","loss 0.20396798849105835 average time 0.011526668600000107\n","loss 0.3272697329521179 average time 0.011589500240000916\n","loss 0.24463562667369843 average time 0.011517487030001803\n","loss 0.28241416811943054 average time 0.011470215469997243\n","loss 0.23010775446891785 average time 0.011569030690001227\n","loss 0.6208177804946899 average time 0.011511533520002786\n","loss 0.17033785581588745 average time 0.011544945699997698\n","loss 0.3814127445220947 average time 0.011450290640000275\n","loss 0.23966942727565765 average time 0.011555290140003081\n","loss 0.4071492552757263 average time 0.011445902159998127\n","loss 0.17455101013183594 average time 0.011629348859997321\n","loss 0.21341435611248016 average time 0.011432651730003159\n","loss 0.294448584318161 average time 0.011584675060001359\n","loss 0.4625200033187866 average time 0.011373904709998328\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n","loss 0.13300096988677979 average time 0.011465281160000132\n","loss 0.2905436158180237 average time 0.011397557089999281\n","loss 0.2388974130153656 average time 0.011490951760000598\n","loss 0.2630692720413208 average time 0.01140239451000184\n","loss 0.25970518589019775 average time 0.011554986840002357\n","loss 0.27418965101242065 average time 0.011454297249998717\n","loss 0.1488192081451416 average time 0.011579226839999138\n","loss 0.18492823839187622 average time 0.011503324229995542\n","Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n","loss 0.23772716522216797 average time 0.01153155421999827\n","loss 0.5149413347244263 average time 0.011494283439996025\n","loss 0.40668365359306335 average time 0.011541292200002431\n","loss 0.31806474924087524 average time 0.011522899230001826\n","loss 0.19423481822013855 average time 0.011462710510002125\n","loss 0.13769309222698212 average time 0.01145812071999785\n","loss 0.2968185245990753 average time 0.011490863020003416\n","loss 0.41747114062309265 average time 0.011549783520001142\n","loss 0.35580894351005554 average time 0.011433007339999222\n","loss 0.44623804092407227 average time 0.011503180529997508\n","loss 0.17109763622283936 average time 0.011512866460000737\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["State:\n","\titeration: 10000\n","\tepoch: 100\n","\tepoch_length: 100\n","\tmax_epochs: 100\n","\toutput: 0.17109763622283936\n","\tbatch: <class 'tuple'>\n","\tmetrics: <class 'dict'>\n","\tdataloader: <class 'cupy_dataset.OptionDataSet'>\n","\tseed: <class 'NoneType'>\n","\ttimes: <class 'dict'>"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"POgAafQrEYu3"},"source":["It improves to compute each mini-batch in $8ms$. As we reduce the model weights to half precision for better performance, the loss need to be scaled to make sure the half precision dynamic range aligns with the computation. It is guessing what is the correct loss scaling factor and adjust it automatically if the gradient overflows. In the end, we will get the best hardware acceleration while maintaining the accuracy of model prediction."]},{"cell_type":"markdown","metadata":{"id":"4HICOmAVEYu4"},"source":["### Multiple GPU training"]},{"cell_type":"markdown","metadata":{"id":"xYzWTw_SEYu4"},"source":["Apex makes multiple GPU training easy. Working on the same training script, we need to take care of a few extra steps:\n","\n","1. Add the argument `--local_rank` which will be automatically set by the distributed launcher\n","2. Initialize the process group\n","2. Generate independent batched data based on process id in the dataset.\n","3. Wrap the model and optimizer to handle distributed computation. \n","4. Scale the loss and optimizer\n","\n","To launch distributed training, we need to put everything into a python file. Following is an example:-"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"c7w-ch7jC3h9","executionInfo":{"status":"ok","timestamp":1619699660098,"user_tz":-480,"elapsed":1014,"user":{"displayName":"YILIAN ZHANG","photoUrl":"","userId":"00778400246289834299"}},"outputId":"85fd8893-5c79-46cd-cf35-106fd05aeb10"},"source":["pwd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/apex'"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Er21_TT_C4wB","executionInfo":{"status":"ok","timestamp":1619699670522,"user_tz":-480,"elapsed":912,"user":{"displayName":"YILIAN ZHANG","photoUrl":"","userId":"00778400246289834299"}},"outputId":"558cafec-45d8-4bea-a5fd-ec7969dd09cd"},"source":["cd .."],"execution_count":null,"outputs":[{"output_type":"stream","text":["/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FVTX2kXxEYu4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619699684810,"user_tz":-480,"elapsed":1172,"user":{"displayName":"YILIAN ZHANG","photoUrl":"","userId":"00778400246289834299"}},"outputId":"c1da6484-3064-4513-fa37-7ecb499066b3"},"source":["%%writefile distributed_train.py \n","import cupy\n","import numpy as np\n","import math\n","import time\n","import os\n","import torch\n","from torch.utils.dlpack import from_dlpack\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","from apex import amp\n","from ignite.engine import Engine, Events\n","from torch.nn import MSELoss\n","from torch.optim import Adam\n","from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n","from ignite.handlers import ModelCheckpoint\n","from apex.parallel import DistributedDataParallel \n","import argparse\n","from model import Net\n","from cupy_dataset import OptionDataSet\n","\n","parser = argparse.ArgumentParser()\n","parser = argparse.ArgumentParser()\n","# this local_rank arg is automaticall set by distributed launch\n","parser.add_argument(\"--local_rank\", default=0, type=int)\n","args = parser.parse_args()\n","\n","args.distributed = False\n","if 'WORLD_SIZE' in os.environ:\n","    args.distributed = int(os.environ['WORLD_SIZE']) > 1\n","\n","if args.distributed:\n","    torch.cuda.set_device(args.local_rank)\n","    torch.distributed.init_process_group(backend='nccl',\n","                                         init_method='env://')\n","\n","torch.backends.cudnn.benchmark = True\n","\n","\n","model = Net().cuda()\n","loss_fn = MSELoss()\n","optimizer = Adam(model.parameters(), lr=1e-3)\n","opt_level = 'O1'\n","model, optimizer = amp.initialize(model, optimizer, opt_level=opt_level)\n","if args.distributed:\n","    model = DistributedDataParallel(model)\n","dataset = OptionDataSet(max_len=10000, number_path = 1024, batch=10240, seed=args.local_rank)\n","\n","def train_update(engine, batch):\n","    model.train()\n","    optimizer.zero_grad()\n","    x = batch[0]\n","    y = batch[1]\n","    y_pred = model(x)\n","    loss = loss_fn(y_pred[:,0], y)\n","    with amp.scale_loss(loss, optimizer) as scaled_loss:\n","        scaled_loss.backward()\n","    optimizer.step()\n","    return loss.item()\n","\n","trainer = Engine(train_update)\n","log_interval = 100\n","\n","scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n","trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n","    \n","@trainer.on(Events.ITERATION_COMPLETED)\n","def log_training_loss(engine):\n","    iter = (engine.state.iteration - 1) % len(dataset) + 1\n","    if iter % log_interval == 0:\n","        print('loss', engine.state.output)\n","        \n","trainer.run(dataset, max_epochs=100)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Overwriting distributed_train.py\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W45P_nauEYu4"},"source":["To launch multiple processes training, we need to run the following command:-"]},{"cell_type":"code","metadata":{"id":"vnPyq4bBEYu4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619699700908,"user_tz":-480,"elapsed":6272,"user":{"displayName":"YILIAN ZHANG","photoUrl":"","userId":"00778400246289834299"}},"outputId":"ed380b51-5f4a-46b6-c181-deadfa92ecb1"},"source":["%reset -f\n","\n","!python -m torch.distributed.launch --nproc_per_node=4 distributed_train.py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["*****************************************\n","Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n","*****************************************\n","Traceback (most recent call last):\n","  File \"distributed_train.py\", line 11, in <module>\n","    from apex import amp\n","ModuleNotFoundError: No module named 'apex'\n","Traceback (most recent call last):\n","  File \"distributed_train.py\", line 11, in <module>\n","    from apex import amp\n","ModuleNotFoundError: No module named 'apex'\n","Traceback (most recent call last):\n","  File \"distributed_train.py\", line 11, in <module>\n","    from apex import amp\n","ModuleNotFoundError: No module named 'apex'\n","Traceback (most recent call last):\n","  File \"distributed_train.py\", line 11, in <module>\n","    from apex import amp\n","ModuleNotFoundError: No module named 'apex'\n","Killing subprocess 290\n","Killing subprocess 291\n","Killing subprocess 292\n","Killing subprocess 293\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n","    \"__main__\", mod_spec)\n","  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 340, in <module>\n","    main()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 326, in main\n","    sigkill_handler(signal.SIGTERM, None)  # not coming back\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 301, in sigkill_handler\n","    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)\n","subprocess.CalledProcessError: Command '['/usr/bin/python3', '-u', 'distributed_train.py', '--local_rank=3']' returned non-zero exit status 1.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"3OkLCotmEYu5"},"source":["It works and all the GPUs are busy to train this network. However, it has a few problems:-\n","   \n","    1. There is no model serialization so the trained model is not saved\n","    2. There is no validation dataset to check the training progress\n","    3. Most of the time is spent in Monte Carlo simulation hence the training is slow\n","    4. We use a few paths(1024) for each option parameter set which is noise and the model cannot converge to a low cost value.\n","We will address these problems in the next notebook"]},{"cell_type":"code","metadata":{"id":"_mYY70ewEYu5"},"source":[""],"execution_count":null,"outputs":[]}]}
