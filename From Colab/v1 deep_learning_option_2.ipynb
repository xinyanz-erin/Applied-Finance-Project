{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "v1 deep_learning_option_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqtdig9rFXEz"
      },
      "source": [
        "!pip install -q condacolab"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxxLhYZ-FsIQ",
        "outputId": "374d1b5d-bc69-4011-be03-d8a02cb6732b"
      },
      "source": [
        "import condacolab\n",
        "condacolab.install('dask_cudf')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:24\n",
            "🔁 Restarting kernel...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC5w1SMtGRSq",
        "outputId": "8c2e99ac-f582-4d5f-d899-d7aa6dfb6bc0"
      },
      "source": [
        "pip install dask_cuda"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dask_cuda\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/cb/334ef05f4099e678b0d081b4ea2a222e9c4a150a42bde650925bde70aa66/dask_cuda-21.6.0-py3-none-any.whl (71kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.7MB/s \n",
            "\u001b[?25hCollecting pynvml>=8.0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/af/b794d013a8ff81d80d6e8fbdc78448ba97c8be8f8f56b09ecb993268edaf/pynvml-11.0.0-py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.2MB/s \n",
            "\u001b[?25hCollecting numba>=0.53.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/73/d9c127eddbe3c105a33379d425b88f9dca249a6eddf39ce886494d49c3f9/numba-0.53.1-cp37-cp37m-manylinux2014_x86_64.whl (3.4MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4MB 25.6MB/s \n",
            "\u001b[?25hCollecting distributed<=2021.5.1,>=2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/31/fa/92163eefde93e445db7b4946daccfcf825b95fe63e347807c55544e2686c/distributed-2021.5.1-py3-none-any.whl (705kB)\n",
            "\u001b[K     |████████████████████████████████| 706kB 17.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from dask_cuda) (1.19.5)\n",
            "Collecting dask<=2021.5.1,>=2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/7c/f4b5259130ecdb0d2c7bc12b32eb8465b74e98b52c86f85de8b6ba5b112c/dask-2021.5.1-py3-none-any.whl (964kB)\n",
            "\u001b[K     |████████████████████████████████| 972kB 13.2MB/s \n",
            "\u001b[?25hCollecting llvmlite<0.37,>=0.36.0rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/25/2b4015e2b0c3be2efa6870cf2cf2bd969dd0e5f937476fc13c102209df32/llvmlite-0.36.0-cp37-cp37m-manylinux2010_x86_64.whl (25.3MB)\n",
            "\u001b[K     |████████████████████████████████| 25.3MB 173kB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.53.1->dask_cuda) (57.0.0)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.5.1,>=2.22.0->dask_cuda) (5.4.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.5.1,>=2.22.0->dask_cuda) (3.13)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.5.1,>=2.22.0->dask_cuda) (7.1.2)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.5.1,>=2.22.0->dask_cuda) (1.7.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.5.1,>=2.22.0->dask_cuda) (2.4.0)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.5.1,>=2.22.0->dask_cuda) (2.0.0)\n",
            "Requirement already satisfied: tornado>=5; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.5.1,>=2.22.0->dask_cuda) (5.1.1)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.5.1,>=2.22.0->dask_cuda) (0.11.1)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from distributed<=2021.5.1,>=2.22.0->dask_cuda) (1.0.2)\n",
            "Collecting cloudpickle>=1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/e3/898487e5dbeb612054cf2e0c188463acb358167fef749c53c8bb8918cea1/cloudpickle-1.6.0-py3-none-any.whl\n",
            "Collecting partd>=0.3.10\n",
            "  Downloading https://files.pythonhosted.org/packages/41/94/360258a68b55f47859d72b2d0b2b3cfe0ca4fbbcb81b78812bd00ae86b7c/partd-1.2.0-py3-none-any.whl\n",
            "Collecting fsspec>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/3a/666e63625a19883ae8e1674099e631f9737bd5478c4790e5ad49c5ac5261/fsspec-2021.6.1-py3-none-any.whl (115kB)\n",
            "\u001b[K     |████████████████████████████████| 122kB 37.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: heapdict in /usr/local/lib/python3.7/dist-packages (from zict>=0.1.3->distributed<=2021.5.1,>=2.22.0->dask_cuda) (1.0.1)\n",
            "Collecting locket\n",
            "  Downloading https://files.pythonhosted.org/packages/50/b8/e789e45b9b9c2db75e9d9e6ceb022c8d1d7e49b2c085ce8c05600f90a96b/locket-0.2.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pynvml, llvmlite, numba, cloudpickle, locket, partd, fsspec, dask, distributed, dask-cuda\n",
            "  Found existing installation: llvmlite 0.34.0\n",
            "    Uninstalling llvmlite-0.34.0:\n",
            "      Successfully uninstalled llvmlite-0.34.0\n",
            "  Found existing installation: numba 0.51.2\n",
            "    Uninstalling numba-0.51.2:\n",
            "      Successfully uninstalled numba-0.51.2\n",
            "  Found existing installation: cloudpickle 1.3.0\n",
            "    Uninstalling cloudpickle-1.3.0:\n",
            "      Successfully uninstalled cloudpickle-1.3.0\n",
            "  Found existing installation: dask 2.12.0\n",
            "    Uninstalling dask-2.12.0:\n",
            "      Successfully uninstalled dask-2.12.0\n",
            "  Found existing installation: distributed 1.25.3\n",
            "    Uninstalling distributed-1.25.3:\n",
            "      Successfully uninstalled distributed-1.25.3\n",
            "Successfully installed cloudpickle-1.6.0 dask-2021.5.1 dask-cuda-21.6.0 distributed-2021.5.1 fsspec-2021.6.1 llvmlite-0.36.0 locket-0.2.1 numba-0.53.1 partd-1.2.0 pynvml-11.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4_0azwVsX5w",
        "outputId": "998990ef-cdd0-4938-fe1f-32e0855046cf"
      },
      "source": [
        "################################# TEST ########################################\n",
        "%%writefile cupy_dataset.py\n",
        "\n",
        "import numba\n",
        "from numba import cuda\n",
        "import random\n",
        "import cupy\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "cupy.cuda.set_allocator(None)\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# batch - number of underlyings in one basket option\n",
        "\n",
        "@cuda.jit\n",
        "def batch_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_BATCH):\n",
        "    # ii - overall thread index\n",
        "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
        "    tmp3 = math.sqrt(T/N_STEPS)\n",
        "    for i in range(ii, N_PATHS * N_BATCH, stride):\n",
        "        batch_id = i // N_PATHS\n",
        "        path_id = i % N_PATHS\n",
        "        tmp1 = mu[batch_id]*T/N_STEPS\n",
        "        tmp2 = math.exp(-r[batch_id]*T)\n",
        "        running_average = 0.0\n",
        "        s_curr = S0[batch_id]\n",
        "        for n in range(N_STEPS):\n",
        "            s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH] # stock price\n",
        "            running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average) # average of the path\n",
        "            if i==0 and batch_id == 2:\n",
        "                print(s_curr)\n",
        "            if running_average <= B[batch_id]: # if reach barrier, drop out the path\n",
        "                break\n",
        "        payoff = running_average - K[batch_id] if running_average > K[batch_id] else 0\n",
        "        d_s[i] = tmp2 * payoff\n",
        "\n",
        "class NumbaOptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len=10, number_path = 1000, batch=2, threads=512, seed=15, stocks=3):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 365\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = np.float32(1.0)\n",
        "        self.output = cupy.zeros(self.N_STOCKS*self.N_PATHS, dtype=cupy.float32) \n",
        "        self.number_of_blocks = (self.N_PATHS * self.N_STOCKS - 1) // threads + 1\n",
        "        self.number_of_threads = threads\n",
        "        cupy.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num > self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros(self.N_BATCH, dtype=cupy.float32)\n",
        "        paras = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "        for op in range(self.N_BATCH):\n",
        "          # X = cupy.random.rand(self.N_STOCKS, 6, dtype=cupy.float32)\n",
        "          X = cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32).reshape(self.N_STOCKS, 6)\n",
        "          # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "          # X = X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2], dtype=cupy.float32) # parameters\n",
        "          # make sure the Barrier is smaller than the Strike price\n",
        "          # X[:, 1] = X[:, 0] * X[:, 1]\n",
        "          for i in range(self.N_STOCKS):\n",
        "            paras[op,i*6:(i+1)*6] = X[i,:]\n",
        "\n",
        "          stocks_randoms_mean = cupy.zeros(self.N_STOCKS, dtype = cupy.float32)\n",
        "          rho = cupy.random.normal(0, 1, self.N_STOCKS, dtype = cupy.float32)\n",
        "          #stocks_randoms_cov = cupy.ones((self.N_STOCKS, self.N_STOCKS), dtype = cupy.float32)\n",
        "          #cupy.fill_diagonal(stocks_randoms_cov, rho)\n",
        "          stocks_randoms_cov = (-0.99 + cupy.random.rand(self.N_STOCKS*self.N_STOCKS, dtype=cupy.float32)*2*0.99).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "          cupy.fill_diagonal(stocks_randoms_cov, 1)\n",
        "          num_of_randoms_each_stock = self.N_PATHS * self.N_STEPS\n",
        "          randoms_gpu = cupy.random.multivariate_normal(stocks_randoms_mean, stocks_randoms_cov,\n",
        "                                                        num_of_randoms_each_stock, dtype=cupy.float32)\n",
        "          b1_r = randoms_gpu[:,0]\n",
        "          b2_r = randoms_gpu[:,1]\n",
        "          randoms = cupy.zeros(self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "          interval = int((self.N_PATHS * self.N_STEPS * self.N_STOCKS) / self.N_PATHS)\n",
        "          for i in range(interval):\n",
        "            if i % 2 == 0:\n",
        "                ind = int(i/2)\n",
        "                randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b1_r[ind:(ind+self.N_PATHS)]\n",
        "            else:\n",
        "                ind = int(i//2)\n",
        "                randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b2_r[ind:(ind+self.N_PATHS)]\n",
        "\n",
        "          randoms = cupy.random.normal(0, 1, self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "          batch_barrier_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, self.T, X[:, 0], \n",
        "                                X[:, 1], X[:, 2], X[:, 3], X[:, 4], X[:, 5], randoms, self.N_STEPS, self.N_PATHS, self.N_STOCKS)\n",
        "          \n",
        "          o = self.output.reshape(self.N_STOCKS, self.N_PATHS)\n",
        "          Y[op] = o.mean(axis = 0).mean()\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(paras.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "\n",
        "# ds = NumbaOptionDataSet(10, number_path=100000, batch=3, seed=random.randint(0,100), stocks=5)\n",
        "# for i in ds:\n",
        "#     print(i[1])\n",
        "################################# TEST ########################################"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing cupy_dataset.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_kh3pEesdEz",
        "outputId": "851d4a0c-4923-4ce7-b7b9-dc3804b4a7c3"
      },
      "source": [
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(18, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 1)\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([200.0, 198.0, 200.0, 0.4, 0.2, 0.2,\n",
        "                                           200.0, 198.0, 200.0, 0.4, 0.2, 0.2,\n",
        "                                           200.0, 198.0, 200.0, 0.4, 0.2, 0.2])) # don't use numpy here - will give error later\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing model.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoDak15wY4Ab"
      },
      "source": [
        "### Deep Learning Model for Asian Barrier Options\n",
        "\n",
        "As shown in the previous notebook, there are a few problems to generate data on the fly \n",
        "   \n",
        "    1. There is no model serialization so the trained model is not saved\n",
        "    2. There is no validation dataset to check the training progress\n",
        "    3. Most of the time is spent on Monte Carlo simulation hence the training is slow\n",
        "    4. We use a few paths(1024) for each option parameter set which is noise and the model cannot converge to a low cost value.\n",
        "The solution is to save the Monte Carlo simulation data on the disk. This allows us to\n",
        "\n",
        "    1. Reuse the same dataset for different models and save the Monte Carlo simulation time\n",
        "    2. Generate more accurate pricing data by increasing the number of paths\n",
        "    \n",
        "We will use CuPy to run the Monte Carlo simulation as it is the most efficient way. Taking the same OptionDataSet defined in the previous notebook:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDZdMs9GgiKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a00796c0-9e6c-478d-c3cb-c6474e6c29a2"
      },
      "source": [
        "!curl https://colab.chainer.org/install |sh -\n",
        "import cupy"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "curl: dask_cudf/lib/libcurl.so.4: no version information available (required by curl)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1580  100  1580    0     0   8404      0 --:--:-- --:--:-- --:--:--  8404\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "\u001b[K     |████████████████████████████████| 58.9MB 87kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 40.1MB/s \n",
            "\u001b[?25h  Building wheel for chainer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "+ set +ex\n",
            "Installation succeeded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCxAxRiqpems"
      },
      "source": [
        "import cupy\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "cupy.cuda.set_allocator(None)\n",
        "from torch.utils.dlpack import from_dlpack"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx78cY95Y4Ae"
      },
      "source": [
        "from cupy_dataset import NumbaOptionDataSet"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9KMhi2GY4Af"
      },
      "source": [
        "Making the directories for the saved data files and the model check points:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ngdUJrvuY4Af"
      },
      "source": [
        "!mkdir -p datafiles\n",
        "!mkdir -p check_points"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9R-VOYAY4Af"
      },
      "source": [
        "Defining a function to generate the dataset file:- "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVnT-7iJY4Ag"
      },
      "source": [
        "import torch\n",
        "\n",
        "def gen_data(n_files = 630, options_per_file = 10000, seed=3):\n",
        "    counter = 0\n",
        "    # ds = OptionDataSet(max_len=n_files * options_per_file, number_path=8192000, batch=1,\n",
        "    #                seed=seed)\n",
        "    ds = NumbaOptionDataSet(max_len=n_files * options_per_file, number_path=81920, batch=1,\n",
        "                   seed=seed)\n",
        "    x = []\n",
        "    y = []\n",
        "    for i in ds:\n",
        "        if counter!=0 and counter % options_per_file == 0:\n",
        "            filename = 'datafiles/'+str(seed) + '_' + str(counter//options_per_file) + '.pth'\n",
        "            state = (torch.cat(x, 0), torch.cat(y, 0))\n",
        "            torch.save(state, filename)\n",
        "            x = []\n",
        "            y = []\n",
        "        x.append(i[0].cpu())\n",
        "        y.append(i[1].cpu())\n",
        "        counter += 1\n",
        "    return seed"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vW1xmbhXY4Ag"
      },
      "source": [
        "It will generate files that contain `X` and `Y` matrix of size `option_per_file` and the filenames are in the format of `seed_group.pth`, we can test run with `n_files` = 5 and `options_per_file` = 16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWBzSA6wY4Ag",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e760f72-c477-47d5-ebb5-8cd3910b3f1e"
      },
      "source": [
        "gen_data(n_files=5, options_per_file = 16, seed=3)\n",
        "X, Y = torch.load('datafiles/3_1.pth')\n",
        "print(X)\n",
        "print(Y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/cupy/random/_distributions.py:476: FutureWarning: cupy.random.multivariate_normal is experimental. The interface can change in the future.\n",
            "  _util.experimental('cupy.random.multivariate_normal')\n",
            "/usr/local/lib/python3.7/dist-packages/cupy/random/_generator.py:337: FutureWarning: cupy.random.RandomState.multivariate_normal is experimental. The interface can change in the future.\n",
            "  _util.experimental('cupy.random.RandomState.multivariate_normal')\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rS6R35SzY4Ah"
      },
      "source": [
        "We will use DASK to generate dataset on multipe GPUs in this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b9di5RQY4Ah",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "5e37a1de-4d40-4695-ac3e-3bfccfe4c95d"
      },
      "source": [
        "import dask\n",
        "import dask_cudf\n",
        "from dask.delayed import delayed\n",
        "from dask_cuda import LocalCUDACluster\n",
        "cluster = LocalCUDACluster()\n",
        "from dask.distributed import Client\n",
        "client = Client(cluster)\n",
        "client"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table style=\"border: 2px solid white;\">\n",
              "<tr>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3 style=\"text-align: left;\">Client</h3>\n",
              "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
              "  <li><b>Scheduler: </b>tcp://127.0.0.1:32785</li>\n",
              "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
              "</ul>\n",
              "</td>\n",
              "<td style=\"vertical-align: top; border: 0px solid white\">\n",
              "<h3 style=\"text-align: left;\">Cluster</h3>\n",
              "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
              "  <li><b>Workers: </b>1</li>\n",
              "  <li><b>Cores: </b>1</li>\n",
              "  <li><b>Memory: </b>12.69 GiB</li>\n",
              "</ul>\n",
              "</td>\n",
              "</tr>\n",
              "</table>"
            ],
            "text/plain": [
              "<Client: 'tcp://127.0.0.1:32785' processes=1 threads=1, memory=12.69 GiB>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqS1jZkoY4Ai"
      },
      "source": [
        "Following code is an example that generates `100x5x16` data points on 4 GPUs. For serious Deep Learning model training, we need millions of data points. You can try to change `n_files` and `options_per_file` to larger numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4fbpuErY4Ai",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "095e4666-b6bf-4c24-d376-289150078abe"
      },
      "source": [
        "futures = []\n",
        "for i in range(0, 100):\n",
        "    future = client.submit(gen_data, 5, 16, i)\n",
        "    futures.append(future)\n",
        "results = client.gather(futures) # This will take long (view datafiles to track progress)\n",
        "results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "distributed.nanny - WARNING - Restarting worker\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-e0c9c2c4e475>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfutures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/distributed/client.py\u001b[0m in \u001b[0;36mgather\u001b[0;34m(self, futures, errors, direct, asynchronous)\u001b[0m\n\u001b[1;32m   1985\u001b[0m                 \u001b[0mdirect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1986\u001b[0m                 \u001b[0mlocal_worker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1987\u001b[0;31m                 \u001b[0masynchronous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1988\u001b[0m             )\n\u001b[1;32m   1989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/distributed/client.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(self, func, asynchronous, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    851\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m             return sync(\n\u001b[0;32m--> 853\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback_timeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_timeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m             )\n\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/distributed/utils.py\u001b[0m in \u001b[0;36msync\u001b[0;34m(loop, func, callback_timeout, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m             \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5UVLNohYTbX",
        "outputId": "b045e7d3-665f-4292-af58-b7da810b19c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9yFh3CWYVhB",
        "outputId": "de664d97-d671-4510-88ed-7224041b683f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mcheck_points\u001b[0m/    \u001b[01;34mdask_cudf\u001b[0m/  model.py      \u001b[01;34msample_data\u001b[0m/\n",
            "cupy_dataset.py  \u001b[01;34mdrive\u001b[0m/      \u001b[01;34m__pycache__\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJejYVjWY4Ai"
      },
      "source": [
        "Once millions of data points are generated, we can combine the data points together and split them into training and validation datasets. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yb0jueiIY4Aj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32822d2a-4d0d-4d6c-dbc4-f5ea5236d149"
      },
      "source": [
        "import pathlib\n",
        "\n",
        "#files = list(pathlib.Path('datafiles/').glob('*.pth'))\n",
        "files = list(pathlib.Path('drive/MyDrive/AFP/Datafiles/').glob('*.pth'))\n",
        "trn_size = int(len(files)*0.7)\n",
        "trn_files = files[:trn_size]\n",
        "val_files = files[trn_size:]\n",
        "\n",
        "trn_x = []\n",
        "trn_y = []\n",
        "count = 0\n",
        "\n",
        "for i in trn_files:\n",
        "    tensor = torch.load(i)\n",
        "    if count % 10 == 0:\n",
        "        print(count,'/',len(trn_files))\n",
        "    trn_x.append(tensor[0])\n",
        "    trn_y.append(tensor[1])\n",
        "    count += 1\n",
        "\n",
        "X = torch.cat(trn_x)\n",
        "Y = torch.cat(trn_y)\n",
        "torch.save((X,Y), 'trn.pth')\n",
        "\n",
        "val_x = []\n",
        "val_y = []\n",
        "count = 0\n",
        "\n",
        "for i in val_files:\n",
        "    tensor = torch.load(i)\n",
        "    if count % 10 == 0:\n",
        "        print(count,'/',len(val_files))\n",
        "    val_x.append(tensor[0])\n",
        "    val_y.append(tensor[1])\n",
        "    count += 1\n",
        "\n",
        "X = torch.cat(val_x)\n",
        "Y = torch.cat(val_y)\n",
        "torch.save((X,Y), 'val.pth')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 / 21\n",
            "10 / 21\n",
            "20 / 21\n",
            "0 / 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXuBnys4Y4Aj"
      },
      "source": [
        "We created two data files `trn.pth` and `val.pth` for training and validation. We can define a new PyTorch Dataset to load data from file and write it to file. This dataset takes rank and world_size arguments for distributed training. It loads the whole dataset into the GPU memory and samples the data points according to the rank id so that dataset of different rank_id gives different data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dlxHp6JY4Aj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9136ccd-040d-4241-f4fc-0080dda5f3b5"
      },
      "source": [
        "%%writefile filedataset.py\n",
        "import torch\n",
        "\n",
        "\n",
        "class OptionDataSet(torch.utils.data.Dataset):\n",
        "    def __init__(self, filename, rank=0, world_size=5):\n",
        "        tensor = torch.load(filename)\n",
        "        self.tensor = (tensor[0].cuda(), tensor[1].cuda())\n",
        "        self.length = len(self.tensor[0]) // world_size\n",
        "        self.world_size = world_size\n",
        "        self.rank = rank\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        index = index * self.world_size + self.rank\n",
        "        return self.tensor[0][index], self.tensor[1][index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing filedataset.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRRP0_63Y4Aj"
      },
      "source": [
        "When training the deep learning models, one effective way to prevent over-fitting is to have separate validation dataset to monitor the out of sample performance. When the validation dataset  performance declines,  it means over-fitting is happening so we can  stop the training. We put everything together into one script that can train the model efficiently in multiple GPUs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYfRplWgKSMP",
        "outputId": "82b93874-3e32-4ec5-ab09-56a186888c56"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/c3/f472843797b5ccbb2f0e806a6927f52c7c9522bfcea8e7e881d39258368b/pytorch_ignite-0.4.5-py3-none-any.whl (221kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 15.0MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 16.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 30kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 40kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 51kB 5.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 61kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 71kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 81kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 92kB 5.8MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 102kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 112kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 122kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 133kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 143kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 153kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 163kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 174kB 6.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 184kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 194kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 204kB 6.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 215kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 6.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OtupFY-K-Im",
        "outputId": "48837576-f0ee-4331-97ce-ea1409b265be"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/apex"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'apex'...\n",
            "remote: Enumerating objects: 8054, done.\u001b[K\n",
            "remote: Counting objects: 100% (141/141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "remote: Total 8054 (delta 68), reused 97 (delta 44), pack-reused 7913\u001b[K\n",
            "Receiving objects: 100% (8054/8054), 14.11 MiB | 27.15 MiB/s, done.\n",
            "Resolving deltas: 100% (5469/5469), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfI3EmZ5MoKL",
        "outputId": "660c2819-9963-473f-c287-208b97e0b8cc"
      },
      "source": [
        "cd apex"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/apex\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrxxYBAiYXBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bddaf77-a9c9-4950-ceef-9fb526830f9e"
      },
      "source": [
        "!pip install -v --disable-pip-version-check --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-zgo76q2c\n",
            "Created temporary directory: /tmp/pip-req-tracker-hkzngspp\n",
            "Created requirements tracker '/tmp/pip-req-tracker-hkzngspp'\n",
            "Created temporary directory: /tmp/pip-install-94a209wq\n",
            "Processing /content/apex\n",
            "  Created temporary directory: /tmp/pip-req-build-swzz_1b2\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-hkzngspp'\n",
            "    Running setup.py (path:/tmp/pip-req-build-swzz_1b2/setup.py) egg_info for package from file:///content/apex\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.9.0+cu102\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-swzz_1b2/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-swzz_1b2/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-swzz_1b2/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-swzz_1b2/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-swzz_1b2/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file '/tmp/pip-req-build-swzz_1b2/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-swzz_1b2/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-swzz_1b2 has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-hkzngspp'\n",
            "Skipping wheel build for apex, due to binaries being disabled for it.\n",
            "Installing collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-record-83krtyt2\n",
            "    Running command /usr/bin/python3.real -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-swzz_1b2/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-swzz_1b2/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-83krtyt2/install-record.txt --single-version-externally-managed --compile\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.9.0+cu102\n",
            "\n",
            "\n",
            "    /tmp/pip-req-build-swzz_1b2/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "\n",
            "    Compiling cuda extensions with\n",
            "    nvcc: NVIDIA (R) Cuda compiler driver\n",
            "    Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "    Built on Wed_Jul_22_19:09:09_PDT_2020\n",
            "    Cuda compilation tools, release 11.0, V11.0.221\n",
            "    Build cuda_11.0_bu.TC445_37.28845127_0\n",
            "    from /usr/local/cuda/bin\n",
            "\n",
            "    Traceback (most recent call last):\n",
            "      File \"<string>\", line 1, in <module>\n",
            "      File \"/tmp/pip-req-build-swzz_1b2/setup.py\", line 171, in <module>\n",
            "        check_cuda_torch_binary_vs_bare_metal(torch.utils.cpp_extension.CUDA_HOME)\n",
            "      File \"/tmp/pip-req-build-swzz_1b2/setup.py\", line 106, in check_cuda_torch_binary_vs_bare_metal\n",
            "        \"https://github.com/NVIDIA/apex/pull/323#discussion_r287021798.  \"\n",
            "    RuntimeError: Cuda extensions are being compiled with a version of Cuda that does not match the version used to compile Pytorch binaries.  Pytorch binaries were compiled with Cuda 10.2.\n",
            "    In some cases, a minor-version mismatch will not cause later errors:  https://github.com/NVIDIA/apex/pull/323#discussion_r287021798.  You can try commenting out this check (at your own risk).\n",
            "    Running setup.py install for apex ... \u001b[?25l\u001b[?25herror\n",
            "Cleaning up...\n",
            "  Removing source in /tmp/pip-req-build-swzz_1b2\n",
            "Removed build tracker '/tmp/pip-req-tracker-hkzngspp'\n",
            "\u001b[31mERROR: Command errored out with exit status 1: /usr/bin/python3.real -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-swzz_1b2/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-swzz_1b2/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-83krtyt2/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\u001b[0m\n",
            "Exception information:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/cli/base_command.py\", line 153, in _main\n",
            "    status = self.run(options, args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py\", line 455, in run\n",
            "    use_user_site=options.use_user_site,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/req/__init__.py\", line 62, in install_given_reqs\n",
            "    **kwargs\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/req/req_install.py\", line 888, in install\n",
            "    cwd=self.unpacked_source_directory,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/subprocess.py\", line 275, in runner\n",
            "    spinner=spinner,\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/pip/_internal/utils/subprocess.py\", line 242, in call_subprocess\n",
            "    raise InstallationError(exc_msg)\n",
            "pip._internal.exceptions.InstallationError: Command errored out with exit status 1: /usr/bin/python3.real -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-swzz_1b2/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-swzz_1b2/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' --cpp_ext --cuda_ext install --record /tmp/pip-record-83krtyt2/install-record.txt --single-version-externally-managed --compile Check the logs for full command output.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seD9FwsT8Dnd",
        "outputId": "31dec247-9e4c-4081-e8e7-9bcfa8964d48"
      },
      "source": [
        "! pwd"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/apex\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT2CLLwT8FOg",
        "outputId": "3c5e6048-19a2-4203-e929-a6df8ead326d"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPFk2XDhY4Ak",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b4a47bf-1b05-498c-e827-15700b8ebc1c"
      },
      "source": [
        "%%writefile distributed_training.py\n",
        "import torch\n",
        "from ignite.engine import Engine, Events\n",
        "from torch.nn import MSELoss\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from apex import amp\n",
        "import argparse\n",
        "import os\n",
        "from apex.parallel import DistributedDataParallel\n",
        "import apex\n",
        "from apex.optimizers import FusedLAMB\n",
        "from model import Net\n",
        "from filedataset import OptionDataSet\n",
        "from ignite.metrics import MeanAbsoluteError\n",
        "import ignite\n",
        "import shutil\n",
        "import torch.distributed as dist\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--local_rank\", default=0, type=int)\n",
        "parser.add_argument(\"--path\", default=None)\n",
        "parser.add_argument(\"--mae_improv_tol\", default=0.002, type=float)\n",
        "args = parser.parse_args()\n",
        "\n",
        "args.distributed = False\n",
        "if 'WORLD_SIZE' in os.environ:\n",
        "    args.distributed = int(os.environ['WORLD_SIZE']) > 1\n",
        "\n",
        "if args.distributed:\n",
        "    torch.cuda.set_device(args.local_rank)\n",
        "    torch.distributed.init_process_group(backend='nccl',\n",
        "                                         init_method='env://')\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "trn_dataset = OptionDataSet(filename='./trn.pth',\n",
        "                            rank=dist.get_rank(),\n",
        "                            world_size=int(os.environ['WORLD_SIZE']))\n",
        "trn_dataset = torch.utils.data.DataLoader(trn_dataset,\n",
        "                                          batch_size=1024,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=0)\n",
        "\n",
        "val_dataset = OptionDataSet(filename='./val.pth',\n",
        "                            rank=dist.get_rank(),\n",
        "                            world_size=int(os.environ['WORLD_SIZE']))\n",
        "val_dataset = torch.utils.data.DataLoader(val_dataset,\n",
        "                                          batch_size=1024,\n",
        "                                          shuffle=False,\n",
        "                                          num_workers=0)\n",
        "\n",
        "model = Net().cuda()\n",
        "optimizer = FusedLAMB(model.parameters(), lr=1e-3)\n",
        "loss_fn = MSELoss()\n",
        "\n",
        "\n",
        "model = apex.parallel.convert_syncbn_model(model, channel_last=True)\n",
        "model, optimizer = amp.initialize(model, optimizer, opt_level='O1')\n",
        "\n",
        "\n",
        "best_mae = 100000\n",
        "\n",
        "if args.path is not None:\n",
        "    def resume():\n",
        "        global best_mae\n",
        "        checkpoint = torch.load(args.path)\n",
        "        best_mae = checkpoint['best_mae']\n",
        "        model.load_state_dict(checkpoint['state_dict'])\n",
        "        amp.load_state_dict(checkpoint['amp'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    resume()\n",
        "\n",
        "\n",
        "if args.distributed:\n",
        "    model = DistributedDataParallel(model)\n",
        "    \n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y, y_pred[:, 0])\n",
        "    with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
        "        scaled_loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 500\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-5, 5e-6,\n",
        "                                     len(trn_dataset),\n",
        "                                     start_value_mult=0.999, end_value_mult=0.999,\n",
        "                                     save_history=False\n",
        "                                     )\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "\n",
        "\n",
        "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
        "    torch.save(state, filename)\n",
        "    if is_best:\n",
        "        shutil.copyfile(filename, 'check_points/model_best.pth.tar')\n",
        "\n",
        "\n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(trn_dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'iter', engine.state.iteration,\n",
        "              'lr', scheduler.get_param())\n",
        "\n",
        "\n",
        "metric = MeanAbsoluteError()\n",
        "loss_m = ignite.metrics.Loss(loss_fn)\n",
        "\n",
        "# run eval at one process only\n",
        "def eval_update(engine, batch):\n",
        "    model.eval()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "    return y, y_pred[:, 0]\n",
        "evaluator = Engine(eval_update)\n",
        "metric.attach(evaluator, \"MAE\")\n",
        "loss_m.attach(evaluator, \"loss\")\n",
        "        \n",
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_evalnumber(engine):\n",
        "    global best_mae\n",
        "    mae_improv_tol = args.mae_improv_tol  # default 0.002 or 0.2% improvement\n",
        "    evaluator.run(val_dataset, max_epochs=1)\n",
        "    metrics = evaluator.state.metrics\n",
        "    average_tensor = torch.tensor([metrics['MAE'], metrics['loss']]).cuda()\n",
        "    torch.distributed.reduce(average_tensor, 0, op=torch.distributed.ReduceOp.SUM)\n",
        "    torch.distributed.broadcast(average_tensor, 0)\n",
        "    average_tensor = average_tensor/int(os.environ['WORLD_SIZE'])\n",
        "\n",
        "    mae = average_tensor[0].item()\n",
        "    is_best = False\n",
        "    if (1 - mae / best_mae) >= mae_improv_tol or \\\n",
        "            (engine.state.epoch == engine.state.max_epochs and\n",
        "             mae < best_mae):\n",
        "        best_mae = mae\n",
        "        is_best = True\n",
        "\n",
        "    # print(\"RANK {}   Val Results - Epoch: {}  Avg MAE: {:.5f} loss: {:.5f} BEST MAE: {:.5f}\"\n",
        "    #      .format(dist.get_rank(), trainer.state.epoch, metrics['MAE'], metrics['loss'], best_mae))\n",
        "\n",
        "    if dist.get_rank() == 0:\n",
        "        print('Epoch {}/{}'.format(engine.state.epoch, engine.state.max_epochs))\n",
        "        print('Best MAE Improvement Tolerance for checkpointing: {}%'.format(100 * mae_improv_tol))\n",
        "        print(\"RANK {} AVG {} NGPUs, best-mae: {:.5f} mae: {:.5f} loss: {:.5f}\".format(\n",
        "            dist.get_rank(),\n",
        "            int(os.environ['WORLD_SIZE']),\n",
        "            best_mae,\n",
        "            average_tensor[0].item(),\n",
        "            average_tensor[1].item()))\n",
        "        fname = 'check_points/current_pth.tar'\n",
        "        if is_best:\n",
        "            save_checkpoint({'epoch': trainer.state.epoch,\n",
        "                             'state_dict': model.module.state_dict(),\n",
        "                             'best_mae': best_mae,\n",
        "                             'optimizer': optimizer.state_dict(),\n",
        "                             'amp': amp.state_dict()\n",
        "                             }, is_best,\n",
        "                            filename=fname)\n",
        "        #inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "        inputs = torch.tensor([[200.0, 198.0, 200.0, 0.4, 0.2, 0.2,\n",
        "                                           200.0, 198.0, 200.0, 0.4, 0.2, 0.2,\n",
        "                                           200.0, 198.0, 200.0, 0.4, 0.2, 0.2]]).cuda()\n",
        "        res = model(inputs)\n",
        "        print('test one example:', res.item())\n",
        "\n",
        "trainer.run(trn_dataset, max_epochs=2000)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing distributed_training.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPjmjndWY4Am"
      },
      "source": [
        "Compared to the last notebook, it is a little complicated because \n",
        "* it handles the validation dataset evaluation\n",
        "* it serializes the model into a file and keeps track of the best performed model based on the mean absolute error(MAE)\n",
        "* it resumes the training from the file\n",
        "\n",
        "We can launch the distributed training by the following command:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXy2yhmxY4Am",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1947b5b1-c3ef-40f9-a04b-1848495422e1"
      },
      "source": [
        "ngpus=!echo $(nvidia-smi -L | wc -l)\n",
        "!python -m torch.distributed.launch --nproc_per_node={ngpus[0]} distributed_training.py"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:164: DeprecationWarning: The 'warn' method is deprecated, use 'warning' instead\n",
            "  \"The module torch.distributed.launch is deprecated \"\n",
            "The module torch.distributed.launch is deprecated and going to be removed in future.Migrate to torch.distributed.run\n",
            "WARNING:torch.distributed.run:--use_env is deprecated and will be removed in future releases.\n",
            " Please read local_rank from `os.environ('LOCAL_RANK')` instead.\n",
            "INFO:torch.distributed.launcher.api:Starting elastic_operator with launch configs:\n",
            "  entrypoint       : distributed_training.py\n",
            "  min_nodes        : 1\n",
            "  max_nodes        : 1\n",
            "  nproc_per_node   : 1\n",
            "  run_id           : none\n",
            "  rdzv_backend     : static\n",
            "  rdzv_endpoint    : 127.0.0.1:29500\n",
            "  rdzv_configs     : {'rank': 0, 'timeout': 900}\n",
            "  max_restarts     : 3\n",
            "  monitor_interval : 5\n",
            "  log_dir          : None\n",
            "  metrics_cfg      : {}\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.local_elastic_agent:log directory set to: /tmp/torchelastic_u4k__ies/none__tiia153\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] starting workers for entrypoint: python3.real\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/utils/store.py:53: FutureWarning: This is an experimental API and will be changed in future.\n",
            "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
            "  restart_count=0\n",
            "  master_addr=127.0.0.1\n",
            "  master_port=29500\n",
            "  group_rank=0\n",
            "  group_world_size=1\n",
            "  local_ranks=[0]\n",
            "  role_ranks=[0]\n",
            "  global_ranks=[0]\n",
            "  role_world_sizes=[1]\n",
            "  global_world_sizes=[1]\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_u4k__ies/none__tiia153/attempt_0/0/error.json\n",
            "distributed_training.py:4: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
            "Traceback (most recent call last):\n",
            "  File \"distributed_training.py\", line 5, in <module>\n",
            "    from apex import amp\n",
            "ImportError: cannot import name 'amp' from 'apex' (unknown location)\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 933) of binary: /usr/bin/python3.real\n",
            "ERROR:torch.distributed.elastic.agent.server.local_elastic_agent:[default] Worker group failed\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Worker group FAILED. 3/3 attempts left; will restart worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Stopping worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
            "  restart_count=1\n",
            "  master_addr=127.0.0.1\n",
            "  master_port=29500\n",
            "  group_rank=0\n",
            "  group_world_size=1\n",
            "  local_ranks=[0]\n",
            "  role_ranks=[0]\n",
            "  global_ranks=[0]\n",
            "  role_world_sizes=[1]\n",
            "  global_world_sizes=[1]\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_u4k__ies/none__tiia153/attempt_1/0/error.json\n",
            "distributed_training.py:4: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
            "Traceback (most recent call last):\n",
            "  File \"distributed_training.py\", line 5, in <module>\n",
            "    from apex import amp\n",
            "ImportError: cannot import name 'amp' from 'apex' (unknown location)\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 939) of binary: /usr/bin/python3.real\n",
            "ERROR:torch.distributed.elastic.agent.server.local_elastic_agent:[default] Worker group failed\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Worker group FAILED. 2/3 attempts left; will restart worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Stopping worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
            "  restart_count=2\n",
            "  master_addr=127.0.0.1\n",
            "  master_port=29500\n",
            "  group_rank=0\n",
            "  group_world_size=1\n",
            "  local_ranks=[0]\n",
            "  role_ranks=[0]\n",
            "  global_ranks=[0]\n",
            "  role_world_sizes=[1]\n",
            "  global_world_sizes=[1]\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_u4k__ies/none__tiia153/attempt_2/0/error.json\n",
            "distributed_training.py:4: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
            "Traceback (most recent call last):\n",
            "  File \"distributed_training.py\", line 5, in <module>\n",
            "    from apex import amp\n",
            "ImportError: cannot import name 'amp' from 'apex' (unknown location)\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 943) of binary: /usr/bin/python3.real\n",
            "ERROR:torch.distributed.elastic.agent.server.local_elastic_agent:[default] Worker group failed\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Worker group FAILED. 1/3 attempts left; will restart worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Stopping worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous'ing worker group\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Rendezvous complete for workers. Result:\n",
            "  restart_count=3\n",
            "  master_addr=127.0.0.1\n",
            "  master_port=29500\n",
            "  group_rank=0\n",
            "  group_world_size=1\n",
            "  local_ranks=[0]\n",
            "  role_ranks=[0]\n",
            "  global_ranks=[0]\n",
            "  role_world_sizes=[1]\n",
            "  global_world_sizes=[1]\n",
            "\n",
            "INFO:torch.distributed.elastic.agent.server.api:[default] Starting worker group\n",
            "INFO:torch.distributed.elastic.multiprocessing:Setting worker0 reply file to: /tmp/torchelastic_u4k__ies/none__tiia153/attempt_3/0/error.json\n",
            "distributed_training.py:4: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
            "Traceback (most recent call last):\n",
            "  File \"distributed_training.py\", line 5, in <module>\n",
            "    from apex import amp\n",
            "ImportError: cannot import name 'amp' from 'apex' (unknown location)\n",
            "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 0 (pid: 949) of binary: /usr/bin/python3.real\n",
            "ERROR:torch.distributed.elastic.agent.server.local_elastic_agent:[default] Worker group failed\n",
            "INFO:torch.distributed.elastic.agent.server.api:Local worker group finished (FAILED). Waiting 300 seconds for other agents to finish\n",
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/utils/store.py:71: FutureWarning: This is an experimental API and will be changed in future.\n",
            "  \"This is an experimental API and will be changed in future.\", FutureWarning\n",
            "INFO:torch.distributed.elastic.agent.server.api:Done waiting for other agents. Elapsed: 0.00033926963806152344 seconds\n",
            "{\"name\": \"torchelastic.worker.status.FAILED\", \"source\": \"WORKER\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": 0, \"group_rank\": 0, \"worker_id\": \"949\", \"role\": \"default\", \"hostname\": \"49a289dff8cc\", \"state\": \"FAILED\", \"total_run_time\": 20, \"rdzv_backend\": \"static\", \"raw_error\": \"{\\\"message\\\": \\\"<NONE>\\\"}\", \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3.real\\\", \\\"local_rank\\\": [0], \\\"role_rank\\\": [0], \\\"role_world_size\\\": [1]}\", \"agent_restarts\": 3}}\n",
            "{\"name\": \"torchelastic.worker.status.SUCCEEDED\", \"source\": \"AGENT\", \"timestamp\": 0, \"metadata\": {\"run_id\": \"none\", \"global_rank\": null, \"group_rank\": 0, \"worker_id\": null, \"role\": \"default\", \"hostname\": \"49a289dff8cc\", \"state\": \"SUCCEEDED\", \"total_run_time\": 20, \"rdzv_backend\": \"static\", \"raw_error\": null, \"metadata\": \"{\\\"group_world_size\\\": 1, \\\"entry_point\\\": \\\"python3.real\\\"}\", \"agent_restarts\": 3}}\n",
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py:354: UserWarning: \n",
            "\n",
            "**********************************************************************\n",
            "               CHILD PROCESS FAILED WITH NO ERROR_FILE                \n",
            "**********************************************************************\n",
            "CHILD PROCESS FAILED WITH NO ERROR_FILE\n",
            "Child process 949 (local_rank 0) FAILED (exitcode 1)\n",
            "Error msg: Process failed with exitcode 1\n",
            "Without writing an error file to <N/A>.\n",
            "While this DOES NOT affect the correctness of your application,\n",
            "no trace information about the error will be available for inspection.\n",
            "Consider decorating your top level entrypoint function with\n",
            "torch.distributed.elastic.multiprocessing.errors.record. Example:\n",
            "\n",
            "  from torch.distributed.elastic.multiprocessing.errors import record\n",
            "\n",
            "  @record\n",
            "  def trainer_main(args):\n",
            "     # do train\n",
            "**********************************************************************\n",
            "  warnings.warn(_no_error_file_warning_msg(rank, failure))\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 173, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 169, in main\n",
            "    run(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/run.py\", line 624, in run\n",
            "    )(*cmd_args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 116, in __call__\n",
            "    return launch_agent(self._config, self._entrypoint, list(args))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py\", line 348, in wrapper\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launcher/api.py\", line 247, in launch_agent\n",
            "    failures=result.failures,\n",
            "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
            "***************************************\n",
            "     distributed_training.py FAILED    \n",
            "=======================================\n",
            "Root Cause:\n",
            "[0]:\n",
            "  time: 2021-06-24_23:40:44\n",
            "  rank: 0 (local_rank: 0)\n",
            "  exitcode: 1 (pid: 949)\n",
            "  error_file: <N/A>\n",
            "  msg: \"Process failed with exitcode 1\"\n",
            "=======================================\n",
            "Other Failures:\n",
            "  <NO_OTHER_FAILURES>\n",
            "***************************************\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWR8uaBCY4An"
      },
      "source": [
        "We need some patience to train the pricing model until it converges."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5arlcWurY4An"
      },
      "source": [
        "### Inference and Greeks\n",
        "Once the training is converged, the best performed model is saved into `check_points/` directory. \n",
        "\n",
        "To get a good model, you need millions of data points to train the model until it converges. Usually it takes 10-20 hours in a single 8 GPUs DGX-1 machine. We trained the model with 10 million training data points and 5 million validation data points. We didn't explore what is the minimum number of training samples but simply use large number of data samples. You may get away by using less data points for training. \n",
        "\n",
        "To save your time, you can run the following commands to download the weights and use them for the inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YDSjbAga8MEn",
        "outputId": "0caff3f2-a5ff-448b-b728-8c6efafeb3d9"
      },
      "source": [
        "pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhJHh5gDY4An",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fef5fad-45d0-41ed-d41a-d85c8da95155"
      },
      "source": [
        "! ((test ! -f './check_points/model_best.pth.tar' ||  test ! -f './check_points/512/model_best.pth.tar') && \\\n",
        "  bash ./download_data.sh) || echo \"Dataset is already present. No need to re-download it.\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-29 14:20:33--  https://query.data.world/s/fb3ilrt77qcpx7kwnfgr3cybvdctk2\n",
            "Resolving query.data.world (query.data.world)... 151.101.2.133, 151.101.66.133, 151.101.130.133, ...\n",
            "Connecting to query.data.world (query.data.world)|151.101.2.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://download.data.world/file_download/yidata/weights1024/model_best.pth.tar?auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OnlpZGF0YSIsImlzcyI6ImFnZW50OnlpZGF0YTo6ZjJkYTQ1NmUtYjA5MC00ZjdiLTgyNTYtOWU0ZTFjNTA5ZGRmIiwiaWF0IjoxNTgxNzAzMDY5LCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiJiZTQxOTdiNDQ2OTZjOWFjNmRjNmFlMDZjMzQxZGE5ZmI2MTY4ODZhIn0.ivgs7kPSxaf1EkRk_CfBrH8BNquYpkiFHnFDOAiY4_9MxfluMFREgtmUUftiYD7536Y6PsNC-x62FrtoZC4JXA [following]\n",
            "--2021-04-29 14:20:34--  https://download.data.world/file_download/yidata/weights1024/model_best.pth.tar?auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OnlpZGF0YSIsImlzcyI6ImFnZW50OnlpZGF0YTo6ZjJkYTQ1NmUtYjA5MC00ZjdiLTgyNTYtOWU0ZTFjNTA5ZGRmIiwiaWF0IjoxNTgxNzAzMDY5LCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiJiZTQxOTdiNDQ2OTZjOWFjNmRjNmFlMDZjMzQxZGE5ZmI2MTY4ODZhIn0.ivgs7kPSxaf1EkRk_CfBrH8BNquYpkiFHnFDOAiY4_9MxfluMFREgtmUUftiYD7536Y6PsNC-x62FrtoZC4JXA\n",
            "Resolving download.data.world (download.data.world)... 151.101.2.133, 151.101.66.133, 151.101.130.133, ...\n",
            "Connecting to download.data.world (download.data.world)|151.101.2.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-tar]\n",
            "Saving to: ‘./check_points/model_best.pth.tar’\n",
            "\n",
            "./check_points/mode     [      <=>           ]  48.15M  39.9MB/s    in 1.2s    \n",
            "\n",
            "2021-04-29 14:20:35 (39.9 MB/s) - ‘./check_points/model_best.pth.tar’ saved [50484852]\n",
            "\n",
            "--2021-04-29 14:20:35--  https://query.data.world/s/o2kzs74pg22mc2mfyhkykyu6pq36yr\n",
            "Resolving query.data.world (query.data.world)... 151.101.2.133, 151.101.66.133, 151.101.130.133, ...\n",
            "Connecting to query.data.world (query.data.world)|151.101.2.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://download.data.world/file_download/yidata/weight512/model_best.pth.tar?auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OnlpZGF0YSIsImlzcyI6ImFnZW50OnlpZGF0YTo6ZjJkYTQ1NmUtYjA5MC00ZjdiLTgyNTYtOWU0ZTFjNTA5ZGRmIiwiaWF0IjoxNTgxNzAzMTU2LCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiIxYTMyMjY4YzA4YjMzYzJiMzlhMjg5MTA4NDE5OGFiZjNjZWExNzdmIn0.QEUxrUZ0uyXu2-cLU6JrhmNHWwScObX0NYghH8UdLP8SJXA6AefVZrtRBINeK6j_iM8ibOzJ19FidH1r5BsJbA [following]\n",
            "--2021-04-29 14:20:36--  https://download.data.world/file_download/yidata/weight512/model_best.pth.tar?auth=eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJwcm9kLXVzZXItY2xpZW50OnlpZGF0YSIsImlzcyI6ImFnZW50OnlpZGF0YTo6ZjJkYTQ1NmUtYjA5MC00ZjdiLTgyNTYtOWU0ZTFjNTA5ZGRmIiwiaWF0IjoxNTgxNzAzMTU2LCJyb2xlIjpbInVzZXIiLCJ1c2VyX2FwaV9hZG1pbiIsInVzZXJfYXBpX3JlYWQiLCJ1c2VyX2FwaV93cml0ZSJdLCJnZW5lcmFsLXB1cnBvc2UiOmZhbHNlLCJ1cmwiOiIxYTMyMjY4YzA4YjMzYzJiMzlhMjg5MTA4NDE5OGFiZjNjZWExNzdmIn0.QEUxrUZ0uyXu2-cLU6JrhmNHWwScObX0NYghH8UdLP8SJXA6AefVZrtRBINeK6j_iM8ibOzJ19FidH1r5BsJbA\n",
            "Resolving download.data.world (download.data.world)... 151.101.2.133, 151.101.66.133, 151.101.130.133, ...\n",
            "Connecting to download.data.world (download.data.world)|151.101.2.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/x-tar]\n",
            "Saving to: ‘./check_points/512/model_best.pth.tar’\n",
            "\n",
            "./check_points/512/     [   <=>              ]  12.08M  19.1MB/s    in 0.6s    \n",
            "\n",
            "2021-04-29 14:20:37 (19.1 MB/s) - ‘./check_points/512/model_best.pth.tar’ saved [12662389]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10yIGtZYY4Ao"
      },
      "source": [
        "We can load the model parameters and use it to do inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLPWkGUmY4Ao",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "201b2830-0990-4ee8-c185-7853ceffc68f"
      },
      "source": [
        "from model import Net\n",
        "import torch\n",
        "\n",
        "checkpoint = torch.load('check_points/model_best.pth.tar')\n",
        "model = Net().cuda()\n",
        "model.load_state_dict(checkpoint['state_dict'])\n",
        "inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "model(inputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[18.7140]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrJQTYSdY4Ap"
      },
      "source": [
        "One of the benefits of building a deep learning model is that the [Greeks](<https://en.wikipedia.org/wiki/Greeks_(finance)#First-order_Greeks>) can be easily computed. \n",
        "We just need to take advantage of the auto-grad feature in Pytorch. Following is an example to compute the first order differentiation for a multiple variable polynomial function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Sh8kFDwY4Ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "464ebc17-115b-43e0-edab-0425d26d2e7e"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import grad\n",
        "'''\n",
        "z = (xy)^2\n",
        "x = 3, y =2\n",
        "\n",
        "first order deriv [24 36]\n",
        "'''\n",
        "inputs = torch.tensor([3.0,2.0], requires_grad=True)\n",
        "z = (inputs[0]*inputs[1])**2\n",
        "first_order_grad = grad(z, inputs, create_graph=True)\n",
        "print(first_order_grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([24., 36.], grad_fn=<AddBackward0>),)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpRbcPIDY4Ap"
      },
      "source": [
        "We can use `grad` function to compute the first order differentiation for parameters 'K, B, S0, sigma, mu, r'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qu8osBOLY4Ap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c6c09a-0ec9-42c6-82ea-1674dc5890ef"
      },
      "source": [
        "inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-6.7092e-01, -2.1257e-02,  7.8896e-01,  1.9219e+01,  4.8331e+01,\n",
              "         -1.8419e+01]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z-nvnNDmY4Aq"
      },
      "source": [
        "Here we are going to plot the Delta graph:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir6V5FEqY4Aq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "15cbbe8a-c7c9-4569-a107-3444104317cf"
      },
      "source": [
        "%matplotlib inline\n",
        "import pylab\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[110.0, 100.0, S, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f853b3a9510>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uWSE6_P2Y4Aq"
      },
      "source": [
        "Calculating the second order derivative is easy in PyTorch too. We just need to apply the `grad` function twice. Following is an example to calculate the second order derivative for the same polynomial function as above:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3kTEnh33Y4Aq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "383baf3b-26aa-4d65-a5b3-71195fbdfe17"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import grad\n",
        "'''\n",
        "z = (xy)^2\n",
        "x = 3, y =2\n",
        "\n",
        "first order deriv [24 36]\n",
        "d2z/dx2 = 8\n",
        "d2z/dxdy = 24\n",
        "d2z/dy2 = 18\n",
        "'''\n",
        "\n",
        "inputs = torch.tensor([3.0,2.0], requires_grad=True)\n",
        "z = (inputs[0]*inputs[1])**2\n",
        "first_order_grad = grad(z, inputs, create_graph=True)\n",
        "second_order_grad_x, = grad(first_order_grad[0][0], inputs, retain_graph=True) #\n",
        "second_order_grad_y, = grad(first_order_grad[0][1], inputs)\n",
        "print(second_order_grad_x)\n",
        "print(second_order_grad_y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 8., 24.])\n",
            "tensor([24., 18.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_uoFDGAY4Ar"
      },
      "source": [
        "Use this mechanism, we can calculate the second order derivatives $\\frac{\\partial^2 P}{\\partial K \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial B \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial S_0^2}$, $\\frac{\\partial^2 P}{\\partial \\sigma \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial \\mu \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial r \\partial S_0}$ in the following example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJOYSKWBY4Ar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a3b120-801e-4e38-ae8a-e7d9c246674a"
      },
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import grad\n",
        "from torch import nn\n",
        "\n",
        "inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs)\n",
        "\n",
        "# instead of using loss.backward(), use torch.autograd.grad() to compute gradients\n",
        "# https://pytorch.org/docs/stable/autograd.html#torch.autograd.grad\n",
        "loss_grads = grad(x, inputs, create_graph=True)\n",
        "drv = grad(loss_grads[0][0][2], inputs)\n",
        "drv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.0143,  0.0039,  0.0098, -0.3183,  1.1455, -0.7876]],\n",
              "        device='cuda:0'),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ISK5VToY4Ar"
      },
      "source": [
        "Gamma is the second order differenation of `S`. We can plot the the Gamma curve as a function of the stock price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gym9MGwhY4Ar",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "1ed54694-a3c5-458d-da21-7b10a3121ec4"
      },
      "source": [
        "import pylab\n",
        "import numpy as np\n",
        "def compute_gamma(S):\n",
        "    inputs = torch.tensor([[110.0, 100.0, S, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    loss_grads = grad(x, inputs, create_graph=True)\n",
        "    drv = grad(loss_grads[0][0][2], inputs)\n",
        "    return drv[0][0][2]\n",
        "\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_gamma(p).item())\n",
        "fig2 = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Gamma')\n",
        "fig2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f853ae59110>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVT5kXo7Y4Ar"
      },
      "source": [
        "[Implied volatility](https://en.wikipedia.org/wiki/Implied_volatility) is the forecasted volatility of the underlying asset based on the quoted prices of the option. It is the reverse mapping of price to the option parameter given the model which is hard to do with the Monte Carlo simulation approach. But if we have the deep learning pricing model, it is an easy task. We can first plot the relationship between volatility and the option price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hg40avDUY4As",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "1df5316a-6e07-4553-8680-24069fa71907"
      },
      "source": [
        "import pylab\n",
        "import numpy as np\n",
        "def compute_price(sigma):\n",
        "    inputs = torch.tensor([[110.0, 100.0, 120.0, sigma, 0.1, 0.05]]).cuda()\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    return x.item()\n",
        "sigmas = np.arange(0, 0.5, 0.1)\n",
        "prices = []\n",
        "for s in sigmas:\n",
        "    prices.append(compute_price(s))\n",
        "fig3 = pylab.plot(sigmas, prices)\n",
        "pylab.xlabel('Sigma')\n",
        "pylab.ylabel('Price')\n",
        "fig3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f853ad43bd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwB23OfBY4As"
      },
      "source": [
        "Given the prices `P`, the implied volatility is the root of the function `compute_price`. We can use bisection to find the root."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAJyPYthY4As",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca2adfe0-a58d-469e-809d-f870a152e3ff"
      },
      "source": [
        "def bisection_root(small, large, fun, target, EPS=1e-6):\n",
        "    if fun(large) - target < 0:\n",
        "        print('upper bound is too small')\n",
        "        return None\n",
        "    if fun(small) - target > 0:\n",
        "        print('lower bound is too large')\n",
        "        return None\n",
        "    while large - small > EPS:\n",
        "        mid = (large + small) / 2.0\n",
        "        if fun(mid) - target >= 0:\n",
        "            large = mid\n",
        "        else:\n",
        "            small = mid\n",
        "    mid = (large + small) / 2.0\n",
        "    return mid, abs(fun(mid) - target)\n",
        "quoted_price = 16.0\n",
        "sigma, err = bisection_root(0, 0.5, compute_price, quoted_price)\n",
        "print('implied volativity', sigma, 'error', err)     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "implied volativity 0.18517351150512695 error 4.76837158203125e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hp5LGoLeY4As"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Yye9XXBY4As"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}