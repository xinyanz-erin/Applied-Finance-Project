{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Combined.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NwN6aLFDnwiy",
        "dBOv_RiBsCWa",
        "u2_89jOknwjH"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Pui/From%20Colab/Combined3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCR6hhw5Xq_R"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSxOZk3ls2XQ",
        "outputId": "1931337a-fc5e-4e01-f2e6-5c51b5ddb57c"
      },
      "source": [
        "!curl https://colab.chainer.org/install |sh -\n",
        "import cupy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1580  100  1580    0     0   4619      0 --:--:-- --:--:-- --:--:--  4619\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "\u001b[K     |████████████████████████████████| 58.9MB 88kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 28.9MB/s \n",
            "\u001b[?25h  Building wheel for chainer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "+ set +ex\n",
            "Installation succeeded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwN6aLFDnwiy"
      },
      "source": [
        "### Deep Learning Barrier Option\n",
        "\n",
        "We used Numba and CuPy in the previous notebook to run Monte Carlo simulation to determine the price of the Asian Barrier option. A Monte Carlo simulation needs millions of paths to get an accurate answer which is computationally intensive. [Ryan et al (2018)](https://arxiv.org/abs/1809.02233) showed that a deep learning model can be trained to value derivatives. The deep learning model is accurate and very fast, capable of producing valuations a million times faster than traditional models. In the this notebook, we will use a fully connected network to learn the pricing mode of the Asian Barrier option. Monte Carlo simulation is used as pricing ground truth for the training. We use the same Asian Barrier Option model as last notebook with parameters listed as following:\n",
        "\n",
        "```\n",
        "T - Maturity (yrs.)\n",
        "S - Spot (usd)\n",
        "K - Strike (usd)\n",
        "sigma - Volatility (per.)\n",
        "r - Risk Free Rate (per.)\n",
        "mu - Stock Drift Rate (per.)\n",
        "B - Barrier (usd)\n",
        "```\n",
        "\n",
        "### Batched Data generation\n",
        "\n",
        "The dataset is an important part of the Deep learning training. We will modify the previous single Asian Barrier Option pricing code to handle a batch of Barrier Option pricing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHYrh4iYfP-n",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "###Test: Judy's new X code\n",
        "#N_STOCKS = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy7qGwT0jv4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "ac958b42-0bd5-4600-d2b8-246276885438"
      },
      "source": [
        "#@title\n",
        "#X = cupy.array([])\n",
        "#for i in range(0,N_STOCKS):\n",
        "  #X =  cupy.concatenate((X,cupy.array([1,1]), cupy.random.rand(3),cupy.array([1])))\n",
        "#X = X.reshape(N_STOCKS,6)\n",
        "#X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 1.        , 0.05103263, 0.0071633 , 0.52167781,\n",
              "        1.        ],\n",
              "       [1.        , 1.        , 0.64857557, 0.32324551, 0.39745689,\n",
              "        1.        ],\n",
              "       [1.        , 1.        , 0.82301291, 0.46666519, 0.8391176 ,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OHtAXC8hVae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "264cef2d-1ead-43b8-e5fd-d8a131f38fda"
      },
      "source": [
        "#@title\n",
        "#X = X * ((cupy.array([200.0, 0, 200.0, 0.4, 0.2, 0.2] * N_STOCKS, dtype = cupy.float32)).reshape(N_STOCKS, 6))\n",
        "#X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.00000000e+02, 0.00000000e+00, 1.02065252e+01, 2.86532070e-03,\n",
              "        1.04335564e-01, 2.00000003e-01],\n",
              "       [2.00000000e+02, 0.00000000e+00, 1.29715113e+02, 1.29298207e-01,\n",
              "        7.94913799e-02, 2.00000003e-01],\n",
              "       [2.00000000e+02, 0.00000000e+00, 1.64602581e+02, 1.86666078e-01,\n",
              "        1.67823523e-01, 2.00000003e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY_9g3tbdLiY"
      },
      "source": [
        "# TEST_ERIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBxT9Eida-c_",
        "outputId": "300c9793-5156-4c99-e9a6-cfe50b393fd8"
      },
      "source": [
        "################################# TEST ########################################\n",
        "%%writefile cupy_dataset.py\n",
        "\n",
        "import numba\n",
        "from numba import cuda\n",
        "import random\n",
        "import cupy\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "cupy.cuda.set_allocator(None)\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "@cuda.jit\n",
        "def batch_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_BATCH):\n",
        "    # ii - overall thread index\n",
        "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
        "    tmp3 = math.sqrt(T/N_STEPS)\n",
        "    for i in range(ii, N_PATHS * N_BATCH, stride):\n",
        "        batch_id = i // N_PATHS\n",
        "        path_id = i % N_PATHS\n",
        "        tmp1 = mu[batch_id]*T/N_STEPS\n",
        "        tmp2 = math.exp(-r[batch_id]*T)\n",
        "        running_average = 0.0\n",
        "        s_curr = S0[batch_id]\n",
        "        for n in range(N_STEPS):\n",
        "            s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH] # stock price\n",
        "            running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average) # average of the path\n",
        "            if i==0 and batch_id == 2:\n",
        "                print(s_curr)\n",
        "            if running_average <= B[batch_id]: # if reach barrier, drop out the path\n",
        "                break\n",
        "        payoff = running_average - K[batch_id] if running_average > K[batch_id] else 0\n",
        "        d_s[i] = tmp2 * payoff\n",
        "\n",
        "class NumbaOptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len=10, number_path = 1000, batch=2, threads=512, seed=15, stocks=3):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 365\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = np.float32(1.0)\n",
        "        self.output = cupy.zeros(self.N_STOCKS*self.N_PATHS, dtype=cupy.float32) \n",
        "        self.number_of_blocks = (self.N_PATHS * self.N_STOCKS - 1) // threads + 1\n",
        "        self.number_of_threads = threads\n",
        "        cupy.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num > self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros(self.N_BATCH, dtype=cupy.float32)\n",
        "        paras = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "        for op in range(self.N_BATCH):\n",
        "          #[K,B,S0,sigma,mu,r]\n",
        "          X = cupy.array([])\n",
        "          K_rand = cupy.random.rand(1)[0]\n",
        "          B_rand = cupy.random.rand(1)[0]\n",
        "          r_rand = cupy.random.rand(1)[0]\n",
        "          for i in range(0,self.N_STOCKS):\n",
        "            X =  cupy.concatenate((X,cupy.array([K_rand,B_rand]), cupy.random.rand(3),cupy.array([r_rand])))\n",
        "          X = X.reshape(self.N_STOCKS,6)\n",
        "          X = X * ((cupy.array([200.0, 0.1, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6))\n",
        "          #X = cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)\n",
        "          #X = 0.9 + cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)*0.1\n",
        "          # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "          #X = (X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6)\n",
        "\n",
        "          # make sure the Barrier is smaller than the Strike price\n",
        "          # X[:, 1] = X[:, 0] * X[:, 1]\n",
        "          for i in range(self.N_STOCKS):\n",
        "            paras[op,i*6:(i+1)*6] = X[i,:]\n",
        "\n",
        "          stocks_randoms_mean = cupy.zeros(self.N_STOCKS, dtype = cupy.float32)\n",
        "          rho = cupy.random.normal(0, 1, self.N_STOCKS, dtype = cupy.float32)\n",
        "\n",
        "          #stocks_randoms_cov = cupy.ones((self.N_STOCKS, self.N_STOCKS), dtype = cupy.float32)\n",
        "          #cupy.fill_diagonal(stocks_randoms_cov, rho)\n",
        "\n",
        "          #stocks_randoms_cov = (-0.99 + cupy.random.rand(self.N_STOCKS*self.N_STOCKS, dtype=cupy.float32)*2*0.99).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "          stocks_randoms_cov = cupy.array([1] * self.N_STOCKS*self.N_STOCKS, dtype = cupy.float32).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "          cupy.fill_diagonal(stocks_randoms_cov, 1)\n",
        "\n",
        "          num_of_randoms_each_stock = self.N_PATHS * self.N_STEPS\n",
        "          randoms_gpu = cupy.random.multivariate_normal(stocks_randoms_mean, stocks_randoms_cov,\n",
        "                                                        num_of_randoms_each_stock, dtype=cupy.float32)\n",
        "          b1_r = randoms_gpu[:,0]\n",
        "          b2_r = randoms_gpu[:,1]\n",
        "          randoms = cupy.zeros(self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "          interval = int((self.N_PATHS * self.N_STEPS * self.N_STOCKS) / self.N_PATHS)\n",
        "          for i in range(interval):\n",
        "            if i % 2 == 0:\n",
        "                ind = int(i/2)\n",
        "                randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b1_r[ind:(ind+self.N_PATHS)]\n",
        "            else:\n",
        "                ind = int(i//2)\n",
        "                randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b2_r[ind:(ind+self.N_PATHS)]\n",
        "\n",
        "          randoms = cupy.random.normal(0, 1, self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "          batch_barrier_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, self.T, X[:, 0], \n",
        "                                X[:, 1], X[:, 2], X[:, 3], X[:, 4], X[:, 5], randoms, self.N_STEPS, self.N_PATHS, self.N_STOCKS)\n",
        "          \n",
        "          o = self.output.reshape(self.N_STOCKS, self.N_PATHS)\n",
        "          Y[op] = o.mean(axis = 0).mean()\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(paras.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "\n",
        "# ds = NumbaOptionDataSet(10, number_path=100000, batch=3, seed=random.randint(0,100), stocks=5)\n",
        "# for i in ds:\n",
        "#     print(i[0])\n",
        "################################# TEST ########################################"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing cupy_dataset.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2_89jOknwjH"
      },
      "source": [
        "### Model\n",
        "To map the option parameters to price, we use 6 layers of fully connected neural network with hidden dimension 512 as inspired by [this paper](https://arxiv.org/abs/1809.02233). Writing this DL price model into a file `model.py`:-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMHqzJycx8XH"
      },
      "source": [
        "### Modified Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTn7iJQryAIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ca9d42e-a415-4fe4-b82b-d7dce7dd86e7"
      },
      "source": [
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(18, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 1)\n",
        "        # self.register_buffer('norm',\n",
        "        #                      torch.tensor([200.0, 198.0, 200.0, 0.4, 0.2, 0.2,\n",
        "        #                                    200.0, 198.0, 200.0, 0.4, 0.2, 0.2,\n",
        "        #                                    200.0, 198.0, 200.0, 0.4, 0.2, 0.2])) # don't use numpy here - will give error later\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([200.0, 0.1, 200.0, 0.4, 0.2, 0.2]*3)) # don't use numpy here - will give error later\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing model.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSPRFqyznwjI"
      },
      "source": [
        "As we know the random parameters' scaling factors, the input parameters are first scaled back to a range of (0-1) by dividing them by (200.0, 198.0, 200.0, 0.4, 0.2, 0.2). Then they are projected 5 times to the hidden dimension of 512 after the `ELu` activation function. `ELu` is chosen because we need to compute the second order differentiation of the parameters. If use ReLu, the second order differentiation will always be zero. The last layer is a linear layer that maps the hidden dimension to the predicted option price. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM8J2liPnwjJ"
      },
      "source": [
        "For training, we use [Ignite](https://github.com/pytorch/ignite) which is a high-level library to train neural networks in PyTorch. We use `MSELoss` as the loss function, `Adam` as the optimizer and `CosineAnnealingScheduler` as the learning rate scheduler. The following code is feeding the random option data to the pricing model to train it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yACi4ge13_rd"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TyZT8_AH35M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "022c0e16-eb84-49be-dfc4-2808adac0456"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/c3/f472843797b5ccbb2f0e806a6927f52c7c9522bfcea8e7e881d39258368b/pytorch_ignite-0.4.5-py3-none-any.whl (221kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 18.8MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 23.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 30kB 11.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 40kB 9.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 51kB 4.2MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 71kB 4.8MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 81kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 92kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 102kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 112kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 122kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 133kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 143kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 153kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 163kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 174kB 5.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 184kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 194kB 5.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 204kB 5.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 215kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 5.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Ej82G8nwjJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "outputId": "117f1147-e396-492b-e77c-0ee96bc6d607"
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import NumbaOptionDataSet\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "# dataset = NumbaOptionDataSet(max_len=10000, number_path = 1024, batch=4800)\n",
        "dataset = NumbaOptionDataSet(max_len=100, number_path = 1024, batch=32, stocks=3)\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred[:,0], y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss 1348.211181640625 average time 0.16685850134999783\n",
            "loss 1128.984375 average time 0.08487756330000593\n",
            "loss 940.9929809570312 average time 0.057521459633339114\n",
            "loss 125.07563781738281 average time 0.04385662178750636\n",
            "loss 72.34493255615234 average time 0.035652158290006356\n",
            "loss 76.38220977783203 average time 0.030184201966676483\n",
            "loss 27.641807556152344 average time 0.026275256678578832\n",
            "loss 31.383182525634766 average time 0.02334492896875844\n",
            "loss 23.642253875732422 average time 0.021068233811120586\n",
            "loss 24.765731811523438 average time 0.019250153810008896\n",
            "loss 27.127243041992188 average time 0.017756466418185565\n",
            "loss 27.962196350097656 average time 0.016511562258339534\n",
            "loss 30.81705665588379 average time 0.015457891973077354\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Engine run is terminating due to exception: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-328a3a63f484>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    799\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     97\u001b[0m           \u001b[0mb1_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandoms_gpu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m           \u001b[0mb2_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandoms_gpu\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m           \u001b[0mrandoms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STOCKS\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_PATHS\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m           \u001b[0minterval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_PATHS\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STEPS\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STOCKS\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_PATHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/cupy/_creation/basic.py\u001b[0m in \u001b[0;36mzeros\u001b[0;34m(shape, dtype, order)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \"\"\"\n\u001b[0;32m--> 209\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m     \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemset_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU1EpGuInwjJ"
      },
      "source": [
        "$2365$ seconds The loss is keeping decreasing which means the pricing model can predict the option prices better. It takes about $12ms$ to compute one mini-batch in average, In the following sections, we will try to expore the full potentials of the GPU to accelerate the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8McNtejRNFT"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRtOr1XIPOvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "020310b7-76bb-4b4c-de91-165ec82df560"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndftly2yPEaM"
      },
      "source": [
        "model_save_name = 'checkpoint9.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6DRO9K2RQoJ"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGXZSV_YRT8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a343a5ca-ab90-46a1-b1b1-130e4363868a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ntY-N5bOqdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ec3d882-9df2-4467-edb7-ab452d20bc73"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'checkpoint7.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0GAGPAgPmgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "228e9059-f59c-4a2e-eb34-e1537c49f091"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=18, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc5): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc6): Linear(in_features=1024, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXT4Bg0wdL7l"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfa9cp6CdG8T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "13ca40df-861c-44f7-974b-fff20c64f3b1"
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import NumbaOptionDataSet\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "# dataset = NumbaOptionDataSet(max_len=10000, number_path = 1024, batch=4800)\n",
        "dataset = NumbaOptionDataSet(max_len=500, number_path = 1024, batch=32, stocks=3)\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred[:,0], y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs=50)\n",
        "\n",
        "model_save_name = 'checkpoint9.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss 0.38853776454925537 average time 0.17599232950014992 iter num 20\n",
            "loss 0.255252867937088 average time 0.08989260520002063 iter num 40\n",
            "loss 0.1659018099308014 average time 0.06125505621682047 iter num 60\n",
            "loss 0.1648981124162674 average time 0.04695751917506641 iter num 80\n",
            "loss 0.12444756180047989 average time 0.03832785258004151 iter num 100\n",
            "loss 0.201492041349411 average time 0.03257214597509422 iter num 120\n",
            "loss 0.11788822710514069 average time 0.028448888764406936 iter num 140\n",
            "loss 0.19737261533737183 average time 0.025374475375110707 iter num 160\n",
            "loss 0.16879725456237793 average time 0.022985531266830447 iter num 180\n",
            "loss 0.18736013770103455 average time 0.02107538606516755 iter num 200\n",
            "loss 0.1337679922580719 average time 0.019510331268363438 iter num 220\n",
            "loss 0.19578289985656738 average time 0.018196588837630163 iter num 240\n",
            "loss 0.18098130822181702 average time 0.017116570853991455 iter num 260\n",
            "loss 0.17451420426368713 average time 0.016159983357244657 iter num 280\n",
            "loss 0.17756526172161102 average time 0.015346960986765528 iter num 300\n",
            "loss 0.12150339782238007 average time 0.014621723712559742 iter num 320\n",
            "loss 0.19022060930728912 average time 0.01398205121180688 iter num 340\n",
            "loss 0.11289404332637787 average time 0.013417173363915126 iter num 360\n",
            "loss 0.15595726668834686 average time 0.012908718292151447 iter num 380\n",
            "loss 0.164775550365448 average time 0.01245427315251618 iter num 400\n",
            "loss 0.08143547177314758 average time 0.012050189364284354 iter num 420\n",
            "loss 0.06508859992027283 average time 0.011680201588610956 iter num 440\n",
            "loss 0.10721941292285919 average time 0.011335310715185187 iter num 460\n",
            "loss 0.10262840986251831 average time 0.011018288681217807 iter num 480\n",
            "loss 0.148553729057312 average time 0.010725987283985888 iter num 500\n",
            "loss 0.2720929980278015 average time 0.17646426889969008 iter num 20\n",
            "loss 0.9517946243286133 average time 0.09008273607505543 iter num 40\n",
            "loss 0.8250637054443359 average time 0.061374925533467226 iter num 60\n",
            "loss 0.1705324500799179 average time 0.04696575921270778 iter num 80\n",
            "loss 0.2551712393760681 average time 0.03834791444012808 iter num 100\n",
            "loss 0.153749018907547 average time 0.03259428324181499 iter num 120\n",
            "loss 0.0988478809595108 average time 0.02847084630014121 iter num 140\n",
            "loss 0.2763392925262451 average time 0.025396657750093254 iter num 160\n",
            "loss 0.32118454575538635 average time 0.022982062644486077 iter num 180\n",
            "loss 0.2807939052581787 average time 0.02107296852003856 iter num 200\n",
            "loss 0.3206276297569275 average time 0.019529848240960167 iter num 220\n",
            "loss 0.2333029806613922 average time 0.018203422508410463 iter num 240\n",
            "loss 0.2277964949607849 average time 0.017114260573180218 iter num 260\n",
            "loss 0.3453255891799927 average time 0.016171509296522606 iter num 280\n",
            "loss 0.10748745501041412 average time 0.015347669866750948 iter num 300\n",
            "loss 0.24011288583278656 average time 0.014610971931313088 iter num 320\n",
            "loss 0.08952565491199493 average time 0.013966564441226879 iter num 340\n",
            "loss 0.0841265618801117 average time 0.013405052925039247 iter num 360\n",
            "loss 0.15080299973487854 average time 0.012888899897437736 iter num 380\n",
            "loss 0.0973024070262909 average time 0.012432404580049478 iter num 400\n",
            "loss 0.1036476343870163 average time 0.012032088147645396 iter num 420\n",
            "loss 0.09848317503929138 average time 0.011659628036398896 iter num 440\n",
            "loss 0.11271166801452637 average time 0.01132347713263026 iter num 460\n",
            "loss 0.07356080412864685 average time 0.011019917275022332 iter num 480\n",
            "loss 0.0679781585931778 average time 0.010734378068023943 iter num 500\n",
            "loss 0.1287323236465454 average time 0.1741553212501458 iter num 20\n",
            "loss 1.0201506614685059 average time 0.08906182787504804 iter num 40\n",
            "loss 0.35354989767074585 average time 0.060606393466756954 iter num 60\n",
            "loss 0.22405844926834106 average time 0.046374809237477166 iter num 80\n",
            "loss 0.8360913991928101 average time 0.037843948799927606 iter num 100\n",
            "loss 0.6378198862075806 average time 0.03215076887502922 iter num 120\n",
            "loss 0.4874551594257355 average time 0.028089543192904135 iter num 140\n",
            "loss 1.0842640399932861 average time 0.0250325147375861 iter num 160\n",
            "loss 0.3685757517814636 average time 0.02266032963895365 iter num 180\n",
            "loss 0.21862564980983734 average time 0.020771001200046157 iter num 200\n",
            "loss 0.3444221615791321 average time 0.019240702036387863 iter num 220\n",
            "loss 0.2081015557050705 average time 0.017943894820837157 iter num 240\n",
            "loss 0.3267892599105835 average time 0.016848352496135005 iter num 260\n",
            "loss 0.17938470840454102 average time 0.015920726885724434 iter num 280\n",
            "loss 0.08861033618450165 average time 0.015104913940012921 iter num 300\n",
            "loss 0.09273426234722137 average time 0.014397461021837898 iter num 320\n",
            "loss 0.07143624126911163 average time 0.01377151379996683 iter num 340\n",
            "loss 0.16355633735656738 average time 0.013217442099984409 iter num 360\n",
            "loss 0.07800064235925674 average time 0.012728173797356584 iter num 380\n",
            "loss 0.16459259390830994 average time 0.012278269219978028 iter num 400\n",
            "loss 0.10574129968881607 average time 0.011873780083277823 iter num 420\n",
            "loss 0.11020120233297348 average time 0.011505310611292688 iter num 440\n",
            "loss 0.13325481116771698 average time 0.011169831184736762 iter num 460\n",
            "loss 0.07786916196346283 average time 0.010859447477029487 iter num 480\n",
            "loss 0.10469013452529907 average time 0.010572601889936778 iter num 500\n",
            "loss 0.1981499195098877 average time 0.17600867379987903 iter num 20\n",
            "loss 0.40216493606567383 average time 0.08987313749985333 iter num 40\n",
            "loss 0.24396876990795135 average time 0.061155401166615775 iter num 60\n",
            "loss 0.2360750138759613 average time 0.0469121381124296 iter num 80\n",
            "loss 0.22300094366073608 average time 0.03827572133999638 iter num 100\n",
            "loss 0.24180153012275696 average time 0.03251019231668882 iter num 120\n",
            "loss 0.12769946455955505 average time 0.028441429800061868 iter num 140\n",
            "loss 0.23307137191295624 average time 0.02537887713131113 iter num 160\n",
            "loss 0.6931964159011841 average time 0.022985818316738005 iter num 180\n",
            "loss 0.15121768414974213 average time 0.02106096259505648 iter num 200\n",
            "loss 0.13292354345321655 average time 0.019500117440938165 iter num 220\n",
            "loss 0.09176156669855118 average time 0.01817780692085762 iter num 240\n",
            "loss 0.14790552854537964 average time 0.01707600411925971 iter num 260\n",
            "loss 0.17601773142814636 average time 0.016114734539288682 iter num 280\n",
            "loss 0.12240943312644958 average time 0.015283421323365473 iter num 300\n",
            "loss 0.10063520073890686 average time 0.014563308225012861 iter num 320\n",
            "loss 0.06749466061592102 average time 0.013942045488275814 iter num 340\n",
            "loss 0.138153538107872 average time 0.013382497938902007 iter num 360\n",
            "loss 0.18051831424236298 average time 0.01287195258158279 iter num 380\n",
            "loss 0.15289416909217834 average time 0.012411992027491579 iter num 400\n",
            "loss 0.10079190135002136 average time 0.012008794090494728 iter num 420\n",
            "loss 0.06748919188976288 average time 0.011633255615908472 iter num 440\n",
            "loss 0.142721027135849 average time 0.011287725467422127 iter num 460\n",
            "loss 0.09466154873371124 average time 0.01098018468336098 iter num 480\n",
            "loss 0.07393687218427658 average time 0.010689526342030149 iter num 500\n",
            "loss 0.20454801619052887 average time 0.1774546056500185 iter num 20\n",
            "loss 0.2827114164829254 average time 0.09062039967520832 iter num 40\n",
            "loss 0.22496765851974487 average time 0.06164354429996213 iter num 60\n",
            "loss 0.5456753373146057 average time 0.04716888892498901 iter num 80\n",
            "loss 0.6255674362182617 average time 0.038502542089954656 iter num 100\n",
            "loss 0.7727372646331787 average time 0.03270495277489924 iter num 120\n",
            "loss 0.402424693107605 average time 0.0285913423927663 iter num 140\n",
            "loss 0.12563098967075348 average time 0.0255038409124154 iter num 160\n",
            "loss 0.2792271375656128 average time 0.023091974866555474 iter num 180\n",
            "loss 0.3358924388885498 average time 0.02118181732987068 iter num 200\n",
            "loss 0.16288864612579346 average time 0.01960149234987925 iter num 220\n",
            "loss 0.10957546532154083 average time 0.018288694495777236 iter num 240\n",
            "loss 0.1836351901292801 average time 0.017174985284509604 iter num 260\n",
            "loss 0.12807850539684296 average time 0.016217700092758084 iter num 280\n",
            "loss 0.19869165122509003 average time 0.015403515106566677 iter num 300\n",
            "loss 0.08132734894752502 average time 0.014687965162374894 iter num 320\n",
            "loss 0.16372503340244293 average time 0.014049695926330649 iter num 340\n",
            "loss 0.10709717124700546 average time 0.013485690019317391 iter num 360\n",
            "loss 0.16883179545402527 average time 0.012983326981453788 iter num 380\n",
            "loss 0.06110210716724396 average time 0.012525996067388405 iter num 400\n",
            "loss 0.10115168988704681 average time 0.012115751283237755 iter num 420\n",
            "loss 0.1056690439581871 average time 0.011746067402178926 iter num 440\n",
            "loss 0.09387698769569397 average time 0.011429383173835168 iter num 460\n",
            "loss 0.07829470932483673 average time 0.011110871304087293 iter num 480\n",
            "loss 0.09659066051244736 average time 0.010816349219930998 iter num 500\n",
            "loss 0.48978596925735474 average time 0.17747238660049333 iter num 20\n",
            "loss 0.21057580411434174 average time 0.09060730787523426 iter num 40\n",
            "loss 0.15448442101478577 average time 0.061689124416746684 iter num 60\n",
            "loss 0.18931716680526733 average time 0.047222731550209576 iter num 80\n",
            "loss 0.2832741439342499 average time 0.03854299302020081 iter num 100\n",
            "loss 0.18086329102516174 average time 0.03274789364189322 iter num 120\n",
            "loss 0.2894671559333801 average time 0.028603490578695656 iter num 140\n",
            "loss 0.15914785861968994 average time 0.025518172725173826 iter num 160\n",
            "loss 0.8465855717658997 average time 0.02310657731124795 iter num 180\n",
            "loss 0.3564441204071045 average time 0.021189557990146567 iter num 200\n",
            "loss 0.18194206058979034 average time 0.019637375013751974 iter num 220\n",
            "loss 0.10841347277164459 average time 0.01832576539592689 iter num 240\n",
            "loss 0.11356975883245468 average time 0.017222810692398456 iter num 260\n",
            "loss 0.1607482135295868 average time 0.01626639443575186 iter num 280\n",
            "loss 0.21333163976669312 average time 0.015433479366680937 iter num 300\n",
            "loss 0.12677457928657532 average time 0.014706512406257843 iter num 320\n",
            "loss 0.10468202829360962 average time 0.014064168855913843 iter num 340\n",
            "loss 0.1265660971403122 average time 0.013499835983374295 iter num 360\n",
            "loss 0.10043399035930634 average time 0.012986660236894845 iter num 380\n",
            "loss 0.15960931777954102 average time 0.012530246112573877 iter num 400\n",
            "loss 0.15770800411701202 average time 0.012113480595300125 iter num 420\n",
            "loss 0.17784491181373596 average time 0.01173735812734032 iter num 440\n",
            "loss 0.06323347985744476 average time 0.011390538823964206 iter num 460\n",
            "loss 0.14470352232456207 average time 0.011069043106302464 iter num 480\n",
            "loss 0.10130879282951355 average time 0.01078754023405054 iter num 500\n",
            "loss 0.23482903838157654 average time 0.17489335500013112 iter num 20\n",
            "loss 0.15972162783145905 average time 0.08945849994988748 iter num 40\n",
            "loss 0.24795499444007874 average time 0.060921471783452336 iter num 60\n",
            "loss 0.2407553493976593 average time 0.04666542672507603 iter num 80\n",
            "loss 0.2739933133125305 average time 0.038101405990018974 iter num 100\n",
            "loss 0.18329641222953796 average time 0.032377698883343936 iter num 120\n",
            "loss 0.406634122133255 average time 0.028295741107155794 iter num 140\n",
            "loss 0.6992597579956055 average time 0.025248821656282415 iter num 160\n",
            "loss 0.6602075099945068 average time 0.022863910344454376 iter num 180\n",
            "loss 0.8111266493797302 average time 0.02095767816999796 iter num 200\n",
            "loss 0.12419252097606659 average time 0.01940388864092132 iter num 220\n",
            "loss 0.2350042462348938 average time 0.01810786854998696 iter num 240\n",
            "loss 0.15448583662509918 average time 0.017012264726900657 iter num 260\n",
            "loss 0.10791853070259094 average time 0.01607458972499184 iter num 280\n",
            "loss 0.23507124185562134 average time 0.015255717290007548 iter num 300\n",
            "loss 0.1042841225862503 average time 0.014539851993788488 iter num 320\n",
            "loss 0.06110144034028053 average time 0.013906724608846965 iter num 340\n",
            "loss 0.12063386291265488 average time 0.013344040450000547 iter num 360\n",
            "loss 0.10878188163042068 average time 0.012848437397358218 iter num 380\n",
            "loss 0.15818309783935547 average time 0.012394150894988343 iter num 400\n",
            "loss 0.07860557734966278 average time 0.012004940964271512 iter num 420\n",
            "loss 0.08348596096038818 average time 0.011635778406815173 iter num 440\n",
            "loss 0.1565161645412445 average time 0.011312194176065058 iter num 460\n",
            "loss 0.17814889550209045 average time 0.011003674245800236 iter num 480\n",
            "loss 0.11828194558620453 average time 0.010724694143980742 iter num 500\n",
            "loss 0.21532636880874634 average time 0.17718224459986232 iter num 20\n",
            "loss 0.4232141971588135 average time 0.0906236877248375 iter num 40\n",
            "loss 0.6803619861602783 average time 0.061696293949717075 iter num 60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Engine run is terminating due to exception: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-8f5de1d1c751>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mmodel_save_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'checkpoint9.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    742\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    745\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    799\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    802\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                 \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m                 \u001b[0mrandoms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_PATHS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_PATHS\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb1_r\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_PATHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m                 \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehmhDw8BUtLi"
      },
      "source": [
        "### Inference and Greeks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uiro43mOU0Ro"
      },
      "source": [
        "We can load the model parameters and use it to do inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svlu6tGTRx1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac881507-0a03-464a-f0bc-7ba424d55563"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[110.0, 0.0, 110.0, 0.35, 0.1, 0.05]*3]).cuda()\n",
        "model(inputs.float())"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10.7121]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1Iy-9pWVRDO"
      },
      "source": [
        "One of the benefits of building a deep learning model is that the [Greeks](<https://en.wikipedia.org/wiki/Greeks_(finance)#First-order_Greeks>) can be easily computed. \n",
        "We just need to take advantage of the auto-grad feature in Pytorch. We can use `grad` function to compute the first order differentiation for parameters 'K, B, S0, sigma, mu, r'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytBZaYHKSnDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "296ee027-a2ab-4aa3-b050-0bae2dff2650"
      },
      "source": [
        "inputs = torch.tensor([[110.0, 0.0, 110.0, 0.35, 0.1, 0.05]*3]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ -0.1527,  -7.3532,   0.2001,   7.1619,   8.7874, -16.5572,  -0.1754,\n",
              "         -27.3704,   0.1899,   7.7943,  11.3682,  -2.8901,  -0.1771,  29.7061,\n",
              "           0.2247,   8.1989,  12.2822,   7.0741]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KeijaDDVZGd"
      },
      "source": [
        "Here we are going to plot the Delta graph:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USh3qaADSYQp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "a9286f68-ceef-4132-d5c5-5a69411d5d88"
      },
      "source": [
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[110.0, 0.0, S, 0.35, 0.1, 0.05] + ([110.0, 0.0, 110.0, 0.35, 0.1, 0.05]*2)]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "prices = np.arange(10, 300, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7feb895bfed0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLO_5nEGVcEc"
      },
      "source": [
        "Calculating the second order derivative is easy in PyTorch too. We just need to apply the `grad` function twice. Use this mechanism, we can calculate the second order derivatives $\\frac{\\partial^2 P}{\\partial K \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial B \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial S_0^2}$, $\\frac{\\partial^2 P}{\\partial \\sigma \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial \\mu \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial r \\partial S_0}$ in the following example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGzj7A3sThZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fea8c55e-d7c5-475e-b061-4cc53d6b369a"
      },
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import grad\n",
        "from torch import nn\n",
        "\n",
        "inputs = torch.tensor([[110.0, 0.0, 110.0, 0.35, 0.1, 0.05]*3]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs)\n",
        "\n",
        "# instead of using loss.backward(), use torch.autograd.grad() to compute gradients\n",
        "# https://pytorch.org/docs/stable/autograd.html#torch.autograd.grad\n",
        "loss_grads = grad(x, inputs, create_graph=True)\n",
        "drv = grad(loss_grads[0][0][2], inputs)\n",
        "drv"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-1.4180e-03, -2.0633e-01,  4.0882e-03, -1.0803e-01,  3.5117e-01,\n",
              "          -3.2388e-01, -1.4516e-03, -3.2864e-01,  2.3022e-04,  6.0619e-03,\n",
              "           3.8800e-02,  7.9051e-02, -1.4529e-03,  4.3756e-01,  7.8982e-05,\n",
              "           9.8479e-03,  3.1283e-03,  8.0015e-03]], device='cuda:0'),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJbZYtvhVmSo"
      },
      "source": [
        "Gamma is the second order differenation of `S`. We can plot the the Gamma curve as a function of the stock price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JpQa3EJToA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "05d62e7e-7f9b-4c28-9c3e-4b869983caa6"
      },
      "source": [
        "import pylab\n",
        "import numpy as np\n",
        "def compute_gamma(S):\n",
        "    inputs = torch.tensor([[110.0, 0.0, S, 0.35, 0.1, 0.05] + ([110.0, 0.0, 110.0, 0.35, 0.1, 0.05]*2)]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    loss_grads = grad(x, inputs, create_graph=True)\n",
        "    drv = grad(loss_grads[0][0][2], inputs)\n",
        "    return drv[0][0][2]\n",
        "\n",
        "prices = np.arange(10, 250, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_gamma(p).item())\n",
        "fig2 = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Gamma')\n",
        "fig2"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7feb89731dd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj7NlW6GVqSA"
      },
      "source": [
        "[Implied volatility](https://en.wikipedia.org/wiki/Implied_volatility) is the forecasted volatility of the underlying asset based on the quoted prices of the option. It is the reverse mapping of price to the option parameter given the model which is hard to do with the Monte Carlo simulation approach. But if we have the deep learning pricing model, it is an easy task. We can first plot the relationship between volatility and the option price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yrCw5UNT07t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "5642d24a-6324-4ae2-89f4-1545353d85c1"
      },
      "source": [
        "import pylab\n",
        "import numpy as np\n",
        "def compute_price(sigma):\n",
        "    inputs = torch.tensor([[110.0, 0.0, 110.0, sigma, 0.1, 0.05] + ([110.0, 0.0, 110.0, 0.35, 0.1, 0.05]*2)]).cuda()\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    return x.item()\n",
        "sigmas = np.arange(0, 0.5, 0.1)\n",
        "prices = []\n",
        "for s in sigmas:\n",
        "    prices.append(compute_price(s))\n",
        "fig3 = pylab.plot(sigmas, prices)\n",
        "pylab.xlabel('Sigma')\n",
        "pylab.ylabel('Price')\n",
        "fig3"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7feb895b9490>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU25Cj29VtCa"
      },
      "source": [
        "Given the prices `P`, the implied volatility is the root of the function `compute_price`. We can use bisection to find the root."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddHnwm_zUBYD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "3b564d6a-8e79-48a5-d27e-80d7550f8e72"
      },
      "source": [
        "def bisection_root(small, large, fun, target, EPS=1e-6):\n",
        "    if fun(large) - target < 0:\n",
        "        print('upper bound is too small')\n",
        "        return None\n",
        "    if fun(small) - target > 0:\n",
        "        print('lower bound is too large')\n",
        "        return None\n",
        "    while large - small > EPS:\n",
        "        mid = (large + small) / 2.0\n",
        "        if fun(mid) - target >= 0:\n",
        "            large = mid\n",
        "        else:\n",
        "            small = mid\n",
        "    mid = (large + small) / 2.0\n",
        "    return mid, abs(fun(mid) - target)\n",
        "quoted_price = 16.0\n",
        "sigma, err = bisection_root(0, 0.5, compute_price, quoted_price)\n",
        "print('implied volativity', sigma, 'error', err)     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "upper bound is too small\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ade689496c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mquoted_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbisection_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoted_price\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'implied volativity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    }
  ]
}