{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Combined.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NwN6aLFDnwiy",
        "dBOv_RiBsCWa",
        "u2_89jOknwjH"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Judy/From%20Colab/Combined3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCR6hhw5Xq_R"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSxOZk3ls2XQ",
        "outputId": "5bf53f9c-4303-4856-af46-9a48edfe2e46"
      },
      "source": [
        "!curl https://colab.chainer.org/install |sh -\n",
        "import cupy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1580  100  1580    0     0  18160      0 --:--:-- --:--:-- --:--:-- 18160\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "\u001b[K     |████████████████████████████████| 58.9MB 51kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 34.3MB/s \n",
            "\u001b[?25h  Building wheel for chainer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "+ set +ex\n",
            "Installation succeeded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwN6aLFDnwiy"
      },
      "source": [
        "### Deep Learning Barrier Option\n",
        "\n",
        "We used Numba and CuPy in the previous notebook to run Monte Carlo simulation to determine the price of the Asian Barrier option. A Monte Carlo simulation needs millions of paths to get an accurate answer which is computationally intensive. [Ryan et al (2018)](https://arxiv.org/abs/1809.02233) showed that a deep learning model can be trained to value derivatives. The deep learning model is accurate and very fast, capable of producing valuations a million times faster than traditional models. In the this notebook, we will use a fully connected network to learn the pricing mode of the Asian Barrier option. Monte Carlo simulation is used as pricing ground truth for the training. We use the same Asian Barrier Option model as last notebook with parameters listed as following:\n",
        "\n",
        "```\n",
        "T - Maturity (yrs.)\n",
        "S - Spot (usd)\n",
        "K - Strike (usd)\n",
        "sigma - Volatility (per.)\n",
        "r - Risk Free Rate (per.)\n",
        "mu - Stock Drift Rate (per.)\n",
        "B - Barrier (usd)\n",
        "```\n",
        "\n",
        "### Batched Data generation\n",
        "\n",
        "The dataset is an important part of the Deep learning training. We will modify the previous single Asian Barrier Option pricing code to handle a batch of Barrier Option pricing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHYrh4iYfP-n",
        "outputId": "a0fc307f-bdb2-4302-c35b-afa0194d1c98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "N_STOCKS = 3\n",
        "X = cupy.random.rand(6 * N_STOCKS, dtype=cupy.float32)\n",
        "X"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9685302 , 0.01461156, 0.55097145, 0.71100914, 0.9359948 ,\n",
              "       0.64643526, 0.64802086, 0.3808537 , 0.28333536, 0.301618  ,\n",
              "       0.883602  , 0.4220532 , 0.789352  , 0.36992654, 0.18029445,\n",
              "       0.9048682 , 0.66439694, 0.49702853], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy7qGwT0jv4A",
        "outputId": "a225af8a-0917-41b0-9e0e-8ff37451ea1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "J = cupy.array([])\n",
        "#cupy.concatenate((cupy.array([1,1]), cupy.random.rand(3),cupy.array([1]),J))\n",
        "for i in range(0,N_STOCKS):\n",
        "  J =  cupy.concatenate((J,cupy.array([1,1]), cupy.random.rand(3),cupy.array([1])))\n",
        "J = J.reshape(N_STOCKS,6)\n",
        "J"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 1.        , 0.9798443 , 0.4155168 , 0.21913677,\n",
              "        1.        ],\n",
              "       [1.        , 1.        , 0.00117758, 0.74957022, 0.59564547,\n",
              "        1.        ],\n",
              "       [1.        , 1.        , 0.99648469, 0.92795319, 0.38051146,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OHtAXC8hVae",
        "outputId": "997c0885-4e5a-406a-f090-5abeddcf335c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "J = J * ((cupy.array([200.0, 0, 200.0, 0.4, 0.2, 0.2] * N_STOCKS, dtype = cupy.float32)).reshape(N_STOCKS, 6))\n",
        "J"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.00000000e+02, 0.00000000e+00, 1.95968859e+02, 1.66206722e-01,\n",
              "        4.38273540e-02, 2.00000003e-01],\n",
              "       [2.00000000e+02, 0.00000000e+00, 2.35516276e-01, 2.99828092e-01,\n",
              "        1.19129095e-01, 2.00000003e-01],\n",
              "       [2.00000000e+02, 0.00000000e+00, 1.99296939e+02, 3.71181280e-01,\n",
              "        7.61022937e-02, 2.00000003e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghk_bQ44oSTK",
        "outputId": "3158c439-e7b6-47f0-9944-69ddf43b3a03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "J"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.00000000e+04, 0.00000000e+00, 2.74365314e+04, 4.07887723e-02,\n",
              "        1.25221396e-02, 4.00000012e-02],\n",
              "       [4.00000000e+04, 0.00000000e+00, 1.93309376e+04, 8.57991447e-02,\n",
              "        3.99256784e-02, 4.00000012e-02],\n",
              "       [4.00000000e+04, 0.00000000e+00, 1.01327826e+04, 1.96253711e-02,\n",
              "        2.54342359e-02, 4.00000012e-02]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Orf3qBi8oQb4",
        "outputId": "335e0701-9147-4f5a-f98c-ee6310aac340",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(cupy.array([200.0, 0, 200.0, 0.4, 0.2, 0.2] * N_STOCKS, dtype = cupy.float32)).reshape(N_STOCKS, 6)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[200. ,   0. , 200. ,   0.4,   0.2,   0.2],\n",
              "       [200. ,   0. , 200. ,   0.4,   0.2,   0.2],\n",
              "       [200. ,   0. , 200. ,   0.4,   0.2,   0.2]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8jtkwqAh7rX",
        "outputId": "2c312f90-9d15-4a97-a057-845a30a9ffac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "a * J"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.00000000e+02, 0.00000000e+00, 1.37182657e+02, 1.01971929e-01,\n",
              "        6.26106973e-02, 2.00000003e-01],\n",
              "       [2.00000000e+02, 0.00000000e+00, 9.66546880e+01, 2.14497858e-01,\n",
              "        1.99628389e-01, 2.00000003e-01],\n",
              "       [2.00000000e+02, 0.00000000e+00, 5.06639131e+01, 4.90634271e-02,\n",
              "        1.27171178e-01, 2.00000003e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIthQw8YfTU1"
      },
      "source": [
        "[K,B,S0,sigma,mu,r]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY_9g3tbdLiY"
      },
      "source": [
        "# TEST_ERIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBxT9Eida-c_",
        "outputId": "39e00b57-f548-43c7-a2ce-8b1f673f5d37"
      },
      "source": [
        "################################# TEST ########################################\n",
        "%%writefile cupy_dataset.py\n",
        "\n",
        "import numba\n",
        "from numba import cuda\n",
        "import random\n",
        "import cupy\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "cupy.cuda.set_allocator(None)\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "@cuda.jit\n",
        "def batch_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_BATCH):\n",
        "    # ii - overall thread index\n",
        "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
        "    tmp3 = math.sqrt(T/N_STEPS)\n",
        "    for i in range(ii, N_PATHS * N_BATCH, stride):\n",
        "        batch_id = i // N_PATHS\n",
        "        path_id = i % N_PATHS\n",
        "        tmp1 = mu[batch_id]*T/N_STEPS\n",
        "        tmp2 = math.exp(-r[batch_id]*T)\n",
        "        running_average = 0.0\n",
        "        s_curr = S0[batch_id]\n",
        "        for n in range(N_STEPS):\n",
        "            s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH] # stock price\n",
        "            running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average) # average of the path\n",
        "            if i==0 and batch_id == 2:\n",
        "                print(s_curr)\n",
        "            if running_average <= B[batch_id]: # if reach barrier, drop out the path\n",
        "                break\n",
        "        payoff = running_average - K[batch_id] if running_average > K[batch_id] else 0\n",
        "        d_s[i] = tmp2 * payoff\n",
        "\n",
        "class NumbaOptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len=10, number_path = 1000, batch=2, threads=512, seed=15, stocks=3):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 365\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = np.float32(1.0)\n",
        "        self.output = cupy.zeros(self.N_STOCKS*self.N_PATHS, dtype=cupy.float32) \n",
        "        self.number_of_blocks = (self.N_PATHS * self.N_STOCKS - 1) // threads + 1\n",
        "        self.number_of_threads = threads\n",
        "        cupy.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num > self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros(self.N_BATCH, dtype=cupy.float32)\n",
        "        paras = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "        for op in range(self.N_BATCH):\n",
        "\n",
        "          X = cupy.array([])\n",
        "          for i in range(0,self.N_STOCKS):\n",
        "            X =  cupy.concatenate((X,cupy.array([1,1]), cupy.random.rand(3),cupy.array([1])))\n",
        "          X = X.reshape(self.N_STOCKS,6)\n",
        "\n",
        "          X = X * ((cupy.array([200.0, 0, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6))\n",
        "          #X = cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)\n",
        "          #X = 0.9 + cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)*0.1\n",
        "          # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "          #X = (X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6)\n",
        "\n",
        "          # make sure the Barrier is smaller than the Strike price\n",
        "          # X[:, 1] = X[:, 0] * X[:, 1]\n",
        "          for i in range(self.N_STOCKS):\n",
        "            paras[op,i*6:(i+1)*6] = X[i,:]\n",
        "\n",
        "          stocks_randoms_mean = cupy.zeros(self.N_STOCKS, dtype = cupy.float32)\n",
        "          rho = cupy.random.normal(0, 1, self.N_STOCKS, dtype = cupy.float32)\n",
        "\n",
        "          #stocks_randoms_cov = cupy.ones((self.N_STOCKS, self.N_STOCKS), dtype = cupy.float32)\n",
        "          #cupy.fill_diagonal(stocks_randoms_cov, rho)\n",
        "\n",
        "          #stocks_randoms_cov = (-0.99 + cupy.random.rand(self.N_STOCKS*self.N_STOCKS, dtype=cupy.float32)*2*0.99).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "          stocks_randoms_cov = cupy.array([0.5] * self.N_STOCKS*self.N_STOCKS, dtype = cupy.float32).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "          cupy.fill_diagonal(stocks_randoms_cov, 1)\n",
        "\n",
        "          num_of_randoms_each_stock = self.N_PATHS * self.N_STEPS\n",
        "          randoms_gpu = cupy.random.multivariate_normal(stocks_randoms_mean, stocks_randoms_cov,\n",
        "                                                        num_of_randoms_each_stock, dtype=cupy.float32)\n",
        "          b1_r = randoms_gpu[:,0]\n",
        "          b2_r = randoms_gpu[:,1]\n",
        "          randoms = cupy.zeros(self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "          interval = int((self.N_PATHS * self.N_STEPS * self.N_STOCKS) / self.N_PATHS)\n",
        "          for i in range(interval):\n",
        "            if i % 2 == 0:\n",
        "                ind = int(i/2)\n",
        "                randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b1_r[ind:(ind+self.N_PATHS)]\n",
        "            else:\n",
        "                ind = int(i//2)\n",
        "                randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b2_r[ind:(ind+self.N_PATHS)]\n",
        "\n",
        "          randoms = cupy.random.normal(0, 1, self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "          batch_barrier_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, self.T, X[:, 0], \n",
        "                                X[:, 1], X[:, 2], X[:, 3], X[:, 4], X[:, 5], randoms, self.N_STEPS, self.N_PATHS, self.N_STOCKS)\n",
        "          \n",
        "          o = self.output.reshape(self.N_STOCKS, self.N_PATHS)\n",
        "          Y[op] = o.mean(axis = 0).mean()\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(paras.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "\n",
        "# ds = NumbaOptionDataSet(10, number_path=100000, batch=3, seed=random.randint(0,100), stocks=5)\n",
        "# for i in ds:\n",
        "#     print(i[0])\n",
        "################################# TEST ########################################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting cupy_dataset.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2_89jOknwjH"
      },
      "source": [
        "### Model\n",
        "To map the option parameters to price, we use 6 layers of fully connected neural network with hidden dimension 512 as inspired by [this paper](https://arxiv.org/abs/1809.02233). Writing this DL price model into a file `model.py`:-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMHqzJycx8XH"
      },
      "source": [
        "### Modified Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTn7iJQryAIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "832679d4-138c-4198-c4b4-2c9bca7450db"
      },
      "source": [
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(60, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 1)\n",
        "        # self.register_buffer('norm',\n",
        "        #                      torch.tensor([200.0, 198.0, 200.0, 0.4, 0.2, 0.2,\n",
        "        #                                    200.0, 198.0, 200.0, 0.4, 0.2, 0.2,\n",
        "        #                                    200.0, 198.0, 200.0, 0.4, 0.2, 0.2])) # don't use numpy here - will give error later\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([200.0, 198.0, 200.0, 0.4, 0.2, 0.2]*10)) # don't use numpy here - will give error later\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing model.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSPRFqyznwjI"
      },
      "source": [
        "As we know the random parameters' scaling factors, the input parameters are first scaled back to a range of (0-1) by dividing them by (200.0, 198.0, 200.0, 0.4, 0.2, 0.2). Then they are projected 5 times to the hidden dimension of 512 after the `ELu` activation function. `ELu` is chosen because we need to compute the second order differentiation of the parameters. If use ReLu, the second order differentiation will always be zero. The last layer is a linear layer that maps the hidden dimension to the predicted option price. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM8J2liPnwjJ"
      },
      "source": [
        "For training, we use [Ignite](https://github.com/pytorch/ignite) which is a high-level library to train neural networks in PyTorch. We use `MSELoss` as the loss function, `Adam` as the optimizer and `CosineAnnealingScheduler` as the learning rate scheduler. The following code is feeding the random option data to the pricing model to train it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yACi4ge13_rd"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TyZT8_AH35M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fb753ac-a083-4738-aeea-0bd1aa0abbf6"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/c3/f472843797b5ccbb2f0e806a6927f52c7c9522bfcea8e7e881d39258368b/pytorch_ignite-0.4.5-py3-none-any.whl (221kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 25.1MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 29.2MB/s eta 0:00:01\r\u001b[K     |████▍                           | 30kB 34.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 40kB 35.8MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 51kB 34.5MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 61kB 34.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 71kB 34.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 81kB 32.2MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 92kB 33.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 102kB 34.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 112kB 34.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 122kB 34.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 133kB 34.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 143kB 34.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 153kB 34.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 163kB 34.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 174kB 34.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 184kB 34.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 194kB 34.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 204kB 34.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 215kB 34.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 34.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Ej82G8nwjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c453b249-ae64-4395-d40a-5fa91bd9ddc7"
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import NumbaOptionDataSet\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "# dataset = NumbaOptionDataSet(max_len=10000, number_path = 1024, batch=4800)\n",
        "dataset = NumbaOptionDataSet(max_len=100, number_path = 2048, batch=8, stocks=10)\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred[:,0], y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 100\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs=300)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss 79.44324493408203 average time 0.07722865029999895 iter num 100\n",
            "loss 68.36408996582031 average time 0.006558406179999565 iter num 100\n",
            "loss 94.816162109375 average time 0.00652295790999915 iter num 100\n",
            "loss 97.63288879394531 average time 0.006537781180001616 iter num 100\n",
            "loss 108.3715591430664 average time 0.006685236180002789 iter num 100\n",
            "loss 59.25494384765625 average time 0.006428280460007159 iter num 100\n",
            "loss 44.10157775878906 average time 0.006482841979997715 iter num 100\n",
            "loss 30.260089874267578 average time 0.0064975406000036175 iter num 100\n",
            "loss 40.38506317138672 average time 0.006531012689998192 iter num 100\n",
            "loss 39.134700775146484 average time 0.006516174819998355 iter num 100\n",
            "loss 32.539886474609375 average time 0.006463374950000684 iter num 100\n",
            "loss 94.96755981445312 average time 0.0065760922499998745 iter num 100\n",
            "loss 46.37235641479492 average time 0.006646164420008063 iter num 100\n",
            "loss 45.69060134887695 average time 0.006492551779997484 iter num 100\n",
            "loss 67.84097290039062 average time 0.006560731309998573 iter num 100\n",
            "loss 41.485801696777344 average time 0.006528050599998778 iter num 100\n",
            "loss 54.78816223144531 average time 0.006512258990001101 iter num 100\n",
            "loss 48.13533020019531 average time 0.00670180217000734 iter num 100\n",
            "loss 63.030452728271484 average time 0.006589774270005364 iter num 100\n",
            "loss 94.65559387207031 average time 0.006491491219998124 iter num 100\n",
            "loss 58.803497314453125 average time 0.006469522709995772 iter num 100\n",
            "loss 43.947654724121094 average time 0.006509462170006372 iter num 100\n",
            "loss 60.36643981933594 average time 0.006443219910001971 iter num 100\n",
            "loss 13.567159652709961 average time 0.006537264310004502 iter num 100\n",
            "loss 41.69667053222656 average time 0.006507517210002334 iter num 100\n",
            "loss 64.77500915527344 average time 0.0064885231800008115 iter num 100\n",
            "loss 35.94023132324219 average time 0.006516153279994797 iter num 100\n",
            "loss 115.07401275634766 average time 0.0064753225799984195 iter num 100\n",
            "loss 73.68865203857422 average time 0.006459950590004837 iter num 100\n",
            "loss 56.20675277709961 average time 0.006726818910015027 iter num 100\n",
            "loss 43.58281707763672 average time 0.006516455340004086 iter num 100\n",
            "loss 23.202123641967773 average time 0.006485172510006123 iter num 100\n",
            "loss 44.70256042480469 average time 0.0065232632000038395 iter num 100\n",
            "loss 10.84716796875 average time 0.006510243339989757 iter num 100\n",
            "loss 33.592918395996094 average time 0.00661340862000543 iter num 100\n",
            "loss 35.624019622802734 average time 0.006759376959998917 iter num 100\n",
            "loss 63.86769485473633 average time 0.0067392691200006995 iter num 100\n",
            "loss 20.532106399536133 average time 0.0065277209500004575 iter num 100\n",
            "loss 40.033729553222656 average time 0.006565767920012604 iter num 100\n",
            "loss 47.304115295410156 average time 0.006551922480002759 iter num 100\n",
            "loss 78.96353912353516 average time 0.006413393710006403 iter num 100\n",
            "loss 54.79295349121094 average time 0.006479127019997577 iter num 100\n",
            "loss 60.349674224853516 average time 0.006587760380000418 iter num 100\n",
            "loss 95.54339599609375 average time 0.0064428621700039915 iter num 100\n",
            "loss 48.895301818847656 average time 0.006507045930009099 iter num 100\n",
            "loss 7.277798652648926 average time 0.006361115590002555 iter num 100\n",
            "loss 19.34603500366211 average time 0.0064561481500004445 iter num 100\n",
            "loss 17.32828712463379 average time 0.006648312340016674 iter num 100\n",
            "loss 35.371299743652344 average time 0.00655263080001987 iter num 100\n",
            "loss 25.198495864868164 average time 0.0064508463199967996 iter num 100\n",
            "loss 45.02593994140625 average time 0.006420773740005643 iter num 100\n",
            "loss 54.439815521240234 average time 0.006422573129980264 iter num 100\n",
            "loss 11.990262031555176 average time 0.006384280079996643 iter num 100\n",
            "loss 56.07917022705078 average time 0.006382239759991535 iter num 100\n",
            "loss 42.822914123535156 average time 0.006505802339986531 iter num 100\n",
            "loss 52.68212127685547 average time 0.00653808812999614 iter num 100\n",
            "loss 13.9278564453125 average time 0.006416977969990967 iter num 100\n",
            "loss 83.91085052490234 average time 0.0065488247499911265 iter num 100\n",
            "loss 56.40644454956055 average time 0.006442472260005161 iter num 100\n",
            "loss 24.827938079833984 average time 0.006427473640001153 iter num 100\n",
            "loss 17.39632225036621 average time 0.00649803553001675 iter num 100\n",
            "loss 33.95979309082031 average time 0.00645227732000194 iter num 100\n",
            "loss 30.788957595825195 average time 0.006531284820002838 iter num 100\n",
            "loss 17.750764846801758 average time 0.006440002759993604 iter num 100\n",
            "loss 11.65474796295166 average time 0.006454021980009657 iter num 100\n",
            "loss 73.03752136230469 average time 0.006464152459980142 iter num 100\n",
            "loss 21.219446182250977 average time 0.006415281059994413 iter num 100\n",
            "loss 39.34074401855469 average time 0.006635406640007204 iter num 100\n",
            "loss 42.741798400878906 average time 0.006502740430014455 iter num 100\n",
            "loss 48.28438949584961 average time 0.00643513081997753 iter num 100\n",
            "loss 19.565479278564453 average time 0.0063986593600157 iter num 100\n",
            "loss 73.2364501953125 average time 0.006490320520042587 iter num 100\n",
            "loss 66.70870208740234 average time 0.00671532947997548 iter num 100\n",
            "loss 44.48828887939453 average time 0.006701018179992389 iter num 100\n",
            "loss 30.32391357421875 average time 0.006529594470011943 iter num 100\n",
            "loss 44.173439025878906 average time 0.006600251609988846 iter num 100\n",
            "loss 16.69168472290039 average time 0.006645894859998407 iter num 100\n",
            "loss 16.29865074157715 average time 0.006594592560009005 iter num 100\n",
            "loss 62.21220397949219 average time 0.0066085724999993545 iter num 100\n",
            "loss 47.334102630615234 average time 0.006610185909989923 iter num 100\n",
            "loss 37.42082214355469 average time 0.006482514789995548 iter num 100\n",
            "loss 21.983444213867188 average time 0.00653117983998527 iter num 100\n",
            "loss 26.711069107055664 average time 0.006452602780027519 iter num 100\n",
            "loss 88.87283325195312 average time 0.0065298742900631625 iter num 100\n",
            "loss 21.88137435913086 average time 0.006561515640009929 iter num 100\n",
            "loss 29.547428131103516 average time 0.006418445549988974 iter num 100\n",
            "loss 51.21527862548828 average time 0.0064177952099907995 iter num 100\n",
            "loss 67.72867584228516 average time 0.006469944000032229 iter num 100\n",
            "loss 43.846656799316406 average time 0.006517051330001777 iter num 100\n",
            "loss 74.7581558227539 average time 0.006609557530023267 iter num 100\n",
            "loss 14.750093460083008 average time 0.006458906450011455 iter num 100\n",
            "loss 35.97574234008789 average time 0.006453844699958609 iter num 100\n",
            "loss 46.594417572021484 average time 0.006704741340008695 iter num 100\n",
            "loss 23.079429626464844 average time 0.006486437469989142 iter num 100\n",
            "loss 31.08470916748047 average time 0.006430929690009179 iter num 100\n",
            "loss 50.37101364135742 average time 0.0064614251700049865 iter num 100\n",
            "loss 35.4625358581543 average time 0.006515471870006877 iter num 100\n",
            "loss 26.459590911865234 average time 0.006414743100003761 iter num 100\n",
            "loss 49.52349090576172 average time 0.006550778499972694 iter num 100\n",
            "loss 58.890594482421875 average time 0.006441185350017804 iter num 100\n",
            "loss 29.363887786865234 average time 0.006448267239966299 iter num 100\n",
            "loss 42.39134979248047 average time 0.006428405019996717 iter num 100\n",
            "loss 51.602638244628906 average time 0.006418335580015082 iter num 100\n",
            "loss 33.34104919433594 average time 0.006452729659981742 iter num 100\n",
            "loss 57.24740219116211 average time 0.006596589770028913 iter num 100\n",
            "loss 25.00912094116211 average time 0.006441547179997542 iter num 100\n",
            "loss 49.825157165527344 average time 0.00644694043000527 iter num 100\n",
            "loss 38.7520751953125 average time 0.006521630080014802 iter num 100\n",
            "loss 45.9880256652832 average time 0.006511985060014922 iter num 100\n",
            "loss 50.570411682128906 average time 0.006368201609989228 iter num 100\n",
            "loss 14.907857894897461 average time 0.0064503186299953085 iter num 100\n",
            "loss 42.44788360595703 average time 0.006410425779990874 iter num 100\n",
            "loss 41.432594299316406 average time 0.006689818120016753 iter num 100\n",
            "loss 16.752605438232422 average time 0.006516275589970064 iter num 100\n",
            "loss 42.06782531738281 average time 0.006493019780018585 iter num 100\n",
            "loss 11.794472694396973 average time 0.006460692830009975 iter num 100\n",
            "loss 26.264976501464844 average time 0.006641997640008413 iter num 100\n",
            "loss 27.13064193725586 average time 0.006470215429994823 iter num 100\n",
            "loss 80.28052520751953 average time 0.006544317450034214 iter num 100\n",
            "loss 36.48028564453125 average time 0.006455350369997177 iter num 100\n",
            "loss 39.7382698059082 average time 0.006485047180017318 iter num 100\n",
            "loss 40.058746337890625 average time 0.006461190229993008 iter num 100\n",
            "loss 67.16803741455078 average time 0.006423977290005496 iter num 100\n",
            "loss 74.76616668701172 average time 0.006427559900007509 iter num 100\n",
            "loss 39.853668212890625 average time 0.006416450410010838 iter num 100\n",
            "loss 42.21759033203125 average time 0.006434611729978315 iter num 100\n",
            "loss 40.20289993286133 average time 0.00648879028999545 iter num 100\n",
            "loss 61.14690399169922 average time 0.006361050069990597 iter num 100\n",
            "loss 40.18036651611328 average time 0.006386434310011282 iter num 100\n",
            "loss 55.74091339111328 average time 0.006643464339990714 iter num 100\n",
            "loss 41.139835357666016 average time 0.006438614099988626 iter num 100\n",
            "loss 37.08229064941406 average time 0.006454855549982312 iter num 100\n",
            "loss 46.033546447753906 average time 0.00651615266997851 iter num 100\n",
            "loss 55.72499084472656 average time 0.006411198900009367 iter num 100\n",
            "loss 40.685123443603516 average time 0.0066327747000195815 iter num 100\n",
            "loss 63.0804443359375 average time 0.006629769219980517 iter num 100\n",
            "loss 33.90391540527344 average time 0.006440628069967715 iter num 100\n",
            "loss 47.76922607421875 average time 0.006566747799970471 iter num 100\n",
            "loss 32.12623977661133 average time 0.006490416549941074 iter num 100\n",
            "loss 16.01688003540039 average time 0.006453633749997607 iter num 100\n",
            "loss 33.776248931884766 average time 0.00650109803003943 iter num 100\n",
            "loss 64.01947021484375 average time 0.0064576380700509615 iter num 100\n",
            "loss 34.035987854003906 average time 0.0064874253600009976 iter num 100\n",
            "loss 32.093658447265625 average time 0.006460963600029572 iter num 100\n",
            "loss 23.22118377685547 average time 0.006413339440023265 iter num 100\n",
            "loss 34.61713409423828 average time 0.006536815899944486 iter num 100\n",
            "loss 68.23431396484375 average time 0.006386050209994209 iter num 100\n",
            "loss 39.56265640258789 average time 0.0064526412800751136 iter num 100\n",
            "loss 38.310420989990234 average time 0.006341516699976637 iter num 100\n",
            "loss 37.49517822265625 average time 0.006426613759986139 iter num 100\n",
            "loss 13.044151306152344 average time 0.006466437630006112 iter num 100\n",
            "loss 33.446868896484375 average time 0.00637863967001067 iter num 100\n",
            "loss 27.289073944091797 average time 0.00652947943001891 iter num 100\n",
            "loss 72.31143188476562 average time 0.006405652459980047 iter num 100\n",
            "loss 12.217801094055176 average time 0.006415221489996839 iter num 100\n",
            "loss 51.13599395751953 average time 0.006555809109986512 iter num 100\n",
            "loss 31.523805618286133 average time 0.006453125589960109 iter num 100\n",
            "loss 26.804424285888672 average time 0.006539610869958778 iter num 100\n",
            "loss 19.43638801574707 average time 0.006407097759984026 iter num 100\n",
            "loss 20.795146942138672 average time 0.006328392120030913 iter num 100\n",
            "loss 36.69601821899414 average time 0.00648925790001158 iter num 100\n",
            "loss 67.85687255859375 average time 0.0064002962499762365 iter num 100\n",
            "loss 55.695030212402344 average time 0.00639620196998294 iter num 100\n",
            "loss 33.75397491455078 average time 0.006633748020021812 iter num 100\n",
            "loss 64.92219543457031 average time 0.006755227550029303 iter num 100\n",
            "loss 57.238956451416016 average time 0.0066546449799716354 iter num 100\n",
            "loss 27.58831024169922 average time 0.006538770110037149 iter num 100\n",
            "loss 35.488155364990234 average time 0.0065586894899388425 iter num 100\n",
            "loss 8.725807189941406 average time 0.006566900030038596 iter num 100\n",
            "loss 26.22600555419922 average time 0.006488338139988627 iter num 100\n",
            "loss 20.813751220703125 average time 0.006554979029961033 iter num 100\n",
            "loss 34.798316955566406 average time 0.006655795469996519 iter num 100\n",
            "loss 62.49030303955078 average time 0.006660406679993684 iter num 100\n",
            "loss 31.622028350830078 average time 0.00651803357000972 iter num 100\n",
            "loss 45.7961311340332 average time 0.006545072310027536 iter num 100\n",
            "loss 39.83905029296875 average time 0.006433154960022875 iter num 100\n",
            "loss 63.31798553466797 average time 0.006365461360001063 iter num 100\n",
            "loss 40.292423248291016 average time 0.006534145729965531 iter num 100\n",
            "loss 42.42396545410156 average time 0.006519637950041215 iter num 100\n",
            "loss 39.49164962768555 average time 0.0064649211600317355 iter num 100\n",
            "loss 69.09497833251953 average time 0.006497596560020611 iter num 100\n",
            "loss 69.0347900390625 average time 0.006496818769928723 iter num 100\n",
            "loss 60.15951919555664 average time 0.006370719709984769 iter num 100\n",
            "loss 33.80366134643555 average time 0.0065119936999872155 iter num 100\n",
            "loss 21.130393981933594 average time 0.0064738579800632575 iter num 100\n",
            "loss 24.255828857421875 average time 0.006571444640030677 iter num 100\n",
            "loss 116.9615249633789 average time 0.00642183871999805 iter num 100\n",
            "loss 56.164093017578125 average time 0.006489834139947561 iter num 100\n",
            "loss 22.90816307067871 average time 0.0065416799399645245 iter num 100\n",
            "loss 103.04264068603516 average time 0.006635138550000193 iter num 100\n",
            "loss 34.41512680053711 average time 0.006761877130020366 iter num 100\n",
            "loss 65.3451156616211 average time 0.006681201079954917 iter num 100\n",
            "loss 53.15235900878906 average time 0.006616825390037775 iter num 100\n",
            "loss 36.93030548095703 average time 0.006607947060010702 iter num 100\n",
            "loss 86.0518798828125 average time 0.006658563840037459 iter num 100\n",
            "loss 52.14972686767578 average time 0.006736527170050977 iter num 100\n",
            "loss 30.02419662475586 average time 0.0067074884100293275 iter num 100\n",
            "loss 29.233760833740234 average time 0.006610900270006823 iter num 100\n",
            "loss 48.81584548950195 average time 0.0067341924199172355 iter num 100\n",
            "loss 47.64715576171875 average time 0.006614181319973795 iter num 100\n",
            "loss 78.27886199951172 average time 0.006833257829975991 iter num 100\n",
            "loss 54.510108947753906 average time 0.006456917079967752 iter num 100\n",
            "loss 50.77154541015625 average time 0.006537640469987309 iter num 100\n",
            "loss 29.477733612060547 average time 0.006455998760020521 iter num 100\n",
            "loss 64.88420104980469 average time 0.006471615519994884 iter num 100\n",
            "loss 23.239574432373047 average time 0.006473684129896355 iter num 100\n",
            "loss 26.12700653076172 average time 0.00640537993001999 iter num 100\n",
            "loss 43.726707458496094 average time 0.006444730829998662 iter num 100\n",
            "loss 44.885528564453125 average time 0.006491943309956696 iter num 100\n",
            "loss 60.46635055541992 average time 0.006347072139997181 iter num 100\n",
            "loss 19.343948364257812 average time 0.006426249809919682 iter num 100\n",
            "loss 81.00265502929688 average time 0.0064746285399633055 iter num 100\n",
            "loss 68.8709487915039 average time 0.006416887759978635 iter num 100\n",
            "loss 33.85111618041992 average time 0.006486013579997234 iter num 100\n",
            "loss 20.126121520996094 average time 0.006398237349958436 iter num 100\n",
            "loss 30.135419845581055 average time 0.006351836200001344 iter num 100\n",
            "loss 35.88037109375 average time 0.006544910119973792 iter num 100\n",
            "loss 13.628396034240723 average time 0.006452639299977818 iter num 100\n",
            "loss 28.630090713500977 average time 0.006423576580045847 iter num 100\n",
            "loss 31.799646377563477 average time 0.006423476050003956 iter num 100\n",
            "loss 56.035709381103516 average time 0.006397236120019443 iter num 100\n",
            "loss 51.73717498779297 average time 0.006425369499993394 iter num 100\n",
            "loss 53.04945373535156 average time 0.006537997810028173 iter num 100\n",
            "loss 48.15081024169922 average time 0.006620970779958952 iter num 100\n",
            "loss 14.164789199829102 average time 0.006492722999955731 iter num 100\n",
            "loss 83.94450378417969 average time 0.00643828471004781 iter num 100\n",
            "loss 64.85065460205078 average time 0.00640903106004771 iter num 100\n",
            "loss 73.1808090209961 average time 0.006477063060001456 iter num 100\n",
            "loss 12.577024459838867 average time 0.006424266840067503 iter num 100\n",
            "loss 34.481475830078125 average time 0.006364691060043697 iter num 100\n",
            "loss 20.705078125 average time 0.006436496779988374 iter num 100\n",
            "loss 31.564247131347656 average time 0.0064069175199256275 iter num 100\n",
            "loss 15.897733688354492 average time 0.006394378629966013 iter num 100\n",
            "loss 36.640647888183594 average time 0.00654533045003518 iter num 100\n",
            "loss 32.798744201660156 average time 0.006399772660015515 iter num 100\n",
            "loss 30.33246612548828 average time 0.006423052559985081 iter num 100\n",
            "loss 27.305418014526367 average time 0.006369381069953306 iter num 100\n",
            "loss 68.09739685058594 average time 0.006378916029934772 iter num 100\n",
            "loss 34.277584075927734 average time 0.00647750418992473 iter num 100\n",
            "loss 24.569541931152344 average time 0.0063469196599908176 iter num 100\n",
            "loss 8.278518676757812 average time 0.00634824789994127 iter num 100\n",
            "loss 53.01236343383789 average time 0.006429320680026649 iter num 100\n",
            "loss 63.98583984375 average time 0.0064362574899314495 iter num 100\n",
            "loss 29.24107551574707 average time 0.006362081519991989 iter num 100\n",
            "loss 50.13771057128906 average time 0.006457786490027501 iter num 100\n",
            "loss 52.54813003540039 average time 0.006416350280060215 iter num 100\n",
            "loss 68.2901611328125 average time 0.0064514835600311925 iter num 100\n",
            "loss 57.68349075317383 average time 0.006519581879956604 iter num 100\n",
            "loss 15.750364303588867 average time 0.006430554990038218 iter num 100\n",
            "loss 26.030317306518555 average time 0.00640083471993421 iter num 100\n",
            "loss 60.396575927734375 average time 0.006449999380029112 iter num 100\n",
            "loss 19.098386764526367 average time 0.006444920399981129 iter num 100\n",
            "loss 26.297500610351562 average time 0.0063695161799842024 iter num 100\n",
            "loss 88.36579895019531 average time 0.006426069129984171 iter num 100\n",
            "loss 24.46903419494629 average time 0.006597834789990884 iter num 100\n",
            "loss 26.113170623779297 average time 0.006431803580053384 iter num 100\n",
            "loss 5.514680862426758 average time 0.00643385889995443 iter num 100\n",
            "loss 34.575416564941406 average time 0.006390287209987946 iter num 100\n",
            "loss 50.48326873779297 average time 0.006467263749973426 iter num 100\n",
            "loss 30.85098648071289 average time 0.0071230226299940115 iter num 100\n",
            "loss 26.262908935546875 average time 0.0066747623900118925 iter num 100\n",
            "loss 26.513408660888672 average time 0.006548792450012116 iter num 100\n",
            "loss 27.671356201171875 average time 0.006525079800003369 iter num 100\n",
            "loss 78.57174682617188 average time 0.0066219968899440575 iter num 100\n",
            "loss 43.35520553588867 average time 0.006692576209979961 iter num 100\n",
            "loss 20.288206100463867 average time 0.006622584329998063 iter num 100\n",
            "loss 62.441123962402344 average time 0.006589320400053111 iter num 100\n",
            "loss 41.17009735107422 average time 0.0067671880200214215 iter num 100\n",
            "loss 13.89989948272705 average time 0.006560598359983487 iter num 100\n",
            "loss 25.860279083251953 average time 0.006585691569980554 iter num 100\n",
            "loss 33.518463134765625 average time 0.006790246449972983 iter num 100\n",
            "loss 26.819686889648438 average time 0.006627021340027568 iter num 100\n",
            "loss 64.35740661621094 average time 0.006635847649968127 iter num 100\n",
            "loss 40.5902099609375 average time 0.006562034089956797 iter num 100\n",
            "loss 12.45767879486084 average time 0.006482920009957525 iter num 100\n",
            "loss 11.570280075073242 average time 0.0064948173399807275 iter num 100\n",
            "loss 65.10977935791016 average time 0.006516128500024933 iter num 100\n",
            "loss 12.914436340332031 average time 0.006559584379956505 iter num 100\n",
            "loss 9.926033973693848 average time 0.00651868572001149 iter num 100\n",
            "loss 30.78120994567871 average time 0.006869150250131497 iter num 100\n",
            "loss 33.49898910522461 average time 0.006658410189993446 iter num 100\n",
            "loss 28.988126754760742 average time 0.006614666949990351 iter num 100\n",
            "loss 11.288084030151367 average time 0.00654650213997229 iter num 100\n",
            "loss 8.362785339355469 average time 0.006609510540019983 iter num 100\n",
            "loss 19.932353973388672 average time 0.0067602704298224126 iter num 100\n",
            "loss 31.30472183227539 average time 0.006638160530092137 iter num 100\n",
            "loss 8.866769790649414 average time 0.006500244540020504 iter num 100\n",
            "loss 43.76786422729492 average time 0.006617797169928963 iter num 100\n",
            "loss 21.871973037719727 average time 0.006739296980067593 iter num 100\n",
            "loss 9.463643074035645 average time 0.006483320109982742 iter num 100\n",
            "loss 18.085756301879883 average time 0.006537431810047564 iter num 100\n",
            "loss 13.571598052978516 average time 0.0065091047800160595 iter num 100\n",
            "loss 9.300313949584961 average time 0.0065751980499953785 iter num 100\n",
            "loss 10.219046592712402 average time 0.0065919192099681825 iter num 100\n",
            "loss 3.8661370277404785 average time 0.006496601799935889 iter num 100\n",
            "loss 7.4090728759765625 average time 0.0066882572699068985 iter num 100\n",
            "loss 7.734675407409668 average time 0.006628015560036147 iter num 100\n",
            "loss 4.266516208648682 average time 0.006663328769882355 iter num 100\n",
            "loss 7.009592056274414 average time 0.006647403110018785 iter num 100\n",
            "loss 12.1848726272583 average time 0.006599725590112939 iter num 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 30000\n",
              "\tepoch: 300\n",
              "\tepoch_length: 100\n",
              "\tmax_epochs: 300\n",
              "\toutput: 12.1848726272583\n",
              "\tbatch: <class 'tuple'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: <class 'cupy_dataset.NumbaOptionDataSet'>\n",
              "\tseed: <class 'NoneType'>\n",
              "\ttimes: <class 'dict'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU1EpGuInwjJ"
      },
      "source": [
        "The loss is keeping decreasing which means the pricing model can predict the option prices better. It takes about $12ms$ to compute one mini-batch in average, In the following sections, we will try to expore the full potentials of the GPU to accelerate the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehmhDw8BUtLi"
      },
      "source": [
        "### Inference and Greeks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uiro43mOU0Ro"
      },
      "source": [
        "We can load the model parameters and use it to do inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svlu6tGTRx1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66fa494d-d6a1-4369-b95a-73a5a58db47b"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05]*10]).cuda()\n",
        "model(inputs.float())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.9896]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1Iy-9pWVRDO"
      },
      "source": [
        "One of the benefits of building a deep learning model is that the [Greeks](<https://en.wikipedia.org/wiki/Greeks_(finance)#First-order_Greeks>) can be easily computed. \n",
        "We just need to take advantage of the auto-grad feature in Pytorch. We can use `grad` function to compute the first order differentiation for parameters 'K, B, S0, sigma, mu, r'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytBZaYHKSnDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6de141f-3795-41a2-8937-0b4d99f206a0"
      },
      "source": [
        "inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05]*10]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.6052e-02, -6.4308e-04,  2.5538e-02,  8.0677e-01,  2.5876e+00,\n",
              "         -1.7653e+00, -2.2743e-02, -2.2676e-03,  2.6036e-02,  4.2738e-01,\n",
              "          1.5023e+00,  7.3798e-02, -2.1319e-02, -9.4905e-03,  2.4557e-02,\n",
              "          7.9236e-01, -7.0950e-01, -3.4097e+00, -2.1604e-02, -1.3818e-02,\n",
              "          2.6768e-02,  3.3145e-01, -4.3951e-01, -2.5203e+00, -3.6301e-03,\n",
              "         -1.2115e-02,  5.6483e-03,  6.7862e-01,  2.4511e+00,  1.3348e+00,\n",
              "         -1.3669e-02, -4.5517e-03,  1.3568e-02,  1.0203e+00,  1.3144e+00,\n",
              "         -1.5501e+00, -1.1048e-02, -3.9607e-03,  1.5911e-02,  1.5457e+00,\n",
              "          6.1679e-01, -3.1586e-03, -2.6725e-02, -3.7096e-03,  3.0611e-02,\n",
              "          5.9456e-01,  1.3927e+00, -4.4443e+00, -9.6084e-03, -8.9692e-03,\n",
              "          1.5108e-02,  7.3334e-01,  3.2638e+00,  2.5660e-02, -2.9865e-02,\n",
              "         -1.6656e-02,  3.1346e-02,  1.8961e+00,  9.7401e-01, -1.5526e+00]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KeijaDDVZGd"
      },
      "source": [
        "Here we are going to plot the Delta graph:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USh3qaADSYQp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "6b30fd3c-8db4-4140-bcb1-4f22bca1f94d"
      },
      "source": [
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[110.0, 100.0, S, 0.35, 0.1, 0.05] + ([110.0, 100.0, 120.0, 0.35, 0.1, 0.05]*9)]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "prices = np.arange(10, 300, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f63c17ab190>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLO_5nEGVcEc"
      },
      "source": [
        "Calculating the second order derivative is easy in PyTorch too. We just need to apply the `grad` function twice. Use this mechanism, we can calculate the second order derivatives $\\frac{\\partial^2 P}{\\partial K \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial B \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial S_0^2}$, $\\frac{\\partial^2 P}{\\partial \\sigma \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial \\mu \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial r \\partial S_0}$ in the following example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGzj7A3sThZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4b2dc61-ea32-4723-9eda-48146e41fa6d"
      },
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import grad\n",
        "from torch import nn\n",
        "\n",
        "inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05]*10]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs)\n",
        "\n",
        "# instead of using loss.backward(), use torch.autograd.grad() to compute gradients\n",
        "# https://pytorch.org/docs/stable/autograd.html#torch.autograd.grad\n",
        "loss_grads = grad(x, inputs, create_graph=True)\n",
        "drv = grad(loss_grads[0][0][2], inputs)\n",
        "drv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-4.2155e-04,  1.8928e-05,  4.3383e-04,  1.9160e-03,  3.1185e-02,\n",
              "          -4.2699e-02, -2.8334e-05, -5.3102e-06,  2.7251e-05,  3.5252e-03,\n",
              "           5.2099e-03,  8.4961e-03, -5.2523e-05, -5.1632e-05,  5.2887e-05,\n",
              "           6.8761e-03, -1.2509e-03, -1.8901e-02, -1.4810e-05, -4.1013e-05,\n",
              "           3.1564e-05, -3.5778e-03, -4.4467e-03,  3.3437e-03, -3.3124e-05,\n",
              "          -6.2398e-05,  3.8438e-05,  2.4191e-03,  1.0250e-02,  8.0289e-03,\n",
              "          -3.5385e-05, -1.0523e-05,  1.6792e-05,  3.9085e-03, -3.8925e-03,\n",
              "          -4.1625e-03, -3.3123e-05, -3.7600e-05,  3.7231e-05,  2.2619e-03,\n",
              "           8.5746e-03, -1.9339e-03, -1.0539e-04, -2.4071e-05,  1.0590e-04,\n",
              "           3.3561e-03, -9.1576e-04, -1.9725e-02, -3.2639e-05, -2.4224e-05,\n",
              "           4.1162e-05,  5.0516e-05,  2.5105e-02, -1.4045e-03, -1.3165e-04,\n",
              "          -7.4675e-05,  1.3472e-04,  4.6619e-03,  4.0463e-03, -4.2377e-03]],\n",
              "        device='cuda:0'),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJbZYtvhVmSo"
      },
      "source": [
        "Gamma is the second order differenation of `S`. We can plot the the Gamma curve as a function of the stock price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JpQa3EJToA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "06e33506-7d71-4106-fa92-4fcb5d572463"
      },
      "source": [
        "import pylab\n",
        "import numpy as np\n",
        "def compute_gamma(S):\n",
        "    inputs = torch.tensor([[110.0, 100.0, S, 0.35, 0.1, 0.05] + ([110.0, 100.0, 120.0, 0.35, 0.1, 0.05]*9)]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    loss_grads = grad(x, inputs, create_graph=True)\n",
        "    drv = grad(loss_grads[0][0][2], inputs)\n",
        "    return drv[0][0][2]\n",
        "\n",
        "prices = np.arange(10, 250, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_gamma(p).item())\n",
        "fig2 = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Gamma')\n",
        "fig2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f63c173c6d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEGCAYAAABCa2PoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1dnA8d+TnS2EfYewBDDsEHEXiiIgVkRRUOurrdaWgr5a277Yt62+1rW2Wq1LSxVFqwWL1uJKRaiKgBCQLayRNayBQFhClsk87x9zE5OQDZg7N5l5vp9PPpk5c++Z5zAhT849554jqooxxhhztqK8DsAYY0x4sIRijDEmKCyhGGOMCQpLKMYYY4LCEooxxpigiPE6AC+1bNlSk5OTvQ7DGGPqlRUrVhxU1VYVyyM6oSQnJ5Oenu51GMYYU6+IyI7Kyu2SlzHGmKCwhGKMMSYoLKEYY4wJClcTioiMFpFNIpIpItMqeT1eRGY7r38lIsllXrvfKd8kIqNqqlNERojIShFZJyIzRSSix4eMMSbUXEsoIhINPA+MAVKBG0UktcJhtwOHVbUH8DTwhHNuKjAJ6AOMBl4Qkeiq6hSRKGAmMElV+wI7gFvdapsxxphTudlDGQpkqupWVS0EZgHjKhwzjkAiAJgDXCYi4pTPUtUCVd0GZDr1VVVnC6BQVTc7dX0CXOdi24wxxlTgZkLpAOwq8zzLKav0GFX1AbkEkkNV51ZVfhCIEZE0p3wC0KmyoETkThFJF5H07OzsM2iWMcaYyoTFoLwG1uCfBDwtIsuAY0BxFcdOV9U0VU1r1eqU+3KMMQaA3Lwi/pG+C9vio/bcHLjeTfleQkenrLJjspxB9KbAoRrOrbRcVZcAlwCIyBVAz6C0whgT1p5fmMklKS3p3zEJAFVlypsr+XDtPgDOaZdI3w5NvQyx3nCzh7IcSBGRriISR6AHMbfCMXP5dvB8ArDA6W3MBSY5s8C6AinAsurqFJHWzvd44H+AP7vYNmNMPaeqrN51hCfnbeLq574sLV+2Lac0mQBc9adFHD5R6EWI9Y5rPRRV9YnIVGAeEA3MUNUMEXkISFfVucDLwOsikgnkEEgQOMe9BawHfMAUVS0GqKxO5y1/LiJXEUiSL6rqArfaZoyp3/KLiun964/Lle04dIJG8TFMnL70lON/PmcNL92adkq5KU8i+fpgWlqa2lpexkSeO2amM3/D/lPKh/VsxWebs4mLieI/PxvO1DdXsnLnES4/pzX3juxJ5+YNaZIQ60HEdYuIrFDVUzJsWAzKG2NMbX2yfn9pMnnnJxfy9a9Hlr722ebAzM+/3DKE9kkNeHvyhVzasxXzNxxg7LOL6Pfgvz2Jub6whGKMiRhrs3L54WuBqxK/viqVwZ2b0axRHL3bNik95onr+vGdXq0BEBH6dUgsV8cf52/mkt8tIDevKHSB1xOWUIwxYe94gY/731nDd59bBEBCbBQ/uCi59PVHxvctfXzd4I7lzr1rREq553+cv4VdOSd56pNN7gVcT1lCMcaEvY/W7uXvy769J/qNO84nsChHwJAuzVlw3zC2Pz6WmOjyvxYTYqPZ/vhYurdqVK585pIddo9KBZZQjDFh7eDxAn4+Z03p81vO78LgzkmnHNetVeNq65n/02E8e+MgbhzaubTsHyuyghdoGLAVeY0xYetIXiFpD88HYHivVtx8XhdGprY5o7pEhKsHtOfqAe1ZvyeX1Vm5TP98KzekVbrKU0SyHooxJmx9sHZv6eMXbx5yxsmkopdvOxeAzAPHWbEjJyh1hgNLKMaYsPXxun10bt6QbY9dSYO46KDV27JxPD8dGVjdaW1WbtDqre8soRhjwtLm/cf4YstBvjugXbkB+GCZ8p0exEQJ2ccLgl53fWUJxRgTdlSVK57+HIAJQ9wZ44iOEto2TWDPkXxX6q+PLKEYY8LO+r1HSx93bdmomiPPTvukBuw+fNK1+usbSyjGmLDz2uIdAHw5bYSr79MhqQG7j1hCKWEJxRgTVg6fKGR2euAmxg5JDVx9r/ZJCew7mk+x325wBEsoxpgwsi83nx/9bQUAD43r4/r7dUhqSLFfeemLra6/V31gNzYaY+o1v185crKI3/97E29+tbO0/Jbzu7j+3kO6NAPgsY828qNh3V1/v7rOEooxpl4b+6dFbCgzCA/wu+v6uzJVuKJezirFo/u0df296gNLKMaYeifnRCGrdx1hxpfbyiWTxvEx/GvqRXSvYV2uYDqnXSLFtkgkYAnFGFMPDX9yIUfzfeXKmjeKY2WZzbJCJS5aKCr2h/x96yJLKMaYeiV52genlH1y76X0aB26XklZq23plVKWUIwx9caunLzSxyN6t6Zt0wQmD+tOp+YNPYupSUIMx/J9fLh2L1f2a+dZHHWBJRRjTJ23cudh9ufmM/mNlQB8fM8l9G6bWMNZofGrsefwP2+v5SdvrGT742O9DsdTdh+KMaZOyy8q5toXFpcmE6DOJBOAUc4Mr/gY+3Xq6r+AiIwWkU0ikiki0yp5PV5EZjuvfyUiyWVeu98p3yQio2qqU0QuE5GVIrJKRBaJSA8322aMcdeh4wXsy82n968/Li1r3iiuzvUCkhrGcX635hT4/Ow4dMLrcDzlWkIRkWjgeWAMkArcKCKpFQ67HTisqj2Ap4EnnHNTgUlAH2A08IKIRNdQ54vAzao6EHgT+JVbbTPGuCvzwHGGPDyf8x/7tFz5uIHtPYqoel2aBxagHPbkf0ie9gH/WrXb44i84WYPZSiQqapbVbUQmAWMq3DMOGCm83gOcJkE7kYaB8xS1QJV3QZkOvVVV6cCJf3gpsAel9pljHHZYx9uKPf8nZ9cyDUD23P/mHM8iqh6PxrWrdzz/561iow9kTf7y82E0gHYVeZ5llNW6TGq6gNygRbVnFtdnXcAH4pIFnAL8HhlQYnInSKSLiLp2dnZZ9AsY4ybXl+ynU83Hih9ftuFyQzu3Iw/ThpEXB0dp+jWqjH3j+ldrmzss4vwR9iikXXz0zkz9wJXqmpH4BXgqcoOUtXpqpqmqmmtWrUKaYDGmOplHyvg1//KAODJCf255/IU/nds3eyVVHTnpd3I+L9RbH98LH3aBy6W7DqcV8NZ4cXNhLIbKLtVWkenrNJjRCSGwKWqQ9WcW2m5iLQCBqjqV075bODC4DTDGBMKfr9y0eMLSp+PH9SBey7vSWx0/fi7V0RoFB+4E+MXowO9lYMRtj2wm5/UciBFRLqKSByBQfa5FY6ZC9zqPJ4ALFBVdconObPAugIpwLJq6jwMNBWRnk5dI4HyF2GNMXXara8so9BZwuTFmwcTU08SSWWaJAQSS86JIo8jCS3XbmxUVZ+ITAXmAdHADFXNEJGHgHRVnQu8DLwuIplADoEEgXPcW8B6wAdMUdVigMrqdMp/CLwtIn4CCeYHbrXNGBNca7KO8MWWgwDM/MFQhvWs35ejOzobe6Vvz2FkahuPowkd0QheJTMtLU3T09O9DsOYiOX3Kz/7x2re+TpwNfzV75/L8F6tPY4qOCb+ZQl5hcW8d9fFXocSdCKyQlXTKpbX3z6lMaZe8xX7ueypz0qTCcAlKfW7Z1JW26YJrN2dy+b9x7wOJWQsoRhjPDF/wwG2Hfz2zvLZd55PdJT7m2KFSpvEBADe/TpybnK0hGKM8cSs5YHteh8d34/tj4/lvG4tPI4ouO65PAWAhnHRHkcSOpZQjDEht/vIST7bnM1dI3pw03mdvQ7HFQ3jYoiPieL3/95Mz//9iEgYr7aEYowJuTtmpqMKN6R1qvngeqzAF5gGXVjs5+5ZqzyOxn2WUIwxIZVzopANe4/SJjHe042xQu291XtInvYBX+887HUorrGEYowJqb9+sRWAV24b6nEk7pv/02Es/Nlwbr+4a2nZ+BcWexiRu2zHRmNMyOQXFfPif74BILV93dkkyy0l+9z3btukXLmqElhYPbxYD8UYEzKfbgisIvy7Cf09jiS0xvRrx/cvSi6d+TXt7bVheenLEooxJmRmLtlO28QErhvc0etQQqpxfAwPfLcPl/UOLMMyO30X419YzO4jJz2OLLgsoRhjQuKT9ftZti2HS1JahtUNjKejb4dEyl7pWrHj217Kx+v2smDjfg+iCh5LKMaYkHhtyXYA7h3Zs9rjwpmIsPXRK5lxW2AZrGJ/YFrxx+v28eO/reQHr6aTe7L+rlBsCcUY47r9R/NZ/M0hJg/vTntnJd5IJSL0bBMYpC/yKbl5Rfz4bytKX5+1bKdXoZ01SyjGGNfNWZFFsV/D/kbG2irZyvijdXu58/XAiudP3TAAgMc+2kh+UbFnsZ0NSyjGGFf5/crs5bs4v1tzurZs5HU4dUKcs3nYwk3ZfLUth4t7tOTaMhMVnv10i1ehnRVLKMYYVy3deoidOXlMOjc81+w6EyVbBZf42aheALw75SIAXvjPN+QV+kIe19myGxuNMa56dfF2EhNiGN23rdeh1Bmx0VE8PXEAUSJ8t397opxZbwM7JREdJRT7lSc+2sgvx55DfEz9Wa3YeijGGNd8tHYv/16/n2sHdyQhtv78YgyF8YM6Mm5gh9JkUmLDQ6MBmLlkBw/OXe9FaGfMEooxJqhUlY/W7uV4gY8/fxZYZuWuET08jqr+KBmwB/j7sp31aoMuSyjGmKD6bHM2k99YyYv/yWR1Vi7/M7o3LRrHex1WvVLSSwF4/KONHkZyeiyhGGOC6rUlOwB46YttxEYL16dF1jIrwdAgLppnbxwEwL6j+fXmZkdXE4qIjBaRTSKSKSLTKnk9XkRmO69/JSLJZV673ynfJCKjaqpTRL4QkVXO1x4RedfNthljTrXj0AkWbgosAFng8zOqT1taWu/kjFw9oD1DuzYH4GikJxQRiQaeB8YAqcCNIpJa4bDbgcOq2gN4GnjCOTcVmAT0AUYDL4hIdHV1quolqjpQVQcCS4B33GqbMeZUK3bkMOzJ/1B2p9ubz+viXUBh4HvnB/79npy3qXTpmrrMzR7KUCBTVbeqaiEwCxhX4ZhxwEzn8RzgMglsEjAOmKWqBaq6Dch06quxThFJBEYA1kMxJoQemJsBQLOGsaVl53dr7lU4YSHBGaCfu3oPv/lXBh+u3etxRNVzM6F0AHaVeZ7llFV6jKr6gFygRTXn1qbOa4BPVfVoZUGJyJ0iki4i6dnZ2afVIGNM5XYeyiNjz1HaNU3gg7svAeCW87uE5SZSodQmMaHc89++X7enEYfjjY03Ai9V9aKqTgemA6SlpWlVxxljau+VxduIFuHdKRfRJjGBzEfGROwS9cE0oFMSb95xHn07NuXch+czoGOS1yFVy82EshsouxJcR6essmOyRCQGaAocquHcKusUkZYELouND0L8xphaOJZfxD/Ss7iqf7vSv6hjom0CabBc2KMlAF1aNPQ4kpq5+akvB1JEpKuIxBEYZJ9b4Zi5wK3O4wnAAlVVp3ySMwusK5ACLKtFnROA91U137VWGWPKmb18F8cLfNx+cTevQwlrMVFR+Jz9U+oq13ooquoTkanAPCAamKGqGSLyEJCuqnOBl4HXRSQTyCGQIHCOewtYD/iAKapaDFBZnWXedhLwuFttMsaUV+xXXl28nXOTm9GvY1OvwwlrsdFCUXHdvkrv6hiKqn4IfFih7DdlHucD11dx7iPAI7Wps8xrw88iXGPMafpk/T6yDp/kV2PP8TqUsBcTHUWhr273UOxCpzHmjL28aBsdmzVgZKqtJOy2wycKWbL1EJ9trruzUy2hGGPOyJtf7WT59sPcdmGyzegKgZKbHL/eedjjSKpmCcUYc9r8fuWxjzYAMPFc29Y3FK4ZFLjlLqlBbA1HescSijHmtC3cdIBj+T6emTSQJgl19xdcOImJDvQCff66OzBvCcUYc9r++sVW2jdN4Mp+7bwOJWLERFlCMcaEmbv+/jVLt+bw/Yu6Ems3MIZMTFTg39pXXHdnetlPgzGm1o7kFfLe6j0ATBxqYyehVNJD+f2/N5N9rMDjaCoXjmt5GWOCLK/Qx+/nbabI+ev4g7svJtHGTkKq7N7zy7blMLZ/3bvcaAnFGFOjxz7cyOtLAzsxjujdmj7t7a54L4zo3ZoFGw+UDtDXNXbJyxhTrfyi4tJkAjB5eHcPo4ls08b0BijtKdY1llCMMdWasyKr3PNzk23TLK+UTII4lu/zOJLK2SUvY0yV8ouKeWFhJgM7JTGkSzOuGVhxPzsTSiUD8/e/s5aU1o1Jq2PJ3RKKMaZKL32xlT25+Tx6bT+G92rtdTgRLy7m24tK767aXecSil3yMsZUKjeviL98vpXLz2ltyaSOaN0knnsuTwHgb0t3ehzNqSyhGGMq9ZfPv+F4gY/7rujldSjGISLcc3nP0ucfr9vnYTSnsoRijDlF9rECXvlyO1f1b8857RK9DsdU8MLNgwH41bvrPI6kPEsoxphTvPifbygs9nOvc3nF1C0la6g1jIv2OJLyLKEYY8rZl5vP377awbWDOtCtVWOvwzHV2JmT53UI5dR6lpeI9AVSgYSSMlV9zY2gjDHeeX5hJn6/cvdl1jupy8b0bctH9XEMRUQeAP7kfH0H+B1wtYtxGWM8sHLnYV5fuoMbzu1Ep+YNvQ7HVKNkbKsurT5c20teE4DLgH2q+n1gAGCL+RgTRlSV376/HoD/tt5JnZcQG/j1XeCrfwnlpKr6AZ+IJAIHAFu72pgwMi9jH1/vPMLj1/ajTWJCzScYT8VF19+Eki4iScBfgRXASmBJTSeJyGgR2SQimSIyrZLX40VktvP6VyKSXOa1+53yTSIyqqY6JeAREdksIhtE5O5ats2YiHeiwMdP3lhJj9aNmTCko9fhmFqIdhJKcR3awbFWg/Kq+hPn4Z9F5GMgUVXXVHeOiEQDzwMjgSxguYjMVdX1ZQ67HTisqj1EZBLwBDBRRFKBSUAfoD0wX0RK7uapqs7bCPSaequqX0Ts1l5jaumRDzfgV7h/TG9ibBfGeiFaAut61buEAiAi/YHkknNEpIeqvlPNKUOBTFXd6hw/CxgHlE0o44AHncdzgOdERJzyWapaAGwTkUynPqqpczJwk3NpDlU9UNu2GRPJ1u85yqxlO7kitQ2XndPG63BMLX27x3zdueRVq4QiIjOA/kAGUBK9AtUllA7ArjLPs4DzqjpGVX0ikgu0cMqXVji3ZJnTqursTqB3Mx7IBu5W1S2VtOVO4E6Azp07VxO+MeFPVXnwvQyaNojlyQkDvA7HnIZoJ6HUoXxS6x7K+aqa6mokZy8eyFfVNBG5FpgBXFLxIFWdDkwHSEtLqzt9RWM88P6avSzblsOj4/vRtKFt6VuflOzaWJd6KLW9WLrEGdc4HbspPxOso1NW6TEiEkNgKvKhas6trs4svu0x/ZNAj8oYU4W8Qh+PfriBPu0TmXiuTdqsb6Lq4BhKbRPKawSSyiYRWSMia0Wk2kF5YDmQIiJdRSSOwCD73ArHzAVudR5PABaoqjrlk5xZYF2BFGBZDXW+S+CmS4BhwOZats2YiDT9863szc3nwav7lF4+MfVHyRhKsdadhFLbS14vA7cAa/l2DKVazpjIVGAeEA3MUNUMEXkISFfVuU69rzuD7jkEEgTOcW8RGGz3AVNUtRigsjqdt3wceENE7gWOA3fUsm3GRJzN+4/xx/lbGNuvnW3pW0+V/BFw4/SlfP2bKzyOJqC2CSXbSQCnRVU/BD6sUPabMo/zgeurOPcR4JHa1OmUHwHGnm6MxkSaQp+fSdMDc16mjentcTTmTJUsvXI4rwhVRcT7XmZtE8rXIvIm8B5QUFJYw7RhY0wd9PKibeScKOSnI3vael31WKfmDbl6QHvmrt5DXmExjeK939G9tmMoDQgkkiuA7zpfV7kVlDHGHbty8njm082M6tPGVhMOA+d1C1yuPFHg8ziSgNreKf99twMxxrhLVXlgbgZRIjzw3T5eh2OCoLHTKzlW4KMuLA1S2+Xru4rIUyLyjojMLflyOzhjTPDMy9jPgo0H+OnInrRPauB1OCYIGsUFEsqjH2zwOJKA2l50e5fAjKz3qOUsL2NM3XGiwMf/vZfBOe0Sue3CZK/DMUEysHMSAJ9urBsrTdU2oeSr6rOuRmKMcc1Tn2xm39F8nrtpsC3+GEZaNo4vfXzoeAGN4mNIiPVun/na/mQ9IyIPiMgFIjK45MvVyIwxQbE2K5dXvtzGTUM7M6RLM6/DMUF2+TmB0ZMhD89n2JMLPY2ltj2UfgRubBxB+cUhR7gRlDEmOHLzirj6+UW0aBTPL0bbPSfh6AcXd2X+hsAlr/1HC2o42l21TSjXA91UtdDNYIwxwfXohxtQhYev6UPTBrb4Yzi6oFsL3p58Ide9uJgmHt+LUttLXuuAJDcDMcYE18KNB5idvosfD+vO6L7tvA7HuEREGNKlGbde0IUoj9dkq206SwI2ishyyt8pf7UrURljzkrOiUJ+PmcNvds24d6RdgNjJIiJjvJ85eHaJpQHXI3CGBM0qsov31lL7slCXvvBUOJjvJv1Y0InJkooKvb2ro7a3in/mduBGGOC452Vu/k4Yx/TxvQmtX2i1+GYEBERCnx+nl+YyZTv9PAkhtreKX++iCwXkeMiUigixSJy1O3gjDGnZ/eRkzw4N4Ohyc354SXdvA7HhFDW4TwAnv30lJ3PQ6a2g/LPATcCWwgsFHkH8LxbQRljTp/fr9z31ir8qvzhhgG2aVaEuWtEYKzs0p6tPIuh1rfMqmomEK2qxar6CjDavbCMMadrxpfbWLo1hwe+28eWpY9Avdo2oX/Hpp6Oo9R2UD7P2XJ3tYj8DtjLaSQjY4y7Nu07xu/mbeLyc9pwfVpHr8MxHsk9WcSarFyyjxXQqkl8zScEWW2Twi3OsVOAE0BH4Dq3gjLG1N7JwmLu+vtKEhNiePy6fnVi5z7jjR2HAuMo5z4ynz1HTob8/atNKCIyTkSmqOoOZ7veT4DbgPHAwBDEZ4ypwUPvr2fz/uM8PXFgucUCTeT58/e+XWJx+fackL9/TT2UXwBl9z2JB4YAw4HJLsVkjKml99fs4e/LdjJ5eHcuSfFuMNbUDaP7tuPT+4YBcMCDdb1qGkOJU9VdZZ4vUtUcIEdEGrkYlzGmBrty8rj/7bUM6pzET0f29DocU0e0SUzw7L1r6qGUW+taVaeWeWp/DhnjkaJiP1P//jUIPDtpELG2x4lxxEYHxtAKPZjtVdNP4Vci8sOKhSLyI2BZTZWLyGgR2SQimSIyrZLX40VktvP6VyKSXOa1+53yTSIyqqY6ReRVEdkmIqucLxvjMWHruQWZrN51hMev7W9ThE05sVGBX+teTB+u6ZLXvcC7InITsNIpG0JgLOWa6k4UkWgCNz+OBLKA5SIyV1XXlznsduCwqvYQkUnAE8BEEUkFJgF9gPbAfBEp6dNXV+fPVXVOja02ph5buOkAzy7YwrWDOzC2v60ibMorWXH4j/O3cM/lob0UWm1CUdUDwIUiMoLAL3eAD1R1QS3qHgpkqupWABGZBYwDyiaUccCDzuM5wHMSmPM4DpilqgXANhHJdOqjFnUaE7Z2Hsrjnlmr6N02kUeu6ed1OKaOO5pfRGJC6PbBqdWFV1VdoKp/cr5qk0wAOgBlB/SznLJKj1FVH5ALtKjm3JrqfERE1ojI0yJS6fxJEblTRNJFJD07O7uWTTHGeycLi/nx31agqvz5e4NpEGerCJvKTRgSuLnVVxza5ezDaSTvfqA3cC7QHPifyg5S1emqmqaqaa1a2bwCUz+oKr94ew0b9h3lmUmD6NLCJlmaqg3qHNgPMdTjKG4mlN1ApzLPOzpllR4jIjFAU+BQNedWWaeq7tWAAuAVvr1EZky99/zCTN5bvYefj+rFd3q39jocU8eVzPoLp4SyHEgRka7OOmCTKH+TJM7zW53HE4AFqqpO+SRnFlhXIIXArLIq6xSRds53ITBhYJ2LbTMmZD5et4/f/3sz4wd1YPKw7l6HY+qBkqnDFz+xkM82h+7SvmsJxRkTmQrMAzYAb6lqhog8JCIlWwe/DLRwBt1/Ckxzzs0A3iIw2P4xMMVZ5bjSOp263hCRtcBaoCXwsFttMyZUMvbkcu/sVQzslMRj19o6XaZ2ThZ+2zO5Y+ZyjuUXheR9JdAhiExpaWmanp7udRjGVGr/0XyufWExflX+NfUiWjfx7g5oU79kHjjO5U99u9FucouGLPzZ8KD9QSIiK1Q1rWJ5OA3KGxM2juYXcdsryzmSV8hf/yvNkok5LT1aN2b742Np0SgOgO2H8sg+7v7aXpZQjKljCnzF/Pj1FWzZf4w/3zKEvh2aeh2Sqae+nDaCycMD426FPvcH6Gu7wZYxJgQC2/iuZvE3h3h64gBbQdiclYTYaFJaNwZCc0+KJRRj6ojck0Vc8Nin5BUWM21Mb8YPsp0XzdmLcaYQ+/zu91DskpcxdcCJAh+3vPwVeYXF3HZhMj+6tJvXIZkwEeus7VVkPRRjwl9+UTF3zEwnY89R/nD9AK4bYj0TEzwlPZT1e44y4cXFFBb7Wf/QaFe2PLAeijEeKvT5mfy3FSzddsiSiXFFXqEPgPv+sZoThcUUFStzVmS58l6WUIzxSFGxn/+e9TULN2Xz6Ph+XDOo4tqpxpy9q/q3P6VsTVauK+9lCcUYD+QXBaYGf7RuH7++KpUbh3b2OiQTpqKjhD9OHEibxHgWTxtBw7hoGrm0UrWNoRgTYrkni/jhzHSW78jh4Wv68r3zu3gdkglz1wzqUNoDjo+JosCle1Ksh2JMCB04ls+k6Uv5etdh/nTjIEsmJuQO5xXx+tIdnCwsDnrdllCMCZGdh/K4/s9L2H7wBC/fem6l17aNCZXth04EvU675GVMCGzYe5T/mrGMomI/b/zwPAZ3buZ1SCZC/XHiQA4eL+CcdolBr9sSijEuUlWe/mQzzy7IpG1iAm/+6AJS2jTxOiwTwdycTWgJxRiXFPr8THtnDe+s3E3j+BjmTL6Ajs0aeh2WMa6xhGKMC/KLirln1io+ztjHfSN7MnVED9scy4Q9SyjGBFn2sQLufD2dr3ce4TdXpfKDi7t6HZIxIWEJxZggyjxwjM1cR9EAABCYSURBVNteWc7B4wW8ePNgxvRr53VIxoSMJRRjgmTp1kNMeWMlUVHCWz+6gP4dk7wOyZiQsoRizFlSVWZ8uZ1HP9xAlxYNeem/0ujWqrHXYRkTcpZQjDkLxX7lkQ82MOPLbVyR2oY/3DCAJgmxXodljCcsoRhzhg4cy+fe2av4MvMQt5zfhf+7ug9RUTaTy0QuV5deEZHRIrJJRDJFZFolr8eLyGzn9a9EJLnMa/c75ZtEZNRp1PmsiBx3q03GAHyZeZArn1lE+vbDPHFdPx4aZ8nEGNd6KCISDTwPjASygOUiMldV15c57HbgsKr2EJFJwBPARBFJBSYBfYD2wHwR6emcU2WdIpIG2JoWxjV+v/KnBZn88dPNdG/VmDfuOI9ebe3Od2PA3UteQ4FMVd0KICKzgHFA2YQyDnjQeTwHeE4Cd3+NA2apagGwTUQynfqoqk4ngT0J3ASMd7FdJkLtysnjvn+sZtm2HK4d1IGHx/elYZxdNTamhJv/GzoAu8o8zwLOq+oYVfWJSC7QwilfWuHckgVoqqpzKjBXVfdWd0eyiNwJ3AnQubNtamRqpqrMWr6Lh99fT5QIT07oz4QhHe3Od2MqCIs/r0SkPXA9MLymY1V1OjAdIC0tTd2NzNR3n27Yz+Q3VlLo83Nh9xY8ef0AOiQ18DosY+okNxPKbqBTmecdnbLKjskSkRigKXCohnMrKx8E9AAynb8aG4pIpqr2CE5TTKTJOpzHb99fz7yM/QA8NK4P3zuviw28G1MNNxPKciBFRLoS+KU/icD4RllzgVuBJcAEYIGqqojMBd4UkacIDMqnAMsAqaxOVc0A2pZUKiLHLZmYM7F5/zF++c5a1u3JRRB+MboXt1/clfgYd/bgNiacuJZQnDGRqcA8IBqYoaoZIvIQkK6qc4GXgdedQfccAgkC57i3CAzg+4ApqloMUFmdbrXBRI4TBT6eXbCFv3y2FYDRfdry6++m2uUtY06DqEbuMEJaWpqmp6d7HYbxkKry/pq9PPLBBvYdzef6IR35wcVdXdnNzphwISIrVDWtYnlYDMobcya27D/GA3MzWPzNIfq0T+T5mwczpIvdxmTMmbKEYiLOniMneWb+Fv6xYheN42P47TV9uWloZ6JtwN2Ys2IJxUSMwycKefGzb3h18XZQ+P5FXfnJ8O60aBzvdWjGhAVLKCbs5Z4s4tUvt/PSF1s5Uejj2sEduefyFNvf3Zggs4RiwtaRvEJmLNrGK19u51iBjytS2/CzUb3o2cbW3jLGDZZQTNjJPlbAq4u3MXPxDo4X+BjTty13jUghtb3N3DLGTZZQTNj4Jvs4L32xjbdXZlFU7OfKfu24e0SKrQZsTIhYQjH1mt+vLMo8yGtLdvDpxv3ERkdx3eCO/PCSrrYNrzEhZgnF1EuHjhfwjxVZvPnVTnbm5NG8URxThvfg1guTadXEZm0Z4wVLKKZeKPT5+WxzNu9+vZsP1u4tLR/atTn3XdGT0X3b2npbxnjMEoqps1SVlTsP88+vd/P+mr0cySuieaM4WjeJ58p+7bj5vM6k2IwtY+oMSyimTin0+Vm2LYf5G/bzyfr97D5ykoTYKK5Ibcv4QR24OKUlsdFRXodpjKmEJRTjuSN5hXy2OZtP1u/ns03ZHCvwkRAbxcU9WvHTkT0Z1bctjePtR9WYus7+l5qQKyr2s2rXEb7YnM0XmQdZvesIfoWWjeO4sl87Rqa24aIeLWkQZ2MixtQnllBMSBzNL2LBhgO8v2YvS7ce4niBjyiBAZ2SmPqdHgzr1ZqBnZJsgUZj6jFLKCboVJU9uflk7M5l5c4jLPnmIGt35+JX6JDUgKsHtufSlJZc0K0lTRvGeh2uMSZILKGYs+Ir9rP90Aky9hx1vnJZv+coh/OKAIiJEgZ1TmLqiBQu7N6CocnNbV92Y8KUJRRzxtK35/C9l78iv8gPQFx0FL3aNmFUn7b0aZ9IavumpLZLtLEQYyKEJRRTa6rK3tx8Nu8/xpb9x/k4Yx/5RX4eGd+XwZ2b0aN1Y5vSa0wEs4RiauVfq3bzq3+u41iBr7SsZeN4brswmZvP6+JhZMaYusISiqmS36/sPnKS/3svg/kbDgDw22v60rN1Y3q2aUKzRnEeR2iMqUtcTSgiMhp4BogGXlLVxyu8Hg+8BgwBDgETVXW789r9wO1AMXC3qs6rrk4ReRlIAwTYDNymqsfdbF99p6qcKCxm+8ETbNx3jP1H80u/9uXms+XAcfIKiwHo3Lwhj4zvyyUprTyO2hhTV7mWUEQkGngeGAlkActFZK6qri9z2O3AYVXtISKTgCeAiSKSCkwC+gDtgfki0tM5p6o671XVo857PwVMBcolsEh3srCYKW+uZFdOHkdOFnEkr5CiYi13TGJCDG2bJtAmMYEb0jrRs00TUto0ZmCnJBsfMcZUy80eylAgU1W3AojILGAcUDahjAMedB7PAZ4TEXHKZ6lqAbBNRDKd+qiqzjLJRIAGQPnflBFIVXn4gw1s2neM3JNFrN2dC0DXlo24/JzWNG0QR7OGsTRvFMegzkl0SGpoM7KMMWfMzYTSAdhV5nkWcF5Vx6iqT0RygRZO+dIK53ZwHldZp4i8AlxJIGndd/ZNqN+yjxXw8qJtAFzUowW3XtCF5JaNuOX8LsRYb8MYE2RhNSivqt93LrX9CZgIvFLxGBG5E7gToHPnzqENMMRKxj+eumEA1w7u6HE0xphw5+afqbuBTmWed3TKKj1GRGKApgQG56s6t8Y6VbUYmAVcV1lQqjpdVdNUNa1Vq/AdYP5w7V7+8MlmABraZSxjTAi42UNZDqSISFcCv/QnATdVOGYucCuwBJgALFBVFZG5wJvO4Hp7IAVYRmAG1yl1OuMm3VU103l8NbDRxbZ5TlU5nFfEiQIfBT4/+UXFHD1ZRIHPT4GvmF+/u44ThT66tWxE77aJXodrjIkAriUUZ0xkKjCPwBTfGaqaISIPAemqOhd4GXjdGXTPIZAgcI57i8BYiA+Y4vQ8qKLOKGCmiCQSSDqrgclutS2Yth08wbJth2jaII4VO3LYuO8Y8THRJMRG0SA2mgZx0TSIjSZjz1EWZR4sPU8EtIZpB7+8sjd3Xtrd5RYYY0yAaE2/lcJYWlqapqenexrDj19fwccZ+8qVpbZLJL+omJPOV35Rcel6WXeN6IEQmMLWrGEcTRJiiI+NJj4miqYNYklwHifERpPcoiGBDpsxxgSPiKxQ1bSK5WE1KF+f+P3Kg+9lkL4jh0Gdk/jtuL4cySsipU1j2iQmnHJ8SeK3BGGMqassoYSIr9iPz68kxEazNfs4419YTO7JwBLvPx7Wnb4dmlZ7viUSY0xdZwklRK7/yxK+3nmE+JgoCnyBy1cdmzXgk3uH2c2ExpiwYAklRDIPHGdQ5yTOTW5OUbGffh2a2r0hxpiwYgklBBZtOcixfB8Xdm/Bz0f19jocY4xxha2/4bLAelqB5ct62f0gxpgwZj0UF20/eILRz3xOfpGfG9I6cvWA9l6HZIwxrrEeikuO5BXy8AcbyC/yc0G3Fvzwkm5eh2SMMa6yHsoZyDlRSEJsFA3jYth28AT7cvNpkhBD4/gYmiTEkNggll/+cy3zN+ynaYNYXvn+uSTE2kwuY0x4s4RyBn4xZzXzNxygYVx06Yq+lWmSEMPnP/+OJRNjTESwhHIGbjqvM0O6NCf7WAGHThQwqFMS7ZMacLzAx9GTRRzND3wf1bctTRvGeh2uMcaEhCWUMzCidxtG9G7jdRjGGFOn2KC8McaYoLCEYowxJigsoRhjjAkKSyjGGGOCwhKKMcaYoLCEYowxJigsoRhjjAkKSyjGGGOCQkr2Ko9EIpIN7ABaAgc9DsdLkdz+SG47RHb7I7ntcHbt76KqrSoWRnRCKSEi6aqa5nUcXonk9kdy2yGy2x/JbQd32m+XvIwxxgSFJRRjjDFBYQklYLrXAXgsktsfyW2HyG5/JLcdXGi/jaEYY4wJCuuhGGOMCQpLKMYYY4Ii4hOKiIwWkU0ikiki07yOx20isl1E1orIKhFJd8qai8gnIrLF+d7M6ziDRURmiMgBEVlXpqzS9krAs87PwhoRGexd5GevirY/KCK7nc9/lYhcWea1+522bxKRUd5EHRwi0klEForIehHJEJH/dsoj5bOvqv3ufv6qGrFfQDTwDdANiANWA6lex+Vym7cDLSuU/Q6Y5jyeBjzhdZxBbO+lwGBgXU3tBa4EPgIEOB/4yuv4XWj7g8DPKjk21fn5jwe6Ov8vor1uw1m0vR0w2HncBNjstDFSPvuq2u/q5x/pPZShQKaqblXVQmAWMM7jmLwwDpjpPJ4JXONhLEGlqp8DORWKq2rvOOA1DVgKJIlIu9BEGnxVtL0q44BZqlqgqtuATAL/P+olVd2rqiudx8eADUAHIuezr6r9VQnK5x/pCaUDsKvM8yyq/0cPBwr8W0RWiMidTlkbVd3rPN4HtPEmtJCpqr2R8vMw1bmsM6PM5c2wbbuIJAODgK+IwM++QvvBxc8/0hNKJLpYVQcDY4ApInJp2Rc10P+NmLnkkdZe4EWgOzAQ2Av8wdtw3CUijYG3gXtU9WjZ1yLhs6+k/a5+/pGeUHYDnco87+iUhS1V3e18PwD8k0C3dn9J9975fsC7CEOiqvaG/c+Dqu5X1WJV9QN/5dvLGmHXdhGJJfDL9A1VfccpjpjPvrL2u/35R3pCWQ6kiEhXEYkDJgFzPY7JNSLSSESalDwGrgDWEWjzrc5htwL/8ibCkKmqvXOB/3Jm/JwP5Ja5PBIWKowLjCfw+UOg7ZNEJF5EugIpwLJQxxcsIiLAy8AGVX2qzEsR8dlX1X7XP3+vZyN4/UVgdsdmArMa/tfreFxuazcCMzlWAxkl7QVaAJ8CW4D5QHOvYw1im/9OoGtfROC68O1VtZfADJ/nnZ+FtUCa1/G70PbXnbatcX6JtCtz/P86bd8EjPE6/rNs+8UELmetAVY5X1dG0GdfVftd/fxt6RVjjDFBEemXvIwxxgSJJRRjjDFBYQnFGGNMUFhCMcYYExSWUIwxxgSFJRRj6gAReUhELvc6DmPOhk0bNsZjIhKtqsVex2HM2bIeijEuEpFkEdkoIm+IyAYRmSMiDZ19aZ4QkZXA9SLyqohMcM45V0QWi8hqEVkmIk1EJFpEnhSR5c7Cfj9yjm0nIp87e1usE5FLPG2wiWgxXgdgTAToBdyuql+KyAzgJ075IQ0s1ImIjHa+xwGzgYmqulxEEoGTBO5yz1XVc0UkHvhSRP4NXAvMU9VHRCQaaBjaphnzLUsoxrhvl6p+6Tz+G3C383h2Jcf2Avaq6nIAdVbIFZErgP4lvRigKYH1lpYDM5yFAN9V1VUutcGYGllCMcZ9FQcqS56fOI06BLhLVeed8kJgC4KxwKsi8pSqvnZmYRpzdmwMxRj3dRaRC5zHNwGLqjl2E9BORM4FcMZPYoB5wGSnJ4KI9HRWj+4C7FfVvwIvEdjy1xhPWEIxxn2bCGxmtgFoRmCTo0ppYCvqicCfRGQ18AmQQCBZrAdWisg64C8ErjAMB1aLyNfOec+42A5jqmXTho1xkbP96vuq2tfjUIxxnfVQjDHGBIX1UIwxxgSF9VCMMcYEhSUUY4wxQWEJxRhjTFBYQjHGGBMUllCMMcYExf8DNRN7HPkZk/QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj7NlW6GVqSA"
      },
      "source": [
        "[Implied volatility](https://en.wikipedia.org/wiki/Implied_volatility) is the forecasted volatility of the underlying asset based on the quoted prices of the option. It is the reverse mapping of price to the option parameter given the model which is hard to do with the Monte Carlo simulation approach. But if we have the deep learning pricing model, it is an easy task. We can first plot the relationship between volatility and the option price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yrCw5UNT07t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "a6061826-8390-403a-d279-c29806a0319f"
      },
      "source": [
        "import pylab\n",
        "import numpy as np\n",
        "def compute_price(sigma):\n",
        "    inputs = torch.tensor([[110.0, 100.0, 120.0, sigma, 0.1, 0.05] + ([110.0, 100.0, 120.0, 0.35, 0.1, 0.05]*9)]).cuda()\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    return x.item()\n",
        "sigmas = np.arange(0, 0.5, 0.1)\n",
        "prices = []\n",
        "for s in sigmas:\n",
        "    prices.append(compute_price(s))\n",
        "fig3 = pylab.plot(sigmas, prices)\n",
        "pylab.xlabel('Sigma')\n",
        "pylab.ylabel('Price')\n",
        "fig3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f63c125a850>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU25Cj29VtCa"
      },
      "source": [
        "Given the prices `P`, the implied volatility is the root of the function `compute_price`. We can use bisection to find the root."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddHnwm_zUBYD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "3b564d6a-8e79-48a5-d27e-80d7550f8e72"
      },
      "source": [
        "def bisection_root(small, large, fun, target, EPS=1e-6):\n",
        "    if fun(large) - target < 0:\n",
        "        print('upper bound is too small')\n",
        "        return None\n",
        "    if fun(small) - target > 0:\n",
        "        print('lower bound is too large')\n",
        "        return None\n",
        "    while large - small > EPS:\n",
        "        mid = (large + small) / 2.0\n",
        "        if fun(mid) - target >= 0:\n",
        "            large = mid\n",
        "        else:\n",
        "            small = mid\n",
        "    mid = (large + small) / 2.0\n",
        "    return mid, abs(fun(mid) - target)\n",
        "quoted_price = 16.0\n",
        "sigma, err = bisection_root(0, 0.5, compute_price, quoted_price)\n",
        "print('implied volativity', sigma, 'error', err)     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "upper bound is too small\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ade689496c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mquoted_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbisection_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoted_price\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'implied volativity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    }
  ]
}