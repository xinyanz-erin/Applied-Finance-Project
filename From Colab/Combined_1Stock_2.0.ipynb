{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Combined.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NwN6aLFDnwiy",
        "dBOv_RiBsCWa",
        "u2_89jOknwjH"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Lilian/From%20Colab/Combined_1Stock_2.0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCR6hhw5Xq_R"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSxOZk3ls2XQ",
        "outputId": "933aaf5c-f068-47c9-b702-bb12e6116428"
      },
      "source": [
        "!curl https://colab.chainer.org/install |sh -\n",
        "import cupy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1580  100  1580    0     0   6007      0 --:--:-- --:--:-- --:--:--  6007\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "\u001b[K     |████████████████████████████████| 58.9 MB 21 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 56.1 MB/s \n",
            "\u001b[?25h  Building wheel for chainer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "+ set +ex\n",
            "Installation succeeded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwN6aLFDnwiy"
      },
      "source": [
        "### Deep Learning Barrier Option\n",
        "\n",
        "We used Numba and CuPy in the previous notebook to run Monte Carlo simulation to determine the price of the Asian Barrier option. A Monte Carlo simulation needs millions of paths to get an accurate answer which is computationally intensive. [Ryan et al (2018)](https://arxiv.org/abs/1809.02233) showed that a deep learning model can be trained to value derivatives. The deep learning model is accurate and very fast, capable of producing valuations a million times faster than traditional models. In the this notebook, we will use a fully connected network to learn the pricing mode of the Asian Barrier option. Monte Carlo simulation is used as pricing ground truth for the training. We use the same Asian Barrier Option model as last notebook with parameters listed as following:\n",
        "\n",
        "```\n",
        "T - Maturity (yrs.)\n",
        "S - Spot (usd)\n",
        "K - Strike (usd)\n",
        "sigma - Volatility (per.)\n",
        "r - Risk Free Rate (per.)\n",
        "mu - Stock Drift Rate (per.)\n",
        "B - Barrier (usd)\n",
        "```\n",
        "\n",
        "### Batched Data generation\n",
        "\n",
        "The dataset is an important part of the Deep learning training. We will modify the previous single Asian Barrier Option pricing code to handle a batch of Barrier Option pricing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHYrh4iYfP-n",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "###Test: Judy's new X code\n",
        "#N_STOCKS = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy7qGwT0jv4A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "ac958b42-0bd5-4600-d2b8-246276885438"
      },
      "source": [
        "#@title\n",
        "#X = cupy.array([])\n",
        "#for i in range(0,N_STOCKS):\n",
        "  #X =  cupy.concatenate((X,cupy.array([1,1]), cupy.random.rand(3),cupy.array([1])))\n",
        "#X = X.reshape(N_STOCKS,6)\n",
        "#X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.        , 1.        , 0.05103263, 0.0071633 , 0.52167781,\n",
              "        1.        ],\n",
              "       [1.        , 1.        , 0.64857557, 0.32324551, 0.39745689,\n",
              "        1.        ],\n",
              "       [1.        , 1.        , 0.82301291, 0.46666519, 0.8391176 ,\n",
              "        1.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OHtAXC8hVae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "264cef2d-1ead-43b8-e5fd-d8a131f38fda"
      },
      "source": [
        "#@title\n",
        "#X = X * ((cupy.array([200.0, 0, 200.0, 0.4, 0.2, 0.2] * N_STOCKS, dtype = cupy.float32)).reshape(N_STOCKS, 6))\n",
        "#X"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[2.00000000e+02, 0.00000000e+00, 1.02065252e+01, 2.86532070e-03,\n",
              "        1.04335564e-01, 2.00000003e-01],\n",
              "       [2.00000000e+02, 0.00000000e+00, 1.29715113e+02, 1.29298207e-01,\n",
              "        7.94913799e-02, 2.00000003e-01],\n",
              "       [2.00000000e+02, 0.00000000e+00, 1.64602581e+02, 1.86666078e-01,\n",
              "        1.67823523e-01, 2.00000003e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY_9g3tbdLiY"
      },
      "source": [
        "# Train(Erin Version)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBxT9Eida-c_",
        "outputId": "a6c4b380-eee1-4c6c-b01a-ccb074762090"
      },
      "source": [
        "################################# TEST ########################################\n",
        "%%writefile cupy_dataset.py\n",
        "\n",
        "import numba\n",
        "from numba import cuda\n",
        "import random\n",
        "import cupy\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "cupy.cuda.set_allocator(None)\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "@cuda.jit\n",
        "def batch_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_BATCH):\n",
        "    # ii - overall thread index\n",
        "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
        "    tmp3 = math.sqrt(T/N_STEPS)\n",
        "    for i in range(ii, N_PATHS * N_BATCH, stride):\n",
        "        batch_id = i // N_PATHS\n",
        "        path_id = i % N_PATHS\n",
        "        tmp1 = mu[batch_id]*T/N_STEPS\n",
        "        tmp2 = math.exp(-r[batch_id]*T)\n",
        "        running_average = 0.0\n",
        "        s_curr = S0[batch_id]\n",
        "        for n in range(N_STEPS):\n",
        "            s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH] # stock price\n",
        "            running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average) # average of the path\n",
        "            if i==0 and batch_id == 2:\n",
        "                print(s_curr)\n",
        "            if running_average <= B[batch_id]: # if reach barrier, drop out the path\n",
        "                break\n",
        "        payoff = running_average - K[batch_id] if running_average > K[batch_id] else 0\n",
        "        d_s[i] = tmp2 * payoff\n",
        "\n",
        "class NumbaOptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len=10, number_path = 1000, batch=2, threads=512, seed=15, stocks=3):  # 3 stocks\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 365\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = np.float32(1.0)\n",
        "        self.output = cupy.zeros(self.N_STOCKS*self.N_PATHS, dtype=cupy.float32) \n",
        "        self.number_of_blocks = (self.N_PATHS * self.N_STOCKS - 1) // threads + 1\n",
        "        self.number_of_threads = threads\n",
        "        cupy.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num > self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros(self.N_BATCH, dtype=cupy.float32)\n",
        "        paras = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "        for op in range(self.N_BATCH):\n",
        "          \n",
        "          X = cupy.array([])\n",
        "          K_rand = cupy.random.rand(1)[0]\n",
        "          B_rand = cupy.random.rand(1)[0]\n",
        "          r_rand = cupy.random.rand(1)[0]\n",
        "          for i in range(0,self.N_STOCKS):\n",
        "            X =  cupy.concatenate((X,cupy.array([K_rand,B_rand]), cupy.random.rand(3),cupy.array([r_rand]))) #[K,B,S0,sigma,mu,r], K B r are shared\n",
        "          X = X.reshape(self.N_STOCKS,6)\n",
        "          X = X * ((cupy.array([110.0, 100.0, 120.0, 0.35, 0.1, 0.05] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6))\n",
        "          #X = cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)\n",
        "          #X = 0.9 + cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)*0.1\n",
        "          # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "          #X = (X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6)\n",
        "\n",
        "          # make sure the Barrier is smaller than the Strike price\n",
        "          # X[:, 1] = X[:, 0] * X[:, 1]\n",
        "          for i in range(self.N_STOCKS):\n",
        "            paras[op,i*6:(i+1)*6] = X[i,:]\n",
        "\n",
        "          stocks_randoms_mean = cupy.zeros(self.N_STOCKS, dtype = cupy.float32)\n",
        "          rho = cupy.random.normal(0, 1, self.N_STOCKS, dtype = cupy.float32)\n",
        "\n",
        "          #stocks_randoms_cov = cupy.ones((self.N_STOCKS, self.N_STOCKS), dtype = cupy.float32)\n",
        "          #cupy.fill_diagonal(stocks_randoms_cov, rho)\n",
        "\n",
        "          #stocks_randoms_cov = (-0.99 + cupy.random.rand(self.N_STOCKS*self.N_STOCKS, dtype=cupy.float32)*2*0.99).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "          stocks_randoms_cov = cupy.array([1] * self.N_STOCKS*self.N_STOCKS, dtype = cupy.float32).reshape(self.N_STOCKS,self.N_STOCKS)  #Covariance\n",
        "          cupy.fill_diagonal(stocks_randoms_cov, 1)\n",
        "\n",
        "          num_of_randoms_each_stock = self.N_PATHS * self.N_STEPS\n",
        "          #randoms_gpu = cupy.random.multivariate_normal(stocks_randoms_mean, stocks_randoms_cov,\n",
        "          #                                              num_of_randoms_each_stock, dtype=cupy.float32)\n",
        "          randoms_gpu = cupy.random.normal(num_of_randoms_each_stock, dtype=cupy.float32)\n",
        "          #b1_r = randoms_gpu[:,0]\n",
        "          #b2_r = randoms_gpu[:,1]\n",
        "          #randoms = cupy.zeros(self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "          #interval = int((self.N_PATHS * self.N_STEPS * self.N_STOCKS) / self.N_PATHS)\n",
        "          #for i in range(interval):\n",
        "           # if i % 2 == 0:\n",
        "            #    ind = int(i/2)\n",
        "            #    randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b1_r[ind:(ind+self.N_PATHS)]\n",
        "            #else:\n",
        "            #    ind = int(i//2)\n",
        "            #    randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b2_r[ind:(ind+self.N_PATHS)]\n",
        "\n",
        "          randoms = cupy.random.normal(0, 1, self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "          batch_barrier_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, self.T, X[:, 0], \n",
        "                                X[:, 1], X[:, 2], X[:, 3], X[:, 4], X[:, 5], randoms, self.N_STEPS, self.N_PATHS, self.N_STOCKS)\n",
        "          \n",
        "          o = self.output.reshape(self.N_STOCKS, self.N_PATHS)\n",
        "          Y[op] = o.mean(axis = 0).mean()\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(paras.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "\n",
        "# ds = NumbaOptionDataSet(10, number_path=100000, batch=3, seed=random.randint(0,100), stocks=5)\n",
        "# for i in ds:\n",
        "#     print(i[0])\n",
        "################################# TEST ########################################"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing cupy_dataset.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2_89jOknwjH"
      },
      "source": [
        "### Model\n",
        "To map the option parameters to price, we use 6 layers of fully connected neural network with hidden dimension 512 as inspired by [this paper](https://arxiv.org/abs/1809.02233). Writing this DL price model into a file `model.py`:-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMHqzJycx8XH"
      },
      "source": [
        "### Modified Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTn7iJQryAIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "956eb8f3-5f40-49a0-dcc4-0074e2f5a618"
      },
      "source": [
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 1)\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([110.0, 100.0, 120.0, 0.35, 0.1, 0.05])) # don't use numpy here - will give error later\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing model.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSPRFqyznwjI"
      },
      "source": [
        "As we know the random parameters' scaling factors, the input parameters are first scaled back to a range of (0-1) by dividing them by (200.0, 198.0, 200.0, 0.4, 0.2, 0.2). Then they are projected 5 times to the hidden dimension of 512 after the `ELu` activation function. `ELu` is chosen because we need to compute the second order differentiation of the parameters. If use ReLu, the second order differentiation will always be zero. The last layer is a linear layer that maps the hidden dimension to the predicted option price. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM8J2liPnwjJ"
      },
      "source": [
        "For training, we use [Ignite](https://github.com/pytorch/ignite) which is a high-level library to train neural networks in PyTorch. We use `MSELoss` as the loss function, `Adam` as the optimizer and `CosineAnnealingScheduler` as the learning rate scheduler. The following code is feeding the random option data to the pricing model to train it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yACi4ge13_rd"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TyZT8_AH35M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da12df8d-48a3-41fd-82a3-8e5067a6f7ab"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.6-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 31.8 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 20 kB 23.2 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 30 kB 17.3 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 40 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |███████                         | 51 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 61 kB 7.1 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 71 kB 7.4 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 81 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 92 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 102 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 112 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 122 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 133 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 143 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 153 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 163 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 174 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 184 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 194 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 204 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 215 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 225 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 232 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Ej82G8nwjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25a98245-f36b-4706-e9cf-3fb658e9cde6"
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import NumbaOptionDataSet\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "# dataset = NumbaOptionDataSet(max_len=10000, number_path = 1024, batch=4800)\n",
        "dataset = NumbaOptionDataSet(max_len=100, number_path = 1024, batch=32, stocks=1)\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred[:,0], y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs=300)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss 933.1363525390625 average time 0.18297407934999513 iter num 20\n",
            "loss 689.5015258789062 average time 0.0934165715499958 iter num 40\n",
            "loss 193.6809844970703 average time 0.06350834688332914 iter num 60\n",
            "loss 243.77304077148438 average time 0.04856680086249625 iter num 80\n",
            "loss 124.23210144042969 average time 0.03964194166999675 iter num 100\n",
            "loss 17.824373245239258 average time 0.009557506950002903 iter num 20\n",
            "loss 3.6758334636688232 average time 0.006626095200000748 iter num 40\n",
            "loss 2.8551340103149414 average time 0.005645648816668351 iter num 60\n",
            "loss 2.569115400314331 average time 0.005132138012503162 iter num 80\n",
            "loss 1.8621571063995361 average time 0.004826226000002975 iter num 100\n",
            "loss 1.7767597436904907 average time 0.009698065450001537 iter num 20\n",
            "loss 1.6369009017944336 average time 0.006500363025000411 iter num 40\n",
            "loss 0.8097441792488098 average time 0.005459133833333378 iter num 60\n",
            "loss 0.4553510844707489 average time 0.004915250012501815 iter num 80\n",
            "loss 0.8779315948486328 average time 0.004590997900003799 iter num 100\n",
            "loss 0.6223431825637817 average time 0.009588510000003225 iter num 20\n",
            "loss 1.5256726741790771 average time 0.006491979925006319 iter num 40\n",
            "loss 1.622211217880249 average time 0.005457984133338793 iter num 60\n",
            "loss 0.8154517412185669 average time 0.0050256070000024525 iter num 80\n",
            "loss 0.7200412750244141 average time 0.004711778420001451 iter num 100\n",
            "loss 1.383528709411621 average time 0.010161052099994095 iter num 20\n",
            "loss 0.6010461449623108 average time 0.006860574774997019 iter num 40\n",
            "loss 0.45414072275161743 average time 0.005775157749999949 iter num 60\n",
            "loss 0.5735681056976318 average time 0.00527798912500046 iter num 80\n",
            "loss 1.5192210674285889 average time 0.0049618723299994375 iter num 100\n",
            "loss 0.9960864782333374 average time 0.011228631549994362 iter num 20\n",
            "loss 0.7349109649658203 average time 0.007433915700001137 iter num 40\n",
            "loss 0.5647035241127014 average time 0.006214982466666659 iter num 60\n",
            "loss 1.0538307428359985 average time 0.005599123362498659 iter num 80\n",
            "loss 0.6607143878936768 average time 0.005214040259999137 iter num 100\n",
            "loss 1.2819280624389648 average time 0.011442884800001708 iter num 20\n",
            "loss 1.5401335954666138 average time 0.007587618850001832 iter num 40\n",
            "loss 0.23811420798301697 average time 0.006251498750001853 iter num 60\n",
            "loss 1.683968186378479 average time 0.005599581612501936 iter num 80\n",
            "loss 0.9674522876739502 average time 0.005237596290002102 iter num 100\n",
            "loss 1.2734140157699585 average time 0.010942970099998206 iter num 20\n",
            "loss 0.7653502225875854 average time 0.007360218099999827 iter num 40\n",
            "loss 0.4965642988681793 average time 0.006172550666666628 iter num 60\n",
            "loss 1.064001202583313 average time 0.005562261687501291 iter num 80\n",
            "loss 0.8345884084701538 average time 0.00519604832000141 iter num 100\n",
            "loss 0.597598135471344 average time 0.011013946249997275 iter num 20\n",
            "loss 0.666124165058136 average time 0.00742254072500117 iter num 40\n",
            "loss 0.735327959060669 average time 0.0062036058000018105 iter num 60\n",
            "loss 1.0952328443527222 average time 0.005613230887497878 iter num 80\n",
            "loss 0.868465006351471 average time 0.0051903244599992605 iter num 100\n",
            "loss 0.5337568521499634 average time 0.009679198150004708 iter num 20\n",
            "loss 0.8843734860420227 average time 0.006589468975003854 iter num 40\n",
            "loss 0.5150667428970337 average time 0.005513585433331514 iter num 60\n",
            "loss 0.5316813588142395 average time 0.005013311599996939 iter num 80\n",
            "loss 0.6656676530838013 average time 0.0046663954999962695 iter num 100\n",
            "loss 1.164226770401001 average time 0.00976627549999307 iter num 20\n",
            "loss 0.9992810487747192 average time 0.006526379874999577 iter num 40\n",
            "loss 0.9113664627075195 average time 0.0054927524333341655 iter num 60\n",
            "loss 0.5427814722061157 average time 0.004945485225001533 iter num 80\n",
            "loss 1.283134937286377 average time 0.004609973340000692 iter num 100\n",
            "loss 1.161902904510498 average time 0.009002586649995693 iter num 20\n",
            "loss 0.6249656081199646 average time 0.006179509399994743 iter num 40\n",
            "loss 0.8292958736419678 average time 0.005211182883329949 iter num 60\n",
            "loss 0.4398438334465027 average time 0.0047217341624978815 iter num 80\n",
            "loss 0.5757563710212708 average time 0.004453009729995756 iter num 100\n",
            "loss 0.567875862121582 average time 0.01053638270001045 iter num 20\n",
            "loss 0.8371084928512573 average time 0.007061884225004178 iter num 40\n",
            "loss 0.6267693638801575 average time 0.005909762416669651 iter num 60\n",
            "loss 0.30958685278892517 average time 0.005360830762503354 iter num 80\n",
            "loss 0.9766495227813721 average time 0.005009622890001424 iter num 100\n",
            "loss 0.6708986163139343 average time 0.011235993550008061 iter num 20\n",
            "loss 0.5099244117736816 average time 0.007444431850001365 iter num 40\n",
            "loss 0.6808863282203674 average time 0.006172992750001072 iter num 60\n",
            "loss 0.3862995505332947 average time 0.005514599500002504 iter num 80\n",
            "loss 1.3456385135650635 average time 0.00512028670000177 iter num 100\n",
            "loss 0.6266574859619141 average time 0.010033483000003684 iter num 20\n",
            "loss 0.5305768847465515 average time 0.006750807449999741 iter num 40\n",
            "loss 0.5679640769958496 average time 0.0056820636833322165 iter num 60\n",
            "loss 0.6471869349479675 average time 0.005117546887499458 iter num 80\n",
            "loss 0.3794286847114563 average time 0.004796929229997886 iter num 100\n",
            "loss 0.8126522302627563 average time 0.010159694400005036 iter num 20\n",
            "loss 0.5073408484458923 average time 0.0068242091750036595 iter num 40\n",
            "loss 0.67151939868927 average time 0.005754014050003775 iter num 60\n",
            "loss 0.8913911581039429 average time 0.005201993175001007 iter num 80\n",
            "loss 0.5098953247070312 average time 0.004844734290002179 iter num 100\n",
            "loss 0.5864366292953491 average time 0.009979188749997547 iter num 20\n",
            "loss 0.6021353006362915 average time 0.006687205450000988 iter num 40\n",
            "loss 0.6719624996185303 average time 0.005609407583335724 iter num 60\n",
            "loss 0.2241700142621994 average time 0.005053933025003232 iter num 80\n",
            "loss 0.44907456636428833 average time 0.00472076084999685 iter num 100\n",
            "loss 0.6612914800643921 average time 0.01034234994998542 iter num 20\n",
            "loss 0.8893439769744873 average time 0.006902383324995753 iter num 40\n",
            "loss 1.0604829788208008 average time 0.0058376945166628506 iter num 60\n",
            "loss 0.7477478981018066 average time 0.005296906774998433 iter num 80\n",
            "loss 0.5647362470626831 average time 0.0050396523899996735 iter num 100\n",
            "loss 0.22865097224712372 average time 0.010611258200003703 iter num 20\n",
            "loss 0.473491907119751 average time 0.007118608175002805 iter num 40\n",
            "loss 1.0051939487457275 average time 0.005969078983338249 iter num 60\n",
            "loss 0.4328951835632324 average time 0.00534670162500106 iter num 80\n",
            "loss 0.47005587816238403 average time 0.004980820510000967 iter num 100\n",
            "loss 2.2042288780212402 average time 0.009544934599995258 iter num 20\n",
            "loss 1.4981482028961182 average time 0.006514945100002478 iter num 40\n",
            "loss 0.43896591663360596 average time 0.005459981766671262 iter num 60\n",
            "loss 0.4946422576904297 average time 0.004951092375006283 iter num 80\n",
            "loss 0.39207467436790466 average time 0.004620820570002024 iter num 100\n",
            "loss 1.3927509784698486 average time 0.010105213349987707 iter num 20\n",
            "loss 1.0836012363433838 average time 0.0067253826499921844 iter num 40\n",
            "loss 0.8361766338348389 average time 0.005617140566662708 iter num 60\n",
            "loss 0.13061055541038513 average time 0.005036068587493503 iter num 80\n",
            "loss 1.009683609008789 average time 0.004713648719995262 iter num 100\n",
            "loss 0.9342262148857117 average time 0.008972281650011382 iter num 20\n",
            "loss 1.2623822689056396 average time 0.0061826363500046 iter num 40\n",
            "loss 0.3379325866699219 average time 0.005252716750000748 iter num 60\n",
            "loss 0.9445412755012512 average time 0.004810274912502166 iter num 80\n",
            "loss 0.9505691528320312 average time 0.004537442650002959 iter num 100\n",
            "loss 1.7768827676773071 average time 0.01042489349999869 iter num 20\n",
            "loss 0.4595286250114441 average time 0.006965383149997706 iter num 40\n",
            "loss 1.005466103553772 average time 0.005804526883326844 iter num 60\n",
            "loss 0.19987303018569946 average time 0.0052291844624917875 iter num 80\n",
            "loss 0.28230375051498413 average time 0.004882054709992189 iter num 100\n",
            "loss 0.7143269181251526 average time 0.009915627299994867 iter num 20\n",
            "loss 0.3989025950431824 average time 0.006692225199995505 iter num 40\n",
            "loss 0.4532359540462494 average time 0.005676529216664979 iter num 60\n",
            "loss 0.3292628228664398 average time 0.005188676024998529 iter num 80\n",
            "loss 0.5319730043411255 average time 0.004830395039996347 iter num 100\n",
            "loss 1.1591155529022217 average time 0.0095682912000143 iter num 20\n",
            "loss 2.4636483192443848 average time 0.006496057325009019 iter num 40\n",
            "loss 0.6230465173721313 average time 0.005459491166677329 iter num 60\n",
            "loss 0.7947618961334229 average time 0.004967599400009704 iter num 80\n",
            "loss 0.41114214062690735 average time 0.004654806260008399 iter num 100\n",
            "loss 0.5376075506210327 average time 0.009255450650005059 iter num 20\n",
            "loss 0.5929948091506958 average time 0.006340577250003321 iter num 40\n",
            "loss 0.8115734457969666 average time 0.005336844450005174 iter num 60\n",
            "loss 0.5222504138946533 average time 0.004833994650005025 iter num 80\n",
            "loss 0.6243895292282104 average time 0.0045508603500036314 iter num 100\n",
            "loss 1.0854153633117676 average time 0.009758847849997209 iter num 20\n",
            "loss 1.4582539796829224 average time 0.006843795175004175 iter num 40\n",
            "loss 0.9900718331336975 average time 0.005723801416667129 iter num 60\n",
            "loss 0.2440284639596939 average time 0.0051660183375020095 iter num 80\n",
            "loss 0.2540300786495209 average time 0.004810046809999449 iter num 100\n",
            "loss 3.205009937286377 average time 0.01012462560000813 iter num 20\n",
            "loss 0.8972779512405396 average time 0.0068522502499945405 iter num 40\n",
            "loss 0.4745754897594452 average time 0.005751669083328655 iter num 60\n",
            "loss 0.4343603551387787 average time 0.00522505173749579 iter num 80\n",
            "loss 0.9404284954071045 average time 0.004879683269997485 iter num 100\n",
            "loss 1.6623390913009644 average time 0.00996473044999675 iter num 20\n",
            "loss 0.628715991973877 average time 0.006760536699997033 iter num 40\n",
            "loss 2.182427406311035 average time 0.005676747783333743 iter num 60\n",
            "loss 0.5559107661247253 average time 0.005152253799998618 iter num 80\n",
            "loss 0.4672513008117676 average time 0.0048620094299963055 iter num 100\n",
            "loss 2.3713998794555664 average time 0.010013539899983926 iter num 20\n",
            "loss 0.7709699869155884 average time 0.006640683324994257 iter num 40\n",
            "loss 0.4485815167427063 average time 0.0055189233833289105 iter num 60\n",
            "loss 0.9455987811088562 average time 0.0049478485499989235 iter num 80\n",
            "loss 0.6803804636001587 average time 0.00460484261999909 iter num 100\n",
            "loss 1.6519768238067627 average time 0.00903069034999362 iter num 20\n",
            "loss 0.9026134610176086 average time 0.006141953175011849 iter num 40\n",
            "loss 0.5555865168571472 average time 0.0051880614999997 iter num 60\n",
            "loss 0.5551021099090576 average time 0.00471779281249809 iter num 80\n",
            "loss 0.6197834014892578 average time 0.004426475659995504 iter num 100\n",
            "loss 0.971282422542572 average time 0.00963726104998841 iter num 20\n",
            "loss 0.5980690121650696 average time 0.006478792649991761 iter num 40\n",
            "loss 0.29104650020599365 average time 0.005420535483330014 iter num 60\n",
            "loss 0.1945706307888031 average time 0.004885462137497143 iter num 80\n",
            "loss 0.31518638134002686 average time 0.004587187000000767 iter num 100\n",
            "loss 3.9314517974853516 average time 0.009609356549998439 iter num 20\n",
            "loss 0.565835177898407 average time 0.006521834499997681 iter num 40\n",
            "loss 0.5017335414886475 average time 0.0055129110999966235 iter num 60\n",
            "loss 0.4372069835662842 average time 0.00502557621249764 iter num 80\n",
            "loss 0.5482724905014038 average time 0.004721801850000702 iter num 100\n",
            "loss 5.710554122924805 average time 0.010627888350006743 iter num 20\n",
            "loss 0.535388708114624 average time 0.0069763290000111056 iter num 40\n",
            "loss 0.6723058819770813 average time 0.005806823033344699 iter num 60\n",
            "loss 0.3402647376060486 average time 0.005238307462506952 iter num 80\n",
            "loss 0.417486310005188 average time 0.0048744012900044705 iter num 100\n",
            "loss 1.8154518604278564 average time 0.01074398844997404 iter num 20\n",
            "loss 0.2935226857662201 average time 0.007049523399982149 iter num 40\n",
            "loss 0.6167291402816772 average time 0.005806671249987024 iter num 60\n",
            "loss 0.5904391407966614 average time 0.005252962524987481 iter num 80\n",
            "loss 0.2843460142612457 average time 0.004873868869990475 iter num 100\n",
            "loss 0.8240543603897095 average time 0.010266295300004913 iter num 20\n",
            "loss 0.9248988032341003 average time 0.006853178050008069 iter num 40\n",
            "loss 0.9963093400001526 average time 0.005694891083332247 iter num 60\n",
            "loss 0.23504674434661865 average time 0.005120771299996818 iter num 80\n",
            "loss 0.6622273921966553 average time 0.004792769109994879 iter num 100\n",
            "loss 0.8314087986946106 average time 0.009853797049993318 iter num 20\n",
            "loss 0.7674619555473328 average time 0.006661613574993908 iter num 40\n",
            "loss 0.2111435979604721 average time 0.005569266049999063 iter num 60\n",
            "loss 1.188334584236145 average time 0.004996143749997373 iter num 80\n",
            "loss 0.2358972281217575 average time 0.004675436069998113 iter num 100\n",
            "loss 1.0638684034347534 average time 0.009833852149995437 iter num 20\n",
            "loss 0.44640251994132996 average time 0.006580180174995576 iter num 40\n",
            "loss 0.13424962759017944 average time 0.0054649214833318634 iter num 60\n",
            "loss 0.38120734691619873 average time 0.00493266021250065 iter num 80\n",
            "loss 0.4625341594219208 average time 0.004602109549999796 iter num 100\n",
            "loss 1.2878143787384033 average time 0.009670159449996163 iter num 20\n",
            "loss 1.1718082427978516 average time 0.006492858999999384 iter num 40\n",
            "loss 1.1198570728302002 average time 0.005458152383332996 iter num 60\n",
            "loss 0.6780307292938232 average time 0.0049196497999986375 iter num 80\n",
            "loss 0.8059816956520081 average time 0.004609112439999308 iter num 100\n",
            "loss 0.715556263923645 average time 0.009140116099990792 iter num 20\n",
            "loss 0.5868393182754517 average time 0.006202792749996888 iter num 40\n",
            "loss 0.49118679761886597 average time 0.005222288399998358 iter num 60\n",
            "loss 0.1710488349199295 average time 0.004792492037501006 iter num 80\n",
            "loss 0.6186716556549072 average time 0.004549661659998492 iter num 100\n",
            "loss 1.3070485591888428 average time 0.010413622850001048 iter num 20\n",
            "loss 2.880441188812256 average time 0.0069582177750078245 iter num 40\n",
            "loss 2.178135395050049 average time 0.00578475865000693 iter num 60\n",
            "loss 0.7765498161315918 average time 0.0051886456500000126 iter num 80\n",
            "loss 0.2095029652118683 average time 0.00484432879999872 iter num 100\n",
            "loss 1.67006254196167 average time 0.00994412790000183 iter num 20\n",
            "loss 0.3586347699165344 average time 0.006699441575000265 iter num 40\n",
            "loss 1.1485987901687622 average time 0.005592398183335945 iter num 60\n",
            "loss 0.3168535828590393 average time 0.005021299737497031 iter num 80\n",
            "loss 0.2797115743160248 average time 0.00468893189999676 iter num 100\n",
            "loss 0.42232248187065125 average time 0.00940955079998389 iter num 20\n",
            "loss 4.049475193023682 average time 0.0064211540249885955 iter num 40\n",
            "loss 1.8585937023162842 average time 0.00538237506666898 iter num 60\n",
            "loss 0.4076688885688782 average time 0.004877549312502083 iter num 80\n",
            "loss 0.2425967901945114 average time 0.00458659266000268 iter num 100\n",
            "loss 0.9087957143783569 average time 0.009278811500001894 iter num 20\n",
            "loss 0.4573824405670166 average time 0.0063132312750184385 iter num 40\n",
            "loss 0.7243940830230713 average time 0.005288651516677115 iter num 60\n",
            "loss 0.6845226287841797 average time 0.004803844362503184 iter num 80\n",
            "loss 0.9588279724121094 average time 0.004490632810008038 iter num 100\n",
            "loss 0.9489659070968628 average time 0.009491085949997568 iter num 20\n",
            "loss 1.2934441566467285 average time 0.006425549675000752 iter num 40\n",
            "loss 0.24115177989006042 average time 0.005387611400002849 iter num 60\n",
            "loss 0.7138615250587463 average time 0.00486309822500317 iter num 80\n",
            "loss 0.525180459022522 average time 0.004630289950000588 iter num 100\n",
            "loss 1.05697762966156 average time 0.009860758349998378 iter num 20\n",
            "loss 0.5056946873664856 average time 0.006684440250000989 iter num 40\n",
            "loss 0.29509544372558594 average time 0.0056709738000051855 iter num 60\n",
            "loss 0.39512789249420166 average time 0.0051110214875052405 iter num 80\n",
            "loss 0.5079549551010132 average time 0.004788109310003392 iter num 100\n",
            "loss 0.31256771087646484 average time 0.009848944100008339 iter num 20\n",
            "loss 0.4656042456626892 average time 0.006640046350008788 iter num 40\n",
            "loss 0.9673562049865723 average time 0.005611824400002282 iter num 60\n",
            "loss 1.294098973274231 average time 0.005051706062504024 iter num 80\n",
            "loss 0.09085211157798767 average time 0.004697299320000638 iter num 100\n",
            "loss 0.6775301694869995 average time 0.00967801395000265 iter num 20\n",
            "loss 0.6621866822242737 average time 0.006496160874993962 iter num 40\n",
            "loss 0.3278292417526245 average time 0.005449256349995342 iter num 60\n",
            "loss 0.1926872730255127 average time 0.004901029674998369 iter num 80\n",
            "loss 0.2897084951400757 average time 0.0045736484299993664 iter num 100\n",
            "loss 0.6759405136108398 average time 0.009238748249998707 iter num 20\n",
            "loss 0.4365236759185791 average time 0.006254055299996253 iter num 40\n",
            "loss 0.3065252900123596 average time 0.005299129699996759 iter num 60\n",
            "loss 0.3106193542480469 average time 0.004790344512494471 iter num 80\n",
            "loss 0.3479437232017517 average time 0.004491166039993004 iter num 100\n",
            "loss 0.6121498346328735 average time 0.00999572679999119 iter num 20\n",
            "loss 0.6382074356079102 average time 0.006684645875003526 iter num 40\n",
            "loss 0.41869258880615234 average time 0.005550247216670338 iter num 60\n",
            "loss 0.6507331728935242 average time 0.004974532887504779 iter num 80\n",
            "loss 0.4280344843864441 average time 0.004636760620002178 iter num 100\n",
            "loss 2.081449031829834 average time 0.010247292999986257 iter num 20\n",
            "loss 1.2024792432785034 average time 0.006811391024996283 iter num 40\n",
            "loss 0.210861474275589 average time 0.0057381220833292446 iter num 60\n",
            "loss 0.8279945850372314 average time 0.005183976762492648 iter num 80\n",
            "loss 0.24074018001556396 average time 0.004830635249994657 iter num 100\n",
            "loss 0.11959432065486908 average time 0.009695366850013442 iter num 20\n",
            "loss 0.8769055604934692 average time 0.006578992025012553 iter num 40\n",
            "loss 0.37029749155044556 average time 0.005515701450010132 iter num 60\n",
            "loss 0.8191491365432739 average time 0.004983030825007973 iter num 80\n",
            "loss 0.5218641757965088 average time 0.004684466610004847 iter num 100\n",
            "loss 0.5572215914726257 average time 0.009588543400002435 iter num 20\n",
            "loss 0.3715476393699646 average time 0.006511105950005458 iter num 40\n",
            "loss 0.7327344417572021 average time 0.005517383733331371 iter num 60\n",
            "loss 0.34894344210624695 average time 0.0049965525750025105 iter num 80\n",
            "loss 0.4491652548313141 average time 0.004686448800001699 iter num 100\n",
            "loss 2.800748825073242 average time 0.009259974900010093 iter num 20\n",
            "loss 1.162859559059143 average time 0.006452845724996337 iter num 40\n",
            "loss 0.65943843126297 average time 0.0054276707833309954 iter num 60\n",
            "loss 0.20143386721611023 average time 0.004942300499993735 iter num 80\n",
            "loss 0.48753196001052856 average time 0.004663304309993919 iter num 100\n",
            "loss 0.339252769947052 average time 0.00972020779999525 iter num 20\n",
            "loss 1.8537180423736572 average time 0.006581138575000978 iter num 40\n",
            "loss 0.4968681037425995 average time 0.005601021299999805 iter num 60\n",
            "loss 0.7201148271560669 average time 0.005082152574999554 iter num 80\n",
            "loss 0.15154315531253815 average time 0.0047819334999985585 iter num 100\n",
            "loss 0.450898677110672 average time 0.01082186989997922 iter num 20\n",
            "loss 0.32442110776901245 average time 0.007282451374990728 iter num 40\n",
            "loss 0.24825957417488098 average time 0.0061503545166620675 iter num 60\n",
            "loss 0.4595244526863098 average time 0.005545440487496478 iter num 80\n",
            "loss 0.27249211072921753 average time 0.005198299219999853 iter num 100\n",
            "loss 1.0886362791061401 average time 0.010592137500020726 iter num 20\n",
            "loss 0.5747177004814148 average time 0.007299365050016604 iter num 40\n",
            "loss 0.38526028394699097 average time 0.006191627766672051 iter num 60\n",
            "loss 0.28199702501296997 average time 0.005614056125006072 iter num 80\n",
            "loss 0.4045296609401703 average time 0.005253387090003798 iter num 100\n",
            "loss 0.8513453006744385 average time 0.010363077949989474 iter num 20\n",
            "loss 0.9894232153892517 average time 0.007118874924992724 iter num 40\n",
            "loss 0.34987401962280273 average time 0.005973689049991056 iter num 60\n",
            "loss 0.38386523723602295 average time 0.005393088599990392 iter num 80\n",
            "loss 0.23659731447696686 average time 0.005002002419992095 iter num 100\n",
            "loss 1.5790371894836426 average time 0.010026185000003806 iter num 20\n",
            "loss 1.0425047874450684 average time 0.006760067024993077 iter num 40\n",
            "loss 0.45950862765312195 average time 0.005666663499994229 iter num 60\n",
            "loss 0.5855303406715393 average time 0.005127521437489691 iter num 80\n",
            "loss 0.38039258122444153 average time 0.004802014839992807 iter num 100\n",
            "loss 0.988252580165863 average time 0.010955400950012972 iter num 20\n",
            "loss 2.261323928833008 average time 0.007159470475028229 iter num 40\n",
            "loss 0.28238165378570557 average time 0.005954595533338155 iter num 60\n",
            "loss 0.6450009346008301 average time 0.0053896580625036 iter num 80\n",
            "loss 0.6793113350868225 average time 0.004995398180008124 iter num 100\n",
            "loss 2.987095594406128 average time 0.009430259499993099 iter num 20\n",
            "loss 0.13624846935272217 average time 0.006463442999984181 iter num 40\n",
            "loss 0.9797012805938721 average time 0.005448745833329364 iter num 60\n",
            "loss 0.25172287225723267 average time 0.004925446462502236 iter num 80\n",
            "loss 0.6860171556472778 average time 0.004612020750009833 iter num 100\n",
            "loss 1.6075491905212402 average time 0.009432503300013195 iter num 20\n",
            "loss 0.3108002543449402 average time 0.006366074074998096 iter num 40\n",
            "loss 0.2683663070201874 average time 0.005353098200005965 iter num 60\n",
            "loss 0.28860941529273987 average time 0.004877380600004244 iter num 80\n",
            "loss 0.25845929980278015 average time 0.004573605880000287 iter num 100\n",
            "loss 0.37900257110595703 average time 0.009248316250011612 iter num 20\n",
            "loss 0.8260353803634644 average time 0.006384491650021573 iter num 40\n",
            "loss 0.5053998231887817 average time 0.005415242466684352 iter num 60\n",
            "loss 0.27034807205200195 average time 0.004935364775016637 iter num 80\n",
            "loss 0.40049028396606445 average time 0.004657139030016424 iter num 100\n",
            "loss 1.061137080192566 average time 0.010808861549969606 iter num 20\n",
            "loss 0.4681350290775299 average time 0.007164655174983636 iter num 40\n",
            "loss 1.5269877910614014 average time 0.0059354182166581875 iter num 60\n",
            "loss 0.505298376083374 average time 0.005310367199987809 iter num 80\n",
            "loss 0.21666431427001953 average time 0.0049424947499869636 iter num 100\n",
            "loss 0.7974693775177002 average time 0.009551963449996492 iter num 20\n",
            "loss 0.18599726259708405 average time 0.006500987175007822 iter num 40\n",
            "loss 0.5313519835472107 average time 0.0054800193666703 iter num 60\n",
            "loss 0.3454414904117584 average time 0.004987512412500905 iter num 80\n",
            "loss 0.19338321685791016 average time 0.00465272914000252 iter num 100\n",
            "loss 1.295440673828125 average time 0.009608560749973094 iter num 20\n",
            "loss 0.7644883394241333 average time 0.006468849549975175 iter num 40\n",
            "loss 0.40085533261299133 average time 0.0054036629333268135 iter num 60\n",
            "loss 0.3569311499595642 average time 0.0048717955749992825 iter num 80\n",
            "loss 0.32046741247177124 average time 0.004568407500005378 iter num 100\n",
            "loss 0.23591525852680206 average time 0.009208456850058156 iter num 20\n",
            "loss 0.3126954734325409 average time 0.0062765211250280116 iter num 40\n",
            "loss 0.620962381362915 average time 0.0053467932000065355 iter num 60\n",
            "loss 0.2354244887828827 average time 0.004824776862503199 iter num 80\n",
            "loss 0.13691920042037964 average time 0.004532704709999962 iter num 100\n",
            "loss 0.6915625333786011 average time 0.009520802849988286 iter num 20\n",
            "loss 0.21669167280197144 average time 0.006442953299978171 iter num 40\n",
            "loss 0.5520849823951721 average time 0.005487489949977468 iter num 60\n",
            "loss 0.3668425679206848 average time 0.00502516492498728 iter num 80\n",
            "loss 0.23080620169639587 average time 0.004729231629989954 iter num 100\n",
            "loss 0.3593093156814575 average time 0.00986300359999177 iter num 20\n",
            "loss 0.8218032121658325 average time 0.0066623470999843445 iter num 40\n",
            "loss 0.3114165663719177 average time 0.005590312749992184 iter num 60\n",
            "loss 0.6685993671417236 average time 0.005042208099999357 iter num 80\n",
            "loss 0.20707157254219055 average time 0.004739688029997069 iter num 100\n",
            "loss 0.7616968750953674 average time 0.010047114300004979 iter num 20\n",
            "loss 0.8299391269683838 average time 0.006719550950003849 iter num 40\n",
            "loss 0.4755590260028839 average time 0.005657329749999463 iter num 60\n",
            "loss 0.2901574671268463 average time 0.005077034712496697 iter num 80\n",
            "loss 0.19051051139831543 average time 0.004729467729994212 iter num 100\n",
            "loss 0.4383205771446228 average time 0.009595271250020687 iter num 20\n",
            "loss 0.25913023948669434 average time 0.006537133100005121 iter num 40\n",
            "loss 0.3141217827796936 average time 0.0055041685000029855 iter num 60\n",
            "loss 0.18899966776371002 average time 0.004958442675004449 iter num 80\n",
            "loss 0.44077247381210327 average time 0.004639287739998963 iter num 100\n",
            "loss 0.5917841196060181 average time 0.009395948599990333 iter num 20\n",
            "loss 0.7022209167480469 average time 0.00634882132499115 iter num 40\n",
            "loss 0.9202232360839844 average time 0.005339052899989838 iter num 60\n",
            "loss 0.3306218087673187 average time 0.0048431275124954706 iter num 80\n",
            "loss 0.5200611352920532 average time 0.004530412760002492 iter num 100\n",
            "loss 0.5277769565582275 average time 0.009742570349999369 iter num 20\n",
            "loss 0.4268196225166321 average time 0.006495196349982279 iter num 40\n",
            "loss 1.1663687229156494 average time 0.005456116266653529 iter num 60\n",
            "loss 0.1996774524450302 average time 0.004950680049989842 iter num 80\n",
            "loss 0.3423091769218445 average time 0.004648855799994181 iter num 100\n",
            "loss 1.0007364749908447 average time 0.010045519250002143 iter num 20\n",
            "loss 0.3741980493068695 average time 0.0067514453999990565 iter num 40\n",
            "loss 0.41421887278556824 average time 0.005698013633332266 iter num 60\n",
            "loss 0.4141826033592224 average time 0.005145483512504256 iter num 80\n",
            "loss 0.30636370182037354 average time 0.004819319609998729 iter num 100\n",
            "loss 0.7765288352966309 average time 0.010908422500017423 iter num 20\n",
            "loss 0.4690137803554535 average time 0.0072190218500168156 iter num 40\n",
            "loss 0.29240572452545166 average time 0.005981583016675055 iter num 60\n",
            "loss 0.5281875729560852 average time 0.005338396325004169 iter num 80\n",
            "loss 0.4707373380661011 average time 0.004977145850002671 iter num 100\n",
            "loss 0.5659292936325073 average time 0.009515806050012543 iter num 20\n",
            "loss 0.6073254346847534 average time 0.006581227775018306 iter num 40\n",
            "loss 0.28681227564811707 average time 0.005585585766675649 iter num 60\n",
            "loss 0.30060747265815735 average time 0.005095257875012749 iter num 80\n",
            "loss 0.4638482332229614 average time 0.004811986630013507 iter num 100\n",
            "loss 0.7728534936904907 average time 0.010138051100000212 iter num 20\n",
            "loss 0.25184744596481323 average time 0.006762487325016764 iter num 40\n",
            "loss 0.9673210382461548 average time 0.005656390566684877 iter num 60\n",
            "loss 0.20415109395980835 average time 0.005083443275015043 iter num 80\n",
            "loss 0.12101434916257858 average time 0.0047270961900153455 iter num 100\n",
            "loss 0.3603084683418274 average time 0.009276539600011801 iter num 20\n",
            "loss 0.39014214277267456 average time 0.00630850687500697 iter num 40\n",
            "loss 0.4918196201324463 average time 0.00537268136667232 iter num 60\n",
            "loss 0.24650995433330536 average time 0.004964764312501302 iter num 80\n",
            "loss 0.2633521854877472 average time 0.004673687679999147 iter num 100\n",
            "loss 0.5853104591369629 average time 0.010001704900003006 iter num 20\n",
            "loss 0.2795726954936981 average time 0.00672677092501317 iter num 40\n",
            "loss 0.9788452982902527 average time 0.0056496894166760585 iter num 60\n",
            "loss 0.44837063550949097 average time 0.005115115987507579 iter num 80\n",
            "loss 0.5281455516815186 average time 0.004787284410012944 iter num 100\n",
            "loss 0.5471491813659668 average time 0.010318211999981486 iter num 20\n",
            "loss 2.159097194671631 average time 0.006912109025012114 iter num 40\n",
            "loss 0.5210928916931152 average time 0.005736219499999607 iter num 60\n",
            "loss 0.7470420002937317 average time 0.005166255062499658 iter num 80\n",
            "loss 0.1712697446346283 average time 0.004849787200002993 iter num 100\n",
            "loss 0.3861750364303589 average time 0.009348728200006918 iter num 20\n",
            "loss 0.5899218320846558 average time 0.006380440324988967 iter num 40\n",
            "loss 0.8533933162689209 average time 0.005402820400009508 iter num 60\n",
            "loss 0.19768798351287842 average time 0.004880023750007467 iter num 80\n",
            "loss 0.29633286595344543 average time 0.004562164870008018 iter num 100\n",
            "loss 0.3222145438194275 average time 0.00958127730001479 iter num 20\n",
            "loss 0.5073778629302979 average time 0.006425570150014437 iter num 40\n",
            "loss 0.465177446603775 average time 0.005420107533351862 iter num 60\n",
            "loss 0.39233729243278503 average time 0.004892170787510963 iter num 80\n",
            "loss 0.367522656917572 average time 0.004622111670009872 iter num 100\n",
            "loss 0.3639073967933655 average time 0.009651848249984597 iter num 20\n",
            "loss 1.6431307792663574 average time 0.006512088825002138 iter num 40\n",
            "loss 0.16489166021347046 average time 0.0054205177666820726 iter num 60\n",
            "loss 0.4699767529964447 average time 0.004892033850001099 iter num 80\n",
            "loss 0.2734413743019104 average time 0.004607630740003969 iter num 100\n",
            "loss 0.29613709449768066 average time 0.010586011449970557 iter num 20\n",
            "loss 0.3171975910663605 average time 0.007020654274975868 iter num 40\n",
            "loss 0.3893558084964752 average time 0.005852879549979662 iter num 60\n",
            "loss 0.3886182904243469 average time 0.005261614349984711 iter num 80\n",
            "loss 1.0475106239318848 average time 0.004906947429988122 iter num 100\n",
            "loss 0.7791876792907715 average time 0.010031691300002876 iter num 20\n",
            "loss 0.3846944570541382 average time 0.006720174749995067 iter num 40\n",
            "loss 0.5157021284103394 average time 0.0056285961999947174 iter num 60\n",
            "loss 0.7303544282913208 average time 0.005061319050000179 iter num 80\n",
            "loss 0.3225734233856201 average time 0.004709265979997781 iter num 100\n",
            "loss 3.0674455165863037 average time 0.009391814699995393 iter num 20\n",
            "loss 0.37176841497421265 average time 0.00639660427497688 iter num 40\n",
            "loss 0.4986596703529358 average time 0.005406841849980993 iter num 60\n",
            "loss 0.27060991525650024 average time 0.004930132387494268 iter num 80\n",
            "loss 0.23113317787647247 average time 0.0047534290299995514 iter num 100\n",
            "loss 0.5781071782112122 average time 0.010584276999986741 iter num 20\n",
            "loss 0.4572521448135376 average time 0.007043815499974926 iter num 40\n",
            "loss 0.4878076910972595 average time 0.00584308101666314 iter num 60\n",
            "loss 0.42120805382728577 average time 0.005264183112498699 iter num 80\n",
            "loss 0.3167440891265869 average time 0.00491619219000313 iter num 100\n",
            "loss 0.2597481608390808 average time 0.009779836949996934 iter num 20\n",
            "loss 2.9880504608154297 average time 0.006554969250004206 iter num 40\n",
            "loss 1.2114646434783936 average time 0.005468152266678317 iter num 60\n",
            "loss 0.6323018074035645 average time 0.0049908207750121395 iter num 80\n",
            "loss 0.21105659008026123 average time 0.004718487600016487 iter num 100\n",
            "loss 0.4019705653190613 average time 0.009186103449997063 iter num 20\n",
            "loss 0.23559994995594025 average time 0.006234817999990127 iter num 40\n",
            "loss 0.3658043444156647 average time 0.005320869266662006 iter num 60\n",
            "loss 0.3793339431285858 average time 0.004812610549996066 iter num 80\n",
            "loss 0.16632354259490967 average time 0.004510005539993926 iter num 100\n",
            "loss 2.15736722946167 average time 0.009067205749977348 iter num 20\n",
            "loss 0.5858379602432251 average time 0.0061856522999960365 iter num 40\n",
            "loss 0.31476402282714844 average time 0.0052172142500012345 iter num 60\n",
            "loss 0.35984671115875244 average time 0.004738403387511881 iter num 80\n",
            "loss 0.3077943027019501 average time 0.004462803560008979 iter num 100\n",
            "loss 0.44838547706604004 average time 0.008934506499997497 iter num 20\n",
            "loss 0.5169143080711365 average time 0.006165950025007305 iter num 40\n",
            "loss 0.5757893919944763 average time 0.005270740033328517 iter num 60\n",
            "loss 0.37590834498405457 average time 0.004805117162499073 iter num 80\n",
            "loss 0.21067409217357635 average time 0.004521711220004363 iter num 100\n",
            "loss 0.8925448656082153 average time 0.010912559949997559 iter num 20\n",
            "loss 0.15501689910888672 average time 0.007180221324989589 iter num 40\n",
            "loss 0.2467913031578064 average time 0.005947157449982873 iter num 60\n",
            "loss 0.2673627436161041 average time 0.005321574224981873 iter num 80\n",
            "loss 0.24207079410552979 average time 0.0049429174399779185 iter num 100\n",
            "loss 0.3585328757762909 average time 0.010606499399966652 iter num 20\n",
            "loss 0.37856435775756836 average time 0.006969678824998482 iter num 40\n",
            "loss 0.1658552587032318 average time 0.005762393716656789 iter num 60\n",
            "loss 0.5892899036407471 average time 0.00515212627499011 iter num 80\n",
            "loss 0.11304916441440582 average time 0.0047844143599877495 iter num 100\n",
            "loss 0.6094356775283813 average time 0.009637054700010594 iter num 20\n",
            "loss 0.4138526916503906 average time 0.006559033000002046 iter num 40\n",
            "loss 0.3074694275856018 average time 0.005470599400014938 iter num 60\n",
            "loss 0.20878756046295166 average time 0.0049327781250070755 iter num 80\n",
            "loss 0.31105366349220276 average time 0.0046003524100046884 iter num 100\n",
            "loss 0.40041351318359375 average time 0.009435792149986355 iter num 20\n",
            "loss 1.5392026901245117 average time 0.00633758534998492 iter num 40\n",
            "loss 0.5258551836013794 average time 0.0053448008999869975 iter num 60\n",
            "loss 0.20810170471668243 average time 0.004859935662494763 iter num 80\n",
            "loss 0.4807361662387848 average time 0.004545336669998505 iter num 100\n",
            "loss 1.070688247680664 average time 0.009297839249995832 iter num 20\n",
            "loss 0.3055136203765869 average time 0.006395986499995843 iter num 40\n",
            "loss 0.42446887493133545 average time 0.005401664866667488 iter num 60\n",
            "loss 0.1818522959947586 average time 0.004914170087505454 iter num 80\n",
            "loss 0.25780004262924194 average time 0.004619129869997778 iter num 100\n",
            "loss 0.7226349711418152 average time 0.010452161250043446 iter num 20\n",
            "loss 0.4075643718242645 average time 0.006977283225023711 iter num 40\n",
            "loss 0.5870192646980286 average time 0.005805159700025797 iter num 60\n",
            "loss 0.4215659499168396 average time 0.005235000862523975 iter num 80\n",
            "loss 0.23907093703746796 average time 0.00488099057001591 iter num 100\n",
            "loss 0.4888903498649597 average time 0.010225917199988999 iter num 20\n",
            "loss 0.30853235721588135 average time 0.00686595824998335 iter num 40\n",
            "loss 0.40816304087638855 average time 0.005696716566649229 iter num 60\n",
            "loss 0.6979381442070007 average time 0.005096995174994845 iter num 80\n",
            "loss 0.14964236319065094 average time 0.004736715450001157 iter num 100\n",
            "loss 1.695237398147583 average time 0.009726334149968352 iter num 20\n",
            "loss 0.6920648813247681 average time 0.006577523724979528 iter num 40\n",
            "loss 0.3159937560558319 average time 0.005484832533299292 iter num 60\n",
            "loss 0.43902692198753357 average time 0.004935853649971023 iter num 80\n",
            "loss 0.3082560896873474 average time 0.004601050109984044 iter num 100\n",
            "loss 0.3906436860561371 average time 0.009870944500028145 iter num 20\n",
            "loss 1.4693400859832764 average time 0.0066203036000388234 iter num 40\n",
            "loss 0.6288389563560486 average time 0.005584589916694919 iter num 60\n",
            "loss 0.283184289932251 average time 0.0050498303250321895 iter num 80\n",
            "loss 0.228244811296463 average time 0.004721600840032352 iter num 100\n",
            "loss 0.2643846273422241 average time 0.009679469249988415 iter num 20\n",
            "loss 0.14653626084327698 average time 0.006541296824980236 iter num 40\n",
            "loss 0.20781590044498444 average time 0.005482535283310123 iter num 60\n",
            "loss 0.25472748279571533 average time 0.004977716412480504 iter num 80\n",
            "loss 0.29967200756073 average time 0.004681490429979931 iter num 100\n",
            "loss 0.9826546907424927 average time 0.010450636350014975 iter num 20\n",
            "loss 0.35680943727493286 average time 0.006937694225013047 iter num 40\n",
            "loss 0.466920405626297 average time 0.005868672100010978 iter num 60\n",
            "loss 0.25981539487838745 average time 0.005249099675009461 iter num 80\n",
            "loss 0.22996805608272552 average time 0.004887462450003568 iter num 100\n",
            "loss 0.5451122522354126 average time 0.009917952150010479 iter num 20\n",
            "loss 0.6537463068962097 average time 0.006703335000025845 iter num 40\n",
            "loss 0.9101372957229614 average time 0.0055770303166771855 iter num 60\n",
            "loss 0.712082028388977 average time 0.0050058198750036805 iter num 80\n",
            "loss 0.6105481386184692 average time 0.0046532049599977655 iter num 100\n",
            "loss 0.6883935928344727 average time 0.009942052099995635 iter num 20\n",
            "loss 0.5696297883987427 average time 0.006596207624983208 iter num 40\n",
            "loss 0.4452914893627167 average time 0.005516264983312643 iter num 60\n",
            "loss 0.1897859275341034 average time 0.005031901249984117 iter num 80\n",
            "loss 0.15349216759204865 average time 0.004714115339975251 iter num 100\n",
            "loss 0.5509151220321655 average time 0.009754873100007444 iter num 20\n",
            "loss 6.026438236236572 average time 0.006542528874990694 iter num 40\n",
            "loss 0.8953703045845032 average time 0.005480379849992308 iter num 60\n",
            "loss 0.22633624076843262 average time 0.0049361537499976295 iter num 80\n",
            "loss 0.14168544113636017 average time 0.004621484729998428 iter num 100\n",
            "loss 0.2747390866279602 average time 0.009949554450008691 iter num 20\n",
            "loss 0.49966371059417725 average time 0.006637135125004079 iter num 40\n",
            "loss 0.1039634570479393 average time 0.005512148566666989 iter num 60\n",
            "loss 0.15686991810798645 average time 0.004985169287493818 iter num 80\n",
            "loss 0.2944110929965973 average time 0.004680344839989629 iter num 100\n",
            "loss 0.32048922777175903 average time 0.010293735549987559 iter num 20\n",
            "loss 0.21295049786567688 average time 0.0069337977500083525 iter num 40\n",
            "loss 0.4703265428543091 average time 0.00583366673333785 iter num 60\n",
            "loss 0.24218258261680603 average time 0.005248200787499968 iter num 80\n",
            "loss 0.18558108806610107 average time 0.004897398700002213 iter num 100\n",
            "loss 0.27249085903167725 average time 0.010396132899995792 iter num 20\n",
            "loss 0.26359790563583374 average time 0.00699828907500546 iter num 40\n",
            "loss 0.4449206590652466 average time 0.005812342233332402 iter num 60\n",
            "loss 0.4149395525455475 average time 0.005194239487508412 iter num 80\n",
            "loss 0.16474351286888123 average time 0.004810666170008062 iter num 100\n",
            "loss 0.4643494784832001 average time 0.009635759050013348 iter num 20\n",
            "loss 0.7272893190383911 average time 0.0066532886750110265 iter num 40\n",
            "loss 0.17523333430290222 average time 0.0056076457500050005 iter num 60\n",
            "loss 0.43331095576286316 average time 0.005110822825000127 iter num 80\n",
            "loss 0.515638530254364 average time 0.004819349690001218 iter num 100\n",
            "loss 0.08812718093395233 average time 0.010644912749967261 iter num 20\n",
            "loss 0.150698721408844 average time 0.007098379199993588 iter num 40\n",
            "loss 0.2752487361431122 average time 0.005913573566670038 iter num 60\n",
            "loss 0.22121404111385345 average time 0.00540415671249832 iter num 80\n",
            "loss 0.23374740779399872 average time 0.005084016009998322 iter num 100\n",
            "loss 0.5133414268493652 average time 0.009517458000027545 iter num 20\n",
            "loss 0.2372036874294281 average time 0.0064311157000076944 iter num 40\n",
            "loss 0.7219923734664917 average time 0.005438396100006079 iter num 60\n",
            "loss 0.35845229029655457 average time 0.004929793400006588 iter num 80\n",
            "loss 0.531366229057312 average time 0.004619772080013717 iter num 100\n",
            "loss 2.357755184173584 average time 0.009784615750027115 iter num 20\n",
            "loss 0.05781742185354233 average time 0.006611806525029351 iter num 40\n",
            "loss 0.1456684172153473 average time 0.005612118650026332 iter num 60\n",
            "loss 0.17849645018577576 average time 0.005051138175019787 iter num 80\n",
            "loss 0.43062764406204224 average time 0.004719186840018211 iter num 100\n",
            "loss 0.9490305781364441 average time 0.009820953349969842 iter num 20\n",
            "loss 0.8412976861000061 average time 0.006649733249980727 iter num 40\n",
            "loss 0.3098669946193695 average time 0.005588540166657671 iter num 60\n",
            "loss 0.36982136964797974 average time 0.00507201297499762 iter num 80\n",
            "loss 0.1856273114681244 average time 0.004732688499993856 iter num 100\n",
            "loss 0.16594426333904266 average time 0.010105548449996605 iter num 20\n",
            "loss 0.43204861879348755 average time 0.00685906042497777 iter num 40\n",
            "loss 0.17047160863876343 average time 0.005759728766671894 iter num 60\n",
            "loss 0.0957077294588089 average time 0.005235557575008443 iter num 80\n",
            "loss 0.36057648062705994 average time 0.004903633360006552 iter num 100\n",
            "loss 0.2980045974254608 average time 0.009983350000015889 iter num 20\n",
            "loss 0.4893631041049957 average time 0.006887811900008955 iter num 40\n",
            "loss 0.31308650970458984 average time 0.005834627816674735 iter num 60\n",
            "loss 0.3245002031326294 average time 0.005278509525001596 iter num 80\n",
            "loss 0.3438546657562256 average time 0.004913678500001879 iter num 100\n",
            "loss 0.32766592502593994 average time 0.010148169299975507 iter num 20\n",
            "loss 0.260830283164978 average time 0.006737648374974014 iter num 40\n",
            "loss 0.7036334276199341 average time 0.005583931183309687 iter num 60\n",
            "loss 0.26554161310195923 average time 0.005014899412481099 iter num 80\n",
            "loss 0.2516055107116699 average time 0.004660273329984648 iter num 100\n",
            "loss 0.534535825252533 average time 0.009434632050022174 iter num 20\n",
            "loss 0.43281883001327515 average time 0.006357600074994707 iter num 40\n",
            "loss 0.6998715400695801 average time 0.005353677999998278 iter num 60\n",
            "loss 0.16238132119178772 average time 0.004845805275007819 iter num 80\n",
            "loss 0.23342016339302063 average time 0.00452612704000785 iter num 100\n",
            "loss 0.43863895535469055 average time 0.009511456000041107 iter num 20\n",
            "loss 1.0554124116897583 average time 0.006358367675022692 iter num 40\n",
            "loss 0.3095342516899109 average time 0.005307021400009641 iter num 60\n",
            "loss 0.2127304971218109 average time 0.004800180012506416 iter num 80\n",
            "loss 0.23957300186157227 average time 0.004495702120009355 iter num 100\n",
            "loss 0.3666706681251526 average time 0.009826104050000594 iter num 20\n",
            "loss 0.5264432430267334 average time 0.00655099547499276 iter num 40\n",
            "loss 0.4815205931663513 average time 0.005495900683335246 iter num 60\n",
            "loss 0.22924238443374634 average time 0.004973242824999602 iter num 80\n",
            "loss 0.14956215023994446 average time 0.00467286565999757 iter num 100\n",
            "loss 0.4997597634792328 average time 0.01028088624997281 iter num 20\n",
            "loss 0.20222961902618408 average time 0.006864387224993607 iter num 40\n",
            "loss 0.4594084620475769 average time 0.00571037654998842 iter num 60\n",
            "loss 0.13914284110069275 average time 0.0051439167124925685 iter num 80\n",
            "loss 0.3124896287918091 average time 0.004815718389991162 iter num 100\n",
            "loss 0.3620798587799072 average time 0.01055456894996496 iter num 20\n",
            "loss 0.44037437438964844 average time 0.00698741162495935 iter num 40\n",
            "loss 0.08657597750425339 average time 0.005753628199969777 iter num 60\n",
            "loss 0.15809054672718048 average time 0.005134303724983624 iter num 80\n",
            "loss 0.32337623834609985 average time 0.004761098459994173 iter num 100\n",
            "loss 1.091956377029419 average time 0.009374224049986423 iter num 20\n",
            "loss 0.4006423354148865 average time 0.006339806574999329 iter num 40\n",
            "loss 0.20670299232006073 average time 0.005308527766654455 iter num 60\n",
            "loss 0.28350234031677246 average time 0.004859514137496035 iter num 80\n",
            "loss 0.1941925585269928 average time 0.004537477860001218 iter num 100\n",
            "loss 0.6792622804641724 average time 0.00915031364997958 iter num 20\n",
            "loss 0.4199026823043823 average time 0.006189052549990493 iter num 40\n",
            "loss 1.1740261316299438 average time 0.0052047537666605114 iter num 60\n",
            "loss 0.5333625078201294 average time 0.004714364287488592 iter num 80\n",
            "loss 0.27402424812316895 average time 0.0044348524899987755 iter num 100\n",
            "loss 0.21056929230690002 average time 0.009280917000000954 iter num 20\n",
            "loss 0.6613612174987793 average time 0.0062999639750046296 iter num 40\n",
            "loss 0.5207424163818359 average time 0.005292282016671379 iter num 60\n",
            "loss 0.2646998167037964 average time 0.0048259827624974605 iter num 80\n",
            "loss 0.24996483325958252 average time 0.004544890759989357 iter num 100\n",
            "loss 0.7391669750213623 average time 0.010202526900025077 iter num 20\n",
            "loss 0.3870067000389099 average time 0.006788870775017131 iter num 40\n",
            "loss 0.4756491780281067 average time 0.005671114700021462 iter num 60\n",
            "loss 0.41445282101631165 average time 0.005101163700010148 iter num 80\n",
            "loss 0.26263427734375 average time 0.0047554302400158125 iter num 100\n",
            "loss 0.2698083519935608 average time 0.010063023799989423 iter num 20\n",
            "loss 2.9110500812530518 average time 0.0067245083499869905 iter num 40\n",
            "loss 0.37081021070480347 average time 0.005569036716663808 iter num 60\n",
            "loss 0.23192569613456726 average time 0.005015211162495347 iter num 80\n",
            "loss 0.1586296409368515 average time 0.004683378269999139 iter num 100\n",
            "loss 1.4176886081695557 average time 0.009010567050006557 iter num 20\n",
            "loss 1.068206548690796 average time 0.006153566775003583 iter num 40\n",
            "loss 0.4516183137893677 average time 0.005206612816668136 iter num 60\n",
            "loss 0.39580076932907104 average time 0.004745230775000664 iter num 80\n",
            "loss 0.3270646631717682 average time 0.004446715850003784 iter num 100\n",
            "loss 0.23659074306488037 average time 0.008973649400013528 iter num 20\n",
            "loss 0.1606081873178482 average time 0.006104881100014836 iter num 40\n",
            "loss 0.33601611852645874 average time 0.005154031916678529 iter num 60\n",
            "loss 0.25526919960975647 average time 0.004722279612508373 iter num 80\n",
            "loss 0.6023150086402893 average time 0.004432226460007769 iter num 100\n",
            "loss 0.5155330896377563 average time 0.009356218849995912 iter num 20\n",
            "loss 0.32988226413726807 average time 0.0063296816249931 iter num 40\n",
            "loss 0.22390440106391907 average time 0.005333746166653933 iter num 60\n",
            "loss 0.3171321153640747 average time 0.004830252762485543 iter num 80\n",
            "loss 0.13879048824310303 average time 0.004537683409989768 iter num 100\n",
            "loss 0.19439615309238434 average time 0.011036438949997774 iter num 20\n",
            "loss 1.404973030090332 average time 0.007284795874994643 iter num 40\n",
            "loss 0.35666605830192566 average time 0.005983337600014238 iter num 60\n",
            "loss 0.308449923992157 average time 0.005339793150008631 iter num 80\n",
            "loss 0.36443787813186646 average time 0.004964427740001156 iter num 100\n",
            "loss 0.9278623461723328 average time 0.010371244649979872 iter num 20\n",
            "loss 1.5104734897613525 average time 0.00687049927499288 iter num 40\n",
            "loss 0.4657546877861023 average time 0.005724597416656252 iter num 60\n",
            "loss 0.39152538776397705 average time 0.005114659424987167 iter num 80\n",
            "loss 0.24945783615112305 average time 0.004761397759996271 iter num 100\n",
            "loss 0.2705222964286804 average time 0.009432370999991235 iter num 20\n",
            "loss 0.35669946670532227 average time 0.0063341711749899336 iter num 40\n",
            "loss 0.5537200570106506 average time 0.005314331966663606 iter num 60\n",
            "loss 0.2480449676513672 average time 0.0048303654875041955 iter num 80\n",
            "loss 0.2872990369796753 average time 0.004520341820009435 iter num 100\n",
            "loss 0.43704667687416077 average time 0.010199631049977143 iter num 20\n",
            "loss 0.3385846018791199 average time 0.00672905954998555 iter num 40\n",
            "loss 0.41656240820884705 average time 0.005552860816646898 iter num 60\n",
            "loss 0.20175801217556 average time 0.00496511072499004 iter num 80\n",
            "loss 0.26982975006103516 average time 0.004627660609987743 iter num 100\n",
            "loss 0.9746382236480713 average time 0.009318087399992691 iter num 20\n",
            "loss 0.23597291111946106 average time 0.006340850374999718 iter num 40\n",
            "loss 0.35131433606147766 average time 0.005367404816661292 iter num 60\n",
            "loss 0.3008357286453247 average time 0.004855970874999116 iter num 80\n",
            "loss 0.22626054286956787 average time 0.0045875614700048575 iter num 100\n",
            "loss 1.0580028295516968 average time 0.010016430500013485 iter num 20\n",
            "loss 0.7539946436882019 average time 0.006796010500022476 iter num 40\n",
            "loss 0.652899980545044 average time 0.00574074643335886 iter num 60\n",
            "loss 0.4783313274383545 average time 0.005221314012538869 iter num 80\n",
            "loss 0.28808096051216125 average time 0.004879498570053329 iter num 100\n",
            "loss 0.7755828499794006 average time 0.0100633692999736 iter num 20\n",
            "loss 0.2960371971130371 average time 0.0067997211999681895 iter num 40\n",
            "loss 0.3828650712966919 average time 0.005671673766664753 iter num 60\n",
            "loss 0.22619453072547913 average time 0.005143868837501486 iter num 80\n",
            "loss 0.138429656624794 average time 0.004765419529994688 iter num 100\n",
            "loss 0.5105690956115723 average time 0.009377788900042105 iter num 20\n",
            "loss 0.4176056981086731 average time 0.006393736125028226 iter num 40\n",
            "loss 0.2887091040611267 average time 0.0054675841667100634 iter num 60\n",
            "loss 0.13211029767990112 average time 0.005001549837544417 iter num 80\n",
            "loss 0.11595471203327179 average time 0.004697443580053005 iter num 100\n",
            "loss 0.1876716911792755 average time 0.009564427449981849 iter num 20\n",
            "loss 0.44954437017440796 average time 0.006538399399971695 iter num 40\n",
            "loss 0.4576773941516876 average time 0.005513719233340453 iter num 60\n",
            "loss 0.18372288346290588 average time 0.004991351400002486 iter num 80\n",
            "loss 0.11213883012533188 average time 0.004708179439994638 iter num 100\n",
            "loss 0.5347321033477783 average time 0.009931003850033449 iter num 20\n",
            "loss 0.2198869287967682 average time 0.006660007225013942 iter num 40\n",
            "loss 0.08471782505512238 average time 0.005536657750023248 iter num 60\n",
            "loss 0.1764153242111206 average time 0.004955436662521606 iter num 80\n",
            "loss 0.16443395614624023 average time 0.004617509720005728 iter num 100\n",
            "loss 0.14929905533790588 average time 0.009416014099997483 iter num 20\n",
            "loss 0.21208976209163666 average time 0.006341383475000839 iter num 40\n",
            "loss 0.2579476833343506 average time 0.005315635400014192 iter num 60\n",
            "loss 0.12087389081716537 average time 0.0048090817374941254 iter num 80\n",
            "loss 0.19800002872943878 average time 0.004504668839995247 iter num 100\n",
            "loss 1.149274468421936 average time 0.00902591564990871 iter num 20\n",
            "loss 0.2923404574394226 average time 0.006125753349954266 iter num 40\n",
            "loss 0.2131340205669403 average time 0.005185185966661265 iter num 60\n",
            "loss 0.4736938774585724 average time 0.004691064337487205 iter num 80\n",
            "loss 0.3768801689147949 average time 0.004397157300008985 iter num 100\n",
            "loss 0.7124554514884949 average time 0.00924400020005578 iter num 20\n",
            "loss 0.15870635211467743 average time 0.006260518975022933 iter num 40\n",
            "loss 0.33485591411590576 average time 0.00527865556668227 iter num 60\n",
            "loss 0.5442559719085693 average time 0.004812956887496967 iter num 80\n",
            "loss 0.22603152692317963 average time 0.004525802320004004 iter num 100\n",
            "loss 0.484507292509079 average time 0.0099154776999967 iter num 20\n",
            "loss 0.4555337429046631 average time 0.006663151674990786 iter num 40\n",
            "loss 0.23475059866905212 average time 0.0055674618833336355 iter num 60\n",
            "loss 0.13128860294818878 average time 0.005023137362491071 iter num 80\n",
            "loss 0.37971818447113037 average time 0.004720554849991458 iter num 100\n",
            "loss 0.2165186107158661 average time 0.010117212600039237 iter num 20\n",
            "loss 0.18763229250907898 average time 0.006763728125019952 iter num 40\n",
            "loss 0.38192272186279297 average time 0.00561468401666995 iter num 60\n",
            "loss 0.35191860795021057 average time 0.005027322300014703 iter num 80\n",
            "loss 0.15716896951198578 average time 0.004674013180010661 iter num 100\n",
            "loss 0.676960289478302 average time 0.009229338450040814 iter num 20\n",
            "loss 0.4969474673271179 average time 0.006275387550010692 iter num 40\n",
            "loss 0.18658456206321716 average time 0.00531515320002048 iter num 60\n",
            "loss 0.19020295143127441 average time 0.004825639287508921 iter num 80\n",
            "loss 0.4211844205856323 average time 0.004522623980024037 iter num 100\n",
            "loss 4.175497055053711 average time 0.009326344099940797 iter num 20\n",
            "loss 0.482042521238327 average time 0.006296722824981771 iter num 40\n",
            "loss 0.5516542196273804 average time 0.005303154250001777 iter num 60\n",
            "loss 0.33442702889442444 average time 0.004785321437509538 iter num 80\n",
            "loss 0.08113721758127213 average time 0.0044719730300039374 iter num 100\n",
            "loss 0.4560241997241974 average time 0.00875279194997347 iter num 20\n",
            "loss 0.19480513036251068 average time 0.0060423926999874315 iter num 40\n",
            "loss 0.4316369295120239 average time 0.00510407403331404 iter num 60\n",
            "loss 0.2657666504383087 average time 0.004644807712492138 iter num 80\n",
            "loss 0.20394133031368256 average time 0.0043945094599939696 iter num 100\n",
            "loss 0.651518702507019 average time 0.009942357050044847 iter num 20\n",
            "loss 0.6290156245231628 average time 0.006684990474991537 iter num 40\n",
            "loss 0.1319362223148346 average time 0.005613590516653251 iter num 60\n",
            "loss 0.30902111530303955 average time 0.005065564624999297 iter num 80\n",
            "loss 0.1780955195426941 average time 0.004725539009987187 iter num 100\n",
            "loss 0.202899768948555 average time 0.009918337650037756 iter num 20\n",
            "loss 0.272922545671463 average time 0.006651700625036483 iter num 40\n",
            "loss 0.325441837310791 average time 0.0055628535000323606 iter num 60\n",
            "loss 0.20819786190986633 average time 0.005013102337534292 iter num 80\n",
            "loss 0.06339971721172333 average time 0.004662226940035907 iter num 100\n",
            "loss 0.5613042116165161 average time 0.009377659300025699 iter num 20\n",
            "loss 0.12128718197345734 average time 0.006321705900029428 iter num 40\n",
            "loss 0.22602114081382751 average time 0.005285705650021555 iter num 60\n",
            "loss 0.1544162780046463 average time 0.0047709552125013484 iter num 80\n",
            "loss 0.1793489158153534 average time 0.00447217276000174 iter num 100\n",
            "loss 0.1165943443775177 average time 0.00935150329996759 iter num 20\n",
            "loss 0.44137006998062134 average time 0.0063109725499998605 iter num 40\n",
            "loss 0.2770073413848877 average time 0.005292275716647055 iter num 60\n",
            "loss 0.09225839376449585 average time 0.00478319841248549 iter num 80\n",
            "loss 0.3172591030597687 average time 0.004481143579982927 iter num 100\n",
            "loss 1.5135860443115234 average time 0.009848666899983982 iter num 20\n",
            "loss 1.234666109085083 average time 0.006544234475006761 iter num 40\n",
            "loss 0.1750895082950592 average time 0.005463843900020038 iter num 60\n",
            "loss 0.4018924832344055 average time 0.004907960575013704 iter num 80\n",
            "loss 0.16227367520332336 average time 0.004575502630013943 iter num 100\n",
            "loss 0.638734757900238 average time 0.010051722449998125 iter num 20\n",
            "loss 0.14522452652454376 average time 0.006750131450019126 iter num 40\n",
            "loss 0.47806960344314575 average time 0.005657016033357346 iter num 60\n",
            "loss 0.11512425541877747 average time 0.0051186048500255765 iter num 80\n",
            "loss 0.11949305981397629 average time 0.004778065330019672 iter num 100\n",
            "loss 0.4489930272102356 average time 0.009848134100002426 iter num 20\n",
            "loss 0.7339857816696167 average time 0.006656625850007458 iter num 40\n",
            "loss 0.2776881158351898 average time 0.005585158716697455 iter num 60\n",
            "loss 0.33813241124153137 average time 0.00503845113752277 iter num 80\n",
            "loss 0.14744918048381805 average time 0.004776153399998293 iter num 100\n",
            "loss 0.17186200618743896 average time 0.009597506300019631 iter num 20\n",
            "loss 0.38618236780166626 average time 0.006498104175034314 iter num 40\n",
            "loss 0.14607739448547363 average time 0.005422749983351119 iter num 60\n",
            "loss 0.3331547975540161 average time 0.004872589624994816 iter num 80\n",
            "loss 0.13754478096961975 average time 0.004546970609994787 iter num 100\n",
            "loss 0.3062214255332947 average time 0.009183682850016339 iter num 20\n",
            "loss 0.29858431220054626 average time 0.006211435900002016 iter num 40\n",
            "loss 0.14581003785133362 average time 0.005220046383343894 iter num 60\n",
            "loss 0.4990766644477844 average time 0.004731442612501269 iter num 80\n",
            "loss 0.2605261504650116 average time 0.004429753599997639 iter num 100\n",
            "loss 0.1785396933555603 average time 0.00943782325000484 iter num 20\n",
            "loss 0.38031136989593506 average time 0.006327849000012975 iter num 40\n",
            "loss 0.1903267204761505 average time 0.005293446283333955 iter num 60\n",
            "loss 0.1909455955028534 average time 0.004774999912507382 iter num 80\n",
            "loss 0.2404988408088684 average time 0.004474875780015281 iter num 100\n",
            "loss 2.2792439460754395 average time 0.009371793649984283 iter num 20\n",
            "loss 0.4554661214351654 average time 0.006386496324989821 iter num 40\n",
            "loss 0.0754210352897644 average time 0.005380139649992089 iter num 60\n",
            "loss 0.3543602526187897 average time 0.004878137287488471 iter num 80\n",
            "loss 0.1300719678401947 average time 0.00457122919000085 iter num 100\n",
            "loss 0.1711498349905014 average time 0.010154991649937984 iter num 20\n",
            "loss 0.15963152050971985 average time 0.0067679602499651995 iter num 40\n",
            "loss 0.9309032559394836 average time 0.005651068999964082 iter num 60\n",
            "loss 0.437969446182251 average time 0.005093330249951578 iter num 80\n",
            "loss 0.16059133410453796 average time 0.004748798019963942 iter num 100\n",
            "loss 1.207500696182251 average time 0.010166554100010217 iter num 20\n",
            "loss 0.14557862281799316 average time 0.006811201625009744 iter num 40\n",
            "loss 0.3934513330459595 average time 0.0056283876166692915 iter num 60\n",
            "loss 0.2541022300720215 average time 0.005079282199989166 iter num 80\n",
            "loss 0.2815844416618347 average time 0.004738885920005487 iter num 100\n",
            "loss 0.3802003264427185 average time 0.010828366500027187 iter num 20\n",
            "loss 1.0035525560379028 average time 0.007148629100026937 iter num 40\n",
            "loss 0.2596898078918457 average time 0.005896906950033554 iter num 60\n",
            "loss 0.2641080617904663 average time 0.005275028050016317 iter num 80\n",
            "loss 0.21460391581058502 average time 0.004904830460018275 iter num 100\n",
            "loss 0.23687976598739624 average time 0.010683300950017838 iter num 20\n",
            "loss 0.320244699716568 average time 0.007053616474991031 iter num 40\n",
            "loss 0.22308063507080078 average time 0.005851579400026215 iter num 60\n",
            "loss 0.23978930711746216 average time 0.005215787612530676 iter num 80\n",
            "loss 0.15123364329338074 average time 0.004832082720022299 iter num 100\n",
            "loss 0.11930353939533234 average time 0.00915930210001079 iter num 20\n",
            "loss 0.6218677759170532 average time 0.006186905850006497 iter num 40\n",
            "loss 0.4106087386608124 average time 0.0052091504999907555 iter num 60\n",
            "loss 0.16741454601287842 average time 0.004738098599995055 iter num 80\n",
            "loss 0.1522171050310135 average time 0.0044407170100021175 iter num 100\n",
            "loss 0.3795134425163269 average time 0.009325762849903186 iter num 20\n",
            "loss 0.7915322780609131 average time 0.006292981274930299 iter num 40\n",
            "loss 0.07283791899681091 average time 0.005307880299983481 iter num 60\n",
            "loss 0.24573661386966705 average time 0.004790897087485746 iter num 80\n",
            "loss 0.1238759458065033 average time 0.004479435680004826 iter num 100\n",
            "loss 0.6726001501083374 average time 0.00948577799999839 iter num 20\n",
            "loss 0.5167936086654663 average time 0.006372153099982824 iter num 40\n",
            "loss 0.6861977577209473 average time 0.005326869166644125 iter num 60\n",
            "loss 0.19213324785232544 average time 0.0048039748749715725 iter num 80\n",
            "loss 0.2487260401248932 average time 0.0045072022799740805 iter num 100\n",
            "loss 0.17898054420948029 average time 0.0095960980500422 iter num 20\n",
            "loss 0.16675004363059998 average time 0.00646643022500939 iter num 40\n",
            "loss 0.1800030916929245 average time 0.005442810933338175 iter num 60\n",
            "loss 0.630531907081604 average time 0.004939046275012515 iter num 80\n",
            "loss 0.25871530175209045 average time 0.004622156270006599 iter num 100\n",
            "loss 0.6587445735931396 average time 0.01036063374999685 iter num 20\n",
            "loss 0.28594711422920227 average time 0.006876772924965735 iter num 40\n",
            "loss 0.11919109523296356 average time 0.005703460516648799 iter num 60\n",
            "loss 0.14836269617080688 average time 0.0051088265999851504 iter num 80\n",
            "loss 0.09078007936477661 average time 0.004735211749989503 iter num 100\n",
            "loss 0.3072211742401123 average time 0.009015926449978905 iter num 20\n",
            "loss 0.2471277266740799 average time 0.006146588599995085 iter num 40\n",
            "loss 0.34455642104148865 average time 0.005190304933315322 iter num 60\n",
            "loss 0.31179922819137573 average time 0.004740188049987637 iter num 80\n",
            "loss 0.28510934114456177 average time 0.004447419989987793 iter num 100\n",
            "loss 0.3621068596839905 average time 0.010215431950041421 iter num 20\n",
            "loss 0.3257652521133423 average time 0.006691509900031178 iter num 40\n",
            "loss 0.12654641270637512 average time 0.005552316400022998 iter num 60\n",
            "loss 0.14467158913612366 average time 0.004976601912511569 iter num 80\n",
            "loss 0.33089056611061096 average time 0.004634364550015562 iter num 100\n",
            "loss 0.6579179763793945 average time 0.008769372600022507 iter num 20\n",
            "loss 0.266476035118103 average time 0.005987556924969795 iter num 40\n",
            "loss 0.26162487268447876 average time 0.005080245383320896 iter num 60\n",
            "loss 0.34200575947761536 average time 0.004645578112467774 iter num 80\n",
            "loss 0.2354898452758789 average time 0.0043930233999890335 iter num 100\n",
            "loss 0.35960936546325684 average time 0.009851025599959939 iter num 20\n",
            "loss 0.6745946407318115 average time 0.006642254575024253 iter num 40\n",
            "loss 0.42450159788131714 average time 0.005566937916682946 iter num 60\n",
            "loss 0.1672268509864807 average time 0.005029410250011778 iter num 80\n",
            "loss 0.17074939608573914 average time 0.004718269219997637 iter num 100\n",
            "loss 0.24371695518493652 average time 0.010133168349966581 iter num 20\n",
            "loss 0.35739898681640625 average time 0.006788792674979049 iter num 40\n",
            "loss 0.36211463809013367 average time 0.005657612899957106 iter num 60\n",
            "loss 0.33819901943206787 average time 0.0050793950124671024 iter num 80\n",
            "loss 0.08591830730438232 average time 0.004723359259978679 iter num 100\n",
            "loss 0.38532736897468567 average time 0.009301579099951596 iter num 20\n",
            "loss 0.5356004238128662 average time 0.00624695737494676 iter num 40\n",
            "loss 0.32740598917007446 average time 0.005252796266646934 iter num 60\n",
            "loss 0.3683928847312927 average time 0.004755078925012412 iter num 80\n",
            "loss 0.2598962187767029 average time 0.004457482960019661 iter num 100\n",
            "loss 0.5615421533584595 average time 0.00900265250004395 iter num 20\n",
            "loss 0.091517373919487 average time 0.0061037250500476144 iter num 40\n",
            "loss 0.6590253114700317 average time 0.005131361716712491 iter num 60\n",
            "loss 0.23770049214363098 average time 0.004649970037530693 iter num 80\n",
            "loss 0.1264571249485016 average time 0.004367048510016502 iter num 100\n",
            "loss 0.26597723364830017 average time 0.009353348100034964 iter num 20\n",
            "loss 0.32180145382881165 average time 0.006329550975021902 iter num 40\n",
            "loss 0.19616729021072388 average time 0.005293078316700909 iter num 60\n",
            "loss 0.23566985130310059 average time 0.004784062412505818 iter num 80\n",
            "loss 0.16356180608272552 average time 0.004466292859992791 iter num 100\n",
            "loss 0.3544490337371826 average time 0.009530499600009535 iter num 20\n",
            "loss 0.1775631308555603 average time 0.0064210932750143005 iter num 40\n",
            "loss 0.2553415298461914 average time 0.0054126232833368705 iter num 60\n",
            "loss 0.6178762912750244 average time 0.004908747837481542 iter num 80\n",
            "loss 0.16338318586349487 average time 0.004609760479993384 iter num 100\n",
            "loss 0.76462322473526 average time 0.00963773860000856 iter num 20\n",
            "loss 0.7252175807952881 average time 0.006536943625053482 iter num 40\n",
            "loss 0.13832172751426697 average time 0.005517696900036147 iter num 60\n",
            "loss 0.23786085844039917 average time 0.005007901687537242 iter num 80\n",
            "loss 0.059406738728284836 average time 0.00469751401004487 iter num 100\n",
            "loss 0.596574068069458 average time 0.009860714899991763 iter num 20\n",
            "loss 0.3027447462081909 average time 0.006745406949971766 iter num 40\n",
            "loss 0.4286532998085022 average time 0.005591493349970733 iter num 60\n",
            "loss 0.23094213008880615 average time 0.005013398212469156 iter num 80\n",
            "loss 0.20925725996494293 average time 0.004696608339991144 iter num 100\n",
            "loss 0.2621869444847107 average time 0.009853684450035871 iter num 20\n",
            "loss 0.2911345362663269 average time 0.0065592632000289084 iter num 40\n",
            "loss 0.202897310256958 average time 0.005462739766683929 iter num 60\n",
            "loss 0.13884058594703674 average time 0.004899963962492393 iter num 80\n",
            "loss 0.05882323533296585 average time 0.004566145529979622 iter num 100\n",
            "loss 0.3398914933204651 average time 0.008945698600018658 iter num 20\n",
            "loss 0.32238972187042236 average time 0.006103288924987282 iter num 40\n",
            "loss 0.38103264570236206 average time 0.005161631399990559 iter num 60\n",
            "loss 0.14941304922103882 average time 0.004670398349986726 iter num 80\n",
            "loss 0.07062213122844696 average time 0.0044001221100052135 iter num 100\n",
            "loss 0.1299060881137848 average time 0.009797377650033922 iter num 20\n",
            "loss 0.32780152559280396 average time 0.006515696899975864 iter num 40\n",
            "loss 0.744219183921814 average time 0.005457074766665452 iter num 60\n",
            "loss 0.4558091163635254 average time 0.00495893793750497 iter num 80\n",
            "loss 0.14736145734786987 average time 0.004641475760017784 iter num 100\n",
            "loss 0.1560639888048172 average time 0.010326087049952548 iter num 20\n",
            "loss 0.06134805083274841 average time 0.00685616414997412 iter num 40\n",
            "loss 0.7836636900901794 average time 0.005709400049977375 iter num 60\n",
            "loss 0.20993101596832275 average time 0.005128250662494338 iter num 80\n",
            "loss 0.22344309091567993 average time 0.004773042159995384 iter num 100\n",
            "loss 0.3958677649497986 average time 0.010495842249997622 iter num 20\n",
            "loss 0.2635790705680847 average time 0.006926930024985722 iter num 40\n",
            "loss 0.05728061497211456 average time 0.005731387149982462 iter num 60\n",
            "loss 0.4520750939846039 average time 0.005117665599982502 iter num 80\n",
            "loss 0.19372916221618652 average time 0.004771052559995041 iter num 100\n",
            "loss 0.1605849415063858 average time 0.009423931100013761 iter num 20\n",
            "loss 0.06871405988931656 average time 0.0064065373250059565 iter num 40\n",
            "loss 0.2270500808954239 average time 0.005432567966681745 iter num 60\n",
            "loss 0.15905511379241943 average time 0.004925399500001504 iter num 80\n",
            "loss 0.3570423722267151 average time 0.004620030329988367 iter num 100\n",
            "loss 0.7232826352119446 average time 0.010094979899986357 iter num 20\n",
            "loss 1.1420097351074219 average time 0.006715769049969822 iter num 40\n",
            "loss 0.2919655442237854 average time 0.005608969199958362 iter num 60\n",
            "loss 0.37689289450645447 average time 0.005083777437459957 iter num 80\n",
            "loss 0.08339081704616547 average time 0.004727787989972967 iter num 100\n",
            "loss 0.18276700377464294 average time 0.00977862575000472 iter num 20\n",
            "loss 0.18864354491233826 average time 0.00652074212498519 iter num 40\n",
            "loss 0.31064873933792114 average time 0.005432863316627845 iter num 60\n",
            "loss 0.21999645233154297 average time 0.004878698949966065 iter num 80\n",
            "loss 0.060010503977537155 average time 0.00456201652998061 iter num 100\n",
            "loss 0.28631627559661865 average time 0.009178166149945354 iter num 20\n",
            "loss 0.9745831489562988 average time 0.006216047099962907 iter num 40\n",
            "loss 0.15031494200229645 average time 0.00522448933332574 iter num 60\n",
            "loss 0.2341577410697937 average time 0.004724999249998518 iter num 80\n",
            "loss 0.20622728765010834 average time 0.004442570259984677 iter num 100\n",
            "loss 1.227540373802185 average time 0.009421960249983385 iter num 20\n",
            "loss 0.5680139064788818 average time 0.006351189699955739 iter num 40\n",
            "loss 0.17617306113243103 average time 0.0053051089499679925 iter num 60\n",
            "loss 0.17683082818984985 average time 0.004778765412453367 iter num 80\n",
            "loss 0.18345855176448822 average time 0.004466110719981771 iter num 100\n",
            "loss 0.3002871572971344 average time 0.009485165849991973 iter num 20\n",
            "loss 0.3393349349498749 average time 0.00642729967496507 iter num 40\n",
            "loss 0.2650962471961975 average time 0.005411335899990869 iter num 60\n",
            "loss 0.17728161811828613 average time 0.004917911437502198 iter num 80\n",
            "loss 0.16283221542835236 average time 0.004613847600003282 iter num 100\n",
            "loss 0.4521934986114502 average time 0.009890907550038719 iter num 20\n",
            "loss 0.2820620834827423 average time 0.0067001888500271885 iter num 40\n",
            "loss 0.34597641229629517 average time 0.0056649865000281355 iter num 60\n",
            "loss 0.18299934267997742 average time 0.005102437500028145 iter num 80\n",
            "loss 0.1409912109375 average time 0.004798709560018324 iter num 100\n",
            "loss 0.648212194442749 average time 0.009412965600017743 iter num 20\n",
            "loss 0.42024335265159607 average time 0.006329929500043363 iter num 40\n",
            "loss 0.24465502798557281 average time 0.005306599750019814 iter num 60\n",
            "loss 0.14446574449539185 average time 0.004796751062514204 iter num 80\n",
            "loss 0.12296170741319656 average time 0.004484108340011517 iter num 100\n",
            "loss 0.2982597053050995 average time 0.009734269000023232 iter num 20\n",
            "loss 0.5780971646308899 average time 0.00649365455002453 iter num 40\n",
            "loss 0.30411115288734436 average time 0.0054438606833628 iter num 60\n",
            "loss 0.07257213443517685 average time 0.004890648612507676 iter num 80\n",
            "loss 0.17421501874923706 average time 0.004592297639997014 iter num 100\n",
            "loss 0.5524355173110962 average time 0.009305357050038765 iter num 20\n",
            "loss 0.15851028263568878 average time 0.0062674426250168835 iter num 40\n",
            "loss 0.23107606172561646 average time 0.005250413433335173 iter num 60\n",
            "loss 0.37047767639160156 average time 0.004742466100020692 iter num 80\n",
            "loss 0.07599282264709473 average time 0.004449878890018227 iter num 100\n",
            "loss 0.33853790163993835 average time 0.008955487649950555 iter num 20\n",
            "loss 0.38473305106163025 average time 0.006113656449997507 iter num 40\n",
            "loss 0.45704546570777893 average time 0.005197525199969277 iter num 60\n",
            "loss 0.3335226774215698 average time 0.004831837499966696 iter num 80\n",
            "loss 0.14128157496452332 average time 0.004544415469977139 iter num 100\n",
            "loss 0.13757917284965515 average time 0.010046113199973662 iter num 20\n",
            "loss 0.8506465554237366 average time 0.006678746024977045 iter num 40\n",
            "loss 0.2398214340209961 average time 0.005581308049977451 iter num 60\n",
            "loss 0.42945921421051025 average time 0.0050377995874896445 iter num 80\n",
            "loss 0.17258989810943604 average time 0.004710350569985167 iter num 100\n",
            "loss 0.4192814826965332 average time 0.010146732599991992 iter num 20\n",
            "loss 0.15178076922893524 average time 0.006694300350011418 iter num 40\n",
            "loss 0.15177446603775024 average time 0.005591469566676703 iter num 60\n",
            "loss 0.15255138278007507 average time 0.005002914012504789 iter num 80\n",
            "loss 0.057098694145679474 average time 0.0046401611400051475 iter num 100\n",
            "loss 0.6146082282066345 average time 0.00875871354994615 iter num 20\n",
            "loss 0.23612232506275177 average time 0.005990005049955016 iter num 40\n",
            "loss 0.2543165385723114 average time 0.005074768049970165 iter num 60\n",
            "loss 0.06399399042129517 average time 0.004613313724979662 iter num 80\n",
            "loss 0.2704520523548126 average time 0.004334822829991936 iter num 100\n",
            "loss 0.550669252872467 average time 0.00919230314991637 iter num 20\n",
            "loss 0.2324480563402176 average time 0.006201965699972334 iter num 40\n",
            "loss 0.08380372077226639 average time 0.005197096899996723 iter num 60\n",
            "loss 0.16171060502529144 average time 0.004697121287500749 iter num 80\n",
            "loss 0.32809239625930786 average time 0.0044058930500114005 iter num 100\n",
            "loss 0.5971323251724243 average time 0.009318062599982113 iter num 20\n",
            "loss 0.8528051376342773 average time 0.00629556642497846 iter num 40\n",
            "loss 0.2757231891155243 average time 0.005297481899985238 iter num 60\n",
            "loss 0.43631798028945923 average time 0.004812594762501021 iter num 80\n",
            "loss 0.05993174761533737 average time 0.004527915059993575 iter num 100\n",
            "loss 0.3007342219352722 average time 0.009437782950021756 iter num 20\n",
            "loss 0.3017507791519165 average time 0.00640157759999056 iter num 40\n",
            "loss 0.22467562556266785 average time 0.005395185216661958 iter num 60\n",
            "loss 0.3849380612373352 average time 0.004891545712496281 iter num 80\n",
            "loss 0.12531515955924988 average time 0.0045823047600015345 iter num 100\n",
            "loss 1.4573149681091309 average time 0.010032577599963588 iter num 20\n",
            "loss 0.2537555396556854 average time 0.006709646499984956 iter num 40\n",
            "loss 0.3793739676475525 average time 0.005568470900000951 iter num 60\n",
            "loss 0.19063818454742432 average time 0.004996711325003389 iter num 80\n",
            "loss 0.07675595581531525 average time 0.00465177075000156 iter num 100\n",
            "loss 0.29975205659866333 average time 0.00990644904995861 iter num 20\n",
            "loss 0.23703831434249878 average time 0.006809166925017962 iter num 40\n",
            "loss 0.16077755391597748 average time 0.005649494283344817 iter num 60\n",
            "loss 0.2404347062110901 average time 0.005046917662519945 iter num 80\n",
            "loss 0.11109986901283264 average time 0.004679532690015548 iter num 100\n",
            "loss 0.44124311208724976 average time 0.008986568849991272 iter num 20\n",
            "loss 0.24825018644332886 average time 0.0060992936749812545 iter num 40\n",
            "loss 0.24588006734848022 average time 0.005138342149977385 iter num 60\n",
            "loss 0.1504978984594345 average time 0.00465832171250895 iter num 80\n",
            "loss 0.09343446791172028 average time 0.004372998090002511 iter num 100\n",
            "loss 0.1651419997215271 average time 0.008813595849937883 iter num 20\n",
            "loss 0.07336299121379852 average time 0.006166520399972342 iter num 40\n",
            "loss 0.17662644386291504 average time 0.0051949381999899435 iter num 60\n",
            "loss 0.07678408175706863 average time 0.004702168062510737 iter num 80\n",
            "loss 0.09212784469127655 average time 0.004443361260009624 iter num 100\n",
            "loss 0.12458711862564087 average time 0.010242557499964278 iter num 20\n",
            "loss 0.13118207454681396 average time 0.006829787124956965 iter num 40\n",
            "loss 0.08370062708854675 average time 0.005700525983282508 iter num 60\n",
            "loss 0.4305053949356079 average time 0.00511685727495319 iter num 80\n",
            "loss 0.09700876474380493 average time 0.00477897577996373 iter num 100\n",
            "loss 0.536853015422821 average time 0.00996002804993168 iter num 20\n",
            "loss 0.38326525688171387 average time 0.006672473849948801 iter num 40\n",
            "loss 0.2700512409210205 average time 0.005569723749984708 iter num 60\n",
            "loss 0.139792338013649 average time 0.005006915549967061 iter num 80\n",
            "loss 0.177841916680336 average time 0.004693298609963676 iter num 100\n",
            "loss 0.4746442139148712 average time 0.009328146750021915 iter num 20\n",
            "loss 0.2776336073875427 average time 0.0062841850000040726 iter num 40\n",
            "loss 0.2949162721633911 average time 0.005291442949987868 iter num 60\n",
            "loss 0.17855693399906158 average time 0.00476895761249807 iter num 80\n",
            "loss 0.12506727874279022 average time 0.004460137900000518 iter num 100\n",
            "loss 1.160710096359253 average time 0.008896586550031315 iter num 20\n",
            "loss 0.4380848705768585 average time 0.0060932290249979815 iter num 40\n",
            "loss 0.18184497952461243 average time 0.00513905771666335 iter num 60\n",
            "loss 0.14006085693836212 average time 0.004659551412498786 iter num 80\n",
            "loss 0.18341964483261108 average time 0.004372834129999319 iter num 100\n",
            "loss 0.28508779406547546 average time 0.008613759099989692 iter num 20\n",
            "loss 0.2107471078634262 average time 0.005976122574963938 iter num 40\n",
            "loss 0.17592090368270874 average time 0.005108778566667146 iter num 60\n",
            "loss 0.1729028820991516 average time 0.004662458325009311 iter num 80\n",
            "loss 0.11883790791034698 average time 0.004384838850019151 iter num 100\n",
            "loss 0.13387487828731537 average time 0.010006364899982145 iter num 20\n",
            "loss 0.3030678629875183 average time 0.006672946175012839 iter num 40\n",
            "loss 0.48877644538879395 average time 0.0055700246166604 iter num 60\n",
            "loss 0.16871444880962372 average time 0.005014971937492873 iter num 80\n",
            "loss 0.19132980704307556 average time 0.0046815950799918935 iter num 100\n",
            "loss 0.4005858302116394 average time 0.009718906450007125 iter num 20\n",
            "loss 0.1476069986820221 average time 0.006553500849997817 iter num 40\n",
            "loss 0.11734052002429962 average time 0.005494103616645892 iter num 60\n",
            "loss 0.1497638076543808 average time 0.004969242687485576 iter num 80\n",
            "loss 0.22603242099285126 average time 0.004647492789986245 iter num 100\n",
            "loss 0.7243412733078003 average time 0.009456341349937248 iter num 20\n",
            "loss 0.16244100034236908 average time 0.0063552276999530475 iter num 40\n",
            "loss 0.14061012864112854 average time 0.00532671196664675 iter num 60\n",
            "loss 0.14293964207172394 average time 0.004841785212477134 iter num 80\n",
            "loss 0.1455533802509308 average time 0.0045461760499847514 iter num 100\n",
            "loss 0.6786041855812073 average time 0.010233477900055733 iter num 20\n",
            "loss 0.13294990360736847 average time 0.006851728525043654 iter num 40\n",
            "loss 0.3463843762874603 average time 0.00567866501668656 iter num 60\n",
            "loss 0.37547385692596436 average time 0.005103858612517343 iter num 80\n",
            "loss 0.17838971316814423 average time 0.004758843410008921 iter num 100\n",
            "loss 0.15502232313156128 average time 0.009951166099972398 iter num 20\n",
            "loss 0.26534926891326904 average time 0.006645894899986615 iter num 40\n",
            "loss 0.32993650436401367 average time 0.00550690070000807 iter num 60\n",
            "loss 0.26743096113204956 average time 0.004940725612499364 iter num 80\n",
            "loss 0.09797945618629456 average time 0.004609928510003556 iter num 100\n",
            "loss 0.4572921395301819 average time 0.009391184399987651 iter num 20\n",
            "loss 0.8577331304550171 average time 0.006437584474974755 iter num 40\n",
            "loss 0.777577817440033 average time 0.005454938149978261 iter num 60\n",
            "loss 0.1034252941608429 average time 0.004933262599985255 iter num 80\n",
            "loss 0.41176682710647583 average time 0.004626836129973526 iter num 100\n",
            "loss 0.5037331581115723 average time 0.00957757215003312 iter num 20\n",
            "loss 0.23239806294441223 average time 0.0064800918000401 iter num 40\n",
            "loss 0.11141646653413773 average time 0.0054592565333678065 iter num 60\n",
            "loss 0.20057669281959534 average time 0.00493962898754603 iter num 80\n",
            "loss 0.09371747076511383 average time 0.004628302530036308 iter num 100\n",
            "loss 2.887146234512329 average time 0.009423723550048635 iter num 20\n",
            "loss 0.39896610379219055 average time 0.006465146050015846 iter num 40\n",
            "loss 0.16156725585460663 average time 0.005447391466683864 iter num 60\n",
            "loss 0.14347143471240997 average time 0.004979093000008561 iter num 80\n",
            "loss 0.1121080219745636 average time 0.004732428700003765 iter num 100\n",
            "loss 0.17560674250125885 average time 0.010581140549993507 iter num 20\n",
            "loss 0.20689812302589417 average time 0.007111228624978594 iter num 40\n",
            "loss 0.07662147283554077 average time 0.005962101549948784 iter num 60\n",
            "loss 0.20467007160186768 average time 0.00536495237495842 iter num 80\n",
            "loss 0.14425626397132874 average time 0.00501332635997187 iter num 100\n",
            "loss 0.32916849851608276 average time 0.010441858149943074 iter num 20\n",
            "loss 0.1805519312620163 average time 0.006954054924972297 iter num 40\n",
            "loss 0.07458261400461197 average time 0.00579535414995765 iter num 60\n",
            "loss 0.36744630336761475 average time 0.005178887249968511 iter num 80\n",
            "loss 0.154381662607193 average time 0.004816134569987298 iter num 100\n",
            "loss 0.22893467545509338 average time 0.009434319899924049 iter num 20\n",
            "loss 0.33821550011634827 average time 0.006447734549942652 iter num 40\n",
            "loss 0.1276915967464447 average time 0.005415650533283648 iter num 60\n",
            "loss 0.05129373073577881 average time 0.004967366287445429 iter num 80\n",
            "loss 0.037524838000535965 average time 0.0046792491299493125 iter num 100\n",
            "loss 0.13800764083862305 average time 0.009832143350058687 iter num 20\n",
            "loss 0.12007910758256912 average time 0.006651156000009451 iter num 40\n",
            "loss 0.11834802478551865 average time 0.005530614500025876 iter num 60\n",
            "loss 0.2512243390083313 average time 0.004978732187521473 iter num 80\n",
            "loss 0.048925090581178665 average time 0.004633309500022733 iter num 100\n",
            "loss 0.2524479925632477 average time 0.009327065350021257 iter num 20\n",
            "loss 0.2708616554737091 average time 0.006265860275004797 iter num 40\n",
            "loss 0.2765394151210785 average time 0.005245117600012842 iter num 60\n",
            "loss 0.20685037970542908 average time 0.00472727883750963 iter num 80\n",
            "loss 0.0882796049118042 average time 0.004434859560010409 iter num 100\n",
            "loss 0.5325464010238647 average time 0.009910035599955336 iter num 20\n",
            "loss 0.1218707337975502 average time 0.006637847149943354 iter num 40\n",
            "loss 0.22440312802791595 average time 0.005536661549983061 iter num 60\n",
            "loss 0.08036789298057556 average time 0.0049965990124803735 iter num 80\n",
            "loss 0.142925426363945 average time 0.00466375031998723 iter num 100\n",
            "loss 0.23966452479362488 average time 0.010107041949981976 iter num 20\n",
            "loss 0.19389913976192474 average time 0.006723608049992435 iter num 40\n",
            "loss 0.22738933563232422 average time 0.005609469433352388 iter num 60\n",
            "loss 0.10796947777271271 average time 0.0050435899000092375 iter num 80\n",
            "loss 0.2933782637119293 average time 0.0046836425100127595 iter num 100\n",
            "loss 0.2400871366262436 average time 0.009125986999993074 iter num 20\n",
            "loss 0.1885848492383957 average time 0.006162549875000423 iter num 40\n",
            "loss 0.35821107029914856 average time 0.005197834083332964 iter num 60\n",
            "loss 0.15796665847301483 average time 0.004729754487499349 iter num 80\n",
            "loss 0.0940105989575386 average time 0.00443941249001 iter num 100\n",
            "loss 0.3341142237186432 average time 0.009113559349952994 iter num 20\n",
            "loss 0.224331796169281 average time 0.00617965172498316 iter num 40\n",
            "loss 0.12644550204277039 average time 0.005196878949959682 iter num 60\n",
            "loss 0.0366424098610878 average time 0.0047101143749614495 iter num 80\n",
            "loss 0.12041006237268448 average time 0.00442550722996657 iter num 100\n",
            "loss 0.239935040473938 average time 0.009586870300040573 iter num 20\n",
            "loss 0.13498491048812866 average time 0.006398791425033324 iter num 40\n",
            "loss 0.08412575721740723 average time 0.005353983250006422 iter num 60\n",
            "loss 0.19467265903949738 average time 0.004828932037491995 iter num 80\n",
            "loss 0.27952611446380615 average time 0.004527618270003586 iter num 100\n",
            "loss 0.09428255259990692 average time 0.009669118600004366 iter num 20\n",
            "loss 0.1378113329410553 average time 0.006525862025011975 iter num 40\n",
            "loss 0.22884908318519592 average time 0.005470766350003942 iter num 60\n",
            "loss 0.1574876606464386 average time 0.004942873799996051 iter num 80\n",
            "loss 0.13262897729873657 average time 0.004621155919990088 iter num 100\n",
            "loss 0.6632300615310669 average time 0.009789673799923548 iter num 20\n",
            "loss 0.1372813582420349 average time 0.0065589054499469055 iter num 40\n",
            "loss 0.2835012674331665 average time 0.005491431866623013 iter num 60\n",
            "loss 0.3084087371826172 average time 0.004953185687452333 iter num 80\n",
            "loss 0.05263752490282059 average time 0.004627293559951795 iter num 100\n",
            "loss 0.18643836677074432 average time 0.010047858800021459 iter num 20\n",
            "loss 0.09130576252937317 average time 0.006625806525005373 iter num 40\n",
            "loss 0.25852566957473755 average time 0.005491267033327555 iter num 60\n",
            "loss 0.13630038499832153 average time 0.004917901799984747 iter num 80\n",
            "loss 0.14237670600414276 average time 0.00457274019999204 iter num 100\n",
            "loss 0.25046661496162415 average time 0.009936159349990703 iter num 20\n",
            "loss 0.16242356598377228 average time 0.006583730500005913 iter num 40\n",
            "loss 0.2604336738586426 average time 0.005456722516669288 iter num 60\n",
            "loss 0.10672195255756378 average time 0.004937929837495858 iter num 80\n",
            "loss 0.10344452410936356 average time 0.004617503869981192 iter num 100\n",
            "loss 0.07194577157497406 average time 0.009463766149974618 iter num 20\n",
            "loss 0.13049332797527313 average time 0.006332521349986564 iter num 40\n",
            "loss 0.19845634698867798 average time 0.005290129383335322 iter num 60\n",
            "loss 0.1525595486164093 average time 0.004771745287496287 iter num 80\n",
            "loss 0.2181970328092575 average time 0.004455946780008162 iter num 100\n",
            "loss 0.32861173152923584 average time 0.009065313450014401 iter num 20\n",
            "loss 0.285271555185318 average time 0.006154592525012959 iter num 40\n",
            "loss 0.27196624875068665 average time 0.0052436618499844675 iter num 60\n",
            "loss 0.07690154761075974 average time 0.004772450074977996 iter num 80\n",
            "loss 0.10457718372344971 average time 0.004513216889963587 iter num 100\n",
            "loss 1.6724599599838257 average time 0.009945213350033556 iter num 20\n",
            "loss 0.40875810384750366 average time 0.0068291071749854385 iter num 40\n",
            "loss 0.3156067132949829 average time 0.005713887749993774 iter num 60\n",
            "loss 0.12641815841197968 average time 0.0051529815000037615 iter num 80\n",
            "loss 0.29890891909599304 average time 0.004831801920013277 iter num 100\n",
            "loss 0.24258819222450256 average time 0.01034401624997372 iter num 20\n",
            "loss 0.31175726652145386 average time 0.006846953599949757 iter num 40\n",
            "loss 0.11427333205938339 average time 0.0056419956666180346 iter num 60\n",
            "loss 0.06159184128046036 average time 0.005045430337446533 iter num 80\n",
            "loss 0.1351877897977829 average time 0.0047272654099560895 iter num 100\n",
            "loss 0.5076237916946411 average time 0.010170564249983726 iter num 20\n",
            "loss 0.24688765406608582 average time 0.00689811979998467 iter num 40\n",
            "loss 0.17467692494392395 average time 0.005817220233302578 iter num 60\n",
            "loss 0.17933866381645203 average time 0.005272741374966472 iter num 80\n",
            "loss 0.06222457438707352 average time 0.004906781319969014 iter num 100\n",
            "loss 0.0863557681441307 average time 0.00990349495011742 iter num 20\n",
            "loss 0.06859274208545685 average time 0.006616087125053127 iter num 40\n",
            "loss 0.1251082867383957 average time 0.005535672300031062 iter num 60\n",
            "loss 0.17385753989219666 average time 0.004971408725015181 iter num 80\n",
            "loss 0.16814471781253815 average time 0.004622828800020216 iter num 100\n",
            "loss 0.3097168803215027 average time 0.009291576199984775 iter num 20\n",
            "loss 0.05586564540863037 average time 0.0063196328250114675 iter num 40\n",
            "loss 0.11820711195468903 average time 0.005271221033331131 iter num 60\n",
            "loss 0.19948311150074005 average time 0.004763781812494016 iter num 80\n",
            "loss 0.1331137865781784 average time 0.004453447209984915 iter num 100\n",
            "loss 0.06601254642009735 average time 0.009421199599955798 iter num 20\n",
            "loss 0.2578875422477722 average time 0.0063096008999764305 iter num 40\n",
            "loss 0.19971132278442383 average time 0.005270433983340202 iter num 60\n",
            "loss 0.14773355424404144 average time 0.00476353623751038 iter num 80\n",
            "loss 0.14481621980667114 average time 0.004448690649996934 iter num 100\n",
            "loss 0.09643067419528961 average time 0.008998493750004855 iter num 20\n",
            "loss 0.15324634313583374 average time 0.006097331974990539 iter num 40\n",
            "loss 0.19712719321250916 average time 0.005142374249968876 iter num 60\n",
            "loss 0.25301241874694824 average time 0.004653462549981668 iter num 80\n",
            "loss 0.1439206451177597 average time 0.004368371759983347 iter num 100\n",
            "loss 0.2393045872449875 average time 0.009113268999976753 iter num 20\n",
            "loss 0.1094253659248352 average time 0.006260703925011058 iter num 40\n",
            "loss 0.11380691826343536 average time 0.005317973866673735 iter num 60\n",
            "loss 0.05806668847799301 average time 0.00481932913751848 iter num 80\n",
            "loss 0.06159921735525131 average time 0.004517717770017953 iter num 100\n",
            "loss 0.12004773318767548 average time 0.009790533649947974 iter num 20\n",
            "loss 0.3320317268371582 average time 0.006570922574996985 iter num 40\n",
            "loss 0.22207999229431152 average time 0.005484277333342409 iter num 60\n",
            "loss 0.15340697765350342 average time 0.004941913150008759 iter num 80\n",
            "loss 0.15411734580993652 average time 0.004654332600007365 iter num 100\n",
            "loss 0.3953503966331482 average time 0.009014043549950657 iter num 20\n",
            "loss 0.10850371420383453 average time 0.006128791600008299 iter num 40\n",
            "loss 0.08304505795240402 average time 0.005154162799984382 iter num 60\n",
            "loss 0.03809735178947449 average time 0.004663713899981303 iter num 80\n",
            "loss 0.058055195957422256 average time 0.004375523889980287 iter num 100\n",
            "loss 0.20319761335849762 average time 0.009301461450013449 iter num 20\n",
            "loss 0.33891499042510986 average time 0.00628541895005128 iter num 40\n",
            "loss 0.18246299028396606 average time 0.00526159115001974 iter num 60\n",
            "loss 0.2749794125556946 average time 0.004736464362514426 iter num 80\n",
            "loss 0.04629844054579735 average time 0.004431949070008159 iter num 100\n",
            "loss 0.39379334449768066 average time 0.00967494184997122 iter num 20\n",
            "loss 0.15171387791633606 average time 0.00649129799999173 iter num 40\n",
            "loss 0.18764014542102814 average time 0.0053917659166624315 iter num 60\n",
            "loss 0.14307886362075806 average time 0.004842594550001422 iter num 80\n",
            "loss 0.1048489362001419 average time 0.004504237390001435 iter num 100\n",
            "loss 0.06772717833518982 average time 0.009420411299993247 iter num 20\n",
            "loss 0.15829774737358093 average time 0.006394148699985181 iter num 40\n",
            "loss 0.1180102601647377 average time 0.005387477100005829 iter num 60\n",
            "loss 0.1536220908164978 average time 0.004892884874999481 iter num 80\n",
            "loss 0.16998650133609772 average time 0.004629198579996227 iter num 100\n",
            "loss 0.49913936853408813 average time 0.010066701399932754 iter num 20\n",
            "loss 0.18321405351161957 average time 0.00670872777494651 iter num 40\n",
            "loss 0.17786119878292084 average time 0.005577125216639918 iter num 60\n",
            "loss 0.035713814198970795 average time 0.005016539649989227 iter num 80\n",
            "loss 0.08464747667312622 average time 0.00467150008997578 iter num 100\n",
            "loss 0.5166040658950806 average time 0.009953467049922438 iter num 20\n",
            "loss 1.2070094347000122 average time 0.006620206149966635 iter num 40\n",
            "loss 0.24091438949108124 average time 0.005490087449978394 iter num 60\n",
            "loss 0.10140882432460785 average time 0.004919904062495562 iter num 80\n",
            "loss 0.10909636318683624 average time 0.00458741441998427 iter num 100\n",
            "loss 0.10221967846155167 average time 0.00917761669995798 iter num 20\n",
            "loss 0.021352970972657204 average time 0.006188685050005915 iter num 40\n",
            "loss 0.1033051460981369 average time 0.005188110516693693 iter num 60\n",
            "loss 0.09923359751701355 average time 0.004683628300006149 iter num 80\n",
            "loss 0.10828588157892227 average time 0.0043878379500074515 iter num 100\n",
            "loss 0.13249152898788452 average time 0.009391746949950175 iter num 20\n",
            "loss 0.3693481981754303 average time 0.0063357998999549634 iter num 40\n",
            "loss 0.1789940893650055 average time 0.005300410033282787 iter num 60\n",
            "loss 0.11661368608474731 average time 0.004781643274952785 iter num 80\n",
            "loss 0.09525974094867706 average time 0.004474887659957858 iter num 100\n",
            "loss 0.07149258255958557 average time 0.009452240399969013 iter num 20\n",
            "loss 1.1602015495300293 average time 0.0064336549750123595 iter num 40\n",
            "loss 0.6006602644920349 average time 0.005430433116657696 iter num 60\n",
            "loss 0.085428386926651 average time 0.004909876662486568 iter num 80\n",
            "loss 0.09019067138433456 average time 0.004601992379984949 iter num 100\n",
            "loss 0.15136167407035828 average time 0.010027355850002095 iter num 20\n",
            "loss 0.08693356812000275 average time 0.006683628675045838 iter num 40\n",
            "loss 0.29335901141166687 average time 0.005573202200055979 iter num 60\n",
            "loss 0.12115581333637238 average time 0.005019389100050375 iter num 80\n",
            "loss 0.10193163901567459 average time 0.004694623610043891 iter num 100\n",
            "loss 0.2268706113100052 average time 0.009946044199978132 iter num 20\n",
            "loss 0.8295149803161621 average time 0.006613975375000791 iter num 40\n",
            "loss 0.3444005846977234 average time 0.00549449128334345 iter num 60\n",
            "loss 0.08146747946739197 average time 0.004933868825025911 iter num 80\n",
            "loss 0.08370356261730194 average time 0.004599809530031962 iter num 100\n",
            "loss 0.07184536755084991 average time 0.009493204449995574 iter num 20\n",
            "loss 0.16995231807231903 average time 0.006340201824957603 iter num 40\n",
            "loss 0.08859910070896149 average time 0.0052961787333060785 iter num 60\n",
            "loss 0.17905759811401367 average time 0.004760605412474206 iter num 80\n",
            "loss 0.10895119607448578 average time 0.004448950209985014 iter num 100\n",
            "loss 0.1341582089662552 average time 0.00961000189997776 iter num 20\n",
            "loss 0.2562521696090698 average time 0.006414861124972049 iter num 40\n",
            "loss 0.07506480067968369 average time 0.005352610549994097 iter num 60\n",
            "loss 0.047067947685718536 average time 0.004816171562487171 iter num 80\n",
            "loss 0.0618864968419075 average time 0.004500459639980363 iter num 100\n",
            "loss 0.2832180857658386 average time 0.009757543849991635 iter num 20\n",
            "loss 0.42730215191841125 average time 0.006514887074979469 iter num 40\n",
            "loss 0.47572121024131775 average time 0.005438516366651432 iter num 60\n",
            "loss 0.10842062532901764 average time 0.0049263837874832465 iter num 80\n",
            "loss 0.08025719225406647 average time 0.0046044447200074504 iter num 100\n",
            "loss 0.17960608005523682 average time 0.009857135700008257 iter num 20\n",
            "loss 0.1564949005842209 average time 0.006587231949970374 iter num 40\n",
            "loss 0.22987273335456848 average time 0.005511934716651012 iter num 60\n",
            "loss 0.22563497722148895 average time 0.004974154587483781 iter num 80\n",
            "loss 0.12156146764755249 average time 0.004647352470001352 iter num 100\n",
            "loss 0.32542628049850464 average time 0.00961333674999878 iter num 20\n",
            "loss 0.12551376223564148 average time 0.006473872249989654 iter num 40\n",
            "loss 0.1576414853334427 average time 0.0054386826999916595 iter num 60\n",
            "loss 0.09400208294391632 average time 0.004893264112490669 iter num 80\n",
            "loss 0.03635214641690254 average time 0.004553843349981435 iter num 100\n",
            "loss 0.06363966315984726 average time 0.0091445767499863 iter num 20\n",
            "loss 0.3182646930217743 average time 0.006175316999963343 iter num 40\n",
            "loss 0.04960302636027336 average time 0.005237575916657989 iter num 60\n",
            "loss 0.15763640403747559 average time 0.0047341298125047615 iter num 80\n",
            "loss 0.15872761607170105 average time 0.00442534933000843 iter num 100\n",
            "loss 0.0772346705198288 average time 0.00931974780000928 iter num 20\n",
            "loss 0.1575939953327179 average time 0.00625840032502083 iter num 40\n",
            "loss 0.1678406000137329 average time 0.00524587423333287 iter num 60\n",
            "loss 0.13215535879135132 average time 0.004729052337495432 iter num 80\n",
            "loss 0.04802572354674339 average time 0.004431074899994201 iter num 100\n",
            "loss 0.22905834019184113 average time 0.009473131599975204 iter num 20\n",
            "loss 0.1508476287126541 average time 0.00633352044997082 iter num 40\n",
            "loss 0.10175624489784241 average time 0.005301212099978633 iter num 60\n",
            "loss 0.042085856199264526 average time 0.004764484937476254 iter num 80\n",
            "loss 0.07857924699783325 average time 0.0044732675399836806 iter num 100\n",
            "loss 0.7351533770561218 average time 0.009459912100010116 iter num 20\n",
            "loss 0.3409843444824219 average time 0.006375990650019503 iter num 40\n",
            "loss 0.13750503957271576 average time 0.005361126716684339 iter num 60\n",
            "loss 0.05317475646734238 average time 0.004861279800013563 iter num 80\n",
            "loss 0.06425899267196655 average time 0.004554784100023425 iter num 100\n",
            "loss 0.1623498797416687 average time 0.010319670750027399 iter num 20\n",
            "loss 0.24604904651641846 average time 0.006854199675001382 iter num 40\n",
            "loss 0.07203052192926407 average time 0.0056832545000133905 iter num 60\n",
            "loss 0.0907813012599945 average time 0.005078023550015587 iter num 80\n",
            "loss 0.06453660130500793 average time 0.004715769370018279 iter num 100\n",
            "loss 0.7136660814285278 average time 0.009680857100033791 iter num 20\n",
            "loss 0.5679091811180115 average time 0.0064685974499866464 iter num 40\n",
            "loss 0.23509515821933746 average time 0.005426621466661648 iter num 60\n",
            "loss 0.12233570218086243 average time 0.004897693662485381 iter num 80\n",
            "loss 0.09175877273082733 average time 0.004590367240007253 iter num 100\n",
            "loss 0.09795744717121124 average time 0.009552139899983558 iter num 20\n",
            "loss 0.027402635663747787 average time 0.006452135150004779 iter num 40\n",
            "loss 0.14304004609584808 average time 0.0054129144333425454 iter num 60\n",
            "loss 0.0789150595664978 average time 0.004892636687526419 iter num 80\n",
            "loss 0.138283833861351 average time 0.004601334290000523 iter num 100\n",
            "loss 0.21750810742378235 average time 0.00992474540000785 iter num 20\n",
            "loss 1.525155782699585 average time 0.006572885800039785 iter num 40\n",
            "loss 1.2123870849609375 average time 0.005459779833351301 iter num 60\n",
            "loss 0.2290945053100586 average time 0.004893458600002986 iter num 80\n",
            "loss 0.10512039065361023 average time 0.004552108030011368 iter num 100\n",
            "loss 0.20128566026687622 average time 0.009563846399987596 iter num 20\n",
            "loss 0.15496595203876495 average time 0.006395489875012572 iter num 40\n",
            "loss 0.2954366207122803 average time 0.005333758183329943 iter num 60\n",
            "loss 0.06268589943647385 average time 0.004810033737487629 iter num 80\n",
            "loss 0.029682952910661697 average time 0.004490198149983371 iter num 100\n",
            "loss 0.1799778938293457 average time 0.009368755349964886 iter num 20\n",
            "loss 0.7178407907485962 average time 0.006274896050001644 iter num 40\n",
            "loss 0.10082944482564926 average time 0.005245753449995997 iter num 60\n",
            "loss 0.0421999953687191 average time 0.004729477062505793 iter num 80\n",
            "loss 0.10699304193258286 average time 0.0044155268900112786 iter num 100\n",
            "loss 0.1761191189289093 average time 0.008956989650050673 iter num 20\n",
            "loss 0.3799229860305786 average time 0.006073131675032073 iter num 40\n",
            "loss 0.1555221676826477 average time 0.005140940483352096 iter num 60\n",
            "loss 0.09722170233726501 average time 0.004703856037525611 iter num 80\n",
            "loss 0.02512277103960514 average time 0.0044298183200180575 iter num 100\n",
            "loss 0.24192263185977936 average time 0.00963065080004526 iter num 20\n",
            "loss 0.4036463499069214 average time 0.006493786950034064 iter num 40\n",
            "loss 0.07801714539527893 average time 0.0054289239833375785 iter num 60\n",
            "loss 0.11253318935632706 average time 0.004909599525007025 iter num 80\n",
            "loss 0.07084851711988449 average time 0.004575051270003314 iter num 100\n",
            "loss 0.1923857480287552 average time 0.010020153900018158 iter num 20\n",
            "loss 0.11907979846000671 average time 0.006684104950022629 iter num 40\n",
            "loss 0.07204299420118332 average time 0.005552108133391205 iter num 60\n",
            "loss 0.04510817676782608 average time 0.004951542150053001 iter num 80\n",
            "loss 0.09635767340660095 average time 0.004604196200039041 iter num 100\n",
            "loss 0.19485193490982056 average time 0.009170940950070872 iter num 20\n",
            "loss 0.06502573192119598 average time 0.006252081150023514 iter num 40\n",
            "loss 0.10156137496232986 average time 0.00524914026669497 iter num 60\n",
            "loss 0.23637689650058746 average time 0.004834974837524442 iter num 80\n",
            "loss 0.09247802197933197 average time 0.004522039660027986 iter num 100\n",
            "loss 0.8340051174163818 average time 0.009263702250018468 iter num 20\n",
            "loss 0.257018119096756 average time 0.006252915575009866 iter num 40\n",
            "loss 0.14148582518100739 average time 0.005227715249967939 iter num 60\n",
            "loss 0.09025564044713974 average time 0.004710863487485994 iter num 80\n",
            "loss 0.06710270047187805 average time 0.004404805519998263 iter num 100\n",
            "loss 1.118373990058899 average time 0.00909245129998908 iter num 20\n",
            "loss 0.10431449115276337 average time 0.006161420550017738 iter num 40\n",
            "loss 0.2745407819747925 average time 0.005189176966678133 iter num 60\n",
            "loss 0.18354105949401855 average time 0.004711997687491021 iter num 80\n",
            "loss 0.0845298171043396 average time 0.004461719989990343 iter num 100\n",
            "loss 0.10787607729434967 average time 0.010134407200007444 iter num 20\n",
            "loss 0.04983127862215042 average time 0.006721036450005613 iter num 40\n",
            "loss 0.061513133347034454 average time 0.005625675583337398 iter num 60\n",
            "loss 0.18460030853748322 average time 0.005072219349995066 iter num 80\n",
            "loss 0.027306005358695984 average time 0.00472558412998751 iter num 100\n",
            "loss 0.08772484958171844 average time 0.01039535504989999 iter num 20\n",
            "loss 0.06125607341527939 average time 0.006857312349950462 iter num 40\n",
            "loss 0.13044682145118713 average time 0.005695015049976367 iter num 60\n",
            "loss 0.08129715919494629 average time 0.005114955187485748 iter num 80\n",
            "loss 0.09931990504264832 average time 0.0047333376700044024 iter num 100\n",
            "loss 0.4950459599494934 average time 0.009315922800078624 iter num 20\n",
            "loss 0.10562705248594284 average time 0.006281453800045256 iter num 40\n",
            "loss 0.12198445945978165 average time 0.00525902270004129 iter num 60\n",
            "loss 0.16865046322345734 average time 0.004744270550025931 iter num 80\n",
            "loss 0.10577721148729324 average time 0.004427497790020425 iter num 100\n",
            "loss 0.19181448221206665 average time 0.009358683849973204 iter num 20\n",
            "loss 0.1701376587152481 average time 0.006314165800006322 iter num 40\n",
            "loss 0.16458012163639069 average time 0.005285441766667039 iter num 60\n",
            "loss 0.04102441295981407 average time 0.004769852575003597 iter num 80\n",
            "loss 0.15844452381134033 average time 0.004474155460011389 iter num 100\n",
            "loss 0.21129658818244934 average time 0.00929234720003933 iter num 20\n",
            "loss 0.09248970448970795 average time 0.006292360175041267 iter num 40\n",
            "loss 0.07562249898910522 average time 0.0052569799500209536 iter num 60\n",
            "loss 0.09538185596466064 average time 0.004758428437531848 iter num 80\n",
            "loss 0.11632874608039856 average time 0.004464227160024165 iter num 100\n",
            "loss 0.21746325492858887 average time 0.00972562465003648 iter num 20\n",
            "loss 0.3742455840110779 average time 0.0065366430500148455 iter num 40\n",
            "loss 0.2450447529554367 average time 0.005481814333332598 iter num 60\n",
            "loss 0.11451070010662079 average time 0.004948846912492399 iter num 80\n",
            "loss 0.11060397326946259 average time 0.00464392030999079 iter num 100\n",
            "loss 1.8377143144607544 average time 0.010082147549951515 iter num 20\n",
            "loss 1.3240666389465332 average time 0.006714381149959081 iter num 40\n",
            "loss 0.24577170610427856 average time 0.005613559899999624 iter num 60\n",
            "loss 0.0608171783387661 average time 0.005039302837496961 iter num 80\n",
            "loss 0.0771682932972908 average time 0.004686204619983983 iter num 100\n",
            "loss 0.13100619614124298 average time 0.009521543649975683 iter num 20\n",
            "loss 0.11395804584026337 average time 0.0063607537499933645 iter num 40\n",
            "loss 0.14266613125801086 average time 0.005301749316648359 iter num 60\n",
            "loss 0.04570457711815834 average time 0.004771258787502575 iter num 80\n",
            "loss 0.08096544444561005 average time 0.0044559036900000135 iter num 100\n",
            "loss 0.053191520273685455 average time 0.00934239670000352 iter num 20\n",
            "loss 0.11860916763544083 average time 0.00626875152501043 iter num 40\n",
            "loss 0.097057044506073 average time 0.00525001664999157 iter num 60\n",
            "loss 0.1599361151456833 average time 0.004734156649999477 iter num 80\n",
            "loss 0.12823626399040222 average time 0.004433676080002442 iter num 100\n",
            "loss 0.09887155145406723 average time 0.008912821100034307 iter num 20\n",
            "loss 0.09479282796382904 average time 0.006030422975038618 iter num 40\n",
            "loss 0.08327463269233704 average time 0.00515492830002889 iter num 60\n",
            "loss 0.028591398149728775 average time 0.004666036962527187 iter num 80\n",
            "loss 0.0349244624376297 average time 0.004385550660022091 iter num 100\n",
            "loss 0.40771085023880005 average time 0.009398472649991163 iter num 20\n",
            "loss 0.3318988084793091 average time 0.00645026219999636 iter num 40\n",
            "loss 0.11793360859155655 average time 0.005417763416661122 iter num 60\n",
            "loss 0.2052002251148224 average time 0.0049106537000113805 iter num 80\n",
            "loss 0.07759442180395126 average time 0.004599969090008926 iter num 100\n",
            "loss 0.07465368509292603 average time 0.00964541064995501 iter num 20\n",
            "loss 0.1340939700603485 average time 0.006510628825003551 iter num 40\n",
            "loss 0.09296252578496933 average time 0.005465880883336164 iter num 60\n",
            "loss 0.13125775754451752 average time 0.004935210050018668 iter num 80\n",
            "loss 0.17416667938232422 average time 0.004629290980005862 iter num 100\n",
            "loss 0.18685199320316315 average time 0.010385682249943785 iter num 20\n",
            "loss 0.10324661433696747 average time 0.006808737249957631 iter num 40\n",
            "loss 0.10633566230535507 average time 0.005608419499988789 iter num 60\n",
            "loss 0.10134017467498779 average time 0.005039630399994621 iter num 80\n",
            "loss 0.04769645631313324 average time 0.004705821499987906 iter num 100\n",
            "loss 0.6874391436576843 average time 0.009771511849930904 iter num 20\n",
            "loss 0.7549788355827332 average time 0.006577637525003866 iter num 40\n",
            "loss 0.1824045479297638 average time 0.005510836333337465 iter num 60\n",
            "loss 0.1695125699043274 average time 0.004973692749990733 iter num 80\n",
            "loss 0.13387955725193024 average time 0.004652332139989994 iter num 100\n",
            "loss 0.07431364804506302 average time 0.01014187684997978 iter num 20\n",
            "loss 0.17372076213359833 average time 0.006802645449988631 iter num 40\n",
            "loss 0.20110352337360382 average time 0.005656515833356935 iter num 60\n",
            "loss 0.11157296597957611 average time 0.005044751712523521 iter num 80\n",
            "loss 0.11821014434099197 average time 0.004667414490008923 iter num 100\n",
            "loss 0.2694151997566223 average time 0.009456286749968967 iter num 20\n",
            "loss 0.23645246028900146 average time 0.006329613299988069 iter num 40\n",
            "loss 0.20413151383399963 average time 0.005291437666649775 iter num 60\n",
            "loss 0.08854971081018448 average time 0.00477735221248281 iter num 80\n",
            "loss 0.23185698688030243 average time 0.004460024069994688 iter num 100\n",
            "loss 0.09535433351993561 average time 0.009127170850047151 iter num 20\n",
            "loss 0.14491558074951172 average time 0.006172612750049211 iter num 40\n",
            "loss 0.12924863398075104 average time 0.005248767616702329 iter num 60\n",
            "loss 0.13698196411132812 average time 0.004732504262523207 iter num 80\n",
            "loss 0.10420446842908859 average time 0.004434790830009661 iter num 100\n",
            "loss 0.17855720221996307 average time 0.009483627000054184 iter num 20\n",
            "loss 0.14341109991073608 average time 0.006354523975016946 iter num 40\n",
            "loss 0.14777059853076935 average time 0.005291212549999121 iter num 60\n",
            "loss 0.09194496273994446 average time 0.004757429412512693 iter num 80\n",
            "loss 0.06974057108163834 average time 0.004463600670023879 iter num 100\n",
            "loss 0.1565195471048355 average time 0.009758166799997525 iter num 20\n",
            "loss 0.1808851957321167 average time 0.0066361860500251165 iter num 40\n",
            "loss 0.06097707152366638 average time 0.005526407733358004 iter num 60\n",
            "loss 0.08014050126075745 average time 0.004981492850009772 iter num 80\n",
            "loss 0.03689314424991608 average time 0.00465216005000002 iter num 100\n",
            "loss 0.7063872814178467 average time 0.009663714500015885 iter num 20\n",
            "loss 0.6344133615493774 average time 0.006503074525016928 iter num 40\n",
            "loss 0.224800705909729 average time 0.005446121783324998 iter num 60\n",
            "loss 0.12294067442417145 average time 0.004915572274990154 iter num 80\n",
            "loss 0.06193843483924866 average time 0.004574850209992292 iter num 100\n",
            "loss 1.0064092874526978 average time 0.00949945414990907 iter num 20\n",
            "loss 0.4339992105960846 average time 0.006388554774946442 iter num 40\n",
            "loss 0.2184193730354309 average time 0.005335354816649366 iter num 60\n",
            "loss 0.07953410595655441 average time 0.004798280374990327 iter num 80\n",
            "loss 0.04531963914632797 average time 0.0044879168599891274 iter num 100\n",
            "loss 0.11199870705604553 average time 0.008928079950010215 iter num 20\n",
            "loss 0.05748976767063141 average time 0.006082568950046152 iter num 40\n",
            "loss 0.035605017095804214 average time 0.005152195950025392 iter num 60\n",
            "loss 0.049567148089408875 average time 0.00469543211254404 iter num 80\n",
            "loss 0.10846838355064392 average time 0.004408611390017541 iter num 100\n",
            "loss 0.46450453996658325 average time 0.009396792300003653 iter num 20\n",
            "loss 0.11120059341192245 average time 0.006310379325009307 iter num 40\n",
            "loss 0.08409592509269714 average time 0.005281593183296233 iter num 60\n",
            "loss 0.07216203957796097 average time 0.0047681315499858105 iter num 80\n",
            "loss 0.05985323339700699 average time 0.004456387199988967 iter num 100\n",
            "loss 0.0695742815732956 average time 0.009940016049904443 iter num 20\n",
            "loss 0.13538599014282227 average time 0.006663868499890669 iter num 40\n",
            "loss 0.054913222789764404 average time 0.005546512183248827 iter num 60\n",
            "loss 0.13008661568164825 average time 0.004996842362436383 iter num 80\n",
            "loss 0.044294361025094986 average time 0.004669701199927659 iter num 100\n",
            "loss 0.28561097383499146 average time 0.009794812450081736 iter num 20\n",
            "loss 0.22769257426261902 average time 0.006590487175003545 iter num 40\n",
            "loss 0.22576361894607544 average time 0.005514402816652364 iter num 60\n",
            "loss 0.031197231262922287 average time 0.004995367987464761 iter num 80\n",
            "loss 0.04867443069815636 average time 0.004703588980000859 iter num 100\n",
            "loss 1.0418565273284912 average time 0.009885579450065051 iter num 20\n",
            "loss 0.20329418778419495 average time 0.006569588449997355 iter num 40\n",
            "loss 0.2108955830335617 average time 0.00544677768331591 iter num 60\n",
            "loss 0.09734171628952026 average time 0.0048933283125052185 iter num 80\n",
            "loss 0.09818721562623978 average time 0.004564702009975008 iter num 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 30000\n",
              "\tepoch: 300\n",
              "\tepoch_length: 100\n",
              "\tmax_epochs: 300\n",
              "\toutput: 0.09818721562623978\n",
              "\tbatch: <class 'tuple'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: <class 'cupy_dataset.NumbaOptionDataSet'>\n",
              "\tseed: <class 'NoneType'>\n",
              "\ttimes: <class 'dict'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU1EpGuInwjJ"
      },
      "source": [
        "$2365$ seconds The loss is keeping decreasing which means the pricing model can predict the option prices better. It takes about $12ms$ to compute one mini-batch in average, In the following sections, we will try to expore the full potentials of the GPU to accelerate the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8McNtejRNFT"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRtOr1XIPOvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f5674c1-8ab8-4fd1-f3bb-1972184c3503"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UWrNr_-pa2G"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndftly2yPEaM"
      },
      "source": [
        "model_save_name = 'checkpoint_1Stock_Yidong.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Lilian/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6DRO9K2RQoJ"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGXZSV_YRT8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4419af5c-0234-4616-eddf-6e69630b17e6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ntY-N5bOqdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6224d08-6928-4fac-b4fe-92e6db3e3e79"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'checkpoint_1Stock_Yidong.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Lilian/{model_save_name}\" \n",
        "#checkpoint15.pth\n",
        "#path = F\"/content/drive/MyDrive/AFP Project/Lilian/checkpoint15.pth\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0GAGPAgPmgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4487b253-4aa7-42ac-92d7-1a8403dfce52"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=6, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc5): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc6): Linear(in_features=1024, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXT4Bg0wdL7l"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfa9cp6CdG8T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c84f281d-5cb1-4192-998b-9898f2e7ee98"
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import NumbaOptionDataSet\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "# dataset = NumbaOptionDataSet(max_len=10000, number_path = 1024, batch=4800)\n",
        "dataset = NumbaOptionDataSet(max_len=500, number_path = 1024, batch=32, stocks=1)\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred[:,0], y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs=300)\n",
        "\n",
        "model_save_name = 'checkpoint16.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Lilian/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss 7.214704513549805 average time 0.015507421699976476 iter num 20\n",
            "loss 1.0778486728668213 average time 0.009840025049993529 iter num 40\n",
            "loss 0.37314093112945557 average time 0.007902153366671882 iter num 60\n",
            "loss 0.306063711643219 average time 0.006950461224994342 iter num 80\n",
            "loss 0.3060457706451416 average time 0.0063979668899946775 iter num 100\n",
            "loss 0.19354447722434998 average time 0.0060052794833268305 iter num 120\n",
            "loss 0.19129589200019836 average time 0.00572158151428539 iter num 140\n",
            "loss 0.1863013505935669 average time 0.005510465581252788 iter num 160\n",
            "loss 0.15241162478923798 average time 0.0053492253166647664 iter num 180\n",
            "loss 0.2375759482383728 average time 0.005228159155005869 iter num 200\n",
            "loss 0.3298381268978119 average time 0.005123763645457819 iter num 220\n",
            "loss 0.41137880086898804 average time 0.005033318275000435 iter num 240\n",
            "loss 0.14944978058338165 average time 0.0049600181653834 iter num 260\n",
            "loss 0.15932652354240417 average time 0.004895639089293777 iter num 280\n",
            "loss 0.15333381295204163 average time 0.004875555453343926 iter num 300\n",
            "loss 0.16098552942276 average time 0.0048263316875065245 iter num 320\n",
            "loss 0.5444318652153015 average time 0.004787780032357017 iter num 340\n",
            "loss 0.5010879039764404 average time 0.0047464697777829514 iter num 360\n",
            "loss 0.14413729310035706 average time 0.004712920626323131 iter num 380\n",
            "loss 0.3566768765449524 average time 0.004680095072507129 iter num 400\n",
            "loss 0.21139375865459442 average time 0.004650004123816741 iter num 420\n",
            "loss 0.25093874335289 average time 0.004626371618193885 iter num 440\n",
            "loss 0.08496526628732681 average time 0.004600666567399537 iter num 460\n",
            "loss 0.17688263952732086 average time 0.004581544022923367 iter num 480\n",
            "loss 0.13023924827575684 average time 0.0045605451880055626 iter num 500\n",
            "loss 0.4371236264705658 average time 0.012819691349932327 iter num 20\n",
            "loss 0.5790501236915588 average time 0.0084783915249659 iter num 40\n",
            "loss 0.24858808517456055 average time 0.007002534333287258 iter num 60\n",
            "loss 0.30499327182769775 average time 0.006261606987459345 iter num 80\n",
            "loss 0.30719542503356934 average time 0.0058210221699664545 iter num 100\n",
            "loss 0.4809126555919647 average time 0.005534481991651319 iter num 120\n",
            "loss 0.549069881439209 average time 0.005322743314283279 iter num 140\n",
            "loss 0.3416160047054291 average time 0.005174246981246711 iter num 160\n",
            "loss 0.3294905424118042 average time 0.0050686930222228616 iter num 180\n",
            "loss 0.21338370442390442 average time 0.004973254855001414 iter num 200\n",
            "loss 0.28984206914901733 average time 0.004898272827280049 iter num 220\n",
            "loss 0.2248842418193817 average time 0.004834723091674201 iter num 240\n",
            "loss 0.31428560614585876 average time 0.004792728976929958 iter num 260\n",
            "loss 0.20035526156425476 average time 0.004736816471431991 iter num 280\n",
            "loss 0.23274163901805878 average time 0.004689820126673112 iter num 300\n",
            "loss 0.14954392611980438 average time 0.004662609062506817 iter num 320\n",
            "loss 0.1149064153432846 average time 0.00462657075000366 iter num 340\n",
            "loss 0.3536792993545532 average time 0.004597242233337006 iter num 360\n",
            "loss 0.26343268156051636 average time 0.004568324189480527 iter num 380\n",
            "loss 0.2692575454711914 average time 0.004542401725009313 iter num 400\n",
            "loss 0.3054847717285156 average time 0.004518781376197824 iter num 420\n",
            "loss 0.24659612774848938 average time 0.004501598638643662 iter num 440\n",
            "loss 0.27977484464645386 average time 0.004480532489135484 iter num 460\n",
            "loss 0.16133897006511688 average time 0.004463277395838835 iter num 480\n",
            "loss 0.2289743274450302 average time 0.0044484950660034885 iter num 500\n",
            "loss 0.30859118700027466 average time 0.012906179449942101 iter num 20\n",
            "loss 1.1582106351852417 average time 0.008469221599978028 iter num 40\n",
            "loss 0.9867253303527832 average time 0.0069906366833265565 iter num 60\n",
            "loss 2.2873988151550293 average time 0.006272129074983468 iter num 80\n",
            "loss 0.3043178617954254 average time 0.005832669339997665 iter num 100\n",
            "loss 2.1449038982391357 average time 0.005583357691671153 iter num 120\n",
            "loss 0.6352052688598633 average time 0.00536537655000302 iter num 140\n",
            "loss 0.7132024765014648 average time 0.0051992192312468434 iter num 160\n",
            "loss 0.5518878102302551 average time 0.005069939161103321 iter num 180\n",
            "loss 0.2473783791065216 average time 0.004978734799994982 iter num 200\n",
            "loss 0.4992173910140991 average time 0.004917054468176667 iter num 220\n",
            "loss 0.5275574326515198 average time 0.004847425454166417 iter num 240\n",
            "loss 0.37251901626586914 average time 0.004784766007688072 iter num 260\n",
            "loss 0.15906192362308502 average time 0.0047343431857127275 iter num 280\n",
            "loss 0.8759022951126099 average time 0.004691274453331668 iter num 300\n",
            "loss 0.39416468143463135 average time 0.004652762865626414 iter num 320\n",
            "loss 0.043231572955846786 average time 0.0046265622852963454 iter num 340\n",
            "loss 0.10871338099241257 average time 0.004597445275001317 iter num 360\n",
            "loss 0.2526854872703552 average time 0.004576582047372157 iter num 380\n",
            "loss 0.20572781562805176 average time 0.004565253310003073 iter num 400\n",
            "loss 0.48124176263809204 average time 0.004541917204766746 iter num 420\n",
            "loss 0.3501541018486023 average time 0.004520226097731045 iter num 440\n",
            "loss 0.2753365635871887 average time 0.004501865982614538 iter num 460\n",
            "loss 0.49289876222610474 average time 0.0044836603708394785 iter num 480\n",
            "loss 0.18132929503917694 average time 0.004469611284007442 iter num 500\n",
            "loss 0.979407012462616 average time 0.013059857900043426 iter num 20\n",
            "loss 0.9922518730163574 average time 0.008593196375011302 iter num 40\n",
            "loss 0.8379126191139221 average time 0.007074917883323905 iter num 60\n",
            "loss 1.300997018814087 average time 0.006318855074988505 iter num 80\n",
            "loss 1.348501443862915 average time 0.005870438500001001 iter num 100\n",
            "loss 2.7960381507873535 average time 0.005563769283321562 iter num 120\n",
            "loss 1.517947793006897 average time 0.0053515484714223155 iter num 140\n",
            "loss 0.5065560936927795 average time 0.005193978400001242 iter num 160\n",
            "loss 0.43688756227493286 average time 0.005082366166670404 iter num 180\n",
            "loss 0.339716374874115 average time 0.005011863810004798 iter num 200\n",
            "loss 0.33903321623802185 average time 0.004947153327266691 iter num 220\n",
            "loss 0.47399210929870605 average time 0.004879623308333218 iter num 240\n",
            "loss 0.06243351101875305 average time 0.004819332180766021 iter num 260\n",
            "loss 0.2934645712375641 average time 0.004769919707137303 iter num 280\n",
            "loss 0.3517278730869293 average time 0.00472651779666497 iter num 300\n",
            "loss 0.14556318521499634 average time 0.004694948262498144 iter num 320\n",
            "loss 0.8023731708526611 average time 0.004670306723527146 iter num 340\n",
            "loss 0.3286616802215576 average time 0.004635041208329463 iter num 360\n",
            "loss 0.1965770721435547 average time 0.004608091636835429 iter num 380\n",
            "loss 0.16054633259773254 average time 0.004584884909993434 iter num 400\n",
            "loss 0.1601083129644394 average time 0.004561111569040847 iter num 420\n",
            "loss 0.4105948209762573 average time 0.004542368627264957 iter num 440\n",
            "loss 0.13620170950889587 average time 0.004525295297816742 iter num 460\n",
            "loss 0.1311618834733963 average time 0.004509789389575758 iter num 480\n",
            "loss 0.26874181628227234 average time 0.004492151185992043 iter num 500\n",
            "loss 7.268255233764648 average time 0.012667622999947526 iter num 20\n",
            "loss 0.5216573476791382 average time 0.008446418349979012 iter num 40\n",
            "loss 0.7280447483062744 average time 0.007021754283300652 iter num 60\n",
            "loss 1.6115362644195557 average time 0.006289250412470438 iter num 80\n",
            "loss 0.5219078660011292 average time 0.005843938279967915 iter num 100\n",
            "loss 1.0205763578414917 average time 0.005545855058297396 iter num 120\n",
            "loss 4.01356840133667 average time 0.005342950835672257 iter num 140\n",
            "loss 0.4996996521949768 average time 0.005206035337457138 iter num 160\n",
            "loss 0.5157113075256348 average time 0.005075674305516663 iter num 180\n",
            "loss 0.37310922145843506 average time 0.00500561164996725 iter num 200\n",
            "loss 0.2512030303478241 average time 0.004931492940876193 iter num 220\n",
            "loss 0.2098282277584076 average time 0.004859682541634432 iter num 240\n",
            "loss 0.4876079559326172 average time 0.004795845403808786 iter num 260\n",
            "loss 0.16131708025932312 average time 0.004745655610679478 iter num 280\n",
            "loss 0.3525291681289673 average time 0.00470177390329809 iter num 300\n",
            "loss 0.4952668249607086 average time 0.004667473584346738 iter num 320\n",
            "loss 0.23364640772342682 average time 0.004643865702916414 iter num 340\n",
            "loss 0.37578126788139343 average time 0.004612601047201932 iter num 360\n",
            "loss 0.1686909794807434 average time 0.004588162936824789 iter num 380\n",
            "loss 0.1202993243932724 average time 0.004569474824983218 iter num 400\n",
            "loss 0.22510480880737305 average time 0.004561069495222606 iter num 420\n",
            "loss 0.08898046612739563 average time 0.004548029270441393 iter num 440\n",
            "loss 0.2867492139339447 average time 0.004536367078251557 iter num 460\n",
            "loss 0.20591150224208832 average time 0.004521732585407297 iter num 480\n",
            "loss 0.1349083036184311 average time 0.004504592131993377 iter num 500\n",
            "loss 1.7706434726715088 average time 0.012982223549988703 iter num 20\n",
            "loss 2.988234519958496 average time 0.008572976749996996 iter num 40\n",
            "loss 0.7482503652572632 average time 0.007078382033334189 iter num 60\n",
            "loss 0.21748198568820953 average time 0.006353512524987082 iter num 80\n",
            "loss 0.7034395933151245 average time 0.005899739159995079 iter num 100\n",
            "loss 2.3626976013183594 average time 0.0055927881166515665 iter num 120\n",
            "loss 0.9020348787307739 average time 0.005373845842843496 iter num 140\n",
            "loss 1.5116877555847168 average time 0.005252350331227262 iter num 160\n",
            "loss 0.351081907749176 average time 0.005132104594430429 iter num 180\n",
            "loss 0.3991931080818176 average time 0.005035806699993373 iter num 200\n",
            "loss 0.4921343922615051 average time 0.004954305059081063 iter num 220\n",
            "loss 0.5164743661880493 average time 0.0048841613499917 iter num 240\n",
            "loss 0.23369374871253967 average time 0.004822904380760589 iter num 260\n",
            "loss 0.28068268299102783 average time 0.004767111117850423 iter num 280\n",
            "loss 0.30586332082748413 average time 0.004720686459992672 iter num 300\n",
            "loss 0.33319464325904846 average time 0.004680985212495159 iter num 320\n",
            "loss 0.45752161741256714 average time 0.00464599675587632 iter num 340\n",
            "loss 0.28826257586479187 average time 0.004611735772215929 iter num 360\n",
            "loss 0.29035255312919617 average time 0.004582486605255853 iter num 380\n",
            "loss 0.2873935103416443 average time 0.004589943767493878 iter num 400\n",
            "loss 0.08972771465778351 average time 0.004576786373802731 iter num 420\n",
            "loss 0.14087849855422974 average time 0.004552608297720698 iter num 440\n",
            "loss 0.37498411536216736 average time 0.004529902571733186 iter num 460\n",
            "loss 0.204315185546875 average time 0.004519175552078044 iter num 480\n",
            "loss 0.15983428061008453 average time 0.0045000156939941005 iter num 500\n",
            "loss 0.15204034745693207 average time 0.012711981450024723 iter num 20\n",
            "loss 1.2598429918289185 average time 0.00844096200007698 iter num 40\n",
            "loss 0.2855018675327301 average time 0.006975627333379937 iter num 60\n",
            "loss 1.472015619277954 average time 0.006264687662530832 iter num 80\n",
            "loss 0.3933188319206238 average time 0.005819096450027246 iter num 100\n",
            "loss 0.49345219135284424 average time 0.005541349916685098 iter num 120\n",
            "loss 0.2770841121673584 average time 0.0053315868928848435 iter num 140\n",
            "loss 0.307775616645813 average time 0.005185161418776829 iter num 160\n",
            "loss 0.3925909996032715 average time 0.005066681394466994 iter num 180\n",
            "loss 0.8205580115318298 average time 0.0049667665550168745 iter num 200\n",
            "loss 0.4165889620780945 average time 0.004885309563651803 iter num 220\n",
            "loss 0.5453365445137024 average time 0.004812726825017914 iter num 240\n",
            "loss 0.24960944056510925 average time 0.004755638061556056 iter num 260\n",
            "loss 0.4565732479095459 average time 0.004712825500015632 iter num 280\n",
            "loss 0.2487095594406128 average time 0.004675639430012477 iter num 300\n",
            "loss 0.2991848289966583 average time 0.0046395330125108105 iter num 320\n",
            "loss 0.1703956127166748 average time 0.004604980470598468 iter num 340\n",
            "loss 0.23674534261226654 average time 0.004587565216674092 iter num 360\n",
            "loss 0.3216919004917145 average time 0.004558156510528246 iter num 380\n",
            "loss 0.18497450649738312 average time 0.004541895949998888 iter num 400\n",
            "loss 0.41544997692108154 average time 0.004528714004761371 iter num 420\n",
            "loss 0.3260534107685089 average time 0.004514503338637868 iter num 440\n",
            "loss 0.4399295449256897 average time 0.004494603397826881 iter num 460\n",
            "loss 0.4286571741104126 average time 0.004479426064583928 iter num 480\n",
            "loss 0.09053236246109009 average time 0.004462275450000561 iter num 500\n",
            "loss 2.3642771244049072 average time 0.012942719599982411 iter num 20\n",
            "loss 0.566745400428772 average time 0.008492433424999035 iter num 40\n",
            "loss 0.48053833842277527 average time 0.0070059019666511325 iter num 60\n",
            "loss 0.6200450658798218 average time 0.00626826324998433 iter num 80\n",
            "loss 0.871403694152832 average time 0.00587071860998094 iter num 100\n",
            "loss 2.5800886154174805 average time 0.005569606216666519 iter num 120\n",
            "loss 0.7916594743728638 average time 0.005355206664281857 iter num 140\n",
            "loss 0.3367869257926941 average time 0.005195107068749394 iter num 160\n",
            "loss 0.32375916838645935 average time 0.005070378355551636 iter num 180\n",
            "loss 1.3353815078735352 average time 0.004967361259998597 iter num 200\n",
            "loss 0.2710444927215576 average time 0.004886984936363413 iter num 220\n",
            "loss 0.6383057832717896 average time 0.004819015766670039 iter num 240\n",
            "loss 0.21161288022994995 average time 0.004768857723080636 iter num 260\n",
            "loss 0.20736104249954224 average time 0.004725295385717995 iter num 280\n",
            "loss 0.5351988077163696 average time 0.004678738626671475 iter num 300\n",
            "loss 0.8869820833206177 average time 0.004646132081253996 iter num 320\n",
            "loss 0.34694838523864746 average time 0.004617149623530114 iter num 340\n",
            "loss 0.3282977342605591 average time 0.004593674030555424 iter num 360\n",
            "loss 0.3624413013458252 average time 0.004567440352627129 iter num 380\n",
            "loss 0.5481041073799133 average time 0.004544327027492728 iter num 400\n",
            "loss 0.2672625184059143 average time 0.00452431320237511 iter num 420\n",
            "loss 0.5383956432342529 average time 0.004517402015903826 iter num 440\n",
            "loss 0.14932800829410553 average time 0.004498672941303006 iter num 460\n",
            "loss 0.2154894918203354 average time 0.004485202802082237 iter num 480\n",
            "loss 0.08842049539089203 average time 0.00446914382599698 iter num 500\n",
            "loss 0.18661358952522278 average time 0.012709651399973154 iter num 20\n",
            "loss 0.3140319883823395 average time 0.008441816149991154 iter num 40\n",
            "loss 2.780080556869507 average time 0.006993652349994287 iter num 60\n",
            "loss 0.9628123641014099 average time 0.0063085283250131855 iter num 80\n",
            "loss 0.17212724685668945 average time 0.005882574280008157 iter num 100\n",
            "loss 1.329211950302124 average time 0.005579391899993879 iter num 120\n",
            "loss 1.8350183963775635 average time 0.005363994735713667 iter num 140\n",
            "loss 0.7282658815383911 average time 0.005197836231249653 iter num 160\n",
            "loss 0.06809544563293457 average time 0.00508358215000347 iter num 180\n",
            "loss 0.4899941682815552 average time 0.004993527955004993 iter num 200\n",
            "loss 0.7459791302680969 average time 0.0049118898863732535 iter num 220\n",
            "loss 0.5315127968788147 average time 0.004840461887505398 iter num 240\n",
            "loss 0.2358773797750473 average time 0.004784890788468706 iter num 260\n",
            "loss 0.232185959815979 average time 0.004738033625007379 iter num 280\n",
            "loss 0.4397108554840088 average time 0.0046932852533351855 iter num 300\n",
            "loss 0.44330647587776184 average time 0.004660002331249302 iter num 320\n",
            "loss 0.07439568638801575 average time 0.004633818085297957 iter num 340\n",
            "loss 0.12129287421703339 average time 0.004602901225003582 iter num 360\n",
            "loss 0.1498832404613495 average time 0.004578395002637368 iter num 380\n",
            "loss 0.5167726874351501 average time 0.0045663913550026795 iter num 400\n",
            "loss 0.09078748524188995 average time 0.004541451011907936 iter num 420\n",
            "loss 0.2331935614347458 average time 0.004520905052277158 iter num 440\n",
            "loss 0.06257465481758118 average time 0.004501173213048273 iter num 460\n",
            "loss 0.1450360268354416 average time 0.004484018735423471 iter num 480\n",
            "loss 0.35754191875457764 average time 0.004469954592004797 iter num 500\n",
            "loss 0.13563373684883118 average time 0.013077742749987919 iter num 20\n",
            "loss 0.5006903409957886 average time 0.008561576749991672 iter num 40\n",
            "loss 3.282756805419922 average time 0.007062821466661262 iter num 60\n",
            "loss 1.5280122756958008 average time 0.006298288162514609 iter num 80\n",
            "loss 0.5854157209396362 average time 0.005866136660001757 iter num 100\n",
            "loss 1.036301612854004 average time 0.005595871866660218 iter num 120\n",
            "loss 0.5925618410110474 average time 0.005393738985708297 iter num 140\n",
            "loss 0.2241363823413849 average time 0.00522609111249892 iter num 160\n",
            "loss 0.4981629252433777 average time 0.005097291633332033 iter num 180\n",
            "loss 0.08684219419956207 average time 0.004999368075002622 iter num 200\n",
            "loss 0.20466618239879608 average time 0.0049217754318202755 iter num 220\n",
            "loss 0.2503211200237274 average time 0.004852662233340273 iter num 240\n",
            "loss 0.6378870606422424 average time 0.004796672300013737 iter num 260\n",
            "loss 0.18916982412338257 average time 0.004744615621442401 iter num 280\n",
            "loss 0.05864185094833374 average time 0.004701804376675985 iter num 300\n",
            "loss 0.6296731233596802 average time 0.004664032975010457 iter num 320\n",
            "loss 0.5331299901008606 average time 0.00463646265883493 iter num 340\n",
            "loss 0.2156914472579956 average time 0.004606898788896766 iter num 360\n",
            "loss 0.22499412298202515 average time 0.004579891405270294 iter num 380\n",
            "loss 0.2828245759010315 average time 0.004555940577504316 iter num 400\n",
            "loss 0.22578179836273193 average time 0.004534295392860648 iter num 420\n",
            "loss 0.17512467503547668 average time 0.004512812856825638 iter num 440\n",
            "loss 0.1753711998462677 average time 0.0044939094760949325 iter num 460\n",
            "loss 0.2581075429916382 average time 0.004479458168755931 iter num 480\n",
            "loss 0.11465346813201904 average time 0.004463770946006662 iter num 500\n",
            "loss 0.4162404239177704 average time 0.013407401500012383 iter num 20\n",
            "loss 0.9959621429443359 average time 0.008735251299992797 iter num 40\n",
            "loss 0.8518539667129517 average time 0.007239461433308255 iter num 60\n",
            "loss 1.210893154144287 average time 0.006516941087460282 iter num 80\n",
            "loss 0.9111148118972778 average time 0.0060288164699795746 iter num 100\n",
            "loss 0.1435239613056183 average time 0.005701873124993048 iter num 120\n",
            "loss 0.2767358422279358 average time 0.005470130278575068 iter num 140\n",
            "loss 0.13259878754615784 average time 0.005294660218748959 iter num 160\n",
            "loss 0.8709834814071655 average time 0.005158689644450634 iter num 180\n",
            "loss 0.21418851613998413 average time 0.00506482998501724 iter num 200\n",
            "loss 0.8924506306648254 average time 0.004972467413658292 iter num 220\n",
            "loss 0.2019042819738388 average time 0.004893151950022911 iter num 240\n",
            "loss 0.3303642272949219 average time 0.004827546450024573 iter num 260\n",
            "loss 0.31764230132102966 average time 0.00477273841072799 iter num 280\n",
            "loss 0.5733291506767273 average time 0.00472480963333813 iter num 300\n",
            "loss 0.4596232771873474 average time 0.0046816469562656945 iter num 320\n",
            "loss 0.26675090193748474 average time 0.004654832147073595 iter num 340\n",
            "loss 0.0745297446846962 average time 0.004621320800012856 iter num 360\n",
            "loss 0.3980475962162018 average time 0.004591346144743032 iter num 380\n",
            "loss 0.2227029651403427 average time 0.004565043800002968 iter num 400\n",
            "loss 0.35644280910491943 average time 0.004543028371437599 iter num 420\n",
            "loss 0.08483576774597168 average time 0.004522767786372903 iter num 440\n",
            "loss 0.0769926905632019 average time 0.0045088990630495615 iter num 460\n",
            "loss 0.13953566551208496 average time 0.0044899555916780775 iter num 480\n",
            "loss 0.08924128115177155 average time 0.0044737415680083355 iter num 500\n",
            "loss 0.17400632798671722 average time 0.012787196550107183 iter num 20\n",
            "loss 0.6571136116981506 average time 0.008405251275075899 iter num 40\n",
            "loss 0.6950134038925171 average time 0.0069682497167074565 iter num 60\n",
            "loss 1.338577151298523 average time 0.0062383919625403905 iter num 80\n",
            "loss 0.641938328742981 average time 0.005797226410013536 iter num 100\n",
            "loss 0.40155255794525146 average time 0.005516886291676807 iter num 120\n",
            "loss 1.0855711698532104 average time 0.00531689977143677 iter num 140\n",
            "loss 2.9264979362487793 average time 0.005158405593761017 iter num 160\n",
            "loss 0.6995154619216919 average time 0.0050528469500224875 iter num 180\n",
            "loss 0.2011280357837677 average time 0.00497123993002333 iter num 200\n",
            "loss 0.3170052766799927 average time 0.004904633795471951 iter num 220\n",
            "loss 0.2515106797218323 average time 0.004838206208349524 iter num 240\n",
            "loss 0.32491716742515564 average time 0.00480290601539519 iter num 260\n",
            "loss 0.1826941967010498 average time 0.004753169460708965 iter num 280\n",
            "loss 0.3917781114578247 average time 0.004709377023330793 iter num 300\n",
            "loss 0.2584075927734375 average time 0.00467021261875118 iter num 320\n",
            "loss 0.09737714380025864 average time 0.004636882132356678 iter num 340\n",
            "loss 0.5755350589752197 average time 0.00460881541944218 iter num 360\n",
            "loss 0.10408947616815567 average time 0.0045800726947355114 iter num 380\n",
            "loss 0.19034534692764282 average time 0.004558230682505382 iter num 400\n",
            "loss 0.2652704119682312 average time 0.00453704756190789 iter num 420\n",
            "loss 0.20555853843688965 average time 0.0045277078454587765 iter num 440\n",
            "loss 0.22273565828800201 average time 0.004507835699996576 iter num 460\n",
            "loss 0.2263675332069397 average time 0.0044913966041633556 iter num 480\n",
            "loss 0.052067048847675323 average time 0.004478351862002455 iter num 500\n",
            "loss 0.46762651205062866 average time 0.012844508450052671 iter num 20\n",
            "loss 0.43128126859664917 average time 0.008499997674948644 iter num 40\n",
            "loss 19.958892822265625 average time 0.007017787266598437 iter num 60\n",
            "loss 0.9603829383850098 average time 0.006273360074965239 iter num 80\n",
            "loss 0.8183924555778503 average time 0.005833789459975378 iter num 100\n",
            "loss 0.5966689586639404 average time 0.005537134566664766 iter num 120\n",
            "loss 0.9526494145393372 average time 0.005366252285713407 iter num 140\n",
            "loss 0.3716049790382385 average time 0.00521167856250031 iter num 160\n",
            "loss 0.7159844636917114 average time 0.005082886572219851 iter num 180\n",
            "loss 0.3743499517440796 average time 0.004978422860003775 iter num 200\n",
            "loss 0.6888649463653564 average time 0.004898406095464287 iter num 220\n",
            "loss 0.17263638973236084 average time 0.004832707316662284 iter num 240\n",
            "loss 0.3747231960296631 average time 0.0047711371884606 iter num 260\n",
            "loss 0.1627238392829895 average time 0.004727366471417684 iter num 280\n",
            "loss 0.30918383598327637 average time 0.004681151526662385 iter num 300\n",
            "loss 0.5046930909156799 average time 0.00464676855937114 iter num 320\n",
            "loss 0.22484014928340912 average time 0.004621030526467461 iter num 340\n",
            "loss 0.21892455220222473 average time 0.004589178949989521 iter num 360\n",
            "loss 0.21158084273338318 average time 0.0045607167763017445 iter num 380\n",
            "loss 0.2970723807811737 average time 0.004535291204983877 iter num 400\n",
            "loss 0.16481183469295502 average time 0.004511211969035382 iter num 420\n",
            "loss 0.1940043866634369 average time 0.004488626943175818 iter num 440\n",
            "loss 0.22884777188301086 average time 0.004468868865205877 iter num 460\n",
            "loss 0.25080859661102295 average time 0.00445543220415819 iter num 480\n",
            "loss 0.3284313678741455 average time 0.004448350647990083 iter num 500\n",
            "loss 0.5489267110824585 average time 0.012614764049885707 iter num 20\n",
            "loss 0.5003153085708618 average time 0.0083188088749921 iter num 40\n",
            "loss 1.8522601127624512 average time 0.006893066583370455 iter num 60\n",
            "loss 1.0143638849258423 average time 0.00621708210004499 iter num 80\n",
            "loss 6.113116264343262 average time 0.005777985440026896 iter num 100\n",
            "loss 0.6845206022262573 average time 0.005483653033335637 iter num 120\n",
            "loss 0.32406026124954224 average time 0.005283485814275731 iter num 140\n",
            "loss 0.3435637950897217 average time 0.00512513494373934 iter num 160\n",
            "loss 0.1998666524887085 average time 0.005003631827781242 iter num 180\n",
            "loss 0.2153865396976471 average time 0.004913669420006954 iter num 200\n",
            "loss 0.5066472887992859 average time 0.004833200150005723 iter num 220\n",
            "loss 0.27956801652908325 average time 0.004769965287501539 iter num 240\n",
            "loss 0.19859452545642853 average time 0.004715656734609953 iter num 260\n",
            "loss 0.24779275059700012 average time 0.004666812210725116 iter num 280\n",
            "loss 0.3145553469657898 average time 0.004628855256681466 iter num 300\n",
            "loss 0.13909628987312317 average time 0.004590542909394912 iter num 320\n",
            "loss 0.299106240272522 average time 0.004561208202951949 iter num 340\n",
            "loss 0.17935895919799805 average time 0.004534968008344246 iter num 360\n",
            "loss 0.21194404363632202 average time 0.004523180202644844 iter num 380\n",
            "loss 0.12151488661766052 average time 0.0045027763250095635 iter num 400\n",
            "loss 0.2063889354467392 average time 0.00448608470239075 iter num 420\n",
            "loss 0.7430462837219238 average time 0.0044671792909163986 iter num 440\n",
            "loss 0.20482999086380005 average time 0.004455280732617726 iter num 460\n",
            "loss 0.1824904978275299 average time 0.004442403052089124 iter num 480\n",
            "loss 0.1659889668226242 average time 0.004426491154006726 iter num 500\n",
            "loss 0.3341885507106781 average time 0.012855756149974695 iter num 20\n",
            "loss 0.8133807182312012 average time 0.008448680574974787 iter num 40\n",
            "loss 0.33717405796051025 average time 0.006987746399939473 iter num 60\n",
            "loss 0.3235974907875061 average time 0.006311615574941243 iter num 80\n",
            "loss 0.8177978992462158 average time 0.0059032524299527725 iter num 100\n",
            "loss 0.2779337167739868 average time 0.005595687858294696 iter num 120\n",
            "loss 0.5002099275588989 average time 0.005385428528526453 iter num 140\n",
            "loss 1.1554361581802368 average time 0.005230395199953363 iter num 160\n",
            "loss 0.10021547973155975 average time 0.00509922038886038 iter num 180\n",
            "loss 0.414096474647522 average time 0.004992291664966615 iter num 200\n",
            "loss 0.2918599247932434 average time 0.0049172191636113315 iter num 220\n",
            "loss 0.232270285487175 average time 0.004844904116650165 iter num 240\n",
            "loss 0.4748014509677887 average time 0.004783155949983736 iter num 260\n",
            "loss 0.34002426266670227 average time 0.0047300923785672105 iter num 280\n",
            "loss 0.4876568913459778 average time 0.004683588096668245 iter num 300\n",
            "loss 0.13468149304389954 average time 0.004644193096882532 iter num 320\n",
            "loss 0.1749161183834076 average time 0.004622405561769269 iter num 340\n",
            "loss 0.581288754940033 average time 0.004591855316678246 iter num 360\n",
            "loss 0.17844538390636444 average time 0.004562202915803937 iter num 380\n",
            "loss 0.21257615089416504 average time 0.004546511927510437 iter num 400\n",
            "loss 0.3063070774078369 average time 0.0045252586214419785 iter num 420\n",
            "loss 0.09802953898906708 average time 0.00450553459092217 iter num 440\n",
            "loss 0.21240635216236115 average time 0.004487115454359177 iter num 460\n",
            "loss 0.08009664714336395 average time 0.004469812045842522 iter num 480\n",
            "loss 0.17279605567455292 average time 0.004466814872008399 iter num 500\n",
            "loss 0.6751859784126282 average time 0.01286864994995085 iter num 20\n",
            "loss 0.31505391001701355 average time 0.00846571239997047 iter num 40\n",
            "loss 0.17673470079898834 average time 0.007132920333303142 iter num 60\n",
            "loss 0.21526500582695007 average time 0.006432585149968873 iter num 80\n",
            "loss 0.36811351776123047 average time 0.005948146329983501 iter num 100\n",
            "loss 0.29099345207214355 average time 0.0056374276499961224 iter num 120\n",
            "loss 0.31060388684272766 average time 0.005442454521426043 iter num 140\n",
            "loss 1.8523058891296387 average time 0.005268411325022271 iter num 160\n",
            "loss 0.300296425819397 average time 0.005135226311136244 iter num 180\n",
            "loss 0.2646426856517792 average time 0.005034965795025528 iter num 200\n",
            "loss 0.1826120913028717 average time 0.004948692804575992 iter num 220\n",
            "loss 0.08598430454730988 average time 0.004873224470857925 iter num 240\n",
            "loss 0.43354853987693787 average time 0.004811879842334468 iter num 260\n",
            "loss 0.2933822274208069 average time 0.004767319053592343 iter num 280\n",
            "loss 0.13060857355594635 average time 0.004731873953345105 iter num 300\n",
            "loss 0.09254428744316101 average time 0.00468846061251611 iter num 320\n",
            "loss 0.2945859432220459 average time 0.00465663282648433 iter num 340\n",
            "loss 0.19840332865715027 average time 0.004623159238899967 iter num 360\n",
            "loss 0.556148886680603 average time 0.0045923505526412845 iter num 380\n",
            "loss 0.6762049794197083 average time 0.004564050680012315 iter num 400\n",
            "loss 0.2612001895904541 average time 0.004543914957152343 iter num 420\n",
            "loss 0.6006835699081421 average time 0.004522312052286411 iter num 440\n",
            "loss 0.08760930597782135 average time 0.004507766365227523 iter num 460\n",
            "loss 0.30054956674575806 average time 0.004497464054171966 iter num 480\n",
            "loss 0.20160827040672302 average time 0.004479695378009637 iter num 500\n",
            "loss 0.4053754210472107 average time 0.01286799464996875 iter num 20\n",
            "loss 0.0871315598487854 average time 0.008473324374995173 iter num 40\n",
            "loss 0.42553627490997314 average time 0.0070004914000340555 iter num 60\n",
            "loss 3.172652006149292 average time 0.0062563985750102805 iter num 80\n",
            "loss 0.45362526178359985 average time 0.005834178019995306 iter num 100\n",
            "loss 0.4922991394996643 average time 0.005541401291672325 iter num 120\n",
            "loss 0.23671311140060425 average time 0.0053289743500045 iter num 140\n",
            "loss 1.572262167930603 average time 0.005172685112489717 iter num 160\n",
            "loss 0.2329528033733368 average time 0.005058467888870331 iter num 180\n",
            "loss 0.6096104383468628 average time 0.004976016249988788 iter num 200\n",
            "loss 0.1461939662694931 average time 0.004897870268169672 iter num 220\n",
            "loss 0.44163569808006287 average time 0.004825941204156455 iter num 240\n",
            "loss 0.4594818949699402 average time 0.004766462126907264 iter num 260\n",
            "loss 0.17583006620407104 average time 0.0047157515356957445 iter num 280\n",
            "loss 0.07549821585416794 average time 0.004689044176642104 iter num 300\n",
            "loss 0.3873891532421112 average time 0.0046502057124740755 iter num 320\n",
            "loss 0.21844366192817688 average time 0.004614567017624187 iter num 340\n",
            "loss 0.46434566378593445 average time 0.004582093769421489 iter num 360\n",
            "loss 0.6075335741043091 average time 0.0045573670052386946 iter num 380\n",
            "loss 0.27374938130378723 average time 0.004548203509971245 iter num 400\n",
            "loss 0.12187087535858154 average time 0.004533372371400089 iter num 420\n",
            "loss 0.11591484397649765 average time 0.004523746036335813 iter num 440\n",
            "loss 0.15236234664916992 average time 0.004510827393454272 iter num 460\n",
            "loss 0.17841093242168427 average time 0.004491572743726617 iter num 480\n",
            "loss 0.15902814269065857 average time 0.004472983683981511 iter num 500\n",
            "loss 2.396146774291992 average time 0.013126356950078844 iter num 20\n",
            "loss 0.43887072801589966 average time 0.008597534850014198 iter num 40\n",
            "loss 1.9695045948028564 average time 0.007112040666667477 iter num 60\n",
            "loss 0.4736717939376831 average time 0.006369183112497012 iter num 80\n",
            "loss 0.3509266674518585 average time 0.005908068460012145 iter num 100\n",
            "loss 0.5900778770446777 average time 0.005602274308360696 iter num 120\n",
            "loss 0.7987769842147827 average time 0.005389586499995857 iter num 140\n",
            "loss 0.5638531446456909 average time 0.0052227023999932955 iter num 160\n",
            "loss 0.22367367148399353 average time 0.005092534499999602 iter num 180\n",
            "loss 0.36483651399612427 average time 0.005003687030007313 iter num 200\n",
            "loss 0.298686146736145 average time 0.004920522700012952 iter num 220\n",
            "loss 0.22734177112579346 average time 0.004847721233337173 iter num 240\n",
            "loss 0.24156665802001953 average time 0.004791199761547642 iter num 260\n",
            "loss 0.18017563223838806 average time 0.004739784639299874 iter num 280\n",
            "loss 0.12790057063102722 average time 0.004703916836682159 iter num 300\n",
            "loss 0.15516223013401031 average time 0.004666625512518863 iter num 320\n",
            "loss 0.4572768211364746 average time 0.004630765132367956 iter num 340\n",
            "loss 0.5035697221755981 average time 0.004606388194451938 iter num 360\n",
            "loss 0.3807547092437744 average time 0.004587276968430543 iter num 380\n",
            "loss 0.1564963161945343 average time 0.004564977825011738 iter num 400\n",
            "loss 0.2278471291065216 average time 0.004542107883344216 iter num 420\n",
            "loss 0.15897652506828308 average time 0.004520402911372333 iter num 440\n",
            "loss 0.2249651998281479 average time 0.0045015803869674804 iter num 460\n",
            "loss 0.230444073677063 average time 0.004499411360429425 iter num 480\n",
            "loss 0.33486685156822205 average time 0.004486758736013144 iter num 500\n",
            "loss 0.728119969367981 average time 0.012909779849951519 iter num 20\n",
            "loss 1.378815770149231 average time 0.008517563224995684 iter num 40\n",
            "loss 13.197453498840332 average time 0.007021469816648581 iter num 60\n",
            "loss 1.4704397916793823 average time 0.006274089450005249 iter num 80\n",
            "loss 0.6734488010406494 average time 0.005824758290045793 iter num 100\n",
            "loss 0.4136276841163635 average time 0.005531772416694973 iter num 120\n",
            "loss 0.0853617787361145 average time 0.005321483807191336 iter num 140\n",
            "loss 0.30591535568237305 average time 0.005163415731283294 iter num 160\n",
            "loss 0.31035614013671875 average time 0.005036804166694411 iter num 180\n",
            "loss 0.3952406048774719 average time 0.004940296095032864 iter num 200\n",
            "loss 0.47019779682159424 average time 0.004859859195481807 iter num 220\n",
            "loss 0.15311257541179657 average time 0.0047938006041893765 iter num 240\n",
            "loss 0.12604324519634247 average time 0.00474130004617319 iter num 260\n",
            "loss 0.5051425099372864 average time 0.004690648442864845 iter num 280\n",
            "loss 0.5432806015014648 average time 0.00465915062000325 iter num 300\n",
            "loss 0.29144155979156494 average time 0.004619591884386409 iter num 320\n",
            "loss 0.16190257668495178 average time 0.004585567900018277 iter num 340\n",
            "loss 0.22126305103302002 average time 0.004557272291685876 iter num 360\n",
            "loss 0.17670586705207825 average time 0.004535362750019837 iter num 380\n",
            "loss 0.17659598588943481 average time 0.004510222677520232 iter num 400\n",
            "loss 0.20472180843353271 average time 0.0044954817643017685 iter num 420\n",
            "loss 0.6532678604125977 average time 0.004474416872744769 iter num 440\n",
            "loss 0.27087053656578064 average time 0.004457988232622049 iter num 460\n",
            "loss 0.11652109026908875 average time 0.0044411941375111985 iter num 480\n",
            "loss 0.18742719292640686 average time 0.004428065650015924 iter num 500\n",
            "loss 0.9730748534202576 average time 0.012857242399923053 iter num 20\n",
            "loss 0.4325307309627533 average time 0.00845793944995421 iter num 40\n",
            "loss 1.3606096506118774 average time 0.006989073166702535 iter num 60\n",
            "loss 0.2343486249446869 average time 0.00625268840001354 iter num 80\n",
            "loss 0.9984114766120911 average time 0.005820745419987361 iter num 100\n",
            "loss 0.5450731515884399 average time 0.005526430108329805 iter num 120\n",
            "loss 0.6748066544532776 average time 0.005337561600000689 iter num 140\n",
            "loss 0.2734889090061188 average time 0.00517294450000918 iter num 160\n",
            "loss 0.33661049604415894 average time 0.0050439585277874555 iter num 180\n",
            "loss 0.24561037123203278 average time 0.004942870930021854 iter num 200\n",
            "loss 0.6073988676071167 average time 0.004861663036374673 iter num 220\n",
            "loss 0.440371572971344 average time 0.004793789520851988 iter num 240\n",
            "loss 0.3860856890678406 average time 0.004736485223090243 iter num 260\n",
            "loss 0.2222607135772705 average time 0.004687916521437988 iter num 280\n",
            "loss 0.0848301574587822 average time 0.0046476724800110485 iter num 300\n",
            "loss 0.10601520538330078 average time 0.004609097215634961 iter num 320\n",
            "loss 0.29758256673812866 average time 0.004576753714715832 iter num 340\n",
            "loss 0.08176565170288086 average time 0.00454745408057483 iter num 360\n",
            "loss 0.26916074752807617 average time 0.004523560002651625 iter num 380\n",
            "loss 0.42243003845214844 average time 0.004500858582518958 iter num 400\n",
            "loss 0.20176178216934204 average time 0.0044821577047795946 iter num 420\n",
            "loss 0.24603278934955597 average time 0.004462249959105561 iter num 440\n",
            "loss 0.24438852071762085 average time 0.00444552088914782 iter num 460\n",
            "loss 0.15585580468177795 average time 0.004428316843768698 iter num 480\n",
            "loss 0.2945903539657593 average time 0.0044147962520146395 iter num 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "9vkPlpcxeIKF",
        "outputId": "b21cb1d8-7d35-408d-d525-f8da45bfa89d"
      },
      "source": [
        "# Train 1 stock\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import NumbaOptionDataSet\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "# dataset = NumbaOptionDataSet(max_len=10000, number_path = 1024, batch=4800)\n",
        "dataset = NumbaOptionDataSet(max_len=500, number_path = 1024, batch=32, stocks=1)\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred[:,0], y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs=20)\n",
        "\n",
        "model_save_name = 'checkpoint16.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/Lilian/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-72a7d7ee923d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train 1 stock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mignite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTimer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMSELoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ignite'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehmhDw8BUtLi"
      },
      "source": [
        "### Inference and Greeks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uiro43mOU0Ro"
      },
      "source": [
        "We can load the model parameters and use it to do inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svlu6tGTRx1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b1e5265-48c0-4d41-a3f3-4a4ca40d5ece"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([110.0, 100.0, 120.0, 0.35, 0.1, 0.05]).cuda()\n",
        "model(inputs.float())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([18.4788], device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1Iy-9pWVRDO"
      },
      "source": [
        "One of the benefits of building a deep learning model is that the [Greeks](<https://en.wikipedia.org/wiki/Greeks_(finance)#First-order_Greeks>) can be easily computed. \n",
        "We just need to take advantage of the auto-grad feature in Pytorch. We can use `grad` function to compute the first order differentiation for parameters 'K, B, S0, sigma, mu, r'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-yQhRfYTFgc"
      },
      "source": [
        "#Gradient Function 1(Lilian)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytBZaYHKSnDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce40560a-c2b8-4fe1-add2-9d27288206da"
      },
      "source": [
        "#All\n",
        "inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs)\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-7.0839e-01,  1.8378e-02,  7.8065e-01,  1.6033e+01,  4.7398e+01,\n",
              "         -1.6739e+01]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NXZmffAQ0Nn",
        "outputId": "358029a5-5b87-4b32-cb11-154d55aabcf2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Delta\n",
        "inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs)\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient[0][2]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.7807, device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53NahQIETODX"
      },
      "source": [
        "#Gradient Function 2(Lilian)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8khjk06P8jR",
        "outputId": "47219131-a752-4746-a48e-7c559af0647e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from torch import Tensor\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import grad\n",
        "from torch import nn\n",
        " \n",
        "inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs)\n",
        " \n",
        "# instead of using loss.backward(), use torch.autograd.grad() to compute gradients\n",
        "# https://pytorch.org/docs/stable/autograd.html#torch.autograd.grad\n",
        "loss_grads = grad(x, inputs, create_graph=True)\n",
        "drv = grad(loss_grads[0][0][1], inputs)\n",
        "drv"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-0.0035,  0.0006,  0.0029,  0.0160, -0.1639,  0.0216]],\n",
              "        device='cuda:0'),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3qIq63kKWa5"
      },
      "source": [
        "#from dask.distributed import Client\n",
        "\n",
        "#client = Client()  # start local workers as processes\n",
        "# or\n",
        "#client = Client(processes=False)  # start local workers as threads"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKr91Ou3KMxt",
        "outputId": "a4b7dcbb-dda6-4999-93dc-c6fd44a3040f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#futures = []\n",
        "#for i in range(0, 100):\n",
        "#    future = client.submit(gen_data, 5, 16, i)\n",
        "#    futures.append(future)\n",
        "#results = client.gather(futures) "
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "distributed.nanny - WARNING - Restarting worker\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KeijaDDVZGd"
      },
      "source": [
        "Here we are going to plot the Delta graph:-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skwgeVDsA_Mr"
      },
      "source": [
        "# Delta (Original One)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USh3qaADSYQp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "b02bae5f-2aac-45c6-aa2e-5c993a8a2c72"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0]\n",
        "\n",
        "print(compute_delta(110))\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-7.0839e-01,  1.8378e-02,  7.8065e-01,  1.6033e+01,  4.7398e+01,\n",
            "        -1.6739e+01], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-da6842f5986f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mdeltas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompute_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpylab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeltas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mpylab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'prices'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "VGk5Hw64fMdh",
        "outputId": "b7af026c-592b-4985-9308-059f41a5669d"
      },
      "source": [
        "## Using Finite Difference, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    epsilon = 0.01\n",
        "    inputs1 = torch.tensor([110.0, 0.0, S, 0.35, 0.1, 0.05]).cuda()\n",
        "    inputs2 = torch.tensor([110.0, 0.0, S + epsilon, 0.35, 0.1, 0.05]).cuda()\n",
        "    delta = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return delta\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fc736542550>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLStvS2qCSjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "978b240e-2546-4993-f6a4-811fc60e3823"
      },
      "source": [
        "compute_delta(110)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.6234], device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "4O1I8COnUxnz",
        "outputId": "a45c9555-96c6-4f70-c44d-11d3e4e3b78e"
      },
      "source": [
        "##Using Finite Difference, Change 3 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    #epsilon = 0.01\n",
        "    epsilon = 1\n",
        "    inputs1 = torch.tensor([[110.0, 0.0, S, 0.35, 0.1, 0.05]*3]).cuda()\n",
        "    inputs2 = torch.tensor([[110.0, 0.0, S + epsilon, 0.35, 0.1, 0.05]*3]).cuda()\n",
        "    delta = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return delta\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3be004e110>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd5xVhZ338c9v7jTK0EcYepEiigUGsUSDsWGJJKYIGxNTLIkaN8luds2TfVzXLYnJk+wmxtVo4to1xqhB4wY1osZYYKjSGZAyQ5mhSBum3Ht/zx/3QC44AwicObd836/XvO65554Zvpy5c773dHN3REQkfxVEHUBERKKlIhARyXMqAhGRPKciEBHJcyoCEZE8Vxh1gI+qV69ePnjw4KhjiIhkldmzZ2929/LWXsu6Ihg8eDBVVVVRxxARySpmtqat17RpSEQkz6kIRETynIpARCTPhVYEZvaAmdWZ2cI2Xjcz+7mZVZvZAjMbG1YWERFpW5hrBA8Ckw7y+iXA8ODreuCeELOIiEgbQisCd38D2HqQSSYDD3vKO0A3M6sIK4+IiLQuyn0E/YB1ac9rgnEfYmbXm1mVmVXV19e3SzgRkXyRFecRuPt9wH0AlZWVum62iBxSMuk0J5I0J5K0xJO0JJzmePA8+GqOJ2lsSdIUT9DYkqSxJUFTPPXYGE+QSDgFBUZhgRHb+xgr2Pe8tChGx6IYHYtjlBanHjsWFVJaXEBJYYziWAFFsdS0Zhb1LGlTlEVQCwxIe94/GCcieaAlkWRbQzMfNLSwszFOQ3Oc3U0Jdjamnu9sjLOrqYVdTQl2N/319X0L8YTTHE/QkvB945riexfyTiKZOZ8ZzaAoVrCvGIpiBRTFCigMhotjBRQXpr5KCvd/nj58+ckVjBvU45jni7IIpgE3m9mTwARgu7tviDCPiIQgkXQW1m5nyYYdLN24k2Ubd7J800627G4+5Pd2KIrRqaSQziUxOhYX0rE4RnFhAZ1LC/dbsBYXFuxbuO5deBbFCigqtH0L0r2vF8WMkrTnpUUxSgpTj6VFqU/ypUWp54UFRsJTpRJPOolE6jHpqfJpbEnQ0JxgT3OChpbgsTnBnuZ4UEqeVlxJWuJOPJlaE4knnXhQWk3BmkpTS4JdTfHUmkswbt9wPMmoPmXZVQRm9gQwEehlZjXAPwNFAO5+L/AicClQDTQAXwkri4i0rw8amvnTkjpeW17PG8vr2b6nBUgt2Ef0KeOCE3rTr3sHuncsomvHYrqUFtKppJAORTG6lBZRVlpIWWkhhbHoT3XKiu3nRym0/6O7Tz3E6w7cFNa/LyLtqymeYMbSOp6ZU8uMZXW0JJzyshIuHN2bc0eUc0r/rgzo3pGCgszdVp6v8qHsRCQk7s6ctdt4Zk4tLyzYwPY9LZSXlXDNmYOZfGo/TuzbRQv+LKAiEJGPbO2WBp6ZW8Ozc2tZs6WB0qICJp3Yh0+P7c/Zw3pmxCYdOXwqAhE5bI0tCf7l+cU8OWstAGcO7ck3PzGcSSf1oXOJFifZSr85ETksjS0Jrnu4ijerN/PVs4dw7TlDqOjaIepYcgyoCETkkBpbEtzwyGzerN7MnZ85mc9XDjj0N0nW0IY8ETmopniCbzw6m9eX1/PDK8eoBHKQikBE2uTu/P1vFzBjWT0/uHIMV40fGHUkCYGKQETadM/rK3l+/nq+e/FIpp6uEshVKgIRadWMpXX8ePoyLj+5ghsnDos6joRIRSAiH7Kyfhe3PDGX0RVd+PFnT8noK2fK0VMRiMh+tu9p4bqHqygqLOCXXxxHh+JY1JEkZCoCEdknnkhy8+NzWLe1gXu+MJb+3TtGHUnagc4jEJF9/vWFxfx5xWbu/MwYJgztGXUcaSdaIxARAB55ezUPvb2G684ZosNE84yKQER4c8Vmbn9+MeePOo5bLzkh6jjSzlQEInluZf0ubnxsNseXd+ZnU08jpstG5x0VgUge+6ChmWsfqqIoVsCvrqnUFUTzlH7rInmqJZHkxsfmULttD49fN4EBPXSEUL5SEYjkIXfntt8v4q2VW/jp50+hcvCxvyG6ZA9tGhLJQ3e9Ws0TM9dy48RhXDm2f9RxJGIqApE88+g7a/jpy8v57Lj+fPfikVHHkQygIhDJI8/OreH//n4h5486jh9eOUbXEBJARSCSNx5/dy3feWo+Zw7tyS/+ZqxuMC/7aGexSI5zd3795vv82x+WcN7Icu65ehylRbqQnPyVikAkhzW2JLjt9wt5qqqGS07qw8+mnEZxodYEZH8qApEctWH7Hr7+6Bzmr/uAWz5xPN+6YAQFOmtYWqEiEMlBM9/fyo2PzWZPc4J7rx7HpJP6RB1JMpiKQCSHJJLOPa9V85+vrGBQj448cd0ZDO9dFnUsyXAqApEcsXrzbr779Hxmrd7GJ0/py79/+iS6lBZFHUuygIpAJAe8u2oLX/6fWRTGjP+66lQ+dVq/qCNJFlERiGS5Reu3c+1DVfTtVspj155Bn66lUUeSLBPqcWRmNsnMlplZtZnd2srrA81shpnNNbMFZnZpmHlEcs3K+l1c88BMykoLeeRrE1QCckRCKwIziwF3A5cAo4GpZjb6gMn+CXjK3U8DpgD/HVYekVyzZstuvnD/uwA8cu0E+nbrEHEiyVZhrhGcDlS7+yp3bwaeBCYfMI0DXYLhrsD6EPOI5Iw5a7dx5X+/RWM8waPXTmBYeeeoI0kWC3MfQT9gXdrzGmDCAdPcDrxkZt8EOgEXtPaDzOx64HqAgQN1U23JX8mk8+Bbq/nhH5fSp0sp//OV8SoBOWpRn2s+FXjQ3fsDlwKPmNmHMrn7fe5e6e6V5eXl7R5SJBOsqt/FFx94lzteWMw5x/fi2RvPUgnIMRHmGkEtMCDtef9gXLqvAZMA3P1tMysFegF1IeYSySp7mhP85KVlPPjWakqLYvzgyjFMGT9Al5CWYybMIpgFDDezIaQKYArwNwdMsxY4H3jQzE4ASoH6EDOJZJVdTXGm3Pc2C2t3cFXlAP7+4pGUl5VEHUtyTGhF4O5xM7sZmA7EgAfcfZGZ3QFUufs04O+A+83s26R2HH/Z3T2sTCLZxN35u6fmsWTDTu7/UiUXju4ddSTJUaGeUObuLwIvHjDutrThxcDZYWYQyVYvLNjA9EWb+N4lo1QCEqqodxaLSCvcnZ//aQUnVHTh2nOGRh1HcpyKQCQDzVm7jRV1u/jyWYOI6R4CEjIVgUgGenLmOjoVx7j85L5RR5E8oCIQyTA7G1t4YcEGPnlKXzqV6LqQEj4VgUiGmTZ/PXtaElw1fsChJxY5BlQEIhnE3Xn0nbWM6lPGqQO6RR1H8oSKQCSDzF33AUs27ODqMwbpzGFpNyoCkQzy2Dtr6VQc0x3GpF2pCEQyxMbtjTw/fz2fHtuPztpJLO1IRSCSIe59fSUJd244d1jUUSTPqAhEMkD9ziaemLmWK0/rx4AeHaOOI3lGRSCSAX795vu0JJLceN7xUUeRPKQiEInY9oYWHn1nDZeOqWBIr05Rx5E8pCIQidjDb69mV1OcGydqbUCioSIQiVBDc5wH/vI+nxh1HKP7dok6juQpFYFIhJ6YuY5tDS3cdJ6OFJLoqAhEItIUT3D/G6uYMKQH4wb1iDqO5DEVgUhEnp1Ty8YdjdykI4UkYioCkQgkks69r69kTL+unDO8V9RxJM+pCEQi8OJ7G1i9pYGbzhumi8tJ5FQEIu3M3bl7RjXDyjtx0eg+UccRURGItLcZy+pYunEnN048ngLdj1gygIpApB2l1gZW0q9bB644VfcjlsygIhBpRzPf38rsNdu4/tyhFMX05yeZQe9EkXb036+tpGenYj5fqfsRS+ZQEYi0k4W123l9eT1f/dgQOhTHoo4jso+KQKSd/OxPKygrKeTqMwZFHUVkPyoCkXZQtXorLy/exA0fH0rXDkVRxxHZj4pAJGTuzp1/XMpxZSV89WNDoo4j8iEqApGQTZu/nlmrt/GtC0bQsVg3pZfMoyIQCdG23c3c8fxiThnQjavG60ghyUyhFoGZTTKzZWZWbWa3tjHN581ssZktMrPHw8wj0t7+/cUlbN/Twg+vHENMZxFLhgptPdXMYsDdwIVADTDLzKa5++K0aYYD3wPOdvdtZnZcWHlE2tufV9Tz9Owabpw4jBMqdPcxyVxhrhGcDlS7+yp3bwaeBCYfMM11wN3uvg3A3etCzCPSbnY2tvCPTy9gaHknbjl/eNRxRA4qzCLoB6xLe14TjEs3AhhhZn8xs3fMbFJrP8jMrjezKjOrqq+vDymuyLHzHy8uYeOORv7f506htEgnj0lmi3pncSEwHJgITAXuN7NuB07k7ve5e6W7V5aXl7dzRJGP5o3l9Twxcx3XnTOUsQO7Rx1H5JDCLIJaIP0wif7BuHQ1wDR3b3H394HlpIpBJCvtaGzh1t8tYFh5J7594Yio44gcljCLYBYw3MyGmFkxMAWYdsA0z5FaG8DMepHaVLQqxEwiofqPP6Q2Cf3k86dqk5BkjdCKwN3jwM3AdGAJ8JS7LzKzO8zsimCy6cAWM1sMzAC+6+5bwsokEqbXltXx5Kx13PDxYZw64ENbOEUylrl71Bk+ksrKSq+qqoo6hsh+djS2cPF/vkHnkkJeuOVjlBRqbUAyi5nNdvfK1l7T+e4ix8C/vbCYup1N3Hv1OJWAZJ2ojxoSyXozltbxVFUNX//4UE7RJiHJQioCkaOwvaGFW59ZwMjeZTpxTLKWNg2JHIV/eWERm3c186svjdcmIclaWiMQOUKz12zjmTm1fOPjwxjTv2vUcUSO2GGtEQQXh/sBMBoo3Tve3YeGlEsk4/3XK8vp2amYb0wcFnUUkaNyuGsE/wPcA8SB84CHgUfDCiWS6ZZv2smfV2zmunOH0qlEW1glux1uEXRw9z+ROu9gjbvfDlwWXiyRzPb07BoKC4zPjesfdRSRo3a4H2WazKwAWGFmN5O6ZlDn8GKJZK54Iskzc2r5xKjj6Nm5JOo4IkftcNcI/hboCNwCjAOuBr4UViiRTPb68no272ris1obkBxxuEUw2N13uXuNu3/F3T8DDAwzmEimenp2DT07FXPeKN1QT3LD4RbB9w5znEhO27a7mVeWbOKKU/tSFNPR15IbDrqPwMwuAS4F+pnZz9Ne6kLqCCKRvPL7ebW0JJzPjRtw6IlFssShdhavB2YDVwSPe+0Evh1WKJFM9fScGk7s24XRfXUzeskdBy0Cd58PzDezR4P7C4jkrSUbdrCwdgf//MnRUUcROaYOtWnoPcCD4Q+97u4nhxNLJPP8tqqGopgx+dR+UUcROaYOtWno8nZJIZLhmuNJnptXy/mjetOjU3HUcUSOqUNtGlqzd9jMBgHD3f0VM+twqO8VySWvLNnE1t3NfK5S5w5I7jms49/M7DrgaeCXwaj+pG48L5IXHnxrNf27d2DiSJ07ILnncA+Evgk4G9gB4O4rAP1FSF5YsmEHM9/fyhfPGESs4MP7ykSy3eEWQZO7N+99YmaFBDuRRXLdw2+vpqSwgKvG69wByU2HWwSvm9n/ATqY2YXAb4Hnw4slkhm2N7Tw7NxaPnVqP7p11E5iyU2HWwS3AvXAe8ANwIvAP4UVSiRTPFW1jsaWJF86a1DUUURCc1hH/rh70syeA55z9/qQM4lkhETSeeSdNYwf3J0T++pWlJK7DrpGYCm3m9lmYBmwzMzqzey29oknEp3XltWxdmsD15w1OOooIqE61Kahb5M6Wmi8u/dw9x7ABOBsM9O1hiSnPfT2Gnp3KeHiE/tEHUUkVIcqgi8CU939/b0j3H0VujGN5LiV9bt4Y3k9X5gwSJeblpx3qHd4kbtvPnBksJ+gKJxIItF75O01FMWMqafr/kuS+w5VBM1H+JpI1trVFOd3s2u4bEwF5WW6J7HkvkMdNXSKme1oZbwBpSHkEYncc3Nr2dkU105iyRuHuuhcrL2CiGSKF9/bwLDyTpw6oFvUUUTaRah7wcxskpktM7NqM7v1INN9xszczCrDzCNyKB80NPPu+1u5+MQ+rd6DQyQXhVYEZhYD7gYuAUYDU83sQ7d2MrMy4G+Bd8PKInK4Xl1aRyLpXKRDRiWPhLlGcDpQ7e6rggvWPQlMbmW6fwXuBBpDzCJyWF5atIneXUo4uZ/OJJb8EWYR9APWpT2vCcbtY2ZjgQHu/oeD/SAzu97Mqsysqr5eV7iQcDS2JHh9eT0Xju5NgS43LXkksjNlzKwA+Cnwd4ea1t3vc/dKd68sLy8PP5zkpTdXbGZPS4KLRmuzkOSXMIugFki/gHv/YNxeZcBJwGtmtho4A5imHcYSlZcWb6SspJAzhvaMOopIuwqzCGYBw81siJkVA1OAaXtfdPft7t7L3Qe7+2DgHeAKd68KMZNIqxJJ55UldZw36jiKC3VJCckvob3j3T0O3AxMB5YAT7n7IjO7w8yuCOvfFTkSs9dsY+vuZi46sXfUUUTa3WHdj+BIufuLpG5ikz6u1UtYu/vEMLOIHMxLizZSHCvg4yO0D0ryj9aBJe+5Oy8v2cRZx/ekrFTXUpT8oyKQvLd80y7WbGnQ0UKSt1QEkvemL9oIwAUnHBdxEpFoqAgk701ftJFxg7pzXBddUFfyk4pA8tq6rQ0sWr+Di3W0kOQxFYHktb2bhXRfYslnKgLJay8t2sSoPmUM6tkp6igikVERSN6q39nErDVbtTYgeU9FIHnrlSWbcIdJJ6kIJL+pCCRv/XHhRgb26MioPmVRRxGJlIpA8tKOxhbeWrmZSSfplpQiKgLJSzOW1tGScB02KoKKQPLU9EUbKS8r4bQB3aOOIhI5FYHknT3NCV5bVs9FuiWlCKAikDw0Y1kdDc0JLh1TEXUUkYygIpC888KC9fTqXMyEIT2ijiKSEVQEkld2N8V5dWkdl46poDCmt78IqAgkz/xuTg2NLUk+dVq/qKOIZAwVgeSNhuY49762klMHdGPsQB0tJLKXikDyxo/+uIz12xv5/mUnRB1FJKOoCCQvzFhWx4NvrebLZw1m/GDtJBZJpyKQnLd5VxPf/e18RvYu49ZLRkUdRyTjFEYdQCRM7s6tv1vAjsY4j117BqVFsagjiWQcrRFITps2fz2vLKnjHy4eyUhdZVSkVSoCyVnbdjfzL88v5tQB3fjK2UOijiOSsbRpSHLW/X9exbaGZh6/bgIxXVNIpE1aI5CctH1PC4+8vYZLT6pgVJ8uUccRyWgqAslJj76zhp1Ncb4xcVjUUUQynopAcs6e5gS/fvN9zhtZzkn9ukYdRyTjqQgk5zw/fz1bdzfz9Y9rbUDkcKgIJOc8PnMtw4/rzOm6zLTIYQm1CMxskpktM7NqM7u1lde/Y2aLzWyBmf3JzAaFmUdy3+L1O5i37gOmnj5QN6UXOUyhFYGZxYC7gUuA0cBUMxt9wGRzgUp3Pxl4GvhRWHkkPzw5ay3FhQVcOVaXmRY5XGGuEZwOVLv7KndvBp4EJqdP4O4z3L0hePoO0D/EPJLj9jQneHZOLZeNqaBbx+Ko44hkjTCLoB+wLu15TTCuLV8D/re1F8zsejOrMrOq+vr6YxhRcskLC9azsynO1NMHRh1FJKtkxM5iM7saqAR+3Nrr7n6fu1e6e2V5eXn7hpOs8cTMtQwr78T4wbrpjMhHEWYR1AID0p73D8btx8wuAL4PXOHuTSHmkRy2dOMO5qzVTmKRIxFmEcwChpvZEDMrBqYA09InMLPTgF+SKoG6ELNIjnv83dRO4s+M1W4mkY8qtCJw9zhwMzAdWAI85e6LzOwOM7simOzHQGfgt2Y2z8ymtfHjRNq0dyfxpSf1oXsn7SQW+ahCvfqou78IvHjAuNvShi8I89+X/DBtfi07m+JM0U5ikSOSETuLRY5UMunc/+f3GdWnjAk6k1jkiKgIJKu9vrye6rpdXH/uUO0kFjlCKgLJavf/eRW9u5Rw+cl9o44ikrVUBJK15q/7gLdWbuHLZw2huFBvZZEjpb8eyVo/fXk53ToWcfUZ2kkscjRUBJKVZq/ZyuvL67nh3GGUlRZFHUckq6kIJOu4Oz95aTm9OhdzzVm6crnI0VIRSNZ5efEm3lq5hZvPO56OxaGeCiOSF1QEklUaWxL86x8WM6J3Z75whtYGRI4FfZySrHL/G6tYt3UPj107gaKYPseIHAv6S5KssWzjTu56tZrLxlRw9vG9oo4jkjNUBJIVWhJJvvPUPMpKC7lj8olRxxHJKdo0JFnhrlerWbR+B7/84jh6di6JOo5ITtEagWS8N1ds5q5XV3Dl2H5cfGKfqOOI5BwVgWS0Ddv3cMuTcxl+XGf+7VMnRR1HJCepCCRj7WlO8PVH59DUkuCeq8fpnAGRkOgvSzJSPJHkm0/MZUHNB9x79TiGlXeOOpJIztIagWScZNL5p+cW8sqSTdz+yRO1X0AkZFojkIySSDrfe2YBT1XVcNN5w7jmrMFRRxLJeSoCyRhN8QT/+PQCnpu3nls+cTzfvnBE1JFE8oKKQDLCll1N3PDIbKrWbOO7F4/kpvOOjzqSSN5QEUjkZq/Zxi1PzGXzribumnoanzxFt50UaU8qAolMPJHkrler+cWMaiq6lvLUDWdyyoBuUccSyTsqAonEzPe3ctvvF7J0406uPK0ft08+kS6605hIJFQE0q7WbNnNf768nOfmradv11LuvXosk06qiDqWSF5TEUi7WLulgV/MWMHv5tRSWGDcdN4wbtIdxkQygv4KJTTJpPOXlZt56K01vLp0E4WxAr54xiBunDiM47qURh1PRAIqAjnmqut2MW3+eqbNq2X1lgZ6dirmGxOH8aUzB9NbBSCScVQEctTiiSTz1n3A68vreWVJHUs27MAMzhzak1vOH85lJ1dQUhiLOqaItEFFIB9ZUzzBovU7mLNmG7PXbOPN6s3sbIxTYDB2YHduu3w0l59coc0/IllCRSBtcnfqdzaxfNMuVtTtZPmmXSzduINFtTtoTiQB6NetA5eNqeDcEeWcPawXXTvqEFCRbBNqEZjZJOBnQAz4lbv/8IDXS4CHgXHAFuAqd18dZiZJcXd27ImzeXcTm3c2sXFHIzXb9rD+gz3UfhA8btvD7ubEvu/p1rGIEb3L+MrZgzltYHfGDuymT/0iOSC0IjCzGHA3cCFQA8wys2nuvjhtsq8B29z9eDObAtwJXBVWpmPB3XGHpDuJ9OGkk/TUkTJJD4bd9732oemC15LJtGEnmPav03nw7xz4s+OJJI3xBE0tSRpbEjTGk6nhveP2e0zQFE9Nt7spwdbdzWzZ3URLwj/0/+vesYi+3TowqGcnzhrWi8E9OzKidxnH9+5MeecSzCyCuS4iYQpzjeB0oNrdVwGY2ZPAZCC9CCYDtwfDTwO/MDNz9w8voY7Sb2at5b43VuFOsGDdfyGcSKYWuukL7kTaAjp9IZzJimJGaWGMkqICSoLH0rTHPl2LOLFvF3p2LqFX52J6dS6hZ+diKrqWUtG1A51KtLVQJN+E+VffD1iX9rwGmNDWNO4eN7PtQE9gc/pEZnY9cD3AwIEDjyhMj04ljKroQoEZBQYxM8yMWAEUHDD81y+IFbQyXfBaQUEr0+03fv/pDvUz9k0XPE/9u61MZ0Zh2gI/fcEfK9AndhH5aLLi45+73wfcB1BZWXlEn8kvHN2bC0f3Pqa5RERyQZi3qqwFBqQ97x+Ma3UaMysEupLaaSwiIu0kzCKYBQw3syFmVgxMAaYdMM004Jpg+LPAq2HsHxARkbaFtmko2OZ/MzCd1OGjD7j7IjO7A6hy92nAr4FHzKwa2EqqLEREpB2Fuo/A3V8EXjxg3G1pw43A58LMICIiBxfmpiEREckCKgIRkTynIhARyXMqAhGRPGfZdrSmmdUDa6LO0YZeHHBWdIZRvqOX6RmV7+jkcr5B7l7e2gtZVwSZzMyq3L0y6hxtUb6jl+kZle/o5Gs+bRoSEclzKgIRkTynIji27os6wCEo39HL9IzKd3TyMp/2EYiI5DmtEYiI5DkVgYhInlMRHCEzG2BmM8xssZktMrO/Dcbfbma1ZjYv+Lo0woyrzey9IEdVMK6Hmb1sZiuCx+4RZRuZNo/mmdkOM/tWlPPPzB4wszozW5g2rtX5ZSk/N7NqM1tgZmMjyvdjM1saZHjWzLoF4web2Z60+XhvRPna/H2a2feC+bfMzC6OKN9v0rKtNrN5wfgo5l9by5Tw34Opm7Hr66N+ARXA2GC4DFgOjCZ1D+a/jzpfkGs10OuAcT8Cbg2GbwXuzICcMWAjMCjK+QecC4wFFh5qfgGXAv8LGHAG8G5E+S4CCoPhO9PyDU6fLsL51+rvM/hbmQ+UAEOAlUCsvfMd8PpPgNsinH9tLVNCfw9qjeAIufsGd58TDO8ElpC6B3Ommww8FAw/BHwqwix7nQ+sdPdIzxh39zdI3RcjXVvzazLwsKe8A3Qzs4r2zufuL7l7PHj6Dqk7AUaijfnXlsnAk+7e5O7vA9XA6aGF4+D5zMyAzwNPhJnhYA6yTAn9PagiOAbMbDBwGvBuMOrmYFXtgag2vQQceMnMZpvZ9cG43u6+IRjeCGTCjZynsP8fYKbMP2h7fvUD1qVNV0P0HwS+SuoT4l5DzGyumb1uZudEFYrWf5+ZNv/OATa5+4q0cZHNvwOWKaG/B1UER8nMOgO/A77l7juAe4BhwKnABlKrm1H5mLuPBS4BbjKzc9Nf9NT6ZaTHD1vqNqZXAL8NRmXS/NtPJsyvtpjZ94E48FgwagMw0N1PA74DPG5mXSKIlrG/zwNMZf8PI5HNv1aWKfuE9R5UERwFMysi9Qt7zN2fAXD3Te6ecPckcD8hr+4ejLvXBo91wLNBlk17Vx+Dx7qo8gUuAea4+ybIrPkXaGt+1QID0qbrH4xrd2b2ZeBy4AvBgoJgk8uWYHg2qW3wI9o720F+n5k0/wqBK4Hf7B0X1fxrbZlCO7wHVQRHKNim+Gtgibv/NG18+ja6TwMLD/ze9mBmncysbO8wqZ2KC4FpwDXBZNcAv48iX5r9PollyvxL09b8mgZ8KThy4wxge9rqe7sxs0nAPwBXuHtD2vhyM4sFw0OB4cCqCPK19fucBkwxsxIzGxLkm/4DEhwAAAKHSURBVNne+QIXAEvdvWbviCjmX1vLFNrjPdiee8Vz6Qv4GKlVtAXAvODrUuAR4L1g/DSgIqJ8Q0kdlTEfWAR8PxjfE/gTsAJ4BegR4TzsBGwBuqaNi2z+kSqkDUALqe2tX2trfpE6UuNuUp8U3wMqI8pXTWo78d734L3BtJ8Jfu/zgDnAJyPK1+bvE/h+MP+WAZdEkS8Y/yDw9QOmjWL+tbVMCf09qEtMiIjkOW0aEhHJcyoCEZE8pyIQEclzKgIRkTynIhARyXMqApEjZGZ3mNkFUecQOVo6fFTkCJhZzN0TUecQORa0RiBygOBa9EvN7DEzW2JmT5tZx+B69Xea2Rzgc2b2oJl9Nvie8Wb2lpnNN7OZZlZmZjFL3S9gVnDRtRuCaSvM7I3gOvcLI74gnAiFUQcQyVAjSZ15+hczewC4MRi/xVMX8tt7eYe9F877DXCVu88KLk62h9SZtdvdfbyZlQB/MbOXSF3XZrq7/3twGYOO7ftfE9mfikCkdevc/S/B8KPALcHwb1qZdiSwwd1nAXhwxUgzuwg4ee9aA9CV1DVrZgEPBBcYe87d54X0fxA5LCoCkdYduPNs7/PdH+FnGPBNd5/+oRdSlwS/DHjQzH7q7g8fWUyRo6d9BCKtG2hmZwbDfwO8eZBplwEVZjYeINg/UAhMB74RfPLHzEYEV4UdROomKPcDvyJ1+0SRyKgIRFq3jNTNfJYA3UndYKVV7t4MXAXcZWbzgZeBUlIL+cXAHEvdMP2XpNbCJwLzzWxu8H0/C/H/IXJIOnxU5ADBbQJfcPeTIo4i0i60RiAikue0RiAikue0RiAikudUBCIieU5FICKS51QEIiJ5TkUgIpLn/j+urBORa+rtYgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rvU4uMtEc2g5"
      },
      "source": [
        "#Lilian_New"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "0g5yeyilcsbt",
        "outputId": "6ddcc5f5-b513-4d80-c7a7-5698e936a92f"
      },
      "source": [
        "##Using Finite Difference, Change 2 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    #epsilon = 0.01\n",
        "    epsilon = 0.01\n",
        "    inputs1 = torch.tensor([[110.0, 0.0, S, 0.35, 0.1, 0.05]*2 + ([110.0, 0.0, 110.0, 0.35, 0.1, 0.05])]).cuda()\n",
        "    inputs2 = torch.tensor([[110.0, 0.0, S + epsilon, 0.35, 0.1, 0.05]*2 + ([110.0, 0.0, 110.0, 0.35, 0.1, 0.05])]).cuda()\n",
        "    delta = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return delta\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3bd3fa8790>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySrey9KzB0AF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ed34012-ff7a-4cc6-deb3-a8dfbf533d2c"
      },
      "source": [
        "compute_delta(110).item()  # It's not 0.5!! SOS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4027366638183594"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMyME_1WCGZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "040d79b9-bc60-4d79-b120-910e8cd91bb0"
      },
      "source": [
        "compute_delta(102).item() # Close to 0.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.502777099609375"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNB8LPwfBMHQ"
      },
      "source": [
        "# Gamma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLO_5nEGVcEc"
      },
      "source": [
        "Calculating the second order derivative is easy in PyTorch too. We just need to apply the `grad` function twice. Use this mechanism, we can calculate the second order derivatives $\\frac{\\partial^2 P}{\\partial K \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial B \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial S_0^2}$, $\\frac{\\partial^2 P}{\\partial \\sigma \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial \\mu \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial r \\partial S_0}$ in the following example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGzj7A3sThZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f477244-2c9a-41e4-ab0e-a6b10a608b13"
      },
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import grad\n",
        "from torch import nn\n",
        "\n",
        "inputs = torch.tensor([[110.0, 0.0, 110.0, 0.35, 0.1, 0.05]*3]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs)\n",
        "\n",
        "# instead of using loss.backward(), use torch.autograd.grad() to compute gradients\n",
        "# https://pytorch.org/docs/stable/autograd.html#torch.autograd.grad\n",
        "loss_grads = grad(x, inputs, create_graph=True)\n",
        "drv = grad(loss_grads[0][0][2], inputs)\n",
        "drv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-1.6023e-03, -2.3967e-01,  4.9180e-03, -8.3777e-02,  4.3252e-01,\n",
              "          -3.4538e-01, -1.6144e-03, -3.7401e-01, -4.7186e-05,  1.0418e-02,\n",
              "           1.3443e-02,  9.7121e-02, -1.6194e-03,  5.3559e-01, -8.4335e-05,\n",
              "           1.6220e-02, -4.6263e-03,  2.4582e-02]], device='cuda:0'),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJbZYtvhVmSo"
      },
      "source": [
        "Gamma is the second order differenation of `S`. We can plot the the Gamma curve as a function of the stock price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JpQa3EJToA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "62b8c7a0-f5ae-4681-ba3b-b7c386f129aa"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "import pylab\n",
        "import numpy as np\n",
        "def compute_gamma(S):\n",
        "    inputs = torch.tensor([[110.0, 0.0, S, 0.35, 0.1, 0.05] + ([110.0, 0.0, 110.0, 0.35, 0.1, 0.05]*2)]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    loss_grads = grad(x, inputs, create_graph=True)\n",
        "    drv = grad(loss_grads[0][0][2], inputs)\n",
        "    return drv[0][0][2]\n",
        "\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "gammas = []\n",
        "for p in prices:\n",
        "    gammas.append(compute_gamma(p).item())\n",
        "fig2 = pylab.plot(prices, gammas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Gamma')\n",
        "fig2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe4801c6cd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsoaOyCDxQy0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "fa4f517b-b341-4643-cea4-0ee905784f40"
      },
      "source": [
        "##Using Finite Difference, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_gamma(S):\n",
        "    epsilon = 0.5\n",
        "    inputs1 = torch.tensor([[110.0, 0.0, S, 0.35, 0.1, 0.05]  + ([110.0, 0.0, 110.0, 0.35, 0.1, 0.05]*2)]).cuda()\n",
        "    inputs2 = torch.tensor([[110.0, 0.0, S + epsilon, 0.35, 0.1, 0.05]  + ([110.0, 0.0, 110.0, 0.35, 0.1, 0.05]*2)]).cuda()\n",
        "    inputs3 = torch.tensor([[110.0, 0.0, S - epsilon, 0.35, 0.1, 0.05]  + ([110.0, 0.0, 110.0, 0.35, 0.1, 0.05]*2)]).cuda()\n",
        "    gamma = (model(inputs2.float()) - 2*model(inputs1.float()) + model(inputs3.float()))/(epsilon**2)\n",
        "    return gamma\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "gammas = []\n",
        "for p in prices:\n",
        "    gammas.append(compute_gamma(p).item())\n",
        "fig = pylab.plot(prices, gammas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Gamma')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe4801b8450>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "aOsXgOwWZ_ru",
        "outputId": "0e3893c5-a64c-4187-d350-b01c53751003"
      },
      "source": [
        "##Using Finite Difference, Change 3 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_gamma(S):\n",
        "    epsilon = 0.5\n",
        "    inputs1 = torch.tensor([[110.0, 0.0, S, 0.35, 0.1, 0.05]*3]).cuda()\n",
        "    inputs2 = torch.tensor([[110.0, 0.0, S + epsilon, 0.35, 0.1, 0.05]*3]).cuda()\n",
        "    inputs3 = torch.tensor([[110.0, 0.0, S - epsilon, 0.35, 0.1, 0.05]*3]).cuda()\n",
        "    gamma = (model(inputs2.float()) - 2*model(inputs1.float()) + model(inputs3.float()))/(epsilon**2)\n",
        "    return gamma\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "gammas = []\n",
        "for p in prices:\n",
        "    gammas.append(compute_gamma(p).item())\n",
        "fig = pylab.plot(prices, gammas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Gamma')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe4801208d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67lca2xrBh9a"
      },
      "source": [
        "# Vega"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muozc-hzhSGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "a141b74b-9e67-4f25-a3ae-389e6a42961e"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "# vega\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_vega(S):\n",
        "    epsilon = 0.5\n",
        "    inputs1 = torch.tensor([[110.0, 0.0, S, 0.35, 0.1, 0.05] + ([110.0, 0.0, 110.0, 0.35, 0.1, 0.05]*2)]).cuda()\n",
        "    inputs2 = torch.tensor([[110.0, 0.0, S, 0.35 + epsilon, 0.1, 0.05] + ([110.0, 0.0, 110.0, 0.35, 0.1, 0.05]*2)]).cuda()\n",
        "    vega = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return vega\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "vegas = []\n",
        "for p in prices:\n",
        "    vegas.append(compute_vega(p).item())\n",
        "fig = pylab.plot(prices, vegas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Vega')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fb166b0d190>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "0KATxBCAdlFt",
        "outputId": "8ca0307a-932f-4b83-b3ee-976d9ddf74b2"
      },
      "source": [
        "##Using Finite Difference, Change 3 S0 at a timev\n",
        "# vega\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_vega(S):\n",
        "    epsilon = 0.5\n",
        "    inputs1 = torch.tensor([[110.0, 0.0, S, 0.35, 0.1, 0.05]*3]).cuda()\n",
        "    inputs2 = torch.tensor([[110.0, 0.0, S, 0.35 + epsilon, 0.1, 0.05]*3]).cuda()\n",
        "    vega = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return vega\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "vegas = []\n",
        "for p in prices:\n",
        "    vegas.append(compute_vega(p).item())\n",
        "fig = pylab.plot(prices, vegas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Vega')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe4800b3c90>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj7NlW6GVqSA"
      },
      "source": [
        "[Implied volatility](https://en.wikipedia.org/wiki/Implied_volatility) is the forecasted volatility of the underlying asset based on the quoted prices of the option. It is the reverse mapping of price to the option parameter given the model which is hard to do with the Monte Carlo simulation approach. But if we have the deep learning pricing model, it is an easy task. We can first plot the relationship between volatility and the option price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yrCw5UNT07t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "190d5877-924a-44ce-ecdb-50d5438767ae"
      },
      "source": [
        "import pylab\n",
        "import numpy as np\n",
        "def compute_price(sigma):\n",
        "    inputs = torch.tensor([[110.0, 0.0, 110.0, sigma, 0.1, 0.05] + ([110.0, 0.0, 110.0, 0.35, 0.1, 0.05]*2)]).cuda()\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    return x.item()\n",
        "sigmas = np.arange(0, 0.5, 0.1)\n",
        "prices = []\n",
        "for s in sigmas:\n",
        "    prices.append(compute_price(s))\n",
        "fig3 = pylab.plot(sigmas, prices)\n",
        "pylab.xlabel('Sigma')\n",
        "pylab.ylabel('Price')\n",
        "fig3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f21eccb09d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU25Cj29VtCa"
      },
      "source": [
        "Given the prices `P`, the implied volatility is the root of the function `compute_price`. We can use bisection to find the root."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddHnwm_zUBYD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "3b564d6a-8e79-48a5-d27e-80d7550f8e72"
      },
      "source": [
        "def bisection_root(small, large, fun, target, EPS=1e-6):\n",
        "    if fun(large) - target < 0:\n",
        "        print('upper bound is too small')\n",
        "        return None\n",
        "    if fun(small) - target > 0:\n",
        "        print('lower bound is too large')\n",
        "        return None\n",
        "    while large - small > EPS:\n",
        "        mid = (large + small) / 2.0\n",
        "        if fun(mid) - target >= 0:\n",
        "            large = mid\n",
        "        else:\n",
        "            small = mid\n",
        "    mid = (large + small) / 2.0\n",
        "    return mid, abs(fun(mid) - target)\n",
        "quoted_price = 16.0\n",
        "sigma, err = bisection_root(0, 0.5, compute_price, quoted_price)\n",
        "print('implied volativity', sigma, 'error', err)     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "upper bound is too small\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-ade689496c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mquoted_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbisection_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoted_price\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'implied volativity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    }
  ]
}