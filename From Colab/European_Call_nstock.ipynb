{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "European_Call_nstock.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "NwN6aLFDnwiy",
        "TY_9g3tbdLiY",
        "u2_89jOknwjH",
        "rXT4Bg0wdL7l"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Pui/From%20Colab/European_Call_nstock.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCR6hhw5Xq_R"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSxOZk3ls2XQ",
        "outputId": "bf2e1e79-1ad6-4d18-dd56-caba992cd7eb"
      },
      "source": [
        "!curl https://colab.chainer.org/install |sh -\n",
        "import cupy"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1580  100  1580    0     0   6396      0 --:--:-- --:--:-- --:--:--  6396\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "\u001b[K     |████████████████████████████████| 58.9 MB 51 kB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 59.9 MB/s \n",
            "\u001b[?25h  Building wheel for chainer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "+ set +ex\n",
            "Installation succeeded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwN6aLFDnwiy"
      },
      "source": [
        "### Deep Learning Barrier Option\n",
        "\n",
        "We used Numba and CuPy in the previous notebook to run Monte Carlo simulation to determine the price of the Asian Barrier option. A Monte Carlo simulation needs millions of paths to get an accurate answer which is computationally intensive. [Ryan et al (2018)](https://arxiv.org/abs/1809.02233) showed that a deep learning model can be trained to value derivatives. The deep learning model is accurate and very fast, capable of producing valuations a million times faster than traditional models. In the this notebook, we will use a fully connected network to learn the pricing mode of the Asian Barrier option. Monte Carlo simulation is used as pricing ground truth for the training. We use the same Asian Barrier Option model as last notebook with parameters listed as following:\n",
        "\n",
        "```\n",
        "T - Maturity (yrs.)\n",
        "S - Spot (usd)\n",
        "K - Strike (usd)\n",
        "sigma - Volatility (per.)\n",
        "r - Risk Free Rate (per.)\n",
        "mu - Stock Drift Rate (per.)\n",
        "B - Barrier (usd)\n",
        "```\n",
        "\n",
        "### Batched Data generation\n",
        "\n",
        "The dataset is an important part of the Deep learning training. We will modify the previous single Asian Barrier Option pricing code to handle a batch of Barrier Option pricing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHYrh4iYfP-n",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "###Test: Judy's new X code\n",
        "#N_STOCKS = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hy7qGwT0jv4A",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#X = cupy.array([])\n",
        "#for i in range(0,N_STOCKS):\n",
        "  #X =  cupy.concatenate((X,cupy.array([1,1]), cupy.random.rand(3),cupy.array([1])))\n",
        "#X = X.reshape(N_STOCKS,6)\n",
        "#X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9OHtAXC8hVae",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#X = X * ((cupy.array([200.0, 0, 200.0, 0.4, 0.2, 0.2] * N_STOCKS, dtype = cupy.float32)).reshape(N_STOCKS, 6))\n",
        "#X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY_9g3tbdLiY"
      },
      "source": [
        "### Train(Erin Version)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qBxT9Eida-c_"
      },
      "source": [
        "# ################################# TEST ########################################\n",
        "# %%writefile cupy_dataset.py\n",
        "\n",
        "# import numba\n",
        "# from numba import cuda\n",
        "# import random\n",
        "# import cupy\n",
        "# import numpy as np\n",
        "# import math\n",
        "# import time\n",
        "# import torch\n",
        "# cupy.cuda.set_allocator(None)\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# @cuda.jit\n",
        "# def batch_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_BATCH):\n",
        "#     # ii - overall thread index\n",
        "#     ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "#     stride = cuda.gridDim.x * cuda.blockDim.x\n",
        "#     tmp3 = math.sqrt(T/N_STEPS)\n",
        "#     for i in range(ii, N_PATHS * N_BATCH, stride):\n",
        "#         batch_id = i // N_PATHS\n",
        "#         path_id = i % N_PATHS\n",
        "#         tmp1 = mu[batch_id]*T/N_STEPS\n",
        "#         tmp2 = math.exp(-r[batch_id]*T)\n",
        "#         running_average = 0.0\n",
        "#         s_curr = S0[batch_id]\n",
        "#         for n in range(N_STEPS):\n",
        "#             s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH] # stock price\n",
        "#             running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average) # average of the path\n",
        "#             if i==0 and batch_id == 2:\n",
        "#                 print(s_curr)\n",
        "#             if running_average <= B[batch_id]: # if reach barrier, drop out the path\n",
        "#                 break\n",
        "#         payoff = running_average - K[batch_id] if running_average > K[batch_id] else 0\n",
        "#         d_s[i] = tmp2 * payoff\n",
        "\n",
        "# class NumbaOptionDataSet(object):\n",
        "    \n",
        "#     def __init__(self, max_len=10, number_path = 1000, batch=2, threads=512, seed=15, stocks=3):  # 3 stocks\n",
        "#         self.num = 0\n",
        "#         self.max_length = max_len\n",
        "#         self.N_PATHS = number_path\n",
        "#         self.N_STEPS = 365\n",
        "#         self.N_BATCH = batch\n",
        "#         self.N_STOCKS = stocks\n",
        "#         self.T = np.float32(1.0)\n",
        "#         self.output = cupy.zeros(self.N_STOCKS*self.N_PATHS, dtype=cupy.float32) \n",
        "#         self.number_of_blocks = (self.N_PATHS * self.N_STOCKS - 1) // threads + 1\n",
        "#         self.number_of_threads = threads\n",
        "#         cupy.random.seed(seed)\n",
        "        \n",
        "#     def __len__(self):\n",
        "#         return self.max_length\n",
        "        \n",
        "#     def __iter__(self):\n",
        "#         self.num = 0\n",
        "#         return self\n",
        "    \n",
        "#     def __next__(self):\n",
        "#         if self.num > self.max_length:\n",
        "#             raise StopIteration\n",
        "        \n",
        "#         Y = cupy.zeros(self.N_BATCH, dtype=cupy.float32)\n",
        "#         paras = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "#         for op in range(self.N_BATCH):\n",
        "          \n",
        "#           X = cupy.array([])\n",
        "#           K_rand = cupy.random.rand(1)[0]\n",
        "#           B_rand = cupy.random.rand(1)[0]\n",
        "#           r_rand = cupy.random.rand(1)[0]\n",
        "#           for i in range(0,self.N_STOCKS):\n",
        "#             X =  cupy.concatenate((X,cupy.array([K_rand,B_rand]), cupy.random.rand(3),cupy.array([r_rand]))) #[K,B,S0,sigma,mu,r], K B r are shared\n",
        "#           X = X.reshape(self.N_STOCKS,6)\n",
        "#           X = X * ((cupy.array([200.0, 0.1, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6))\n",
        "#           #X = cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)\n",
        "#           #X = 0.9 + cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)*0.1\n",
        "#           # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "#           #X = (X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6)\n",
        "\n",
        "#           # make sure the Barrier is smaller than the Strike price\n",
        "#           # X[:, 1] = X[:, 0] * X[:, 1]\n",
        "#           for i in range(self.N_STOCKS):\n",
        "#             paras[op,i*6:(i+1)*6] = X[i,:]\n",
        "\n",
        "#           stocks_randoms_mean = cupy.zeros(self.N_STOCKS, dtype = cupy.float32)\n",
        "#           rho = cupy.random.normal(0, 1, self.N_STOCKS, dtype = cupy.float32)\n",
        "\n",
        "#           #stocks_randoms_cov = cupy.ones((self.N_STOCKS, self.N_STOCKS), dtype = cupy.float32)\n",
        "#           #cupy.fill_diagonal(stocks_randoms_cov, rho)\n",
        "\n",
        "#           #stocks_randoms_cov = (-0.99 + cupy.random.rand(self.N_STOCKS*self.N_STOCKS, dtype=cupy.float32)*2*0.99).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "#           stocks_randoms_cov = cupy.array([1] * self.N_STOCKS*self.N_STOCKS, dtype = cupy.float32).reshape(self.N_STOCKS,self.N_STOCKS)  #Covariance\n",
        "#           cupy.fill_diagonal(stocks_randoms_cov, 1)\n",
        "\n",
        "#           num_of_randoms_each_stock = self.N_PATHS * self.N_STEPS\n",
        "#           randoms_gpu = cupy.random.multivariate_normal(stocks_randoms_mean, stocks_randoms_cov,\n",
        "#                                                         num_of_randoms_each_stock, dtype=cupy.float32)\n",
        "#           b1_r = randoms_gpu[:,0]\n",
        "#           b2_r = randoms_gpu[:,1]\n",
        "#           randoms = cupy.zeros(self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "#           interval = int((self.N_PATHS * self.N_STEPS * self.N_STOCKS) / self.N_PATHS)\n",
        "#           for i in range(interval):\n",
        "#             if i % 2 == 0:\n",
        "#                 ind = int(i/2)\n",
        "#                 randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b1_r[ind:(ind+self.N_PATHS)]\n",
        "#             else:\n",
        "#                 ind = int(i//2)\n",
        "#                 randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b2_r[ind:(ind+self.N_PATHS)]\n",
        "\n",
        "#           randoms = cupy.random.normal(0, 1, self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "#           batch_barrier_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, self.T, X[:, 0], \n",
        "#                                 X[:, 1], X[:, 2], X[:, 3], X[:, 4], X[:, 5], randoms, self.N_STEPS, self.N_PATHS, self.N_STOCKS)\n",
        "          \n",
        "#           o = self.output.reshape(self.N_STOCKS, self.N_PATHS)\n",
        "#           Y[op] = o.mean(axis = 0).mean()\n",
        "\n",
        "#         self.num += 1\n",
        "#         return (from_dlpack(paras.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "\n",
        "# # ds = NumbaOptionDataSet(10, number_path=100000, batch=3, seed=random.randint(0,100), stocks=5)\n",
        "# # for i in ds:\n",
        "# #     print(i[0])\n",
        "# ################################# TEST ########################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6dZnWTTfbf1"
      },
      "source": [
        "### Train (European Call option)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CeREuPw0fguQ",
        "outputId": "cdf983cb-5a45-499e-d173-72528aa150d4"
      },
      "source": [
        "################################# TEST ########################################\n",
        "%%writefile cupy_dataset.py\n",
        "\n",
        "import numba\n",
        "from numba import cuda\n",
        "import random\n",
        "import cupy\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "cupy.cuda.set_allocator(None)\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "@cuda.jit\n",
        "def European_call_option(d_s, T, K, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_BATCH):\n",
        "    # ii - overall thread index\n",
        "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
        "    #tmp3 = math.sqrt(T/N_STEPS)\n",
        "    for i in range(ii, N_PATHS * N_BATCH, stride):\n",
        "        batch_id = i // N_PATHS\n",
        "        path_id = i % N_PATHS\n",
        "        h = T[batch_id] / N_STEPS\n",
        "        tmp1 = r[batch_id]*T[batch_id]/N_STEPS \n",
        "        tmp2 = math.exp(-r[batch_id]*T[batch_id]) # discount\n",
        "        tmp3 = math.sqrt(T[batch_id]/N_STEPS)\n",
        "        #running_average = 0.0\n",
        "        s_curr = S0[batch_id]\n",
        "        for n in range(N_STEPS):\n",
        "          s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH] # stock price\n",
        "          #s_curr = s_curr * math.exp((r[batch_id] - (1/2)*sigma[batch_id]**2)*h + sigma[batch_id] * tmp3 * d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH])\n",
        "          #running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average) # average of the path\n",
        "          #if i==0 and batch_id == 2:\n",
        "          #    print(s_curr)\n",
        "          #if running_average <= B[batch_id]: # if reach barrier, drop out the path\n",
        "          #    break\n",
        "        #payoff = running_average - K[batch_id] if running_average > K[batch_id] else 0\n",
        "        #payoff = s_curr - K[batch_id] if s_curr > K[batch_id] else 0\n",
        "        #d_s[i] = tmp2 * payoff\n",
        "        d_s[i] = s_curr\n",
        "\n",
        "class NumbaOptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len=10, number_path = 1000, batch=2, threads=512, seed=15, stocks=3):  # 3 stocks\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        #self.N_STEPS = 365\n",
        "        self.N_STEPS = 10000\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        #self.T = np.float32(1.0)\n",
        "        self.output = cupy.zeros(self.N_STOCKS*self.N_PATHS, dtype=cupy.float32)\n",
        "        self.number_of_blocks = (self.N_PATHS * self.N_STOCKS - 1) // threads + 1\n",
        "        self.number_of_threads = threads\n",
        "        cupy.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num > self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros(self.N_BATCH, dtype=cupy.float32)\n",
        "        paras = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "        #paras = cupy.zeros((self.N_BATCH, self.N_STOCKS * 5), dtype = cupy.float32)\n",
        "\n",
        "        for op in range(self.N_BATCH):\n",
        "          \n",
        "          X = cupy.array([])\n",
        "          #T_rand = cupy.random.rand(1)[0]\n",
        "          K_rand = cupy.random.rand(1)\n",
        "          #B_rand = cupy.random.rand(1)[0]\n",
        "          r_rand = cupy.random.rand(1)\n",
        "          for i in range(0, self.N_STOCKS):\n",
        "            #X =  cupy.concatenate((X, cupy.array([K_rand,B_rand]), cupy.random.rand(3), cupy.array([r_rand]))) #[K,B,S0,sigma,mu,r], K B r are shared\n",
        "            X = cupy.concatenate((X, cupy.array([1.0]), K_rand, cupy.random.rand(3), r_rand))\n",
        "          \n",
        "          X = X.reshape(self.N_STOCKS, 6)\n",
        "          #X = X * ((cupy.array([200.0, 0.1, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6))\n",
        "          #[T, K, S0, sigma, mu, r]\n",
        "          X = X * ((cupy.array([1, 150.0, 150.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6))\n",
        "          #X = cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)\n",
        "          #X = 0.9 + cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)*0.1\n",
        "          # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "          #X = (X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6)\n",
        "\n",
        "          # make sure the Barrier is smaller than the Strike price\n",
        "          # X[:, 1] = X[:, 0] * X[:, 1]\n",
        "          for i in range(self.N_STOCKS):\n",
        "            paras[op,i*6:(i+1)*6] = X[i,:]\n",
        "            #paras[op, i*5:(i+1)*5] = X[i,:]\n",
        "\n",
        "          stocks_randoms_mean = cupy.zeros(self.N_STOCKS, dtype = cupy.float32)\n",
        "          rho = cupy.random.normal(0, 1, self.N_STOCKS, dtype = cupy.float32)\n",
        "\n",
        "          #stocks_randoms_cov = cupy.ones((self.N_STOCKS, self.N_STOCKS), dtype = cupy.float32)\n",
        "          #cupy.fill_diagonal(stocks_randoms_cov, rho)\n",
        "\n",
        "          #stocks_randoms_cov = (-0.99 + cupy.random.rand(self.N_STOCKS*self.N_STOCKS, dtype=cupy.float32)*2*0.99).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "          if self.N_STOCKS != 1:\n",
        "            randoms = cupy.random.normal(0, 1, self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "            # stocks_randoms_cov = cupy.array([0] * self.N_STOCKS*self.N_STOCKS, dtype = cupy.float32).reshape(self.N_STOCKS,self.N_STOCKS)  #Covariance\n",
        "            # cupy.fill_diagonal(stocks_randoms_cov, 1)\n",
        "\n",
        "            # num_of_randoms_each_stock = self.N_PATHS * self.N_STEPS\n",
        "            # randoms_gpu = cupy.random.multivariate_normal(stocks_randoms_mean, stocks_randoms_cov,\n",
        "            #                                               num_of_randoms_each_stock, dtype=cupy.float32)\n",
        "            # b1_r = randoms_gpu[:,0]\n",
        "            # b2_r = randoms_gpu[:,1]\n",
        "            # randoms = cupy.zeros(self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "            # interval = int((self.N_PATHS * self.N_STEPS * self.N_STOCKS) / self.N_PATHS)\n",
        "            # for i in range(interval):\n",
        "            #   if i % 2 == 0:\n",
        "            #       ind = int(i/2)\n",
        "            #       randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b1_r[ind:(ind+self.N_PATHS)]\n",
        "            #   else:\n",
        "            #       ind = int(i//2)\n",
        "            #       randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b2_r[ind:(ind+self.N_PATHS)]\n",
        "          if self.N_STOCKS == 1:\n",
        "            randoms = cupy.random.normal(0, 1, self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "          \n",
        "          European_call_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, X[:, 0], \n",
        "                                X[:, 1], X[:, 2], X[:, 3], X[:, 4], X[:, 5], randoms, self.N_STEPS, self.N_PATHS, self.N_STOCKS)\n",
        "          \n",
        "          o = self.output.reshape(self.N_STOCKS, self.N_PATHS) # this contains prices for each stock for each path at time T\n",
        "          K = K_rand * 150\n",
        "          r = r_rand * 0.2\n",
        "          o = o.mean(axis = 0) # average across stocks end prices\n",
        "          payoff = np.maximum(o - K, 0) # compute payoff\n",
        "          payoff = payoff * np.exp(-r*1) # T=1, discount\n",
        "          Y[op] = payoff.mean()\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(paras.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "# ds = NumbaOptionDataSet(1, number_path = 10000, batch = 3, seed = random.randint(0,100), stocks=3)\n",
        "# for i in ds:\n",
        "#     print(i)\n",
        "################################# TEST ########################################"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing cupy_dataset.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DTuXR1ANZPC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77a8e308-6345-40db-d2a9-4dee3600dd67"
      },
      "source": [
        "# def test(array):\n",
        "#   S1 = array[2]\n",
        "#   S2 = array[8]\n",
        "#   S3 = array[14]\n",
        "#   sigma1 = array[3]\n",
        "#   sigma2 = array[9]\n",
        "#   sigma3 = array[15]\n",
        "#   T = 1  \n",
        "#   K = array[1]\n",
        "#   r = array[5]\n",
        "\n",
        "#   dt = 1/1000\n",
        "#   N = round(T/dt)\n",
        "#   t = np.linspace(0, T, N)\n",
        "\n",
        "#   out = []\n",
        "\n",
        "#   for i in range(10000):\n",
        "#     W1 = np.random.standard_normal(size = N)\n",
        "#     W1 = np.cumsum(W1) * np.sqrt(dt)\n",
        "#     W2 = np.random.standard_normal(size = N)\n",
        "#     W2 = np.cumsum(W2) * np.sqrt(dt)\n",
        "#     W3 = np.random.standard_normal(size = N)\n",
        "#     W3 = np.cumsum(W3) * np.sqrt(dt)\n",
        "\n",
        "#     # W = np.random.standard_normal(size = N)\n",
        "#     # W = np.cumsum(W) * np.sqrt(dt)\n",
        "    \n",
        "#     P1_T = (S1 * np.exp((r - 0.5*sigma1**2) *t + sigma1 * W1))[-1]\n",
        "#     P2_T = (S2 * np.exp((r - 0.5*sigma2**2) *t + sigma2 * W2))[-1]\n",
        "#     P3_T = (S3 * np.exp((r - 0.5*sigma3**2) *t + sigma3 * W3))[-1]\n",
        "#     payoff = (P1_T+P2_T+P3_T)/3 - K if (P1_T+P2_T+P3_T)/3 > K else 0\n",
        "#     out.append(payoff * np.exp(-r*T))\n",
        "  \n",
        "#   return(np.array(out).mean())\n",
        "\n",
        "# print(test(np.array([1.0000e+00, 5.8549e+00, 3.6871e+01, 2.6866e-01, 1.9026e-01, 1.8305e-01,\n",
        "#          1.0000e+00, 5.8549e+00, 4.1110e+00, 2.3714e-01, 5.9547e-02, 1.8305e-01,\n",
        "#          1.0000e+00, 5.8549e+00, 1.6189e+01, 7.3936e-02, 1.1713e-01, 1.8305e-01])))\n",
        "# print(test(np.array([1.0000e+00, 1.1296e+02, 7.4318e+01, 2.0409e-01, 1.9133e-01, 5.3904e-02,\n",
        "#          1.0000e+00, 1.1296e+02, 5.3453e+01, 4.8439e-02, 5.8557e-02, 5.3904e-02,\n",
        "#          1.0000e+00, 1.1296e+02, 3.8721e+01, 2.0259e-01, 6.0423e-02, 5.3904e-02])))\n",
        "# print(test(np.array([1.0000e+00, 3.2307e+01, 3.8874e+01, 2.5820e-01, 1.9522e-01, 8.6353e-02,\n",
        "#          1.0000e+00, 3.2307e+01, 3.6077e+01, 3.7123e-01, 1.8810e-01, 8.6353e-02,\n",
        "#          1.0000e+00, 3.2307e+01, 6.9274e+01, 2.4100e-01, 1.9839e-01, 8.6353e-02])))\n",
        "# print(test(np.array([1.0000e+00, 2.4764e+01, 6.6956e+01, 2.0769e-01, 9.8127e-02, 1.7302e-01,\n",
        "#          1.0000e+00, 2.4764e+01, 3.6483e+01, 8.9075e-02, 1.9375e-01, 1.7302e-01,\n",
        "#          1.0000e+00, 2.4764e+01, 9.4748e+01, 2.6420e-01, 1.2015e-01, 1.7302e-01])))\n",
        "# print(test(np.array([1.0000e+00, 8.4591e+01, 1.2730e+02, 2.8949e-02, 1.0954e-01, 1.3706e-01,\n",
        "#          1.0000e+00, 8.4591e+01, 1.2859e+02, 1.5262e-01, 1.4064e-03, 1.3706e-01,\n",
        "#          1.0000e+00, 8.4591e+01, 4.6679e+01, 2.6688e-01, 1.5895e-01, 1.3706e-01])))\n",
        "# print(test(np.array([1.0000e+00, 6.8433e+01, 3.5593e+01, 6.5870e-02, 6.8068e-02, 1.3578e-02,\n",
        "#          1.0000e+00, 6.8433e+01, 2.3864e+01, 9.5815e-02, 1.6075e-01, 1.3578e-02,\n",
        "#          1.0000e+00, 6.8433e+01, 1.1863e+02, 3.0400e-01, 5.6958e-02, 1.3578e-02])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14.178983092451038\n",
            "0.0\n",
            "18.49899724819542\n",
            "45.0927326387435\n",
            "27.086101994054008\n",
            "2.2379929268359713\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqx6hNuucM5U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "606eb2b1-4ca1-4aff-d998-491b96a1de14"
      },
      "source": [
        "# array = np.array([1.0000e+00, 8.3754e+01, 1.2787e+02, 2.7420e-01, 1.2507e-01, 1.7700e-01,\n",
        "#          1.0000e+00, 8.3754e+01, 4.0869e+01, 3.3302e-01, 1.7439e-01, 1.7700e-01,\n",
        "#          1.0000e+00, 8.3754e+01, 1.1031e+02, 3.5945e-01, 1.5382e-01, 1.7700e-01])\n",
        "\n",
        "# S1 = array[2]\n",
        "# S2 = array[8]\n",
        "# S3 = array[14]\n",
        "# sigma1 = array[3]\n",
        "# sigma2 = array[9]\n",
        "# sigma3 = array[15]\n",
        "# T = 1  \n",
        "# K = array[1]\n",
        "# r = array[5]\n",
        "\n",
        "# dt = 1/100\n",
        "# N = round(T/dt)\n",
        "# t = np.linspace(0, T, N)\n",
        "\n",
        "# out = []\n",
        "\n",
        "# #for i in range(1000):\n",
        "# W = np.random.standard_normal(size = N)\n",
        "# W = np.cumsum(W) * np.sqrt(dt)\n",
        "# P1_T = (S1 * np.exp((r - 0.5*sigma1**2) *t + sigma1 * W))\n",
        "# P2_T = (S2 * np.exp((r - 0.5*sigma2**2) *t + sigma2 * W))[-1]\n",
        "# P3_T = (S3 * np.exp((r - 0.5*sigma3**2) *t + sigma3 * W))[-1]\n",
        "# #ayoff = (P1_T+P2_T+P3_T)/3 - K if (P1_T+P2_T+P3_T)/3 > K else 0\n",
        "# #out.append(payoff * np.exp(-r*T))\n",
        "\n",
        "# #return(np.array(out).mean())\n",
        "# #P1_T\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.plot(t, P1_T)\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tpLw9WDhx8b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84c6818b-404e-442d-98d5-f5d88bdc7f0f"
      },
      "source": [
        "# stocks_randoms_cov = cupy.array([0.99999] * 3 * 3, dtype = cupy.float32).reshape(3,3)  #Covariance\n",
        "# cupy.fill_diagonal(stocks_randoms_cov, 1)\n",
        "\n",
        "# stocks_randoms_mean = cupy.zeros(3, dtype = cupy.float32)\n",
        "\n",
        "# num_of_randoms_each_stock = 2 * 3\n",
        "# randoms_gpu = cupy.random.multivariate_normal(stocks_randoms_mean, stocks_randoms_cov,\n",
        "#                                               num_of_randoms_each_stock, dtype=cupy.float32)\n",
        "# randoms_gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.65482956,  0.6572376 ,  0.6532573 ],\n",
              "       [ 0.48803887,  0.49295187,  0.48680273],\n",
              "       [ 0.27158147,  0.27349606,  0.27123773],\n",
              "       [-1.562605  , -1.5679818 , -1.5590374 ],\n",
              "       [ 0.52474624,  0.5278822 ,  0.5220242 ],\n",
              "       [-1.5967214 , -1.5923952 , -1.5992373 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2_89jOknwjH"
      },
      "source": [
        "### Model\n",
        "To map the option parameters to price, we use 6 layers of fully connected neural network with hidden dimension 512 as inspired by [this paper](https://arxiv.org/abs/1809.02233). Writing this DL price model into a file `model.py`:-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMHqzJycx8XH"
      },
      "source": [
        "### Modified Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTn7iJQryAIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d22c93e6-b78b-4902-f5a7-14da34bd80c2"
      },
      "source": [
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# class Net(nn.Module):\n",
        "\n",
        "#     def __init__(self, hidden=1024):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.fc1 = nn.Linear(18, hidden) # remember to change this!\n",
        "#         self.fc2 = nn.Linear(hidden, hidden)\n",
        "#         self.fc3 = nn.Linear(hidden, hidden)\n",
        "#         self.fc4 = nn.Linear(hidden, hidden)\n",
        "#         self.fc5 = nn.Linear(hidden, hidden)\n",
        "#         self.fc6 = nn.Linear(hidden, 1)\n",
        "#         self.register_buffer('norm',\n",
        "#                              torch.tensor([200.0, 0.1, 200.0, 0.4, 0.2, 0.2]*3)) # don't use numpy here - will give error later\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 1)\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1, 150.0, 150.0, 0.4, 0.2, 0.2]*3)) # don't use numpy here - will give error later\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing model.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSPRFqyznwjI"
      },
      "source": [
        "As we know the random parameters' scaling factors, the input parameters are first scaled back to a range of (0-1) by dividing them by (200.0, 198.0, 200.0, 0.4, 0.2, 0.2). Then they are projected 5 times to the hidden dimension of 512 after the `ELu` activation function. `ELu` is chosen because we need to compute the second order differentiation of the parameters. If use ReLu, the second order differentiation will always be zero. The last layer is a linear layer that maps the hidden dimension to the predicted option price. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM8J2liPnwjJ"
      },
      "source": [
        "For training, we use [Ignite](https://github.com/pytorch/ignite) which is a high-level library to train neural networks in PyTorch. We use `MSELoss` as the loss function, `Adam` as the optimizer and `CosineAnnealingScheduler` as the learning rate scheduler. The following code is feeding the random option data to the pricing model to train it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yACi4ge13_rd"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TyZT8_AH35M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78e113f1-135b-4558-bab9-1950a6127380"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.6-py3-none-any.whl (232 kB)\n",
            "\u001b[K     |████████████████████████████████| 232 kB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Ej82G8nwjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f930e5ed-effb-4342-83ba-36cb94190f4f"
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import NumbaOptionDataSet\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "# dataset = NumbaOptionDataSet(max_len = 10000, number_path = 1024, batch = 4800)\n",
        "# dataset = NumbaOptionDataSet(max_len = 100, number_path = 1024, batch = 32, stocks = 3)\n",
        "dataset = NumbaOptionDataSet(max_len = 1000, number_path = 1024, batch = 1, stocks = 1)\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred[:,0], y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 800)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "loss 0.3753979206085205 average time 0.0030538156499460454 iter num 20\n",
            "loss 0.07987592369318008 average time 0.0026949340999181002 iter num 40\n",
            "loss 9.272710800170898 average time 0.002578504566645279 iter num 60\n",
            "loss 1.7408227920532227 average time 0.002535996137453367 iter num 80\n",
            "loss 3.937411069869995 average time 0.0025810805499168056 iter num 100\n",
            "loss 1.014735221862793 average time 0.0025338514999172427 iter num 120\n",
            "loss 0.6870109438896179 average time 0.002543925449975047 iter num 140\n",
            "loss 6.650151252746582 average time 0.0025350100249852403 iter num 160\n",
            "loss 13.515111923217773 average time 0.002509427805519711 iter num 180\n",
            "loss 39.94326400756836 average time 0.002498423439974431 iter num 200\n",
            "loss 0.46967145800590515 average time 0.0025345902408844267 iter num 220\n",
            "loss 7.027190685272217 average time 0.002527838012489762 iter num 240\n",
            "loss 1701.6619873046875 average time 0.0025154414192281997 iter num 260\n",
            "loss 5.8225417137146 average time 0.002503667357145137 iter num 280\n",
            "loss 1.9927440881729126 average time 0.0024946623766481935 iter num 300\n",
            "loss 30.32788848876953 average time 0.0024944103281086425 iter num 320\n",
            "loss 0.4162249267101288 average time 0.0025265784029429865 iter num 340\n",
            "loss 1.58430016040802 average time 0.002514966480551569 iter num 360\n",
            "loss 1.4149984121322632 average time 0.002500418578931299 iter num 380\n",
            "loss 10.537276268005371 average time 0.002497951447508058 iter num 400\n",
            "loss 6.680406093597412 average time 0.0024914340904745457 iter num 420\n",
            "loss 2.0387957096099854 average time 0.0025111517090904687 iter num 440\n",
            "loss 1.2719155550003052 average time 0.0025185607478266795 iter num 460\n",
            "loss 4.647185325622559 average time 0.0025197845604187324 iter num 480\n",
            "loss 0.06501825153827667 average time 0.0025095465620033792 iter num 500\n",
            "loss 4.138041973114014 average time 0.0024990570384698704 iter num 520\n",
            "loss 3.904658317565918 average time 0.002492419959276891 iter num 540\n",
            "loss 1.0433679819107056 average time 0.0024966653518017014 iter num 560\n",
            "loss 0.8528100848197937 average time 0.0024911081534590832 iter num 580\n",
            "loss 7.085140705108643 average time 0.0024872426666812924 iter num 600\n",
            "loss 4.152612686157227 average time 0.0024817857854912057 iter num 620\n",
            "loss 0.052387602627277374 average time 0.0024903698968785195 iter num 640\n",
            "loss 1.2822964191436768 average time 0.0024931479469766297 iter num 660\n",
            "loss 1.7169432640075684 average time 0.0024947195691230957 iter num 680\n",
            "loss 0.006430302746593952 average time 0.002504091124288347 iter num 700\n",
            "loss 0.003893862012773752 average time 0.002502170320831788 iter num 720\n",
            "loss 1.165967345237732 average time 0.002495601600000825 iter num 740\n",
            "loss 0.6679275631904602 average time 0.0024913391868387025 iter num 760\n",
            "loss 1.3144614696502686 average time 0.002489484126913456 iter num 780\n",
            "loss 0.05190787836909294 average time 0.002500211692490666 iter num 800\n",
            "loss 0.006089218892157078 average time 0.0024969363170628906 iter num 820\n",
            "loss 1.320766806602478 average time 0.0024923391023743795 iter num 840\n",
            "loss 0.4375910460948944 average time 0.002490245562783161 iter num 860\n",
            "loss 0.004599162843078375 average time 0.0024943760170427513 iter num 880\n",
            "loss 3.5606648921966553 average time 0.0024903586899927177 iter num 900\n",
            "loss 0.35665059089660645 average time 0.002497140681512262 iter num 920\n",
            "loss 105.56076049804688 average time 0.0024919003180757307 iter num 940\n",
            "loss 5.373021602630615 average time 0.0024949581072860384 iter num 960\n",
            "loss 0.1521649956703186 average time 0.002491385135710182 iter num 980\n",
            "loss 66.05766296386719 average time 0.0024894469049941107 iter num 1000\n",
            "loss 0.30760324001312256 average time 0.002882013700036623 iter num 20\n",
            "loss 1.7291210889816284 average time 0.0025967281750581606 iter num 40\n",
            "loss 0.16381396353244781 average time 0.00248387573343886 iter num 60\n",
            "loss 3.1432812213897705 average time 0.0025445762375284177 iter num 80\n",
            "loss 364.8880615234375 average time 0.002491857110017008 iter num 100\n",
            "loss 26.268753051757812 average time 0.002509022566694815 iter num 120\n",
            "loss 0.0032101052347570658 average time 0.0024748464500329906 iter num 140\n",
            "loss 0.2745104730129242 average time 0.002457118293773419 iter num 160\n",
            "loss 3.699558973312378 average time 0.0024424425000284422 iter num 180\n",
            "loss 4.02439022064209 average time 0.002428378335016532 iter num 200\n",
            "loss 0.017238181084394455 average time 0.0024207211363649218 iter num 220\n",
            "loss 20.922657012939453 average time 0.0024061275375136877 iter num 240\n",
            "loss 10.833948135375977 average time 0.002397488619240343 iter num 260\n",
            "loss 4.058862209320068 average time 0.002393513921424528 iter num 280\n",
            "loss 9.16892147064209 average time 0.0023876956366560382 iter num 300\n",
            "loss 0.08076058328151703 average time 0.0023931713156173373 iter num 320\n",
            "loss 14.597643852233887 average time 0.002401389026464826 iter num 340\n",
            "loss 0.9197388291358948 average time 0.002417475469443768 iter num 360\n",
            "loss 13.88397216796875 average time 0.002428146871041367 iter num 380\n",
            "loss 0.16279654204845428 average time 0.0024218364399985147 iter num 400\n",
            "loss 1.0949511528015137 average time 0.00244351902857445 iter num 420\n",
            "loss 0.17900997400283813 average time 0.002437826195471809 iter num 440\n",
            "loss 0.6701991558074951 average time 0.0024335165587059315 iter num 460\n",
            "loss 118.59308624267578 average time 0.002426273972927599 iter num 480\n",
            "loss 0.35662782192230225 average time 0.0024221077760012122 iter num 500\n",
            "loss 1.8033068180084229 average time 0.0024188790173131844 iter num 520\n",
            "loss 4.223559379577637 average time 0.0024152424611033727 iter num 540\n",
            "loss 2.323689295735676e-05 average time 0.002410593155351697 iter num 560\n",
            "loss 4.194500923156738 average time 0.002407821374128679 iter num 580\n",
            "loss 2.944432020187378 average time 0.0024210404616648398 iter num 600\n",
            "loss 0.9907349348068237 average time 0.0024205403999956383 iter num 620\n",
            "loss 2.0247020721435547 average time 0.0024157978515603417 iter num 640\n",
            "loss 0.5992681980133057 average time 0.0024117595712127558 iter num 660\n",
            "loss 1.3641332387924194 average time 0.0024076083500029414 iter num 680\n",
            "loss 0.6136461496353149 average time 0.002402128208577778 iter num 700\n",
            "loss 1.7737585306167603 average time 0.002398805826394184 iter num 720\n",
            "loss 0.313601016998291 average time 0.002394841478385265 iter num 740\n",
            "loss 180.0410614013672 average time 0.0023914117552713402 iter num 760\n",
            "loss 0.3821304142475128 average time 0.0023885006756455157 iter num 780\n",
            "loss 3.361372232437134 average time 0.0023859312675017464 iter num 800\n",
            "loss 0.05897224694490433 average time 0.0023851922426862387 iter num 820\n",
            "loss 0.002417988143861294 average time 0.002389657122624894 iter num 840\n",
            "loss 0.05200342833995819 average time 0.0023910349709356437 iter num 860\n",
            "loss 0.8798184394836426 average time 0.0023877685113699375 iter num 880\n",
            "loss 10.516727447509766 average time 0.002385259545561793 iter num 900\n",
            "loss 0.10320896655321121 average time 0.002393597958695429 iter num 920\n",
            "loss 0.0011867836583405733 average time 0.0023905733861690178 iter num 940\n",
            "loss 0.13555170595645905 average time 0.0023895725791646784 iter num 960\n",
            "loss 3.718071937561035 average time 0.0023970721418348205 iter num 980\n",
            "loss 0.10400393605232239 average time 0.0023953545489930547 iter num 1000\n",
            "loss 1.0807996988296509 average time 0.002955714950167021 iter num 20\n",
            "loss 96.52246856689453 average time 0.0026352046500505823 iter num 40\n",
            "loss 3.703169822692871 average time 0.0025157063333608675 iter num 60\n",
            "loss 22.56344223022461 average time 0.0024735912750429635 iter num 80\n",
            "loss 171.78750610351562 average time 0.0024551756100299827 iter num 100\n",
            "loss 0.0008737988537177444 average time 0.0024319001750730727 iter num 120\n",
            "loss 0.35591498017311096 average time 0.002407570592900551 iter num 140\n",
            "loss 0.28489524126052856 average time 0.00239641659377412 iter num 160\n",
            "loss 21.043560028076172 average time 0.002433872466715709 iter num 180\n",
            "loss 0.810967743396759 average time 0.0024184872050318517 iter num 200\n",
            "loss 0.000846239912789315 average time 0.0024110621136556308 iter num 220\n",
            "loss 1.4295016527175903 average time 0.0024270166000178507 iter num 240\n",
            "loss 0.15697252750396729 average time 0.002415713823085333 iter num 260\n",
            "loss 2.9173688888549805 average time 0.0024114939357397294 iter num 280\n",
            "loss 0.1586640179157257 average time 0.002398606026702813 iter num 300\n",
            "loss 17.188270568847656 average time 0.002419572856280183 iter num 320\n",
            "loss 14.750259399414062 average time 0.0024133981794608084 iter num 340\n",
            "loss 6.007561206817627 average time 0.0024064033694836933 iter num 360\n",
            "loss 0.7988218069076538 average time 0.002395975539514582 iter num 380\n",
            "loss 0.7796290516853333 average time 0.0023903768950594897 iter num 400\n",
            "loss 26.070913314819336 average time 0.002384410647673143 iter num 420\n",
            "loss 0.9236941337585449 average time 0.0023784546523322866 iter num 440\n",
            "loss 7.667524814605713 average time 0.002374337728317345 iter num 460\n",
            "loss 8.403461456298828 average time 0.002386092239635218 iter num 480\n",
            "loss 0.08566313236951828 average time 0.0023817984960514877 iter num 500\n",
            "loss 0.7557777166366577 average time 0.002392433209668245 iter num 520\n",
            "loss 2.4625279903411865 average time 0.0023930230981999622 iter num 540\n",
            "loss 0.10266061127185822 average time 0.0023886550804036234 iter num 560\n",
            "loss 23.328659057617188 average time 0.002399574843149884 iter num 580\n",
            "loss 0.0930694043636322 average time 0.0024098437483735325 iter num 600\n",
            "loss 0.05666166543960571 average time 0.0024092006226173026 iter num 620\n",
            "loss 14.149092674255371 average time 0.00240849910317138 iter num 640\n",
            "loss 29.35718536376953 average time 0.002415472187925788 iter num 660\n",
            "loss 0.8741027116775513 average time 0.0024220082426943596 iter num 680\n",
            "loss 0.064753457903862 average time 0.002429482297193317 iter num 700\n",
            "loss 1.280810832977295 average time 0.002440817538932707 iter num 720\n",
            "loss 0.7670275568962097 average time 0.0024385306378757673 iter num 740\n",
            "loss 0.3027215898036957 average time 0.0024431978895049005 iter num 760\n",
            "loss 0.5102383494377136 average time 0.0024458354423353367 iter num 780\n",
            "loss 0.16292910277843475 average time 0.002453244727521451 iter num 800\n",
            "loss 14.3461275100708 average time 0.0024609485646711927 iter num 820\n",
            "loss 3.6492726802825928 average time 0.0024606229500369367 iter num 840\n",
            "loss 0.3202976882457733 average time 0.0024630274349239996 iter num 860\n",
            "loss 0.4956408441066742 average time 0.002468788701172674 iter num 880\n",
            "loss 0.005944379139691591 average time 0.0024742271867035015 iter num 900\n",
            "loss 0.07819429039955139 average time 0.002483625597859946 iter num 920\n",
            "loss 221.7891082763672 average time 0.0024855660489768697 iter num 940\n",
            "loss 0.23997940123081207 average time 0.00248407185316258 iter num 960\n",
            "loss 0.28754308819770813 average time 0.0024855401775869036 iter num 980\n",
            "loss 5.384912490844727 average time 0.002490682159035714 iter num 1000\n",
            "loss 14.709763526916504 average time 0.0031757688002471696 iter num 20\n",
            "loss 0.830378532409668 average time 0.002892945550229342 iter num 40\n",
            "loss 8.285773277282715 average time 0.0027940881001389545 iter num 60\n",
            "loss 0.04018820822238922 average time 0.0027271557750736973 iter num 80\n",
            "loss 0.058898940682411194 average time 0.002673838140035514 iter num 100\n",
            "loss 5.513227462768555 average time 0.002675175091720424 iter num 120\n",
            "loss 2.63859224319458 average time 0.002667933678575147 iter num 140\n",
            "loss 18.87635040283203 average time 0.002659534581266598 iter num 160\n",
            "loss 2.8899831771850586 average time 0.0026559403722381425 iter num 180\n",
            "loss 1.3018827438354492 average time 0.0026593737249822878 iter num 200\n",
            "loss 49.3846321105957 average time 0.0026642270499988544 iter num 220\n",
            "loss 1.9928367137908936 average time 0.002674442358344701 iter num 240\n",
            "loss 0.20011255145072937 average time 0.0026748274961741676 iter num 260\n",
            "loss 0.0534997433423996 average time 0.002669084925011183 iter num 280\n",
            "loss 0.5712224841117859 average time 0.0026842569966659844 iter num 300\n",
            "loss 0.002330843359231949 average time 0.002678094490619287 iter num 320\n",
            "loss 11.067276954650879 average time 0.002678833585292416 iter num 340\n",
            "loss 2.2178001403808594 average time 0.002676926155562695 iter num 360\n",
            "loss 0.005490317940711975 average time 0.002678457578952619 iter num 380\n",
            "loss 99.11634063720703 average time 0.00267552010250256 iter num 400\n",
            "loss 0.4466308355331421 average time 0.0026729977833296983 iter num 420\n",
            "loss 0.5313707590103149 average time 0.0026714098045555476 iter num 440\n",
            "loss 0.17359399795532227 average time 0.002667378780449286 iter num 460\n",
            "loss 9.917679786682129 average time 0.002670419366677379 iter num 480\n",
            "loss 26.711332321166992 average time 0.0026651012020083727 iter num 500\n",
            "loss 13.74570083618164 average time 0.0026673047134758796 iter num 520\n",
            "loss 0.34857749938964844 average time 0.0026700645463043422 iter num 540\n",
            "loss 2.104327917098999 average time 0.0026689435714323346 iter num 560\n",
            "loss 1.1161589622497559 average time 0.0026701858431053926 iter num 580\n",
            "loss 14.959211349487305 average time 0.0026679811616728936 iter num 600\n",
            "loss 45.43826675415039 average time 0.0026579930064643473 iter num 620\n",
            "loss 0.10857918113470078 average time 0.0026532964250066014 iter num 640\n",
            "loss 7.2682881355285645 average time 0.002651142193936914 iter num 660\n",
            "loss 9.864005088806152 average time 0.002663895461755066 iter num 680\n",
            "loss 9.34902286529541 average time 0.002664136804277015 iter num 700\n",
            "loss 0.0002930720802396536 average time 0.0026616168666451913 iter num 720\n",
            "loss 0.6540629267692566 average time 0.0026638952661955585 iter num 740\n",
            "loss 0.6836981773376465 average time 0.002658979982875041 iter num 760\n",
            "loss 0.2726745307445526 average time 0.002662514633315228 iter num 780\n",
            "loss 16.366609573364258 average time 0.002658715381228376 iter num 800\n",
            "loss 17.789098739624023 average time 0.002654008802415419 iter num 820\n",
            "loss 9.108172416687012 average time 0.0026557077690237446 iter num 840\n",
            "loss 0.005573163740336895 average time 0.0026504119825382752 iter num 860\n",
            "loss 0.3494383692741394 average time 0.0026508560102105217 iter num 880\n",
            "loss 0.0003732176264747977 average time 0.002651747529980639 iter num 900\n",
            "loss 0.2859687805175781 average time 0.0026452334217241433 iter num 920\n",
            "loss 500.8714599609375 average time 0.0026553304765795783 iter num 940\n",
            "loss 0.01380139123648405 average time 0.0026546199364493833 iter num 960\n",
            "loss 0.17759212851524353 average time 0.0026531485846859066 iter num 980\n",
            "loss 0.8343948125839233 average time 0.002651106297991646 iter num 1000\n",
            "loss 0.40177804231643677 average time 0.0031502094499956 iter num 20\n",
            "loss 8.441678047180176 average time 0.0027675739749611237 iter num 40\n",
            "loss 0.2317124605178833 average time 0.0028869412500171165 iter num 60\n",
            "loss 0.04868714138865471 average time 0.002829445687484622 iter num 80\n",
            "loss 6.722493648529053 average time 0.0028048246900470985 iter num 100\n",
            "loss 36.28179931640625 average time 0.0027848504416700354 iter num 120\n",
            "loss 0.01280672661960125 average time 0.0027524178214532314 iter num 140\n",
            "loss 136.59658813476562 average time 0.0027273363250174044 iter num 160\n",
            "loss 0.20243717730045319 average time 0.002746335761124404 iter num 180\n",
            "loss 0.1550775170326233 average time 0.002740013575021294 iter num 200\n",
            "loss 0.04982668533921242 average time 0.0027332306136651657 iter num 220\n",
            "loss 1.5643996000289917 average time 0.0027275460750161074 iter num 240\n",
            "loss 0.47107449173927307 average time 0.002715275246170607 iter num 260\n",
            "loss 29.52825164794922 average time 0.0027066373928781623 iter num 280\n",
            "loss 3.674917459487915 average time 0.00270481073335759 iter num 300\n",
            "loss 0.012536467984318733 average time 0.0027004641562712096 iter num 320\n",
            "loss 0.013204172253608704 average time 0.002694009258854802 iter num 340\n",
            "loss 39.161746978759766 average time 0.002693973655570719 iter num 360\n",
            "loss 2.6874282360076904 average time 0.002693491168438892 iter num 380\n",
            "loss 0.12503263354301453 average time 0.0026917471875094632 iter num 400\n",
            "loss 0.5387800931930542 average time 0.0026759249880862106 iter num 420\n",
            "loss 9.309361457824707 average time 0.0026963390659023967 iter num 440\n",
            "loss 0.1184726431965828 average time 0.0026952169499924387 iter num 460\n",
            "loss 26.034074783325195 average time 0.0026949355854071653 iter num 480\n",
            "loss 0.05150356516242027 average time 0.002676032285991823 iter num 500\n",
            "loss 147.80984497070312 average time 0.002661383296131484 iter num 520\n",
            "loss 6.077993869781494 average time 0.0026479644148013097 iter num 540\n",
            "loss 3.9538350105285645 average time 0.0026357267660647005 iter num 560\n",
            "loss 1.224934697151184 average time 0.0026275084103276483 iter num 580\n",
            "loss 0.6146506667137146 average time 0.0026184283866587067 iter num 600\n",
            "loss 0.0002647025976330042 average time 0.002609436382250175 iter num 620\n",
            "loss 1.9630815982818604 average time 0.0026053667937475213 iter num 640\n",
            "loss 1.775664210319519 average time 0.0026014325333314696 iter num 660\n",
            "loss 15.737898826599121 average time 0.0025918428779438244 iter num 680\n",
            "loss 0.20313966274261475 average time 0.00258259190429661 iter num 700\n",
            "loss 0.7998040318489075 average time 0.0025752895083441117 iter num 720\n",
            "loss 29.409801483154297 average time 0.0025685275243361233 iter num 740\n",
            "loss 0.1010226309299469 average time 0.0025609458934324814 iter num 760\n",
            "loss 10.586913108825684 average time 0.0025532914910423314 iter num 780\n",
            "loss 0.6710144877433777 average time 0.0025556367600052 iter num 800\n",
            "loss 0.08953551203012466 average time 0.002555940951218118 iter num 820\n",
            "loss 0.3794997036457062 average time 0.0025511372785677806 iter num 840\n",
            "loss 2.6720595359802246 average time 0.002550539560461614 iter num 860\n",
            "loss 98.35430145263672 average time 0.0025518477056803847 iter num 880\n",
            "loss 2.459984540939331 average time 0.0025464055688886825 iter num 900\n",
            "loss 67.05664825439453 average time 0.0025408191413055685 iter num 920\n",
            "loss 2.0074992179870605 average time 0.0025399413031935067 iter num 940\n",
            "loss 9.528096199035645 average time 0.002541434620839785 iter num 960\n",
            "loss 5.331648349761963 average time 0.002538127369395198 iter num 980\n",
            "loss 4.496886730194092 average time 0.00253264154500539 iter num 1000\n",
            "loss 1.20136559009552 average time 0.002900953449898225 iter num 20\n",
            "loss 1.7700786590576172 average time 0.0026942898748075093 iter num 40\n",
            "loss 0.6020685434341431 average time 0.0025655297332074648 iter num 60\n",
            "loss 51.45636749267578 average time 0.002500818137355054 iter num 80\n",
            "loss 0.0028463720809668303 average time 0.0025327322498924333 iter num 100\n",
            "loss 0.24236495792865753 average time 0.00249822752490824 iter num 120\n",
            "loss 5.746513366699219 average time 0.002476366157069216 iter num 140\n",
            "loss 0.0451781339943409 average time 0.0024585298312217673 iter num 160\n",
            "loss 1.862427830696106 average time 0.0024374923888596336 iter num 180\n",
            "loss 5.187732219696045 average time 0.002440209799951845 iter num 200\n",
            "loss 50.7169303894043 average time 0.002423927886304062 iter num 220\n",
            "loss 0.0002954626106657088 average time 0.002419578412430686 iter num 240\n",
            "loss 0.001472120638936758 average time 0.0024062676191743564 iter num 260\n",
            "loss 2.5816895961761475 average time 0.0023950201463646538 iter num 280\n",
            "loss 0.033965855836868286 average time 0.00240148561329382 iter num 300\n",
            "loss 14.03756332397461 average time 0.0024103654749580983 iter num 320\n",
            "loss 1.2938933372497559 average time 0.0024233220381949436 iter num 340\n",
            "loss 10.833370208740234 average time 0.002419728369401734 iter num 360\n",
            "loss 3.0888822078704834 average time 0.002411307418385963 iter num 380\n",
            "loss 0.5533706545829773 average time 0.00240409395747065 iter num 400\n",
            "loss 54.901710510253906 average time 0.0023979228261634404 iter num 420\n",
            "loss 0.04089484363794327 average time 0.0024136871772456785 iter num 440\n",
            "loss 5.420734405517578 average time 0.002406378221708703 iter num 460\n",
            "loss 1.2315046787261963 average time 0.002401728356217821 iter num 480\n",
            "loss 12.022225379943848 average time 0.002395818237975618 iter num 500\n",
            "loss 4.197571754455566 average time 0.0023956191596006156 iter num 520\n",
            "loss 0.0990457758307457 average time 0.002392258625904678 iter num 540\n",
            "loss 0.05044661462306976 average time 0.0023892116285521427 iter num 560\n",
            "loss 0.040882501751184464 average time 0.0024355438620440165 iter num 580\n",
            "loss 0.48060986399650574 average time 0.002439408461638474 iter num 600\n",
            "loss 17.887683868408203 average time 0.002437831422556032 iter num 620\n",
            "loss 0.5432076454162598 average time 0.002432178320279377 iter num 640\n",
            "loss 0.09131580591201782 average time 0.002441818690873664 iter num 660\n",
            "loss 7.33673620223999 average time 0.0024488960249661484 iter num 680\n",
            "loss 0.1790228933095932 average time 0.002444149164259995 iter num 700\n",
            "loss 0.08792424947023392 average time 0.002440802426372102 iter num 720\n",
            "loss 250.61407470703125 average time 0.002438470327005898 iter num 740\n",
            "loss 0.016035838052630424 average time 0.0024336193815519148 iter num 760\n",
            "loss 7.262673854827881 average time 0.0024301003897142857 iter num 780\n",
            "loss 0.01764625310897827 average time 0.0024266856124700096 iter num 800\n",
            "loss 0.03286759927868843 average time 0.0024343555767988687 iter num 820\n",
            "loss 26.50640869140625 average time 0.0024324583773531706 iter num 840\n",
            "loss 8.146862983703613 average time 0.002429240213923338 iter num 860\n",
            "loss 12.889826774597168 average time 0.0024272726545136306 iter num 880\n",
            "loss 1.1657118797302246 average time 0.002423914319962124 iter num 900\n",
            "loss 0.1273992359638214 average time 0.0024234899336534 iter num 920\n",
            "loss 0.24818749725818634 average time 0.002420069291451426 iter num 940\n",
            "loss 0.08902657777070999 average time 0.002429586967669669 iter num 960\n",
            "loss 0.30962473154067993 average time 0.002426456639757965 iter num 980\n",
            "loss 0.1730753481388092 average time 0.0024252944689669674 iter num 1000\n",
            "loss 308.07183837890625 average time 0.003050136250021751 iter num 20\n",
            "loss 2.6716854572296143 average time 0.002781849799976044 iter num 40\n",
            "loss 14.74781322479248 average time 0.002605856549962482 iter num 60\n",
            "loss 13.498106002807617 average time 0.0026237886874696413 iter num 80\n",
            "loss 14.736959457397461 average time 0.002545156819960539 iter num 100\n",
            "loss 0.9871933460235596 average time 0.0025030056916421017 iter num 120\n",
            "loss 0.16362905502319336 average time 0.002477687907126632 iter num 140\n",
            "loss 0.9969267845153809 average time 0.0024614079062075687 iter num 160\n",
            "loss 9.22194766998291 average time 0.0024404390777716697 iter num 180\n",
            "loss 138.26463317871094 average time 0.0024281178499950327 iter num 200\n",
            "loss 2.6322507858276367 average time 0.0024299737272568483 iter num 220\n",
            "loss 26.30536651611328 average time 0.002436987004155829 iter num 240\n",
            "loss 0.4980635344982147 average time 0.0024259220846173635 iter num 260\n",
            "loss 0.019421154633164406 average time 0.002415215803596636 iter num 280\n",
            "loss 0.0855930894613266 average time 0.002413528469999922 iter num 300\n",
            "loss 29.04979133605957 average time 0.002415175421879212 iter num 320\n",
            "loss 1.1582772731781006 average time 0.002404549911753908 iter num 340\n",
            "loss 2.74200177192688 average time 0.0023967192277672845 iter num 360\n",
            "loss 4.9668684005737305 average time 0.002391986850005579 iter num 380\n",
            "loss 9.312061309814453 average time 0.002394169480007804 iter num 400\n",
            "loss 123.05148315429688 average time 0.002389268992867853 iter num 420\n",
            "loss 9.850830078125 average time 0.0023852542818159155 iter num 440\n",
            "loss 0.154087632894516 average time 0.002381582921735453 iter num 460\n",
            "loss 0.10619904845952988 average time 0.0023851941124917175 iter num 480\n",
            "loss 0.46121829748153687 average time 0.0023834387320057432 iter num 500\n",
            "loss 1.7791072130203247 average time 0.0023816917750082212 iter num 520\n",
            "loss 6.966374397277832 average time 0.002379182120370792 iter num 540\n",
            "loss 9.430286407470703 average time 0.002394966892857805 iter num 560\n",
            "loss 0.07651412487030029 average time 0.0023900422068938248 iter num 580\n",
            "loss 0.23144476115703583 average time 0.002386445454991796 iter num 600\n",
            "loss 47.12934875488281 average time 0.0023844083241783666 iter num 620\n",
            "loss 13.06473445892334 average time 0.0023827098468586884 iter num 640\n",
            "loss 1.0202314853668213 average time 0.0023818275924206702 iter num 660\n",
            "loss 0.0074974652379751205 average time 0.0023799305573581533 iter num 680\n",
            "loss 3.5984039306640625 average time 0.0023786345085786056 iter num 700\n",
            "loss 1.9443343877792358 average time 0.0023873679222282994 iter num 720\n",
            "loss 1.6209266185760498 average time 0.002384174679731144 iter num 740\n",
            "loss 0.10669883340597153 average time 0.002381155438153751 iter num 760\n",
            "loss 1.9961004257202148 average time 0.002380721814102006 iter num 780\n",
            "loss 0.5765165686607361 average time 0.002378082692496264 iter num 800\n",
            "loss 0.8496012091636658 average time 0.0023762290560958585 iter num 820\n",
            "loss 0.006687883287668228 average time 0.002374634622615953 iter num 840\n",
            "loss 0.0009675236069597304 average time 0.0023720142360405083 iter num 860\n",
            "loss 0.8765919208526611 average time 0.0023717437011328 iter num 880\n",
            "loss 2.726257801055908 average time 0.002375324111110078 iter num 900\n",
            "loss 0.0010406422661617398 average time 0.002373455772826476 iter num 920\n",
            "loss 67.3893051147461 average time 0.0023719502000026393 iter num 940\n",
            "loss 0.047573432326316833 average time 0.002377200356253676 iter num 960\n",
            "loss 5.1423258781433105 average time 0.002376266567345589 iter num 980\n",
            "loss 17.76082420349121 average time 0.0023844096030024957 iter num 1000\n",
            "loss 3.9168829917907715 average time 0.002933286700226745 iter num 20\n",
            "loss 2.4649229049682617 average time 0.0026409970251734193 iter num 40\n",
            "loss 9.046064376831055 average time 0.002521288533353072 iter num 60\n",
            "loss 0.37803003191947937 average time 0.0025055498249685116 iter num 80\n",
            "loss 1.495843768119812 average time 0.0024634571499518644 iter num 100\n",
            "loss 1.1546016931533813 average time 0.002441038558284466 iter num 120\n",
            "loss 0.24005065858364105 average time 0.0024172227713929067 iter num 140\n",
            "loss 103.9559097290039 average time 0.002398027793708479 iter num 160\n",
            "loss 1.761710286140442 average time 0.0023898293610929815 iter num 180\n",
            "loss 33.59562301635742 average time 0.0024013661150092958 iter num 200\n",
            "loss 2.0029819011688232 average time 0.0023942789818317 iter num 220\n",
            "loss 0.02302360348403454 average time 0.0024106119458565446 iter num 240\n",
            "loss 110.60540771484375 average time 0.002405793492324357 iter num 260\n",
            "loss 32.57804489135742 average time 0.0024139531535833417 iter num 280\n",
            "loss 9.717048645019531 average time 0.002405058113333022 iter num 300\n",
            "loss 1.461089849472046 average time 0.002398346656235617 iter num 320\n",
            "loss 4.926694869995117 average time 0.0023932425882241446 iter num 340\n",
            "loss 1.5913374423980713 average time 0.002389484594429329 iter num 360\n",
            "loss 0.0857011005282402 average time 0.0023834407131528824 iter num 380\n",
            "loss 0.8000956177711487 average time 0.002383997072488455 iter num 400\n",
            "loss 0.4789714515209198 average time 0.0023793122523654477 iter num 420\n",
            "loss 0.0026919180527329445 average time 0.0023772804999763054 iter num 440\n",
            "loss 7.5211615562438965 average time 0.0023965938586709102 iter num 460\n",
            "loss 0.010998560115695 average time 0.0023893007291462707 iter num 480\n",
            "loss 4.301050186157227 average time 0.0023845123299870465 iter num 500\n",
            "loss 0.08422800898551941 average time 0.002387202865377101 iter num 520\n",
            "loss 2.8843634128570557 average time 0.0023909431999999033 iter num 540\n",
            "loss 3.950805187225342 average time 0.002386417435715365 iter num 560\n",
            "loss 1.6668493747711182 average time 0.0023831953517213247 iter num 580\n",
            "loss 4.712932586669922 average time 0.0023900008333293953 iter num 600\n",
            "loss 14.06564712524414 average time 0.0023861690370957206 iter num 620\n",
            "loss 0.08508718758821487 average time 0.002383229807807652 iter num 640\n",
            "loss 1.0959463119506836 average time 0.0023909392954478926 iter num 660\n",
            "loss 3.439687728881836 average time 0.002392539117638936 iter num 680\n",
            "loss 2.2069718837738037 average time 0.0023903494756996224 iter num 700\n",
            "loss 112.82367706298828 average time 0.002396582598592229 iter num 720\n",
            "loss 0.24946622550487518 average time 0.002405534897283163 iter num 740\n",
            "loss 59.592529296875 average time 0.002410353811831699 iter num 760\n",
            "loss 13.803068161010742 average time 0.0024082656512757986 iter num 780\n",
            "loss 3.312565565109253 average time 0.002407311354993453 iter num 800\n",
            "loss 0.18285655975341797 average time 0.0024147669256042096 iter num 820\n",
            "loss 0.287657767534256 average time 0.0024262131833200414 iter num 840\n",
            "loss 1.0122020244598389 average time 0.0024315797011505037 iter num 860\n",
            "loss 0.0033903277944773436 average time 0.0024383326715802798 iter num 880\n",
            "loss 0.2319193184375763 average time 0.0024420008955470013 iter num 900\n",
            "loss 0.1976378858089447 average time 0.002448321349993421 iter num 920\n",
            "loss 1.6979666948318481 average time 0.002454670771273046 iter num 940\n",
            "loss 0.015777960419654846 average time 0.0024594648187511816 iter num 960\n",
            "loss 0.14839118719100952 average time 0.0024615445765281334 iter num 980\n",
            "loss 3.729820966720581 average time 0.002466139045998716 iter num 1000\n",
            "loss 10.903972625732422 average time 0.0034531552002590614 iter num 20\n",
            "loss 3.3402838706970215 average time 0.0030638539001756728 iter num 40\n",
            "loss 6.178854465484619 average time 0.0029288593001486635 iter num 60\n",
            "loss 4.52452278137207 average time 0.0029039033750677843 iter num 80\n",
            "loss 1.8800445795059204 average time 0.0027881695400355966 iter num 100\n",
            "loss 0.23760546743869781 average time 0.002783687033343085 iter num 120\n",
            "loss 1.1101549863815308 average time 0.002761882264322984 iter num 140\n",
            "loss 9.893403053283691 average time 0.00276500443749228 iter num 160\n",
            "loss 9.550718307495117 average time 0.002731670483313388 iter num 180\n",
            "loss 0.11689291149377823 average time 0.0027276461149722308 iter num 200\n",
            "loss 0.07597287744283676 average time 0.0027385630045418195 iter num 220\n",
            "loss 9.638096809387207 average time 0.0027228425291847694 iter num 240\n",
            "loss 0.016793562099337578 average time 0.0026977303000001902 iter num 260\n",
            "loss 0.03832300752401352 average time 0.002698709775001719 iter num 280\n",
            "loss 2.2035956382751465 average time 0.00269561275998664 iter num 300\n",
            "loss 0.659648060798645 average time 0.0026988554562137777 iter num 320\n",
            "loss 12.613195419311523 average time 0.002695351282331745 iter num 340\n",
            "loss 4.311091423034668 average time 0.002682993649978016 iter num 360\n",
            "loss 0.057368479669094086 average time 0.0026772818578760242 iter num 380\n",
            "loss 11.662951469421387 average time 0.002677776172472477 iter num 400\n",
            "loss 9.749991416931152 average time 0.0026682745356733256 iter num 420\n",
            "loss 5.038153648376465 average time 0.002675945059060971 iter num 440\n",
            "loss 269.8604431152344 average time 0.002662258739106303 iter num 460\n",
            "loss 3.1794869899749756 average time 0.0026687254791454506 iter num 480\n",
            "loss 2.667353630065918 average time 0.002673427357975015 iter num 500\n",
            "loss 0.130976140499115 average time 0.002668214184590257 iter num 520\n",
            "loss 310.37872314453125 average time 0.0026701206073758603 iter num 540\n",
            "loss 0.04616669937968254 average time 0.00266288752496361 iter num 560\n",
            "loss 0.09212451428174973 average time 0.002660717206862469 iter num 580\n",
            "loss 0.12087158113718033 average time 0.002665287104964591 iter num 600\n",
            "loss 0.07072291523218155 average time 0.0026658609790003187 iter num 620\n",
            "loss 0.044428013265132904 average time 0.002667930614029501 iter num 640\n",
            "loss 0.8780182003974915 average time 0.002668516683303151 iter num 660\n",
            "loss 33.41381072998047 average time 0.0026689006279144345 iter num 680\n",
            "loss 95.52545166015625 average time 0.0026693607642534647 iter num 700\n",
            "loss 1.1564387083053589 average time 0.0026699419430188855 iter num 720\n",
            "loss 0.6633797287940979 average time 0.0026697970580735766 iter num 740\n",
            "loss 0.22202853858470917 average time 0.0026693371802258823 iter num 760\n",
            "loss 9.380167961120605 average time 0.0026703043127828353 iter num 780\n",
            "loss 23.813106536865234 average time 0.002668495182463175 iter num 800\n",
            "loss 1.949273705482483 average time 0.0026661111731322664 iter num 820\n",
            "loss 0.1461426466703415 average time 0.002677630491635206 iter num 840\n",
            "loss 0.0005889774765819311 average time 0.0026733045988040368 iter num 860\n",
            "loss 0.31450366973876953 average time 0.002677604770422642 iter num 880\n",
            "loss 82.45599365234375 average time 0.002678031896632294 iter num 900\n",
            "loss 6.260380268096924 average time 0.0026759311423535585 iter num 920\n",
            "loss 0.01564217172563076 average time 0.0026717018808143467 iter num 940\n",
            "loss 28.969741821289062 average time 0.0026685390739241183 iter num 960\n",
            "loss 103.19715118408203 average time 0.0026804208009930243 iter num 980\n",
            "loss 15.451109886169434 average time 0.002679099958975712 iter num 1000\n",
            "loss 0.20948036015033722 average time 0.0033242256001358326 iter num 20\n",
            "loss 55.35431671142578 average time 0.003031105500167541 iter num 40\n",
            "loss 0.09519489854574203 average time 0.002899113466628478 iter num 60\n",
            "loss 7.178782939910889 average time 0.0028140115250380403 iter num 80\n",
            "loss 0.16336789727210999 average time 0.002727250730022206 iter num 100\n",
            "loss 0.3020167946815491 average time 0.0027328612666830546 iter num 120\n",
            "loss 64.52328491210938 average time 0.00267203710717305 iter num 140\n",
            "loss 0.24993014335632324 average time 0.0026703883688014686 iter num 160\n",
            "loss 15.655016899108887 average time 0.0026623993389370704 iter num 180\n",
            "loss 0.5252498388290405 average time 0.0026644961400324975 iter num 200\n",
            "loss 2.614370107650757 average time 0.0026641643409179364 iter num 220\n",
            "loss 5.583817958831787 average time 0.002664035166700766 iter num 240\n",
            "loss 3.1876273155212402 average time 0.0026518156577227414 iter num 260\n",
            "loss 5.464715957641602 average time 0.0026540707536111896 iter num 280\n",
            "loss 11.1688814163208 average time 0.0026544349833723876 iter num 300\n",
            "loss 0.6823016405105591 average time 0.002659026668789011 iter num 320\n",
            "loss 0.6528699398040771 average time 0.002657756494163015 iter num 340\n",
            "loss 572.8899536132812 average time 0.002646381477835449 iter num 360\n",
            "loss 3.5208911895751953 average time 0.0026401480500537313 iter num 380\n",
            "loss 3.6276252269744873 average time 0.0026450045025421787 iter num 400\n",
            "loss 0.07875753939151764 average time 0.002641888964323395 iter num 420\n",
            "loss 0.7195420861244202 average time 0.0026401326364024996 iter num 440\n",
            "loss 30.83302879333496 average time 0.002643515017410644 iter num 460\n",
            "loss 0.0026020335499197245 average time 0.0026364664333489904 iter num 480\n",
            "loss 202.1101531982422 average time 0.0026367019600183994 iter num 500\n",
            "loss 39.07814025878906 average time 0.002644639223101946 iter num 520\n",
            "loss 1.1492218971252441 average time 0.0026472376944757007 iter num 540\n",
            "loss 1.1254652738571167 average time 0.0026449967857420883 iter num 560\n",
            "loss 20.313770294189453 average time 0.0026361868517502944 iter num 580\n",
            "loss 6.214687824249268 average time 0.0026299659766906795 iter num 600\n",
            "loss 59.62480926513672 average time 0.0026312886226033667 iter num 620\n",
            "loss 0.4524623155593872 average time 0.0026210730359537138 iter num 640\n",
            "loss 0.5424038171768188 average time 0.0026230302575999246 iter num 660\n",
            "loss 0.9463199377059937 average time 0.002615371329447418 iter num 680\n",
            "loss 12.86327075958252 average time 0.002605189708600457 iter num 700\n",
            "loss 46.342559814453125 average time 0.002595655669476097 iter num 720\n",
            "loss 0.02824811264872551 average time 0.002603472321656276 iter num 740\n",
            "loss 0.2504274249076843 average time 0.0026063018460861617 iter num 760\n",
            "loss 0.47483551502227783 average time 0.002597548616699313 iter num 780\n",
            "loss 5.414483547210693 average time 0.002589550630029862 iter num 800\n",
            "loss 0.017012769356369972 average time 0.002581802931736758 iter num 820\n",
            "loss 0.6699618101119995 average time 0.0025741351952677047 iter num 840\n",
            "loss 0.03167671337723732 average time 0.002567361446531428 iter num 860\n",
            "loss 0.14671923220157623 average time 0.0025605367681981244 iter num 880\n",
            "loss 0.06039612740278244 average time 0.002554853453352229 iter num 900\n",
            "loss 0.3926589787006378 average time 0.0025491034793602646 iter num 920\n",
            "loss 11.832514762878418 average time 0.00254348249895013 iter num 940\n",
            "loss 0.6763026714324951 average time 0.002538467846888655 iter num 960\n",
            "loss 0.037341728806495667 average time 0.002534999878588103 iter num 980\n",
            "loss 0.09811215847730637 average time 0.002529895956016844 iter num 1000\n",
            "loss 0.834863543510437 average time 0.003094482749929739 iter num 20\n",
            "loss 18.254444122314453 average time 0.002684243099974992 iter num 40\n",
            "loss 15.564738273620605 average time 0.0025571963167143013 iter num 60\n",
            "loss 0.858328640460968 average time 0.0025149719375349377 iter num 80\n",
            "loss 1.2185930013656616 average time 0.002474492869932874 iter num 100\n",
            "loss 1.9359710216522217 average time 0.0024866804916200635 iter num 120\n",
            "loss 3.2909114360809326 average time 0.0025005746570968767 iter num 140\n",
            "loss 17.601415634155273 average time 0.002477028018722649 iter num 160\n",
            "loss 1.3208019733428955 average time 0.0024574255833006947 iter num 180\n",
            "loss 4.561737060546875 average time 0.0024446255499606193 iter num 200\n",
            "loss 5.143744468688965 average time 0.002429781586314758 iter num 220\n",
            "loss 4.015000820159912 average time 0.002437559916635716 iter num 240\n",
            "loss 3.1135263442993164 average time 0.0024309040307553703 iter num 260\n",
            "loss 25.516864776611328 average time 0.0024427184892829245 iter num 280\n",
            "loss 31.064430236816406 average time 0.0024353006599812945 iter num 300\n",
            "loss 44.500579833984375 average time 0.0024329896562448996 iter num 320\n",
            "loss 7.403719902038574 average time 0.00243030302647051 iter num 340\n",
            "loss 0.9987872838973999 average time 0.0024253268638808043 iter num 360\n",
            "loss 1.2412134408950806 average time 0.0024205311210416286 iter num 380\n",
            "loss 13.758942604064941 average time 0.002415937169989775 iter num 400\n",
            "loss 2.6031441688537598 average time 0.002411413533320142 iter num 420\n",
            "loss 61.534828186035156 average time 0.0024050999045233433 iter num 440\n",
            "loss 0.8654682636260986 average time 0.002402905469546607 iter num 460\n",
            "loss 16.558982849121094 average time 0.0024390937812313494 iter num 480\n",
            "loss 0.006850486621260643 average time 0.0024442718919817706 iter num 500\n",
            "loss 3.717454195022583 average time 0.002439283661522915 iter num 520\n",
            "loss 4.478025913238525 average time 0.002445196861103964 iter num 540\n",
            "loss 0.3694603443145752 average time 0.00245053853927532 iter num 560\n",
            "loss 0.15510155260562897 average time 0.0024471893499923743 iter num 580\n",
            "loss 0.4498027563095093 average time 0.0024431468733261377 iter num 600\n",
            "loss 0.08954921364784241 average time 0.002440565183857665 iter num 620\n",
            "loss 0.6197891235351562 average time 0.002437917079677732 iter num 640\n",
            "loss 2.273268461227417 average time 0.0024362714287759226 iter num 660\n",
            "loss 0.7029787302017212 average time 0.0024404698367454652 iter num 680\n",
            "loss 0.44637593626976013 average time 0.0024446505942614747 iter num 700\n",
            "loss 17.70142364501953 average time 0.0024479613777480657 iter num 720\n",
            "loss 0.4856475293636322 average time 0.0024467531202414673 iter num 740\n",
            "loss 0.11244107782840729 average time 0.002451543943394235 iter num 760\n",
            "loss 0.4056682586669922 average time 0.0024494381089565508 iter num 780\n",
            "loss 6.0168867111206055 average time 0.002463894446241284 iter num 800\n",
            "loss 1.9878736734390259 average time 0.0024612573085350292 iter num 820\n",
            "loss 0.06612184643745422 average time 0.0024585655119023745 iter num 840\n",
            "loss 0.27576780319213867 average time 0.002458806698837708 iter num 860\n",
            "loss 9.207125663757324 average time 0.002462298622729329 iter num 880\n",
            "loss 0.1011681780219078 average time 0.0024584442877797603 iter num 900\n",
            "loss 7.135287761688232 average time 0.002455388763046753 iter num 920\n",
            "loss 481.25390625 average time 0.0024626460999996277 iter num 940\n",
            "loss 0.21263177692890167 average time 0.0024642481979185505 iter num 960\n",
            "loss 146.15878295898438 average time 0.002461620366330881 iter num 980\n",
            "loss 132.7449493408203 average time 0.0024593144490045234 iter num 1000\n",
            "loss 0.6444682478904724 average time 0.002938083499611821 iter num 20\n",
            "loss 1.1949542760849 average time 0.00274605014988083 iter num 40\n",
            "loss 0.14513377845287323 average time 0.0026147546832665587 iter num 60\n",
            "loss 5.548520565032959 average time 0.0025361832125327054 iter num 80\n",
            "loss 4.276248455047607 average time 0.0025762809500338335 iter num 100\n",
            "loss 0.0007982095121406019 average time 0.002599188266700973 iter num 120\n",
            "loss 15.081298828125 average time 0.002594400300027441 iter num 140\n",
            "loss 1.0171537399291992 average time 0.002559560637530467 iter num 160\n",
            "loss 0.3234827518463135 average time 0.0025811886500479077 iter num 180\n",
            "loss 1.8965882062911987 average time 0.0025607487150136874 iter num 200\n",
            "loss 2.2815582752227783 average time 0.002546032754575704 iter num 220\n",
            "loss 6.541093349456787 average time 0.0025685904042272037 iter num 240\n",
            "loss 1.67778480052948 average time 0.002552705684677046 iter num 260\n",
            "loss 0.0022437998559325933 average time 0.002538093560782987 iter num 280\n",
            "loss 2.316725969314575 average time 0.0025452173434011155 iter num 300\n",
            "loss 0.02467522956430912 average time 0.002532331518830233 iter num 320\n",
            "loss 1.0328196287155151 average time 0.0025259672471239516 iter num 340\n",
            "loss 193.14599609375 average time 0.00251397952783413 iter num 360\n",
            "loss 0.8184705376625061 average time 0.0025024691000477394 iter num 380\n",
            "loss 0.028783494606614113 average time 0.002510249455049234 iter num 400\n",
            "loss 0.7978401780128479 average time 0.002499045309564064 iter num 420\n",
            "loss 1.8857396841049194 average time 0.002496258868210465 iter num 440\n",
            "loss 0.0010800173040479422 average time 0.002486628034820688 iter num 460\n",
            "loss 0.23893320560455322 average time 0.0024797802250418497 iter num 480\n",
            "loss 0.00929386354982853 average time 0.0024949792000370508 iter num 500\n",
            "loss 5.521928310394287 average time 0.00249099363849242 iter num 520\n",
            "loss 0.10039796680212021 average time 0.0024876468555871892 iter num 540\n",
            "loss 20.386184692382812 average time 0.002495260332174049 iter num 560\n",
            "loss 0.9236639142036438 average time 0.0024933668586495984 iter num 580\n",
            "loss 2.6159863471984863 average time 0.0025017135633606815 iter num 600\n",
            "loss 16.50836944580078 average time 0.0025203379742115136 iter num 620\n",
            "loss 0.01817205734550953 average time 0.0025192885515821217 iter num 640\n",
            "loss 5.082741737365723 average time 0.0025240807939608755 iter num 660\n",
            "loss 9.037919998168945 average time 0.002531095130905883 iter num 680\n",
            "loss 0.00783512368798256 average time 0.0025248638100206985 iter num 700\n",
            "loss 0.012659902684390545 average time 0.002527173576411062 iter num 720\n",
            "loss 0.01582111418247223 average time 0.002524566474341948 iter num 740\n",
            "loss 1.5234750509262085 average time 0.002519546682912589 iter num 760\n",
            "loss 0.03976261988282204 average time 0.0025162555179658506 iter num 780\n",
            "loss 7.647732257843018 average time 0.002513745727510468 iter num 800\n",
            "loss 4.9569010734558105 average time 0.002515487058540535 iter num 820\n",
            "loss 0.29418882727622986 average time 0.002510198797621602 iter num 840\n",
            "loss 0.04372403025627136 average time 0.0025058936546587954 iter num 860\n",
            "loss 0.8853362798690796 average time 0.0025029919727268695 iter num 880\n",
            "loss 0.49881628155708313 average time 0.0025027860300017185 iter num 900\n",
            "loss 0.2191833108663559 average time 0.002504931180435407 iter num 920\n",
            "loss 18.70599365234375 average time 0.0024995047563858494 iter num 940\n",
            "loss 0.06977655738592148 average time 0.00249654461041852 iter num 960\n",
            "loss 0.8881716728210449 average time 0.002498515037759531 iter num 980\n",
            "loss 0.012523037381470203 average time 0.002495192220007084 iter num 1000\n",
            "loss 2.257499933242798 average time 0.0033702056500260367 iter num 20\n",
            "loss 1.362780213356018 average time 0.0029231507749045704 iter num 40\n",
            "loss 14.159541130065918 average time 0.0027865474000160853 iter num 60\n",
            "loss 3.6177797317504883 average time 0.0026716893500406515 iter num 80\n",
            "loss 0.2612171769142151 average time 0.0025989164000202437 iter num 100\n",
            "loss 0.6551200151443481 average time 0.002532319091687896 iter num 120\n",
            "loss 1.9458028078079224 average time 0.002539251064315197 iter num 140\n",
            "loss 4.308525562286377 average time 0.0025087627624998275 iter num 160\n",
            "loss 3.6101508140563965 average time 0.002483396516638297 iter num 180\n",
            "loss 8.877625465393066 average time 0.0024581530499744987 iter num 200\n",
            "loss 1.0887070894241333 average time 0.0024558675227126514 iter num 220\n",
            "loss 8.377251625061035 average time 0.0024413589791644577 iter num 240\n",
            "loss 0.06236893683671951 average time 0.0024251786653761744 iter num 260\n",
            "loss 0.6118306517601013 average time 0.00241497505713986 iter num 280\n",
            "loss 0.004765688441693783 average time 0.0024103590433393646 iter num 300\n",
            "loss 6.7358527183532715 average time 0.0024017997812563864 iter num 320\n",
            "loss 162.20297241210938 average time 0.0023923052676657203 iter num 340\n",
            "loss 54.81705856323242 average time 0.0023879946611133265 iter num 360\n",
            "loss 6.465137958526611 average time 0.002389809013172788 iter num 380\n",
            "loss 15.425898551940918 average time 0.002419125537517175 iter num 400\n",
            "loss 1.2097309827804565 average time 0.0024095528404835757 iter num 420\n",
            "loss 12.577893257141113 average time 0.0024049998999957595 iter num 440\n",
            "loss 5.650196552276611 average time 0.0024040878521744795 iter num 460\n",
            "loss 0.34686410427093506 average time 0.0023988701687547593 iter num 480\n",
            "loss 0.4130018651485443 average time 0.0024021362800158387 iter num 500\n",
            "loss 22.61486053466797 average time 0.002398146325010832 iter num 520\n",
            "loss 24.093454360961914 average time 0.002394893881501048 iter num 540\n",
            "loss 38.452545166015625 average time 0.0023899472732344814 iter num 560\n",
            "loss 138.10409545898438 average time 0.002387022358630804 iter num 580\n",
            "loss 0.8212752342224121 average time 0.002384731448334302 iter num 600\n",
            "loss 0.008142462931573391 average time 0.0023836574983819915 iter num 620\n",
            "loss 1.2961914539337158 average time 0.0023814280921811816 iter num 640\n",
            "loss 1.4687882661819458 average time 0.002389550799993727 iter num 660\n",
            "loss 77.27766418457031 average time 0.0023863641852853216 iter num 680\n",
            "loss 4.347316741943359 average time 0.002383867467129416 iter num 700\n",
            "loss 7.171765901148319e-05 average time 0.002381825718048781 iter num 720\n",
            "loss 0.030074728652834892 average time 0.002379392177030044 iter num 740\n",
            "loss 14.9840669631958 average time 0.0023780481526285402 iter num 760\n",
            "loss 0.05167241021990776 average time 0.0023963781076930995 iter num 780\n",
            "loss 0.01065437775105238 average time 0.0023938105074967097 iter num 800\n",
            "loss 0.5172501802444458 average time 0.0023921327695062226 iter num 820\n",
            "loss 8.88991621650348e-07 average time 0.002392020994037531 iter num 840\n",
            "loss 4.1172099113464355 average time 0.002401683703479902 iter num 860\n",
            "loss 0.09786795824766159 average time 0.002408776587489311 iter num 880\n",
            "loss 56.042137145996094 average time 0.0024133645510988166 iter num 900\n",
            "loss 0.13845902681350708 average time 0.0024116555499858806 iter num 920\n",
            "loss 9.625748634338379 average time 0.002414697924454463 iter num 940\n",
            "loss 0.0008490463951602578 average time 0.002420514999990549 iter num 960\n",
            "loss 151.92323303222656 average time 0.002424503892843302 iter num 980\n",
            "loss 6.220889568328857 average time 0.002425743937988955 iter num 1000\n",
            "loss 3.5409233570098877 average time 0.0032895780001126695 iter num 20\n",
            "loss 1.154443383216858 average time 0.002987160925022181 iter num 40\n",
            "loss 4.18701171875 average time 0.0028795904167054688 iter num 60\n",
            "loss 10.82691764831543 average time 0.0028690198375443286 iter num 80\n",
            "loss 26.439598083496094 average time 0.0027994526000111363 iter num 100\n",
            "loss 5.046230792999268 average time 0.002854951608333067 iter num 120\n",
            "loss 33.49010467529297 average time 0.002829540985710212 iter num 140\n",
            "loss 4.221051216125488 average time 0.0027950338812161137 iter num 160\n",
            "loss 510.6195983886719 average time 0.00278113303886332 iter num 180\n",
            "loss 25.749235153198242 average time 0.002777046724977481 iter num 200\n",
            "loss 18.347135543823242 average time 0.00277326924091209 iter num 220\n",
            "loss 6.359499454498291 average time 0.00275837128749572 iter num 240\n",
            "loss 1.177603840827942 average time 0.0027539785923111665 iter num 260\n",
            "loss 81.61930084228516 average time 0.002745916900006965 iter num 280\n",
            "loss 3.607947587966919 average time 0.0027434947766899614 iter num 300\n",
            "loss 0.046769607812166214 average time 0.0027398161312760295 iter num 320\n",
            "loss 64.93023681640625 average time 0.0027251448235641445 iter num 340\n",
            "loss 2.1013076305389404 average time 0.002722401200041228 iter num 360\n",
            "loss 3.1427767276763916 average time 0.0027233102474144145 iter num 380\n",
            "loss 3.8940612284932286e-05 average time 0.0027168136925365617 iter num 400\n",
            "loss 160.18722534179688 average time 0.002699611626225565 iter num 420\n",
            "loss 0.1383344978094101 average time 0.002698717720481496 iter num 440\n",
            "loss 0.41298508644104004 average time 0.0026990305652480344 iter num 460\n",
            "loss 8.344061851501465 average time 0.0026923425792006127 iter num 480\n",
            "loss 0.17624469101428986 average time 0.0026925358400367258 iter num 500\n",
            "loss 29.528335571289062 average time 0.002700105425030695 iter num 520\n",
            "loss 0.939984917640686 average time 0.0027020280055862884 iter num 540\n",
            "loss 24.581775665283203 average time 0.0026965618411070734 iter num 560\n",
            "loss 0.00014808174455538392 average time 0.0026967941224499774 iter num 580\n",
            "loss 59.308284759521484 average time 0.0026983538333721904 iter num 600\n",
            "loss 3.790985584259033 average time 0.0026913401451976473 iter num 620\n",
            "loss 0.04345767945051193 average time 0.0026919372687871147 iter num 640\n",
            "loss 5.1869224989786744e-05 average time 0.002682487157612327 iter num 660\n",
            "loss 50.30245590209961 average time 0.0026825334162019904 iter num 680\n",
            "loss 3.3064863681793213 average time 0.0026818344757365206 iter num 700\n",
            "loss 0.0018512021051719785 average time 0.0026747132958512844 iter num 720\n",
            "loss 0.34359997510910034 average time 0.002666672917581997 iter num 740\n",
            "loss 0.05035002902150154 average time 0.002664929065806638 iter num 760\n",
            "loss 0.0015884973108768463 average time 0.0026628039410379408 iter num 780\n",
            "loss 0.002674529328942299 average time 0.0026605606062616973 iter num 800\n",
            "loss 5.869619369506836 average time 0.002658322041468903 iter num 820\n",
            "loss 0.08295724540948868 average time 0.0026605108476295365 iter num 840\n",
            "loss 0.37976762652397156 average time 0.002659608322100275 iter num 860\n",
            "loss 2.683095693588257 average time 0.0026525951852322165 iter num 880\n",
            "loss 1.3016085624694824 average time 0.0026607854388890294 iter num 900\n",
            "loss 24.21561622619629 average time 0.0026540537347856394 iter num 920\n",
            "loss 5.3876566886901855 average time 0.0026541724308620533 iter num 940\n",
            "loss 35.20128631591797 average time 0.0026550885510497817 iter num 960\n",
            "loss 1.6219539642333984 average time 0.0026555241949033502 iter num 980\n",
            "loss 0.03984499350190163 average time 0.0026544636960024945 iter num 1000\n",
            "loss 4.780175685882568 average time 0.003281013549803902 iter num 20\n",
            "loss 4.00485372543335 average time 0.0029522205999001016 iter num 40\n",
            "loss 6.822242736816406 average time 0.002827314183195995 iter num 60\n",
            "loss 0.01963936910033226 average time 0.0027730053498771666 iter num 80\n",
            "loss 1.1614570617675781 average time 0.0027473846898828924 iter num 100\n",
            "loss 0.010357602499425411 average time 0.0026788732915520087 iter num 120\n",
            "loss 131.22335815429688 average time 0.002663590121314233 iter num 140\n",
            "loss 2.355539560317993 average time 0.0026653662436274318 iter num 160\n",
            "loss 9.7188081741333 average time 0.0026677355554460924 iter num 180\n",
            "loss 0.8216404318809509 average time 0.0026379820748934435 iter num 200\n",
            "loss 38.828487396240234 average time 0.00263922193175445 iter num 220\n",
            "loss 1.8059254884719849 average time 0.0026519660541074095 iter num 240\n",
            "loss 125.15469360351562 average time 0.002685340357612194 iter num 260\n",
            "loss 5.22196102142334 average time 0.002704334307080509 iter num 280\n",
            "loss 1.0998804569244385 average time 0.0027014195966209324 iter num 300\n",
            "loss 2.0857651233673096 average time 0.0026946916499525743 iter num 320\n",
            "loss 0.049460358917713165 average time 0.0026887311234906307 iter num 340\n",
            "loss 12.922168731689453 average time 0.0026900749249610576 iter num 360\n",
            "loss 14.587603569030762 average time 0.0026944653920748496 iter num 380\n",
            "loss 0.24313554167747498 average time 0.0026893013849576164 iter num 400\n",
            "loss 1.734487533569336 average time 0.002681012247575425 iter num 420\n",
            "loss 0.10763221979141235 average time 0.0026787967704256684 iter num 440\n",
            "loss 65.51524353027344 average time 0.0026769659456279088 iter num 460\n",
            "loss 0.045381974428892136 average time 0.0026778662645483564 iter num 480\n",
            "loss 2.245493173599243 average time 0.002679697399977158 iter num 500\n",
            "loss 27.642425537109375 average time 0.0026683416192099683 iter num 520\n",
            "loss 0.3039822280406952 average time 0.002664385466650182 iter num 540\n",
            "loss 0.9703764915466309 average time 0.002663469049983697 iter num 560\n",
            "loss 0.21009697020053864 average time 0.0026588043258361097 iter num 580\n",
            "loss 4.449817180633545 average time 0.00264903810164166 iter num 600\n",
            "loss 1.18524968624115 average time 0.002650645890292752 iter num 620\n",
            "loss 0.22310125827789307 average time 0.002655473328090352 iter num 640\n",
            "loss 5.546041011810303 average time 0.002662296340870605 iter num 660\n",
            "loss 3.454294443130493 average time 0.0026603304367279848 iter num 680\n",
            "loss 18.301021575927734 average time 0.0026627975456748184 iter num 700\n",
            "loss 0.09864339977502823 average time 0.002675901781905547 iter num 720\n",
            "loss 3.0453341007232666 average time 0.002670206485099452 iter num 740\n",
            "loss 29.30298614501953 average time 0.002660576240755051 iter num 760\n",
            "loss 0.1509828120470047 average time 0.002650828002531806 iter num 780\n",
            "loss 0.02416732907295227 average time 0.00264089364872234 iter num 800\n",
            "loss 0.02444506622850895 average time 0.0026313635036342197 iter num 820\n",
            "loss 0.2454851269721985 average time 0.0026217604071202263 iter num 840\n",
            "loss 0.023845210671424866 average time 0.002622218060442656 iter num 860\n",
            "loss 58.467323303222656 average time 0.002616575861338788 iter num 880\n",
            "loss 29.819547653198242 average time 0.0026087630855322966 iter num 900\n",
            "loss 0.03002057783305645 average time 0.0026031846651973036 iter num 920\n",
            "loss 0.001027761260047555 average time 0.0026027556829618295 iter num 940\n",
            "loss 33.893802642822266 average time 0.0026035089906050264 iter num 960\n",
            "loss 0.5031998753547668 average time 0.0025968640265109943 iter num 980\n",
            "loss 119.57550811767578 average time 0.0025901015419894976 iter num 1000\n",
            "loss 4.738025665283203 average time 0.0031993009497455205 iter num 20\n",
            "loss 4.837838172912598 average time 0.002742061049912081 iter num 40\n",
            "loss 11.027920722961426 average time 0.0026038684499023173 iter num 60\n",
            "loss 16.713531494140625 average time 0.0025122774999545073 iter num 80\n",
            "loss 16.95143699645996 average time 0.0024613920199408313 iter num 100\n",
            "loss 4.173651218414307 average time 0.002428423724950335 iter num 120\n",
            "loss 1.4508897066116333 average time 0.002412677057106651 iter num 140\n",
            "loss 9.5329008102417 average time 0.002388953474940081 iter num 160\n",
            "loss 8.263157844543457 average time 0.0023974179999135636 iter num 180\n",
            "loss 46.574127197265625 average time 0.002413720939948689 iter num 200\n",
            "loss 20.595401763916016 average time 0.0024020879726859594 iter num 220\n",
            "loss 1.5784361362457275 average time 0.0023908390416105857 iter num 240\n",
            "loss 0.08681023865938187 average time 0.0023856911230303434 iter num 260\n",
            "loss 5.902306079864502 average time 0.0023734111856616178 iter num 280\n",
            "loss 0.08623125404119492 average time 0.0023710204932952668 iter num 300\n",
            "loss 0.0009033815003931522 average time 0.0023675752405949877 iter num 320\n",
            "loss 10.770206451416016 average time 0.002360127561737232 iter num 340\n",
            "loss 2.029829263687134 average time 0.0023595092971946644 iter num 360\n",
            "loss 2.3759167194366455 average time 0.0023563593973449314 iter num 380\n",
            "loss 0.5674777030944824 average time 0.002402249589972598 iter num 400\n",
            "loss 1.2006824016571045 average time 0.0024081810214045705 iter num 420\n",
            "loss 4.75060510635376 average time 0.002404458518164822 iter num 440\n",
            "loss 15.805527687072754 average time 0.002400674680425057 iter num 460\n",
            "loss 1.9531103372573853 average time 0.002417962827083405 iter num 480\n",
            "loss 0.4701000452041626 average time 0.002425038245997712 iter num 500\n",
            "loss 6.5256876945495605 average time 0.002435023832686056 iter num 520\n",
            "loss 0.6492553949356079 average time 0.002447600051851219 iter num 540\n",
            "loss 7.315115928649902 average time 0.0024520140482146807 iter num 560\n",
            "loss 0.03171438351273537 average time 0.002457977765513125 iter num 580\n",
            "loss 0.7743280529975891 average time 0.002459263033330596 iter num 600\n",
            "loss 0.34430721402168274 average time 0.0024658081177368596 iter num 620\n",
            "loss 25.86090087890625 average time 0.00246800333124213 iter num 640\n",
            "loss 1.2518119812011719 average time 0.0024780601287905787 iter num 660\n",
            "loss 5.146963596343994 average time 0.0024762203485298576 iter num 680\n",
            "loss 0.734139084815979 average time 0.0024752216128581493 iter num 700\n",
            "loss 0.07294981926679611 average time 0.002481408865274817 iter num 720\n",
            "loss 3.7293789386749268 average time 0.002488354218914193 iter num 740\n",
            "loss 1.7534087896347046 average time 0.002491876259208718 iter num 760\n",
            "loss 0.9102078676223755 average time 0.002489606453845903 iter num 780\n",
            "loss 7.379410266876221 average time 0.002492539472511908 iter num 800\n",
            "loss 0.29842329025268555 average time 0.0024975151622040758 iter num 820\n",
            "loss 0.04548173397779465 average time 0.0024975830619128137 iter num 840\n",
            "loss 0.9128023386001587 average time 0.002501452368607377 iter num 860\n",
            "loss 2.083991050720215 average time 0.0024998795750000432 iter num 880\n",
            "loss 86.80651092529297 average time 0.002503819557785189 iter num 900\n",
            "loss 0.05482613667845726 average time 0.002505896541307938 iter num 920\n",
            "loss 2.7298617362976074 average time 0.0025057396936237174 iter num 940\n",
            "loss 0.6018105149269104 average time 0.0025160416593773033 iter num 960\n",
            "loss 1.9653325080871582 average time 0.002514046260211569 iter num 980\n",
            "loss 0.3327568769454956 average time 0.002518573808009023 iter num 1000\n",
            "loss 19.4711856842041 average time 0.0032781643999442167 iter num 20\n",
            "loss 12.139912605285645 average time 0.0030305816999771197 iter num 40\n",
            "loss 4.851885795593262 average time 0.002931203083365593 iter num 60\n",
            "loss 4.333678722381592 average time 0.0028807099874939013 iter num 80\n",
            "loss 73.29158782958984 average time 0.002811500830011937 iter num 100\n",
            "loss 8.560798645019531 average time 0.0027823700583212486 iter num 120\n",
            "loss 0.8985108733177185 average time 0.0028018130071619193 iter num 140\n",
            "loss 3.8107047080993652 average time 0.002773915200009469 iter num 160\n",
            "loss 1.0373458862304688 average time 0.0027658378944579454 iter num 180\n",
            "loss 6.7649126052856445 average time 0.002757294785033082 iter num 200\n",
            "loss 50.545166015625 average time 0.0027507835454839966 iter num 220\n",
            "loss 4.745169162750244 average time 0.002722262762533016 iter num 240\n",
            "loss 0.6240411996841431 average time 0.0027202910807878093 iter num 260\n",
            "loss 6.160079479217529 average time 0.002719843203619478 iter num 280\n",
            "loss 431.876220703125 average time 0.0027222369600470604 iter num 300\n",
            "loss 2.3299612998962402 average time 0.0027124368500381023 iter num 320\n",
            "loss 2.013820171356201 average time 0.0027016588912000075 iter num 340\n",
            "loss 0.5340444445610046 average time 0.0026932206639180044 iter num 360\n",
            "loss 2.2934203147888184 average time 0.0026886681526536306 iter num 380\n",
            "loss 1.4076058864593506 average time 0.0026918856450220117 iter num 400\n",
            "loss 3.4301486015319824 average time 0.0026912031976323867 iter num 420\n",
            "loss 0.8897901773452759 average time 0.002689476445477174 iter num 440\n",
            "loss 4.294032096862793 average time 0.0027016518543543657 iter num 460\n",
            "loss 2.4620041847229004 average time 0.0026929466270795882 iter num 480\n",
            "loss 0.3335404396057129 average time 0.0027075227439891025 iter num 500\n",
            "loss 0.22929082810878754 average time 0.0026987651019156214 iter num 520\n",
            "loss 1.3292328119277954 average time 0.002696715879617976 iter num 540\n",
            "loss 0.7183400392532349 average time 0.0026917165339130278 iter num 560\n",
            "loss 0.6675013303756714 average time 0.0026886760620480595 iter num 580\n",
            "loss 5.146894454956055 average time 0.002689302398318129 iter num 600\n",
            "loss 0.24098846316337585 average time 0.0026854791790150733 iter num 620\n",
            "loss 56.50388717651367 average time 0.002675853262479677 iter num 640\n",
            "loss 11.400308609008789 average time 0.0026765757590648275 iter num 660\n",
            "loss 0.8430325984954834 average time 0.0026705831396745504 iter num 680\n",
            "loss 10.968461036682129 average time 0.002663915085678517 iter num 700\n",
            "loss 3.4062256813049316 average time 0.0026583000319204885 iter num 720\n",
            "loss 11.502352714538574 average time 0.002653387251324897 iter num 740\n",
            "loss 0.3572272062301636 average time 0.0026543156328683068 iter num 760\n",
            "loss 3.003688335418701 average time 0.002655392455098757 iter num 780\n",
            "loss 3.759584665298462 average time 0.002656458277472211 iter num 800\n",
            "loss 6.567188262939453 average time 0.0026574661951022658 iter num 820\n",
            "loss 0.0006172090652398765 average time 0.0026534340237850257 iter num 840\n",
            "loss 2.176729202270508 average time 0.002651746997646622 iter num 860\n",
            "loss 1.3908166885375977 average time 0.002648393877246814 iter num 880\n",
            "loss 17.4032039642334 average time 0.0026492285788582296 iter num 900\n",
            "loss 0.04695786535739899 average time 0.0026453453401858416 iter num 920\n",
            "loss 14.899957656860352 average time 0.0026462478201810494 iter num 940\n",
            "loss 1.8048850297927856 average time 0.0026444481010116762 iter num 960\n",
            "loss 1.635966181755066 average time 0.002645891095889223 iter num 980\n",
            "loss 0.0001766348723322153 average time 0.0026477380759715743 iter num 1000\n",
            "loss 43.99987030029297 average time 0.0029665457001101458 iter num 20\n",
            "loss 0.0888858512043953 average time 0.002802777875103857 iter num 40\n",
            "loss 266.55633544921875 average time 0.0027557317333958054 iter num 60\n",
            "loss 6.5446062088012695 average time 0.0027049138124766612 iter num 80\n",
            "loss 12.519186019897461 average time 0.0026801189099933255 iter num 100\n",
            "loss 1.2406398057937622 average time 0.002702380558336396 iter num 120\n",
            "loss 1.6643779277801514 average time 0.0026957243499834607 iter num 140\n",
            "loss 2.5314345359802246 average time 0.002699940562456504 iter num 160\n",
            "loss 36.13727569580078 average time 0.0026630914943780227 iter num 180\n",
            "loss 0.5217418074607849 average time 0.0026610542599610197 iter num 200\n",
            "loss 4.225096225738525 average time 0.002664296936324139 iter num 220\n",
            "loss 0.07415183633565903 average time 0.0026947331708015556 iter num 240\n",
            "loss 14.891301155090332 average time 0.002720802326880053 iter num 260\n",
            "loss 0.02278718538582325 average time 0.002716291160673531 iter num 280\n",
            "loss 218.6283721923828 average time 0.002711585649976769 iter num 300\n",
            "loss 10.03380298614502 average time 0.002686549624985446 iter num 320\n",
            "loss 11.598939895629883 average time 0.0026655936529256423 iter num 340\n",
            "loss 0.00025816471315920353 average time 0.0026418453194259604 iter num 360\n",
            "loss 11.474773406982422 average time 0.0026228577578829 iter num 380\n",
            "loss 0.01859825663268566 average time 0.0026084961549804574 iter num 400\n",
            "loss 0.05999293923377991 average time 0.0025921326475976717 iter num 420\n",
            "loss 15.688179969787598 average time 0.0025811862636187883 iter num 440\n",
            "loss 33.48233413696289 average time 0.0025701525325767644 iter num 460\n",
            "loss 20.970476150512695 average time 0.002560581477045313 iter num 480\n",
            "loss 1.3434057235717773 average time 0.002548154131964111 iter num 500\n",
            "loss 1.8768341760733165e-05 average time 0.0025503215268879733 iter num 520\n",
            "loss 0.029079940170049667 average time 0.002543263381452292 iter num 540\n",
            "loss 0.21020817756652832 average time 0.0025342940589000917 iter num 560\n",
            "loss 0.09401330351829529 average time 0.0025260439465361333 iter num 580\n",
            "loss 1.6850920915603638 average time 0.002517000029981015 iter num 600\n",
            "loss 0.1333274245262146 average time 0.0025276840338524526 iter num 620\n",
            "loss 0.09892907738685608 average time 0.002521784573409036 iter num 640\n",
            "loss 2.834333896636963 average time 0.0025128937711832063 iter num 660\n",
            "loss 6.012264728546143 average time 0.0025088683661552377 iter num 680\n",
            "loss 0.4738345444202423 average time 0.0025008052828369336 iter num 700\n",
            "loss 78.76454162597656 average time 0.002495441255534085 iter num 720\n",
            "loss 22.47090721130371 average time 0.002488428279701947 iter num 740\n",
            "loss 0.12331856787204742 average time 0.002493435809181296 iter num 760\n",
            "loss 0.4632827937602997 average time 0.002487861887148495 iter num 780\n",
            "loss 5.9175333976745605 average time 0.002485831628721371 iter num 800\n",
            "loss 42.69390869140625 average time 0.0024809728377765236 iter num 820\n",
            "loss 132.96726989746094 average time 0.002476880559492028 iter num 840\n",
            "loss 0.06400816887617111 average time 0.0024712783185731136 iter num 860\n",
            "loss 0.19865745306015015 average time 0.002468866703378064 iter num 880\n",
            "loss 1.9618288278579712 average time 0.002464239485523447 iter num 900\n",
            "loss 0.38215938210487366 average time 0.0024621565554041255 iter num 920\n",
            "loss 0.4420638680458069 average time 0.0024590970595493268 iter num 940\n",
            "loss 0.07499562948942184 average time 0.002456091690599275 iter num 960\n",
            "loss 0.664418637752533 average time 0.00245351265099757 iter num 980\n",
            "loss 3.145878791809082 average time 0.0024521415239778434 iter num 1000\n",
            "loss 19.9040470123291 average time 0.0033068281001760623 iter num 20\n",
            "loss 37.48098373413086 average time 0.0027801860499948815 iter num 40\n",
            "loss 8.034775733947754 average time 0.0025864466667068577 iter num 60\n",
            "loss 61.38254928588867 average time 0.0025138331125390324 iter num 80\n",
            "loss 0.004075899720191956 average time 0.002478613699968264 iter num 100\n",
            "loss 2.4744908809661865 average time 0.002455872766631728 iter num 120\n",
            "loss 0.6414040923118591 average time 0.002429870678536515 iter num 140\n",
            "loss 8.344843864440918 average time 0.002424154637481024 iter num 160\n",
            "loss 6.323494911193848 average time 0.002442236488877825 iter num 180\n",
            "loss 2.883193016052246 average time 0.0024258476900104143 iter num 200\n",
            "loss 17.90874481201172 average time 0.0024136453681835104 iter num 220\n",
            "loss 0.9936566948890686 average time 0.0024084563333341674 iter num 240\n",
            "loss 6.155980587005615 average time 0.00240082125000509 iter num 260\n",
            "loss 0.04856180399656296 average time 0.0023941431785520504 iter num 280\n",
            "loss 14.310288429260254 average time 0.0024038300166466797 iter num 300\n",
            "loss 0.00032667076447978616 average time 0.002396026656225558 iter num 320\n",
            "loss 3.8775928020477295 average time 0.002391717649970815 iter num 340\n",
            "loss 37.1708984375 average time 0.00239407804440614 iter num 360\n",
            "loss 96.31450653076172 average time 0.0024111834605001175 iter num 380\n",
            "loss 9.782846450805664 average time 0.002408866402483909 iter num 400\n",
            "loss 1.9707977771759033 average time 0.0024179434142708833 iter num 420\n",
            "loss 1.5424044132232666 average time 0.0024239300318020635 iter num 440\n",
            "loss 0.0800122320652008 average time 0.0024291661804217374 iter num 460\n",
            "loss 1.2622926235198975 average time 0.0024334112416454444 iter num 480\n",
            "loss 0.2840067744255066 average time 0.002428488365974772 iter num 500\n",
            "loss 7.127912521362305 average time 0.0024277749019032714 iter num 520\n",
            "loss 9.930441856384277 average time 0.00242398452961694 iter num 540\n",
            "loss 0.25692906975746155 average time 0.002435711069629828 iter num 560\n",
            "loss 0.09698328375816345 average time 0.0024298965706701235 iter num 580\n",
            "loss 0.3561450242996216 average time 0.0024259513733189426 iter num 600\n",
            "loss 1.2099169492721558 average time 0.0024224146774031396 iter num 620\n",
            "loss 1.0953723192214966 average time 0.0024205327031012304 iter num 640\n",
            "loss 0.08615285158157349 average time 0.0024152283984690396 iter num 660\n",
            "loss 0.43983474373817444 average time 0.002410902727928367 iter num 680\n",
            "loss 12.869345664978027 average time 0.0024074259414140083 iter num 700\n",
            "loss 9.866544723510742 average time 0.0024117361541559352 iter num 720\n",
            "loss 3.5438337326049805 average time 0.002407203609451441 iter num 740\n",
            "loss 0.22912108898162842 average time 0.002403431985517033 iter num 760\n",
            "loss 13.677390098571777 average time 0.002413592753831696 iter num 780\n",
            "loss 0.47829583287239075 average time 0.0024126462262233873 iter num 800\n",
            "loss 264.9921569824219 average time 0.0024088562438741865 iter num 820\n",
            "loss 12.480504989624023 average time 0.002406588707104415 iter num 840\n",
            "loss 37.237979888916016 average time 0.002404040113920336 iter num 860\n",
            "loss 2.7478652000427246 average time 0.0024089893181553634 iter num 880\n",
            "loss 13.854249954223633 average time 0.002406758945528256 iter num 900\n",
            "loss 1.3652472496032715 average time 0.0024047706586731257 iter num 920\n",
            "loss 21.633665084838867 average time 0.0024008916053041523 iter num 940\n",
            "loss 0.05633040517568588 average time 0.002405298101026195 iter num 960\n",
            "loss 0.053503382951021194 average time 0.002403812771413237 iter num 980\n",
            "loss 2.3848273754119873 average time 0.0024099921499837365 iter num 1000\n",
            "loss 0.3199819028377533 average time 0.0028961199499462965 iter num 20\n",
            "loss 0.7439115047454834 average time 0.002595365674915229 iter num 40\n",
            "loss 16.359355926513672 average time 0.002501527233228747 iter num 60\n",
            "loss 7.412836074829102 average time 0.0024549595623966523 iter num 80\n",
            "loss 0.13132308423519135 average time 0.0024121293199277716 iter num 100\n",
            "loss 30.750896453857422 average time 0.00244108414162838 iter num 120\n",
            "loss 36.353248596191406 average time 0.002423410535694919 iter num 140\n",
            "loss 0.37041327357292175 average time 0.002394960143726621 iter num 160\n",
            "loss 0.8805376887321472 average time 0.0024061796166380293 iter num 180\n",
            "loss 220.4127960205078 average time 0.002397656074945189 iter num 200\n",
            "loss 4.871037483215332 average time 0.002387403168144043 iter num 220\n",
            "loss 0.7106627821922302 average time 0.0023780859124675163 iter num 240\n",
            "loss 0.5207445025444031 average time 0.002372382996124473 iter num 260\n",
            "loss 3.0321505069732666 average time 0.002394092114270409 iter num 280\n",
            "loss 0.7976152896881104 average time 0.002384380286645561 iter num 300\n",
            "loss 1.1925286054611206 average time 0.0023782131562427367 iter num 320\n",
            "loss 0.06467849016189575 average time 0.002373502258807789 iter num 340\n",
            "loss 8.025284767150879 average time 0.002397115416660098 iter num 360\n",
            "loss 3.4626760482788086 average time 0.002391458063165804 iter num 380\n",
            "loss 38.7552604675293 average time 0.002386180762500771 iter num 400\n",
            "loss 16.440738677978516 average time 0.0023786051785767387 iter num 420\n",
            "loss 59.62875747680664 average time 0.002377539652277185 iter num 440\n",
            "loss 0.970362663269043 average time 0.0023741550586909516 iter num 460\n",
            "loss 9.566097259521484 average time 0.0023711157875065205 iter num 480\n",
            "loss 16.018117904663086 average time 0.002368643064000935 iter num 500\n",
            "loss 115.2992172241211 average time 0.0023648211557708867 iter num 520\n",
            "loss 0.00602509081363678 average time 0.002363826968508807 iter num 540\n",
            "loss 1.6371861696243286 average time 0.0023625843535650605 iter num 560\n",
            "loss 7.963428497314453 average time 0.002376861955166658 iter num 580\n",
            "loss 0.14912094175815582 average time 0.002375008418333285 iter num 600\n",
            "loss 1.0937998294830322 average time 0.0023740917564487795 iter num 620\n",
            "loss 4.102145195007324 average time 0.0023722871500012842 iter num 640\n",
            "loss 229.9432373046875 average time 0.0023691718015139817 iter num 660\n",
            "loss 0.3931252360343933 average time 0.002368823338239214 iter num 680\n",
            "loss 0.9164243340492249 average time 0.002367096745708425 iter num 700\n",
            "loss 1.7145347595214844 average time 0.002364510629157242 iter num 720\n",
            "loss 0.015096912160515785 average time 0.002361991009444397 iter num 740\n",
            "loss 3.1100003719329834 average time 0.0023605398157685972 iter num 760\n",
            "loss 0.44217485189437866 average time 0.002360463144848323 iter num 780\n",
            "loss 0.5692535638809204 average time 0.002358771431227069 iter num 800\n",
            "loss 0.6637564897537231 average time 0.002356932195100565 iter num 820\n",
            "loss 1.0619193315505981 average time 0.002355666865456182 iter num 840\n",
            "loss 12.517701148986816 average time 0.0023533749790468116 iter num 860\n",
            "loss 0.05432083457708359 average time 0.00235149137725495 iter num 880\n",
            "loss 1.0555919408798218 average time 0.002349854895536636 iter num 900\n",
            "loss 1.123012661933899 average time 0.0023558383032432966 iter num 920\n",
            "loss 0.2852908968925476 average time 0.0023547574595582737 iter num 940\n",
            "loss 0.1567745804786682 average time 0.0023529085749790586 iter num 960\n",
            "loss 0.8177114725112915 average time 0.0023581394530436004 iter num 980\n",
            "loss 1.3230431079864502 average time 0.002357512381986453 iter num 1000\n",
            "loss 6.85464334487915 average time 0.003294992049814027 iter num 20\n",
            "loss 0.10755900293588638 average time 0.0028200303750509194 iter num 40\n",
            "loss 7.336230278015137 average time 0.002636479083381952 iter num 60\n",
            "loss 1.9690299034118652 average time 0.0025431783500380334 iter num 80\n",
            "loss 4.21691370010376 average time 0.0024982055900909473 iter num 100\n",
            "loss 0.22093135118484497 average time 0.00246317851671544 iter num 120\n",
            "loss 15.788787841796875 average time 0.002430646800049934 iter num 140\n",
            "loss 0.8288713097572327 average time 0.002447240606261403 iter num 160\n",
            "loss 5.775728702545166 average time 0.0024419225222421423 iter num 180\n",
            "loss 3.984649181365967 average time 0.002422174580015053 iter num 200\n",
            "loss 0.08450258523225784 average time 0.002413393363663503 iter num 220\n",
            "loss 3.5709731578826904 average time 0.002400744875012606 iter num 240\n",
            "loss 16.764442443847656 average time 0.0024292497153860144 iter num 260\n",
            "loss 22.801076889038086 average time 0.0024198397964287975 iter num 280\n",
            "loss 0.4967324733734131 average time 0.002412063349996364 iter num 300\n",
            "loss 15.6536283493042 average time 0.002426740718738074 iter num 320\n",
            "loss 11.713705062866211 average time 0.0024163616323515753 iter num 340\n",
            "loss 24.5017147064209 average time 0.002418120866660603 iter num 360\n",
            "loss 0.13660277426242828 average time 0.002408454236827215 iter num 380\n",
            "loss 2.113213300704956 average time 0.0024007257774837855 iter num 400\n",
            "loss 0.7493436336517334 average time 0.002396633283314302 iter num 420\n",
            "loss 54.54637145996094 average time 0.002391609390898256 iter num 440\n",
            "loss 0.084202341735363 average time 0.002384915865213375 iter num 460\n",
            "loss 0.3524430990219116 average time 0.002384923118753098 iter num 480\n",
            "loss 0.5439847707748413 average time 0.002380764420002379 iter num 500\n",
            "loss 1.7281079292297363 average time 0.0023921041346161823 iter num 520\n",
            "loss 0.004315306898206472 average time 0.002390229099991201 iter num 540\n",
            "loss 0.023051973432302475 average time 0.002400085855346593 iter num 560\n",
            "loss 0.30742859840393066 average time 0.0024100832068833025 iter num 580\n",
            "loss 0.674992024898529 average time 0.0024111319616531546 iter num 600\n",
            "loss 0.442728728055954 average time 0.002420779348370073 iter num 620\n",
            "loss 0.38868311047554016 average time 0.0024281229890505073 iter num 640\n",
            "loss 0.016476482152938843 average time 0.002429916698471943 iter num 660\n",
            "loss 124.559814453125 average time 0.002429872291165392 iter num 680\n",
            "loss 1.6454699039459229 average time 0.0024303113371310506 iter num 700\n",
            "loss 3.720794200897217 average time 0.0024386315458211055 iter num 720\n",
            "loss 14.394484519958496 average time 0.0024576444756692923 iter num 740\n",
            "loss 0.42145130038261414 average time 0.00246476012761808 iter num 760\n",
            "loss 0.004764726385474205 average time 0.002468475930755887 iter num 780\n",
            "loss 3.7139394283294678 average time 0.0024719729162416115 iter num 800\n",
            "loss 0.3057515025138855 average time 0.0024774370841330936 iter num 820\n",
            "loss 1.2581772804260254 average time 0.002483430591649137 iter num 840\n",
            "loss 5.979888916015625 average time 0.002484736682543921 iter num 860\n",
            "loss 3.6425023078918457 average time 0.0024808360545276547 iter num 880\n",
            "loss 3.7437431812286377 average time 0.002484571449984085 iter num 900\n",
            "loss 24.77498435974121 average time 0.002489402747806193 iter num 920\n",
            "loss 2.869094133377075 average time 0.0024906643393381835 iter num 940\n",
            "loss 0.24008294939994812 average time 0.0025090030135193806 iter num 960\n",
            "loss 2.291572093963623 average time 0.0025104107877361496 iter num 980\n",
            "loss 1.4601309299468994 average time 0.0025110490969818783 iter num 1000\n",
            "loss 186.69602966308594 average time 0.0033155710998471477 iter num 20\n",
            "loss 3.715310573577881 average time 0.003062693949959794 iter num 40\n",
            "loss 1.8462620973587036 average time 0.002920064983239475 iter num 60\n",
            "loss 0.2056274712085724 average time 0.002830018400004519 iter num 80\n",
            "loss 1.9365549087524414 average time 0.002794340020027448 iter num 100\n",
            "loss 3.053107738494873 average time 0.0027698647667117864 iter num 120\n",
            "loss 60.21597671508789 average time 0.0027989240357133636 iter num 140\n",
            "loss 13.102265357971191 average time 0.0027755991500271193 iter num 160\n",
            "loss 50.21440124511719 average time 0.002766283300024952 iter num 180\n",
            "loss 3.6410980224609375 average time 0.0027642234950144484 iter num 200\n",
            "loss 10.266560554504395 average time 0.0027580672636511074 iter num 220\n",
            "loss 0.7608243823051453 average time 0.00275360836251366 iter num 240\n",
            "loss 5.23183536529541 average time 0.002737180761540423 iter num 260\n",
            "loss 2.8162264823913574 average time 0.0027368513071516125 iter num 280\n",
            "loss 2.475403070449829 average time 0.002734121906675379 iter num 300\n",
            "loss 33.9037971496582 average time 0.002755163015621065 iter num 320\n",
            "loss 4.0365824699401855 average time 0.002754390285291961 iter num 340\n",
            "loss 0.021685142070055008 average time 0.002735503302776326 iter num 360\n",
            "loss 5.543130397796631 average time 0.0027348190815820617 iter num 380\n",
            "loss 3.7818219661712646 average time 0.0027316072050052754 iter num 400\n",
            "loss 0.05565282329916954 average time 0.0027265851428637687 iter num 420\n",
            "loss 0.032243743538856506 average time 0.0027256235772545718 iter num 440\n",
            "loss 1.5582114458084106 average time 0.0027200011108541966 iter num 460\n",
            "loss 18.92879295349121 average time 0.002716351841646277 iter num 480\n",
            "loss 1.4715478420257568 average time 0.0027124156399804633 iter num 500\n",
            "loss 0.1565188467502594 average time 0.002713096698055149 iter num 520\n",
            "loss 0.056123603135347366 average time 0.0027360040184922344 iter num 540\n",
            "loss 0.11730541288852692 average time 0.0027331536963986634 iter num 560\n",
            "loss 14.857462882995605 average time 0.002734049594791627 iter num 580\n",
            "loss 7.714295387268066 average time 0.0027342253099686786 iter num 600\n",
            "loss 2.968806505203247 average time 0.002732535053198057 iter num 620\n",
            "loss 2.4268605709075928 average time 0.0027469592655990026 iter num 640\n",
            "loss 1.284422516822815 average time 0.00274692598936092 iter num 660\n",
            "loss 11.486717224121094 average time 0.0027412842926156267 iter num 680\n",
            "loss 3.118051290512085 average time 0.002741529845682505 iter num 700\n",
            "loss 1.2072287797927856 average time 0.002742059084686035 iter num 720\n",
            "loss 0.21782809495925903 average time 0.0027445170310464754 iter num 740\n",
            "loss 0.010821574367582798 average time 0.0027406964525964308 iter num 760\n",
            "loss 0.44245201349258423 average time 0.0027447754691937195 iter num 780\n",
            "loss 2.329284429550171 average time 0.0027433777224655388 iter num 800\n",
            "loss 0.018860919401049614 average time 0.0027426622255827568 iter num 820\n",
            "loss 0.008760296739637852 average time 0.002741917244024773 iter num 840\n",
            "loss 3.1196413040161133 average time 0.0027386284836994003 iter num 860\n",
            "loss 0.16683052480220795 average time 0.0027302565772515663 iter num 880\n",
            "loss 0.8843362331390381 average time 0.002724389743311298 iter num 900\n",
            "loss 23.946130752563477 average time 0.0027246281043240427 iter num 920\n",
            "loss 0.17207381129264832 average time 0.0027309888680587817 iter num 940\n",
            "loss 52.2900505065918 average time 0.002729747464557401 iter num 960\n",
            "loss 6.732526779174805 average time 0.0027224755275228186 iter num 980\n",
            "loss 0.20625007152557373 average time 0.0027208094139714377 iter num 1000\n",
            "loss 1.462196707725525 average time 0.0031969003500307734 iter num 20\n",
            "loss 4.707464218139648 average time 0.0028037126751314645 iter num 40\n",
            "loss 0.382307231426239 average time 0.0027771049833366607 iter num 60\n",
            "loss 15.192877769470215 average time 0.0027696428750004997 iter num 80\n",
            "loss 2.7962758541107178 average time 0.002780387020011403 iter num 100\n",
            "loss 0.18251967430114746 average time 0.0027147527166865378 iter num 120\n",
            "loss 27.474090576171875 average time 0.002703736164273453 iter num 140\n",
            "loss 8.367714881896973 average time 0.0027061410874466675 iter num 160\n",
            "loss 5.018205642700195 average time 0.002703486888862648 iter num 180\n",
            "loss 22.685373306274414 average time 0.002700719794947872 iter num 200\n",
            "loss 1.6461697816848755 average time 0.002688509436318947 iter num 220\n",
            "loss 10.967602729797363 average time 0.0026831970999561844 iter num 240\n",
            "loss 21.676969528198242 average time 0.002685589276902297 iter num 260\n",
            "loss 1.6977877616882324 average time 0.002676523271410198 iter num 280\n",
            "loss 257.8328552246094 average time 0.0026592575599837195 iter num 300\n",
            "loss 1.3483357429504395 average time 0.00267154169373498 iter num 320\n",
            "loss 114.90386962890625 average time 0.002714917299994447 iter num 340\n",
            "loss 4.399953468237072e-06 average time 0.0027100077777706447 iter num 360\n",
            "loss 1.0765455961227417 average time 0.002711896063125383 iter num 380\n",
            "loss 0.03775756061077118 average time 0.002707118109979092 iter num 400\n",
            "loss 0.08442823588848114 average time 0.0026889837547492963 iter num 420\n",
            "loss 7.7931647300720215 average time 0.0026851695386209363 iter num 440\n",
            "loss 8.905993461608887 average time 0.002685919563021383 iter num 460\n",
            "loss 3.3400468826293945 average time 0.0026890527249785615 iter num 480\n",
            "loss 8.18691635131836 average time 0.002695768103985756 iter num 500\n",
            "loss 4.8570075035095215 average time 0.0026815677653653086 iter num 520\n",
            "loss 0.31270068883895874 average time 0.002671079861095307 iter num 540\n",
            "loss 0.00011012890900019556 average time 0.0026759864178367413 iter num 560\n",
            "loss 0.1636287420988083 average time 0.002666251012051989 iter num 580\n",
            "loss 0.26541534066200256 average time 0.002668080511645409 iter num 600\n",
            "loss 259.7411193847656 average time 0.0026574999790154245 iter num 620\n",
            "loss 0.002660872647538781 average time 0.0026548251671641766 iter num 640\n",
            "loss 1.7917686700820923 average time 0.002646155310580842 iter num 660\n",
            "loss 8.205896377563477 average time 0.002639833379388994 iter num 680\n",
            "loss 0.004408920183777809 average time 0.0026309663599775896 iter num 700\n",
            "loss 20.016735076904297 average time 0.0026229726360902025 iter num 720\n",
            "loss 19.627471923828125 average time 0.0026237122783567355 iter num 740\n",
            "loss 3.6458120346069336 average time 0.0026244726341845214 iter num 760\n",
            "loss 0.8831169605255127 average time 0.0026301608384458703 iter num 780\n",
            "loss 33.34421157836914 average time 0.0026232115162292758 iter num 800\n",
            "loss 1.7211670875549316 average time 0.002615538148762514 iter num 820\n",
            "loss 4.057697772979736 average time 0.0026106417690286996 iter num 840\n",
            "loss 35.91435623168945 average time 0.002602849720915401 iter num 860\n",
            "loss 0.1637769192457199 average time 0.00260459455452788 iter num 880\n",
            "loss 1.4590617418289185 average time 0.002603315982198385 iter num 900\n",
            "loss 0.004033149220049381 average time 0.0025965751717154963 iter num 920\n",
            "loss 1.1632750034332275 average time 0.0025972994393378803 iter num 940\n",
            "loss 0.0007278455304913223 average time 0.0025999079083097363 iter num 960\n",
            "loss 0.01228673942387104 average time 0.0025955469581332388 iter num 980\n",
            "loss 3.0894622802734375 average time 0.002593598783972993 iter num 1000\n",
            "loss 86.45494079589844 average time 0.0034084312997947563 iter num 20\n",
            "loss 1.6340248584747314 average time 0.0029760373999579313 iter num 40\n",
            "loss 0.009915093891322613 average time 0.0027549662666691197 iter num 60\n",
            "loss 0.20296701788902283 average time 0.002717515599965736 iter num 80\n",
            "loss 2.3129217624664307 average time 0.002695908089990553 iter num 100\n",
            "loss 7.2990498542785645 average time 0.002678492274950865 iter num 120\n",
            "loss 3.831176996231079 average time 0.0026301295856683282 iter num 140\n",
            "loss 4.999123573303223 average time 0.0025912056562106046 iter num 160\n",
            "loss 0.0007465113303624094 average time 0.0025715877221955453 iter num 180\n",
            "loss 20.372268676757812 average time 0.0025485810599639083 iter num 200\n",
            "loss 9.153495788574219 average time 0.002559013386350919 iter num 220\n",
            "loss 60.30789566040039 average time 0.0025408938208101974 iter num 240\n",
            "loss 3.772554636001587 average time 0.0025607087999630425 iter num 260\n",
            "loss 108.11861419677734 average time 0.0025453305642453676 iter num 280\n",
            "loss 1.4384733438491821 average time 0.0025526614232937086 iter num 300\n",
            "loss 1.1902384757995605 average time 0.0025424808374680196 iter num 320\n",
            "loss 0.014130719006061554 average time 0.0025313644823280117 iter num 340\n",
            "loss 22.802534103393555 average time 0.002517041069424724 iter num 360\n",
            "loss 57.31413650512695 average time 0.0025069436183816594 iter num 380\n",
            "loss 45.19626235961914 average time 0.0024948134774604113 iter num 400\n",
            "loss 3.6797237396240234 average time 0.0024865091094787724 iter num 420\n",
            "loss 9.402660369873047 average time 0.0024805437749488525 iter num 440\n",
            "loss 1.0847939252853394 average time 0.0024760031564730286 iter num 460\n",
            "loss 1.5240288972854614 average time 0.0024855886207850136 iter num 480\n",
            "loss 8.426344871520996 average time 0.0024996766559634126 iter num 500\n",
            "loss 1.744225025177002 average time 0.0024955498480442027 iter num 520\n",
            "loss 3.2413089275360107 average time 0.0024936209333005807 iter num 540\n",
            "loss 0.3888912498950958 average time 0.002506682216042983 iter num 560\n",
            "loss 0.0606277696788311 average time 0.00250767143446363 iter num 580\n",
            "loss 2.9135193824768066 average time 0.0025025202816474725 iter num 600\n",
            "loss 16.639568328857422 average time 0.0025030884596602726 iter num 620\n",
            "loss 0.07881554961204529 average time 0.0024981314640399434 iter num 640\n",
            "loss 0.4118555784225464 average time 0.00249394230148744 iter num 660\n",
            "loss 0.2866617441177368 average time 0.0024902789646843943 iter num 680\n",
            "loss 1.2232316732406616 average time 0.002490149297123675 iter num 700\n",
            "loss 15.746798515319824 average time 0.002488393751365139 iter num 720\n",
            "loss 2.018578290939331 average time 0.002489741387816557 iter num 740\n",
            "loss 0.3795807659626007 average time 0.0024874992341928624 iter num 760\n",
            "loss 0.382114052772522 average time 0.0024836816217686693 iter num 780\n",
            "loss 0.001079766545444727 average time 0.002478507949967934 iter num 800\n",
            "loss 0.6108046174049377 average time 0.0024835759609453728 iter num 820\n",
            "loss 1.5751686096191406 average time 0.002478942071389784 iter num 840\n",
            "loss 0.1467323899269104 average time 0.002474245810436662 iter num 860\n",
            "loss 2.719107151031494 average time 0.002469827555651963 iter num 880\n",
            "loss 3.6963753700256348 average time 0.002483290981084186 iter num 900\n",
            "loss 0.0052846865728497505 average time 0.002478512501062616 iter num 920\n",
            "loss 3.8647420406341553 average time 0.0024804393361495037 iter num 940\n",
            "loss 4.576189994812012 average time 0.0024783699093575253 iter num 960\n",
            "loss 1.1385407447814941 average time 0.00247513633263336 iter num 980\n",
            "loss 0.27022990584373474 average time 0.0024707562739822607 iter num 1000\n",
            "loss 1.5081822872161865 average time 0.0028771954500371065 iter num 20\n",
            "loss 6.273826599121094 average time 0.0025938049748219782 iter num 40\n",
            "loss 4.937380790710449 average time 0.0025594341832099114 iter num 60\n",
            "loss 4.211275577545166 average time 0.0025001307624961553 iter num 80\n",
            "loss 13.373520851135254 average time 0.0024447468900507374 iter num 100\n",
            "loss 8.97538948059082 average time 0.0024142663250586336 iter num 120\n",
            "loss 5.346897602081299 average time 0.0024305479286340415 iter num 140\n",
            "loss 0.2216188907623291 average time 0.0024097687438029425 iter num 160\n",
            "loss 0.4337035119533539 average time 0.0023994224611568723 iter num 180\n",
            "loss 24.056018829345703 average time 0.002430531805021019 iter num 200\n",
            "loss 11.260501861572266 average time 0.002419517222766775 iter num 220\n",
            "loss 30.48801040649414 average time 0.002404037675046311 iter num 240\n",
            "loss 193.6898956298828 average time 0.0023979377654191362 iter num 260\n",
            "loss 6.023061275482178 average time 0.0023911588893497536 iter num 280\n",
            "loss 0.27013716101646423 average time 0.002388880043363315 iter num 300\n",
            "loss 7.3455424308776855 average time 0.0023957404187740393 iter num 320\n",
            "loss 0.002222370821982622 average time 0.0023862408029558806 iter num 340\n",
            "loss 4.810323238372803 average time 0.002383014672230072 iter num 360\n",
            "loss 36.910823822021484 average time 0.0023814204447549663 iter num 380\n",
            "loss 15.211320877075195 average time 0.002379365040014818 iter num 400\n",
            "loss 5.928063869476318 average time 0.0023796970000191887 iter num 420\n",
            "loss 0.7916101217269897 average time 0.002378540897755308 iter num 440\n",
            "loss 45.703765869140625 average time 0.002380105652212913 iter num 460\n",
            "loss 0.06832504272460938 average time 0.0023746942917000522 iter num 480\n",
            "loss 10.663808822631836 average time 0.002371080956039805 iter num 500\n",
            "loss 162.85523986816406 average time 0.002366676001961073 iter num 520\n",
            "loss 0.013494953513145447 average time 0.0023789849130042527 iter num 540\n",
            "loss 0.14066992700099945 average time 0.0023774759643271992 iter num 560\n",
            "loss 0.5133710503578186 average time 0.002373738813840364 iter num 580\n",
            "loss 0.014351261779665947 average time 0.002370947150044837 iter num 600\n",
            "loss 0.1488979160785675 average time 0.00237026544519986 iter num 620\n",
            "loss 0.9690842628479004 average time 0.0023658887891087944 iter num 640\n",
            "loss 1.5300545692443848 average time 0.0023688883303458913 iter num 660\n",
            "loss 44.212677001953125 average time 0.0023665871971014197 iter num 680\n",
            "loss 0.21838772296905518 average time 0.0023777271086094383 iter num 700\n",
            "loss 0.09429067373275757 average time 0.0023758553764208854 iter num 720\n",
            "loss 0.12006933987140656 average time 0.0023761420851646895 iter num 740\n",
            "loss 0.048515159636735916 average time 0.0023721391487158956 iter num 760\n",
            "loss 2.4450435638427734 average time 0.002372452906440277 iter num 780\n",
            "loss 10.362500190734863 average time 0.002369035898773291 iter num 800\n",
            "loss 6.893068313598633 average time 0.0023666631268453074 iter num 820\n",
            "loss 267.4931335449219 average time 0.002364925101205916 iter num 840\n",
            "loss 0.6826860308647156 average time 0.002373463331410718 iter num 860\n",
            "loss 7.36339807510376 average time 0.0023730862591016624 iter num 880\n",
            "loss 0.00908108800649643 average time 0.0023815724488971076 iter num 900\n",
            "loss 0.6991837620735168 average time 0.0023790432250161363 iter num 920\n",
            "loss 20.750598907470703 average time 0.0023774223872506093 iter num 940\n",
            "loss 0.18473847210407257 average time 0.0023753763271031404 iter num 960\n",
            "loss 0.26906514167785645 average time 0.002372862612264726 iter num 980\n",
            "loss 11.957474708557129 average time 0.002372715692017664 iter num 1000\n",
            "loss 0.4663621187210083 average time 0.00296705384962479 iter num 20\n",
            "loss 0.01876719295978546 average time 0.0026393138998628274 iter num 40\n",
            "loss 6.944241523742676 average time 0.0025166865500068523 iter num 60\n",
            "loss 0.0024152060505002737 average time 0.002463342037526672 iter num 80\n",
            "loss 16.562599182128906 average time 0.002441500429995358 iter num 100\n",
            "loss 0.0007702750735916197 average time 0.002418873825020758 iter num 120\n",
            "loss 78.70352935791016 average time 0.00252440349999493 iter num 140\n",
            "loss 42.408145904541016 average time 0.002501112606262268 iter num 160\n",
            "loss 7.970308780670166 average time 0.0024783367111113975 iter num 180\n",
            "loss 94.74290466308594 average time 0.0024584641000001285 iter num 200\n",
            "loss 19.199817657470703 average time 0.0024412509954841385 iter num 220\n",
            "loss 12.485788345336914 average time 0.002427485425020374 iter num 240\n",
            "loss 39.648521423339844 average time 0.00243749484619072 iter num 260\n",
            "loss 1.2002978324890137 average time 0.0024271004178964568 iter num 280\n",
            "loss 29.803321838378906 average time 0.0024194199766983124 iter num 300\n",
            "loss 144.0186767578125 average time 0.0024113700812847584 iter num 320\n",
            "loss 116.7089614868164 average time 0.002428562300049046 iter num 340\n",
            "loss 0.56126469373703 average time 0.002422071102824298 iter num 360\n",
            "loss 0.195490300655365 average time 0.002419463839525729 iter num 380\n",
            "loss 0.7841405868530273 average time 0.0024123437975458726 iter num 400\n",
            "loss 1.6452399492263794 average time 0.0024052352143371534 iter num 420\n",
            "loss 24.32190704345703 average time 0.002399496988685066 iter num 440\n",
            "loss 11.537453651428223 average time 0.0023924253000547216 iter num 460\n",
            "loss 0.2657177150249481 average time 0.0023893256500400637 iter num 480\n",
            "loss 8.125057220458984 average time 0.0023985009920361334 iter num 500\n",
            "loss 167.2808074951172 average time 0.0023944839154235245 iter num 520\n",
            "loss 3.6379787921905518 average time 0.0023897056370683627 iter num 540\n",
            "loss 0.058796901255846024 average time 0.002394563783965558 iter num 560\n",
            "loss 0.7865001559257507 average time 0.0023894025879599213 iter num 580\n",
            "loss 23.11699867248535 average time 0.0023872908183572386 iter num 600\n",
            "loss 44.18244934082031 average time 0.0023859610467943347 iter num 620\n",
            "loss 0.6091421842575073 average time 0.002384186614077066 iter num 640\n",
            "loss 7.689458847045898 average time 0.002386705372737197 iter num 660\n",
            "loss 3.9501380920410156 average time 0.0023945406220691975 iter num 680\n",
            "loss 0.02432870678603649 average time 0.0023918883914380525 iter num 700\n",
            "loss 247.8376007080078 average time 0.002391858501401758 iter num 720\n",
            "loss 0.014654401689767838 average time 0.002392683959474321 iter num 740\n",
            "loss 31.822675704956055 average time 0.002400392575014178 iter num 760\n",
            "loss 6.754498481750488 average time 0.0024045130615493876 iter num 780\n",
            "loss 0.08505461364984512 average time 0.002408876905010402 iter num 800\n",
            "loss 1.8511065244674683 average time 0.002412564550011267 iter num 820\n",
            "loss 3.270376682281494 average time 0.0024121016000100055 iter num 840\n",
            "loss 700.5382080078125 average time 0.00241849346280211 iter num 860\n",
            "loss 4.711375713348389 average time 0.0024249173966009864 iter num 880\n",
            "loss 0.4172961711883545 average time 0.002429561487788305 iter num 900\n",
            "loss 0.004280295222997665 average time 0.002429272520661787 iter num 920\n",
            "loss 3.90866756439209 average time 0.002428314557452742 iter num 940\n",
            "loss 2.747664451599121 average time 0.0024435975375088977 iter num 960\n",
            "loss 77.58836364746094 average time 0.002446794162256547 iter num 980\n",
            "loss 0.07613732665777206 average time 0.0024496681700111366 iter num 1000\n",
            "loss 36.689918518066406 average time 0.002955510850097198 iter num 20\n",
            "loss 0.018116561695933342 average time 0.0027574520000143822 iter num 40\n",
            "loss 212.88536071777344 average time 0.0027392460333127626 iter num 60\n",
            "loss 0.2534066140651703 average time 0.002729053574989848 iter num 80\n",
            "loss 0.49700406193733215 average time 0.002721009189972392 iter num 100\n",
            "loss 37.851707458496094 average time 0.0027068110083291685 iter num 120\n",
            "loss 3.383312702178955 average time 0.002661695528630454 iter num 140\n",
            "loss 1.5444800853729248 average time 0.0026200132625604057 iter num 160\n",
            "loss 13.118660926818848 average time 0.0026114320611870627 iter num 180\n",
            "loss 8.73233413696289 average time 0.0026167547350632956 iter num 200\n",
            "loss 13.017731666564941 average time 0.002605067822762728 iter num 220\n",
            "loss 1.8413722515106201 average time 0.0026054617250338198 iter num 240\n",
            "loss 10.326025009155273 average time 0.0026126862885086245 iter num 260\n",
            "loss 10.694225311279297 average time 0.0026132307929011794 iter num 280\n",
            "loss 3.298832893371582 average time 0.002612924166727074 iter num 300\n",
            "loss 0.9172436594963074 average time 0.0026174770313161845 iter num 320\n",
            "loss 0.09305538237094879 average time 0.002601937370667763 iter num 340\n",
            "loss 2.8368372917175293 average time 0.0026394927306278584 iter num 360\n",
            "loss 0.1729801446199417 average time 0.002634005010598852 iter num 380\n",
            "loss 0.27680346369743347 average time 0.002629240300075253 iter num 400\n",
            "loss 69.16045379638672 average time 0.002634478781025488 iter num 420\n",
            "loss 2.096140146255493 average time 0.002622169579614241 iter num 440\n",
            "loss 0.38311710953712463 average time 0.002624317069627147 iter num 460\n",
            "loss 8.981653213500977 average time 0.002622731200066634 iter num 480\n",
            "loss 4.896951198577881 average time 0.0026304383640563173 iter num 500\n",
            "loss 3.055494546890259 average time 0.0026354281865853687 iter num 520\n",
            "loss 4.248117446899414 average time 0.002625023468556686 iter num 540\n",
            "loss 78.76020812988281 average time 0.0026216582482577774 iter num 560\n",
            "loss 0.8031644821166992 average time 0.002618518800048558 iter num 580\n",
            "loss 0.9000750184059143 average time 0.0026092286500534103 iter num 600\n",
            "loss 20.317312240600586 average time 0.0026129484419881565 iter num 620\n",
            "loss 15.166608810424805 average time 0.0026223958438038155 iter num 640\n",
            "loss 0.02444649301469326 average time 0.002623096547014222 iter num 660\n",
            "loss 4.326915264129639 average time 0.0026199714206460853 iter num 680\n",
            "loss 0.15225428342819214 average time 0.002619424851488605 iter num 700\n",
            "loss 0.45352011919021606 average time 0.0026243968806183046 iter num 720\n",
            "loss 1.231445074081421 average time 0.0026229519622230895 iter num 740\n",
            "loss 12.276850700378418 average time 0.0026325006500620045 iter num 760\n",
            "loss 0.12239348143339157 average time 0.002635672598777698 iter num 780\n",
            "loss 2.4206840991973877 average time 0.0026377499850627826 iter num 800\n",
            "loss 0.01270504854619503 average time 0.002635818932987338 iter num 820\n",
            "loss 0.3830830156803131 average time 0.0026351176393421025 iter num 840\n",
            "loss 0.11976860463619232 average time 0.002629778264013852 iter num 860\n",
            "loss 0.4465288519859314 average time 0.0026309788148265313 iter num 880\n",
            "loss 0.5163767337799072 average time 0.0026322600389479095 iter num 900\n",
            "loss 0.11422163993120193 average time 0.0026296798076659994 iter num 920\n",
            "loss 8.36669921875 average time 0.0026242858702739506 iter num 940\n",
            "loss 11.096636772155762 average time 0.002621045118805417 iter num 960\n",
            "loss 0.7329628467559814 average time 0.00262073954903158 iter num 980\n",
            "loss 31.528200149536133 average time 0.0026197014650551865 iter num 1000\n",
            "loss 0.03272249549627304 average time 0.003358839099837496 iter num 20\n",
            "loss 0.8059455752372742 average time 0.003033983549903496 iter num 40\n",
            "loss 2.219980001449585 average time 0.002943776949905441 iter num 60\n",
            "loss 0.14186999201774597 average time 0.002805029462342645 iter num 80\n",
            "loss 4.041059494018555 average time 0.002770229369907611 iter num 100\n",
            "loss 3.7021422386169434 average time 0.0028099862332510383 iter num 120\n",
            "loss 9.424739837646484 average time 0.00277792538567415 iter num 140\n",
            "loss 0.5763786435127258 average time 0.0028112076062143387 iter num 160\n",
            "loss 32.07857894897461 average time 0.0027973229610728997 iter num 180\n",
            "loss 1.0443813800811768 average time 0.002779246959953525 iter num 200\n",
            "loss 1.5088081359863281 average time 0.0027605403090257656 iter num 220\n",
            "loss 3.0867137908935547 average time 0.0027561226165971676 iter num 240\n",
            "loss 81.1597900390625 average time 0.0027429560191824117 iter num 260\n",
            "loss 2.595984935760498 average time 0.0027369460642538406 iter num 280\n",
            "loss 7.2175822257995605 average time 0.0027268538066285448 iter num 300\n",
            "loss 26.4468936920166 average time 0.0027153699187124404 iter num 320\n",
            "loss 4.283856391906738 average time 0.0026960806205780126 iter num 340\n",
            "loss 8.590871810913086 average time 0.0026874444833184597 iter num 360\n",
            "loss 2.7318031787872314 average time 0.0026922472131397962 iter num 380\n",
            "loss 2.344235897064209 average time 0.002688671594992229 iter num 400\n",
            "loss 0.8795357942581177 average time 0.002683890742849014 iter num 420\n",
            "loss 24.825895309448242 average time 0.0026806627909081726 iter num 440\n",
            "loss 51.29755783081055 average time 0.0026797245630326 iter num 460\n",
            "loss 67.34784698486328 average time 0.002679054585413117 iter num 480\n",
            "loss 0.6245324611663818 average time 0.0026812685940058147 iter num 500\n",
            "loss 0.353456974029541 average time 0.0026787585884693937 iter num 520\n",
            "loss 3.993990182876587 average time 0.002674755518526379 iter num 540\n",
            "loss 0.4232635498046875 average time 0.002664559123211672 iter num 560\n",
            "loss 0.947307288646698 average time 0.00265045455345334 iter num 580\n",
            "loss 0.27702227234840393 average time 0.0026502677266792792 iter num 600\n",
            "loss 59.17463302612305 average time 0.0026376922016366263 iter num 620\n",
            "loss 0.7826887369155884 average time 0.002628314040640589 iter num 640\n",
            "loss 2.487854480743408 average time 0.002616721086374265 iter num 660\n",
            "loss 0.049543533474206924 average time 0.002618729645604724 iter num 680\n",
            "loss 0.36405032873153687 average time 0.002608672768593741 iter num 700\n",
            "loss 20.152202606201172 average time 0.0026033157666814884 iter num 720\n",
            "loss 1.7501219511032104 average time 0.002596214748661402 iter num 740\n",
            "loss 2.5920896530151367 average time 0.0025874235026429617 iter num 760\n",
            "loss 0.780004620552063 average time 0.0025901939871964246 iter num 780\n",
            "loss 0.35248470306396484 average time 0.0025817964637644764 iter num 800\n",
            "loss 0.011900678277015686 average time 0.00257746107196753 iter num 820\n",
            "loss 0.0243550892919302 average time 0.002570943788105935 iter num 840\n",
            "loss 0.18734003603458405 average time 0.0025641231186095547 iter num 860\n",
            "loss 0.02436036430299282 average time 0.0025627670227260585 iter num 880\n",
            "loss 0.2166873663663864 average time 0.0025576146455589172 iter num 900\n",
            "loss 1.4858530759811401 average time 0.0025520877597856547 iter num 920\n",
            "loss 7.0534348487854 average time 0.0025475118372343514 iter num 940\n",
            "loss 9.133794784545898 average time 0.0025421775000021777 iter num 960\n",
            "loss 0.03379909694194794 average time 0.002543745179588898 iter num 980\n",
            "loss 10.052492141723633 average time 0.002542535112992482 iter num 1000\n",
            "loss 8.84022331237793 average time 0.0028741648499817527 iter num 20\n",
            "loss 0.970511794090271 average time 0.0025959775251067187 iter num 40\n",
            "loss 11.6782865524292 average time 0.0026110585500646265 iter num 60\n",
            "loss 20.33253288269043 average time 0.0025682404000235692 iter num 80\n",
            "loss 26.919418334960938 average time 0.002503064540032938 iter num 100\n",
            "loss 47.44528579711914 average time 0.0024701570250272196 iter num 120\n",
            "loss 0.4973396062850952 average time 0.0024652033071626126 iter num 140\n",
            "loss 0.011711512692272663 average time 0.002436766687515046 iter num 160\n",
            "loss 0.39446818828582764 average time 0.002419772455515259 iter num 180\n",
            "loss 2.7032973766326904 average time 0.0024138124349701684 iter num 200\n",
            "loss 5.626826286315918 average time 0.0024293644181604826 iter num 220\n",
            "loss 9.854805946350098 average time 0.002429673074978685 iter num 240\n",
            "loss 3.908247232437134 average time 0.0024215356461424493 iter num 260\n",
            "loss 0.000802244758233428 average time 0.002409007214263121 iter num 280\n",
            "loss 0.1284877210855484 average time 0.0024185026299771077 iter num 300\n",
            "loss 9.98492431640625 average time 0.0024170292655981028 iter num 320\n",
            "loss 0.5769076347351074 average time 0.002412864802933173 iter num 340\n",
            "loss 0.13609789311885834 average time 0.0024071597722316557 iter num 360\n",
            "loss 12.05150032043457 average time 0.002408824197372221 iter num 380\n",
            "loss 0.11862608790397644 average time 0.0024128205224997145 iter num 400\n",
            "loss 6.473443508148193 average time 0.0024085108119011453 iter num 420\n",
            "loss 6.321634292602539 average time 0.00240366971362908 iter num 440\n",
            "loss 3.3325912952423096 average time 0.002411913669564693 iter num 460\n",
            "loss 2.1307284832000732 average time 0.002407163327075068 iter num 480\n",
            "loss 14.06341552734375 average time 0.0024030549919953044 iter num 500\n",
            "loss 0.028380341827869415 average time 0.0023970724634532065 iter num 520\n",
            "loss 0.12494632601737976 average time 0.002403675716656532 iter num 540\n",
            "loss 4.333869457244873 average time 0.002398843580353319 iter num 560\n",
            "loss 0.5732036232948303 average time 0.002395585131025341 iter num 580\n",
            "loss 0.02365255542099476 average time 0.0023924204749861625 iter num 600\n",
            "loss 31.94605827331543 average time 0.0023978958370794463 iter num 620\n",
            "loss 36.23337936401367 average time 0.002392616357792576 iter num 640\n",
            "loss 0.08952152729034424 average time 0.0023896243954340843 iter num 660\n",
            "loss 0.9480838775634766 average time 0.0023975781235147974 iter num 680\n",
            "loss 0.03717295080423355 average time 0.0024104850928363575 iter num 700\n",
            "loss 16.957422256469727 average time 0.0024059512735877635 iter num 720\n",
            "loss 0.25284937024116516 average time 0.0024021168702421237 iter num 740\n",
            "loss 7.090482711791992 average time 0.002398259949979164 iter num 760\n",
            "loss 0.052207186818122864 average time 0.002404734249982236 iter num 780\n",
            "loss 0.047096867114305496 average time 0.0024000283112309262 iter num 800\n",
            "loss 2.1881296634674072 average time 0.0023987758390032424 iter num 820\n",
            "loss 16.086971282958984 average time 0.0023980151892655636 iter num 840\n",
            "loss 0.0007139505469240248 average time 0.0024121535871863883 iter num 860\n",
            "loss 1.1990861892700195 average time 0.0024100674113469722 iter num 880\n",
            "loss 54.154335021972656 average time 0.002408072883315779 iter num 900\n",
            "loss 0.05479973182082176 average time 0.0024069936206338434 iter num 920\n",
            "loss 103.59202575683594 average time 0.002408841276573707 iter num 940\n",
            "loss 2.9653804302215576 average time 0.0024055078468488015 iter num 960\n",
            "loss 722.948974609375 average time 0.0024042707163043444 iter num 980\n",
            "loss 0.03705959767103195 average time 0.0024098662389787934 iter num 1000\n",
            "loss 0.00020277878502383828 average time 0.002920951200121635 iter num 20\n",
            "loss 0.0009440550929866731 average time 0.002601662825236417 iter num 40\n",
            "loss 0.16745612025260925 average time 0.0024907049501659154 iter num 60\n",
            "loss 44.418575286865234 average time 0.002439386887635919 iter num 80\n",
            "loss 2.0113277435302734 average time 0.0024642756700814063 iter num 100\n",
            "loss 1.2502226829528809 average time 0.002435807850057851 iter num 120\n",
            "loss 0.12953726947307587 average time 0.002417194135770322 iter num 140\n",
            "loss 2.8969976902008057 average time 0.0023956571063081357 iter num 160\n",
            "loss 2.8908684253692627 average time 0.002411667761195228 iter num 180\n",
            "loss 0.2301725596189499 average time 0.0024005823000516104 iter num 200\n",
            "loss 11.46940803527832 average time 0.0023923595954990808 iter num 220\n",
            "loss 14.876510620117188 average time 0.0023944303458999154 iter num 240\n",
            "loss 9.329038619995117 average time 0.002411041003947153 iter num 260\n",
            "loss 1.1203320026397705 average time 0.0023978084286552207 iter num 280\n",
            "loss 88.90922546386719 average time 0.0024205389500699917 iter num 300\n",
            "loss 2.7458791732788086 average time 0.002429884850062081 iter num 320\n",
            "loss 2.295980215072632 average time 0.0024214229794779383 iter num 340\n",
            "loss 0.5320586562156677 average time 0.002413495550071174 iter num 360\n",
            "loss 1.1240800619125366 average time 0.0024181688421729057 iter num 380\n",
            "loss 0.0420369915664196 average time 0.002409531932567006 iter num 400\n",
            "loss 2.5932459831237793 average time 0.0024019491786280663 iter num 420\n",
            "loss 22.7441349029541 average time 0.002397173640979004 iter num 440\n",
            "loss 0.740333616733551 average time 0.002414103926153273 iter num 460\n",
            "loss 7.275632858276367 average time 0.002410182793820089 iter num 480\n",
            "loss 17.45337677001953 average time 0.002415537358065194 iter num 500\n",
            "loss 0.45053476095199585 average time 0.002409709042373064 iter num 520\n",
            "loss 10.105664253234863 average time 0.0024027195278399126 iter num 540\n",
            "loss 22.166271209716797 average time 0.002416530025071292 iter num 560\n",
            "loss 7.5661091804504395 average time 0.0024120333724756073 iter num 580\n",
            "loss 4.894791603088379 average time 0.0024094835933919966 iter num 600\n",
            "loss 25.01060676574707 average time 0.002405043943608396 iter num 620\n",
            "loss 0.10505101829767227 average time 0.002404395815685234 iter num 640\n",
            "loss 8.43498420715332 average time 0.002425804240969724 iter num 660\n",
            "loss 1.9218782186508179 average time 0.002423354241238271 iter num 680\n",
            "loss 2.4291326999664307 average time 0.0024203023286203723 iter num 700\n",
            "loss 0.19813507795333862 average time 0.0024181753680977635 iter num 720\n",
            "loss 0.32747069001197815 average time 0.0024218042297704683 iter num 740\n",
            "loss 37.48366928100586 average time 0.002427727436880607 iter num 760\n",
            "loss 0.0006338784005492926 average time 0.002426765832094064 iter num 780\n",
            "loss 4.115631103515625 average time 0.0024265773525462466 iter num 800\n",
            "loss 19.103134155273438 average time 0.0024286595512665638 iter num 820\n",
            "loss 0.403768390417099 average time 0.0024258393786220993 iter num 840\n",
            "loss 70.82649230957031 average time 0.0024251249826087334 iter num 860\n",
            "loss 0.7328583598136902 average time 0.0024233383216410815 iter num 880\n",
            "loss 0.03205769509077072 average time 0.0024298724378240878 iter num 900\n",
            "loss 1.559583067893982 average time 0.0024272432674380348 iter num 920\n",
            "loss 1.1747740507125854 average time 0.002425761250046019 iter num 940\n",
            "loss 0.22232139110565186 average time 0.0024231824656775797 iter num 960\n",
            "loss 0.060621701180934906 average time 0.002419974786795249 iter num 980\n",
            "loss 1.785055160522461 average time 0.0024174796200532 iter num 1000\n",
            "loss 0.45726439356803894 average time 0.003365927950017067 iter num 20\n",
            "loss 1.324660062789917 average time 0.0029830927750026603 iter num 40\n",
            "loss 6.201305389404297 average time 0.0028655762833598906 iter num 60\n",
            "loss 2.457442283630371 average time 0.002722693837586121 iter num 80\n",
            "loss 0.18214502930641174 average time 0.0026376539301054434 iter num 100\n",
            "loss 7.951752662658691 average time 0.002578298133418381 iter num 120\n",
            "loss 8.585036277770996 average time 0.0025402195857688117 iter num 140\n",
            "loss 7.714273929595947 average time 0.0025062092000553093 iter num 160\n",
            "loss 0.3349522650241852 average time 0.002477610800017121 iter num 180\n",
            "loss 0.5454084873199463 average time 0.0024748932200054697 iter num 200\n",
            "loss 0.5214072465896606 average time 0.0024582778318207685 iter num 220\n",
            "loss 0.4513375163078308 average time 0.002444992558321246 iter num 240\n",
            "loss 6.240085601806641 average time 0.00242979074613546 iter num 260\n",
            "loss 3.2233059406280518 average time 0.0024536089428563303 iter num 280\n",
            "loss 7.9009108543396 average time 0.002441512086673659 iter num 300\n",
            "loss 0.9796962141990662 average time 0.0024469306500179756 iter num 320\n",
            "loss 6.714247703552246 average time 0.0024340639676612387 iter num 340\n",
            "loss 0.30694231390953064 average time 0.002425474622229255 iter num 360\n",
            "loss 0.22473791241645813 average time 0.0024197100684336635 iter num 380\n",
            "loss 4.914154529571533 average time 0.002411191520009197 iter num 400\n",
            "loss 11.847898483276367 average time 0.0024057195928651794 iter num 420\n",
            "loss 4.151928424835205 average time 0.0024121307363781275 iter num 440\n",
            "loss 3.7599692344665527 average time 0.0024260596043661833 iter num 460\n",
            "loss 4.691792964935303 average time 0.002429065647936568 iter num 480\n",
            "loss 0.23945532739162445 average time 0.0024239744980259275 iter num 500\n",
            "loss 0.41210702061653137 average time 0.002437939251950201 iter num 520\n",
            "loss 93.37935638427734 average time 0.0024322417796611264 iter num 540\n",
            "loss 0.47519832849502563 average time 0.00242768891430712 iter num 560\n",
            "loss 0.001362422714009881 average time 0.002421682743123052 iter num 580\n",
            "loss 0.6645147204399109 average time 0.0024170313166966178 iter num 600\n",
            "loss 32.74617385864258 average time 0.002416279882283796 iter num 620\n",
            "loss 19.007476806640625 average time 0.0024173737765835314 iter num 640\n",
            "loss 1.5850300788879395 average time 0.0024140576348724027 iter num 660\n",
            "loss 26.35866928100586 average time 0.0024110365647282057 iter num 680\n",
            "loss 56.246337890625 average time 0.0024090635157387754 iter num 700\n",
            "loss 0.3466598391532898 average time 0.002406311058355944 iter num 720\n",
            "loss 2.8017771244049072 average time 0.002415853471641615 iter num 740\n",
            "loss 1.541987419128418 average time 0.0024137047052758326 iter num 760\n",
            "loss 1.1402183771133423 average time 0.0024133842628310583 iter num 780\n",
            "loss 0.020376183092594147 average time 0.0024201931450124905 iter num 800\n",
            "loss 88.95052337646484 average time 0.0024242284878177663 iter num 820\n",
            "loss 0.15315765142440796 average time 0.002422951341677184 iter num 840\n",
            "loss 0.5517684817314148 average time 0.002436752440709909 iter num 860\n",
            "loss 0.0003387494361959398 average time 0.0024428084227400343 iter num 880\n",
            "loss 21.67334747314453 average time 0.0024416853455679504 iter num 900\n",
            "loss 0.023925980553030968 average time 0.002445496806532664 iter num 920\n",
            "loss 0.8150454163551331 average time 0.002449957029802271 iter num 940\n",
            "loss 2.4246623516082764 average time 0.002456762934394874 iter num 960\n",
            "loss 3.109297275543213 average time 0.0024556956949208122 iter num 980\n",
            "loss 55.75100326538086 average time 0.0024569557630184135 iter num 1000\n",
            "loss 26.3537540435791 average time 0.003103563500189921 iter num 20\n",
            "loss 0.04541890695691109 average time 0.002854015650154906 iter num 40\n",
            "loss 8.056438446044922 average time 0.0028119722333940444 iter num 60\n",
            "loss 3.148897171020508 average time 0.0027554077000104373 iter num 80\n",
            "loss 0.9214261174201965 average time 0.0027241811900239553 iter num 100\n",
            "loss 6.276693344116211 average time 0.0027247265916533554 iter num 120\n",
            "loss 18.074207305908203 average time 0.002722000285692567 iter num 140\n",
            "loss 1.2032418251037598 average time 0.0026968846625095464 iter num 160\n",
            "loss 0.7401522994041443 average time 0.002689687172227827 iter num 180\n",
            "loss 0.046356089413166046 average time 0.002685008634998667 iter num 200\n",
            "loss 24.09967041015625 average time 0.002652522249974771 iter num 220\n",
            "loss 4.337427616119385 average time 0.0026618123124611277 iter num 240\n",
            "loss 9.94150447845459 average time 0.002673368057646887 iter num 260\n",
            "loss 0.09774687141180038 average time 0.0026747467070825743 iter num 280\n",
            "loss 14.070168495178223 average time 0.0026683555299253686 iter num 300\n",
            "loss 0.9667423963546753 average time 0.002661040784306579 iter num 320\n",
            "loss 0.2363588511943817 average time 0.002659579341113439 iter num 340\n",
            "loss 9.35875129699707 average time 0.0026593808832735197 iter num 360\n",
            "loss 3.790677309036255 average time 0.002663802060478223 iter num 380\n",
            "loss 2.2480263710021973 average time 0.002653430959971956 iter num 400\n",
            "loss 0.4447208344936371 average time 0.002654180452351457 iter num 420\n",
            "loss 0.010587925091385841 average time 0.00264878837725436 iter num 440\n",
            "loss 14.367230415344238 average time 0.0026473304064932998 iter num 460\n",
            "loss 0.09769237041473389 average time 0.002651249852059815 iter num 480\n",
            "loss 5.986308574676514 average time 0.0026468301059758234 iter num 500\n",
            "loss 0.028448743745684624 average time 0.002646613498049751 iter num 520\n",
            "loss 29.171388626098633 average time 0.0026498113555337315 iter num 540\n",
            "loss 15.032599449157715 average time 0.002646316539270239 iter num 560\n",
            "loss 0.010377023369073868 average time 0.0026465898361995393 iter num 580\n",
            "loss 0.04524873569607735 average time 0.0026448608149924743 iter num 600\n",
            "loss 35.64729309082031 average time 0.002644773629030932 iter num 620\n",
            "loss 0.035886455327272415 average time 0.0026449404046900325 iter num 640\n",
            "loss 3.590954542160034 average time 0.0026535767878792258 iter num 660\n",
            "loss 0.2916654944419861 average time 0.002651917264703276 iter num 680\n",
            "loss 0.10693735629320145 average time 0.0026499879571331673 iter num 700\n",
            "loss 2.043095588684082 average time 0.0026471374263792313 iter num 720\n",
            "loss 0.15841519832611084 average time 0.0026397750972874576 iter num 740\n",
            "loss 1.6071780920028687 average time 0.002641639318411954 iter num 760\n",
            "loss 0.24251146614551544 average time 0.0026359568487047606 iter num 780\n",
            "loss 3.1175124645233154 average time 0.0026397907687351107 iter num 800\n",
            "loss 5.701635360717773 average time 0.002641212152422845 iter num 820\n",
            "loss 0.15665584802627563 average time 0.0026424535523693476 iter num 840\n",
            "loss 0.012277016416192055 average time 0.0026420811837090507 iter num 860\n",
            "loss 11.442852973937988 average time 0.0026413488852168403 iter num 880\n",
            "loss 4.23814582824707 average time 0.002641090943327274 iter num 900\n",
            "loss 0.7055169343948364 average time 0.002641365909780886 iter num 920\n",
            "loss 9.875114440917969 average time 0.0026403904691467183 iter num 940\n",
            "loss 0.01861671358346939 average time 0.002642407230200661 iter num 960\n",
            "loss 96.88724517822266 average time 0.002639365734686013 iter num 980\n",
            "loss 0.0011635847622528672 average time 0.002634540384988213 iter num 1000\n",
            "loss 0.4006979167461395 average time 0.003257558550012618 iter num 20\n",
            "loss 0.4036846160888672 average time 0.00282281740005601 iter num 40\n",
            "loss 11.947372436523438 average time 0.0027793467500184005 iter num 60\n",
            "loss 80.4687271118164 average time 0.002707364487559971 iter num 80\n",
            "loss 30.981395721435547 average time 0.002682366280059796 iter num 100\n",
            "loss 4.737605094909668 average time 0.0026826918417555135 iter num 120\n",
            "loss 3.9631588459014893 average time 0.002682449614400996 iter num 140\n",
            "loss 729.4210815429688 average time 0.0026490186376008753 iter num 160\n",
            "loss 105.4510498046875 average time 0.002621021894537989 iter num 180\n",
            "loss 2.3412930965423584 average time 0.0026211262150991387 iter num 200\n",
            "loss 17.77992820739746 average time 0.0026266341364548267 iter num 220\n",
            "loss 234.93972778320312 average time 0.002634739916751035 iter num 240\n",
            "loss 0.07347403466701508 average time 0.0026328699077706776 iter num 260\n",
            "loss 30.393468856811523 average time 0.0026357005822189553 iter num 280\n",
            "loss 2.207334280014038 average time 0.00263780709340305 iter num 300\n",
            "loss 1.3930670022964478 average time 0.00263882229693877 iter num 320\n",
            "loss 551.4743041992188 average time 0.002634067911816708 iter num 340\n",
            "loss 0.02563047781586647 average time 0.002640744344494629 iter num 360\n",
            "loss 0.17236222326755524 average time 0.0026455366342576637 iter num 380\n",
            "loss 0.0504046268761158 average time 0.00263963151752705 iter num 400\n",
            "loss 0.45315003395080566 average time 0.002640597385734942 iter num 420\n",
            "loss 0.07610917091369629 average time 0.002636430822746082 iter num 440\n",
            "loss 1.7734333276748657 average time 0.0026386570174073984 iter num 460\n",
            "loss 0.02322489395737648 average time 0.0026340336937588898 iter num 480\n",
            "loss 0.0271674245595932 average time 0.0026548633400161636 iter num 500\n",
            "loss 173.72508239746094 average time 0.0026532275365508 iter num 520\n",
            "loss 0.34493395686149597 average time 0.002653804907408307 iter num 540\n",
            "loss 2.16426944732666 average time 0.0026567530571323266 iter num 560\n",
            "loss 0.11999893933534622 average time 0.002657192432744868 iter num 580\n",
            "loss 2.4086241722106934 average time 0.0026610722849939824 iter num 600\n",
            "loss 12.445060729980469 average time 0.002660333127418961 iter num 620\n",
            "loss 0.7188752293586731 average time 0.0026577831828205945 iter num 640\n",
            "loss 1.388586163520813 average time 0.002658057577280653 iter num 660\n",
            "loss 1.701965570449829 average time 0.002659631932361021 iter num 680\n",
            "loss 1.0644524097442627 average time 0.0026506272514364225 iter num 700\n",
            "loss 0.20330572128295898 average time 0.0026424843444576456 iter num 720\n",
            "loss 0.33348792791366577 average time 0.0026420686811016404 iter num 740\n",
            "loss 36.1670036315918 average time 0.002631238872388502 iter num 760\n",
            "loss 0.02423337660729885 average time 0.0026236083487394635 iter num 780\n",
            "loss 2.5306484699249268 average time 0.002615593105026619 iter num 800\n",
            "loss 215.91342163085938 average time 0.0026145196756349434 iter num 820\n",
            "loss 1.1966217756271362 average time 0.0026073544643124827 iter num 840\n",
            "loss 0.11652093380689621 average time 0.0025990613104832573 iter num 860\n",
            "loss 1.9989038705825806 average time 0.0025926071556982193 iter num 880\n",
            "loss 0.03839491307735443 average time 0.0025953015955747106 iter num 900\n",
            "loss 0.008172285743057728 average time 0.002592475636975391 iter num 920\n",
            "loss 0.015437251888215542 average time 0.002584865114912394 iter num 940\n",
            "loss 0.08136195689439774 average time 0.002578682457309848 iter num 960\n",
            "loss 0.4470796287059784 average time 0.002573624026554542 iter num 980\n",
            "loss 72.13117980957031 average time 0.0025690029190245695 iter num 1000\n",
            "loss 0.3577997088432312 average time 0.0029250750501887525 iter num 20\n",
            "loss 7.737590312957764 average time 0.0027726726752462126 iter num 40\n",
            "loss 14.660616874694824 average time 0.0026401966834782797 iter num 60\n",
            "loss 0.11327601224184036 average time 0.0025567537251390605 iter num 80\n",
            "loss 0.28403714299201965 average time 0.002500638420096948 iter num 100\n",
            "loss 2.3058910369873047 average time 0.0025123694834140527 iter num 120\n",
            "loss 5.98309850692749 average time 0.002473981871493639 iter num 140\n",
            "loss 0.008982519619166851 average time 0.0024471705750556795 iter num 160\n",
            "loss 0.05718550458550453 average time 0.0024234640944693336 iter num 180\n",
            "loss 0.023236757144331932 average time 0.0024112416450134335 iter num 200\n",
            "loss 4.4118523597717285 average time 0.0023976437409146457 iter num 220\n",
            "loss 0.24397142231464386 average time 0.002392267283350217 iter num 240\n",
            "loss 4.489302158355713 average time 0.0023887936038590853 iter num 260\n",
            "loss 12.989008903503418 average time 0.0023879853607533213 iter num 280\n",
            "loss 0.19089841842651367 average time 0.0023930511600580456 iter num 300\n",
            "loss 1.1345196962356567 average time 0.002387387284414899 iter num 320\n",
            "loss 14.350520133972168 average time 0.002397000432392815 iter num 340\n",
            "loss 0.6071401238441467 average time 0.0023920464167278828 iter num 360\n",
            "loss 0.39621731638908386 average time 0.0023904224053168084 iter num 380\n",
            "loss 1.4175587892532349 average time 0.0023856397925601414 iter num 400\n",
            "loss 34.77842712402344 average time 0.0023807715810151074 iter num 420\n",
            "loss 0.6935191750526428 average time 0.0023754335705151873 iter num 440\n",
            "loss 0.9083296656608582 average time 0.0023753318978813934 iter num 460\n",
            "loss 3.709404706954956 average time 0.0023719329042251047 iter num 480\n",
            "loss 3.879101514816284 average time 0.0023683783820633835 iter num 500\n",
            "loss 6.804792404174805 average time 0.002367348042347518 iter num 520\n",
            "loss 0.16500186920166016 average time 0.002363408087061274 iter num 540\n",
            "loss 0.05748184770345688 average time 0.002358325967874667 iter num 560\n",
            "loss 0.22471123933792114 average time 0.002356268222420426 iter num 580\n",
            "loss 0.24470870196819305 average time 0.0023541395300010967 iter num 600\n",
            "loss 0.09614779055118561 average time 0.00235495257903465 iter num 620\n",
            "loss 147.76718139648438 average time 0.002357564326561601 iter num 640\n",
            "loss 1.1035000085830688 average time 0.00235538264696791 iter num 660\n",
            "loss 0.010884786956012249 average time 0.002361042844118214 iter num 680\n",
            "loss 0.07449466735124588 average time 0.0023599800628575653 iter num 700\n",
            "loss 14.998305320739746 average time 0.0023569832361065184 iter num 720\n",
            "loss 5.4229326248168945 average time 0.002354906770265311 iter num 740\n",
            "loss 0.5762501358985901 average time 0.0023632891644650186 iter num 760\n",
            "loss 3.418952465057373 average time 0.0023614807794845732 iter num 780\n",
            "loss 0.3102024495601654 average time 0.0023644788075012 iter num 800\n",
            "loss 6.280910968780518 average time 0.002366051964635539 iter num 820\n",
            "loss 3.0337820053100586 average time 0.0023643077678549337 iter num 840\n",
            "loss 15.954378128051758 average time 0.002363986472091499 iter num 860\n",
            "loss 11.302014350891113 average time 0.0023642999704530997 iter num 880\n",
            "loss 7.726866245269775 average time 0.002362590404445655 iter num 900\n",
            "loss 1.1668139696121216 average time 0.002362844490224471 iter num 920\n",
            "loss 3.6523594856262207 average time 0.0023621520351143578 iter num 940\n",
            "loss 0.04262984171509743 average time 0.0023598414072902568 iter num 960\n",
            "loss 1.4868024587631226 average time 0.002361973828570923 iter num 980\n",
            "loss 0.02000844106078148 average time 0.0023639526789957016 iter num 1000\n",
            "loss 0.09670371562242508 average time 0.0028909628996188984 iter num 20\n",
            "loss 153.82608032226562 average time 0.0026020104498002184 iter num 40\n",
            "loss 0.0854199081659317 average time 0.0025339661665384483 iter num 60\n",
            "loss 35.44405746459961 average time 0.002466497224941122 iter num 80\n",
            "loss 4.319840431213379 average time 0.0024316638599884755 iter num 100\n",
            "loss 0.0011981679126620293 average time 0.002398975249995298 iter num 120\n",
            "loss 4.0428924560546875 average time 0.002387973014304277 iter num 140\n",
            "loss 15.289918899536133 average time 0.0023700727062987426 iter num 160\n",
            "loss 0.5255674719810486 average time 0.0024264755333812597 iter num 180\n",
            "loss 0.023347929120063782 average time 0.002411008365043017 iter num 200\n",
            "loss 18.86468505859375 average time 0.0024079050591436415 iter num 220\n",
            "loss 3.6786627769470215 average time 0.002401225954235997 iter num 240\n",
            "loss 0.044362761080265045 average time 0.0023912123923484894 iter num 260\n",
            "loss 25.85869026184082 average time 0.0023823531357460783 iter num 280\n",
            "loss 8.671876907348633 average time 0.0023827995933667504 iter num 300\n",
            "loss 0.0173410065472126 average time 0.002390789575031249 iter num 320\n",
            "loss 0.0012018680572509766 average time 0.002414821832382372 iter num 340\n",
            "loss 4.0933732986450195 average time 0.0024068113917009113 iter num 360\n",
            "loss 5.539897918701172 average time 0.002402243521072179 iter num 380\n",
            "loss 0.10715506970882416 average time 0.0024210127050173468 iter num 400\n",
            "loss 0.9653176665306091 average time 0.0024126350523883526 iter num 420\n",
            "loss 0.07404400408267975 average time 0.002406642406826491 iter num 440\n",
            "loss 18.5069580078125 average time 0.002415997832612566 iter num 460\n",
            "loss 0.0020317072048783302 average time 0.002410139862502092 iter num 480\n",
            "loss 0.20207591354846954 average time 0.002407581662002485 iter num 500\n",
            "loss 0.02211488038301468 average time 0.0023998797423176324 iter num 520\n",
            "loss 2.004462957382202 average time 0.002399414849999933 iter num 540\n",
            "loss 17.49945640563965 average time 0.002394305537498959 iter num 560\n",
            "loss 45.293766021728516 average time 0.0023911320775776655 iter num 580\n",
            "loss 54.333473205566406 average time 0.002394411658324316 iter num 600\n",
            "loss 0.07097523659467697 average time 0.0023924366612845917 iter num 620\n",
            "loss 7.740455627441406 average time 0.0023900215999901773 iter num 640\n",
            "loss 0.48317304253578186 average time 0.002392988245446759 iter num 660\n",
            "loss 0.13079625368118286 average time 0.002389484847045049 iter num 680\n",
            "loss 0.8552495837211609 average time 0.0023890050256938724 iter num 700\n",
            "loss 0.004052553325891495 average time 0.0023881292972014814 iter num 720\n",
            "loss 1.0994163751602173 average time 0.00238473483106547 iter num 740\n",
            "loss 72.35172271728516 average time 0.00238305803024655 iter num 760\n",
            "loss 0.17566223442554474 average time 0.0023882101794674196 iter num 780\n",
            "loss 1.8701822757720947 average time 0.0023849923649822812 iter num 800\n",
            "loss 0.0401645191013813 average time 0.0023928275463265714 iter num 820\n",
            "loss 14.525559425354004 average time 0.0023901790285608946 iter num 840\n",
            "loss 70.17475128173828 average time 0.002389037423244042 iter num 860\n",
            "loss 0.16227713227272034 average time 0.0023850952045387946 iter num 880\n",
            "loss 0.30725517868995667 average time 0.0023837265722229657 iter num 900\n",
            "loss 1.0352168083190918 average time 0.002381604599998394 iter num 920\n",
            "loss 0.5807531476020813 average time 0.002381225120210187 iter num 940\n",
            "loss 0.030735649168491364 average time 0.002379417177077888 iter num 960\n",
            "loss 6.69259786605835 average time 0.0023778417061145534 iter num 980\n",
            "loss 0.7476274967193604 average time 0.0023762498809956015 iter num 1000\n",
            "loss 26.441402435302734 average time 0.003798286149958585 iter num 20\n",
            "loss 7.368098258972168 average time 0.0030439145498803557 iter num 40\n",
            "loss 1.7720045434543863e-05 average time 0.002791020133251247 iter num 60\n",
            "loss 6.708278656005859 average time 0.0026675308748735915 iter num 80\n",
            "loss 69.47589874267578 average time 0.002613151619971177 iter num 100\n",
            "loss 0.39966991543769836 average time 0.002567078774973197 iter num 120\n",
            "loss 1.22007155418396 average time 0.0025266034571879053 iter num 140\n",
            "loss 0.0011994887609034777 average time 0.002504936168804761 iter num 160\n",
            "loss 5.58071756362915 average time 0.002490280827846113 iter num 180\n",
            "loss 2.833409070968628 average time 0.002469159255060731 iter num 200\n",
            "loss 0.4309995770454407 average time 0.0024541788818830605 iter num 220\n",
            "loss 5.190265655517578 average time 0.002438542233411075 iter num 240\n",
            "loss 2.259974479675293 average time 0.002435720950045204 iter num 260\n",
            "loss 2.2064664363861084 average time 0.002429870217916427 iter num 280\n",
            "loss 8.78744888305664 average time 0.002418963246709609 iter num 300\n",
            "loss 0.007961698807775974 average time 0.0024104889469185762 iter num 320\n",
            "loss 0.09769795835018158 average time 0.0024430292000461656 iter num 340\n",
            "loss 0.7203719019889832 average time 0.002436009425026795 iter num 360\n",
            "loss 1.3902949094772339 average time 0.002425307702656267 iter num 380\n",
            "loss 2.7733967304229736 average time 0.0024255957975310594 iter num 400\n",
            "loss 0.1279904842376709 average time 0.0024325320643064125 iter num 420\n",
            "loss 0.557178258895874 average time 0.002433929986376494 iter num 440\n",
            "loss 1.166502833366394 average time 0.00243463940001754 iter num 460\n",
            "loss 0.23190714418888092 average time 0.0024315608187672902 iter num 480\n",
            "loss 0.5749564170837402 average time 0.0024439656520189603 iter num 500\n",
            "loss 0.001586673315614462 average time 0.0024374800346217505 iter num 520\n",
            "loss 21.88662338256836 average time 0.0024343776185358165 iter num 540\n",
            "loss 0.4407827854156494 average time 0.002429834001788679 iter num 560\n",
            "loss 0.0011873145122081041 average time 0.0024426693689653394 iter num 580\n",
            "loss 0.880580723285675 average time 0.002442577981667758 iter num 600\n",
            "loss 50.931884765625 average time 0.002438495169357221 iter num 620\n",
            "loss 117.5253677368164 average time 0.002449720651571852 iter num 640\n",
            "loss 1.0528579950332642 average time 0.0024499451454616837 iter num 660\n",
            "loss 3.3611624240875244 average time 0.002452755423540593 iter num 680\n",
            "loss 67.89190673828125 average time 0.002447665807152849 iter num 700\n",
            "loss 120.09214782714844 average time 0.0024436604527914418 iter num 720\n",
            "loss 2.3970963954925537 average time 0.0024415019094777635 iter num 740\n",
            "loss 6.705709934234619 average time 0.0024365206381772673 iter num 760\n",
            "loss 6.712765216827393 average time 0.0024327770038652463 iter num 780\n",
            "loss 5.545142650604248 average time 0.002429577917516781 iter num 800\n",
            "loss 4.040890693664551 average time 0.002426340758552769 iter num 820\n",
            "loss 47.69523620605469 average time 0.0024358974321612116 iter num 840\n",
            "loss 4.71349573135376 average time 0.0024313215349011865 iter num 860\n",
            "loss 0.00036720733623951674 average time 0.0024348571784271783 iter num 880\n",
            "loss 129.71331787109375 average time 0.0024326049789124226 iter num 900\n",
            "loss 0.8894987106323242 average time 0.0024280612891506397 iter num 920\n",
            "loss 2.1309289932250977 average time 0.002432436867039019 iter num 940\n",
            "loss 165.94778442382812 average time 0.0024394093323034365 iter num 960\n",
            "loss 9.04505443572998 average time 0.0024412142908250664 iter num 980\n",
            "loss 0.14768528938293457 average time 0.0024388731630078835 iter num 1000\n",
            "loss 0.4558100402355194 average time 0.003309926850215561 iter num 20\n",
            "loss 3.9801273345947266 average time 0.003019881275122316 iter num 40\n",
            "loss 46.251869201660156 average time 0.002885456283517366 iter num 60\n",
            "loss 14.461760520935059 average time 0.0027902393126851164 iter num 80\n",
            "loss 147.92283630371094 average time 0.0027625473901571242 iter num 100\n",
            "loss 17.75357437133789 average time 0.0027475363168377952 iter num 120\n",
            "loss 3.046063184738159 average time 0.0027086379215558866 iter num 140\n",
            "loss 12.97279167175293 average time 0.0027095561063674722 iter num 160\n",
            "loss 13.701723098754883 average time 0.002702342450104172 iter num 180\n",
            "loss 23.967788696289062 average time 0.002700140560109503 iter num 200\n",
            "loss 12.974769592285156 average time 0.002689503704641538 iter num 220\n",
            "loss 2.6920008659362793 average time 0.0026964040876085466 iter num 240\n",
            "loss 0.53146892786026 average time 0.0027286114424056834 iter num 260\n",
            "loss 1.620370626449585 average time 0.0027252947179801723 iter num 280\n",
            "loss 5.055429935455322 average time 0.002709331080107707 iter num 300\n",
            "loss 4.942574977874756 average time 0.0027048554282202986 iter num 320\n",
            "loss 0.7187951803207397 average time 0.0026944696883273375 iter num 340\n",
            "loss 19.99475860595703 average time 0.002683348694548234 iter num 360\n",
            "loss 23.070398330688477 average time 0.0026896524580048496 iter num 380\n",
            "loss 0.641511082649231 average time 0.0026841331875994 iter num 400\n",
            "loss 62.544986724853516 average time 0.00266992516199025 iter num 420\n",
            "loss 0.07543712854385376 average time 0.0026732533318987737 iter num 440\n",
            "loss 2.0762007236480713 average time 0.002675458869626986 iter num 460\n",
            "loss 4.8468918800354 average time 0.002673587545886373 iter num 480\n",
            "loss 0.3294982314109802 average time 0.002668809178059746 iter num 500\n",
            "loss 1.9898103475570679 average time 0.00266621579236506 iter num 520\n",
            "loss 28.350515365600586 average time 0.002663029448211563 iter num 540\n",
            "loss 1.5560232400894165 average time 0.002651597505421575 iter num 560\n",
            "loss 2.4535000324249268 average time 0.0026525070448863925 iter num 580\n",
            "loss 3.4107329845428467 average time 0.0026629928250501205 iter num 600\n",
            "loss 1.654157280921936 average time 0.0026625270758579003 iter num 620\n",
            "loss 89.42909240722656 average time 0.002664408965677012 iter num 640\n",
            "loss 3.7833800315856934 average time 0.0026626063379394924 iter num 660\n",
            "loss 0.3842780590057373 average time 0.0026612388177160457 iter num 680\n",
            "loss 10.057893753051758 average time 0.0026598577057692246 iter num 700\n",
            "loss 2.4299516677856445 average time 0.002661064234775444 iter num 720\n",
            "loss 34.9261589050293 average time 0.002652845440585421 iter num 740\n",
            "loss 0.08621528744697571 average time 0.002647806268463395 iter num 760\n",
            "loss 11.059816360473633 average time 0.002651502237215307 iter num 780\n",
            "loss 0.1483515053987503 average time 0.0026569096187881768 iter num 800\n",
            "loss 6.261220455169678 average time 0.002653851409794276 iter num 820\n",
            "loss 4.17331600189209 average time 0.0026495967167084883 iter num 840\n",
            "loss 0.30388548970222473 average time 0.0026433890419041766 iter num 860\n",
            "loss 1.4496768712997437 average time 0.0026431610045909277 iter num 880\n",
            "loss 0.6223803758621216 average time 0.002640909731154453 iter num 900\n",
            "loss 8.56652545928955 average time 0.0026364548348223964 iter num 920\n",
            "loss 2.5435421466827393 average time 0.0026351806128041837 iter num 940\n",
            "loss 1.9694631099700928 average time 0.0026327512000345146 iter num 960\n",
            "loss 0.04488600417971611 average time 0.002634489182681285 iter num 980\n",
            "loss 0.11527495086193085 average time 0.0026292920650248562 iter num 1000\n",
            "loss 25.09775161743164 average time 0.0034374863499579077 iter num 20\n",
            "loss 0.867851197719574 average time 0.0029118264749740776 iter num 40\n",
            "loss 142.13783264160156 average time 0.002770085300047261 iter num 60\n",
            "loss 0.023914143443107605 average time 0.002797715537599288 iter num 80\n",
            "loss 1.0614196062088013 average time 0.00278014293005981 iter num 100\n",
            "loss 8.592011451721191 average time 0.0027207180916927125 iter num 120\n",
            "loss 2.429809093475342 average time 0.002677702814305251 iter num 140\n",
            "loss 203.33482360839844 average time 0.0026580551000051854 iter num 160\n",
            "loss 0.9770467281341553 average time 0.0026228565222279738 iter num 180\n",
            "loss 44.9515266418457 average time 0.002592320585008565 iter num 200\n",
            "loss 158.90052795410156 average time 0.0025945783318175844 iter num 220\n",
            "loss 4.030851364135742 average time 0.002591349245813035 iter num 240\n",
            "loss 1.1106725931167603 average time 0.002589085511513426 iter num 260\n",
            "loss 0.18164066970348358 average time 0.0025830463999747216 iter num 280\n",
            "loss 0.018153950572013855 average time 0.0025863255433068843 iter num 300\n",
            "loss 0.1302812397480011 average time 0.002595910621846542 iter num 320\n",
            "loss 0.000982292927801609 average time 0.0025923768617330473 iter num 340\n",
            "loss 1.1722725629806519 average time 0.0025973770638504194 iter num 360\n",
            "loss 6.286282539367676 average time 0.002587300023634797 iter num 380\n",
            "loss 0.0667184442281723 average time 0.0025921814024468404 iter num 400\n",
            "loss 0.25838521122932434 average time 0.0025964860427978107 iter num 420\n",
            "loss 0.08096816390752792 average time 0.0025969647181103605 iter num 440\n",
            "loss 4.327407360076904 average time 0.0025978352781946697 iter num 460\n",
            "loss 15.069657325744629 average time 0.0025886878832617794 iter num 480\n",
            "loss 0.8492206335067749 average time 0.0025887764579238135 iter num 500\n",
            "loss 13.549983978271484 average time 0.002581615059541666 iter num 520\n",
            "loss 15.822759628295898 average time 0.0025834207666001158 iter num 540\n",
            "loss 0.0004994121845811605 average time 0.002584935585654031 iter num 560\n",
            "loss 67.51349639892578 average time 0.0025883662499303494 iter num 580\n",
            "loss 0.05610911548137665 average time 0.002595427043267288 iter num 600\n",
            "loss 0.13503965735435486 average time 0.002595949612840477 iter num 620\n",
            "loss 34.03670883178711 average time 0.002594845053062045 iter num 640\n",
            "loss 6.426862716674805 average time 0.0025961701499358186 iter num 660\n",
            "loss 13.718672752380371 average time 0.0025943170072931774 iter num 680\n",
            "loss 14.059009552001953 average time 0.0025901681785061165 iter num 700\n",
            "loss 35.82196807861328 average time 0.0025940274096557104 iter num 720\n",
            "loss 2.212597131729126 average time 0.0025920695215555078 iter num 740\n",
            "loss 0.1973395198583603 average time 0.0025926474170390925 iter num 760\n",
            "loss 0.4165818393230438 average time 0.002595314689673008 iter num 780\n",
            "loss 1.0885159969329834 average time 0.002595955373678862 iter num 800\n",
            "loss 84.55166625976562 average time 0.002600279531634442 iter num 820\n",
            "loss 22.17259407043457 average time 0.0026032837427876422 iter num 840\n",
            "loss 0.08187423646450043 average time 0.0025993401278398332 iter num 860\n",
            "loss 123.45991516113281 average time 0.0025912455181221297 iter num 880\n",
            "loss 0.008863606490194798 average time 0.0025841497343854925 iter num 900\n",
            "loss 5.3561015129089355 average time 0.002577102743421362 iter num 920\n",
            "loss 0.46930527687072754 average time 0.0025814970754776795 iter num 940\n",
            "loss 3.794740915298462 average time 0.0025744577749454343 iter num 960\n",
            "loss 0.3131754994392395 average time 0.0025694780734126224 iter num 980\n",
            "loss 7.349513053894043 average time 0.002563608177944843 iter num 1000\n",
            "loss 2.4921162128448486 average time 0.0028829205999500117 iter num 20\n",
            "loss 21.607580184936523 average time 0.0025496443751308107 iter num 40\n",
            "loss 11.969666481018066 average time 0.002457564533384963 iter num 60\n",
            "loss 459.9479064941406 average time 0.002435306387542369 iter num 80\n",
            "loss 0.7685250043869019 average time 0.0024117786600436376 iter num 100\n",
            "loss 0.046315327286720276 average time 0.002383251850005763 iter num 120\n",
            "loss 0.24265049397945404 average time 0.002366538028594992 iter num 140\n",
            "loss 53.96092224121094 average time 0.0023594959812498926 iter num 160\n",
            "loss 0.0799185186624527 average time 0.0023793962833224213 iter num 180\n",
            "loss 183.12425231933594 average time 0.002368688235001173 iter num 200\n",
            "loss 1.6286476850509644 average time 0.0023565014363653475 iter num 220\n",
            "loss 0.0062853023409843445 average time 0.0023536133124859287 iter num 240\n",
            "loss 63.07465744018555 average time 0.0023489592615218357 iter num 260\n",
            "loss 1.5784478187561035 average time 0.0023432429499994863 iter num 280\n",
            "loss 5.076173305511475 average time 0.002347374536669425 iter num 300\n",
            "loss 0.9163323640823364 average time 0.002348324393767598 iter num 320\n",
            "loss 2.406212329864502 average time 0.00234686076766914 iter num 340\n",
            "loss 222.09121704101562 average time 0.0023469501861503278 iter num 360\n",
            "loss 16.182586669921875 average time 0.002341404297390239 iter num 380\n",
            "loss 3.6619269847869873 average time 0.002342197815014515 iter num 400\n",
            "loss 0.04036352410912514 average time 0.0023649887761989486 iter num 420\n",
            "loss 2.499082565307617 average time 0.0023636897000167004 iter num 440\n",
            "loss 3.084033489227295 average time 0.0023592666391501235 iter num 460\n",
            "loss 105.59870147705078 average time 0.002367715714611525 iter num 480\n",
            "loss 0.0777171179652214 average time 0.0023623041220380402 iter num 500\n",
            "loss 17.067150115966797 average time 0.0023586560731158755 iter num 520\n",
            "loss 0.029644884169101715 average time 0.00235670569077734 iter num 540\n",
            "loss 0.0014265213394537568 average time 0.0023535800357519423 iter num 560\n",
            "loss 0.10872393846511841 average time 0.0023502967396905597 iter num 580\n",
            "loss 0.1317959427833557 average time 0.0023474711883621543 iter num 600\n",
            "loss 0.04769814386963844 average time 0.0023518377596994998 iter num 620\n",
            "loss 6.814652442932129 average time 0.002351568053146025 iter num 640\n",
            "loss 1.0072075128555298 average time 0.002360052263658431 iter num 660\n",
            "loss 34.11678695678711 average time 0.0023609837941421575 iter num 680\n",
            "loss 32.869911193847656 average time 0.0023604664657432294 iter num 700\n",
            "loss 2.389023542404175 average time 0.0023589947778039763 iter num 720\n",
            "loss 0.4329527020454407 average time 0.002358054490562338 iter num 740\n",
            "loss 0.05894458666443825 average time 0.002356238413181257 iter num 760\n",
            "loss 6.543552398681641 average time 0.0023660122795053423 iter num 780\n",
            "loss 2.100511312484741 average time 0.0023635818575144184 iter num 800\n",
            "loss 11.269771575927734 average time 0.002362509192687689 iter num 820\n",
            "loss 24.54433250427246 average time 0.002360050285716127 iter num 840\n",
            "loss 20.106197357177734 average time 0.0023585859569742076 iter num 860\n",
            "loss 21.251331329345703 average time 0.002357634119312024 iter num 880\n",
            "loss 0.7802202701568604 average time 0.0023569393977737087 iter num 900\n",
            "loss 17.229162216186523 average time 0.002355723947826134 iter num 920\n",
            "loss 1.5225141048431396 average time 0.0023533351904355166 iter num 940\n",
            "loss 1.164087176322937 average time 0.0023600220406327327 iter num 960\n",
            "loss 0.7833908200263977 average time 0.002366590887762571 iter num 980\n",
            "loss 14.419967651367188 average time 0.002364649837003526 iter num 1000\n",
            "loss 1.5286751985549927 average time 0.0028033456500452304 iter num 20\n",
            "loss 4.83626127243042 average time 0.0026870952500757995 iter num 40\n",
            "loss 1.8880661725997925 average time 0.0026059333333857166 iter num 60\n",
            "loss 7.021007061004639 average time 0.002601791975121159 iter num 80\n",
            "loss 13.652008056640625 average time 0.0025461860700670513 iter num 100\n",
            "loss 0.19427748024463654 average time 0.002555546983391347 iter num 120\n",
            "loss 0.15499339997768402 average time 0.0025218461357456234 iter num 140\n",
            "loss 22.66067123413086 average time 0.002489525531268555 iter num 160\n",
            "loss 10.613988876342773 average time 0.0024665125944617707 iter num 180\n",
            "loss 0.2644273638725281 average time 0.002465188889982528 iter num 200\n",
            "loss 0.19285720586776733 average time 0.0024504683545356703 iter num 220\n",
            "loss 15.112157821655273 average time 0.002438869570823954 iter num 240\n",
            "loss 0.24307429790496826 average time 0.0024268669000146194 iter num 260\n",
            "loss 76.03988647460938 average time 0.0024186645571522346 iter num 280\n",
            "loss 0.8804518580436707 average time 0.0024100936200193244 iter num 300\n",
            "loss 0.015941493213176727 average time 0.0023990004812674214 iter num 320\n",
            "loss 8.112492561340332 average time 0.0023971422617892935 iter num 340\n",
            "loss 9.696820259094238 average time 0.002390902722239237 iter num 360\n",
            "loss 0.9062200784683228 average time 0.0023861172105458343 iter num 380\n",
            "loss 3.3881490230560303 average time 0.0023821004625096975 iter num 400\n",
            "loss 63.798744201660156 average time 0.002376341542865356 iter num 420\n",
            "loss 2.8506696224212646 average time 0.0023750544477355684 iter num 440\n",
            "loss 0.027422038838267326 average time 0.002374310130440078 iter num 460\n",
            "loss 0.002125618513673544 average time 0.0023777143958416975 iter num 480\n",
            "loss 0.0120749706402421 average time 0.002375299742008792 iter num 500\n",
            "loss 0.4335728883743286 average time 0.0023722825942373814 iter num 520\n",
            "loss 0.9682883024215698 average time 0.0023691780055506333 iter num 540\n",
            "loss 0.13002926111221313 average time 0.0023711871732172898 iter num 560\n",
            "loss 0.060067810118198395 average time 0.002370913693106684 iter num 580\n",
            "loss 1.0316568613052368 average time 0.0023804594383424653 iter num 600\n",
            "loss 0.41407662630081177 average time 0.002378197800014952 iter num 620\n",
            "loss 4.223355293273926 average time 0.002387973223446238 iter num 640\n",
            "loss 14.72419261932373 average time 0.0023840400833361136 iter num 660\n",
            "loss 3.9785215854644775 average time 0.0023926343499999134 iter num 680\n",
            "loss 0.7791701555252075 average time 0.0023890541228632042 iter num 700\n",
            "loss 0.49280887842178345 average time 0.0023860153472267283 iter num 720\n",
            "loss 0.6112817525863647 average time 0.0023881606054036073 iter num 740\n",
            "loss 7.950289726257324 average time 0.002386559235528215 iter num 760\n",
            "loss 0.03012034110724926 average time 0.0023836494538441817 iter num 780\n",
            "loss 0.05149663984775543 average time 0.002381432107499677 iter num 800\n",
            "loss 7.435557842254639 average time 0.002378593039023743 iter num 820\n",
            "loss 4.416797637939453 average time 0.0023800745452414655 iter num 840\n",
            "loss 1.3505159616470337 average time 0.002377876960462197 iter num 860\n",
            "loss 5.7807536125183105 average time 0.0023761994147724346 iter num 880\n",
            "loss 13.302022933959961 average time 0.0023740973811092973 iter num 900\n",
            "loss 69.07787322998047 average time 0.002377446002174111 iter num 920\n",
            "loss 0.0018094461411237717 average time 0.002380312406379009 iter num 940\n",
            "loss 0.06726585328578949 average time 0.002376934340624833 iter num 960\n",
            "loss 3.2484209537506104 average time 0.0023754920857179374 iter num 980\n",
            "loss 6.570140838623047 average time 0.002373321773011412 iter num 1000\n",
            "loss 5.9212646484375 average time 0.002926096200098982 iter num 20\n",
            "loss 4.266693115234375 average time 0.002623162474901619 iter num 40\n",
            "loss 0.03595676273107529 average time 0.0025144486999124638 iter num 60\n",
            "loss 5.119651794433594 average time 0.002484195662395905 iter num 80\n",
            "loss 12.527528762817383 average time 0.0025277005898715287 iter num 100\n",
            "loss 2.8295230865478516 average time 0.0024785146165868356 iter num 120\n",
            "loss 5.26729679107666 average time 0.0024546306213778734 iter num 140\n",
            "loss 2.652925491333008 average time 0.0024672550562172546 iter num 160\n",
            "loss 0.015067397616803646 average time 0.0024599729221841293 iter num 180\n",
            "loss 0.7815533876419067 average time 0.002440543879974939 iter num 200\n",
            "loss 6.912010669708252 average time 0.0024273362863161973 iter num 220\n",
            "loss 0.08697474747896194 average time 0.0024158492124342957 iter num 240\n",
            "loss 0.020195432007312775 average time 0.0024100715306933406 iter num 260\n",
            "loss 4.537440776824951 average time 0.002401008421364687 iter num 280\n",
            "loss 16.297080993652344 average time 0.002391980623257647 iter num 300\n",
            "loss 0.891907274723053 average time 0.0024018424843063714 iter num 320\n",
            "loss 2.0226290225982666 average time 0.002391928394059933 iter num 340\n",
            "loss 1.2831777334213257 average time 0.0023909219305096483 iter num 360\n",
            "loss 1.3775501251220703 average time 0.002386341552578654 iter num 380\n",
            "loss 2.8424947261810303 average time 0.0023994093949477246 iter num 400\n",
            "loss 3.5751264095306396 average time 0.002394279016603139 iter num 420\n",
            "loss 0.12284096330404282 average time 0.002388452106776061 iter num 440\n",
            "loss 11.02452564239502 average time 0.0023835419738687685 iter num 460\n",
            "loss 5.439508438110352 average time 0.002382704197880988 iter num 480\n",
            "loss 0.24079374969005585 average time 0.002383788429960987 iter num 500\n",
            "loss 1.4999016523361206 average time 0.002380460882659463 iter num 520\n",
            "loss 0.22791756689548492 average time 0.002379366896258472 iter num 540\n",
            "loss 6.765289306640625 average time 0.002380964542823806 iter num 560\n",
            "loss 2.15147066116333 average time 0.002378222837894006 iter num 580\n",
            "loss 27.335142135620117 average time 0.002374729614972845 iter num 600\n",
            "loss 34.72265625 average time 0.0023737057806160478 iter num 620\n",
            "loss 0.7574707269668579 average time 0.002371906603099205 iter num 640\n",
            "loss 3.514423370361328 average time 0.0023693633014827908 iter num 660\n",
            "loss 3.100757122039795 average time 0.0023654810146741937 iter num 680\n",
            "loss 1.31178617477417 average time 0.0023633969628203237 iter num 700\n",
            "loss 0.07983624190092087 average time 0.002372334311073448 iter num 720\n",
            "loss 1.9710962772369385 average time 0.002375850786452124 iter num 740\n",
            "loss 0.33034080266952515 average time 0.0023742124381203066 iter num 760\n",
            "loss 3.0368058681488037 average time 0.002372878979447425 iter num 780\n",
            "loss 0.7382780313491821 average time 0.002383243747458437 iter num 800\n",
            "loss 0.007120170630514622 average time 0.0023811688341039573 iter num 820\n",
            "loss 0.04936877638101578 average time 0.0023786160380560822 iter num 840\n",
            "loss 2.105921983718872 average time 0.0023763070778650853 iter num 860\n",
            "loss 64.03907012939453 average time 0.0023850289999596827 iter num 880\n",
            "loss 41.149837493896484 average time 0.002383671546627334 iter num 900\n",
            "loss 0.19079923629760742 average time 0.002385050255398987 iter num 920\n",
            "loss 2.0746397972106934 average time 0.002381817530815479 iter num 940\n",
            "loss 48.25782012939453 average time 0.002379232473919046 iter num 960\n",
            "loss 167.3883819580078 average time 0.002378301777513784 iter num 980\n",
            "loss 130.7648468017578 average time 0.0023765698789629825 iter num 1000\n",
            "loss 15.5802583694458 average time 0.0032500853998499225 iter num 20\n",
            "loss 15.149031639099121 average time 0.0028793165498882446 iter num 40\n",
            "loss 12.665055274963379 average time 0.002664581299844334 iter num 60\n",
            "loss 6.723304748535156 average time 0.0025622049124194744 iter num 80\n",
            "loss 1.338043451309204 average time 0.002515626049898856 iter num 100\n",
            "loss 29.01378059387207 average time 0.0025098811999365958 iter num 120\n",
            "loss 2.854896306991577 average time 0.0025174455499446984 iter num 140\n",
            "loss 0.37158897519111633 average time 0.002520533868732855 iter num 160\n",
            "loss 2.6102664470672607 average time 0.0025127753444293276 iter num 180\n",
            "loss 7.280191898345947 average time 0.0025284210049994725 iter num 200\n",
            "loss 30.59040641784668 average time 0.0025289593045437703 iter num 220\n",
            "loss 0.20364917814731598 average time 0.002543219924996265 iter num 240\n",
            "loss 17.400657653808594 average time 0.0025549002153638866 iter num 260\n",
            "loss 6.3741302490234375 average time 0.0025522082678435254 iter num 280\n",
            "loss 0.712729811668396 average time 0.0025620878766555205 iter num 300\n",
            "loss 8.442110061645508 average time 0.00255874696561591 iter num 320\n",
            "loss 4.076481342315674 average time 0.002570688173524532 iter num 340\n",
            "loss 4.0128278732299805 average time 0.0025993607166633916 iter num 360\n",
            "loss 122.67414855957031 average time 0.0025978540236888206 iter num 380\n",
            "loss 96.142822265625 average time 0.00259477860500283 iter num 400\n",
            "loss 0.003669620491564274 average time 0.0025874690833309916 iter num 420\n",
            "loss 142.71363830566406 average time 0.002583606288631431 iter num 440\n",
            "loss 16.881444931030273 average time 0.0025890329717383237 iter num 460\n",
            "loss 47.45369338989258 average time 0.0025884582145825636 iter num 480\n",
            "loss 0.4406953454017639 average time 0.0025871065139945132 iter num 500\n",
            "loss 0.1358332633972168 average time 0.002580663111523161 iter num 520\n",
            "loss 31.979658126831055 average time 0.0025863049036935854 iter num 540\n",
            "loss 0.4069472849369049 average time 0.002583765183918071 iter num 560\n",
            "loss 0.15385688841342926 average time 0.0025846471327550433 iter num 580\n",
            "loss 1.6270008087158203 average time 0.0025870911499896467 iter num 600\n",
            "loss 0.08049380034208298 average time 0.002578807109667621 iter num 620\n",
            "loss 14.068938255310059 average time 0.0025833537031218156 iter num 640\n",
            "loss 5.4695143699646 average time 0.0025855879999929156 iter num 660\n",
            "loss 0.023394957184791565 average time 0.002584781324990485 iter num 680\n",
            "loss 0.025288404896855354 average time 0.002587117142848001 iter num 700\n",
            "loss 3.8361775875091553 average time 0.002591001302777032 iter num 720\n",
            "loss 4.046736240386963 average time 0.002590711064860099 iter num 740\n",
            "loss 2.1065640449523926 average time 0.002594097998677937 iter num 760\n",
            "loss 0.017875023186206818 average time 0.0025898676038382407 iter num 780\n",
            "loss 1.3553789854049683 average time 0.0025885939299928394 iter num 800\n",
            "loss 0.13663962483406067 average time 0.0025892821707313445 iter num 820\n",
            "loss 15.290634155273438 average time 0.0025878321511819584 iter num 840\n",
            "loss 49.07853698730469 average time 0.0025822661162766413 iter num 860\n",
            "loss 0.014744646847248077 average time 0.0025777132102327662 iter num 880\n",
            "loss 6.1245598793029785 average time 0.0025799846088941395 iter num 900\n",
            "loss 1.335879921913147 average time 0.0025811403619568213 iter num 920\n",
            "loss 7.989015579223633 average time 0.002583099905321897 iter num 940\n",
            "loss 0.5248458981513977 average time 0.002587554098962149 iter num 960\n",
            "loss 1.309113621711731 average time 0.0025877695112266875 iter num 980\n",
            "loss 11.30878734588623 average time 0.0025876755160024914 iter num 1000\n",
            "loss 0.019146770238876343 average time 0.0031744337497002562 iter num 20\n",
            "loss 1.8186458349227905 average time 0.0028609237247110286 iter num 40\n",
            "loss 1.9887558221817017 average time 0.0026934504498967726 iter num 60\n",
            "loss 1.0008471012115479 average time 0.0026048275999073665 iter num 80\n",
            "loss 10.780725479125977 average time 0.0025620291799532424 iter num 100\n",
            "loss 11.991426467895508 average time 0.002540961983292315 iter num 120\n",
            "loss 2.93734073638916 average time 0.0025354649142562786 iter num 140\n",
            "loss 11.911165237426758 average time 0.002518564262527434 iter num 160\n",
            "loss 9.40024183364585e-05 average time 0.0025392233444411732 iter num 180\n",
            "loss 1.1324595212936401 average time 0.0025880897549814107 iter num 200\n",
            "loss 0.7197965383529663 average time 0.002607467854531106 iter num 220\n",
            "loss 26.766603469848633 average time 0.002606096108335502 iter num 240\n",
            "loss 5.305607795715332 average time 0.0026069225653932685 iter num 260\n",
            "loss 3.541191577911377 average time 0.0026063137393066427 iter num 280\n",
            "loss 0.015549512580037117 average time 0.0026004368600176047 iter num 300\n",
            "loss 1.03653883934021 average time 0.0025994233312701454 iter num 320\n",
            "loss 0.00953972339630127 average time 0.002590686297074118 iter num 340\n",
            "loss 4.324090957641602 average time 0.0025931741138972737 iter num 360\n",
            "loss 0.03755836561322212 average time 0.0025912663052766126 iter num 380\n",
            "loss 6.519140720367432 average time 0.002579912625014913 iter num 400\n",
            "loss 5.296947479248047 average time 0.002586443190479518 iter num 420\n",
            "loss 0.2559477388858795 average time 0.0025850742045432445 iter num 440\n",
            "loss 0.1868310123682022 average time 0.0025856886065214538 iter num 460\n",
            "loss 0.26022961735725403 average time 0.0025902302687427436 iter num 480\n",
            "loss 1.0117967128753662 average time 0.0025898170119980934 iter num 500\n",
            "loss 35.79740524291992 average time 0.0025910372192391572 iter num 520\n",
            "loss 1.3537274599075317 average time 0.0025906718592725356 iter num 540\n",
            "loss 1.0585893392562866 average time 0.002583955492861735 iter num 560\n",
            "loss 0.3599298596382141 average time 0.0025847108379382228 iter num 580\n",
            "loss 5.5334978103637695 average time 0.002579691983343461 iter num 600\n",
            "loss 0.0019039497710764408 average time 0.002578750838719932 iter num 620\n",
            "loss 2.4264090061187744 average time 0.0025837726125160997 iter num 640\n",
            "loss 0.09536872804164886 average time 0.00258079539395994 iter num 660\n",
            "loss 4.871525764465332 average time 0.00258457494559854 iter num 680\n",
            "loss 1.438267469406128 average time 0.002582697552877237 iter num 700\n",
            "loss 0.22442154586315155 average time 0.0025879018264125383 iter num 720\n",
            "loss 0.05682159215211868 average time 0.0025853254648879826 iter num 740\n",
            "loss 184.3497314453125 average time 0.0025893163460750657 iter num 760\n",
            "loss 1.0016180276870728 average time 0.002583604600029223 iter num 780\n",
            "loss 19.925189971923828 average time 0.0025822802925335965 iter num 800\n",
            "loss 0.19379690289497375 average time 0.002584371467108257 iter num 820\n",
            "loss 1.8734807968139648 average time 0.0025798728476513046 iter num 840\n",
            "loss 1.6151983737945557 average time 0.00258053942328589 iter num 860\n",
            "loss 0.0348210409283638 average time 0.0025833694250340243 iter num 880\n",
            "loss 0.787881076335907 average time 0.00258338940225561 iter num 900\n",
            "loss 0.03854108974337578 average time 0.002587030041337604 iter num 920\n",
            "loss 0.7891682982444763 average time 0.0025924913213105916 iter num 940\n",
            "loss 0.09510301053524017 average time 0.0025949240958652807 iter num 960\n",
            "loss 1.8072432279586792 average time 0.0025955263367645133 iter num 980\n",
            "loss 0.19742615520954132 average time 0.002595737733034184 iter num 1000\n",
            "loss 0.5519300103187561 average time 0.0033293861998572537 iter num 20\n",
            "loss 0.8400588631629944 average time 0.0028160247998130217 iter num 40\n",
            "loss 497.35546875 average time 0.002821424449909197 iter num 60\n",
            "loss 0.41246262192726135 average time 0.002689147287378546 iter num 80\n",
            "loss 0.2631929814815521 average time 0.0027158626199161517 iter num 100\n",
            "loss 16.494873046875 average time 0.0026444113999635494 iter num 120\n",
            "loss 3.103132963180542 average time 0.00259753232143599 iter num 140\n",
            "loss 1.061271071434021 average time 0.0025599949625075167 iter num 160\n",
            "loss 0.8265175223350525 average time 0.0025251682222410133 iter num 180\n",
            "loss 0.4307859539985657 average time 0.0025014655950235465 iter num 200\n",
            "loss 4.347269058227539 average time 0.00248421371820355 iter num 220\n",
            "loss 0.3567578196525574 average time 0.0024691235667053963 iter num 240\n",
            "loss 0.02750706672668457 average time 0.002455463765433636 iter num 260\n",
            "loss 0.5521000623703003 average time 0.002444586989330284 iter num 280\n",
            "loss 0.14304213225841522 average time 0.0024394584467154344 iter num 300\n",
            "loss 0.0036206075455993414 average time 0.002436191809408683 iter num 320\n",
            "loss 0.7485486268997192 average time 0.0024261243706271618 iter num 340\n",
            "loss 9.077160835266113 average time 0.0024162012805845736 iter num 360\n",
            "loss 1.3109300136566162 average time 0.0024333491816114954 iter num 380\n",
            "loss 0.022818177938461304 average time 0.0024285252925346865 iter num 400\n",
            "loss 0.016674738377332687 average time 0.0024264683952857184 iter num 420\n",
            "loss 1.465030312538147 average time 0.0024392938091295944 iter num 440\n",
            "loss 2.2495808601379395 average time 0.0024540417174332262 iter num 460\n",
            "loss 2.5553739070892334 average time 0.0024469880958728632 iter num 480\n",
            "loss 2.180687427520752 average time 0.0024414455520454796 iter num 500\n",
            "loss 7.440384864807129 average time 0.002436302111590731 iter num 520\n",
            "loss 73.88008117675781 average time 0.0024440210352386876 iter num 540\n",
            "loss 0.026400795206427574 average time 0.002438097076833401 iter num 560\n",
            "loss 1.2329092025756836 average time 0.0024320229741753227 iter num 580\n",
            "loss 0.1887659877538681 average time 0.0024287570983718373 iter num 600\n",
            "loss 4.2257232666015625 average time 0.0024330607887438215 iter num 620\n",
            "loss 139.5921173095703 average time 0.0024387590328529994 iter num 640\n",
            "loss 16.273374557495117 average time 0.0024460895848829804 iter num 660\n",
            "loss 0.06703769415616989 average time 0.0024504727412102724 iter num 680\n",
            "loss 70.84780883789062 average time 0.0024562698528929365 iter num 700\n",
            "loss 0.3347584307193756 average time 0.002452611855586737 iter num 720\n",
            "loss 7.0248942375183105 average time 0.002449297159494784 iter num 740\n",
            "loss 0.5783514976501465 average time 0.0024534251671387832 iter num 760\n",
            "loss 20.68246841430664 average time 0.0024559955449009207 iter num 780\n",
            "loss 3.4593183994293213 average time 0.0024584986362810924 iter num 800\n",
            "loss 1.579694151878357 average time 0.0024659299805091174 iter num 820\n",
            "loss 1.4365935325622559 average time 0.0024719421643025962 iter num 840\n",
            "loss 3.0183072090148926 average time 0.0024684767349056128 iter num 860\n",
            "loss 102.31117248535156 average time 0.0024824092579799318 iter num 880\n",
            "loss 2.3284926414489746 average time 0.002487074636699415 iter num 900\n",
            "loss 0.08620471507310867 average time 0.002489640681555418 iter num 920\n",
            "loss 33.816471099853516 average time 0.0024938955074832576 iter num 940\n",
            "loss 0.014454268850386143 average time 0.0024947638927433975 iter num 960\n",
            "loss 1.0664290189743042 average time 0.0024970317867734353 iter num 980\n",
            "loss 1.1566587686538696 average time 0.002495615028037719 iter num 1000\n",
            "loss 25.112125396728516 average time 0.00342096180002045 iter num 20\n",
            "loss 23.083702087402344 average time 0.0029728201999660087 iter num 40\n",
            "loss 0.7130329608917236 average time 0.002798663349949493 iter num 60\n",
            "loss 1.1889487504959106 average time 0.0027692944999898827 iter num 80\n",
            "loss 4.482062816619873 average time 0.0026907655700051693 iter num 100\n",
            "loss 18.172603607177734 average time 0.0027009881666648044 iter num 120\n",
            "loss 19.54791831970215 average time 0.0026978383714257297 iter num 140\n",
            "loss 9.346643447875977 average time 0.002671776581246377 iter num 160\n",
            "loss 1.6086697578430176 average time 0.0026412490944292383 iter num 180\n",
            "loss 12.424856185913086 average time 0.0026415770149924357 iter num 200\n",
            "loss 8.811752319335938 average time 0.0026257860090977787 iter num 220\n",
            "loss 0.032987773418426514 average time 0.002640054862498194 iter num 240\n",
            "loss 5.006135940551758 average time 0.0026542171730677814 iter num 260\n",
            "loss 72.68502044677734 average time 0.002656537367868493 iter num 280\n",
            "loss 2.663212299346924 average time 0.0026640232400071302 iter num 300\n",
            "loss 0.08366784453392029 average time 0.0026737565781331796 iter num 320\n",
            "loss 20.576431274414062 average time 0.00266574860588127 iter num 340\n",
            "loss 0.045871905982494354 average time 0.0026558790888884685 iter num 360\n",
            "loss 0.014660893939435482 average time 0.002660144894731562 iter num 380\n",
            "loss 0.11004725098609924 average time 0.002662880072484768 iter num 400\n",
            "loss 0.16023342311382294 average time 0.002663712114272563 iter num 420\n",
            "loss 46.04217529296875 average time 0.0026646939068004113 iter num 440\n",
            "loss 0.253240704536438 average time 0.0026638216673745773 iter num 460\n",
            "loss 70.6072006225586 average time 0.0026612180687190326 iter num 480\n",
            "loss 0.09521833062171936 average time 0.0026537118219712285 iter num 500\n",
            "loss 0.46290379762649536 average time 0.002650032861513934 iter num 520\n",
            "loss 0.1171783059835434 average time 0.0026473359055233705 iter num 540\n",
            "loss 0.3394356667995453 average time 0.002636863114256422 iter num 560\n",
            "loss 1.2485085725784302 average time 0.002639715137894231 iter num 580\n",
            "loss 1.6683173179626465 average time 0.0026420318199628433 iter num 600\n",
            "loss 0.41377484798431396 average time 0.002639257809642004 iter num 620\n",
            "loss 3.205233573913574 average time 0.0026302707655958104 iter num 640\n",
            "loss 0.3544815480709076 average time 0.002627798060587917 iter num 660\n",
            "loss 2.4164364337921143 average time 0.002623742482332733 iter num 680\n",
            "loss 2.6227035522460938 average time 0.002616976599973506 iter num 700\n",
            "loss 11.105432510375977 average time 0.0026167183583083896 iter num 720\n",
            "loss 5.053892612457275 average time 0.002627396601331605 iter num 740\n",
            "loss 0.0009523952030576766 average time 0.0026275740855142334 iter num 760\n",
            "loss 0.016580598428845406 average time 0.0026298022140975098 iter num 780\n",
            "loss 0.5632212162017822 average time 0.002632078976239427 iter num 800\n",
            "loss 0.06684153527021408 average time 0.0026359865670556467 iter num 820\n",
            "loss 132.27545166015625 average time 0.002635734009510045 iter num 840\n",
            "loss 4.50056791305542 average time 0.002635911139525909 iter num 860\n",
            "loss 6.58074426651001 average time 0.002637521270447575 iter num 880\n",
            "loss 0.3888692259788513 average time 0.0026416429022133848 iter num 900\n",
            "loss 1.5705593824386597 average time 0.0026450017608626894 iter num 920\n",
            "loss 0.01425454206764698 average time 0.0026432598170163632 iter num 940\n",
            "loss 2.1532392501831055 average time 0.0026436447854109703 iter num 960\n",
            "loss 2.4160807132720947 average time 0.0026451975244897916 iter num 980\n",
            "loss 0.2238350659608841 average time 0.0026441263429987883 iter num 1000\n",
            "loss 0.0001482812804169953 average time 0.0032690475000890728 iter num 20\n",
            "loss 0.18058134615421295 average time 0.0029099409500304317 iter num 40\n",
            "loss 1.3005497455596924 average time 0.0028150955834462367 iter num 60\n",
            "loss 0.2342732846736908 average time 0.002737423250073334 iter num 80\n",
            "loss 1.5849149227142334 average time 0.002665713950045756 iter num 100\n",
            "loss 5.832273006439209 average time 0.002655235383372201 iter num 120\n",
            "loss 4.008152484893799 average time 0.0026447403857153924 iter num 140\n",
            "loss 0.5027021169662476 average time 0.002647173174977979 iter num 160\n",
            "loss 4.306347370147705 average time 0.002643673127739829 iter num 180\n",
            "loss 3.778350830078125 average time 0.002640010174955023 iter num 200\n",
            "loss 24.855098724365234 average time 0.002644674090838221 iter num 220\n",
            "loss 10.494817733764648 average time 0.002646139649921982 iter num 240\n",
            "loss 0.04774147644639015 average time 0.0026495134461094073 iter num 260\n",
            "loss 5.346244812011719 average time 0.002651945099952562 iter num 280\n",
            "loss 2.280728578567505 average time 0.0026520746966464987 iter num 300\n",
            "loss 0.8660078048706055 average time 0.0026449883468728785 iter num 320\n",
            "loss 0.006136939860880375 average time 0.0026455416146745846 iter num 340\n",
            "loss 59.217247009277344 average time 0.0026462600721970375 iter num 360\n",
            "loss 0.8063265085220337 average time 0.002647366486833466 iter num 380\n",
            "loss 4.198102951049805 average time 0.0026606984649924924 iter num 400\n",
            "loss 2.1466166973114014 average time 0.0026576225666542 iter num 420\n",
            "loss 17.25970458984375 average time 0.002659300224993124 iter num 440\n",
            "loss 13.628817558288574 average time 0.0026669600326109186 iter num 460\n",
            "loss 25.098669052124023 average time 0.0026644940916601928 iter num 480\n",
            "loss 0.05268184840679169 average time 0.0026526464479975404 iter num 500\n",
            "loss 0.5287248492240906 average time 0.002654096148073502 iter num 520\n",
            "loss 3.2680728435516357 average time 0.0026407883314850215 iter num 540\n",
            "loss 1.0165002346038818 average time 0.0026297651196403294 iter num 560\n",
            "loss 54.01311492919922 average time 0.0026175594344686973 iter num 580\n",
            "loss 0.00195329450070858 average time 0.0026064010033132945 iter num 600\n",
            "loss 84.77700805664062 average time 0.002616360330622199 iter num 620\n",
            "loss 0.9501679539680481 average time 0.0026169970156018963 iter num 640\n",
            "loss 49.89151382446289 average time 0.0026074304363371058 iter num 660\n",
            "loss 8.032938003540039 average time 0.0025958818749747 iter num 680\n",
            "loss 0.33011171221733093 average time 0.002593920925688248 iter num 700\n",
            "loss 1.7866507768630981 average time 0.0025865198360886803 iter num 720\n",
            "loss 0.34658655524253845 average time 0.002579203663493457 iter num 740\n",
            "loss 8.67909049987793 average time 0.0025719000499832057 iter num 760\n",
            "loss 2.213709592819214 average time 0.002568754652544997 iter num 780\n",
            "loss 3.7159833908081055 average time 0.0025626214024782714 iter num 800\n",
            "loss 0.05046993866562843 average time 0.002556600912175338 iter num 820\n",
            "loss 0.20833396911621094 average time 0.0025496453464083535 iter num 840\n",
            "loss 0.000127498060464859 average time 0.0025469299720731046 iter num 860\n",
            "loss 0.2955928146839142 average time 0.0025523534045264157 iter num 880\n",
            "loss 3.266735315322876 average time 0.0025474483133176465 iter num 900\n",
            "loss 0.10423904657363892 average time 0.0025413222423732963 iter num 920\n",
            "loss 0.4474674165248871 average time 0.002548223314870677 iter num 940\n",
            "loss 0.009088516235351562 average time 0.0025423553239363626 iter num 960\n",
            "loss 2.520209550857544 average time 0.0025376769326297165 iter num 980\n",
            "loss 0.065985307097435 average time 0.002531955273982021 iter num 1000\n",
            "loss 9.983501434326172 average time 0.0031131073498727345 iter num 20\n",
            "loss 6.547026634216309 average time 0.0026970371247898584 iter num 40\n",
            "loss 0.271160751581192 average time 0.0027800379498330585 iter num 60\n",
            "loss 0.5795589685440063 average time 0.0026625422623737906 iter num 80\n",
            "loss 3.6645114421844482 average time 0.0026101807198392634 iter num 100\n",
            "loss 6.313254356384277 average time 0.0025561915748918787 iter num 120\n",
            "loss 6.603116512298584 average time 0.002514023885617332 iter num 140\n",
            "loss 36.75205612182617 average time 0.00248246538743615 iter num 160\n",
            "loss 1.5953192710876465 average time 0.0024995402721894305 iter num 180\n",
            "loss 0.8278290033340454 average time 0.002479046169974026 iter num 200\n",
            "loss 25.128108978271484 average time 0.00245682501360782 iter num 220\n",
            "loss 0.5399623513221741 average time 0.0024730619708028217 iter num 240\n",
            "loss 3.8570289611816406 average time 0.0024640001807361284 iter num 260\n",
            "loss 0.09926499426364899 average time 0.0024456280678220666 iter num 280\n",
            "loss 3.5724148750305176 average time 0.0024306477566339406 iter num 300\n",
            "loss 0.9271328449249268 average time 0.0024185861218484206 iter num 320\n",
            "loss 0.7000548839569092 average time 0.002430441249977294 iter num 340\n",
            "loss 1.3331235647201538 average time 0.002447616113856081 iter num 360\n",
            "loss 0.12275006622076035 average time 0.0024405622210092828 iter num 380\n",
            "loss 4.111499309539795 average time 0.0024328180474503824 iter num 400\n",
            "loss 4.580960750579834 average time 0.002428580971397986 iter num 420\n",
            "loss 2.842097043991089 average time 0.0024208297431538416 iter num 440\n",
            "loss 1.9688301086425781 average time 0.0024221431217167425 iter num 460\n",
            "loss 7.862313747406006 average time 0.002417226014567101 iter num 480\n",
            "loss 11.228023529052734 average time 0.0024145675239851698 iter num 500\n",
            "loss 1.2696106433868408 average time 0.0024115976942189615 iter num 520\n",
            "loss 4.801960468292236 average time 0.0024113010185054145 iter num 540\n",
            "loss 0.2603473663330078 average time 0.002408815974974589 iter num 560\n",
            "loss 0.17698855698108673 average time 0.00241209360169862 iter num 580\n",
            "loss 5.067994594573975 average time 0.002415542851637535 iter num 600\n",
            "loss 0.011420775204896927 average time 0.002410727248359528 iter num 620\n",
            "loss 5.761435508728027 average time 0.002406502010916256 iter num 640\n",
            "loss 1.0118578672409058 average time 0.002403225577252284 iter num 660\n",
            "loss 11413.373046875 average time 0.002398455124974883 iter num 680\n",
            "loss 0.646622896194458 average time 0.0024084530342614536 iter num 700\n",
            "loss 0.1983264684677124 average time 0.0024045374235937642 iter num 720\n",
            "loss 0.3638053834438324 average time 0.0024007067432280198 iter num 740\n",
            "loss 0.31359726190567017 average time 0.0023973315118215204 iter num 760\n",
            "loss 9.901996612548828 average time 0.0023943268692094605 iter num 780\n",
            "loss 0.037594664841890335 average time 0.0023919982387292293 iter num 800\n",
            "loss 1.1533856391906738 average time 0.0023972775390020836 iter num 820\n",
            "loss 1.0365451574325562 average time 0.0023943598356925663 iter num 840\n",
            "loss 0.39960238337516785 average time 0.002393734846493824 iter num 860\n",
            "loss 0.687826931476593 average time 0.0023902697420246774 iter num 880\n",
            "loss 0.3612535297870636 average time 0.002387949947757685 iter num 900\n",
            "loss 0.35273438692092896 average time 0.0023849068130264483 iter num 920\n",
            "loss 8.294999122619629 average time 0.00239108018295736 iter num 940\n",
            "loss 0.1052384227514267 average time 0.002391478682276708 iter num 960\n",
            "loss 0.6004618406295776 average time 0.00239456659386336 iter num 980\n",
            "loss 1.1197808980941772 average time 0.0023918909019885175 iter num 1000\n",
            "loss 2.1673483848571777 average time 0.0028791478000130153 iter num 20\n",
            "loss 0.014806236140429974 average time 0.002589941025053122 iter num 40\n",
            "loss 12.80554485321045 average time 0.0026395964666941535 iter num 60\n",
            "loss 2.8648569583892822 average time 0.0025480360875690168 iter num 80\n",
            "loss 0.0011263721389696002 average time 0.0024915422900267004 iter num 100\n",
            "loss 0.08008603006601334 average time 0.0024519558583354713 iter num 120\n",
            "loss 41.03632354736328 average time 0.0024468399928602074 iter num 140\n",
            "loss 0.00040838259155862033 average time 0.002423727475002124 iter num 160\n",
            "loss 38.210792541503906 average time 0.0024106453388918047 iter num 180\n",
            "loss 3.56255841255188 average time 0.0023954755749855394 iter num 200\n",
            "loss 1.9946357011795044 average time 0.0023858799363634634 iter num 220\n",
            "loss 0.05528581514954567 average time 0.002379214379152472 iter num 240\n",
            "loss 0.8728731870651245 average time 0.0023702431461480535 iter num 260\n",
            "loss 6.771124839782715 average time 0.0023759962428617394 iter num 280\n",
            "loss 8.408791542053223 average time 0.0023733457133312185 iter num 300\n",
            "loss 16.775846481323242 average time 0.0023691794906255835 iter num 320\n",
            "loss 1.647315263748169 average time 0.0023667280147171422 iter num 340\n",
            "loss 10.175482749938965 average time 0.002361184911119886 iter num 360\n",
            "loss 0.7101641893386841 average time 0.0023860589368508186 iter num 380\n",
            "loss 0.1941278725862503 average time 0.0023824818174944086 iter num 400\n",
            "loss 23.81951141357422 average time 0.0023800029547731225 iter num 420\n",
            "loss 13.945443153381348 average time 0.0023751611909119674 iter num 440\n",
            "loss 0.11566755920648575 average time 0.0023689262108785875 iter num 460\n",
            "loss 0.5300405025482178 average time 0.0023707933166823144 iter num 480\n",
            "loss 6.26418924331665 average time 0.002366416744014714 iter num 500\n",
            "loss 0.7947697043418884 average time 0.002365042503858534 iter num 520\n",
            "loss 0.7626288533210754 average time 0.0023630820389101887 iter num 540\n",
            "loss 2.863178253173828 average time 0.002361107139300397 iter num 560\n",
            "loss 72.57331085205078 average time 0.0023590317896629003 iter num 580\n",
            "loss 0.35473495721817017 average time 0.0023587580233440045 iter num 600\n",
            "loss 0.12974879145622253 average time 0.002357075593555501 iter num 620\n",
            "loss 6.225895404815674 average time 0.0023548220984366706 iter num 640\n",
            "loss 23.782514572143555 average time 0.002352479124232504 iter num 660\n",
            "loss 2.492164373397827 average time 0.0023497337367510175 iter num 680\n",
            "loss 0.3153899610042572 average time 0.002346639875704568 iter num 700\n",
            "loss 0.06417668610811234 average time 0.0023446247152732113 iter num 720\n",
            "loss 0.05758890509605408 average time 0.0023442254081011333 iter num 740\n",
            "loss 0.00942838191986084 average time 0.002349528367106981 iter num 760\n",
            "loss 90.18231964111328 average time 0.0023586634500017494 iter num 780\n",
            "loss 44.59962463378906 average time 0.00236181479125662 iter num 800\n",
            "loss 438.4479064941406 average time 0.0023716264170860354 iter num 820\n",
            "loss 0.0013264553854241967 average time 0.002370496695246922 iter num 840\n",
            "loss 8.460973739624023 average time 0.0023672596348914402 iter num 860\n",
            "loss 4.917148590087891 average time 0.0023655801181886008 iter num 880\n",
            "loss 3.7448060512542725 average time 0.002365031134447943 iter num 900\n",
            "loss 0.3899005353450775 average time 0.002364177191307333 iter num 920\n",
            "loss 32.41885757446289 average time 0.002362377114899031 iter num 940\n",
            "loss 0.29854443669319153 average time 0.002359467202090097 iter num 960\n",
            "loss 0.5439895391464233 average time 0.0023581710204149315 iter num 980\n",
            "loss 6.325529098510742 average time 0.0023640612790168233 iter num 1000\n",
            "loss 0.044916462153196335 average time 0.0032343496997782493 iter num 20\n",
            "loss 171.52981567382812 average time 0.002769493300047543 iter num 40\n",
            "loss 0.47700926661491394 average time 0.0026211123166831386 iter num 60\n",
            "loss 67.6509780883789 average time 0.0025442932625310277 iter num 80\n",
            "loss 21.362123489379883 average time 0.0025181212699862954 iter num 100\n",
            "loss 1.2238497734069824 average time 0.002471161866727319 iter num 120\n",
            "loss 0.38458317518234253 average time 0.002450603821502487 iter num 140\n",
            "loss 1.0561563968658447 average time 0.002426116256287969 iter num 160\n",
            "loss 14.860992431640625 average time 0.0024265633389202574 iter num 180\n",
            "loss 1.3698956966400146 average time 0.002413854500046 iter num 200\n",
            "loss 0.5645216703414917 average time 0.0023988482273208235 iter num 220\n",
            "loss 9.469769477844238 average time 0.0023939074333611645 iter num 240\n",
            "loss 1.551478385925293 average time 0.0024200181769629125 iter num 260\n",
            "loss 35.451324462890625 average time 0.002426989692893195 iter num 280\n",
            "loss 31.839937210083008 average time 0.002416128426684736 iter num 300\n",
            "loss 6.1213507652282715 average time 0.002410499246883546 iter num 320\n",
            "loss 0.012433052994310856 average time 0.0024173081294226423 iter num 340\n",
            "loss 0.007870280183851719 average time 0.0024114131750189293 iter num 360\n",
            "loss 6.974410057067871 average time 0.0024020484368616293 iter num 380\n",
            "loss 0.1431727260351181 average time 0.002422692102527435 iter num 400\n",
            "loss 5.628907680511475 average time 0.002417247288130533 iter num 420\n",
            "loss 4.8011369705200195 average time 0.002412133415935552 iter num 440\n",
            "loss 9.29837703704834 average time 0.002405247636978975 iter num 460\n",
            "loss 45.62323760986328 average time 0.002399422912518882 iter num 480\n",
            "loss 1.0594059228897095 average time 0.002412038014012069 iter num 500\n",
            "loss 23.02090835571289 average time 0.0024088059903918362 iter num 520\n",
            "loss 1.8775399923324585 average time 0.0024050386000015822 iter num 540\n",
            "loss 3.058255672454834 average time 0.0024019857285793476 iter num 560\n",
            "loss 1.6493819952011108 average time 0.002412982460351361 iter num 580\n",
            "loss 9.608524322509766 average time 0.002407992615001907 iter num 600\n",
            "loss 5.113715171813965 average time 0.002404487158063632 iter num 620\n",
            "loss 3.0966408252716064 average time 0.0024005490796810136 iter num 640\n",
            "loss 0.2695283889770508 average time 0.0024056618909057623 iter num 660\n",
            "loss 5.813653469085693 average time 0.002402046958816166 iter num 680\n",
            "loss 0.029706470668315887 average time 0.002408432639991328 iter num 700\n",
            "loss 0.000505693955346942 average time 0.0024078937666571518 iter num 720\n",
            "loss 0.000308990478515625 average time 0.0024031306418839595 iter num 740\n",
            "loss 5.523254871368408 average time 0.00240213884736764 iter num 760\n",
            "loss 88.57746124267578 average time 0.0024014375423086257 iter num 780\n",
            "loss 2.331299304962158 average time 0.0024103892100038136 iter num 800\n",
            "loss 10.065098762512207 average time 0.0024147045024442266 iter num 820\n",
            "loss 3.665271043777466 average time 0.0024206608904803165 iter num 840\n",
            "loss 0.39473041892051697 average time 0.002422103649999816 iter num 860\n",
            "loss 0.26277825236320496 average time 0.0024205857636326817 iter num 880\n",
            "loss 0.45992210507392883 average time 0.0024273024711106298 iter num 900\n",
            "loss 0.016364052891731262 average time 0.002434914894555455 iter num 920\n",
            "loss 0.001186050707474351 average time 0.002438876401058533 iter num 940\n",
            "loss 0.08913873136043549 average time 0.002443859409364298 iter num 960\n",
            "loss 8.114622116088867 average time 0.0024466421806005664 iter num 980\n",
            "loss 6.977937698364258 average time 0.0024505511229835973 iter num 1000\n",
            "loss 9.122222900390625 average time 0.002945574950263108 iter num 20\n",
            "loss 3.4996206760406494 average time 0.0027408529000695126 iter num 40\n",
            "loss 18.8743953704834 average time 0.0027013499666585024 iter num 60\n",
            "loss 0.0817803218960762 average time 0.002652005837467186 iter num 80\n",
            "loss 0.33460795879364014 average time 0.0026652028199168855 iter num 100\n",
            "loss 0.714852511882782 average time 0.0026724342832646166 iter num 120\n",
            "loss 20.581483840942383 average time 0.0026606232213582967 iter num 140\n",
            "loss 0.010940950363874435 average time 0.0027004049562037837 iter num 160\n",
            "loss 5.315185070037842 average time 0.0026951411221994527 iter num 180\n",
            "loss 2.68046236038208 average time 0.0026685772449582144 iter num 200\n",
            "loss 0.24353447556495667 average time 0.002670181559030673 iter num 220\n",
            "loss 3.0872230529785156 average time 0.0026472093541163606 iter num 240\n",
            "loss 1.1033717393875122 average time 0.002638085653800842 iter num 260\n",
            "loss 2.652391195297241 average time 0.0026263715178369497 iter num 280\n",
            "loss 0.025503605604171753 average time 0.002629064253311905 iter num 300\n",
            "loss 78.52286529541016 average time 0.00262096895310151 iter num 320\n",
            "loss 0.2760723829269409 average time 0.0026361745941037096 iter num 340\n",
            "loss 6.774162769317627 average time 0.002635953566661758 iter num 360\n",
            "loss 0.9287027716636658 average time 0.002634296026290509 iter num 380\n",
            "loss 5.608639240264893 average time 0.0026382065549705657 iter num 400\n",
            "loss 7.843317985534668 average time 0.002642365126164458 iter num 420\n",
            "loss 1.5161616802215576 average time 0.002643062795438957 iter num 440\n",
            "loss 0.19913987815380096 average time 0.0026394026434702583 iter num 460\n",
            "loss 1.4358209371566772 average time 0.002629512274999494 iter num 480\n",
            "loss 0.4985845983028412 average time 0.0026286010359835928 iter num 500\n",
            "loss 273.33367919921875 average time 0.0026280508692217643 iter num 520\n",
            "loss 8.476781845092773 average time 0.0026288459277734716 iter num 540\n",
            "loss 0.05288022756576538 average time 0.0026318179785611 iter num 560\n",
            "loss 1.0152246952056885 average time 0.0026264184206787645 iter num 580\n",
            "loss 2.3622424602508545 average time 0.002637391041656277 iter num 600\n",
            "loss 0.4098629355430603 average time 0.002634829133864602 iter num 620\n",
            "loss 9.131926536560059 average time 0.0026349616140578292 iter num 640\n",
            "loss 2.1764872074127197 average time 0.002639918587873112 iter num 660\n",
            "loss 0.1537313610315323 average time 0.0026425633750022824 iter num 680\n",
            "loss 0.6814778447151184 average time 0.0026432556242850427 iter num 700\n",
            "loss 28.179790496826172 average time 0.002640281876387639 iter num 720\n",
            "loss 0.7336570620536804 average time 0.0026443572959529726 iter num 740\n",
            "loss 0.5687428116798401 average time 0.0026369155815772452 iter num 760\n",
            "loss 3.060844659805298 average time 0.0026340767243546465 iter num 780\n",
            "loss 309.10797119140625 average time 0.0026331653437409843 iter num 800\n",
            "loss 6.826328277587891 average time 0.0026297069914484957 iter num 820\n",
            "loss 37.74345016479492 average time 0.002623251065456532 iter num 840\n",
            "loss 115.17578887939453 average time 0.00262109154881368 iter num 860\n",
            "loss 24.381919860839844 average time 0.002620261315893334 iter num 880\n",
            "loss 7.584167957305908 average time 0.0026191718510886453 iter num 900\n",
            "loss 0.12824521958827972 average time 0.0026141392945488486 iter num 920\n",
            "loss 0.004213287960737944 average time 0.002616788811688008 iter num 940\n",
            "loss 1.2881778478622437 average time 0.0026189693468628168 iter num 960\n",
            "loss 7.859340667724609 average time 0.002618336940807295 iter num 980\n",
            "loss 0.01985049620270729 average time 0.0026176820309920003 iter num 1000\n",
            "loss 47.202598571777344 average time 0.0030260450001151186 iter num 20\n",
            "loss 1.3346952199935913 average time 0.003066922975040143 iter num 40\n",
            "loss 0.2407974898815155 average time 0.0029196894667014323 iter num 60\n",
            "loss 16.392005920410156 average time 0.0028504201873829514 iter num 80\n",
            "loss 6.946634292602539 average time 0.002825379759888165 iter num 100\n",
            "loss 54.61738967895508 average time 0.002815691708307592 iter num 120\n",
            "loss 3.321058750152588 average time 0.002778974228554684 iter num 140\n",
            "loss 23.924392700195312 average time 0.002766852868762726 iter num 160\n",
            "loss 0.013581739738583565 average time 0.0027396686444565907 iter num 180\n",
            "loss 5.885876655578613 average time 0.002720822995006529 iter num 200\n",
            "loss 0.33236098289489746 average time 0.002718198563674047 iter num 220\n",
            "loss 1.0460759401321411 average time 0.002712563079201876 iter num 240\n",
            "loss 0.004827594850212336 average time 0.0026946535884795034 iter num 260\n",
            "loss 9.09776782989502 average time 0.0026872994000184136 iter num 280\n",
            "loss 0.007192456163465977 average time 0.0026847430600112905 iter num 300\n",
            "loss 2.1693906784057617 average time 0.0026874050093908864 iter num 320\n",
            "loss 1.4178458452224731 average time 0.002687188120596736 iter num 340\n",
            "loss 0.0011955450754612684 average time 0.00267783684444617 iter num 360\n",
            "loss 2.482177734375 average time 0.0026688994421228446 iter num 380\n",
            "loss 14.291793823242188 average time 0.0026709522175315213 iter num 400\n",
            "loss 3.79095196723938 average time 0.0026606125952769485 iter num 420\n",
            "loss 1.436195731163025 average time 0.0026567190000316094 iter num 440\n",
            "loss 80.69843292236328 average time 0.0026564856217626822 iter num 460\n",
            "loss 0.7322975993156433 average time 0.0026712544708478465 iter num 480\n",
            "loss 0.30906999111175537 average time 0.0026674725060147468 iter num 500\n",
            "loss 3.694424629211426 average time 0.0026598691288654665 iter num 520\n",
            "loss 3.244077205657959 average time 0.0026583466889119503 iter num 540\n",
            "loss 0.0043100458569824696 average time 0.0026620173768183773 iter num 560\n",
            "loss 4.752358913421631 average time 0.0026612703586642024 iter num 580\n",
            "loss 152.9054412841797 average time 0.0026651849100471736 iter num 600\n",
            "loss 99.64143371582031 average time 0.0026674013210140402 iter num 620\n",
            "loss 0.8654186129570007 average time 0.002660398928168206 iter num 640\n",
            "loss 22.94886016845703 average time 0.002657762936404183 iter num 660\n",
            "loss 0.005859246477484703 average time 0.00265496787946016 iter num 680\n",
            "loss 3.222210168838501 average time 0.002653971888612432 iter num 700\n",
            "loss 0.017524465918540955 average time 0.002643493061155924 iter num 720\n",
            "loss 10.312446594238281 average time 0.0026330817797733707 iter num 740\n",
            "loss 0.023129649460315704 average time 0.0026250286329310545 iter num 760\n",
            "loss 0.3013013005256653 average time 0.002629088607721851 iter num 780\n",
            "loss 4.157371520996094 average time 0.0026210221875294336 iter num 800\n",
            "loss 0.371049702167511 average time 0.00261245738051579 iter num 820\n",
            "loss 90.94554138183594 average time 0.0026068011345506377 iter num 840\n",
            "loss 0.021454503759741783 average time 0.002600057984909654 iter num 860\n",
            "loss 0.23450644314289093 average time 0.0025915935966188707 iter num 880\n",
            "loss 0.2237069457769394 average time 0.002587226351131701 iter num 900\n",
            "loss 3.458523750305176 average time 0.00258829526958083 iter num 920\n",
            "loss 3.84647274017334 average time 0.0025819311893776993 iter num 940\n",
            "loss 2.545185089111328 average time 0.0025746708395994727 iter num 960\n",
            "loss 0.16682294011116028 average time 0.0025696911561365653 iter num 980\n",
            "loss 0.2691076993942261 average time 0.0025646564430171566 iter num 1000\n",
            "loss 0.13263928890228271 average time 0.003342976299973088 iter num 20\n",
            "loss 0.8976410031318665 average time 0.0028333936750641444 iter num 40\n",
            "loss 0.8147060871124268 average time 0.0026332422667110222 iter num 60\n",
            "loss 0.06492900103330612 average time 0.0025671829375596643 iter num 80\n",
            "loss 44.38553237915039 average time 0.002514309590023913 iter num 100\n",
            "loss 0.39081650972366333 average time 0.0024763653916731227 iter num 120\n",
            "loss 0.770368754863739 average time 0.0024895446714643704 iter num 140\n",
            "loss 3.062704563140869 average time 0.0024959555562418245 iter num 160\n",
            "loss 0.24079374969005585 average time 0.0024685049611030585 iter num 180\n",
            "loss 0.0071073006838560104 average time 0.0024540828449880793 iter num 200\n",
            "loss 8.666755676269531 average time 0.002438239113623488 iter num 220\n",
            "loss 2.2946741580963135 average time 0.0024241708583152407 iter num 240\n",
            "loss 0.029944956302642822 average time 0.0024482676269074613 iter num 260\n",
            "loss 14.33679485321045 average time 0.0024395264142835263 iter num 280\n",
            "loss 42.22550582885742 average time 0.0024292226133244793 iter num 300\n",
            "loss 0.2881464660167694 average time 0.0024211441468821706 iter num 320\n",
            "loss 0.0008808041457086802 average time 0.0024330586058835357 iter num 340\n",
            "loss 11.760872840881348 average time 0.0024257073305408187 iter num 360\n",
            "loss 7.557591438293457 average time 0.0024174011815662915 iter num 380\n",
            "loss 19.22322654724121 average time 0.0024102382624914755 iter num 400\n",
            "loss 0.06777777522802353 average time 0.0024045534999978762 iter num 420\n",
            "loss 4.19175910949707 average time 0.0023994133090912907 iter num 440\n",
            "loss 0.17374466359615326 average time 0.0023951198130421486 iter num 460\n",
            "loss 12.973615646362305 average time 0.0024096579249923405 iter num 480\n",
            "loss 0.4855518341064453 average time 0.0024037859099844353 iter num 500\n",
            "loss 0.9992011189460754 average time 0.0023995446730728314 iter num 520\n",
            "loss 11.444969177246094 average time 0.0023950151296250827 iter num 540\n",
            "loss 5.260702133178711 average time 0.002388549169631915 iter num 560\n",
            "loss 6.290979385375977 average time 0.0023911503465350163 iter num 580\n",
            "loss 2.050687313079834 average time 0.0023881674133250878 iter num 600\n",
            "loss 0.6948238611221313 average time 0.0023852300145101196 iter num 620\n",
            "loss 7.48740816116333 average time 0.0023886850296804597 iter num 640\n",
            "loss 0.023389136418700218 average time 0.002401991146965002 iter num 660\n",
            "loss 2.5214874744415283 average time 0.002399283673519355 iter num 680\n",
            "loss 6.047579765319824 average time 0.002404190752851199 iter num 700\n",
            "loss 7.366731643676758 average time 0.00241202860416302 iter num 720\n",
            "loss 1.6730705499649048 average time 0.0024103883040535604 iter num 740\n",
            "loss 10.546290397644043 average time 0.00241112713289639 iter num 760\n",
            "loss 25.02533531188965 average time 0.0024134618500004134 iter num 780\n",
            "loss 7.712706089019775 average time 0.002415091084999403 iter num 800\n",
            "loss 43.27484130859375 average time 0.0024134134646396333 iter num 820\n",
            "loss 0.8703247904777527 average time 0.002411336713090523 iter num 840\n",
            "loss 0.05695989355444908 average time 0.0024129116709297894 iter num 860\n",
            "loss 0.17854544520378113 average time 0.002408764969320807 iter num 880\n",
            "loss 15.546683311462402 average time 0.0024058642744502223 iter num 900\n",
            "loss 69.26721954345703 average time 0.0024040656652173113 iter num 920\n",
            "loss 0.061512112617492676 average time 0.0024050315010599468 iter num 940\n",
            "loss 1.8105010986328125 average time 0.0024063066937552928 iter num 960\n",
            "loss 3.637207508087158 average time 0.0024035380530648934 iter num 980\n",
            "loss 0.004897821228951216 average time 0.002401672713996959 iter num 1000\n",
            "loss 0.024601055309176445 average time 0.0029514050001125725 iter num 20\n",
            "loss 28.198505401611328 average time 0.002637450925021767 iter num 40\n",
            "loss 1.2102093696594238 average time 0.002519478416676672 iter num 60\n",
            "loss 14.047554969787598 average time 0.0024589400249851678 iter num 80\n",
            "loss 1.666918396949768 average time 0.002465137149938528 iter num 100\n",
            "loss 2.9546523094177246 average time 0.0024259501833057582 iter num 120\n",
            "loss 3.854527235031128 average time 0.002407169628570825 iter num 140\n",
            "loss 0.6142858266830444 average time 0.002399827606279814 iter num 160\n",
            "loss 0.016742944717407227 average time 0.0023909885722383072 iter num 180\n",
            "loss 0.6388120055198669 average time 0.0024519491499995637 iter num 200\n",
            "loss 1.8917810916900635 average time 0.00243430551364244 iter num 220\n",
            "loss 0.5075748562812805 average time 0.0024245680791712704 iter num 240\n",
            "loss 0.8763046264648438 average time 0.0024189139423190053 iter num 260\n",
            "loss 0.021666046231985092 average time 0.002422993546438842 iter num 280\n",
            "loss 6.219586372375488 average time 0.002412873086680823 iter num 300\n",
            "loss 0.991777241230011 average time 0.0024062308500276686 iter num 320\n",
            "loss 1.9580607414245605 average time 0.0024028310706051023 iter num 340\n",
            "loss 0.1046137884259224 average time 0.002398042363923499 iter num 360\n",
            "loss 0.138914093375206 average time 0.002392694234238565 iter num 380\n",
            "loss 6.985114574432373 average time 0.0023872872300307792 iter num 400\n",
            "loss 4.263084888458252 average time 0.002425591990500141 iter num 420\n",
            "loss 0.6284849047660828 average time 0.002420143752293701 iter num 440\n",
            "loss 0.33702412247657776 average time 0.002417319532623483 iter num 460\n",
            "loss 0.33130592107772827 average time 0.002411855275014811 iter num 480\n",
            "loss 5.155916213989258 average time 0.0024114658160142425 iter num 500\n",
            "loss 313.96923828125 average time 0.002409646557711872 iter num 520\n",
            "loss 1.5774840116500854 average time 0.0024062022814952664 iter num 540\n",
            "loss 0.5563115477561951 average time 0.002401873564287728 iter num 560\n",
            "loss 2.9661483764648438 average time 0.002402489943104793 iter num 580\n",
            "loss 9.573366165161133 average time 0.002414792829998381 iter num 600\n",
            "loss 8.470341682434082 average time 0.00241564815000123 iter num 620\n",
            "loss 0.022630250081419945 average time 0.002423664117191038 iter num 640\n",
            "loss 27.677976608276367 average time 0.0024395991954599705 iter num 660\n",
            "loss 15.103914260864258 average time 0.0024372861632427347 iter num 680\n",
            "loss 3.010438919067383 average time 0.002444868625726875 iter num 700\n",
            "loss 4.159518241882324 average time 0.002447238148627346 iter num 720\n",
            "loss 0.011030799709260464 average time 0.0024477292729898183 iter num 740\n",
            "loss 0.002699444303289056 average time 0.002442188542119383 iter num 760\n",
            "loss 35.72604751586914 average time 0.002438460634631412 iter num 780\n",
            "loss 26.013214111328125 average time 0.0024346552775114105 iter num 800\n",
            "loss 3.46223521232605 average time 0.0024369365939159384 iter num 820\n",
            "loss 0.864879310131073 average time 0.0024333468226337748 iter num 840\n",
            "loss 0.41798150539398193 average time 0.0024318372581504707 iter num 860\n",
            "loss 0.3292246460914612 average time 0.002429491379557062 iter num 880\n",
            "loss 0.7057340145111084 average time 0.002435385567787307 iter num 900\n",
            "loss 2.7420268058776855 average time 0.002432900797833534 iter num 920\n",
            "loss 0.10114876925945282 average time 0.002431422224470496 iter num 940\n",
            "loss 7.896815299987793 average time 0.0024297277031242476 iter num 960\n",
            "loss 0.11259785294532776 average time 0.0024336328673524228 iter num 980\n",
            "loss 0.002393134869635105 average time 0.0024363570750065263 iter num 1000\n",
            "loss 0.2972891628742218 average time 0.002906498800166446 iter num 20\n",
            "loss 0.439421683549881 average time 0.0027093579500615307 iter num 40\n",
            "loss 0.05748780816793442 average time 0.002660838000095585 iter num 60\n",
            "loss 0.1718442440032959 average time 0.002603712312566131 iter num 80\n",
            "loss 0.4498385787010193 average time 0.0025464220500907688 iter num 100\n",
            "loss 7.281045913696289 average time 0.0025769371417027286 iter num 120\n",
            "loss 10.702360153198242 average time 0.0025777045143383606 iter num 140\n",
            "loss 0.24394315481185913 average time 0.002547894362533043 iter num 160\n",
            "loss 1.346351981163025 average time 0.002557976383377536 iter num 180\n",
            "loss 18.456775665283203 average time 0.002544323325073492 iter num 200\n",
            "loss 0.8409935832023621 average time 0.0025795481546083466 iter num 220\n",
            "loss 1.2026022672653198 average time 0.0025814287084055345 iter num 240\n",
            "loss 5.38769006729126 average time 0.002564350142382374 iter num 260\n",
            "loss 1.7436683177947998 average time 0.0025456623500758726 iter num 280\n",
            "loss 3.133836798951961e-05 average time 0.0025524000667549746 iter num 300\n",
            "loss 13.553339958190918 average time 0.0025402794719525446 iter num 320\n",
            "loss 3.0364468097686768 average time 0.002530229917706225 iter num 340\n",
            "loss 8.074004173278809 average time 0.002540624227817211 iter num 360\n",
            "loss 2.147757053375244 average time 0.00254274578687967 iter num 380\n",
            "loss 7.557297706604004 average time 0.002533294827530881 iter num 400\n",
            "loss 54.41628646850586 average time 0.0025239662738299343 iter num 420\n",
            "loss 11.595471382141113 average time 0.002513507552298093 iter num 440\n",
            "loss 0.8206893801689148 average time 0.0025334302217743243 iter num 460\n",
            "loss 0.009162123315036297 average time 0.0025278747062695097 iter num 480\n",
            "loss 1.350226640701294 average time 0.0025210983640135964 iter num 500\n",
            "loss 6.5292840003967285 average time 0.0025184235211642004 iter num 520\n",
            "loss 1.7467525005340576 average time 0.0025133341833410397 iter num 540\n",
            "loss 0.43391457200050354 average time 0.0025090342143000402 iter num 560\n",
            "loss 25.275182723999023 average time 0.0025164912034566 iter num 580\n",
            "loss 0.9813140630722046 average time 0.0025148840100064265 iter num 600\n",
            "loss 40.36871337890625 average time 0.0025108271032261275 iter num 620\n",
            "loss 1.457099437713623 average time 0.002505503376556817 iter num 640\n",
            "loss 0.07151465117931366 average time 0.0025025120302939975 iter num 660\n",
            "loss 0.25777432322502136 average time 0.0024994722455818083 iter num 680\n",
            "loss 0.2862207591533661 average time 0.0024961861185511225 iter num 700\n",
            "loss 117.68952178955078 average time 0.00250205067637176 iter num 720\n",
            "loss 0.38068971037864685 average time 0.0024962658986353472 iter num 740\n",
            "loss 0.06549437344074249 average time 0.002499443621036335 iter num 760\n",
            "loss 1.0783908367156982 average time 0.002501776797418223 iter num 780\n",
            "loss 0.5891205668449402 average time 0.002502831157480614 iter num 800\n",
            "loss 3.197524070739746 average time 0.002500229001199797 iter num 820\n",
            "loss 9.300796508789062 average time 0.002500227584509741 iter num 840\n",
            "loss 22.153987884521484 average time 0.0024975426278932753 iter num 860\n",
            "loss 1.1160944700241089 average time 0.002502150854535433 iter num 880\n",
            "loss 2.490767478942871 average time 0.0025040217688789804 iter num 900\n",
            "loss 0.9281172752380371 average time 0.0025076184402085186 iter num 920\n",
            "loss 0.032898109406232834 average time 0.0025095204170146974 iter num 940\n",
            "loss 0.0011673838598653674 average time 0.002513640259371641 iter num 960\n",
            "loss 0.2603375017642975 average time 0.0025186293499988395 iter num 980\n",
            "loss 1.7992725372314453 average time 0.002522511352002766 iter num 1000\n",
            "loss 1.1752526760101318 average time 0.003551607649842481 iter num 20\n",
            "loss 0.06604604423046112 average time 0.0031334759749825024 iter num 40\n",
            "loss 0.33117446303367615 average time 0.003011296983216501 iter num 60\n",
            "loss 32.20539855957031 average time 0.0029125209873654967 iter num 80\n",
            "loss 0.3086777627468109 average time 0.0028710341698933916 iter num 100\n",
            "loss 1.5191928148269653 average time 0.0028504522082736608 iter num 120\n",
            "loss 0.3694601058959961 average time 0.0028086956356414053 iter num 140\n",
            "loss 1.4973490238189697 average time 0.002802827868697477 iter num 160\n",
            "loss 0.9347257018089294 average time 0.0027770929944280296 iter num 180\n",
            "loss 0.0680660828948021 average time 0.0027349171849982666 iter num 200\n",
            "loss 0.4251622259616852 average time 0.0027374890545367883 iter num 220\n",
            "loss 0.006226644851267338 average time 0.0027337565124450217 iter num 240\n",
            "loss 1.1933869123458862 average time 0.002706717411477327 iter num 260\n",
            "loss 0.00012758001685142517 average time 0.0026945356142407816 iter num 280\n",
            "loss 154.66729736328125 average time 0.002686741183297272 iter num 300\n",
            "loss 0.22456513345241547 average time 0.0027086583374739347 iter num 320\n",
            "loss 0.08274862170219421 average time 0.002697379958804317 iter num 340\n",
            "loss 0.004861048888415098 average time 0.002691166694436712 iter num 360\n",
            "loss 0.1578054279088974 average time 0.0026795239394615286 iter num 380\n",
            "loss 0.0833829939365387 average time 0.002677468599981694 iter num 400\n",
            "loss 4.809419631958008 average time 0.002676707102359831 iter num 420\n",
            "loss 2.4740588665008545 average time 0.0026790427295261244 iter num 440\n",
            "loss 4.819062232971191 average time 0.0026650182630280892 iter num 460\n",
            "loss 0.8630709648132324 average time 0.0026645295833266874 iter num 480\n",
            "loss 11.633484840393066 average time 0.0026617802739929176 iter num 500\n",
            "loss 0.10047776252031326 average time 0.002666344767311994 iter num 520\n",
            "loss 1.2582345008850098 average time 0.002666307192588714 iter num 540\n",
            "loss 0.06549368798732758 average time 0.0026598666803465676 iter num 560\n",
            "loss 0.47178593277931213 average time 0.0026577029310295795 iter num 580\n",
            "loss 9.48194694519043 average time 0.0026567511583319475 iter num 600\n",
            "loss 0.9419461488723755 average time 0.0026559947822446 iter num 620\n",
            "loss 4.155038356781006 average time 0.002655921249990456 iter num 640\n",
            "loss 0.017909908667206764 average time 0.002655733665139423 iter num 660\n",
            "loss 1.0957635641098022 average time 0.0026553607632195052 iter num 680\n",
            "loss 0.3778564929962158 average time 0.002655685485699775 iter num 700\n",
            "loss 0.1898406744003296 average time 0.0026547895985989576 iter num 720\n",
            "loss 1.1169731616973877 average time 0.0026555669134919494 iter num 740\n",
            "loss 6.546963214874268 average time 0.0026566423289224126 iter num 760\n",
            "loss 0.42397114634513855 average time 0.002665818006384003 iter num 780\n",
            "loss 7.994407653808594 average time 0.0026677439237232647 iter num 800\n",
            "loss 12.903608322143555 average time 0.0026638546353418995 iter num 820\n",
            "loss 1.5913374423980713 average time 0.002663441202353819 iter num 840\n",
            "loss 0.06273044645786285 average time 0.002659248368575412 iter num 860\n",
            "loss 0.897391676902771 average time 0.002660445811331804 iter num 880\n",
            "loss 3.8457248210906982 average time 0.00265867472108059 iter num 900\n",
            "loss 0.19345496594905853 average time 0.0026592449054098086 iter num 920\n",
            "loss 2.336042881011963 average time 0.0026589210169964024 iter num 940\n",
            "loss 1.9575750827789307 average time 0.002662760281231158 iter num 960\n",
            "loss 0.0006676093325950205 average time 0.00266480677344923 iter num 980\n",
            "loss 0.050323497503995895 average time 0.0026642486449782155 iter num 1000\n",
            "loss 29.773944854736328 average time 0.0033972736496252764 iter num 20\n",
            "loss 1.9339599609375 average time 0.0030454881247351296 iter num 40\n",
            "loss 61.40239334106445 average time 0.0028877618331534906 iter num 60\n",
            "loss 7.994235038757324 average time 0.0028330158497965386 iter num 80\n",
            "loss 10.982650756835938 average time 0.0027917225998680805 iter num 100\n",
            "loss 0.8966525793075562 average time 0.002718150133220358 iter num 120\n",
            "loss 6.569065570831299 average time 0.0026993919642206623 iter num 140\n",
            "loss 4.356547832489014 average time 0.002681609087449033 iter num 160\n",
            "loss 1.2875680923461914 average time 0.0026733786777387854 iter num 180\n",
            "loss 4.07454776763916 average time 0.002673370319962487 iter num 200\n",
            "loss 2.616330862045288 average time 0.00269988144541871 iter num 220\n",
            "loss 14.646889686584473 average time 0.002695876462447207 iter num 240\n",
            "loss 1.4516984224319458 average time 0.002697512826867191 iter num 260\n",
            "loss 0.004662578925490379 average time 0.002697705032083572 iter num 280\n",
            "loss 7.426947116851807 average time 0.002715684049932558 iter num 300\n",
            "loss 18.02996063232422 average time 0.0027181225187007385 iter num 320\n",
            "loss 2.520136833190918 average time 0.0027090323411197033 iter num 340\n",
            "loss 0.009525260888040066 average time 0.002701074027729394 iter num 360\n",
            "loss 0.18929174542427063 average time 0.002722080928900763 iter num 380\n",
            "loss 0.052386894822120667 average time 0.002724075524952241 iter num 400\n",
            "loss 0.041225679218769073 average time 0.0027209491190010988 iter num 420\n",
            "loss 64.04431915283203 average time 0.002720614145416469 iter num 440\n",
            "loss 18.20252227783203 average time 0.0027178849086616852 iter num 460\n",
            "loss 0.33574753999710083 average time 0.002716196708286134 iter num 480\n",
            "loss 0.0011539526749402285 average time 0.0027122596239605628 iter num 500\n",
            "loss 13.247563362121582 average time 0.0027111394768850844 iter num 520\n",
            "loss 2.9096856117248535 average time 0.002708226751831346 iter num 540\n",
            "loss 1.850473403930664 average time 0.0027037262928290926 iter num 560\n",
            "loss 0.4987664222717285 average time 0.0027036388017003103 iter num 580\n",
            "loss 2.0558691024780273 average time 0.0027041407583055844 iter num 600\n",
            "loss 3.9783618450164795 average time 0.0027058082418959877 iter num 620\n",
            "loss 0.3522169291973114 average time 0.0027035213265321546 iter num 640\n",
            "loss 164.4547119140625 average time 0.0027189168772427806 iter num 660\n",
            "loss 516.1007080078125 average time 0.002717622530853452 iter num 680\n",
            "loss 4.848012924194336 average time 0.0027179672299800068 iter num 700\n",
            "loss 0.27730700373649597 average time 0.0027179310097001992 iter num 720\n",
            "loss 0.0006268896977417171 average time 0.002719370525652709 iter num 740\n",
            "loss 17.097074508666992 average time 0.0027203669776123492 iter num 760\n",
            "loss 0.5802938938140869 average time 0.002715918546143187 iter num 780\n",
            "loss 0.16661402583122253 average time 0.0027076103549870823 iter num 800\n",
            "loss 6.510728359222412 average time 0.0027012486548678347 iter num 820\n",
            "loss 0.09877917170524597 average time 0.002696313991659086 iter num 840\n",
            "loss 1.36887788772583 average time 0.002696210589523574 iter num 860\n",
            "loss 0.25390589237213135 average time 0.0026932924818083848 iter num 880\n",
            "loss 0.2419184297323227 average time 0.0026937462611001843 iter num 900\n",
            "loss 0.046855442225933075 average time 0.002694647416293937 iter num 920\n",
            "loss 1.7682859897613525 average time 0.002687193635098625 iter num 940\n",
            "loss 0.0007171840406954288 average time 0.0026782560895734758 iter num 960\n",
            "loss 10.643712043762207 average time 0.0026714485795811035 iter num 980\n",
            "loss 4.746116638183594 average time 0.002673060204986541 iter num 1000\n",
            "loss 23.514270782470703 average time 0.0029854843999601146 iter num 20\n",
            "loss 0.295378714799881 average time 0.00267762339994988 iter num 40\n",
            "loss 0.026133093982934952 average time 0.0025797415166077067 iter num 60\n",
            "loss 4.775514602661133 average time 0.002535678874914993 iter num 80\n",
            "loss 0.06436823308467865 average time 0.0024824371799331856 iter num 100\n",
            "loss 4.550907135009766 average time 0.0025542965250072787 iter num 120\n",
            "loss 1.4692720174789429 average time 0.0025175340357236563 iter num 140\n",
            "loss 6.1161041259765625 average time 0.002504542937526821 iter num 160\n",
            "loss 0.23980453610420227 average time 0.002487049738889861 iter num 180\n",
            "loss 217.796630859375 average time 0.0024702459900072427 iter num 200\n",
            "loss 336.8061828613281 average time 0.0024608040272803256 iter num 220\n",
            "loss 189.70169067382812 average time 0.002460240254170761 iter num 240\n",
            "loss 3.577738046646118 average time 0.0024578549153934895 iter num 260\n",
            "loss 0.7001697421073914 average time 0.002447799535743148 iter num 280\n",
            "loss 65.68440246582031 average time 0.0024647818700032076 iter num 300\n",
            "loss 11.346867561340332 average time 0.0024709475843906147 iter num 320\n",
            "loss 4.04523229598999 average time 0.0024920487823799384 iter num 340\n",
            "loss 0.45002281665802 average time 0.00248318537779192 iter num 360\n",
            "loss 1.86247980594635 average time 0.002475367218434449 iter num 380\n",
            "loss 0.37105435132980347 average time 0.0024693996400174 iter num 400\n",
            "loss 7.925012111663818 average time 0.0024629006523874913 iter num 420\n",
            "loss 0.012188415043056011 average time 0.0024739975363693456 iter num 440\n",
            "loss 0.3663060665130615 average time 0.0024664134304380834 iter num 460\n",
            "loss 0.01402486115694046 average time 0.0024714686479152684 iter num 480\n",
            "loss 3.08498477935791 average time 0.0024671701380029843 iter num 500\n",
            "loss 0.15758047997951508 average time 0.00246274160770274 iter num 520\n",
            "loss 0.19222471117973328 average time 0.002458393405561731 iter num 540\n",
            "loss 1.898290753364563 average time 0.0024639496428627743 iter num 560\n",
            "loss 1.6751830577850342 average time 0.0024558515206990704 iter num 580\n",
            "loss 0.29857179522514343 average time 0.0024505503033439404 iter num 600\n",
            "loss 1.9399007558822632 average time 0.002444640290330778 iter num 620\n",
            "loss 2.1501057147979736 average time 0.0024410058593844043 iter num 640\n",
            "loss 9.396859169006348 average time 0.002435196759093246 iter num 660\n",
            "loss 4.795442581176758 average time 0.002431733788246086 iter num 680\n",
            "loss 0.8876468539237976 average time 0.0024271220700107475 iter num 700\n",
            "loss 102.40287780761719 average time 0.002426581729175976 iter num 720\n",
            "loss 18.266572952270508 average time 0.0024225296946103815 iter num 740\n",
            "loss 2.8481969833374023 average time 0.0024191882486990692 iter num 760\n",
            "loss 0.1838323175907135 average time 0.0024160023730846894 iter num 780\n",
            "loss 6.493452548980713 average time 0.0024125013350044357 iter num 800\n",
            "loss 0.34079718589782715 average time 0.0024093796768328304 iter num 820\n",
            "loss 2.7487268447875977 average time 0.002413963167860597 iter num 840\n",
            "loss 0.2555707097053528 average time 0.0024197471162805476 iter num 860\n",
            "loss 0.4952756464481354 average time 0.002422633065915844 iter num 880\n",
            "loss 0.6557932496070862 average time 0.002421705970007477 iter num 900\n",
            "loss 14.028303146362305 average time 0.0024181198717463342 iter num 920\n",
            "loss 0.9757651090621948 average time 0.0024155615244706766 iter num 940\n",
            "loss 0.2912895083427429 average time 0.002413945654171812 iter num 960\n",
            "loss 0.15901455283164978 average time 0.002410725151023552 iter num 980\n",
            "loss 1.1890579462051392 average time 0.002420450401010385 iter num 1000\n",
            "loss 2.4966228008270264 average time 0.0029185628996856393 iter num 20\n",
            "loss 71.13734436035156 average time 0.0026376046248515195 iter num 40\n",
            "loss 0.003328097751364112 average time 0.0026231880498623164 iter num 60\n",
            "loss 3.2133965492248535 average time 0.002538250512338891 iter num 80\n",
            "loss 0.3392505347728729 average time 0.002488668169844459 iter num 100\n",
            "loss 6.382762432098389 average time 0.0025092078665087075 iter num 120\n",
            "loss 4.474321365356445 average time 0.0024775966569904996 iter num 140\n",
            "loss 0.030218299478292465 average time 0.0024549509561097695 iter num 160\n",
            "loss 8.264923095703125 average time 0.002428225783185351 iter num 180\n",
            "loss 1.1533231735229492 average time 0.0024436814248656445 iter num 200\n",
            "loss 0.0686536654829979 average time 0.0024303545407499106 iter num 220\n",
            "loss 1.7831475734710693 average time 0.002459556666531171 iter num 240\n",
            "loss 0.31849968433380127 average time 0.0024512628383420703 iter num 260\n",
            "loss 152.3726806640625 average time 0.0024408531356194933 iter num 280\n",
            "loss 1.2050445079803467 average time 0.0024302653265779856 iter num 300\n",
            "loss 0.5134730935096741 average time 0.002421054362412178 iter num 320\n",
            "loss 0.8380663394927979 average time 0.00241252415580675 iter num 340\n",
            "loss 1.332189917564392 average time 0.0024079731554947003 iter num 360\n",
            "loss 2.070136785507202 average time 0.002401426792044061 iter num 380\n",
            "loss 6.719151020050049 average time 0.002393236469938529 iter num 400\n",
            "loss 1.4794193506240845 average time 0.0023887695308942402 iter num 420\n",
            "loss 0.05449730157852173 average time 0.002386333720398232 iter num 440\n",
            "loss 1.5406898260116577 average time 0.0023929436629852876 iter num 460\n",
            "loss 17.84381103515625 average time 0.0023861947103606933 iter num 480\n",
            "loss 0.9833765625953674 average time 0.0023865986899436393 iter num 500\n",
            "loss 23.26366424560547 average time 0.002386532151855975 iter num 520\n",
            "loss 1.631801962852478 average time 0.0024017643999252837 iter num 540\n",
            "loss 0.3238261938095093 average time 0.002397389169569968 iter num 560\n",
            "loss 2.0353405475616455 average time 0.002392196058553964 iter num 580\n",
            "loss 0.5757145285606384 average time 0.002399198813269929 iter num 600\n",
            "loss 29.52933120727539 average time 0.0023968135628380086 iter num 620\n",
            "loss 0.0035322795156389475 average time 0.0023941295171283627 iter num 640\n",
            "loss 0.9352098107337952 average time 0.0023917351302384995 iter num 660\n",
            "loss 0.31813380122184753 average time 0.0023927696631691267 iter num 680\n",
            "loss 0.2510519325733185 average time 0.002393015302792004 iter num 700\n",
            "loss 2.305799722671509 average time 0.0023892262388269755 iter num 720\n",
            "loss 3.7732067108154297 average time 0.002401718843179264 iter num 740\n",
            "loss 2.171020269393921 average time 0.0024053936788851916 iter num 760\n",
            "loss 0.005587412044405937 average time 0.0024014290307045136 iter num 780\n",
            "loss 0.020447809249162674 average time 0.002399239613678219 iter num 800\n",
            "loss 40.457855224609375 average time 0.002396972547491559 iter num 820\n",
            "loss 0.015542786568403244 average time 0.0023952749915960815 iter num 840\n",
            "loss 0.04042869433760643 average time 0.002392447953414291 iter num 860\n",
            "loss 3.7691025733947754 average time 0.0023883806090183994 iter num 880\n",
            "loss 39.58551788330078 average time 0.0023903208010395043 iter num 900\n",
            "loss 1.217637300491333 average time 0.0023881873260131175 iter num 920\n",
            "loss 7.7570953369140625 average time 0.0023842656797162993 iter num 940\n",
            "loss 1.796530842781067 average time 0.0023821354072254054 iter num 960\n",
            "loss 5.060882091522217 average time 0.0023878185091216067 iter num 980\n",
            "loss 0.9617055058479309 average time 0.002396356722940254 iter num 1000\n",
            "loss 1.6555668115615845 average time 0.0028955156500160228 iter num 20\n",
            "loss 27.64691925048828 average time 0.0025698132749766957 iter num 40\n",
            "loss 70.77205657958984 average time 0.00246613944997686 iter num 60\n",
            "loss 1.0059913396835327 average time 0.0024000767749384976 iter num 80\n",
            "loss 0.45759373903274536 average time 0.0023820998599512677 iter num 100\n",
            "loss 1.4087257385253906 average time 0.002367348174948347 iter num 120\n",
            "loss 0.12472715973854065 average time 0.002365135428499343 iter num 140\n",
            "loss 22.968965530395508 average time 0.002381413449961656 iter num 160\n",
            "loss 1.1433207988739014 average time 0.002371737383297538 iter num 180\n",
            "loss 2.127711534500122 average time 0.002365174244969239 iter num 200\n",
            "loss 3.2534892559051514 average time 0.002375713022684067 iter num 220\n",
            "loss 0.36833134293556213 average time 0.0023706252374419514 iter num 240\n",
            "loss 0.003654845990240574 average time 0.0023619374884219723 iter num 260\n",
            "loss 3.3353495597839355 average time 0.002354037578541985 iter num 280\n",
            "loss 67.81623840332031 average time 0.002351379529973201 iter num 300\n",
            "loss 4.434042930603027 average time 0.002360369674983076 iter num 320\n",
            "loss 2.0703125 average time 0.002370125082325103 iter num 340\n",
            "loss 0.05165989324450493 average time 0.0023656062916415977 iter num 360\n",
            "loss 1.7189031839370728 average time 0.002362018071031152 iter num 380\n",
            "loss 19.745155334472656 average time 0.002359424442479394 iter num 400\n",
            "loss 1.1524076461791992 average time 0.0023612171571325492 iter num 420\n",
            "loss 0.27851402759552 average time 0.002359242245442643 iter num 440\n",
            "loss 0.1836908757686615 average time 0.00236958114782006 iter num 460\n",
            "loss 8.249904203694314e-05 average time 0.0023642762166673492 iter num 480\n",
            "loss 6.703912258148193 average time 0.0023609499300109747 iter num 500\n",
            "loss 15.439146041870117 average time 0.0023570887365517244 iter num 520\n",
            "loss 0.0007451793644577265 average time 0.002353347144445353 iter num 540\n",
            "loss 0.0018224597442895174 average time 0.0023510349892863556 iter num 560\n",
            "loss 0.09752069413661957 average time 0.0023483379482780132 iter num 580\n",
            "loss 6.036725997924805 average time 0.002346826478336273 iter num 600\n",
            "loss 53.15412521362305 average time 0.0023453156758067406 iter num 620\n",
            "loss 17.138111114501953 average time 0.00235213654218569 iter num 640\n",
            "loss 0.07192783802747726 average time 0.002351732445450497 iter num 660\n",
            "loss 68.16034698486328 average time 0.0023496116514599955 iter num 680\n",
            "loss 2.147242784500122 average time 0.0023500618671252077 iter num 700\n",
            "loss 7.441217422485352 average time 0.002347447180543188 iter num 720\n",
            "loss 0.11958451569080353 average time 0.00234624638377362 iter num 740\n",
            "loss 1.8357653617858887 average time 0.002344742122360051 iter num 760\n",
            "loss 0.9157518148422241 average time 0.002347052619221265 iter num 780\n",
            "loss 0.11479189246892929 average time 0.0023537596149913044 iter num 800\n",
            "loss 8.135847091674805 average time 0.0023531341243807863 iter num 820\n",
            "loss 0.005724542308598757 average time 0.002351533697615845 iter num 840\n",
            "loss 92.19410705566406 average time 0.002349574810464113 iter num 860\n",
            "loss 3.4530458450317383 average time 0.0023511728136327292 iter num 880\n",
            "loss 0.5413620471954346 average time 0.002348951963326221 iter num 900\n",
            "loss 1.4394434690475464 average time 0.002346611590208973 iter num 920\n",
            "loss 12.331257820129395 average time 0.0023478666255327203 iter num 940\n",
            "loss 0.6249334812164307 average time 0.0023479982666685826 iter num 960\n",
            "loss 0.030891001224517822 average time 0.0023458380367331728 iter num 980\n",
            "loss 20.440370559692383 average time 0.0023456259539962046 iter num 1000\n",
            "loss 3.287064790725708 average time 0.002887734899923089 iter num 20\n",
            "loss 286.931884765625 average time 0.00275146304984446 iter num 40\n",
            "loss 10.087137222290039 average time 0.0027375534332046906 iter num 60\n",
            "loss 7.7834320068359375 average time 0.0026522159374053446 iter num 80\n",
            "loss 1.5688486099243164 average time 0.0026360439699055858 iter num 100\n",
            "loss 5.14069938659668 average time 0.0026283129582679978 iter num 120\n",
            "loss 2.821119546890259 average time 0.002630361921390951 iter num 140\n",
            "loss 30.417238235473633 average time 0.00264070873122364 iter num 160\n",
            "loss 0.021852020174264908 average time 0.0026528341110962275 iter num 180\n",
            "loss 5.2667365074157715 average time 0.002648395679971145 iter num 200\n",
            "loss 0.23100964725017548 average time 0.0026601197590852364 iter num 220\n",
            "loss 10.290678024291992 average time 0.0026574277208358883 iter num 240\n",
            "loss 5.696474075317383 average time 0.0026681212692332896 iter num 260\n",
            "loss 1.114772915840149 average time 0.0026628914392793895 iter num 280\n",
            "loss 2.9853665828704834 average time 0.002656835109992244 iter num 300\n",
            "loss 0.08428574353456497 average time 0.0026634556968758716 iter num 320\n",
            "loss 5.7774152755737305 average time 0.0026574590411762664 iter num 340\n",
            "loss 9.750324249267578 average time 0.002665137377769295 iter num 360\n",
            "loss 7.106337547302246 average time 0.002668517234197727 iter num 380\n",
            "loss 0.06378475576639175 average time 0.002664368532473418 iter num 400\n",
            "loss 0.42958828806877136 average time 0.0026646658071210064 iter num 420\n",
            "loss 32.16584014892578 average time 0.002649529209074072 iter num 440\n",
            "loss 1.0166730880737305 average time 0.00265152374346223 iter num 460\n",
            "loss 0.13756056129932404 average time 0.0026503354874876095 iter num 480\n",
            "loss 1.1661609411239624 average time 0.0026503357179863086 iter num 500\n",
            "loss 0.10938388109207153 average time 0.002651697684597401 iter num 520\n",
            "loss 7.693743705749512 average time 0.002647434548133013 iter num 540\n",
            "loss 6.419708251953125 average time 0.002649004028558011 iter num 560\n",
            "loss 13.998143196105957 average time 0.0026466483413749866 iter num 580\n",
            "loss 0.7980548739433289 average time 0.002647318870000769 iter num 600\n",
            "loss 1.2652666568756104 average time 0.002643828998386579 iter num 620\n",
            "loss 1.5568090677261353 average time 0.0026388291750038206 iter num 640\n",
            "loss 2.0298945903778076 average time 0.0026359838757619427 iter num 660\n",
            "loss 0.02171773463487625 average time 0.0026500696941371537 iter num 680\n",
            "loss 0.2753142714500427 average time 0.002649280138586099 iter num 700\n",
            "loss 3.7828495502471924 average time 0.0026426328055650728 iter num 720\n",
            "loss 1.2180498838424683 average time 0.0026373360837931466 iter num 740\n",
            "loss 1.806709885597229 average time 0.0026369139921084035 iter num 760\n",
            "loss 0.047190502285957336 average time 0.0026308756794885713 iter num 780\n",
            "loss 0.3744795024394989 average time 0.0026271027137522653 iter num 800\n",
            "loss 0.849867582321167 average time 0.00262790180244027 iter num 820\n",
            "loss 647.5120849609375 average time 0.002629921653574673 iter num 840\n",
            "loss 6.468978404998779 average time 0.002623693704656965 iter num 860\n",
            "loss 0.2184230238199234 average time 0.0026263516909177105 iter num 880\n",
            "loss 2.6659023761749268 average time 0.002629031737786944 iter num 900\n",
            "loss 14.377931594848633 average time 0.002626907365222154 iter num 920\n",
            "loss 0.7869670987129211 average time 0.002625721394680171 iter num 940\n",
            "loss 7.239807605743408 average time 0.00262420104688393 iter num 960\n",
            "loss 4.2260212898254395 average time 0.0026247219142904363 iter num 980\n",
            "loss 0.0034744779113680124 average time 0.0026263709340055355 iter num 1000\n",
            "loss 50.604522705078125 average time 0.003209457799948723 iter num 20\n",
            "loss 0.16705985367298126 average time 0.002885367175076681 iter num 40\n",
            "loss 2.026048421859741 average time 0.0027311384167054103 iter num 60\n",
            "loss 248.5799560546875 average time 0.0027008967375650172 iter num 80\n",
            "loss 51.647544860839844 average time 0.002804684080056177 iter num 100\n",
            "loss 0.25941604375839233 average time 0.0027614214083617602 iter num 120\n",
            "loss 46.681861877441406 average time 0.002799165978623413 iter num 140\n",
            "loss 20.628515243530273 average time 0.0027486404625165052 iter num 160\n",
            "loss 17.47514533996582 average time 0.0027247552722150835 iter num 180\n",
            "loss 13.477372169494629 average time 0.0027054901549672648 iter num 200\n",
            "loss 1.5481178760528564 average time 0.0026897633226905205 iter num 220\n",
            "loss 0.6702824234962463 average time 0.0026926673082774263 iter num 240\n",
            "loss 0.6736956238746643 average time 0.0026789134807376496 iter num 260\n",
            "loss 14.636613845825195 average time 0.00267754423567307 iter num 280\n",
            "loss 182.0613555908203 average time 0.0026583251132918425 iter num 300\n",
            "loss 14.033275604248047 average time 0.0026604108968570016 iter num 320\n",
            "loss 0.35946014523506165 average time 0.002662674114681602 iter num 340\n",
            "loss 4.292609214782715 average time 0.0026653468388859536 iter num 360\n",
            "loss 1.0036349296569824 average time 0.0026499249447337397 iter num 380\n",
            "loss 11.465109825134277 average time 0.0026502638175134054 iter num 400\n",
            "loss 4.883624076843262 average time 0.0026562344190573465 iter num 420\n",
            "loss 14.244012832641602 average time 0.002656171579556857 iter num 440\n",
            "loss 39.684268951416016 average time 0.0026435317565301373 iter num 460\n",
            "loss 0.5242809057235718 average time 0.002647972085435413 iter num 480\n",
            "loss 48.986610412597656 average time 0.002640971052020177 iter num 500\n",
            "loss 1.3749008178710938 average time 0.0026382961038577306 iter num 520\n",
            "loss 22.657766342163086 average time 0.0026350688814899413 iter num 540\n",
            "loss 17.584518432617188 average time 0.0026315620214355864 iter num 560\n",
            "loss 17.766193389892578 average time 0.0026308270517269006 iter num 580\n",
            "loss 0.17423388361930847 average time 0.0026478856116621805 iter num 600\n",
            "loss 0.0158445592969656 average time 0.0026489800016098607 iter num 620\n",
            "loss 0.21359163522720337 average time 0.002651444443745277 iter num 640\n",
            "loss 4.393890380859375 average time 0.0026526964727192092 iter num 660\n",
            "loss 10.342972755432129 average time 0.002654224004401626 iter num 680\n",
            "loss 4.212778568267822 average time 0.0026508083085588752 iter num 700\n",
            "loss 3.2893338203430176 average time 0.0026535154013749384 iter num 720\n",
            "loss 0.4589012861251831 average time 0.0026531443580982317 iter num 740\n",
            "loss 0.8200242519378662 average time 0.002649551548670627 iter num 760\n",
            "loss 8.884376525878906 average time 0.002642099692298544 iter num 780\n",
            "loss 2.809943437576294 average time 0.002644807536237295 iter num 800\n",
            "loss 3.454935073852539 average time 0.0026415477804797908 iter num 820\n",
            "loss 26.819520950317383 average time 0.002634867919037528 iter num 840\n",
            "loss 132.8298797607422 average time 0.002636005287198248 iter num 860\n",
            "loss 1.3496383428573608 average time 0.00263409827385782 iter num 880\n",
            "loss 0.42135223746299744 average time 0.0026359122299921484 iter num 900\n",
            "loss 0.0002891302574425936 average time 0.0026369604097770047 iter num 920\n",
            "loss 0.07286510616540909 average time 0.002637732644675549 iter num 940\n",
            "loss 3.3084287643432617 average time 0.0026390575489548002 iter num 960\n",
            "loss 8.668855667114258 average time 0.00263666384080909 iter num 980\n",
            "loss 10.19700813293457 average time 0.00263139830199907 iter num 1000\n",
            "loss 0.14978161454200745 average time 0.003175332049977442 iter num 20\n",
            "loss 0.8908591866493225 average time 0.0027244373999110393 iter num 40\n",
            "loss 0.6416622996330261 average time 0.0026280557665510668 iter num 60\n",
            "loss 50.13339614868164 average time 0.0025381598248259253 iter num 80\n",
            "loss 8.675899505615234 average time 0.00249115118986083 iter num 100\n",
            "loss 2.898587465286255 average time 0.0024938896665541205 iter num 120\n",
            "loss 2.182783603668213 average time 0.00247025937847606 iter num 140\n",
            "loss 5.053318977355957 average time 0.00244283391866702 iter num 160\n",
            "loss 11.992324829101562 average time 0.0024292207165874263 iter num 180\n",
            "loss 3.6708016395568848 average time 0.002447477244941183 iter num 200\n",
            "loss 0.014647071249783039 average time 0.0024341171681209577 iter num 220\n",
            "loss 8.551526069641113 average time 0.0024223865582825967 iter num 240\n",
            "loss 17.360183715820312 average time 0.002412221876882261 iter num 260\n",
            "loss 7.6659088134765625 average time 0.002406324664246183 iter num 280\n",
            "loss 6.548412799835205 average time 0.0024134505933034235 iter num 300\n",
            "loss 66.2183609008789 average time 0.0024073164530989287 iter num 320\n",
            "loss 13.710351943969727 average time 0.0024005260999675716 iter num 340\n",
            "loss 1.1603412628173828 average time 0.0024000322555214853 iter num 360\n",
            "loss 17.85454559326172 average time 0.00239627066576328 iter num 380\n",
            "loss 0.8163332939147949 average time 0.002389994027466855 iter num 400\n",
            "loss 164.59642028808594 average time 0.0023835898856868014 iter num 420\n",
            "loss 11.525769233703613 average time 0.002381057074981899 iter num 440\n",
            "loss 80.44935607910156 average time 0.00237802068259834 iter num 460\n",
            "loss 4.299187183380127 average time 0.0023869763437384486 iter num 480\n",
            "loss 1.6345807313919067 average time 0.002382286592001037 iter num 500\n",
            "loss 19.896696090698242 average time 0.0024053421211507296 iter num 520\n",
            "loss 2.578902006149292 average time 0.0023988345425836827 iter num 540\n",
            "loss 0.5672880411148071 average time 0.0023953058357035063 iter num 560\n",
            "loss 19.548524856567383 average time 0.002391599612050852 iter num 580\n",
            "loss 4.35982084274292 average time 0.002395155198316085 iter num 600\n",
            "loss 0.0062513817101716995 average time 0.002392199635467536 iter num 620\n",
            "loss 9.357656478881836 average time 0.002388637778111047 iter num 640\n",
            "loss 0.28372108936309814 average time 0.002385395845444829 iter num 660\n",
            "loss 0.07445130497217178 average time 0.0023852545823474965 iter num 680\n",
            "loss 8.651421546936035 average time 0.002382447295707867 iter num 700\n",
            "loss 0.06378830969333649 average time 0.0023839443722130857 iter num 720\n",
            "loss 19.227373123168945 average time 0.0023827395810676042 iter num 740\n",
            "loss 0.10262209177017212 average time 0.0023842740473547135 iter num 760\n",
            "loss 4.243417263031006 average time 0.0023813104551080847 iter num 780\n",
            "loss 14.872788429260254 average time 0.0023796377612279682 iter num 800\n",
            "loss 0.0005834477487951517 average time 0.0023769978353434785 iter num 820\n",
            "loss 0.030575327575206757 average time 0.0023762685821198137 iter num 840\n",
            "loss 26.839279174804688 average time 0.002375266769742962 iter num 860\n",
            "loss 4.00909948348999 average time 0.0023725006102019754 iter num 880\n",
            "loss 0.12415589392185211 average time 0.0023708142133020576 iter num 900\n",
            "loss 0.12704510986804962 average time 0.0023705320445356927 iter num 920\n",
            "loss 0.3907375931739807 average time 0.002369338679760558 iter num 940\n",
            "loss 135.75062561035156 average time 0.0023737850218481073 iter num 960\n",
            "loss 10.034382820129395 average time 0.002374187278546371 iter num 980\n",
            "loss 0.4759349226951599 average time 0.00237636176797605 iter num 1000\n",
            "loss 7.89000940322876 average time 0.0031867641000644653 iter num 20\n",
            "loss 0.9605336785316467 average time 0.002737824725045357 iter num 40\n",
            "loss 30.686792373657227 average time 0.0025808104833231482 iter num 60\n",
            "loss 20.368274688720703 average time 0.002522783237532167 iter num 80\n",
            "loss 1.602840542793274 average time 0.002484625409979344 iter num 100\n",
            "loss 10.792702674865723 average time 0.0024441693999809407 iter num 120\n",
            "loss 2.7164909839630127 average time 0.0024210644214170836 iter num 140\n",
            "loss 2.8921561241149902 average time 0.0024006847937357635 iter num 160\n",
            "loss 0.9456965923309326 average time 0.0023889247444458307 iter num 180\n",
            "loss 1.901161551475525 average time 0.0024281185649761027 iter num 200\n",
            "loss 0.4525136351585388 average time 0.0024145618408924333 iter num 220\n",
            "loss 0.4490330219268799 average time 0.002424067654146711 iter num 240\n",
            "loss 9.890955924987793 average time 0.0024144854461225734 iter num 260\n",
            "loss 4.9686455726623535 average time 0.0024091065428170364 iter num 280\n",
            "loss 2.34623384475708 average time 0.0024011010832994846 iter num 300\n",
            "loss 6.930737495422363 average time 0.002403286212478406 iter num 320\n",
            "loss 24.04131507873535 average time 0.0023965020617331047 iter num 340\n",
            "loss 6.394448280334473 average time 0.0023933533055141096 iter num 360\n",
            "loss 4.241622447967529 average time 0.0023897680815456335 iter num 380\n",
            "loss 15.744437217712402 average time 0.002385614124973472 iter num 400\n",
            "loss 1.396653175354004 average time 0.0023882943404454895 iter num 420\n",
            "loss 0.9400706887245178 average time 0.0023997793636019856 iter num 440\n",
            "loss 2.2570278644561768 average time 0.002398757417354911 iter num 460\n",
            "loss 0.6516541242599487 average time 0.0024037581957979154 iter num 480\n",
            "loss 6.669328212738037 average time 0.002398297303967411 iter num 500\n",
            "loss 14.312178611755371 average time 0.0023944789980410303 iter num 520\n",
            "loss 0.7569445967674255 average time 0.002391654648110691 iter num 540\n",
            "loss 3.0260262489318848 average time 0.0023875138374575854 iter num 560\n",
            "loss 11.632391929626465 average time 0.002386964424103694 iter num 580\n",
            "loss 0.7800095081329346 average time 0.0023813203749674964 iter num 600\n",
            "loss 0.2148190140724182 average time 0.002377753820928774 iter num 620\n",
            "loss 1.0457618236541748 average time 0.002374870801517659 iter num 640\n",
            "loss 3.1908836364746094 average time 0.002381559949949543 iter num 660\n",
            "loss 0.16466115415096283 average time 0.0023783631352457366 iter num 680\n",
            "loss 94.99935913085938 average time 0.002376292405666131 iter num 700\n",
            "loss 0.036452583968639374 average time 0.002374883780506328 iter num 720\n",
            "loss 0.061368390917778015 average time 0.002373536755355933 iter num 740\n",
            "loss 6.715809345245361 average time 0.0023705640946924465 iter num 760\n",
            "loss 0.04379492998123169 average time 0.0023686874884170277 iter num 780\n",
            "loss 0.39135488867759705 average time 0.0023660349149599823 iter num 800\n",
            "loss 6.628998279571533 average time 0.0023649167975302744 iter num 820\n",
            "loss 0.0452532134950161 average time 0.0023627509237723558 iter num 840\n",
            "loss 0.1196424812078476 average time 0.002375573779028305 iter num 860\n",
            "loss 0.14646948873996735 average time 0.0023741042920081864 iter num 880\n",
            "loss 11.221927642822266 average time 0.0023726096921846975 iter num 900\n",
            "loss 23.38127326965332 average time 0.0023825116749657867 iter num 920\n",
            "loss 1.5014344453811646 average time 0.0023803770786895604 iter num 940\n",
            "loss 0.8662518858909607 average time 0.0023823816510078664 iter num 960\n",
            "loss 0.19585783779621124 average time 0.0023801630101731963 iter num 980\n",
            "loss 0.22033576667308807 average time 0.00237765683996804 iter num 1000\n",
            "loss 14.243350982666016 average time 0.0029087003002132407 iter num 20\n",
            "loss 7.019613265991211 average time 0.00259334672505247 iter num 40\n",
            "loss 17.467498779296875 average time 0.0025048771833098725 iter num 60\n",
            "loss 3.8931186199188232 average time 0.002464082899996356 iter num 80\n",
            "loss 24.02265167236328 average time 0.002420941340024001 iter num 100\n",
            "loss 0.03036460280418396 average time 0.0024225905916712993 iter num 120\n",
            "loss 4.566930294036865 average time 0.002424976371418909 iter num 140\n",
            "loss 22.869909286499023 average time 0.0024093229812478965 iter num 160\n",
            "loss 2.0929484367370605 average time 0.0023942496389079476 iter num 180\n",
            "loss 0.7702680826187134 average time 0.002389351070005432 iter num 200\n",
            "loss 40.1588020324707 average time 0.0023804119818288945 iter num 220\n",
            "loss 11.15180492401123 average time 0.0023712131291707315 iter num 240\n",
            "loss 47.66099166870117 average time 0.002368079199991021 iter num 260\n",
            "loss 0.22951053082942963 average time 0.0023662220500097774 iter num 280\n",
            "loss 36.440128326416016 average time 0.0023595257533512875 iter num 300\n",
            "loss 40.13013458251953 average time 0.0023624403281417017 iter num 320\n",
            "loss 26.475975036621094 average time 0.002380786555905241 iter num 340\n",
            "loss 22.675636291503906 average time 0.002375070458366382 iter num 360\n",
            "loss 2.8741135597229004 average time 0.002385128055290184 iter num 380\n",
            "loss 0.08769591152667999 average time 0.0023801022525185545 iter num 400\n",
            "loss 169.59263610839844 average time 0.002376138357162528 iter num 420\n",
            "loss 0.014175406657159328 average time 0.002375950838660918 iter num 440\n",
            "loss 1.5266239643096924e-05 average time 0.0023706321652397213 iter num 460\n",
            "loss 8.965106964111328 average time 0.0023681373729383874 iter num 480\n",
            "loss 1.6863070726394653 average time 0.002365053488014382 iter num 500\n",
            "loss 24.418777465820312 average time 0.002363420451939209 iter num 520\n",
            "loss 37.29622268676758 average time 0.0023612773222373143 iter num 540\n",
            "loss 3.9521398544311523 average time 0.0023594648357305103 iter num 560\n",
            "loss 5.886283874511719 average time 0.0023738508120851325 iter num 580\n",
            "loss 69.39350891113281 average time 0.0023719973183597177 iter num 600\n",
            "loss 0.17971880733966827 average time 0.0023746097726108284 iter num 620\n",
            "loss 14.000826835632324 average time 0.002369610089093044 iter num 640\n",
            "loss 0.2382345050573349 average time 0.002366585496995619 iter num 660\n",
            "loss 66.98381805419922 average time 0.002365862220620543 iter num 680\n",
            "loss 0.7263708710670471 average time 0.002362356050037176 iter num 700\n",
            "loss 0.19027267396450043 average time 0.0023609707125337486 iter num 720\n",
            "loss 59.69092559814453 average time 0.002359347012202921 iter num 740\n",
            "loss 2.4794678688049316 average time 0.0023681792974122417 iter num 760\n",
            "loss 11.019694328308105 average time 0.0023674075000436018 iter num 780\n",
            "loss 0.34830614924430847 average time 0.002365490936299466 iter num 800\n",
            "loss 0.0900728702545166 average time 0.0023641171915143077 iter num 820\n",
            "loss 318.22247314453125 average time 0.0023637612024339475 iter num 840\n",
            "loss 0.0011798052582889795 average time 0.0023631729547052473 iter num 860\n",
            "loss 18.452253341674805 average time 0.002362402121643341 iter num 880\n",
            "loss 0.5903480052947998 average time 0.002360884498941434 iter num 900\n",
            "loss 0.012114946730434895 average time 0.0023619527804879434 iter num 920\n",
            "loss 9.675307273864746 average time 0.002367684157496192 iter num 940\n",
            "loss 1.0967620611190796 average time 0.002366499204218068 iter num 960\n",
            "loss 0.010367348790168762 average time 0.002364317677605571 iter num 980\n",
            "loss 12.684625625610352 average time 0.002363160075052292 iter num 1000\n",
            "loss 1.5827257633209229 average time 0.002869804150213895 iter num 20\n",
            "loss 0.29795512557029724 average time 0.002590103325110249 iter num 40\n",
            "loss 34.07072448730469 average time 0.002482784000009512 iter num 60\n",
            "loss 1.9990333318710327 average time 0.002470290050018775 iter num 80\n",
            "loss 0.022111335769295692 average time 0.002503696300009324 iter num 100\n",
            "loss 1.7797585725784302 average time 0.0024723022749943385 iter num 120\n",
            "loss 0.28044259548187256 average time 0.0024444846714426864 iter num 140\n",
            "loss 0.3402518033981323 average time 0.002440014287537906 iter num 160\n",
            "loss 2.338947296142578 average time 0.002434859088942984 iter num 180\n",
            "loss 0.40068644285202026 average time 0.0024971827050376304 iter num 200\n",
            "loss 4.813369274139404 average time 0.002510306190949698 iter num 220\n",
            "loss 6.262670993804932 average time 0.002539935441700436 iter num 240\n",
            "loss 5.889746189117432 average time 0.002543733242328017 iter num 260\n",
            "loss 0.21145880222320557 average time 0.002552430600007938 iter num 280\n",
            "loss 4.578944206237793 average time 0.0025618701166543662 iter num 300\n",
            "loss 1.5444846153259277 average time 0.002577076212475049 iter num 320\n",
            "loss 27.8109130859375 average time 0.002579908088211917 iter num 340\n",
            "loss 4.650086402893066 average time 0.0025920571805424213 iter num 360\n",
            "loss 2.849510431289673 average time 0.002593782947348556 iter num 380\n",
            "loss 25.182809829711914 average time 0.002583512739993239 iter num 400\n",
            "loss 3.0200304985046387 average time 0.002581501238096063 iter num 420\n",
            "loss 0.4588145613670349 average time 0.002585888545453682 iter num 440\n",
            "loss 0.0015603440115228295 average time 0.00258233703043911 iter num 460\n",
            "loss 9.773733139038086 average time 0.0025799460416692454 iter num 480\n",
            "loss 15.256285667419434 average time 0.0025820499540095626 iter num 500\n",
            "loss 64.39122009277344 average time 0.002585460350015777 iter num 520\n",
            "loss 0.3093987703323364 average time 0.002590973285192309 iter num 540\n",
            "loss 0.7328191995620728 average time 0.002594175503587134 iter num 560\n",
            "loss 21.871065139770508 average time 0.00260021158277721 iter num 580\n",
            "loss 5.66978120803833 average time 0.0025971839166807815 iter num 600\n",
            "loss 0.3155271112918854 average time 0.002596195180658176 iter num 620\n",
            "loss 2.7753539085388184 average time 0.0025999469578209754 iter num 640\n",
            "loss 0.04355655983090401 average time 0.002609452578806006 iter num 660\n",
            "loss 0.2894112765789032 average time 0.0026039248941368202 iter num 680\n",
            "loss 31.007328033447266 average time 0.0026063796543011057 iter num 700\n",
            "loss 0.5044779777526855 average time 0.0026032472472378586 iter num 720\n",
            "loss 1.3546197414398193 average time 0.0026044300932586044 iter num 740\n",
            "loss 0.9346519708633423 average time 0.0026084721552754337 iter num 760\n",
            "loss 62.88163757324219 average time 0.0026198288038568325 iter num 780\n",
            "loss 0.1673612892627716 average time 0.002628190328759956 iter num 800\n",
            "loss 16.173809051513672 average time 0.002625227293912935 iter num 820\n",
            "loss 0.5077997446060181 average time 0.00262391978691691 iter num 840\n",
            "loss 68.63749694824219 average time 0.002620565829083928 iter num 860\n",
            "loss 2.159026861190796 average time 0.0026197610613756047 iter num 880\n",
            "loss 11.651447296142578 average time 0.002620915533346609 iter num 900\n",
            "loss 0.005493466276675463 average time 0.002623741519583627 iter num 920\n",
            "loss 4.330788612365723 average time 0.0026225225851278003 iter num 940\n",
            "loss 0.009295865893363953 average time 0.0026222865312718114 iter num 960\n",
            "loss 1.370331048965454 average time 0.002623680513290904 iter num 980\n",
            "loss 7.2485504150390625 average time 0.0026238522860257945 iter num 1000\n",
            "loss 0.08902715146541595 average time 0.0032166608498300775 iter num 20\n",
            "loss 36.306068420410156 average time 0.0029029524499492253 iter num 40\n",
            "loss 0.9313651919364929 average time 0.002845418033363482 iter num 60\n",
            "loss 7.768319129943848 average time 0.002795784825048031 iter num 80\n",
            "loss 0.16932830214500427 average time 0.0028259531000185234 iter num 100\n",
            "loss 4.226068496704102 average time 0.002792112958331927 iter num 120\n",
            "loss 8.564035415649414 average time 0.0027335256642540377 iter num 140\n",
            "loss 3.613947868347168 average time 0.0027309600624676024 iter num 160\n",
            "loss 0.03659839555621147 average time 0.002731662744402759 iter num 180\n",
            "loss 65.48619079589844 average time 0.002729804789960326 iter num 200\n",
            "loss 0.780799925327301 average time 0.002724453422706574 iter num 220\n",
            "loss 1.4428677558898926 average time 0.0027375638541495086 iter num 240\n",
            "loss 6.800200462341309 average time 0.0027369251884500467 iter num 260\n",
            "loss 94.35210418701172 average time 0.0027353747999963422 iter num 280\n",
            "loss 10.123905181884766 average time 0.0027279576766826115 iter num 300\n",
            "loss 3.626230478286743 average time 0.002709069706276068 iter num 320\n",
            "loss 2.353060007095337 average time 0.0027065469676820024 iter num 340\n",
            "loss 0.28887179493904114 average time 0.0027047619861352563 iter num 360\n",
            "loss 4.288042068481445 average time 0.0027024458842453514 iter num 380\n",
            "loss 6.302085876464844 average time 0.0026997308800264363 iter num 400\n",
            "loss 0.026934031397104263 average time 0.002691262464300269 iter num 420\n",
            "loss 1.3401620388031006 average time 0.0026925395909198745 iter num 440\n",
            "loss 0.07939274609088898 average time 0.0026915602608705343 iter num 460\n",
            "loss 7.503826141357422 average time 0.002692478816671458 iter num 480\n",
            "loss 58.190433502197266 average time 0.0026849014200124657 iter num 500\n",
            "loss 2.3647990226745605 average time 0.002686930290407802 iter num 520\n",
            "loss 7.187923431396484 average time 0.002676287655571354 iter num 540\n",
            "loss 0.24779237806797028 average time 0.0026802174839336396 iter num 560\n",
            "loss 0.3243478536605835 average time 0.0026773005103552412 iter num 580\n",
            "loss 0.014086502604186535 average time 0.002678463350005889 iter num 600\n",
            "loss 1.4324586391448975 average time 0.002680598256454452 iter num 620\n",
            "loss 0.3144059479236603 average time 0.002679749100002482 iter num 640\n",
            "loss 1.6819837093353271 average time 0.0026818328500088353 iter num 660\n",
            "loss 1.3101962804794312 average time 0.0026827023720697443 iter num 680\n",
            "loss 0.5285140872001648 average time 0.002681379615730423 iter num 700\n",
            "loss 0.3921571373939514 average time 0.0026810564652931944 iter num 720\n",
            "loss 0.0027440229896456003 average time 0.0026801529216410585 iter num 740\n",
            "loss 0.7002208232879639 average time 0.0026806443697607488 iter num 760\n",
            "loss 1.2427438497543335 average time 0.0026794634987382803 iter num 780\n",
            "loss 6.355074882507324 average time 0.0026789974912662727 iter num 800\n",
            "loss 0.1252734512090683 average time 0.0026788370634343796 iter num 820\n",
            "loss 0.18048495054244995 average time 0.002679405500025279 iter num 840\n",
            "loss 1.3834304809570312 average time 0.0026767279302560404 iter num 860\n",
            "loss 2.1756205558776855 average time 0.0026775103557073717 iter num 880\n",
            "loss 23.80134391784668 average time 0.002677734386688826 iter num 900\n",
            "loss 15.363754272460938 average time 0.002678587192414615 iter num 920\n",
            "loss 11.801934242248535 average time 0.002673018905340754 iter num 940\n",
            "loss 5.400290489196777 average time 0.002672743860434442 iter num 960\n",
            "loss 347.3119201660156 average time 0.0026726836224711128 iter num 980\n",
            "loss 0.009187129326164722 average time 0.0026711976080223392 iter num 1000\n",
            "loss 0.7647878527641296 average time 0.0033440974003497103 iter num 20\n",
            "loss 29.438522338867188 average time 0.0030182940003214754 iter num 40\n",
            "loss 49.36168670654297 average time 0.0027765219169850752 iter num 60\n",
            "loss 0.29216980934143066 average time 0.0026574968876730055 iter num 80\n",
            "loss 0.8561053276062012 average time 0.0025889584001197365 iter num 100\n",
            "loss 0.07546227425336838 average time 0.0025567676084847337 iter num 120\n",
            "loss 3.017329692840576 average time 0.0025135067072889275 iter num 140\n",
            "loss 711.4808959960938 average time 0.002485430656383869 iter num 160\n",
            "loss 9.769153594970703 average time 0.002478957722390381 iter num 180\n",
            "loss 5.037160396575928 average time 0.002461932750147753 iter num 200\n",
            "loss 0.5915238857269287 average time 0.0024442550365000155 iter num 220\n",
            "loss 35.298675537109375 average time 0.0024285438209593244 iter num 240\n",
            "loss 3.8061153888702393 average time 0.0024182931462676674 iter num 260\n",
            "loss 5.990930557250977 average time 0.002415128628672392 iter num 280\n",
            "loss 54.60408401489258 average time 0.0024057979767712822 iter num 300\n",
            "loss 0.010974330827593803 average time 0.002396553828236847 iter num 320\n",
            "loss 0.006738758180290461 average time 0.0024122056001086843 iter num 340\n",
            "loss 32.141178131103516 average time 0.0024043779279003907 iter num 360\n",
            "loss 7.8029985427856445 average time 0.002396527810651605 iter num 380\n",
            "loss 121.4277114868164 average time 0.00241426776510707 iter num 400\n",
            "loss 6.697730541229248 average time 0.0024261963334321905 iter num 420\n",
            "loss 0.5077238082885742 average time 0.002419579334189786 iter num 440\n",
            "loss 5.6593403816223145 average time 0.0024146299348934046 iter num 460\n",
            "loss 2.6588687896728516 average time 0.002429738066784163 iter num 480\n",
            "loss 0.0035741759929805994 average time 0.0024355005461075053 iter num 500\n",
            "loss 2.587779998779297 average time 0.0024303724712633713 iter num 520\n",
            "loss 21.136688232421875 average time 0.002431268888988227 iter num 540\n",
            "loss 0.3289346992969513 average time 0.0024272187572413322 iter num 560\n",
            "loss 20.40534210205078 average time 0.0024293161776830826 iter num 580\n",
            "loss 3.8019824028015137 average time 0.0024399426300897174 iter num 600\n",
            "loss 0.0523066408932209 average time 0.002436609230737245 iter num 620\n",
            "loss 14.20663070678711 average time 0.00243295991571415 iter num 640\n",
            "loss 3.0540010929107666 average time 0.0024352967743294413 iter num 660\n",
            "loss 1.1924160718917847 average time 0.0024322089147865295 iter num 680\n",
            "loss 0.03075437806546688 average time 0.002434377971502337 iter num 700\n",
            "loss 13.071133613586426 average time 0.0024342377167386074 iter num 720\n",
            "loss 73.09342193603516 average time 0.0024383125527664734 iter num 740\n",
            "loss 0.35617581009864807 average time 0.00243687777900672 iter num 760\n",
            "loss 30.613887786865234 average time 0.0024416295256975366 iter num 780\n",
            "loss 84.1683578491211 average time 0.0024455044400497174 iter num 800\n",
            "loss 0.5458959937095642 average time 0.0024503940427321805 iter num 820\n",
            "loss 0.16211387515068054 average time 0.0024480810202822754 iter num 840\n",
            "loss 2.9092724323272705 average time 0.0024508248174792834 iter num 860\n",
            "loss 0.6316460967063904 average time 0.002457020712534524 iter num 880\n",
            "loss 1.3705476522445679 average time 0.0024585829178168854 iter num 900\n",
            "loss 2.9703314304351807 average time 0.0024610372619937823 iter num 920\n",
            "loss 251.892578125 average time 0.0024661842436526447 iter num 940\n",
            "loss 1.7680120468139648 average time 0.0024698980729605563 iter num 960\n",
            "loss 4.803899765014648 average time 0.00247302881433992 iter num 980\n",
            "loss 2.7427597045898438 average time 0.002476448344044911 iter num 1000\n",
            "loss 18.133926391601562 average time 0.003274959200007288 iter num 20\n",
            "loss 2.439856767654419 average time 0.0029744740249498134 iter num 40\n",
            "loss 5.3870368003845215 average time 0.0027764286999627076 iter num 60\n",
            "loss 65.42607116699219 average time 0.0027330688624488176 iter num 80\n",
            "loss 4.330074310302734 average time 0.0026576881398796106 iter num 100\n",
            "loss 3.6211354732513428 average time 0.0026504573249136834 iter num 120\n",
            "loss 0.07121273875236511 average time 0.002643473342816703 iter num 140\n",
            "loss 2.369641065597534 average time 0.002649854381229488 iter num 160\n",
            "loss 0.45437341928482056 average time 0.0026573739833111176 iter num 180\n",
            "loss 2.513794422149658 average time 0.002659017114992821 iter num 200\n",
            "loss 7.440426826477051 average time 0.0026665581999871144 iter num 220\n",
            "loss 6.297851085662842 average time 0.002661249324993757 iter num 240\n",
            "loss 0.03651930019259453 average time 0.0026785566653975716 iter num 260\n",
            "loss 0.26428431272506714 average time 0.0026782843607244494 iter num 280\n",
            "loss 3.148667097091675 average time 0.0026881266233370602 iter num 300\n",
            "loss 0.13668476045131683 average time 0.0026753907874990544 iter num 320\n",
            "loss 0.4452221393585205 average time 0.0026702734440946455 iter num 340\n",
            "loss 1.698866605758667 average time 0.0026631957083029394 iter num 360\n",
            "loss 1.3378024101257324 average time 0.0026626420183914123 iter num 380\n",
            "loss 6.350306034088135 average time 0.0026776656199808714 iter num 400\n",
            "loss 0.22105178236961365 average time 0.0026768426499724487 iter num 420\n",
            "loss 17.200546264648438 average time 0.0026765485363367506 iter num 440\n",
            "loss 3.5903472900390625 average time 0.0026699258760622202 iter num 460\n",
            "loss 5.503504276275635 average time 0.0026722969708240876 iter num 480\n",
            "loss 8.777703285217285 average time 0.0026791298639982416 iter num 500\n",
            "loss 3.117216110229492 average time 0.0026793150519132235 iter num 520\n",
            "loss 5.146305561065674 average time 0.0026812116333328755 iter num 540\n",
            "loss 0.024217484518885612 average time 0.002675693601781859 iter num 560\n",
            "loss 8.904831886291504 average time 0.002686705855169215 iter num 580\n",
            "loss 15.897290229797363 average time 0.002685801488329768 iter num 600\n",
            "loss 4.590346813201904 average time 0.002683041775799211 iter num 620\n",
            "loss 4.568137168884277 average time 0.0026831327312436316 iter num 640\n",
            "loss 0.010271643288433552 average time 0.002678387325751387 iter num 660\n",
            "loss 3.5905206203460693 average time 0.0026730882955823343 iter num 680\n",
            "loss 3.6165900230407715 average time 0.002674865784288808 iter num 700\n",
            "loss 18.208576202392578 average time 0.002674965651385719 iter num 720\n",
            "loss 1.8459510803222656 average time 0.0026728521986459216 iter num 740\n",
            "loss 0.6509398818016052 average time 0.002668188071045638 iter num 760\n",
            "loss 15.845528602600098 average time 0.0026646278025532996 iter num 780\n",
            "loss 0.013124596327543259 average time 0.0026628524362399732 iter num 800\n",
            "loss 0.0026676703710108995 average time 0.0026607889768123774 iter num 820\n",
            "loss 0.4189997613430023 average time 0.002656133886895467 iter num 840\n",
            "loss 0.769622266292572 average time 0.0026550793244115444 iter num 860\n",
            "loss 0.08267103880643845 average time 0.002653019806811327 iter num 880\n",
            "loss 19.441335678100586 average time 0.0026533887122180506 iter num 900\n",
            "loss 0.05233209207653999 average time 0.002651070230428124 iter num 920\n",
            "loss 25.905887603759766 average time 0.0026522607670116526 iter num 940\n",
            "loss 0.06358181685209274 average time 0.00265330585624497 iter num 960\n",
            "loss 16.013919830322266 average time 0.002655102093875921 iter num 980\n",
            "loss 354.2124938964844 average time 0.002657302066001648 iter num 1000\n",
            "loss 7.461304187774658 average time 0.0034875611003371888 iter num 20\n",
            "loss 11.360910415649414 average time 0.003054318250224242 iter num 40\n",
            "loss 2.9258713722229004 average time 0.0029456705501615943 iter num 60\n",
            "loss 12.076887130737305 average time 0.002849942812667905 iter num 80\n",
            "loss 1.7562437057495117 average time 0.002807082460130914 iter num 100\n",
            "loss 1.3384119272232056 average time 0.002775974900184034 iter num 120\n",
            "loss 21.60662269592285 average time 0.002762709914454068 iter num 140\n",
            "loss 6.227627754211426 average time 0.0027416422313876867 iter num 160\n",
            "loss 0.08685363829135895 average time 0.0027179671779069595 iter num 180\n",
            "loss 0.24862906336784363 average time 0.0027009343001100205 iter num 200\n",
            "loss 0.03563566505908966 average time 0.0026919949955547715 iter num 220\n",
            "loss 0.001364905503578484 average time 0.0026786417876110136 iter num 240\n",
            "loss 0.3180047273635864 average time 0.0026729246231787748 iter num 260\n",
            "loss 1.0081188678741455 average time 0.002675032578684165 iter num 280\n",
            "loss 3.7708358764648438 average time 0.0026851601967731163 iter num 300\n",
            "loss 43.22275924682617 average time 0.0026670306907362828 iter num 320\n",
            "loss 1.232101321220398 average time 0.0026511928942187187 iter num 340\n",
            "loss 8.789167404174805 average time 0.0026443136223103163 iter num 360\n",
            "loss 5.40511417388916 average time 0.0026413888421829095 iter num 380\n",
            "loss 10.105270385742188 average time 0.002635321512570954 iter num 400\n",
            "loss 114.767333984375 average time 0.002638643900085992 iter num 420\n",
            "loss 9.594812393188477 average time 0.0026352412455253214 iter num 440\n",
            "loss 0.19717104732990265 average time 0.0026333928283233748 iter num 460\n",
            "loss 74.38746643066406 average time 0.0026224432438198162 iter num 480\n",
            "loss 5.149328708648682 average time 0.0026124413180696137 iter num 500\n",
            "loss 2.039536714553833 average time 0.0026153075577440175 iter num 520\n",
            "loss 0.028788592666387558 average time 0.0026175194537548427 iter num 540\n",
            "loss 0.2115197628736496 average time 0.0026211156214620652 iter num 560\n",
            "loss 3.622570037841797 average time 0.0026229379552080052 iter num 580\n",
            "loss 477.852294921875 average time 0.0026251194783708342 iter num 600\n",
            "loss 0.7538148164749146 average time 0.002627354006495631 iter num 620\n",
            "loss 0.31819403171539307 average time 0.00262357920784666 iter num 640\n",
            "loss 1.1900731325149536 average time 0.0026250068833674465 iter num 660\n",
            "loss 26.822444915771484 average time 0.0026247162867922965 iter num 680\n",
            "loss 0.636542797088623 average time 0.0026148271371701933 iter num 700\n",
            "loss 0.29537975788116455 average time 0.0026078055472579663 iter num 720\n",
            "loss 4.313955307006836 average time 0.002605735916249368 iter num 740\n",
            "loss 15.290186882019043 average time 0.0026077743566020216 iter num 760\n",
            "loss 0.19299836456775665 average time 0.0025991287743752953 iter num 780\n",
            "loss 35.80744934082031 average time 0.002592591952516159 iter num 800\n",
            "loss 1.2184877395629883 average time 0.00258642451830516 iter num 820\n",
            "loss 2.8540327548980713 average time 0.002579577271442412 iter num 840\n",
            "loss 23.569353103637695 average time 0.002573687133727342 iter num 860\n",
            "loss 0.047432124614715576 average time 0.0025690161806923325 iter num 880\n",
            "loss 2.810774803161621 average time 0.002565106671117974 iter num 900\n",
            "loss 78.53909301757812 average time 0.0025574940326133283 iter num 920\n",
            "loss 1.5656486749649048 average time 0.0025547487766027885 iter num 940\n",
            "loss 0.002127564512193203 average time 0.0025482141979258207 iter num 960\n",
            "loss 0.404697060585022 average time 0.0025446339398012222 iter num 980\n",
            "loss 0.1972535252571106 average time 0.0025441556290061273 iter num 1000\n",
            "loss 61.512447357177734 average time 0.0028925661497851253 iter num 20\n",
            "loss 1.2080671787261963 average time 0.002604765674959708 iter num 40\n",
            "loss 19.17975616455078 average time 0.0024958533832432294 iter num 60\n",
            "loss 0.03803735226392746 average time 0.0024510403749445687 iter num 80\n",
            "loss 39.445091247558594 average time 0.0024682752799890296 iter num 100\n",
            "loss 0.6523841619491577 average time 0.0024405271833529696 iter num 120\n",
            "loss 2.7536368370056152 average time 0.0024110461785962147 iter num 140\n",
            "loss 1.4130115509033203 average time 0.0024007026937624687 iter num 160\n",
            "loss 0.3273220658302307 average time 0.002388400416647427 iter num 180\n",
            "loss 13.165472030639648 average time 0.0023804749549708503 iter num 200\n",
            "loss 0.00226283585652709 average time 0.002424414918170276 iter num 220\n",
            "loss 112.80260467529297 average time 0.0024125164458306853 iter num 240\n",
            "loss 1.4860583543777466 average time 0.002397419484616246 iter num 260\n",
            "loss 3.1023895740509033 average time 0.0023915546500055435 iter num 280\n",
            "loss 2.1828737258911133 average time 0.0023835617300028387 iter num 300\n",
            "loss 0.2997819781303406 average time 0.002393200934380957 iter num 320\n",
            "loss 0.15806904435157776 average time 0.0023855542794080976 iter num 340\n",
            "loss 0.13061177730560303 average time 0.002382539450000978 iter num 360\n",
            "loss 60.558536529541016 average time 0.0023765511105155288 iter num 380\n",
            "loss 0.1093800961971283 average time 0.002371771044977322 iter num 400\n",
            "loss 0.8833034038543701 average time 0.002367189623791568 iter num 420\n",
            "loss 0.26149311661720276 average time 0.0023635553840738958 iter num 440\n",
            "loss 0.9025086760520935 average time 0.002376819960856032 iter num 460\n",
            "loss 1.5311211347579956 average time 0.002376129745819829 iter num 480\n",
            "loss 1.6937987804412842 average time 0.002387263513981452 iter num 500\n",
            "loss 37.180503845214844 average time 0.002386058074972215 iter num 520\n",
            "loss 8.146905899047852 average time 0.0023825477092234196 iter num 540\n",
            "loss 14.504805564880371 average time 0.0023791022963970524 iter num 560\n",
            "loss 150.56666564941406 average time 0.002375714022388099 iter num 580\n",
            "loss 0.808205246925354 average time 0.0023709673866445275 iter num 600\n",
            "loss 0.015685049816966057 average time 0.0023674954741709957 iter num 620\n",
            "loss 2.1834373474121094 average time 0.0023658468234145857 iter num 640\n",
            "loss 0.24231067299842834 average time 0.0023634969469474693 iter num 660\n",
            "loss 8.117730140686035 average time 0.0023787521999779795 iter num 680\n",
            "loss 0.20506651699543 average time 0.0023749740571214974 iter num 700\n",
            "loss 0.14360228180885315 average time 0.0023742118611026954 iter num 720\n",
            "loss 72.89421844482422 average time 0.002371329778371374 iter num 740\n",
            "loss 1.053237795829773 average time 0.002369763424985649 iter num 760\n",
            "loss 0.7405477166175842 average time 0.002369453091012894 iter num 780\n",
            "loss 0.02760680392384529 average time 0.002373309037486706 iter num 800\n",
            "loss 0.208151176571846 average time 0.0023714627292553436 iter num 820\n",
            "loss 0.31730812788009644 average time 0.002370179803555012 iter num 840\n",
            "loss 0.7018561363220215 average time 0.0023685891674240125 iter num 860\n",
            "loss 1.3569605350494385 average time 0.0023749370488427633 iter num 880\n",
            "loss 3.9279398918151855 average time 0.002378356994421564 iter num 900\n",
            "loss 0.013584895990788937 average time 0.002377776474978695 iter num 920\n",
            "loss 0.06067107990384102 average time 0.0023761143787057936 iter num 940\n",
            "loss 5.9054484367370605 average time 0.0023852270905990736 iter num 960\n",
            "loss 205.86749267578125 average time 0.0023843980877282607 iter num 980\n",
            "loss 0.29850563406944275 average time 0.002382357451975622 iter num 1000\n",
            "loss 0.7721007466316223 average time 0.0028978680500586053 iter num 20\n",
            "loss 8.359002113342285 average time 0.0026668053751564003 iter num 40\n",
            "loss 19.559051513671875 average time 0.0025324171834654407 iter num 60\n",
            "loss 1.5930558443069458 average time 0.0024734430126272856 iter num 80\n",
            "loss 0.11543674021959305 average time 0.002433604170109902 iter num 100\n",
            "loss 4.505935192108154 average time 0.0024056002251048388 iter num 120\n",
            "loss 5.3487324714660645 average time 0.0024588245143864437 iter num 140\n",
            "loss 2.1645164489746094 average time 0.00244082600636375 iter num 160\n",
            "loss 1.5758416652679443 average time 0.0024232081000971246 iter num 180\n",
            "loss 31.853757858276367 average time 0.0024079438301214395 iter num 200\n",
            "loss 5.575653076171875 average time 0.002395816009175178 iter num 220\n",
            "loss 0.13355223834514618 average time 0.0023873405417361936 iter num 240\n",
            "loss 0.23040322959423065 average time 0.002382685446229096 iter num 260\n",
            "loss 2.3015847206115723 average time 0.0023822262000781588 iter num 280\n",
            "loss 10.024910926818848 average time 0.002377717900059603 iter num 300\n",
            "loss 0.02520887739956379 average time 0.002372849240691721 iter num 320\n",
            "loss 0.5935059189796448 average time 0.002370160673602667 iter num 340\n",
            "loss 10.199785232543945 average time 0.0023679148250721482 iter num 360\n",
            "loss 0.9955988526344299 average time 0.0023645715158780055 iter num 380\n",
            "loss 0.5320926904678345 average time 0.0023621347275729933 iter num 400\n",
            "loss 11.913220405578613 average time 0.0023598028262443093 iter num 420\n",
            "loss 61.42595291137695 average time 0.002360566247766242 iter num 440\n",
            "loss 29.439117431640625 average time 0.002358525065257867 iter num 460\n",
            "loss 0.9828621745109558 average time 0.0023569358646227554 iter num 480\n",
            "loss 32.4904670715332 average time 0.0023547751960395543 iter num 500\n",
            "loss 4.762002944946289 average time 0.0023617171865750537 iter num 520\n",
            "loss 33.10401153564453 average time 0.0023603500426260223 iter num 540\n",
            "loss 0.07171688973903656 average time 0.0023575357893183277 iter num 560\n",
            "loss 0.03017512895166874 average time 0.0023633304155486383 iter num 580\n",
            "loss 1.576397180557251 average time 0.0023605541500395094 iter num 600\n",
            "loss 51.54698181152344 average time 0.002359560654880507 iter num 620\n",
            "loss 0.15950417518615723 average time 0.0023569568344214533 iter num 640\n",
            "loss 1.0012363195419312 average time 0.0023566605651963485 iter num 660\n",
            "loss 0.8535289168357849 average time 0.0023653748544588513 iter num 680\n",
            "loss 0.017604725435376167 average time 0.0023637729500426627 iter num 700\n",
            "loss 14.239348411560059 average time 0.002360539318086315 iter num 720\n",
            "loss 1.628373146057129 average time 0.0023588197770599484 iter num 740\n",
            "loss 12.600896835327148 average time 0.0023567445263540177 iter num 760\n",
            "loss 20.78801155090332 average time 0.0023555336320826496 iter num 780\n",
            "loss 0.02237057499587536 average time 0.0023543300612845998 iter num 800\n",
            "loss 17.30385398864746 average time 0.0023517581951570565 iter num 820\n",
            "loss 0.009097857400774956 average time 0.0023487728786005303 iter num 840\n",
            "loss 0.05623207241296768 average time 0.002347309495383152 iter num 860\n",
            "loss 59.26234436035156 average time 0.002347257484126947 iter num 880\n",
            "loss 6.459009647369385 average time 0.002351957996704894 iter num 900\n",
            "loss 0.08781682699918747 average time 0.002350857333731651 iter num 920\n",
            "loss 0.0042112646624445915 average time 0.0023493464649289577 iter num 940\n",
            "loss 16.849424362182617 average time 0.002351339084409195 iter num 960\n",
            "loss 43.45681381225586 average time 0.0023511968367696387 iter num 980\n",
            "loss 36.71853256225586 average time 0.0023503987330368544 iter num 1000\n",
            "loss 0.31423845887184143 average time 0.0029703515001529013 iter num 20\n",
            "loss 0.08285729587078094 average time 0.0026298846751615203 iter num 40\n",
            "loss 21.437881469726562 average time 0.002524651200049751 iter num 60\n",
            "loss 122.87196350097656 average time 0.002467429499984064 iter num 80\n",
            "loss 21.153564453125 average time 0.0024596629300140194 iter num 100\n",
            "loss 0.92145174741745 average time 0.002438103541635428 iter num 120\n",
            "loss 56.27987289428711 average time 0.0024219202357276767 iter num 140\n",
            "loss 25.012666702270508 average time 0.002411262381258439 iter num 160\n",
            "loss 40.898616790771484 average time 0.002407617577783741 iter num 180\n",
            "loss 0.4404573142528534 average time 0.0023948239649780587 iter num 200\n",
            "loss 1.1049069166183472 average time 0.0023858774590900626 iter num 220\n",
            "loss 10.269108772277832 average time 0.002385326545860759 iter num 240\n",
            "loss 2.906992197036743 average time 0.0024146804615786375 iter num 260\n",
            "loss 3.4025094509124756 average time 0.0024063382393186266 iter num 280\n",
            "loss 23.630508422851562 average time 0.0023962763667077524 iter num 300\n",
            "loss 199.48178100585938 average time 0.002406674475048476 iter num 320\n",
            "loss 0.5698019862174988 average time 0.0023991072000546197 iter num 340\n",
            "loss 15.988397598266602 average time 0.0023962293639417315 iter num 360\n",
            "loss 2.58436918258667 average time 0.0024220352447771707 iter num 380\n",
            "loss 7.3904194831848145 average time 0.0024141235950492046 iter num 400\n",
            "loss 1.351801872253418 average time 0.0024087871786096435 iter num 420\n",
            "loss 1.771544098854065 average time 0.0024127053318559115 iter num 440\n",
            "loss 0.17231442034244537 average time 0.0024086457565554945 iter num 460\n",
            "loss 0.28695183992385864 average time 0.002421151010446465 iter num 480\n",
            "loss 5.109506607055664 average time 0.0024149644060307766 iter num 500\n",
            "loss 3.3258814811706543 average time 0.0024077303173446404 iter num 520\n",
            "loss 66.2183609008789 average time 0.002401950635228584 iter num 540\n",
            "loss 3.2226758003234863 average time 0.002405834992893168 iter num 560\n",
            "loss 0.0032998917158693075 average time 0.002399252050029112 iter num 580\n",
            "loss 1.5392791032791138 average time 0.0023956745100288876 iter num 600\n",
            "loss 8.198467254638672 average time 0.0024002896355135995 iter num 620\n",
            "loss 0.16061827540397644 average time 0.002402633440652835 iter num 640\n",
            "loss 1.85596764087677 average time 0.00239667210002925 iter num 660\n",
            "loss 3.915067434310913 average time 0.002393176141204629 iter num 680\n",
            "loss 28.358192443847656 average time 0.002388335931453704 iter num 700\n",
            "loss 0.027263080701231956 average time 0.0023839257639236976 iter num 720\n",
            "loss 0.0036373399198055267 average time 0.002382093325709197 iter num 740\n",
            "loss 0.10464352369308472 average time 0.0023829560158183565 iter num 760\n",
            "loss 0.09919289499521255 average time 0.002379413846185157 iter num 780\n",
            "loss 0.08610634505748749 average time 0.0023825190600291536 iter num 800\n",
            "loss 2.5185747146606445 average time 0.0023800424036846558 iter num 820\n",
            "loss 18.458250045776367 average time 0.0023823545964508715 iter num 840\n",
            "loss 0.22944779694080353 average time 0.0023873133849054624 iter num 860\n",
            "loss 0.25295746326446533 average time 0.0023926031931978285 iter num 880\n",
            "loss 16.278791427612305 average time 0.002391646290022133 iter num 900\n",
            "loss 207.36135864257812 average time 0.0023966652402399946 iter num 920\n",
            "loss 0.25644367933273315 average time 0.002404908995769337 iter num 940\n",
            "loss 0.20083899796009064 average time 0.0024114466073172024 iter num 960\n",
            "loss 4.517862796783447 average time 0.0024154452265622464 iter num 980\n",
            "loss 0.0005143546732142568 average time 0.0024215774000331293 iter num 1000\n",
            "loss 52.40199279785156 average time 0.0030156372500641736 iter num 20\n",
            "loss 21.472707748413086 average time 0.0028198750248975557 iter num 40\n",
            "loss 0.2119988203048706 average time 0.0027223023998885765 iter num 60\n",
            "loss 0.09397008270025253 average time 0.0027064345873895946 iter num 80\n",
            "loss 7.2312703132629395 average time 0.0026853294399552395 iter num 100\n",
            "loss 3.775758981704712 average time 0.002650347116620348 iter num 120\n",
            "loss 4.358395099639893 average time 0.0026152177285309465 iter num 140\n",
            "loss 0.09889598935842514 average time 0.0026186071999632077 iter num 160\n",
            "loss 1.0663002729415894 average time 0.0026127823555321407 iter num 180\n",
            "loss 0.4841599762439728 average time 0.002616561549984908 iter num 200\n",
            "loss 1.1809966564178467 average time 0.002622248572714108 iter num 220\n",
            "loss 3.91549015045166 average time 0.002627005341666215 iter num 240\n",
            "loss 1.8272573947906494 average time 0.002630577726932433 iter num 260\n",
            "loss 0.0091707743704319 average time 0.0026372085928479854 iter num 280\n",
            "loss 0.35058850049972534 average time 0.0026368175900097412 iter num 300\n",
            "loss 4.770814418792725 average time 0.0026414191687706536 iter num 320\n",
            "loss 1.975436806678772 average time 0.002641427682385042 iter num 340\n",
            "loss 0.05255138874053955 average time 0.0026313276361330886 iter num 360\n",
            "loss 0.001008771825581789 average time 0.002624258681599282 iter num 380\n",
            "loss 2.729412317276001 average time 0.0026165502575213394 iter num 400\n",
            "loss 1.2098455429077148 average time 0.002621682838114447 iter num 420\n",
            "loss 0.2420687973499298 average time 0.002608886420479063 iter num 440\n",
            "loss 0.006585950497537851 average time 0.0026116639217632284 iter num 460\n",
            "loss 4.452376365661621 average time 0.0026042341604390153 iter num 480\n",
            "loss 0.037940870970487595 average time 0.002605840182019165 iter num 500\n",
            "loss 0.021165000274777412 average time 0.002608856380773152 iter num 520\n",
            "loss 51.26445007324219 average time 0.0026128964185200285 iter num 540\n",
            "loss 0.0519929900765419 average time 0.002612249499998143 iter num 560\n",
            "loss 0.20827825367450714 average time 0.0026178025896617077 iter num 580\n",
            "loss 0.31196731328964233 average time 0.0026215635950029535 iter num 600\n",
            "loss 0.016467057168483734 average time 0.002614943796778525 iter num 620\n",
            "loss 0.6936478018760681 average time 0.0026230503765646064 iter num 640\n",
            "loss 1.4530408382415771 average time 0.002627253059094845 iter num 660\n",
            "loss 0.18121172487735748 average time 0.0026293748235382414 iter num 680\n",
            "loss 2.390556812286377 average time 0.0026233875014388883 iter num 700\n",
            "loss 0.06043311953544617 average time 0.0026241907208360417 iter num 720\n",
            "loss 0.02146829105913639 average time 0.0026201312297367573 iter num 740\n",
            "loss 0.05014822259545326 average time 0.0026240162723776225 iter num 760\n",
            "loss 3.5445592403411865 average time 0.002622072850007475 iter num 780\n",
            "loss 1.2046147584915161 average time 0.002622117000005346 iter num 800\n",
            "loss 0.1232447400689125 average time 0.002627688254878882 iter num 820\n",
            "loss 3.0843684673309326 average time 0.0026252302190490203 iter num 840\n",
            "loss 0.09648114442825317 average time 0.0026278209976754985 iter num 860\n",
            "loss 0.5055406093597412 average time 0.002628417204550715 iter num 880\n",
            "loss 332.8837585449219 average time 0.0026291928577767167 iter num 900\n",
            "loss 0.051507893949747086 average time 0.0026270789684748825 iter num 920\n",
            "loss 4.205641269683838 average time 0.00262540137234108 iter num 940\n",
            "loss 0.5949409604072571 average time 0.0026270443302090977 iter num 960\n",
            "loss 0.9682432413101196 average time 0.0026284236520412525 iter num 980\n",
            "loss 30.05979347229004 average time 0.002629620153003998 iter num 1000\n",
            "loss 0.0023965847212821245 average time 0.0033517756997753167 iter num 20\n",
            "loss 11.942706108093262 average time 0.0030411682498197477 iter num 40\n",
            "loss 1.186362862586975 average time 0.0029196242166411443 iter num 60\n",
            "loss 0.8254029154777527 average time 0.0028460713124559335 iter num 80\n",
            "loss 0.16257238388061523 average time 0.0027535133799938194 iter num 100\n",
            "loss 13.921606063842773 average time 0.0027330149166724976 iter num 120\n",
            "loss 0.11856303364038467 average time 0.0026816336499905446 iter num 140\n",
            "loss 15.771451950073242 average time 0.0026708105187026377 iter num 160\n",
            "loss 0.9954110980033875 average time 0.0026631341332783148 iter num 180\n",
            "loss 26.068614959716797 average time 0.002641330249944076 iter num 200\n",
            "loss 8.937578201293945 average time 0.002627609509065885 iter num 220\n",
            "loss 4.3123273849487305 average time 0.002604309074975693 iter num 240\n",
            "loss 0.0007543712854385376 average time 0.0025951119884456814 iter num 260\n",
            "loss 16.584667205810547 average time 0.0026609445928443163 iter num 280\n",
            "loss 0.29833656549453735 average time 0.0026546280933204495 iter num 300\n",
            "loss 2.468038320541382 average time 0.002650794896868547 iter num 320\n",
            "loss 1.9299355745315552 average time 0.0026515660852965083 iter num 340\n",
            "loss 9.585740089416504 average time 0.002648942355563122 iter num 360\n",
            "loss 47.357879638671875 average time 0.0026505650263300737 iter num 380\n",
            "loss 0.22689372301101685 average time 0.002653032947519023 iter num 400\n",
            "loss 68.77661895751953 average time 0.002654876609553217 iter num 420\n",
            "loss 12.351600646972656 average time 0.002668466788670478 iter num 440\n",
            "loss 7.110934734344482 average time 0.002654883926108754 iter num 460\n",
            "loss 26.73637580871582 average time 0.0026537059937747167 iter num 480\n",
            "loss 8.078042984008789 average time 0.002654731872022239 iter num 500\n",
            "loss 4.095935821533203 average time 0.002655927555791165 iter num 520\n",
            "loss 12.970455169677734 average time 0.0026554748815013026 iter num 540\n",
            "loss 0.9819320440292358 average time 0.0026545164107379345 iter num 560\n",
            "loss 0.5708678960800171 average time 0.002651699281049614 iter num 580\n",
            "loss 12.718083381652832 average time 0.002651398766683997 iter num 600\n",
            "loss 0.012309929355978966 average time 0.0026392455709913433 iter num 620\n",
            "loss 0.2624104619026184 average time 0.0026368112422204605 iter num 640\n",
            "loss 1.3671467304229736 average time 0.002631176319730664 iter num 660\n",
            "loss 4.1001057624816895 average time 0.0026424719559225407 iter num 680\n",
            "loss 0.033222369849681854 average time 0.0026404568214612872 iter num 700\n",
            "loss 0.243364617228508 average time 0.0026430569805900935 iter num 720\n",
            "loss 0.2903827726840973 average time 0.002650894656791344 iter num 740\n",
            "loss 3.5020840167999268 average time 0.0026447390658272765 iter num 760\n",
            "loss 0.4327996075153351 average time 0.0026465378231104973 iter num 780\n",
            "loss 6.439711570739746 average time 0.002640568903784697 iter num 800\n",
            "loss 0.22932544350624084 average time 0.0026329547561301033 iter num 820\n",
            "loss 26.984296798706055 average time 0.0026245289809875907 iter num 840\n",
            "loss 0.4951588809490204 average time 0.002616954441892567 iter num 860\n",
            "loss 0.04398433491587639 average time 0.002610208159122025 iter num 880\n",
            "loss 1.1272045373916626 average time 0.002601431008915824 iter num 900\n",
            "loss 0.1927160918712616 average time 0.002602951785895683 iter num 920\n",
            "loss 4.85315465927124 average time 0.0025975456787431963 iter num 940\n",
            "loss 0.06466764211654663 average time 0.0025958223812665437 iter num 960\n",
            "loss 3.6001265048980713 average time 0.0025893296347132898 iter num 980\n",
            "loss 0.2753302752971649 average time 0.00258285454702127 iter num 1000\n",
            "loss 0.7744488716125488 average time 0.002987704850056616 iter num 20\n",
            "loss 0.706558883190155 average time 0.0027915300249333084 iter num 40\n",
            "loss 7.4948835372924805 average time 0.002627787983237795 iter num 60\n",
            "loss 8.937623977661133 average time 0.0025486674999228853 iter num 80\n",
            "loss 1.9160970449447632 average time 0.0025027269799284112 iter num 100\n",
            "loss 4.641258239746094 average time 0.002496423766645724 iter num 120\n",
            "loss 0.18442077934741974 average time 0.0024609153356842787 iter num 140\n",
            "loss 14.442400932312012 average time 0.002439745456217679 iter num 160\n",
            "loss 0.15051084756851196 average time 0.0024238960944280227 iter num 180\n",
            "loss 33.74596405029297 average time 0.0024723212299795705 iter num 200\n",
            "loss 0.8694617748260498 average time 0.0024534565272254193 iter num 220\n",
            "loss 176.56997680664062 average time 0.002439496220805874 iter num 240\n",
            "loss 625.0252075195312 average time 0.0024338550576640744 iter num 260\n",
            "loss 52.93252944946289 average time 0.002432323253541264 iter num 280\n",
            "loss 431.0616455078125 average time 0.002422099143301845 iter num 300\n",
            "loss 0.2777993083000183 average time 0.002412855287474258 iter num 320\n",
            "loss 215.35952758789062 average time 0.002409371241168735 iter num 340\n",
            "loss 0.27995991706848145 average time 0.0024164071138784494 iter num 360\n",
            "loss 23.258146286010742 average time 0.0024102356131583003 iter num 380\n",
            "loss 0.8573727607727051 average time 0.002403620790005334 iter num 400\n",
            "loss 4.14478063583374 average time 0.0023967618785805133 iter num 420\n",
            "loss 45.732086181640625 average time 0.00240576647956087 iter num 440\n",
            "loss 25.329139709472656 average time 0.0024023332217557648 iter num 460\n",
            "loss 0.0925232395529747 average time 0.0023958428937627713 iter num 480\n",
            "loss 1.1567668914794922 average time 0.0023911732160049725 iter num 500\n",
            "loss 2.197235345840454 average time 0.002395679484631658 iter num 520\n",
            "loss 2.0528018474578857 average time 0.0023917372778062902 iter num 540\n",
            "loss 1.0583823919296265 average time 0.002387647169669955 iter num 560\n",
            "loss 58.384395599365234 average time 0.0023827434051938703 iter num 580\n",
            "loss 0.7331849932670593 average time 0.0023839677966861926 iter num 600\n",
            "loss 4.642158031463623 average time 0.0023805476935605486 iter num 620\n",
            "loss 5.536188125610352 average time 0.002377072048457762 iter num 640\n",
            "loss 12.928889274597168 average time 0.002392315843956043 iter num 660\n",
            "loss 8.374557495117188 average time 0.002394897366189873 iter num 680\n",
            "loss 0.0020919363014400005 average time 0.00239184438286819 iter num 700\n",
            "loss 8.63767147064209 average time 0.0023865169458405135 iter num 720\n",
            "loss 0.03725814074277878 average time 0.0023827153824345876 iter num 740\n",
            "loss 36.43305587768555 average time 0.002387650425000749 iter num 760\n",
            "loss 20.579753875732422 average time 0.0023846017410225893 iter num 780\n",
            "loss 0.08367184549570084 average time 0.002381899909994445 iter num 800\n",
            "loss 0.00950175803154707 average time 0.002379566965852818 iter num 820\n",
            "loss 19.344507217407227 average time 0.0023794944583273936 iter num 840\n",
            "loss 2.3120959667721763e-05 average time 0.0023866605581345135 iter num 860\n",
            "loss 2.393371105194092 average time 0.0023850462545397023 iter num 880\n",
            "loss 0.06686520576477051 average time 0.0023899069599873555 iter num 900\n",
            "loss 0.6784313321113586 average time 0.0023872758510823707 iter num 920\n",
            "loss 3.2277727127075195 average time 0.002385297409567469 iter num 940\n",
            "loss 0.4667496979236603 average time 0.002383367683328667 iter num 960\n",
            "loss 5.0631866455078125 average time 0.0023819960836757377 iter num 980\n",
            "loss 1.5146400928497314 average time 0.002385226997002974 iter num 1000\n",
            "loss 0.36873891949653625 average time 0.002876890450170322 iter num 20\n",
            "loss 54.08959197998047 average time 0.0025786505750602373 iter num 40\n",
            "loss 1.9140408039093018 average time 0.002456773800076917 iter num 60\n",
            "loss 0.6359037756919861 average time 0.002421667525095472 iter num 80\n",
            "loss 1.2693699598312378 average time 0.002406934400059981 iter num 100\n",
            "loss 3.1070141792297363 average time 0.0024550787083474765 iter num 120\n",
            "loss 0.9513753652572632 average time 0.002429029092867755 iter num 140\n",
            "loss 1.4417052268981934 average time 0.0024365219250057635 iter num 160\n",
            "loss 3.7745554447174072 average time 0.002430945555554192 iter num 180\n",
            "loss 0.6164373755455017 average time 0.0024167101150032975 iter num 200\n",
            "loss 1.8052488565444946 average time 0.0024032527908688776 iter num 220\n",
            "loss 0.00293838232755661 average time 0.0024218536541487385 iter num 240\n",
            "loss 58.6048469543457 average time 0.002411038253831066 iter num 260\n",
            "loss 1.2922163009643555 average time 0.002400697714269232 iter num 280\n",
            "loss 0.06286579370498657 average time 0.0023914397099724736 iter num 300\n",
            "loss 7.321741104125977 average time 0.0023913124999864976 iter num 320\n",
            "loss 4.564915180206299 average time 0.002415240994115961 iter num 340\n",
            "loss 0.7256525158882141 average time 0.002409947972233163 iter num 360\n",
            "loss 0.5094320774078369 average time 0.0024047408631687225 iter num 380\n",
            "loss 0.0003865529433824122 average time 0.0024151678525004172 iter num 400\n",
            "loss 0.057793229818344116 average time 0.0024087923166613715 iter num 420\n",
            "loss 19.47675895690918 average time 0.0024103424863617627 iter num 440\n",
            "loss 1.052697777748108 average time 0.0024033920804354043 iter num 460\n",
            "loss 3.3539235591888428 average time 0.0023983946229274504 iter num 480\n",
            "loss 34.53651428222656 average time 0.0023971241620201907 iter num 500\n",
            "loss 25.5591983795166 average time 0.002393154953859686 iter num 520\n",
            "loss 55.58296585083008 average time 0.002388029851866762 iter num 540\n",
            "loss 1.465052843093872 average time 0.0023845142571579866 iter num 560\n",
            "loss 0.05437515676021576 average time 0.002399001998288315 iter num 580\n",
            "loss 3.5708866119384766 average time 0.0023963809266782238 iter num 600\n",
            "loss 0.11723870784044266 average time 0.002393784591939977 iter num 620\n",
            "loss 70.85462188720703 average time 0.0023909847531371044 iter num 640\n",
            "loss 2.942861318588257 average time 0.0023859227666710495 iter num 660\n",
            "loss 0.41835644841194153 average time 0.002382185517653317 iter num 680\n",
            "loss 11.143805503845215 average time 0.002383467974286759 iter num 700\n",
            "loss 34.05193328857422 average time 0.0023821952611064665 iter num 720\n",
            "loss 0.007765047252178192 average time 0.0023821640743163525 iter num 740\n",
            "loss 0.1206633672118187 average time 0.0023786552960461307 iter num 760\n",
            "loss 2.198920726776123 average time 0.0023781975089686735 iter num 780\n",
            "loss 1.283851981163025 average time 0.0023794810549907196 iter num 800\n",
            "loss 9.5540189743042 average time 0.0023773554975511017 iter num 820\n",
            "loss 0.02528749592602253 average time 0.002374519186900042 iter num 840\n",
            "loss 1.1182717084884644 average time 0.002373038973249539 iter num 860\n",
            "loss 5.686961650848389 average time 0.002374016147723523 iter num 880\n",
            "loss 39.13434600830078 average time 0.0023731354211102168 iter num 900\n",
            "loss 1.917037010192871 average time 0.002371639169563344 iter num 920\n",
            "loss 6.0779194831848145 average time 0.0023699497691442493 iter num 940\n",
            "loss 0.03979533538222313 average time 0.0023689717041672034 iter num 960\n",
            "loss 55.114810943603516 average time 0.0023679438846909537 iter num 980\n",
            "loss 3.614877939224243 average time 0.002366734329998508 iter num 1000\n",
            "loss 0.6019584536552429 average time 0.0028872939999018852 iter num 20\n",
            "loss 1.393432855606079 average time 0.003011000049809809 iter num 40\n",
            "loss 0.5044190287590027 average time 0.0028152401165243645 iter num 60\n",
            "loss 17.06190299987793 average time 0.002687025112413721 iter num 80\n",
            "loss 3.4599978923797607 average time 0.0026134642298893595 iter num 100\n",
            "loss 2.177149534225464 average time 0.002557793841545693 iter num 120\n",
            "loss 2.30204701423645 average time 0.0025178331069972567 iter num 140\n",
            "loss 2.2315216064453125 average time 0.0025505428436076727 iter num 160\n",
            "loss 0.003574118949472904 average time 0.0025239910276468438 iter num 180\n",
            "loss 11.11744213104248 average time 0.0025052819748907496 iter num 200\n",
            "loss 2.236619710922241 average time 0.0024819038180463725 iter num 220\n",
            "loss 5.920139665249735e-05 average time 0.0024691716207219847 iter num 240\n",
            "loss 24.598791122436523 average time 0.0024552238614328065 iter num 260\n",
            "loss 4.576659202575684 average time 0.0024496052248975633 iter num 280\n",
            "loss 13.998257637023926 average time 0.002435635469889045 iter num 300\n",
            "loss 1.8400681018829346 average time 0.0024290297186439604 iter num 320\n",
            "loss 1.4724735021591187 average time 0.0024183264351984902 iter num 340\n",
            "loss 1.7074480056762695 average time 0.0024157245221279786 iter num 360\n",
            "loss 19.94586753845215 average time 0.0024078636209675383 iter num 380\n",
            "loss 2.0185837745666504 average time 0.0024020900624145726 iter num 400\n",
            "loss 34.55633544921875 average time 0.002396341966578759 iter num 420\n",
            "loss 0.27556726336479187 average time 0.002392005515821438 iter num 440\n",
            "loss 27.20128059387207 average time 0.002388439286875402 iter num 460\n",
            "loss 0.012487557716667652 average time 0.002381793326996255 iter num 480\n",
            "loss 87.02174377441406 average time 0.0023895523119135758 iter num 500\n",
            "loss 0.007735955994576216 average time 0.002395967924919135 iter num 520\n",
            "loss 1.8032777309417725 average time 0.0023928181073272384 iter num 540\n",
            "loss 23.157365798950195 average time 0.00240546849992305 iter num 560\n",
            "loss 5.33339262008667 average time 0.00240004137233976 iter num 580\n",
            "loss 0.28057530522346497 average time 0.0023961788965940894 iter num 600\n",
            "loss 3.3153223991394043 average time 0.002396381983802595 iter num 620\n",
            "loss 0.7023212313652039 average time 0.002392306810870082 iter num 640\n",
            "loss 8.553328370908275e-05 average time 0.0023891519620630073 iter num 660\n",
            "loss 0.6105380058288574 average time 0.00238760240141239 iter num 680\n",
            "loss 1.0458847284317017 average time 0.0023849705928010475 iter num 700\n",
            "loss 2.059743642807007 average time 0.002382511536052334 iter num 720\n",
            "loss 0.21059837937355042 average time 0.0023800530283232227 iter num 740\n",
            "loss 0.40296638011932373 average time 0.002386926769682568 iter num 760\n",
            "loss 1.2010747013846412e-05 average time 0.0023838430960985042 iter num 780\n",
            "loss 0.0013181982794776559 average time 0.002381499753691969 iter num 800\n",
            "loss 0.40351709723472595 average time 0.0023791181889686324 iter num 820\n",
            "loss 4.014172554016113 average time 0.0023783790475612305 iter num 840\n",
            "loss 0.8865976929664612 average time 0.0023758839104101393 iter num 860\n",
            "loss 0.38752222061157227 average time 0.002373975963581126 iter num 880\n",
            "loss 0.11367436498403549 average time 0.0023708902566169044 iter num 900\n",
            "loss 0.14053906500339508 average time 0.002371272001033978 iter num 920\n",
            "loss 2.485015392303467 average time 0.002374626933994884 iter num 940\n",
            "loss 0.010517388582229614 average time 0.002373830768700221 iter num 960\n",
            "loss 2.986342191696167 average time 0.0023733735897436344 iter num 980\n",
            "loss 0.1815193146467209 average time 0.002380346974950953 iter num 1000\n",
            "loss 4.301766395568848 average time 0.0031727640500321284 iter num 20\n",
            "loss 12.913284301757812 average time 0.00287724699987848 iter num 40\n",
            "loss 3.305095672607422 average time 0.0027409760333284793 iter num 60\n",
            "loss 0.03177058324217796 average time 0.0027103682000415574 iter num 80\n",
            "loss 14.988556861877441 average time 0.002675907460015878 iter num 100\n",
            "loss 1.5123077630996704 average time 0.002652014091639406 iter num 120\n",
            "loss 4.869572639465332 average time 0.0026377467785355943 iter num 140\n",
            "loss 0.18457239866256714 average time 0.0026192914311991443 iter num 160\n",
            "loss 0.2039390206336975 average time 0.0026324545833328254 iter num 180\n",
            "loss 1.9737321138381958 average time 0.0026077965650074474 iter num 200\n",
            "loss 50.5811882019043 average time 0.0026094406181982775 iter num 220\n",
            "loss 0.8092407584190369 average time 0.0026074533583293185 iter num 240\n",
            "loss 133.86294555664062 average time 0.002617858388454736 iter num 260\n",
            "loss 15.294811248779297 average time 0.0026313365606906052 iter num 280\n",
            "loss 0.009437167085707188 average time 0.002642802856638203 iter num 300\n",
            "loss 18.073396682739258 average time 0.0026456267624951125 iter num 320\n",
            "loss 4.682968616485596 average time 0.0026490732382037953 iter num 340\n",
            "loss 0.21003104746341705 average time 0.002650070388866273 iter num 360\n",
            "loss 0.3805626332759857 average time 0.002655039497351122 iter num 380\n",
            "loss 24.678621292114258 average time 0.0026797854974938673 iter num 400\n",
            "loss 45.187747955322266 average time 0.002674813861899782 iter num 420\n",
            "loss 0.3548531234264374 average time 0.0026734223772646973 iter num 440\n",
            "loss 6.032495021820068 average time 0.0026749950456376056 iter num 460\n",
            "loss 2.4841976165771484 average time 0.0026646682333345477 iter num 480\n",
            "loss 1.10220205783844 average time 0.0026663780480121204 iter num 500\n",
            "loss 3.0568149089813232 average time 0.0026679146307812445 iter num 520\n",
            "loss 0.018392840400338173 average time 0.0026767772277977472 iter num 540\n",
            "loss 3.921621799468994 average time 0.0026730696143074184 iter num 560\n",
            "loss 0.2524167001247406 average time 0.002675139493121919 iter num 580\n",
            "loss 6.901684284210205 average time 0.002675279181688287 iter num 600\n",
            "loss 6.0427775382995605 average time 0.0026690416548497582 iter num 620\n",
            "loss 6.536879539489746 average time 0.0026724137328272947 iter num 640\n",
            "loss 46.088985443115234 average time 0.0026713099818318205 iter num 660\n",
            "loss 51.12066650390625 average time 0.002670760610298577 iter num 680\n",
            "loss 3.0843818187713623 average time 0.002667559341425658 iter num 700\n",
            "loss 5.1516032218933105 average time 0.002666424276387463 iter num 720\n",
            "loss 1.7557331323623657 average time 0.0026615967513518284 iter num 740\n",
            "loss 0.547277569770813 average time 0.0026624323657918132 iter num 760\n",
            "loss 4.858097553253174 average time 0.0026632634641081936 iter num 780\n",
            "loss 21.993331909179688 average time 0.002664428615005363 iter num 800\n",
            "loss 5.10240364074707 average time 0.002662931417081581 iter num 820\n",
            "loss 0.928584098815918 average time 0.0026648969250064034 iter num 840\n",
            "loss 0.047721512615680695 average time 0.0026788143174472194 iter num 860\n",
            "loss 2.24334454536438 average time 0.0026796445068240165 iter num 880\n",
            "loss 0.028942842036485672 average time 0.0026818265022322723 iter num 900\n",
            "loss 0.005322033539414406 average time 0.002680163628270827 iter num 920\n",
            "loss 0.4347693622112274 average time 0.002678379124477323 iter num 940\n",
            "loss 0.07768584787845612 average time 0.002681884268760844 iter num 960\n",
            "loss 0.4647873640060425 average time 0.0026804488051107465 iter num 980\n",
            "loss 1.3314591646194458 average time 0.002682287243003884 iter num 1000\n",
            "loss 2.6850578784942627 average time 0.003315082349854492 iter num 20\n",
            "loss 0.2994645833969116 average time 0.003013437474919556 iter num 40\n",
            "loss 2.833332061767578 average time 0.0028922324000025886 iter num 60\n",
            "loss 0.8368425369262695 average time 0.00281306230001519 iter num 80\n",
            "loss 23.889118194580078 average time 0.0027976495600341876 iter num 100\n",
            "loss 8.827071189880371 average time 0.0027579798833964257 iter num 120\n",
            "loss 25.198911666870117 average time 0.0027574892000432425 iter num 140\n",
            "loss 7.671106338500977 average time 0.0027328765125275824 iter num 160\n",
            "loss 14.952484130859375 average time 0.0027341011222233647 iter num 180\n",
            "loss 5.550964832305908 average time 0.0027251290699769016 iter num 200\n",
            "loss 22.752212524414062 average time 0.0027137306817828426 iter num 220\n",
            "loss 2.8298609256744385 average time 0.002702145387479504 iter num 240\n",
            "loss 0.46276363730430603 average time 0.002695618865373735 iter num 260\n",
            "loss 0.02591094747185707 average time 0.0026830648142744653 iter num 280\n",
            "loss 0.29777660965919495 average time 0.002686513813308314 iter num 300\n",
            "loss 2.437307119369507 average time 0.002697802218722245 iter num 320\n",
            "loss 48.23821258544922 average time 0.0026825642499876696 iter num 340\n",
            "loss 9.452884674072266 average time 0.0026860251583204647 iter num 360\n",
            "loss 1.5775822401046753 average time 0.0026833210184074568 iter num 380\n",
            "loss 0.05814909189939499 average time 0.002680497809978988 iter num 400\n",
            "loss 0.7647974491119385 average time 0.0026828536166509107 iter num 420\n",
            "loss 7.506668567657471 average time 0.00268096199772365 iter num 440\n",
            "loss 0.41943809390068054 average time 0.0026819634108664024 iter num 460\n",
            "loss 6.100378513336182 average time 0.002685156383328528 iter num 480\n",
            "loss 4.866067409515381 average time 0.0026855194179952377 iter num 500\n",
            "loss 0.9309892654418945 average time 0.0026810127730676377 iter num 520\n",
            "loss 10.474955558776855 average time 0.0026863631703640243 iter num 540\n",
            "loss 14.65530014038086 average time 0.0026874579232136447 iter num 560\n",
            "loss 2.7759640216827393 average time 0.0026864117879430807 iter num 580\n",
            "loss 2.6712863445281982 average time 0.00268634684501194 iter num 600\n",
            "loss 53.342411041259766 average time 0.0026800411967850516 iter num 620\n",
            "loss 0.05252406373620033 average time 0.0026828242468894814 iter num 640\n",
            "loss 6.106598377227783 average time 0.0026733580015306044 iter num 660\n",
            "loss 0.0586288683116436 average time 0.00267141360001701 iter num 680\n",
            "loss 106.59264373779297 average time 0.0026753840743055793 iter num 700\n",
            "loss 0.006036871578544378 average time 0.0026760876402957164 iter num 720\n",
            "loss 0.6288663744926453 average time 0.0026748415000224053 iter num 740\n",
            "loss 222.4597625732422 average time 0.0026895854789664125 iter num 760\n",
            "loss 0.005705270450562239 average time 0.002689630301292476 iter num 780\n",
            "loss 0.9989702701568604 average time 0.0026882523312724517 iter num 800\n",
            "loss 13.602157592773438 average time 0.0026891061841724435 iter num 820\n",
            "loss 0.6589054465293884 average time 0.0026902761595530528 iter num 840\n",
            "loss 0.3836280405521393 average time 0.0026881094977080616 iter num 860\n",
            "loss 0.6768314242362976 average time 0.0026876083011715805 iter num 880\n",
            "loss 6.834743022918701 average time 0.0026867992278049417 iter num 900\n",
            "loss 0.10989544540643692 average time 0.0026809919511141863 iter num 920\n",
            "loss 0.06889913976192474 average time 0.002680463838325832 iter num 940\n",
            "loss 1.5291486978530884 average time 0.002681352870858215 iter num 960\n",
            "loss 12.348624229431152 average time 0.00267900230614663 iter num 980\n",
            "loss 0.6999272108078003 average time 0.00267951224202443 iter num 1000\n",
            "loss 0.43833327293395996 average time 0.0031178623998130207 iter num 20\n",
            "loss 0.0002751054707914591 average time 0.002823778924812359 iter num 40\n",
            "loss 0.6983770132064819 average time 0.0027410860665137687 iter num 60\n",
            "loss 68.42855834960938 average time 0.0027254041499418236 iter num 80\n",
            "loss 4.285998344421387 average time 0.0026648491799824113 iter num 100\n",
            "loss 3.2329423427581787 average time 0.0026133758083536425 iter num 120\n",
            "loss 32.24619674682617 average time 0.002571116264282734 iter num 140\n",
            "loss 2.3576183319091797 average time 0.0025433602437146875 iter num 160\n",
            "loss 83.68888092041016 average time 0.002512158066646306 iter num 180\n",
            "loss 3.2935831546783447 average time 0.002566920809986186 iter num 200\n",
            "loss 33.37558364868164 average time 0.0025480896363329853 iter num 220\n",
            "loss 0.0547134168446064 average time 0.002554292349964271 iter num 240\n",
            "loss 2.109320640563965 average time 0.0025322040576611473 iter num 260\n",
            "loss 7.868197917938232 average time 0.0025407320321197144 iter num 280\n",
            "loss 0.3465174436569214 average time 0.0025265109299652975 iter num 300\n",
            "loss 3.1767666339874268 average time 0.0025298570531049336 iter num 320\n",
            "loss 3.213348099961877e-05 average time 0.002514407394081739 iter num 340\n",
            "loss 0.17630234360694885 average time 0.0025014888999723753 iter num 360\n",
            "loss 0.0012936160201206803 average time 0.002489970192087448 iter num 380\n",
            "loss 0.1231948584318161 average time 0.0024905336174924743 iter num 400\n",
            "loss 0.9188610315322876 average time 0.002482292376182505 iter num 420\n",
            "loss 3.964282989501953 average time 0.0024716247749893227 iter num 440\n",
            "loss 0.01479610800743103 average time 0.0024621447826022 iter num 460\n",
            "loss 2.7581963539123535 average time 0.0024585838208319426 iter num 480\n",
            "loss 3.5201468467712402 average time 0.002452429705987015 iter num 500\n",
            "loss 0.033493999391794205 average time 0.0024451979769100243 iter num 520\n",
            "loss 1.1334282159805298 average time 0.002436683690730543 iter num 540\n",
            "loss 0.7317787408828735 average time 0.002445188971416558 iter num 560\n",
            "loss 0.17185595631599426 average time 0.002439711710331753 iter num 580\n",
            "loss 0.013656020164489746 average time 0.002434544584981874 iter num 600\n",
            "loss 10.072604179382324 average time 0.0024277157370834763 iter num 620\n",
            "loss 111.22981262207031 average time 0.0024256511937380764 iter num 640\n",
            "loss 7.125671863555908 average time 0.0024288713969602242 iter num 660\n",
            "loss 0.32275059819221497 average time 0.002423496961749633 iter num 680\n",
            "loss 3.0806312561035156 average time 0.0024215415199900494 iter num 700\n",
            "loss 9.125092506408691 average time 0.002419780179164061 iter num 720\n",
            "loss 58.80827713012695 average time 0.0024152445378382943 iter num 740\n",
            "loss 0.07074160873889923 average time 0.002421049118414119 iter num 760\n",
            "loss 0.04673661291599274 average time 0.00241551893588901 iter num 780\n",
            "loss 0.14228785037994385 average time 0.0024146581675017842 iter num 800\n",
            "loss 3.4763107299804688 average time 0.0024100271390236185 iter num 820\n",
            "loss 0.05472329631447792 average time 0.002407148644046434 iter num 840\n",
            "loss 0.008959755301475525 average time 0.00240411218371666 iter num 860\n",
            "loss 0.7111842036247253 average time 0.002401622638634845 iter num 880\n",
            "loss 5.759576797485352 average time 0.002399332909998419 iter num 900\n",
            "loss 27.358121871948242 average time 0.00239721932065075 iter num 920\n",
            "loss 1.032997965812683 average time 0.002394693055316082 iter num 940\n",
            "loss 0.051510490477085114 average time 0.0024017612385364372 iter num 960\n",
            "loss 6.239704608917236 average time 0.0024003118306034 iter num 980\n",
            "loss 0.7502156496047974 average time 0.0024048236339895084 iter num 1000\n",
            "loss 7.083495616912842 average time 0.0028394680499332025 iter num 20\n",
            "loss 8.871782302856445 average time 0.002657124899997143 iter num 40\n",
            "loss 0.0380018949508667 average time 0.0025265205334108034 iter num 60\n",
            "loss 2.5898423194885254 average time 0.002466793137591594 iter num 80\n",
            "loss 1.0005232095718384 average time 0.0024899676000677573 iter num 100\n",
            "loss 3.4829142093658447 average time 0.0025598669750252156 iter num 120\n",
            "loss 0.41250666975975037 average time 0.0025206805857383835 iter num 140\n",
            "loss 54.78656005859375 average time 0.0024922760750200725 iter num 160\n",
            "loss 18.69126319885254 average time 0.002472269977786507 iter num 180\n",
            "loss 5.513639450073242 average time 0.0024702829949910664 iter num 200\n",
            "loss 0.10785635560750961 average time 0.002452757877257351 iter num 220\n",
            "loss 12.447321891784668 average time 0.002448885137475069 iter num 240\n",
            "loss 0.06344578415155411 average time 0.0024330387538331988 iter num 260\n",
            "loss 12.785021781921387 average time 0.0024362957714142144 iter num 280\n",
            "loss 3.6060640811920166 average time 0.0024282732366555137 iter num 300\n",
            "loss 1.1578749418258667 average time 0.0024209385531264614 iter num 320\n",
            "loss 1.2303532361984253 average time 0.002415219532357536 iter num 340\n",
            "loss 2.3338401317596436 average time 0.0024108360805712437 iter num 360\n",
            "loss 0.3582784831523895 average time 0.0024045723921278152 iter num 380\n",
            "loss 8.794732093811035 average time 0.002401974615022482 iter num 400\n",
            "loss 6.456799030303955 average time 0.0023974903809782216 iter num 420\n",
            "loss 0.20820073783397675 average time 0.002397315195474386 iter num 440\n",
            "loss 43.43790817260742 average time 0.0024095634391533565 iter num 460\n",
            "loss 0.001044879318214953 average time 0.002404257631269502 iter num 480\n",
            "loss 0.5139618515968323 average time 0.002399421276022622 iter num 500\n",
            "loss 3.74737548828125 average time 0.002399906194243438 iter num 520\n",
            "loss 7.0617451667785645 average time 0.0023931901055591343 iter num 540\n",
            "loss 1.766356348991394 average time 0.0023895494374983174 iter num 560\n",
            "loss 0.05760446935892105 average time 0.002402802610347486 iter num 580\n",
            "loss 0.49009186029434204 average time 0.002401079493335298 iter num 600\n",
            "loss 14.018302917480469 average time 0.002397079783869201 iter num 620\n",
            "loss 0.07534705102443695 average time 0.0023932637156349303 iter num 640\n",
            "loss 0.4424341022968292 average time 0.002390297493945003 iter num 660\n",
            "loss 0.5563371777534485 average time 0.0023883272147165423 iter num 680\n",
            "loss 1.1391757726669312 average time 0.0023969929900028676 iter num 700\n",
            "loss 0.00993133895099163 average time 0.00239178498055834 iter num 720\n",
            "loss 0.04993659257888794 average time 0.002390430929741293 iter num 740\n",
            "loss 0.0015165526419878006 average time 0.002390516234216097 iter num 760\n",
            "loss 28.191638946533203 average time 0.0023877411589777555 iter num 780\n",
            "loss 14.023731231689453 average time 0.002384968127500997 iter num 800\n",
            "loss 4.242914199829102 average time 0.0023821748146385688 iter num 820\n",
            "loss 1.5916790962219238 average time 0.002382843904762835 iter num 840\n",
            "loss 0.15611277520656586 average time 0.002381158941856018 iter num 860\n",
            "loss 1.234778881072998 average time 0.0023793506977281965 iter num 880\n",
            "loss 1.60543692111969 average time 0.002377345145559957 iter num 900\n",
            "loss 0.013593068346381187 average time 0.0023802603663151114 iter num 920\n",
            "loss 17.689355850219727 average time 0.002381022223419271 iter num 940\n",
            "loss 6.212909698486328 average time 0.002378616206270105 iter num 960\n",
            "loss 0.0027794623747467995 average time 0.002376627552060812 iter num 980\n",
            "loss 0.5031457543373108 average time 0.002378360548022101 iter num 1000\n",
            "loss 0.0842200517654419 average time 0.00306570444990939 iter num 20\n",
            "loss 0.29729750752449036 average time 0.0026980627249486135 iter num 40\n",
            "loss 3.9115660190582275 average time 0.002570590249858166 iter num 60\n",
            "loss 13.524383544921875 average time 0.0025482097873464225 iter num 80\n",
            "loss 15.906022071838379 average time 0.0025015527198229393 iter num 100\n",
            "loss 5.416400909423828 average time 0.002487884766484664 iter num 120\n",
            "loss 1.6325427293777466 average time 0.0024619856498377755 iter num 140\n",
            "loss 0.7866913080215454 average time 0.002445660206103639 iter num 160\n",
            "loss 0.6467800736427307 average time 0.002440696672106747 iter num 180\n",
            "loss 6.353267192840576 average time 0.0024286110148750593 iter num 200\n",
            "loss 6.034688949584961 average time 0.0024420739498881715 iter num 220\n",
            "loss 4.24069881439209 average time 0.002439093066550413 iter num 240\n",
            "loss 0.20804154872894287 average time 0.0024254556998969815 iter num 260\n",
            "loss 29.63082504272461 average time 0.002414327432065225 iter num 280\n",
            "loss 8.241339683532715 average time 0.002404052439918208 iter num 300\n",
            "loss 227.9182586669922 average time 0.002401406971819142 iter num 320\n",
            "loss 0.3065113127231598 average time 0.0023961087470203944 iter num 340\n",
            "loss 0.16544844210147858 average time 0.0023919404194051217 iter num 360\n",
            "loss 0.8111704587936401 average time 0.0023855399236565157 iter num 380\n",
            "loss 4.292166709899902 average time 0.002387113672475607 iter num 400\n",
            "loss 20.66831398010254 average time 0.002382802526162344 iter num 420\n",
            "loss 0.9970515370368958 average time 0.00237895414999333 iter num 440\n",
            "loss 206.86178588867188 average time 0.002395942278255224 iter num 460\n",
            "loss 7.851364612579346 average time 0.002392424510424007 iter num 480\n",
            "loss 1.0275461673736572 average time 0.002388928743999713 iter num 500\n",
            "loss 0.7589439153671265 average time 0.002385731346164623 iter num 520\n",
            "loss 16.93640899658203 average time 0.0023841499926068837 iter num 540\n",
            "loss 7.635647296905518 average time 0.0023853354768074756 iter num 560\n",
            "loss 10.428043365478516 average time 0.002383088639685568 iter num 580\n",
            "loss 68.2200698852539 average time 0.0023817522983699746 iter num 600\n",
            "loss 43.06550598144531 average time 0.00238191318551124 iter num 620\n",
            "loss 0.6260534524917603 average time 0.0023807744390808238 iter num 640\n",
            "loss 0.13767801225185394 average time 0.0023777128833458077 iter num 660\n",
            "loss 18.8184871673584 average time 0.0023829294073654155 iter num 680\n",
            "loss 0.2173452079296112 average time 0.0023789872642997318 iter num 700\n",
            "loss 2.7637743949890137 average time 0.0023795762555664625 iter num 720\n",
            "loss 14.2301664352417 average time 0.0023769174000114394 iter num 740\n",
            "loss 33.0460090637207 average time 0.0023746874263188625 iter num 760\n",
            "loss 0.6172612905502319 average time 0.0023726813179541168 iter num 780\n",
            "loss 7.5623321533203125 average time 0.0023718790862540117 iter num 800\n",
            "loss 0.20444117486476898 average time 0.002370153171955835 iter num 820\n",
            "loss 23.50642967224121 average time 0.0023690017369127807 iter num 840\n",
            "loss 20.11707878112793 average time 0.0023683837128014285 iter num 860\n",
            "loss 0.21615064144134521 average time 0.0023687697897871243 iter num 880\n",
            "loss 7.236927922349423e-05 average time 0.0023773017066802517 iter num 900\n",
            "loss 20.885107040405273 average time 0.0023829684282705072 iter num 920\n",
            "loss 2.7226309776306152 average time 0.0023794044351118228 iter num 940\n",
            "loss 1.8315205574035645 average time 0.0023791645656217495 iter num 960\n",
            "loss 0.0029840506613254547 average time 0.0023777201459129825 iter num 980\n",
            "loss 1.3592588901519775 average time 0.0023751763980017133 iter num 1000\n",
            "loss 189.6344451904297 average time 0.0028705885999443124 iter num 20\n",
            "loss 4.360816478729248 average time 0.0026915144001577575 iter num 40\n",
            "loss 34.382362365722656 average time 0.0026188207001420476 iter num 60\n",
            "loss 0.2017018347978592 average time 0.0025428442875636394 iter num 80\n",
            "loss 2.020275115966797 average time 0.0024926352900547497 iter num 100\n",
            "loss 7.1727375984191895 average time 0.002511482716727187 iter num 120\n",
            "loss 0.3615581691265106 average time 0.0024738588001127935 iter num 140\n",
            "loss 24.204879760742188 average time 0.0025102594313466398 iter num 160\n",
            "loss 35.36506652832031 average time 0.0025321174556362774 iter num 180\n",
            "loss 39.9561882019043 average time 0.0025805973750721023 iter num 200\n",
            "loss 1.4849889278411865 average time 0.0025819658228101615 iter num 220\n",
            "loss 74.57011413574219 average time 0.0025918119834007786 iter num 240\n",
            "loss 0.4921128749847412 average time 0.002589661053920841 iter num 260\n",
            "loss 1.9320664405822754 average time 0.002593359725070903 iter num 280\n",
            "loss 8.142486572265625 average time 0.0026016274267506865 iter num 300\n",
            "loss 5.3209428787231445 average time 0.0026010356157087243 iter num 320\n",
            "loss 7.930661678314209 average time 0.002606961170664256 iter num 340\n",
            "loss 19.34551429748535 average time 0.0026446333667334127 iter num 360\n",
            "loss 1.8655318021774292 average time 0.002646916686908777 iter num 380\n",
            "loss 0.16834864020347595 average time 0.002651139192548726 iter num 400\n",
            "loss 10.515144348144531 average time 0.0026535418548042974 iter num 420\n",
            "loss 0.3494022786617279 average time 0.002657315013675543 iter num 440\n",
            "loss 0.2065895050764084 average time 0.0026534264348257513 iter num 460\n",
            "loss 11.252029418945312 average time 0.002649751979204969 iter num 480\n",
            "loss 9.43614387512207 average time 0.0026508715180316358 iter num 500\n",
            "loss 8.117273330688477 average time 0.0026498500981058616 iter num 520\n",
            "loss 1.9825197458267212 average time 0.0026535343463196855 iter num 540\n",
            "loss 32.83031463623047 average time 0.0026477396143198867 iter num 560\n",
            "loss 0.008137837052345276 average time 0.002646929236251363 iter num 580\n",
            "loss 6.061171054840088 average time 0.0026426972550386077 iter num 600\n",
            "loss 1.5146729946136475 average time 0.00263943613873644 iter num 620\n",
            "loss 1.0804595947265625 average time 0.002630953685971349 iter num 640\n",
            "loss 2.703730344772339 average time 0.002634003706093195 iter num 660\n",
            "loss 0.01383652351796627 average time 0.0026325353309082002 iter num 680\n",
            "loss 0.6935493350028992 average time 0.002625493842879223 iter num 700\n",
            "loss 7.521265983581543 average time 0.00262706201808669 iter num 720\n",
            "loss 1.92402184009552 average time 0.002626996302739359 iter num 740\n",
            "loss 11.567275047302246 average time 0.0026222597395046347 iter num 760\n",
            "loss 3.8495001792907715 average time 0.0026225827692705466 iter num 780\n",
            "loss 234.84945678710938 average time 0.002647644615033187 iter num 800\n",
            "loss 2.5369515419006348 average time 0.002648309824423738 iter num 820\n",
            "loss 0.22427520155906677 average time 0.0026492532607530197 iter num 840\n",
            "loss 0.5001197457313538 average time 0.0026501416686335495 iter num 860\n",
            "loss 0.10581154376268387 average time 0.0026493793386614265 iter num 880\n",
            "loss 0.35347285866737366 average time 0.0026455919722502587 iter num 900\n",
            "loss 1.357227087020874 average time 0.002646499607639587 iter num 920\n",
            "loss 1.3885782209399622e-05 average time 0.002648828464922151 iter num 940\n",
            "loss 0.5791577100753784 average time 0.0026495463635683334 iter num 960\n",
            "loss 0.35202282667160034 average time 0.0026495162010438176 iter num 980\n",
            "loss 1.1415385007858276 average time 0.0026485993250280446 iter num 1000\n",
            "loss 307.11444091796875 average time 0.0032745162499850265 iter num 20\n",
            "loss 3.1987247467041016 average time 0.0029611888499402996 iter num 40\n",
            "loss 0.5327489376068115 average time 0.002813754516622187 iter num 60\n",
            "loss 23.73959732055664 average time 0.002793733437420087 iter num 80\n",
            "loss 4.827540397644043 average time 0.0027524216698839154 iter num 100\n",
            "loss 14.1426362991333 average time 0.0027605483665865903 iter num 120\n",
            "loss 0.04363182932138443 average time 0.002750442271371867 iter num 140\n",
            "loss 24.285236358642578 average time 0.0027282902437036683 iter num 160\n",
            "loss 1.8482322692871094 average time 0.0027121240777382306 iter num 180\n",
            "loss 37.44881820678711 average time 0.002731254349946539 iter num 200\n",
            "loss 8.843581199645996 average time 0.002723373159038932 iter num 220\n",
            "loss 4.628938674926758 average time 0.0027219681207952817 iter num 240\n",
            "loss 28.89423370361328 average time 0.0027437712076579584 iter num 260\n",
            "loss 2.0754311084747314 average time 0.002732082492821064 iter num 280\n",
            "loss 0.008387492038309574 average time 0.002722010706650811 iter num 300\n",
            "loss 11.212728500366211 average time 0.002714903487498077 iter num 320\n",
            "loss 1.092531442642212 average time 0.0027141501294114705 iter num 340\n",
            "loss 8.602336883544922 average time 0.002710165838890235 iter num 360\n",
            "loss 0.07789172232151031 average time 0.0027106949552609494 iter num 380\n",
            "loss 33.50282287597656 average time 0.0026963943874989127 iter num 400\n",
            "loss 5.316298007965088 average time 0.00269638671903695 iter num 420\n",
            "loss 5.521632194519043 average time 0.0026965286613589838 iter num 440\n",
            "loss 11.256795883178711 average time 0.002697441815219107 iter num 460\n",
            "loss 0.24441629648208618 average time 0.002700804089583168 iter num 480\n",
            "loss 8.093771934509277 average time 0.0026916123919909296 iter num 500\n",
            "loss 0.08616571128368378 average time 0.002689960678834233 iter num 520\n",
            "loss 0.17318327724933624 average time 0.0026761965703506712 iter num 540\n",
            "loss 0.31694507598876953 average time 0.0026709572731988375 iter num 560\n",
            "loss 0.4693470895290375 average time 0.002673454213775052 iter num 580\n",
            "loss 0.37093585729599 average time 0.002667286551647218 iter num 600\n",
            "loss 0.9668024182319641 average time 0.0026677418451336345 iter num 620\n",
            "loss 2.3637373447418213 average time 0.0026686232046557734 iter num 640\n",
            "loss 23.068235397338867 average time 0.002660653028774642 iter num 660\n",
            "loss 0.19467785954475403 average time 0.0026582037264554804 iter num 680\n",
            "loss 0.37952789664268494 average time 0.002655744157130227 iter num 700\n",
            "loss 0.3954358696937561 average time 0.002666600094431083 iter num 720\n",
            "loss 62.93743133544922 average time 0.0026684358391714734 iter num 740\n",
            "loss 12.912516593933105 average time 0.0026643434736725842 iter num 760\n",
            "loss 12.861006736755371 average time 0.002665914117940888 iter num 780\n",
            "loss 0.00013231378397904336 average time 0.0026695748912447925 iter num 800\n",
            "loss 0.7674418687820435 average time 0.0026709169695073444 iter num 820\n",
            "loss 0.27190616726875305 average time 0.0026637564785644266 iter num 840\n",
            "loss 0.43262895941734314 average time 0.0026650746906916327 iter num 860\n",
            "loss 5.085322380065918 average time 0.0026625295920460054 iter num 880\n",
            "loss 3.6613574028015137 average time 0.0026608383255532116 iter num 900\n",
            "loss 0.424637109041214 average time 0.002657389588037641 iter num 920\n",
            "loss 31.39434242248535 average time 0.0026603774957406363 iter num 940\n",
            "loss 0.9952753782272339 average time 0.002660377761454432 iter num 960\n",
            "loss 0.008181944489479065 average time 0.002654562428571288 iter num 980\n",
            "loss 0.04304021596908569 average time 0.0026559668310001143 iter num 1000\n",
            "loss 22.173887252807617 average time 0.0033108542002082686 iter num 20\n",
            "loss 23.074905395507812 average time 0.002922507399944152 iter num 40\n",
            "loss 0.004980325698852539 average time 0.0028371244665928923 iter num 60\n",
            "loss 18.00511360168457 average time 0.0027297508624997135 iter num 80\n",
            "loss 0.014506139792501926 average time 0.0026320327800385714 iter num 100\n",
            "loss 26.816518783569336 average time 0.0025760316583424963 iter num 120\n",
            "loss 17.576169967651367 average time 0.0025493981571474123 iter num 140\n",
            "loss 9.849345207214355 average time 0.0025099392625065773 iter num 160\n",
            "loss 7.106784820556641 average time 0.0025823723944591215 iter num 180\n",
            "loss 9.330195426940918 average time 0.0025543100800405226 iter num 200\n",
            "loss 9.695228576660156 average time 0.0025325488091270513 iter num 220\n",
            "loss 8.124013900756836 average time 0.0025110055167109143 iter num 240\n",
            "loss 2.6322383880615234 average time 0.002491588800057798 iter num 260\n",
            "loss 0.011700652539730072 average time 0.0024727176071857163 iter num 280\n",
            "loss 18.544837951660156 average time 0.0024653916133805373 iter num 300\n",
            "loss 6.039552211761475 average time 0.0024803441094377377 iter num 320\n",
            "loss 0.4359876215457916 average time 0.002466486952974211 iter num 340\n",
            "loss 0.004442274570465088 average time 0.002455254836129623 iter num 360\n",
            "loss 0.22802628576755524 average time 0.0024664452026531523 iter num 380\n",
            "loss 12.08234977722168 average time 0.002456307205011399 iter num 400\n",
            "loss 22.070898056030273 average time 0.0024531492285816405 iter num 420\n",
            "loss 0.7615448832511902 average time 0.002446556970459245 iter num 440\n",
            "loss 0.6128679513931274 average time 0.002442626621739138 iter num 460\n",
            "loss 0.8245003819465637 average time 0.002448128047914603 iter num 480\n",
            "loss 1.5450917482376099 average time 0.002441913625993038 iter num 500\n",
            "loss 4.0099257603287697e-07 average time 0.002432730186539909 iter num 520\n",
            "loss 0.9830271601676941 average time 0.0024285032611159195 iter num 540\n",
            "loss 60.11288833618164 average time 0.002424105467863618 iter num 560\n",
            "loss 0.7342044115066528 average time 0.002418440881040718 iter num 580\n",
            "loss 0.007989585399627686 average time 0.0024148988750069596 iter num 600\n",
            "loss 2.7305424213409424 average time 0.0024266464129082564 iter num 620\n",
            "loss 0.0668964833021164 average time 0.0024359850437576823 iter num 640\n",
            "loss 20.394142150878906 average time 0.002430424306062791 iter num 660\n",
            "loss 30.19388198852539 average time 0.0024256874161812233 iter num 680\n",
            "loss 0.976797878742218 average time 0.0024225414071562617 iter num 700\n",
            "loss 0.9207488298416138 average time 0.002428863044461751 iter num 720\n",
            "loss 1.6224689483642578 average time 0.0024263691013771136 iter num 740\n",
            "loss 1.1256569623947144 average time 0.0024223511408141157 iter num 760\n",
            "loss 74.90266418457031 average time 0.002419719442336944 iter num 780\n",
            "loss 0.4582490026950836 average time 0.0024181076762761224 iter num 800\n",
            "loss 0.06617646664381027 average time 0.0024141839353876825 iter num 820\n",
            "loss 0.8639217019081116 average time 0.0024108173690755 iter num 840\n",
            "loss 0.21856224536895752 average time 0.002410415383749137 iter num 860\n",
            "loss 865.7822875976562 average time 0.0024158742159381126 iter num 880\n",
            "loss 1.8839170932769775 average time 0.0024214393122585737 iter num 900\n",
            "loss 16.99347686767578 average time 0.0024169122750386718 iter num 920\n",
            "loss 2.513310432434082 average time 0.0024145100862040907 iter num 940\n",
            "loss 2.7511558532714844 average time 0.0024117339521145214 iter num 960\n",
            "loss 22.843063354492188 average time 0.0024081705694178317 iter num 980\n",
            "loss 0.017997125163674355 average time 0.0024056009400319454 iter num 1000\n",
            "loss 1.6859538555145264 average time 0.0029297412501364307 iter num 20\n",
            "loss 1.5652763843536377 average time 0.002637579300062498 iter num 40\n",
            "loss 16.735309600830078 average time 0.0025467345000530863 iter num 60\n",
            "loss 1.2031749486923218 average time 0.0024900331124854346 iter num 80\n",
            "loss 7.419900417327881 average time 0.002515117500006454 iter num 100\n",
            "loss 0.7620410323143005 average time 0.002476509533380522 iter num 120\n",
            "loss 0.06367426365613937 average time 0.0025116084214589916 iter num 140\n",
            "loss 0.18428994715213776 average time 0.002513688006274606 iter num 160\n",
            "loss 4.5810017585754395 average time 0.0025252346389404716 iter num 180\n",
            "loss 15.4688081741333 average time 0.0024945103050322357 iter num 200\n",
            "loss 9.268447875976562 average time 0.0025132156863946877 iter num 220\n",
            "loss 0.7435562014579773 average time 0.002493547829196056 iter num 240\n",
            "loss 6.5280656814575195 average time 0.002479696719260224 iter num 260\n",
            "loss 2.696462869644165 average time 0.0024637077928803463 iter num 280\n",
            "loss 1.7820850610733032 average time 0.0024524410133562923 iter num 300\n",
            "loss 34.96115493774414 average time 0.0024409223312602535 iter num 320\n",
            "loss 19.552709579467773 average time 0.0024383147088348563 iter num 340\n",
            "loss 45.82293701171875 average time 0.002436475508334802 iter num 360\n",
            "loss 12.834117889404297 average time 0.0024297472447199794 iter num 380\n",
            "loss 0.22461992502212524 average time 0.002422444889984945 iter num 400\n",
            "loss 23.3951473236084 average time 0.0024187849547550808 iter num 420\n",
            "loss 1.7897676229476929 average time 0.0024115355590807173 iter num 440\n",
            "loss 0.3090127110481262 average time 0.00240775012390931 iter num 460\n",
            "loss 0.21882398426532745 average time 0.0024041076499959975 iter num 480\n",
            "loss 17.462644577026367 average time 0.0024021470659936314 iter num 500\n",
            "loss 3.3136885166168213 average time 0.0023961721134513098 iter num 520\n",
            "loss 32.953792572021484 average time 0.0023923406444366804 iter num 540\n",
            "loss 4.839785099029541 average time 0.002402525858919294 iter num 560\n",
            "loss 1.6446723937988281 average time 0.0023971922068869453 iter num 580\n",
            "loss 18.00955581665039 average time 0.002401339301665454 iter num 600\n",
            "loss 2.3490686416625977 average time 0.0023979776387052206 iter num 620\n",
            "loss 21.601730346679688 average time 0.0023939192249912366 iter num 640\n",
            "loss 5.576627254486084 average time 0.0023928052287760003 iter num 660\n",
            "loss 2.199429750442505 average time 0.002390456467631285 iter num 680\n",
            "loss 3.7165422439575195 average time 0.002387962951418428 iter num 700\n",
            "loss 0.21852652728557587 average time 0.002386224694439281 iter num 720\n",
            "loss 0.001553269918076694 average time 0.0023850072202696686 iter num 740\n",
            "loss 0.02323017083108425 average time 0.00238190480657929 iter num 760\n",
            "loss 0.09737493097782135 average time 0.0023788856871854083 iter num 780\n",
            "loss 0.32721731066703796 average time 0.0023770089537583773 iter num 800\n",
            "loss 0.32759273052215576 average time 0.0023758089804975565 iter num 820\n",
            "loss 440.354248046875 average time 0.0023846690273937082 iter num 840\n",
            "loss 0.04724268242716789 average time 0.0023823771918677966 iter num 860\n",
            "loss 0.2865017056465149 average time 0.0023812470886489545 iter num 880\n",
            "loss 0.3413318693637848 average time 0.00237968919778925 iter num 900\n",
            "loss 0.132223442196846 average time 0.0023775413054468314 iter num 920\n",
            "loss 3.3597497940063477 average time 0.00238559326277956 iter num 940\n",
            "loss 10.009167671203613 average time 0.002383674011472673 iter num 960\n",
            "loss 18.766098022460938 average time 0.0023826913367531455 iter num 980\n",
            "loss 1.4462065696716309 average time 0.002379712246020063 iter num 1000\n",
            "loss 2.587841510772705 average time 0.0029429448997689176 iter num 20\n",
            "loss 0.009090022183954716 average time 0.0025999916999808192 iter num 40\n",
            "loss 2.40337872505188 average time 0.0025034680334404887 iter num 60\n",
            "loss 4.947393417358398 average time 0.0024747396000748267 iter num 80\n",
            "loss 12.625391006469727 average time 0.002442519570049626 iter num 100\n",
            "loss 0.3038712739944458 average time 0.0024102154083872544 iter num 120\n",
            "loss 83.7961196899414 average time 0.002402686992926257 iter num 140\n",
            "loss 6.100020408630371 average time 0.00238556303132782 iter num 160\n",
            "loss 0.2073947936296463 average time 0.002375413955633121 iter num 180\n",
            "loss 1.480507254600525 average time 0.002374984385078278 iter num 200\n",
            "loss 0.3483556807041168 average time 0.002368391786430121 iter num 220\n",
            "loss 51.63844299316406 average time 0.002361128962562968 iter num 240\n",
            "loss 2.8558504581451416 average time 0.002356423646233452 iter num 260\n",
            "loss 0.6404200196266174 average time 0.0023515661750739777 iter num 280\n",
            "loss 630.11181640625 average time 0.0023496007834061554 iter num 300\n",
            "loss 0.5884560942649841 average time 0.0023724908188228256 iter num 320\n",
            "loss 15.357460021972656 average time 0.0023674154294734333 iter num 340\n",
            "loss 3.0003702640533447 average time 0.002361170063947308 iter num 360\n",
            "loss 6.386155128479004 average time 0.0023584762184710646 iter num 380\n",
            "loss 0.9423830509185791 average time 0.002353560475039558 iter num 400\n",
            "loss 0.5484214425086975 average time 0.0023486150976558358 iter num 420\n",
            "loss 0.21306867897510529 average time 0.002343197727309003 iter num 440\n",
            "loss 21.326169967651367 average time 0.002340402519601649 iter num 460\n",
            "loss 0.1031041368842125 average time 0.0023400272041991838 iter num 480\n",
            "loss 0.49402809143066406 average time 0.0023380730420394682 iter num 500\n",
            "loss 0.3554987907409668 average time 0.0023364034346601468 iter num 520\n",
            "loss 12.22597885131836 average time 0.0023445976296763414 iter num 540\n",
            "loss 4.0979743003845215 average time 0.002341090226819428 iter num 560\n",
            "loss 4.071883678436279 average time 0.0023380428224456786 iter num 580\n",
            "loss 9.636356353759766 average time 0.0023381813016900804 iter num 600\n",
            "loss 2.4050052165985107 average time 0.002337262554864273 iter num 620\n",
            "loss 2.8511462211608887 average time 0.002335559934402909 iter num 640\n",
            "loss 7.554068088531494 average time 0.0023341110818447222 iter num 660\n",
            "loss 0.12068266421556473 average time 0.0023315605691363196 iter num 680\n",
            "loss 13.398921966552734 average time 0.0023391031685995197 iter num 700\n",
            "loss 9.902020454406738 average time 0.002336607423641605 iter num 720\n",
            "loss 0.7699000835418701 average time 0.002335269110836954 iter num 740\n",
            "loss 0.0027121531311422586 average time 0.0023327715605534504 iter num 760\n",
            "loss 0.19585108757019043 average time 0.002336301761573477 iter num 780\n",
            "loss 3.0997965335845947 average time 0.0023458951537850227 iter num 800\n",
            "loss 50.72339630126953 average time 0.0023439225378441312 iter num 820\n",
            "loss 7.896772384643555 average time 0.0023414317869407696 iter num 840\n",
            "loss 0.053225550800561905 average time 0.0023401372698043455 iter num 860\n",
            "loss 0.058688048273324966 average time 0.002339579376176847 iter num 880\n",
            "loss 0.05215229094028473 average time 0.002339227461147352 iter num 900\n",
            "loss 0.9150328636169434 average time 0.0023374776272090535 iter num 920\n",
            "loss 0.006050188560038805 average time 0.002346917029818213 iter num 940\n",
            "loss 0.05249631777405739 average time 0.002345821728158626 iter num 960\n",
            "loss 0.16030435264110565 average time 0.002344734930647974 iter num 980\n",
            "loss 0.033607639372348785 average time 0.0023430264120343053 iter num 1000\n",
            "loss 0.02136668562889099 average time 0.003080009449968202 iter num 20\n",
            "loss 0.02468961291015148 average time 0.002674532299988641 iter num 40\n",
            "loss 34.32914733886719 average time 0.0025540966999566686 iter num 60\n",
            "loss 0.19637435674667358 average time 0.002500221162495109 iter num 80\n",
            "loss 0.40401291847229004 average time 0.0025289669500125457 iter num 100\n",
            "loss 0.39813947677612305 average time 0.0024900170749788232 iter num 120\n",
            "loss 8.269842147827148 average time 0.0024574259928808067 iter num 140\n",
            "loss 1.0655226707458496 average time 0.0024322966250110768 iter num 160\n",
            "loss 2.6746253967285156 average time 0.002421646400044766 iter num 180\n",
            "loss 27.026559829711914 average time 0.00240770305001206 iter num 200\n",
            "loss 0.2580508291721344 average time 0.002395462427301192 iter num 220\n",
            "loss 0.3390246331691742 average time 0.002387308616691068 iter num 240\n",
            "loss 0.004340653773397207 average time 0.0024045290615714084 iter num 260\n",
            "loss 13.46524715423584 average time 0.0024190737714499325 iter num 280\n",
            "loss 1.3963286876678467 average time 0.002439450520008298 iter num 300\n",
            "loss 12.143580436706543 average time 0.0024582092468904194 iter num 320\n",
            "loss 1.0814402103424072 average time 0.002454620900008355 iter num 340\n",
            "loss 18.649545669555664 average time 0.002462731572222765 iter num 360\n",
            "loss 0.0005502108251675963 average time 0.002476281655244269 iter num 380\n",
            "loss 5.327368259429932 average time 0.002519153384992023 iter num 400\n",
            "loss 0.611102819442749 average time 0.0025111584595184206 iter num 420\n",
            "loss 2.8809502124786377 average time 0.0025123386318227857 iter num 440\n",
            "loss 2.5930356979370117 average time 0.0025231808913066863 iter num 460\n",
            "loss 11.154250144958496 average time 0.002521397504168969 iter num 480\n",
            "loss 0.7143623232841492 average time 0.0025240061479998984 iter num 500\n",
            "loss 5.975523948669434 average time 0.002530158930777851 iter num 520\n",
            "loss 2.0188004970550537 average time 0.0025306661037036438 iter num 540\n",
            "loss 6.848831653594971 average time 0.0025384695232170476 iter num 560\n",
            "loss 1.67081880569458 average time 0.0025404931965630536 iter num 580\n",
            "loss 11.038994789123535 average time 0.002545492081674941 iter num 600\n",
            "loss 31.688278198242188 average time 0.0025501627967822707 iter num 620\n",
            "loss 13.054147720336914 average time 0.002552695601571031 iter num 640\n",
            "loss 0.13036511838436127 average time 0.0025578044590970836 iter num 660\n",
            "loss 0.4445936679840088 average time 0.0025556255176525156 iter num 680\n",
            "loss 1.726526141166687 average time 0.002556568355716341 iter num 700\n",
            "loss 0.9509940147399902 average time 0.002564090637505008 iter num 720\n",
            "loss 0.08186325430870056 average time 0.0025643320216290335 iter num 740\n",
            "loss 0.16946960985660553 average time 0.002567071543425252 iter num 760\n",
            "loss 3.8860843181610107 average time 0.0025677153551371774 iter num 780\n",
            "loss 35.02488327026367 average time 0.002569975683754819 iter num 800\n",
            "loss 7.199924945831299 average time 0.002573131831712356 iter num 820\n",
            "loss 0.0020102709531784058 average time 0.002573961358341746 iter num 840\n",
            "loss 0.0018123770132660866 average time 0.0025879690813992566 iter num 860\n",
            "loss 7.510724067687988 average time 0.0025843815340956347 iter num 880\n",
            "loss 96.41351318359375 average time 0.002588219116672311 iter num 900\n",
            "loss 0.5064035058021545 average time 0.0025902158358783946 iter num 920\n",
            "loss 23.36799430847168 average time 0.0025905627819233913 iter num 940\n",
            "loss 0.13312320411205292 average time 0.0025856895437603574 iter num 960\n",
            "loss 0.16118137538433075 average time 0.0025883722408271215 iter num 980\n",
            "loss 0.3828541934490204 average time 0.002590802442013228 iter num 1000\n",
            "loss 0.20873941481113434 average time 0.003053954650295054 iter num 20\n",
            "loss 1.4725197553634644 average time 0.0027992443502625973 iter num 40\n",
            "loss 5.228671073913574 average time 0.002758603800187605 iter num 60\n",
            "loss 6.456838130950928 average time 0.002710276637685638 iter num 80\n",
            "loss 2.4297378063201904 average time 0.0027040038601626295 iter num 100\n",
            "loss 17.787681579589844 average time 0.0027058572501421924 iter num 120\n",
            "loss 1.252783179283142 average time 0.0026630521001217338 iter num 140\n",
            "loss 3.8125038146972656 average time 0.0026619255751029413 iter num 160\n",
            "loss 0.7286517024040222 average time 0.0026626783889696524 iter num 180\n",
            "loss 12.60168170928955 average time 0.0026583811600539775 iter num 200\n",
            "loss 0.8959070444107056 average time 0.002632312500058602 iter num 220\n",
            "loss 2.978821039199829 average time 0.0026387323250598154 iter num 240\n",
            "loss 30.620052337646484 average time 0.002637379019268757 iter num 260\n",
            "loss 0.009600178338587284 average time 0.0026323512964609107 iter num 280\n",
            "loss 15.821423530578613 average time 0.0026295262867218603 iter num 300\n",
            "loss 0.7799094915390015 average time 0.002649352090668344 iter num 320\n",
            "loss 19.17228126525879 average time 0.0026481796676735567 iter num 340\n",
            "loss 3.9369266033172607 average time 0.0026519658333604133 iter num 360\n",
            "loss 167.9807586669922 average time 0.0026536005131770493 iter num 380\n",
            "loss 16.959243774414062 average time 0.002639047362504243 iter num 400\n",
            "loss 4.797915458679199 average time 0.002641462719050954 iter num 420\n",
            "loss 0.001037568086758256 average time 0.0026369459022754943 iter num 440\n",
            "loss 17.67228889465332 average time 0.002633443421734188 iter num 460\n",
            "loss 1.8581054210662842 average time 0.0026325522229171837 iter num 480\n",
            "loss 2.6826674938201904 average time 0.002630993932001729 iter num 500\n",
            "loss 0.14607848227024078 average time 0.0026320749346163772 iter num 520\n",
            "loss 0.3910238444805145 average time 0.002629834398144508 iter num 540\n",
            "loss 0.44824060797691345 average time 0.0026293848214273955 iter num 560\n",
            "loss 2.541060447692871 average time 0.002619898698265325 iter num 580\n",
            "loss 2.049938917160034 average time 0.0026186589033174337 iter num 600\n",
            "loss 8.50367546081543 average time 0.002623159746754907 iter num 620\n",
            "loss 0.12035878747701645 average time 0.0026193146734186713 iter num 640\n",
            "loss 74.03912353515625 average time 0.002621299522715245 iter num 660\n",
            "loss 0.7485100626945496 average time 0.0026235651735104885 iter num 680\n",
            "loss 0.09064384549856186 average time 0.00262606755284131 iter num 700\n",
            "loss 4.5967278480529785 average time 0.002625603265257976 iter num 720\n",
            "loss 3.952155113220215 average time 0.0026249441134913887 iter num 740\n",
            "loss 8.59326457977295 average time 0.002627348024974421 iter num 760\n",
            "loss 2.7024383544921875 average time 0.0026434193525346926 iter num 780\n",
            "loss 0.09533372521400452 average time 0.0026446951237221582 iter num 800\n",
            "loss 0.0002828938013408333 average time 0.0026421480536222724 iter num 820\n",
            "loss 0.317922979593277 average time 0.002643024064255293 iter num 840\n",
            "loss 3.4965107440948486 average time 0.002641287780204229 iter num 860\n",
            "loss 20.23668098449707 average time 0.002642527961335294 iter num 880\n",
            "loss 2.830841064453125 average time 0.0026408579799802588 iter num 900\n",
            "loss 0.17355813086032867 average time 0.002650690138020566 iter num 920\n",
            "loss 0.0986601784825325 average time 0.002648762362744666 iter num 940\n",
            "loss 7.2857818603515625 average time 0.0026462313760229486 iter num 960\n",
            "loss 1.5163166522979736 average time 0.002645204570393505 iter num 980\n",
            "loss 0.5356597900390625 average time 0.00264387436598372 iter num 1000\n",
            "loss 0.009982917457818985 average time 0.0031529422500170766 iter num 20\n",
            "loss 37.84617233276367 average time 0.0029084265000165034 iter num 40\n",
            "loss 3.1046206951141357 average time 0.0027832425666626174 iter num 60\n",
            "loss 0.8449525237083435 average time 0.0027509857749464573 iter num 80\n",
            "loss 1.2546112537384033 average time 0.0027763328799119335 iter num 100\n",
            "loss 0.9314621686935425 average time 0.0027626329915923027 iter num 120\n",
            "loss 2.7079720497131348 average time 0.002762852921348115 iter num 140\n",
            "loss 0.17702822387218475 average time 0.0027302583936943845 iter num 160\n",
            "loss 3.8592917919158936 average time 0.00271323449995988 iter num 180\n",
            "loss 5.834311485290527 average time 0.0027068312499704916 iter num 200\n",
            "loss 0.031937599182128906 average time 0.0027178612226882912 iter num 220\n",
            "loss 5.172022342681885 average time 0.00270352053332014 iter num 240\n",
            "loss 37.504737854003906 average time 0.002707381273082249 iter num 260\n",
            "loss 0.1205534115433693 average time 0.00267820851785083 iter num 280\n",
            "loss 1.9476739168167114 average time 0.0026516137433160716 iter num 300\n",
            "loss 174.01983642578125 average time 0.002632042996850714 iter num 320\n",
            "loss 16.821077346801758 average time 0.002634118308806672 iter num 340\n",
            "loss 0.765815258026123 average time 0.002620131738871755 iter num 360\n",
            "loss 0.017777234315872192 average time 0.002602507478930324 iter num 380\n",
            "loss 23.819398880004883 average time 0.002587749267495383 iter num 400\n",
            "loss 2.4138503074645996 average time 0.0025861830095198542 iter num 420\n",
            "loss 0.36589521169662476 average time 0.002572969213637903 iter num 440\n",
            "loss 0.17345485091209412 average time 0.0025625395021645248 iter num 460\n",
            "loss 1.898564100265503 average time 0.0025496186874837197 iter num 480\n",
            "loss 0.7343964576721191 average time 0.0025448724139750995 iter num 500\n",
            "loss 4.429015636444092 average time 0.0025337319018979964 iter num 520\n",
            "loss 0.10712221264839172 average time 0.002524207803674438 iter num 540\n",
            "loss 0.7298440337181091 average time 0.002529228069608637 iter num 560\n",
            "loss 0.0041852425783872604 average time 0.0025225403103204683 iter num 580\n",
            "loss 0.3943727910518646 average time 0.002514521611641006 iter num 600\n",
            "loss 182.49769592285156 average time 0.0025063620580406294 iter num 620\n",
            "loss 0.5544154047966003 average time 0.002497669598420771 iter num 640\n",
            "loss 0.6013734340667725 average time 0.0024907941802832117 iter num 660\n",
            "loss 2.767996311187744 average time 0.002490199377922074 iter num 680\n",
            "loss 1.6136327981948853 average time 0.0024872258128380053 iter num 700\n",
            "loss 0.010521986521780491 average time 0.0024812658388681384 iter num 720\n",
            "loss 1.6879851818084717 average time 0.0024748286972705526 iter num 740\n",
            "loss 0.023645350709557533 average time 0.002471787955231488 iter num 760\n",
            "loss 5.8685832023620605 average time 0.0024670996730399054 iter num 780\n",
            "loss 3.7070908546447754 average time 0.002463421492470843 iter num 800\n",
            "loss 0.08694558590650558 average time 0.002469748171924726 iter num 820\n",
            "loss 2.0383927822113037 average time 0.002464365579737118 iter num 840\n",
            "loss 6.092956066131592 average time 0.0024600606546258392 iter num 860\n",
            "loss 0.11015618592500687 average time 0.0024647553749797555 iter num 880\n",
            "loss 2.0366177558898926 average time 0.002461430196643859 iter num 900\n",
            "loss 1.7324837244814262e-05 average time 0.0024563533315002765 iter num 920\n",
            "loss 0.18111105263233185 average time 0.0024526872095462903 iter num 940\n",
            "loss 7.445380210876465 average time 0.002449608995804435 iter num 960\n",
            "loss 0.13140292465686798 average time 0.0024464030040467245 iter num 980\n",
            "loss 1.2232253551483154 average time 0.0024436587899654113 iter num 1000\n",
            "loss 0.309998095035553 average time 0.0030751433997465937 iter num 20\n",
            "loss 13.005732536315918 average time 0.0026859928498197405 iter num 40\n",
            "loss 776.1473388671875 average time 0.002563345916587423 iter num 60\n",
            "loss 0.10819739103317261 average time 0.0025116528249782277 iter num 80\n",
            "loss 5.040585517883301 average time 0.0024691378000352413 iter num 100\n",
            "loss 46.14527893066406 average time 0.002433821858342829 iter num 120\n",
            "loss 0.00847786944359541 average time 0.0024302540285784094 iter num 140\n",
            "loss 12.91981029510498 average time 0.0024157605250252345 iter num 160\n",
            "loss 0.07897286862134933 average time 0.0024027917277837534 iter num 180\n",
            "loss 0.5689269304275513 average time 0.002387503270001616 iter num 200\n",
            "loss 18.346416473388672 average time 0.0023845607772934522 iter num 220\n",
            "loss 25.266035079956055 average time 0.002376139933342832 iter num 240\n",
            "loss 4.462024688720703 average time 0.002369308942315211 iter num 260\n",
            "loss 3.596247911453247 average time 0.0023938112392962855 iter num 280\n",
            "loss 1.3969237804412842 average time 0.0024120835900066596 iter num 300\n",
            "loss 0.2058826982975006 average time 0.002401506953134458 iter num 320\n",
            "loss 0.3644210696220398 average time 0.0024000062911855983 iter num 340\n",
            "loss 6.1615095138549805 average time 0.0023923469333516955 iter num 360\n",
            "loss 0.005652613937854767 average time 0.0024088930342354856 iter num 380\n",
            "loss 14.990801811218262 average time 0.0024039543650133054 iter num 400\n",
            "loss 0.6931427717208862 average time 0.0024071140666776392 iter num 420\n",
            "loss 9.902668952941895 average time 0.002399037509092688 iter num 440\n",
            "loss 0.3617737591266632 average time 0.002407138756521106 iter num 460\n",
            "loss 0.4748828411102295 average time 0.0024044436041587383 iter num 480\n",
            "loss 8.144903182983398 average time 0.0024021023860004787 iter num 500\n",
            "loss 5.1845574378967285 average time 0.002410988092319363 iter num 520\n",
            "loss 0.10761654376983643 average time 0.0024104556352068794 iter num 540\n",
            "loss 782.2415771484375 average time 0.0024044987446586673 iter num 560\n",
            "loss 6.309689044952393 average time 0.002399925420709694 iter num 580\n",
            "loss 59.84321975708008 average time 0.002414915441689421 iter num 600\n",
            "loss 0.18902380764484406 average time 0.0024151392016304478 iter num 620\n",
            "loss 0.18585945665836334 average time 0.002422666618761582 iter num 640\n",
            "loss 140.91888427734375 average time 0.002418665486377656 iter num 660\n",
            "loss 15.938048362731934 average time 0.002415177397072993 iter num 680\n",
            "loss 0.013135168701410294 average time 0.0024204807300156972 iter num 700\n",
            "loss 0.010854138992726803 average time 0.002415466155576319 iter num 720\n",
            "loss 26.192245483398438 average time 0.002424019995969256 iter num 740\n",
            "loss 22.78738021850586 average time 0.00242157171186543 iter num 760\n",
            "loss 0.6333207488059998 average time 0.0024250177359159027 iter num 780\n",
            "loss 0.564586877822876 average time 0.002427206120016763 iter num 800\n",
            "loss 2.5874364376068115 average time 0.00242406664513887 iter num 820\n",
            "loss 2.9385175704956055 average time 0.0024215353785816012 iter num 840\n",
            "loss 0.00043379259295761585 average time 0.002420467709307136 iter num 860\n",
            "loss 0.11891280859708786 average time 0.002417533353412761 iter num 880\n",
            "loss 0.5132626295089722 average time 0.002415837575562263 iter num 900\n",
            "loss 4.8686299324035645 average time 0.0024129043054353645 iter num 920\n",
            "loss 0.08888830989599228 average time 0.002419295357449687 iter num 940\n",
            "loss 1.2466763257980347 average time 0.0024242333875084416 iter num 960\n",
            "loss 4.005760192871094 average time 0.0024312359020471803 iter num 980\n",
            "loss 0.15475288033485413 average time 0.0024283609190079007 iter num 1000\n",
            "loss 0.8120502233505249 average time 0.003154272899882926 iter num 20\n",
            "loss 0.8832890391349792 average time 0.002726277825058787 iter num 40\n",
            "loss 17.512544631958008 average time 0.002697783150051691 iter num 60\n",
            "loss 7.089913845062256 average time 0.0025976498625595924 iter num 80\n",
            "loss 16.33955192565918 average time 0.002631464910082286 iter num 100\n",
            "loss 87.71575927734375 average time 0.0025741246084332184 iter num 120\n",
            "loss 4.5308451652526855 average time 0.002532119814376139 iter num 140\n",
            "loss 0.00959793571382761 average time 0.0024943473813436867 iter num 160\n",
            "loss 1.7376213073730469 average time 0.00248004972227136 iter num 180\n",
            "loss 4.3560380935668945 average time 0.0024726010650647366 iter num 200\n",
            "loss 0.0031891746912151575 average time 0.0024547516773385392 iter num 220\n",
            "loss 0.3634724020957947 average time 0.002439584854247793 iter num 240\n",
            "loss 4.367159843444824 average time 0.002445365588531646 iter num 260\n",
            "loss 0.40484747290611267 average time 0.002437073992931411 iter num 280\n",
            "loss 0.1152864396572113 average time 0.0024278311700618362 iter num 300\n",
            "loss 64.91474151611328 average time 0.002418024315687717 iter num 320\n",
            "loss 0.22902831435203552 average time 0.002424365864766621 iter num 340\n",
            "loss 5.102748394012451 average time 0.002415707444510594 iter num 360\n",
            "loss 0.6435865759849548 average time 0.002410027518501585 iter num 380\n",
            "loss 1.2868274450302124 average time 0.0024058164100961223 iter num 400\n",
            "loss 2.818800449371338 average time 0.0024168017643681934 iter num 420\n",
            "loss 0.13543358445167542 average time 0.002445765250083489 iter num 440\n",
            "loss 10.476066589355469 average time 0.0024388294479175112 iter num 460\n",
            "loss 0.10007689893245697 average time 0.002433445952162098 iter num 480\n",
            "loss 7.7152485847473145 average time 0.002453659632075869 iter num 500\n",
            "loss 0.007394638378173113 average time 0.0024479697116161193 iter num 520\n",
            "loss 0.08198117464780807 average time 0.002442650146366321 iter num 540\n",
            "loss 0.5627976059913635 average time 0.0024410828536344654 iter num 560\n",
            "loss 14.96806526184082 average time 0.002435157339713724 iter num 580\n",
            "loss 0.21107305586338043 average time 0.002429875388382546 iter num 600\n",
            "loss 0.016868956387043 average time 0.0024249493371474185 iter num 620\n",
            "loss 0.006729172542691231 average time 0.0024204805922380503 iter num 640\n",
            "loss 16.482650756835938 average time 0.0024151483197453094 iter num 660\n",
            "loss 0.04825770854949951 average time 0.0024144996882809852 iter num 680\n",
            "loss 614.6084594726562 average time 0.002410907204334113 iter num 700\n",
            "loss 0.004183288663625717 average time 0.0024078423069820725 iter num 720\n",
            "loss 1.359619140625 average time 0.0024097651230083617 iter num 740\n",
            "loss 2.520524501800537 average time 0.0024076044566036696 iter num 760\n",
            "loss 0.07181825488805771 average time 0.002404212587209305 iter num 780\n",
            "loss 4.059300422668457 average time 0.0024020952650244 iter num 800\n",
            "loss 1.8358467817306519 average time 0.002404882250015717 iter num 820\n",
            "loss 0.2334749400615692 average time 0.002401835361923163 iter num 840\n",
            "loss 0.04237682744860649 average time 0.0023986571581549785 iter num 860\n",
            "loss 2.3222568035125732 average time 0.0023962128920588426 iter num 880\n",
            "loss 38.19023513793945 average time 0.0024024594922371356 iter num 900\n",
            "loss 1.0272986888885498 average time 0.0024005651358849087 iter num 920\n",
            "loss 11.183164596557617 average time 0.0023973780425721805 iter num 940\n",
            "loss 1.679819941520691 average time 0.002407222319811808 iter num 960\n",
            "loss 22.08925437927246 average time 0.0024091818326733303 iter num 980\n",
            "loss 0.010682965628802776 average time 0.002407409858020401 iter num 1000\n",
            "loss 0.06914317607879639 average time 0.002911875150221022 iter num 20\n",
            "loss 22.104101181030273 average time 0.0027058568251504766 iter num 40\n",
            "loss 1.8996679782867432 average time 0.0026444674166972012 iter num 60\n",
            "loss 14.051106452941895 average time 0.002580178387552223 iter num 80\n",
            "loss 1.6290353536605835 average time 0.002521933430034551 iter num 100\n",
            "loss 24.671117782592773 average time 0.0024933993083929335 iter num 120\n",
            "loss 13.1488676071167 average time 0.0024638014215140305 iter num 140\n",
            "loss 215.86163330078125 average time 0.0025075195438375884 iter num 160\n",
            "loss 2.6625773906707764 average time 0.002479829627847923 iter num 180\n",
            "loss 102.39175415039062 average time 0.002484553905087523 iter num 200\n",
            "loss 0.27592891454696655 average time 0.0024867273500603915 iter num 220\n",
            "loss 0.05592673644423485 average time 0.0024733654792119825 iter num 240\n",
            "loss 31.016822814941406 average time 0.002455625426955521 iter num 260\n",
            "loss 25.550174713134766 average time 0.002447457603622232 iter num 280\n",
            "loss 2.892298698425293 average time 0.002435507463360409 iter num 300\n",
            "loss 0.045600879937410355 average time 0.0024273193344072296 iter num 320\n",
            "loss 1.20992112159729 average time 0.00241816580592593 iter num 340\n",
            "loss 0.8401952981948853 average time 0.0024123074972825028 iter num 360\n",
            "loss 3.5698342323303223 average time 0.002417049184274028 iter num 380\n",
            "loss 0.14401547610759735 average time 0.0024070079200782858 iter num 400\n",
            "loss 34.152801513671875 average time 0.002407925009603267 iter num 420\n",
            "loss 1.3014779090881348 average time 0.0024168019978085134 iter num 440\n",
            "loss 2.3757169246673584 average time 0.0024276202326844847 iter num 460\n",
            "loss 0.08344248682260513 average time 0.002439848268818423 iter num 480\n",
            "loss 0.5700738430023193 average time 0.002444906154061755 iter num 500\n",
            "loss 37.44911193847656 average time 0.0024419550154456933 iter num 520\n",
            "loss 4.147701263427734 average time 0.0024472678722843367 iter num 540\n",
            "loss 0.10895660519599915 average time 0.002451910710773778 iter num 560\n",
            "loss 1.3017956018447876 average time 0.0024591693328210535 iter num 580\n",
            "loss 0.4617988169193268 average time 0.0024640829633972316 iter num 600\n",
            "loss 0.8141588568687439 average time 0.0024717290339345533 iter num 620\n",
            "loss 0.015380393713712692 average time 0.002479372062558127 iter num 640\n",
            "loss 0.3077417016029358 average time 0.0024875869546066853 iter num 660\n",
            "loss 0.004975043702870607 average time 0.002491274148593113 iter num 680\n",
            "loss 0.000396857998566702 average time 0.002490593564351522 iter num 700\n",
            "loss 336.6924743652344 average time 0.0024924515500641875 iter num 720\n",
            "loss 0.1293698251247406 average time 0.0024975259527653523 iter num 740\n",
            "loss 0.5941879749298096 average time 0.0025011047461176578 iter num 760\n",
            "loss 0.27721792459487915 average time 0.0024993556705782956 iter num 780\n",
            "loss 0.6380075216293335 average time 0.002504489800069223 iter num 800\n",
            "loss 0.022827304899692535 average time 0.0025092689244513343 iter num 820\n",
            "loss 0.09749419242143631 average time 0.002520856454824146 iter num 840\n",
            "loss 28.399322509765625 average time 0.0025349762244797265 iter num 860\n",
            "loss 2.2967145442962646 average time 0.002531352130741156 iter num 880\n",
            "loss 0.08101535588502884 average time 0.002537254054497882 iter num 900\n",
            "loss 15.848930358886719 average time 0.0025348845435335375 iter num 920\n",
            "loss 0.6028645038604736 average time 0.0025356087702656373 iter num 940\n",
            "loss 0.13428272306919098 average time 0.0025345253063051134 iter num 960\n",
            "loss 0.2481815665960312 average time 0.002537954941891833 iter num 980\n",
            "loss 0.060128964483737946 average time 0.0025491981850591402 iter num 1000\n",
            "loss 0.3385561406612396 average time 0.0029976384000292454 iter num 20\n",
            "loss 11.924362182617188 average time 0.0027745800749926276 iter num 40\n",
            "loss 3.3721864223480225 average time 0.002659339216643275 iter num 60\n",
            "loss 19.12590789794922 average time 0.002771625437412695 iter num 80\n",
            "loss 101.37800598144531 average time 0.0027617415999156947 iter num 100\n",
            "loss 21.00934600830078 average time 0.0027264434249142746 iter num 120\n",
            "loss 0.2794754207134247 average time 0.002701599757074291 iter num 140\n",
            "loss 5.00522518157959 average time 0.0026667644874464715 iter num 160\n",
            "loss 0.5535662770271301 average time 0.0026639956722040855 iter num 180\n",
            "loss 7.961824417114258 average time 0.0026672534349836494 iter num 200\n",
            "loss 478.11383056640625 average time 0.0026605607545455066 iter num 220\n",
            "loss 4.244831562042236 average time 0.00267547504582429 iter num 240\n",
            "loss 0.3758799731731415 average time 0.0026920993538414434 iter num 260\n",
            "loss 0.9845334887504578 average time 0.0026886518214269016 iter num 280\n",
            "loss 3.7063710689544678 average time 0.0026879627633328105 iter num 300\n",
            "loss 1.6258623600006104 average time 0.0027027543343876915 iter num 320\n",
            "loss 1.5799626111984253 average time 0.002698892570595704 iter num 340\n",
            "loss 2.5854411125183105 average time 0.0026992387944473092 iter num 360\n",
            "loss 0.8670943975448608 average time 0.0026904568921102172 iter num 380\n",
            "loss 19.832054138183594 average time 0.0026736711900093722 iter num 400\n",
            "loss 0.05077945068478584 average time 0.0026727049571621006 iter num 420\n",
            "loss 0.33425173163414 average time 0.0026774356386423197 iter num 440\n",
            "loss 15.791182518005371 average time 0.002674390939121266 iter num 460\n",
            "loss 6.018346309661865 average time 0.0026777551520657046 iter num 480\n",
            "loss 0.3133726119995117 average time 0.002673692457989091 iter num 500\n",
            "loss 44.25530242919922 average time 0.0026740951172961594 iter num 520\n",
            "loss 1.432951807975769 average time 0.0026764516833349327 iter num 540\n",
            "loss 0.5368106961250305 average time 0.0026772220946440937 iter num 560\n",
            "loss 4.383373737335205 average time 0.0026885894637949793 iter num 580\n",
            "loss 1.0316956043243408 average time 0.0026864492516688186 iter num 600\n",
            "loss 0.4515339136123657 average time 0.0026869365403282214 iter num 620\n",
            "loss 2.3898844718933105 average time 0.0026869218906256263 iter num 640\n",
            "loss 0.3161316514015198 average time 0.0026872147287962654 iter num 660\n",
            "loss 0.6657595038414001 average time 0.0026839387206029426 iter num 680\n",
            "loss 186.41357421875 average time 0.0026835572714480806 iter num 700\n",
            "loss 0.06982405483722687 average time 0.0026835243944737562 iter num 720\n",
            "loss 0.01905819959938526 average time 0.0026745009284068885 iter num 740\n",
            "loss 0.39688992500305176 average time 0.0026760596210782463 iter num 760\n",
            "loss 1.753454327583313 average time 0.0026737233795173757 iter num 780\n",
            "loss 1.7058346271514893 average time 0.0026720627012809927 iter num 800\n",
            "loss 1.249369740486145 average time 0.0026729046402712213 iter num 820\n",
            "loss 10.422475814819336 average time 0.002671396164309737 iter num 840\n",
            "loss 5.421018600463867 average time 0.002673101496532391 iter num 860\n",
            "loss 0.003716448089107871 average time 0.0026754934750174058 iter num 880\n",
            "loss 2.958876609802246 average time 0.002669221585571601 iter num 900\n",
            "loss 19.63913345336914 average time 0.00266698073044648 iter num 920\n",
            "loss 41.60757827758789 average time 0.002662684674475926 iter num 940\n",
            "loss 0.07802379131317139 average time 0.002660165728135174 iter num 960\n",
            "loss 42.309730529785156 average time 0.002654384224493994 iter num 980\n",
            "loss 0.1508575826883316 average time 0.002651658454005883 iter num 1000\n",
            "loss 1.1312004327774048 average time 0.0033406734501113533 iter num 20\n",
            "loss 119.3918685913086 average time 0.0028740882752117613 iter num 40\n",
            "loss 8.12553596496582 average time 0.002758507066785872 iter num 60\n",
            "loss 4.727829933166504 average time 0.002734625587595474 iter num 80\n",
            "loss 5.347748756408691 average time 0.0026583204300914074 iter num 100\n",
            "loss 92.816650390625 average time 0.0026350483833842493 iter num 120\n",
            "loss 1.0351392030715942 average time 0.0026089399357780555 iter num 140\n",
            "loss 0.04547196999192238 average time 0.002606612993793078 iter num 160\n",
            "loss 16.288028717041016 average time 0.0026235006056089735 iter num 180\n",
            "loss 0.00429353304207325 average time 0.0026174950100357817 iter num 200\n",
            "loss 0.3416532874107361 average time 0.002599148722757408 iter num 220\n",
            "loss 0.9866628050804138 average time 0.0026357795291914953 iter num 240\n",
            "loss 2.0879690647125244 average time 0.0026285600346384924 iter num 260\n",
            "loss 0.4458446204662323 average time 0.0026305385642899637 iter num 280\n",
            "loss 0.3664812743663788 average time 0.002633069120007955 iter num 300\n",
            "loss 7.03848934173584 average time 0.0026352856187486394 iter num 320\n",
            "loss 0.378452330827713 average time 0.0026354302852911026 iter num 340\n",
            "loss 0.04152752459049225 average time 0.002634760825003468 iter num 360\n",
            "loss 13.044666290283203 average time 0.0026343532315781645 iter num 380\n",
            "loss 6.657531261444092 average time 0.0026175218949902046 iter num 400\n",
            "loss 0.009320426732301712 average time 0.0026216963857093236 iter num 420\n",
            "loss 0.876418948173523 average time 0.0026072578795389165 iter num 440\n",
            "loss 86.76045989990234 average time 0.002605544334773699 iter num 460\n",
            "loss 0.0022398242726922035 average time 0.002593832120821086 iter num 480\n",
            "loss 2.1490318775177 average time 0.0025791111559774435 iter num 500\n",
            "loss 16.16307258605957 average time 0.002568726286524627 iter num 520\n",
            "loss 0.061286672949790955 average time 0.002560467972202955 iter num 540\n",
            "loss 0.029416143894195557 average time 0.0025501323178462243 iter num 560\n",
            "loss 3.6799139976501465 average time 0.0025423975086094537 iter num 580\n",
            "loss 7.890084743499756 average time 0.002531559689987262 iter num 600\n",
            "loss 1.6520384550094604 average time 0.002524390341920568 iter num 620\n",
            "loss 60.8773078918457 average time 0.002516931995299387 iter num 640\n",
            "loss 0.4348699748516083 average time 0.0025106130954361907 iter num 660\n",
            "loss 0.5118458867073059 average time 0.002503580633797623 iter num 680\n",
            "loss 2.5253021717071533 average time 0.0025009381613952946 iter num 700\n",
            "loss 0.005841484759002924 average time 0.0024950969666254724 iter num 720\n",
            "loss 1.07692551612854 average time 0.002491881409425971 iter num 740\n",
            "loss 2.302374839782715 average time 0.0024971112460231157 iter num 760\n",
            "loss 1.3154412508010864 average time 0.002492642848693112 iter num 780\n",
            "loss 22.77911376953125 average time 0.0024887479937228817 iter num 800\n",
            "loss 3.181337356567383 average time 0.0024823958194823852 iter num 820\n",
            "loss 13.29835033416748 average time 0.002477933776165065 iter num 840\n",
            "loss 0.15209104120731354 average time 0.0024745801278820796 iter num 860\n",
            "loss 0.10969320684671402 average time 0.0024700495852006165 iter num 880\n",
            "loss 13.099615097045898 average time 0.0024680456388624507 iter num 900\n",
            "loss 2.258545398712158 average time 0.002464504565187267 iter num 920\n",
            "loss 0.33411383628845215 average time 0.002467997402099888 iter num 940\n",
            "loss 0.7961397171020508 average time 0.0024737578520576636 iter num 960\n",
            "loss 1.514785647392273 average time 0.00247770543874882 iter num 980\n",
            "loss 0.23503760993480682 average time 0.002482029414968565 iter num 1000\n",
            "loss 0.533416748046875 average time 0.0032132189999174443 iter num 20\n",
            "loss 0.7383795976638794 average time 0.00288590787481553 iter num 40\n",
            "loss 128.69468688964844 average time 0.0027202443499239354 iter num 60\n",
            "loss 1.5695604085922241 average time 0.0026880478998918987 iter num 80\n",
            "loss 11.007863998413086 average time 0.002694346499938547 iter num 100\n",
            "loss 3.3479015827178955 average time 0.0026911768249343973 iter num 120\n",
            "loss 69.85083770751953 average time 0.0026697173856389 iter num 140\n",
            "loss 5.183723449707031 average time 0.0026401508561548328 iter num 160\n",
            "loss 1.5975825786590576 average time 0.0026681567443928443 iter num 180\n",
            "loss 0.016919003799557686 average time 0.0026768024299326496 iter num 200\n",
            "loss 0.39188987016677856 average time 0.0026514204999412787 iter num 220\n",
            "loss 0.005803251173347235 average time 0.002654653433258621 iter num 240\n",
            "loss 25.007476806640625 average time 0.0026591860922613145 iter num 260\n",
            "loss 0.009914429858326912 average time 0.002660810539243487 iter num 280\n",
            "loss 7.340911388397217 average time 0.002648952373292559 iter num 300\n",
            "loss 6.02059268951416 average time 0.002645264943703296 iter num 320\n",
            "loss 0.5992392301559448 average time 0.002641408405837437 iter num 340\n",
            "loss 0.3009359538555145 average time 0.0026292438082843243 iter num 360\n",
            "loss 0.04030391201376915 average time 0.0026314145709971184 iter num 380\n",
            "loss 2.237360715866089 average time 0.0026261850374567075 iter num 400\n",
            "loss 6.422414779663086 average time 0.0026245895499457782 iter num 420\n",
            "loss 56.242332458496094 average time 0.0026274303113082583 iter num 440\n",
            "loss 8.541366577148438 average time 0.0026289306803807012 iter num 460\n",
            "loss 116.14308166503906 average time 0.0026284143936929163 iter num 480\n",
            "loss 0.7365630269050598 average time 0.002632442057947628 iter num 500\n",
            "loss 0.0008944422006607056 average time 0.002621549711490773 iter num 520\n",
            "loss 3.574650526046753 average time 0.002624987414761832 iter num 540\n",
            "loss 37.23483657836914 average time 0.0026287988981526463 iter num 560\n",
            "loss 0.41499775648117065 average time 0.0026275493085543937 iter num 580\n",
            "loss 1.642725944519043 average time 0.0026178232682711193 iter num 600\n",
            "loss 0.1331176459789276 average time 0.0026155847321910363 iter num 620\n",
            "loss 38.20664596557617 average time 0.0026243528046279605 iter num 640\n",
            "loss 0.46206843852996826 average time 0.0026240629378249153 iter num 660\n",
            "loss 16.191364288330078 average time 0.0026276682293588666 iter num 680\n",
            "loss 0.04242932051420212 average time 0.0026303359699574817 iter num 700\n",
            "loss 1.0798450708389282 average time 0.002631570763845856 iter num 720\n",
            "loss 0.023335708305239677 average time 0.002633919197253547 iter num 740\n",
            "loss 4.476346969604492 average time 0.0026351958447034312 iter num 760\n",
            "loss 0.38239097595214844 average time 0.002637969280730874 iter num 780\n",
            "loss 12.309245109558105 average time 0.002631998841209224 iter num 800\n",
            "loss 23.60032844543457 average time 0.002630543246303249 iter num 820\n",
            "loss 72.77962493896484 average time 0.0026248498678168764 iter num 840\n",
            "loss 0.009366150014102459 average time 0.0026285240569323344 iter num 860\n",
            "loss 0.25819095969200134 average time 0.0026245338488210604 iter num 880\n",
            "loss 2.763660192489624 average time 0.0026234722955187965 iter num 900\n",
            "loss 3.401341438293457 average time 0.0026190915749615988 iter num 920\n",
            "loss 1.6695197820663452 average time 0.0026181682861340263 iter num 940\n",
            "loss 0.00025988376000896096 average time 0.002615644578086555 iter num 960\n",
            "loss 0.000512158963829279 average time 0.00261653615608357 iter num 980\n",
            "loss 0.6520113945007324 average time 0.002618947608962117 iter num 1000\n",
            "loss 4.453454971313477 average time 0.0030734492499504993 iter num 20\n",
            "loss 1.9454363584518433 average time 0.0028766945751158347 iter num 40\n",
            "loss 0.14995883405208588 average time 0.00283275190004133 iter num 60\n",
            "loss 5.363758563995361 average time 0.0027788554250264496 iter num 80\n",
            "loss 3.6532161235809326 average time 0.002830436890017154 iter num 100\n",
            "loss 9.865346908569336 average time 0.00279124180836637 iter num 120\n",
            "loss 2.369464874267578 average time 0.0027765413000192243 iter num 140\n",
            "loss 0.0013021327322348952 average time 0.00272898613130792 iter num 160\n",
            "loss 1.297390341758728 average time 0.002726082088964985 iter num 180\n",
            "loss 0.2703707218170166 average time 0.002706809355113364 iter num 200\n",
            "loss 0.6966351270675659 average time 0.002673295072814984 iter num 220\n",
            "loss 1.0851356983184814 average time 0.0026699545458996 iter num 240\n",
            "loss 24.351999282836914 average time 0.0026673803923795976 iter num 260\n",
            "loss 3.6240556240081787 average time 0.0026469698107835678 iter num 280\n",
            "loss 149.50021362304688 average time 0.002643731340067461 iter num 300\n",
            "loss 4.877724647521973 average time 0.0026370113594339274 iter num 320\n",
            "loss 7.6701555252075195 average time 0.002645041685365654 iter num 340\n",
            "loss 1.6039202213287354 average time 0.0026463965139504986 iter num 360\n",
            "loss 61.962764739990234 average time 0.0026480263053168815 iter num 380\n",
            "loss 0.013114191591739655 average time 0.002640534147544713 iter num 400\n",
            "loss 0.8032944202423096 average time 0.0026451788190873533 iter num 420\n",
            "loss 217.3662872314453 average time 0.0026430708818638363 iter num 440\n",
            "loss 529.9739990234375 average time 0.002636232376133431 iter num 460\n",
            "loss 4.027420997619629 average time 0.0026270551000379784 iter num 480\n",
            "loss 9.020519256591797 average time 0.0026325765100336865 iter num 500\n",
            "loss 21.329059600830078 average time 0.002636012801958014 iter num 520\n",
            "loss 1.8069663047790527 average time 0.0026335432148496493 iter num 540\n",
            "loss 0.8420976996421814 average time 0.0026400556321829883 iter num 560\n",
            "loss 3.995606675744057e-06 average time 0.0026451070707261006 iter num 580\n",
            "loss 0.2815089225769043 average time 0.0026551509367103185 iter num 600\n",
            "loss 0.017989113926887512 average time 0.002647309287142214 iter num 620\n",
            "loss 3.930004119873047 average time 0.0026482455172327944 iter num 640\n",
            "loss 9.209209442138672 average time 0.002649349983370154 iter num 660\n",
            "loss 4.011849403381348 average time 0.0026498233720972436 iter num 680\n",
            "loss 0.6822574734687805 average time 0.0026488222200376707 iter num 700\n",
            "loss 0.3036794364452362 average time 0.002647700820875798 iter num 720\n",
            "loss 0.048481814563274384 average time 0.002649367471661429 iter num 740\n",
            "loss 4.415105819702148 average time 0.0026506146145086522 iter num 760\n",
            "loss 0.31471067667007446 average time 0.002647862516702541 iter num 780\n",
            "loss 4.08541202545166 average time 0.002646542123791278 iter num 800\n",
            "loss 1.3538872003555298 average time 0.0026486196256483687 iter num 820\n",
            "loss 1.7875840663909912 average time 0.0026488859428982756 iter num 840\n",
            "loss 364.023193359375 average time 0.002639218243066987 iter num 860\n",
            "loss 2.503444194793701 average time 0.0026415658329886522 iter num 880\n",
            "loss 4.571837425231934 average time 0.002633726844479598 iter num 900\n",
            "loss 0.2793333828449249 average time 0.002626797585899903 iter num 920\n",
            "loss 0.7598397731781006 average time 0.0026215738468365205 iter num 940\n",
            "loss 27.539113998413086 average time 0.002615616260442266 iter num 960\n",
            "loss 83.00142669677734 average time 0.002609053048999325 iter num 980\n",
            "loss 284.1207275390625 average time 0.0026013720340124563 iter num 1000\n",
            "loss 4.17473840713501 average time 0.0030801748500380198 iter num 20\n",
            "loss 1.8664906024932861 average time 0.0030684110499805684 iter num 40\n",
            "loss 8.912278175354004 average time 0.0029247406667006243 iter num 60\n",
            "loss 1.0758253335952759 average time 0.0027733020251162087 iter num 80\n",
            "loss 4.008457660675049 average time 0.002691020770089381 iter num 100\n",
            "loss 4.372518539428711 average time 0.0026250983167301458 iter num 120\n",
            "loss 16.812498092651367 average time 0.0025697503143289526 iter num 140\n",
            "loss 0.2764042019844055 average time 0.002535570118777741 iter num 160\n",
            "loss 12.462931632995605 average time 0.0025173666333810412 iter num 180\n",
            "loss 1.3178049325942993 average time 0.002535294205035825 iter num 200\n",
            "loss 0.013599918223917484 average time 0.0025208889000416755 iter num 220\n",
            "loss 17.106761932373047 average time 0.0025035296792035905 iter num 240\n",
            "loss 2.9803857803344727 average time 0.002487804646184836 iter num 260\n",
            "loss 0.7503081560134888 average time 0.0024765824785975255 iter num 280\n",
            "loss 4.864306449890137 average time 0.002462590043360251 iter num 300\n",
            "loss 12.611379623413086 average time 0.0024544726562794493 iter num 320\n",
            "loss 19.946821212768555 average time 0.0024427319058999914 iter num 340\n",
            "loss 0.5688579082489014 average time 0.002431950175009155 iter num 360\n",
            "loss 94.22379302978516 average time 0.0024252259342287482 iter num 380\n",
            "loss 2.1038851737976074 average time 0.00241839125502338 iter num 400\n",
            "loss 10.234610557556152 average time 0.00241300105956162 iter num 420\n",
            "loss 2.0257441997528076 average time 0.002404281961402045 iter num 440\n",
            "loss 0.03665302321314812 average time 0.002398845378292722 iter num 460\n",
            "loss 244.4900360107422 average time 0.0023963061041968104 iter num 480\n",
            "loss 17.82905387878418 average time 0.0023969084520322212 iter num 500\n",
            "loss 0.009163948707282543 average time 0.0023961926615671614 iter num 520\n",
            "loss 9.489983558654785 average time 0.0024026678666814404 iter num 540\n",
            "loss 8.88023853302002 average time 0.0023989352660919393 iter num 560\n",
            "loss 7.245361804962158 average time 0.002396491451741142 iter num 580\n",
            "loss 59.416561126708984 average time 0.0023922432283446445 iter num 600\n",
            "loss 0.00838439166545868 average time 0.0023886059838802 iter num 620\n",
            "loss 0.2075546532869339 average time 0.002385731210955555 iter num 640\n",
            "loss 6.4601922035217285 average time 0.002398860109102922 iter num 660\n",
            "loss 1.813476800918579 average time 0.0023945951382409155 iter num 680\n",
            "loss 0.2637755274772644 average time 0.0023902183257164976 iter num 700\n",
            "loss 0.306254506111145 average time 0.0023872216513887504 iter num 720\n",
            "loss 0.17590214312076569 average time 0.0023860731878419363 iter num 740\n",
            "loss 86.33771514892578 average time 0.0023836200486919935 iter num 760\n",
            "loss 127.7894058227539 average time 0.0023807954217982814 iter num 780\n",
            "loss 0.7533842921257019 average time 0.002387318105004397 iter num 800\n",
            "loss 1.2673293352127075 average time 0.0023883285634194802 iter num 820\n",
            "loss 0.8762269616127014 average time 0.002384964716670116 iter num 840\n",
            "loss 43.447261810302734 average time 0.002382811605819074 iter num 860\n",
            "loss 0.1862148493528366 average time 0.002382746671597405 iter num 880\n",
            "loss 74.7492904663086 average time 0.0023818685288905625 iter num 900\n",
            "loss 227.8199005126953 average time 0.002379978825007603 iter num 920\n",
            "loss 2.0426034927368164 average time 0.002378252022349733 iter num 940\n",
            "loss 30.71190071105957 average time 0.002378359988553787 iter num 960\n",
            "loss 3.6410934925079346 average time 0.0023782077571533073 iter num 980\n",
            "loss 3.6245453357696533 average time 0.002380220362012551 iter num 1000\n",
            "loss 0.7522906064987183 average time 0.0035495454498231994 iter num 20\n",
            "loss 24.983522415161133 average time 0.003097867574842894 iter num 40\n",
            "loss 40.48202896118164 average time 0.0030204220165918135 iter num 60\n",
            "loss 62.431724548339844 average time 0.0029378409999026188 iter num 80\n",
            "loss 1.4262959957122803 average time 0.002814219889951346 iter num 100\n",
            "loss 2.3224730491638184 average time 0.002764317708276091 iter num 120\n",
            "loss 0.5026020407676697 average time 0.0027157976070546802 iter num 140\n",
            "loss 15.217853546142578 average time 0.0026622445999464617 iter num 160\n",
            "loss 0.2386600822210312 average time 0.002618339005493908 iter num 180\n",
            "loss 11.29615306854248 average time 0.0025879200799226966 iter num 200\n",
            "loss 0.10915816575288773 average time 0.0025769090635466537 iter num 220\n",
            "loss 31.743877410888672 average time 0.002594918708246041 iter num 240\n",
            "loss 38.737972259521484 average time 0.002583431657589804 iter num 260\n",
            "loss 8.225401878356934 average time 0.0025592894070476696 iter num 280\n",
            "loss 3.139968156814575 average time 0.0025383183999050135 iter num 300\n",
            "loss 52.384212493896484 average time 0.0025229619999208807 iter num 320\n",
            "loss 10.987585067749023 average time 0.0025130202352128808 iter num 340\n",
            "loss 0.3814663887023926 average time 0.0025138991637959408 iter num 360\n",
            "loss 6.069006443023682 average time 0.002521547526238895 iter num 380\n",
            "loss 0.15340556204319 average time 0.002512037122437505 iter num 400\n",
            "loss 1.0533984899520874 average time 0.0025018231404092582 iter num 420\n",
            "loss 2.2688400745391846 average time 0.0024906814181122174 iter num 440\n",
            "loss 2.04130220413208 average time 0.0024923710434173385 iter num 460\n",
            "loss 0.030538011342287064 average time 0.002548029731197706 iter num 480\n",
            "loss 0.8058632612228394 average time 0.002536953545946744 iter num 500\n",
            "loss 3.2546393871307373 average time 0.0025266869922618822 iter num 520\n",
            "loss 418.5263366699219 average time 0.0025180043647600944 iter num 540\n",
            "loss 11.92588996887207 average time 0.002509918928519385 iter num 560\n",
            "loss 2.2350664138793945 average time 0.0025034408499589613 iter num 580\n",
            "loss 7.89960241317749 average time 0.002496730901630144 iter num 600\n",
            "loss 0.027643850073218346 average time 0.0024903226241628044 iter num 620\n",
            "loss 0.013518533669412136 average time 0.002485533167165954 iter num 640\n",
            "loss 6.997702598571777 average time 0.0024990559878571013 iter num 660\n",
            "loss 0.3739459812641144 average time 0.002493059689686561 iter num 680\n",
            "loss 0.013146976009011269 average time 0.002489166758553308 iter num 700\n",
            "loss 59.058250427246094 average time 0.002493173690262059 iter num 720\n",
            "loss 37.46760177612305 average time 0.002488880877019649 iter num 740\n",
            "loss 0.17406228184700012 average time 0.0024869448697269324 iter num 760\n",
            "loss 0.06302403658628464 average time 0.002480107420500971 iter num 780\n",
            "loss 0.42571163177490234 average time 0.0024752127124861543 iter num 800\n",
            "loss 3.3490183353424072 average time 0.002473374487782144 iter num 820\n",
            "loss 1.2410264015197754 average time 0.0024688378023646302 iter num 840\n",
            "loss 0.08419099450111389 average time 0.002466471068586289 iter num 860\n",
            "loss 0.002773676998913288 average time 0.0024626488124795285 iter num 880\n",
            "loss 0.13135315477848053 average time 0.0024592161988726325 iter num 900\n",
            "loss 0.39726191759109497 average time 0.0024555409815033985 iter num 920\n",
            "loss 0.7641920447349548 average time 0.002451305368066777 iter num 940\n",
            "loss 2.5621883869171143 average time 0.0024525835468580228 iter num 960\n",
            "loss 0.026319041848182678 average time 0.002455354848963016 iter num 980\n",
            "loss 0.018801700323820114 average time 0.0024518925859865703 iter num 1000\n",
            "loss 11.624483108520508 average time 0.0028643649501645997 iter num 20\n",
            "loss 47.159523010253906 average time 0.002612023025039889 iter num 40\n",
            "loss 0.9370728135108948 average time 0.0025809539167615486 iter num 60\n",
            "loss 6.395143032073975 average time 0.002508356587554772 iter num 80\n",
            "loss 34.21614456176758 average time 0.0024716523100141784 iter num 100\n",
            "loss 0.23838691413402557 average time 0.0024394476999835507 iter num 120\n",
            "loss 30.36844825744629 average time 0.002420428742815212 iter num 140\n",
            "loss 13.72042465209961 average time 0.002407609349950235 iter num 160\n",
            "loss 2.322575330734253 average time 0.0023930004888421132 iter num 180\n",
            "loss 24.598922729492188 average time 0.002434697894977944 iter num 200\n",
            "loss 23.992149353027344 average time 0.0024225956363476474 iter num 220\n",
            "loss 43.216941833496094 average time 0.0024069979124760723 iter num 240\n",
            "loss 0.5010968446731567 average time 0.002404486296137083 iter num 260\n",
            "loss 0.2194262593984604 average time 0.002395903260678876 iter num 280\n",
            "loss 24.810075759887695 average time 0.002390631929962789 iter num 300\n",
            "loss 4.446325302124023 average time 0.002384092546850525 iter num 320\n",
            "loss 0.3070606589317322 average time 0.0023853974058671585 iter num 340\n",
            "loss 18.064218521118164 average time 0.002380527952775285 iter num 360\n",
            "loss 0.0318034403026104 average time 0.0023781912578957226 iter num 380\n",
            "loss 0.09175202995538712 average time 0.002370696677498927 iter num 400\n",
            "loss 0.014231326058506966 average time 0.0023747677238090893 iter num 420\n",
            "loss 0.5643612146377563 average time 0.0023855192568134954 iter num 440\n",
            "loss 32.48735427856445 average time 0.002382319789127075 iter num 460\n",
            "loss 9.827472686767578 average time 0.002381582735415577 iter num 480\n",
            "loss 0.022474689409136772 average time 0.002388941678003903 iter num 500\n",
            "loss 0.8686687350273132 average time 0.002384881790388905 iter num 520\n",
            "loss 0.16381435096263885 average time 0.002387174672229001 iter num 540\n",
            "loss 0.6857391595840454 average time 0.0023837100839273263 iter num 560\n",
            "loss 0.29509422183036804 average time 0.0023798077068837805 iter num 580\n",
            "loss 33.70272445678711 average time 0.002378886576655835 iter num 600\n",
            "loss 4.163845062255859 average time 0.0023757816967718685 iter num 620\n",
            "loss 0.3479066491127014 average time 0.0023713092343712106 iter num 640\n",
            "loss 1.407711148262024 average time 0.0023854008045473716 iter num 660\n",
            "loss 0.11922556161880493 average time 0.0023821476294147836 iter num 680\n",
            "loss 123.67414093017578 average time 0.002377992761438301 iter num 700\n",
            "loss 3.249135971069336 average time 0.00237554933334094 iter num 720\n",
            "loss 2.407952308654785 average time 0.0023719280919018227 iter num 740\n",
            "loss 15.23695182800293 average time 0.0023692469381785485 iter num 760\n",
            "loss 4.905668258666992 average time 0.002370138421816265 iter num 780\n",
            "loss 0.23201528191566467 average time 0.0023673219362694907 iter num 800\n",
            "loss 0.012926151975989342 average time 0.002366166564652525 iter num 820\n",
            "loss 1.701867938041687 average time 0.0023676171964520367 iter num 840\n",
            "loss 0.22447094321250916 average time 0.002364007553508198 iter num 860\n",
            "loss 0.4836956560611725 average time 0.00236884106251306 iter num 880\n",
            "loss 0.4143396317958832 average time 0.0023683178266765024 iter num 900\n",
            "loss 0.013087994419038296 average time 0.0023712902663172155 iter num 920\n",
            "loss 6.983582019805908 average time 0.002368759001074842 iter num 940\n",
            "loss 2.8618874549865723 average time 0.00236759077605484 iter num 960\n",
            "loss 0.3458845615386963 average time 0.0023654088163441753 iter num 980\n",
            "loss 0.18506105244159698 average time 0.002364692889021171 iter num 1000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 800000\n",
              "\tepoch: 800\n",
              "\tepoch_length: 1000\n",
              "\tmax_epochs: 800\n",
              "\toutput: 0.18506105244159698\n",
              "\tbatch: <class 'tuple'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: <class 'cupy_dataset.NumbaOptionDataSet'>\n",
              "\tseed: <class 'NoneType'>\n",
              "\ttimes: <class 'dict'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU1EpGuInwjJ"
      },
      "source": [
        "$2365$ seconds The loss is keeping decreasing which means the pricing model can predict the option prices better. It takes about $12ms$ to compute one mini-batch in average, In the following sections, we will try to expore the full potentials of the GPU to accelerate the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8McNtejRNFT"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRtOr1XIPOvF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87491847-ab24-4b64-b60c-a68108bd7c03"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.activity.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fexperimentsandconfigs%20https%3a%2f%2fwww.googleapis.com%2fauth%2fphotos.native&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/1AX4XfWgbnWEPGCLmnfOz_XYoNfYja3QUJtMDsSR93OnqcFttYqJVvTTU62k\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndftly2yPEaM"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'EuCall_1_v2.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6DRO9K2RQoJ"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HGXZSV_YRT8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a197a78f-3f6b-441a-ba7a-d45f83bb1743"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ntY-N5bOqdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "975859c0-d7ea-4143-901d-f3666ecd3a3b"
      },
      "source": [
        "import torch\n",
        "# model_save_name = 'EuCall_1_v2.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0GAGPAgPmgh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65bac430-ba2b-4f72-baf0-8455b507930b"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=6, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc5): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc6): Linear(in_features=1024, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rXT4Bg0wdL7l"
      },
      "source": [
        "### Continue to train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zfa9cp6CdG8T"
      },
      "source": [
        "# from ignite.engine import Engine, Events\n",
        "# from ignite.handlers import Timer\n",
        "# from torch.nn import MSELoss\n",
        "# from torch.optim import Adam\n",
        "# from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "# from ignite.handlers import ModelCheckpoint\n",
        "# from model import Net\n",
        "# from cupy_dataset import NumbaOptionDataSet\n",
        "# timer = Timer(average=True)\n",
        "# #model = Net().cuda()\n",
        "# loss_fn = MSELoss()\n",
        "# optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "# # dataset = NumbaOptionDataSet(max_len=10000, number_path = 1024, batch=4800)\n",
        "# dataset = NumbaOptionDataSet(max_len=500, number_path = 1024, batch=32, stocks=3)\n",
        "\n",
        "# def train_update(engine, batch):\n",
        "#     model.train()\n",
        "#     optimizer.zero_grad()\n",
        "#     x = batch[0]\n",
        "#     y = batch[1]\n",
        "#     y_pred = model(x)\n",
        "#     loss = loss_fn(y_pred[:,0], y)\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#     return loss.item()\n",
        "\n",
        "# trainer = Engine(train_update)\n",
        "# log_interval = 20\n",
        "\n",
        "# scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "# trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "# timer.attach(trainer,\n",
        "#              start=Events.EPOCH_STARTED,\n",
        "#              resume=Events.ITERATION_STARTED,\n",
        "#              pause=Events.ITERATION_COMPLETED,\n",
        "#              step=Events.ITERATION_COMPLETED)    \n",
        "# @trainer.on(Events.ITERATION_COMPLETED)\n",
        "# def log_training_loss(engine):\n",
        "#     iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "#     if iter % log_interval == 0:\n",
        "#         print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "# trainer.run(dataset, max_epochs=20)\n",
        "\n",
        "# model_save_name = 'checkpoint15.pth'\n",
        "# path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "# torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehmhDw8BUtLi"
      },
      "source": [
        "### Inference and Greeks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uiro43mOU0Ro"
      },
      "source": [
        "We can load the model parameters and use it to do inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svlu6tGTRx1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d860d5ea-35ef-45a6-ddc5-19598e3d5092"
      },
      "source": [
        "import torch\n",
        "# inputs = torch.tensor([[1, 110.0, 110.0, 0.35, 0.1, 0.05]*1]).cuda()\n",
        "# model(inputs.float())\n",
        "inputs = torch.tensor([[1, 110.0, 200.0, 0.35, 0.1, 0.05]*1]).cuda()\n",
        "model(inputs.float())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[95.4640]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1Iy-9pWVRDO"
      },
      "source": [
        "One of the benefits of building a deep learning model is that the [Greeks](<https://en.wikipedia.org/wiki/Greeks_(finance)#First-order_Greeks>) can be easily computed. \n",
        "We just need to take advantage of the auto-grad feature in Pytorch. We can use `grad` function to compute the first order differentiation for parameters 'K, B, S0, sigma, mu, r'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytBZaYHKSnDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "220f8dca-5437-4a7f-9805-9326b2dec050"
      },
      "source": [
        "inputs = torch.tensor([[1, 110.0, 200.0, 0.35, 0.1, 0.05]*1]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 8.8086, -0.8740,  0.9518,  9.5438,  0.8059, 90.7632]],\n",
              "       device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KeijaDDVZGd"
      },
      "source": [
        "Here we are going to plot the Delta graph:-"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skwgeVDsA_Mr"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USh3qaADSYQp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "4af67a2d-47c0-44b2-f453-128bbc61ab43"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    # inputs = torch.tensor([[110.0, 0.0, S, 0.35, 0.1, 0.05] + ([110.0, 0.0, 110.0, 0.35, 0.1, 0.05]*2)]).cuda()\n",
        "    inputs = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fca05a62950>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "VGk5Hw64fMdh",
        "outputId": "402ff3b0-6a19-4b67-f586-35afbb22e060"
      },
      "source": [
        "## Using Finite Difference, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    epsilon = 0.01\n",
        "    inputs1 = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, S + epsilon, 0.35, 0.1, 0.05]]).cuda()\n",
        "    delta = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return delta\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fca05561450>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tLStvS2qCSjm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a38c7ee-1553-45a9-a4e0-527500f546fe"
      },
      "source": [
        "compute_delta(110)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6796]], device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "4O1I8COnUxnz",
        "outputId": "0b51fefe-d8ae-4c65-ede0-72ef5e8ad024"
      },
      "source": [
        "##Using Finite Difference, Change 3 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    epsilon = 0.01\n",
        "    inputs1 = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, S + epsilon, 0.35, 0.1, 0.05]]).cuda()\n",
        "    delta = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return delta\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fca05552790>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySrey9KzB0AF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b811f4b-4865-4d90-f419-2c5ca66e5618"
      },
      "source": [
        "compute_delta(110).item()  # It's not 0.5!! SOS"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6795883178710938"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMyME_1WCGZz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "993edf60-cc56-4ec0-a2f5-f50bbb5e8a82"
      },
      "source": [
        "compute_delta(102).item() # Close to 0.5"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.574493408203125"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNB8LPwfBMHQ"
      },
      "source": [
        "# Gamma"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLO_5nEGVcEc"
      },
      "source": [
        "Calculating the second order derivative is easy in PyTorch too. We just need to apply the `grad` function twice. Use this mechanism, we can calculate the second order derivatives $\\frac{\\partial^2 P}{\\partial K \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial B \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial S_0^2}$, $\\frac{\\partial^2 P}{\\partial \\sigma \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial \\mu \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial r \\partial S_0}$ in the following example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGzj7A3sThZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f8cad3-edab-46ad-affb-be58712adf16"
      },
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import grad\n",
        "from torch import nn\n",
        "\n",
        "inputs = torch.tensor([[1, 110.0, 110.0, 0.35, 0.1, 0.05]*1]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs)\n",
        "\n",
        "# instead of using loss.backward(), use torch.autograd.grad() to compute gradients\n",
        "# https://pytorch.org/docs/stable/autograd.html#torch.autograd.grad\n",
        "loss_grads = grad(x, inputs, create_graph=True)\n",
        "drv = grad(loss_grads[0][0][2], inputs)\n",
        "drv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.3466, -0.0274,  0.0324,  0.9254, -0.0570,  2.8929]],\n",
              "        device='cuda:0'),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJbZYtvhVmSo"
      },
      "source": [
        "Gamma is the second order differenation of `S`. We can plot the the Gamma curve as a function of the stock price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JpQa3EJToA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "bd985a3c-6e0b-4b7d-99c0-401756ec702a"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "import pylab\n",
        "import numpy as np\n",
        "def compute_gamma(S):\n",
        "    inputs = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    loss_grads = grad(x, inputs, create_graph=True)\n",
        "    drv = grad(loss_grads[0][0][2], inputs)\n",
        "    return drv[0][0][2]\n",
        "\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "gammas = []\n",
        "for p in prices:\n",
        "    gammas.append(compute_gamma(p).item())\n",
        "fig2 = pylab.plot(prices, gammas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Gamma')\n",
        "fig2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fca054d1d50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsoaOyCDxQy0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "d480ceee-d089-4e0c-eef6-7c6a5a891f14"
      },
      "source": [
        "##Using Finite Difference, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_gamma(S):\n",
        "    epsilon = 0.5\n",
        "    inputs1 = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, S + epsilon, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs3 = torch.tensor([[1, 110.02, S - epsilon, 0.35, 0.1, 0.05]]).cuda()\n",
        "    gamma = (model(inputs2.float()) - 2*model(inputs1.float()) + model(inputs3.float()))/(epsilon**2)\n",
        "    return gamma\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "gammas = []\n",
        "for p in prices:\n",
        "    gammas.append(compute_gamma(p).item())\n",
        "fig = pylab.plot(prices, gammas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Gamma')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fca054409d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "aOsXgOwWZ_ru",
        "outputId": "b5074b43-9921-49a0-dd9a-5cb7d0bd72ed"
      },
      "source": [
        "##Using Finite Difference, Change 3 S0 at a time\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_gamma(S):\n",
        "    epsilon = 0.5\n",
        "    inputs1 = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]*1]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, S + epsilon, 0.35, 0.1, 0.05]*1]).cuda()\n",
        "    inputs3 = torch.tensor([[1, 110.0, S - epsilon, 0.35, 0.1, 0.05]*1]).cuda()\n",
        "    gamma = (model(inputs2.float()) - 2*model(inputs1.float()) + model(inputs3.float()))/(epsilon**2)\n",
        "    return gamma\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "gammas = []\n",
        "for p in prices:\n",
        "    gammas.append(compute_gamma(p).item())\n",
        "fig = pylab.plot(prices, gammas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Gamma')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fca053b1cd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67lca2xrBh9a"
      },
      "source": [
        "# Vega"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muozc-hzhSGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "e00238cb-d5ac-4216-ce67-fd1ca504c940"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "# vega\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_vega(S):\n",
        "    epsilon = 0.5\n",
        "    inputs1 = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, S, 0.35 + epsilon, 0.1, 0.05]]).cuda()\n",
        "    vega = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return vega\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "vegas = []\n",
        "for p in prices:\n",
        "    vegas.append(compute_vega(p).item())\n",
        "fig = pylab.plot(prices, vegas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Vega')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fca062eb150>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "0KATxBCAdlFt",
        "outputId": "dbb765df-1d5a-4fc4-dc84-3f84454eb9a9"
      },
      "source": [
        "##Using Finite Difference, Change 3 S0 at a timev\n",
        "# vega\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "def compute_vega(S):\n",
        "    epsilon = 0.5\n",
        "    inputs1 = torch.tensor([[1, 110.0, S, 0.35, 0.1, 0.05]*1]).cuda()\n",
        "    inputs2 = torch.tensor([[1, 110.0, S, 0.35 + epsilon, 0.1, 0.05]*1]).cuda()\n",
        "    vega = (model(inputs2.float()) - model(inputs1.float()))/epsilon\n",
        "    return vega\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "vegas = []\n",
        "for p in prices:\n",
        "    vegas.append(compute_vega(p).item())\n",
        "fig = pylab.plot(prices, vegas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Vega')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fca076c2050>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj7NlW6GVqSA"
      },
      "source": [
        "[Implied volatility](https://en.wikipedia.org/wiki/Implied_volatility) is the forecasted volatility of the underlying asset based on the quoted prices of the option. It is the reverse mapping of price to the option parameter given the model which is hard to do with the Monte Carlo simulation approach. But if we have the deep learning pricing model, it is an easy task. We can first plot the relationship between volatility and the option price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yrCw5UNT07t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "1330a28c-7d24-45dd-e5ca-ed23ec99626b"
      },
      "source": [
        "import pylab\n",
        "import numpy as np\n",
        "def compute_price(sigma):\n",
        "    inputs = torch.tensor([[1, 110.0, 110.0, sigma, 0.1, 0.05]]).cuda()\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    return x.item()\n",
        "sigmas = np.arange(0, 0.5, 0.1)\n",
        "prices = []\n",
        "for s in sigmas:\n",
        "    prices.append(compute_price(s))\n",
        "fig3 = pylab.plot(sigmas, prices)\n",
        "pylab.xlabel('Sigma')\n",
        "pylab.ylabel('Price')\n",
        "fig3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fca07884410>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU25Cj29VtCa"
      },
      "source": [
        "Given the prices `P`, the implied volatility is the root of the function `compute_price`. We can use bisection to find the root."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddHnwm_zUBYD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92595e68-e1d4-4c72-80dc-843c2118937c"
      },
      "source": [
        "def bisection_root(small, large, fun, target, EPS=1e-6):\n",
        "    if fun(large) - target < 0:\n",
        "        print('upper bound is too small')\n",
        "        return None\n",
        "    if fun(small) - target > 0:\n",
        "        print('lower bound is too large')\n",
        "        return None\n",
        "    while large - small > EPS:\n",
        "        mid = (large + small) / 2.0\n",
        "        if fun(mid) - target >= 0:\n",
        "            large = mid\n",
        "        else:\n",
        "            small = mid\n",
        "    mid = (large + small) / 2.0\n",
        "    return mid, abs(fun(mid) - target)\n",
        "quoted_price = 16.0\n",
        "sigma, err = bisection_root(0, 0.5, compute_price, quoted_price)\n",
        "print('implied volativity', sigma, 'error', err)     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "implied volativity 0.2896866798400879 error 9.5367431640625e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEiAredqQGxf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}