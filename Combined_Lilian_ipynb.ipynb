{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "“Combined.ipynb”的副本",
      "provenance": [],
      "collapsed_sections": [
        "NwN6aLFDnwiy",
        "dBOv_RiBsCWa",
        "u2_89jOknwjH"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Lilian/Combined_Lilian_ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCR6hhw5Xq_R"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSxOZk3ls2XQ",
        "outputId": "3a20fd38-af92-4f68-ae22-3e0c5b60f106"
      },
      "source": [
        "!curl https://colab.chainer.org/install |sh -\n",
        "import cupy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "\r  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\r100  1580  100  1580    0     0   9080      0 --:--:-- --:--:-- --:--:--  9080\n",
            "+ apt -y -q install cuda-libraries-dev-10-0\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "cuda-libraries-dev-10-0 is already the newest version (10.0.130-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "+ pip install -q cupy-cuda100  chainer \n",
            "+ set +ex\n",
            "Installation succeeded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwN6aLFDnwiy"
      },
      "source": [
        "### Deep Learning Barrier Option\n",
        "\n",
        "We used Numba and CuPy in the previous notebook to run Monte Carlo simulation to determine the price of the Asian Barrier option. A Monte Carlo simulation needs millions of paths to get an accurate answer which is computationally intensive. [Ryan et al (2018)](https://arxiv.org/abs/1809.02233) showed that a deep learning model can be trained to value derivatives. The deep learning model is accurate and very fast, capable of producing valuations a million times faster than traditional models. In the this notebook, we will use a fully connected network to learn the pricing mode of the Asian Barrier option. Monte Carlo simulation is used as pricing ground truth for the training. We use the same Asian Barrier Option model as last notebook with parameters listed as following:\n",
        "\n",
        "```\n",
        "T - Maturity (yrs.)\n",
        "S - Spot (usd)\n",
        "K - Strike (usd)\n",
        "sigma - Volatility (per.)\n",
        "r - Risk Free Rate (per.)\n",
        "mu - Stock Drift Rate (per.)\n",
        "B - Barrier (usd)\n",
        "```\n",
        "\n",
        "### Batched Data generation\n",
        "\n",
        "The dataset is an important part of the Deep learning training. We will modify the previous single Asian Barrier Option pricing code to handle a batch of Barrier Option pricing. \n",
        "\n",
        "Loading all the necessary libraries:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu6no5JzH-B6"
      },
      "source": [
        "# !pip install cupy-cuda101"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbkx3hXWnwi8"
      },
      "source": [
        "# import cupy\n",
        "# import numpy as np\n",
        "# import math\n",
        "# import time\n",
        "# import torch\n",
        "# cupy.cuda.set_allocator(None)\n",
        "# from torch.utils.dlpack import from_dlpack"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqBN3YFOnwi-"
      },
      "source": [
        "The CuPy version of batched barrier option pricing simulation is as follows:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzhj4DtLnwi-"
      },
      "source": [
        "# cupy_batched_barrier_option = cupy.RawKernel(r'''\n",
        "# extern \"C\" __global__ void batched_barrier_option(\n",
        "#     float *d_s,\n",
        "#     const float T,\n",
        "#     const float * K,\n",
        "#     const float * B,\n",
        "#     const float * S0,\n",
        "#     const float * sigma,\n",
        "#     const float * mu,\n",
        "#     const float * r,\n",
        "#     const float * d_normals,\n",
        "#     const long N_STEPS,\n",
        "#     const long N_PATHS,\n",
        "#     const long N_BATCH)\n",
        "# {\n",
        "#   unsigned idx =  threadIdx.x + blockIdx.x * blockDim.x;\n",
        "#   unsigned stride = blockDim.x * gridDim.x;\n",
        "#   unsigned tid = threadIdx.x;\n",
        "#   const float tmp3 = sqrt(T/N_STEPS);\n",
        "\n",
        "\n",
        "#   for (unsigned i = idx; i<N_PATHS * N_BATCH; i+=stride)\n",
        "#   {\n",
        "#     int batch_id = i / N_PATHS;\n",
        "#     int path_id = i % N_PATHS;\n",
        "#     float s_curr = S0[batch_id];\n",
        "#     float tmp1 = mu[batch_id]*T/N_STEPS;\n",
        "#     float tmp2 = exp(-r[batch_id]*T);\n",
        "#     unsigned n=0;\n",
        "#     double running_average = 0.0;\n",
        "#     for(unsigned n = 0; n < N_STEPS; n++){\n",
        "#        s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH];\n",
        "#        running_average += (s_curr - running_average) / (n + 1.0);\n",
        "#        if (running_average <= B[batch_id]){\n",
        "#            break;\n",
        "#        }\n",
        "#     }\n",
        "\n",
        "#     float payoff = (running_average>K[batch_id] ? running_average-K[batch_id] : 0.f); \n",
        "#     d_s[i] = tmp2 * payoff;\n",
        "#   }\n",
        "# }\n",
        "\n",
        "# ''', 'batched_barrier_option')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRjmX5zcnwi_"
      },
      "source": [
        "Note, the parameters (K, B, S0, sigma, mu, r) are passed in as an array with length of batch size. The output array is a two dimensional array flatten to 1-D. The first dimension is for Batch and the second dimension is for Path. \n",
        "\n",
        "Testing it out by entering two sets of option parameters:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn4PMo7Inwi_"
      },
      "source": [
        "# N_PATHS = 2048000\n",
        "# N_STEPS = 365\n",
        "# N_BATCH = 2\n",
        "# T = 1.0\n",
        "\n",
        "# K = cupy.array([110.0, 120.0], dtype=cupy.float32)\n",
        "# B = cupy.array([100.0, 90.0], dtype=cupy.float32)\n",
        "# S0 = cupy.array([120.0, 100.0], dtype=cupy.float32)\n",
        "# sigma = cupy.array([0.35, 0.2], dtype=cupy.float32)\n",
        "# mu = cupy.array([0.15, 0.1], dtype=cupy.float32)\n",
        "# r =cupy.array([0.05, 0.05], dtype=cupy.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpWK3wcEnwjA"
      },
      "source": [
        "Put everything into a simple function to launch this GPU kernel. The option prices for each batch is the average of the corresponding path terminal values. This can be computed easily by Cupy function `mean(axis=1)`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhAb34NTnwjA"
      },
      "source": [
        "# def batch_run():\n",
        "#     number_of_threads = 256\n",
        "#     number_of_blocks = (N_PATHS * N_BATCH - 1) // number_of_threads + 1\n",
        "#     randoms_gpu = cupy.random.normal(0, 1, N_BATCH*N_PATHS * N_STEPS, dtype=cupy.float32)\n",
        "#     output = cupy.zeros(N_BATCH*N_PATHS, dtype=cupy.float32)\n",
        "#     cupy.cuda.stream.get_current_stream().synchronize()\n",
        "#     s = time.time()\n",
        "#     cupy_batched_barrier_option((number_of_blocks,), (number_of_threads,),\n",
        "#                        (output, np.float32(T), K, B, S0, sigma, mu, r,\n",
        "#                         randoms_gpu, N_STEPS, N_PATHS, N_BATCH))\n",
        "#     v = output.reshape(N_BATCH, N_PATHS).mean(axis=1)\n",
        "#     cupy.cuda.stream.get_current_stream().synchronize()\n",
        "#     e = time.time()\n",
        "#     print('time', e-s, 'v',v)\n",
        "# batch_run()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "puRgQCelnwjC"
      },
      "source": [
        "This produces the option prices $21.22$ and $0.848$ for these two sets of option parameters in $66ms$.\n",
        "\n",
        "It works efficiently hence we will construct an `OptionDataSet` class to wrap the above code so we can use it in Pytorch. For every `next` element, it generates uniform distributed random option parameters in the specified range, launches the GPU kernel to compute the option prices, convert the CuPy array to Pytorch tensors with zero copy via the DLPack. Note how we implemented the iterable Dataset interface:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1KUra7ZnwjC"
      },
      "source": [
        "# class OptionDataSet(torch.utils.data.IterableDataset):\n",
        "    \n",
        "#     def __init__(self, max_len=10, number_path = 1000, batch=2, threads=256,seed=15):\n",
        "#         self.num = 0\n",
        "#         self.max_length = max_len\n",
        "#         self.N_PATHS = number_path\n",
        "#         self.N_STEPS = 365\n",
        "#         self.N_BATCH = batch\n",
        "#         self.T = np.float32(1.0)\n",
        "#         self.output = cupy.zeros(self.N_BATCH*self.N_PATHS, dtype=cupy.float32) \n",
        "#         self.number_of_blocks = (self.N_PATHS * self.N_BATCH - 1) // threads + 1\n",
        "#         self.number_of_threads = threads\n",
        "#         cupy.random.seed(seed)\n",
        "        \n",
        "#     def __len__(self):\n",
        "#         return self.max_length\n",
        "        \n",
        "#     def __iter__(self):\n",
        "#         self.num = 0\n",
        "#         return self\n",
        "    \n",
        "#     def __next__(self):\n",
        "#         if self.num > self.max_length:\n",
        "#             raise StopIteration\n",
        "#         X = cupy.random.rand(self.N_BATCH, 6, dtype=cupy.float32)\n",
        "#         # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "#         X = X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2], dtype=cupy.float32)\n",
        "#         # make sure the Barrier is smaller than the Strike price\n",
        "#         X[:, 1] = X[:, 0] * X[:, 1]\n",
        "#         randoms = cupy.random.normal(0, 1, self.N_BATCH * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "#         cupy_batched_barrier_option((self.number_of_blocks,), (self.number_of_threads,), (self.output, self.T, cupy.ascontiguousarray(X[:, 0]), \n",
        "#                               cupy.ascontiguousarray(X[:, 1]), cupy.ascontiguousarray(X[:, 2]), cupy.ascontiguousarray(X[:, 3]), cupy.ascontiguousarray(X[:, 4]), cupy.ascontiguousarray(X[:, 5]), randoms, self.N_STEPS, self.N_PATHS, self.N_BATCH))\n",
        "#         Y = self.output.reshape(self.N_BATCH, self.N_PATHS).mean(axis=1)\n",
        "#         self.num += 1\n",
        "#         return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zo46Vf4XnwjD"
      },
      "source": [
        "Put everything related to Pytorch dataset into a file `cupy_dataset.py`:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwQUGMBlnwjE"
      },
      "source": [
        "# #%%writefile cupy_dataset.py \n",
        "# import cupy\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "# cupy.cuda.set_allocator(None)\n",
        "\n",
        "# cupy_batched_barrier_option = cupy.RawKernel(r'''\n",
        "# extern \"C\" __global__ void batched_barrier_option(\n",
        "#     float *d_s,\n",
        "#     const float T,\n",
        "#     const float * K,\n",
        "#     const float * B,\n",
        "#     const float * S0,\n",
        "#     const float * sigma,\n",
        "#     const float * mu,\n",
        "#     const float * r,\n",
        "#     const float * d_normals,\n",
        "#     const long N_STEPS,\n",
        "#     const long N_PATHS,\n",
        "#     const long N_BATCH)\n",
        "# {\n",
        "#   unsigned idx =  threadIdx.x + blockIdx.x * blockDim.x;\n",
        "#   unsigned stride = blockDim.x * gridDim.x;\n",
        "#   unsigned tid = threadIdx.x;\n",
        "#   const float tmp3 = sqrt(T/N_STEPS);\n",
        "\n",
        "\n",
        "#   for (unsigned i = idx; i<N_PATHS * N_BATCH; i+=stride)\n",
        "#   {\n",
        "#     int batch_id = i / N_PATHS;\n",
        "#     int path_id = i % N_PATHS;\n",
        "#     float s_curr = S0[batch_id];\n",
        "#     float tmp1 = mu[batch_id]*T/N_STEPS;\n",
        "#     float tmp2 = exp(-r[batch_id]*T);\n",
        "#     unsigned n=0;\n",
        "#     double running_average = 0.0;\n",
        "#     for(unsigned n = 0; n < N_STEPS; n++){\n",
        "#        s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH];\n",
        "#        running_average += (s_curr - running_average) / (n + 1.0);\n",
        "#        if (running_average <= B[batch_id]){\n",
        "#            break;\n",
        "#        }\n",
        "#     }\n",
        "\n",
        "#     float payoff = (running_average>K[batch_id] ? running_average-K[batch_id] : 0.f); \n",
        "#     d_s[i] = tmp2 * payoff;\n",
        "#   }\n",
        "# }\n",
        "\n",
        "# ''', 'batched_barrier_option')\n",
        "\n",
        "# class OptionDataSet(torch.utils.data.IterableDataset):\n",
        "    \n",
        "#     def __init__(self, max_len=10, number_path = 1000, batch=2, threads=256,seed=15):\n",
        "#         self.num = 0\n",
        "#         self.max_length = max_len\n",
        "#         self.N_PATHS = number_path\n",
        "#         self.N_STEPS = 365\n",
        "#         self.N_BATCH = batch\n",
        "#         self.T = np.float32(1.0)\n",
        "#         self.output = cupy.zeros(self.N_BATCH*self.N_PATHS, dtype=cupy.float32) \n",
        "#         self.number_of_blocks = (self.N_PATHS * self.N_BATCH - 1) // threads + 1\n",
        "#         self.number_of_threads = threads\n",
        "#         cupy.random.seed(seed)\n",
        "        \n",
        "#     def __len__(self):\n",
        "#         return self.max_length\n",
        "        \n",
        "#     def __iter__(self):\n",
        "#         self.num = 0\n",
        "#         return self\n",
        "    \n",
        "#     def __next__(self):\n",
        "#         if self.num > self.max_length:\n",
        "#             raise StopIteration\n",
        "#         X = cupy.random.rand(self.N_BATCH, 6, dtype=cupy.float32)\n",
        "#         # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "#         X = X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2], dtype=cupy.float32)\n",
        "#         # make sure the Barrier is smaller than the Strike price\n",
        "#         X[:, 1] = X[:, 0] * X[:, 1]\n",
        "#         randoms = cupy.random.normal(0, 1, self.N_BATCH * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "#         cupy_batched_barrier_option((self.number_of_blocks,), (self.number_of_threads,), (self.output, self.T, cupy.ascontiguousarray(X[:, 0]), \n",
        "#                               cupy.ascontiguousarray(X[:, 1]), cupy.ascontiguousarray(X[:, 2]), cupy.ascontiguousarray(X[:, 3]), cupy.ascontiguousarray(X[:, 4]), cupy.ascontiguousarray(X[:, 5]), randoms, self.N_STEPS, self.N_PATHS, self.N_BATCH))\n",
        "#         Y = self.output.reshape(self.N_BATCH, self.N_PATHS).mean(axis=1)\n",
        "#         self.num += 1\n",
        "#         return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyPAsh7JnwjF"
      },
      "source": [
        "Here is a test code to sample 10 data points with batch size 16:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLKxMF05nwjF"
      },
      "source": [
        "# from cupy_dataset import OptionDataSet\n",
        "# ds = OptionDataSet(10, number_path=100000, batch=16, seed=15)\n",
        "# for i in ds:\n",
        "#     print(i[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTlzRTD0nwjG"
      },
      "source": [
        "We can implement the same code by using Numba to accelerate the calculation in GPU:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IsfSwVwnwjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bb49636-2adf-46fe-b7f6-c1e6d12a4aa5"
      },
      "source": [
        "# import numba\n",
        "# from numba import cuda\n",
        "\n",
        "# @cuda.jit\n",
        "# def batch_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_BATCH):\n",
        "#     # ii - overall thread index\n",
        "#     ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "#     stride = cuda.gridDim.x * cuda.blockDim.x\n",
        "#     tmp3 = math.sqrt(T/N_STEPS)\n",
        "#     for i in range(ii, N_PATHS * N_BATCH, stride):\n",
        "#         batch_id = i // N_PATHS\n",
        "#         path_id = i % N_PATHS\n",
        "#         tmp1 = mu[batch_id]*T/N_STEPS\n",
        "#         tmp2 = math.exp(-r[batch_id]*T)\n",
        "#         running_average = 0.0\n",
        "#         s_curr = S0[batch_id]\n",
        "#         for n in range(N_STEPS):\n",
        "\n",
        "#             s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH]\n",
        "#             running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average)\n",
        "#             if i==0 and batch_id == 2:\n",
        "#                 print(s_curr)\n",
        "#             if running_average <= B[batch_id]:\n",
        "#                 break\n",
        "#         payoff = running_average - K[batch_id] if running_average > K[batch_id] else 0\n",
        "#         d_s[i] = tmp2 * payoff\n",
        "\n",
        "# class NumbaOptionDataSet(object):\n",
        "    \n",
        "#     def __init__(self, max_len=10, number_path = 1000, batch=2, threads=512, seed=15):\n",
        "#         self.num = 0\n",
        "#         self.max_length = max_len\n",
        "#         self.N_PATHS = number_path\n",
        "#         self.N_STEPS = 365\n",
        "#         self.N_BATCH = batch\n",
        "#         self.T = np.float32(1.0)\n",
        "#         self.output = cupy.zeros(self.N_BATCH*self.N_PATHS, dtype=cupy.float32) \n",
        "#         self.number_of_blocks = (self.N_PATHS * self.N_BATCH - 1) // threads + 1\n",
        "#         self.number_of_threads = threads\n",
        "#         cupy.random.seed(seed)\n",
        "        \n",
        "#     def __len__(self):\n",
        "#         return self.max_length\n",
        "\n",
        "#     def __iter__(self):\n",
        "#         self.num = 0\n",
        "#         return self\n",
        "    \n",
        "#     def __next__(self):\n",
        "#         if self.num > self.max_length:\n",
        "#             raise StopIteration\n",
        "#         X = cupy.random.rand(self.N_BATCH, 6, dtype=cupy.float32)\n",
        "#         # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "#         X = X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2], dtype=cupy.float32)\n",
        "#         # make sure the Barrier is smaller than the Strike price\n",
        "#         X[:, 1] = X[:, 0] * X[:, 1]\n",
        "#         randoms = cupy.random.normal(0, 1, self.N_BATCH * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "#         batch_barrier_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, self.T, X[:, 0], \n",
        "#                               X[:, 1], X[:, 2], X[:, 3], X[:, 4], X[:, 5], randoms, self.N_STEPS, self.N_PATHS, self.N_BATCH)\n",
        "#         o = self.output.reshape(self.N_BATCH, self.N_PATHS)\n",
        "#         Y = o.mean(axis = 1) \n",
        "#         self.num += 1\n",
        "#         return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "# ds = NumbaOptionDataSet(10, number_path=100000, batch=1, seed=15)\n",
        "# for i in ds:\n",
        "#     print(i[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([165.6941], device='cuda:0')\n",
            "tensor([51.4442], device='cuda:0')\n",
            "tensor([31.0613], device='cuda:0')\n",
            "tensor([21.1520], device='cuda:0')\n",
            "tensor([32.8344], device='cuda:0')\n",
            "tensor([21.4236], device='cuda:0')\n",
            "tensor([0.], device='cuda:0')\n",
            "tensor([22.7325], device='cuda:0')\n",
            "tensor([0.0027], device='cuda:0')\n",
            "tensor([66.4288], device='cuda:0')\n",
            "tensor([39.2807], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY_9g3tbdLiY"
      },
      "source": [
        "# TEST_ERIN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qBxT9Eida-c_",
        "outputId": "d465f229-59a1-4172-cf38-573a3b8faedc"
      },
      "source": [
        "################################# TEST ########################################\n",
        "%%writefile cupy_dataset.py\n",
        "\n",
        "import numba\n",
        "from numba import cuda\n",
        "import random\n",
        "import cupy\n",
        "import numpy as np\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "cupy.cuda.set_allocator(None)\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "@cuda.jit\n",
        "def batch_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_BATCH):\n",
        "    # ii - overall thread index\n",
        "    ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "    stride = cuda.gridDim.x * cuda.blockDim.x\n",
        "    tmp3 = math.sqrt(T/N_STEPS)\n",
        "    for i in range(ii, N_PATHS * N_BATCH, stride):\n",
        "        batch_id = i // N_PATHS\n",
        "        path_id = i % N_PATHS\n",
        "        tmp1 = mu[batch_id]*T/N_STEPS\n",
        "        tmp2 = math.exp(-r[batch_id]*T)\n",
        "        running_average = 0.0\n",
        "        s_curr = S0[batch_id]\n",
        "        for n in range(N_STEPS):\n",
        "            s_curr += tmp1 * s_curr + sigma[batch_id]*s_curr*tmp3*d_normals[path_id + batch_id * N_PATHS + n * N_PATHS * N_BATCH] # stock price\n",
        "            running_average = running_average + 1.0/(n + 1.0) * (s_curr - running_average) # average of the path\n",
        "            if i==0 and batch_id == 2:\n",
        "                print(s_curr)\n",
        "            if running_average <= B[batch_id]: # if reach barrier, drop out the path\n",
        "                break\n",
        "        payoff = running_average - K[batch_id] if running_average > K[batch_id] else 0\n",
        "        d_s[i] = tmp2 * payoff\n",
        "\n",
        "class NumbaOptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len=10, number_path = 1000, batch=2, threads=512, seed=15, stocks=3):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 365\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = np.float32(1.0)\n",
        "        self.output = cupy.zeros(self.N_STOCKS*self.N_PATHS, dtype=cupy.float32) \n",
        "        self.number_of_blocks = (self.N_PATHS * self.N_STOCKS - 1) // threads + 1\n",
        "        self.number_of_threads = threads\n",
        "        cupy.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num > self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros(self.N_BATCH, dtype=cupy.float32)\n",
        "        paras = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "        for op in range(self.N_BATCH):\n",
        "\n",
        "          X = cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)\n",
        "          #X = 0.9 + cupy.random.rand(6 * self.N_STOCKS, dtype=cupy.float32)*0.1\n",
        "\n",
        "          # scale the [0, 1) random numbers to the correct range for each of the option parameters\n",
        "          X = (X * cupy.array([200.0, 0.99, 200.0, 0.4, 0.2, 0.2] * self.N_STOCKS, dtype = cupy.float32)).reshape(self.N_STOCKS, 6)\n",
        "\n",
        "          # make sure the Barrier is smaller than the Strike price\n",
        "          # X[:, 1] = X[:, 0] * X[:, 1]\n",
        "          for i in range(self.N_STOCKS):\n",
        "            paras[op,i*6:(i+1)*6] = X[i,:]\n",
        "\n",
        "          stocks_randoms_mean = cupy.zeros(self.N_STOCKS, dtype = cupy.float32)\n",
        "          rho = cupy.random.normal(0, 1, self.N_STOCKS, dtype = cupy.float32)\n",
        "\n",
        "          #stocks_randoms_cov = cupy.ones((self.N_STOCKS, self.N_STOCKS), dtype = cupy.float32)\n",
        "          #cupy.fill_diagonal(stocks_randoms_cov, rho)\n",
        "\n",
        "          #stocks_randoms_cov = (-0.99 + cupy.random.rand(self.N_STOCKS*self.N_STOCKS, dtype=cupy.float32)*2*0.99).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "          stocks_randoms_cov = cupy.array([0.9] * self.N_STOCKS*self.N_STOCKS, dtype = cupy.float32).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "          cupy.fill_diagonal(stocks_randoms_cov, 1)\n",
        "\n",
        "          num_of_randoms_each_stock = self.N_PATHS * self.N_STEPS\n",
        "          randoms_gpu = cupy.random.multivariate_normal(stocks_randoms_mean, stocks_randoms_cov,\n",
        "                                                        num_of_randoms_each_stock, dtype=cupy.float32)\n",
        "          b1_r = randoms_gpu[:,0]\n",
        "          b2_r = randoms_gpu[:,1]\n",
        "          randoms = cupy.zeros(self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "          interval = int((self.N_PATHS * self.N_STEPS * self.N_STOCKS) / self.N_PATHS)\n",
        "          for i in range(interval):\n",
        "            if i % 2 == 0:\n",
        "                ind = int(i/2)\n",
        "                randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b1_r[ind:(ind+self.N_PATHS)]\n",
        "            else:\n",
        "                ind = int(i//2)\n",
        "                randoms[i*self.N_PATHS:(i+1)*self.N_PATHS] = b2_r[ind:(ind+self.N_PATHS)]\n",
        "\n",
        "          randoms = cupy.random.normal(0, 1, self.N_STOCKS * self.N_PATHS * self.N_STEPS, dtype=cupy.float32)\n",
        "          batch_barrier_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, self.T, X[:, 0], \n",
        "                                X[:, 1], X[:, 2], X[:, 3], X[:, 4], X[:, 5], randoms, self.N_STEPS, self.N_PATHS, self.N_STOCKS)\n",
        "          \n",
        "          o = self.output.reshape(self.N_STOCKS, self.N_PATHS)\n",
        "          Y[op] = o.mean(axis = 0).mean()\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(paras.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "\n",
        "# ds = NumbaOptionDataSet(10, number_path=100000, batch=3, seed=random.randint(0,100), stocks=5)\n",
        "# for i in ds:\n",
        "#     print(i[0])\n",
        "################################# TEST ########################################"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting cupy_dataset.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBOv_RiBsCWa"
      },
      "source": [
        "### PUI TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BME87CgGsFrd"
      },
      "source": [
        "# %%writefile cupy_dataset.py\n",
        "# import numba\n",
        "# from numba import cuda\n",
        "# import cupy\n",
        "# import numpy as np\n",
        "# import math\n",
        "# import time\n",
        "# import torch\n",
        "# cupy.cuda.set_allocator(None)\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# @cuda.jit\n",
        "# def single_barrier_option(d_s, T, K, B, S0, sigma, mu, r, d_normals, N_STEPS, N_PATHS, N_STOCKS, s_curr):\n",
        "\n",
        "#     # ii - overall thread index\n",
        "#     ii = cuda.threadIdx.x + cuda.blockIdx.x * cuda.blockDim.x\n",
        "#     stride = cuda.gridDim.x * cuda.blockDim.x\n",
        "#     tmp2 = math.exp(-r*T)\n",
        "#     tmp3 = math.sqrt(T/N_STEPS)    \n",
        "\n",
        "#     for i in range(ii, N_PATHS, stride): # for each path          \n",
        "#         running_average = 0.0\n",
        "\n",
        "#         for j in range(N_STOCKS): # initialize S0\n",
        "#             s_curr[j] = S0[j]\n",
        "\n",
        "#         for n in range(N_STEPS): # for each step\n",
        "#             s_curr_avg = 0.0\n",
        "\n",
        "#             for j in range(N_STOCKS): # for each stock\n",
        "#                 tmp1 = mu[j]*T/N_STEPS  \n",
        "#                 s_curr[j] += tmp1 * s_curr[j] + sigma[j]*s_curr[j]*tmp3*d_normals[i,n,j]\n",
        "#                 s_curr_avg = s_curr_avg + 1.0/(j + 1.0) * (s_curr[j] - s_curr_avg) # S average in this step\n",
        "\n",
        "#             # add stock average to running average\n",
        "#             running_average = running_average + 1.0/(n + 1.0) * (s_curr_avg - running_average)\n",
        "\n",
        "#             # compare to barrier\n",
        "#             if running_average <= B:\n",
        "#                 break\n",
        "\n",
        "#         payoff = running_average - K if running_average > K else 0\n",
        "#         d_s[i] = tmp2 * payoff\n",
        "    \n",
        "\n",
        "# class NumbaOptionDataSet(object):\n",
        "    \n",
        "#     def __init__(self, max_len=10, number_path = 1000, number_stocks = 3, batch=1, threads=512, seed=15, T=1):\n",
        "#         self.num = 0\n",
        "#         self.max_length = max_len\n",
        "#         self.N_PATHS = number_path\n",
        "#         self.N_STEPS = 365\n",
        "#         self.N_STOCKS = number_stocks\n",
        "#         self.N_BATCH = batch\n",
        "#         self.T = np.float32(T)\n",
        "#         self.output = cupy.zeros(self.N_PATHS, dtype=cupy.float32) \n",
        "#         self.number_of_blocks = (self.N_PATHS * self.N_STOCKS - 1) // threads + 1\n",
        "#         self.number_of_threads = threads\n",
        "#         cupy.random.seed(seed)\n",
        "\n",
        "#         ############ <new\n",
        "#         self.Z_mean = cupy.zeros(self.N_STOCKS, dtype=cupy.float32)\n",
        "#         self.Z_cov = (-0.2 + cupy.random.rand(self.N_STOCKS*self.N_STOCKS, dtype=cupy.float32)*0.4).reshape(self.N_STOCKS,self.N_STOCKS)\n",
        "#         cupy.fill_diagonal(self.Z_cov, 1)\n",
        "#         ############ new>\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return self.max_length\n",
        "        \n",
        "#     def __iter__(self):\n",
        "#         self.num = 0\n",
        "#         return self\n",
        "    \n",
        "#     def __next__(self):\n",
        "#         if self.num > self.max_length:\n",
        "#             raise StopIteration\n",
        "\n",
        "#         X = cupy.zeros((self.N_BATCH, 3 + self.N_STOCKS * 3), dtype=cupy.float32)\n",
        "#         Y = cupy.zeros(self.N_BATCH, dtype=cupy.float32)\n",
        "\n",
        "#         for i in range(self.N_BATCH): # for each batch\n",
        "#           self.S0 = cupy.random.rand(self.N_STOCKS, dtype=cupy.float32) * 200\n",
        "#           self.K = 110.0\n",
        "#           self.B = 100.0\n",
        "#           self.sigma = cupy.random.rand(self.N_STOCKS, dtype=cupy.float32) * 0.2\n",
        "#           self.mu = cupy.random.rand(self.N_STOCKS, dtype=cupy.float32) * 0.2\n",
        "#           self.r = 0.05\n",
        "#           self.s_curr = cupy.zeros(self.N_STOCKS, dtype=cupy.float32) # used to store s_curr in kernel\n",
        "\n",
        "#           ############ <new - add correlation between stocks\n",
        "#           all_normals = cupy.random.multivariate_normal(self.Z_mean, self.Z_cov, (self.N_PATHS, self.N_STEPS), dtype=cupy.float32)\n",
        "#           ############ new>\n",
        "          \n",
        "#           single_barrier_option[(self.number_of_blocks,), (self.number_of_threads,)](self.output, self.T, self.K, self.B, self.S0, \n",
        "#                                                                                     self.sigma, self.mu, self.r, all_normals, self.N_STEPS, self.N_PATHS, self.N_STOCKS, self.s_curr)\n",
        "#           Y[i] = self.output.mean()\n",
        "\n",
        "#           ############ <new - combine to get X matrix\n",
        "#           X[i,:] = cupy.array([self.K, self.B] + self.S0.tolist() +\n",
        "#                                 self.sigma.tolist() + self.mu.tolist() + [self.r], dtype=cupy.float32)\n",
        "#           ############ new>\n",
        "        \n",
        "#         self.num += 1\n",
        "#         return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "# ds = NumbaOptionDataSet(max_len=10, number_path=100, batch=2, seed=15)\n",
        "# for i in ds:\n",
        "#   print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2_89jOknwjH"
      },
      "source": [
        "### Model\n",
        "To map the option parameters to price, we use 6 layers of fully connected neural network with hidden dimension 512 as inspired by [this paper](https://arxiv.org/abs/1809.02233). Writing this DL price model into a file `model.py`:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cQt8PqinwjI"
      },
      "source": [
        "# %%writefile model.py\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import torch\n",
        "\n",
        "\n",
        "# class Net(nn.Module):\n",
        "\n",
        "#     def __init__(self, hidden=1024):\n",
        "#         super(Net, self).__init__()\n",
        "#         self.fc1 = nn.Linear(6, hidden)\n",
        "#         self.fc2 = nn.Linear(hidden, hidden)\n",
        "#         self.fc3 = nn.Linear(hidden, hidden)\n",
        "#         self.fc4 = nn.Linear(hidden, hidden)\n",
        "#         self.fc5 = nn.Linear(hidden, hidden)\n",
        "#         self.fc6 = nn.Linear(hidden, 1)\n",
        "#         self.register_buffer('norm',\n",
        "#                              torch.tensor([200.0,\n",
        "#                                            198.0,\n",
        "#                                            200.0,\n",
        "#                                            0.4,\n",
        "#                                            0.2,\n",
        "#                                            0.2,]))\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # normalize the parameter to range [0-1] \n",
        "#         x = x / self.norm\n",
        "#         x = F.elu(self.fc1(x))\n",
        "#         x = F.elu(self.fc2(x))\n",
        "#         x = F.elu(self.fc3(x))\n",
        "#         x = F.elu(self.fc4(x))\n",
        "#         x = F.elu(self.fc5(x))\n",
        "#         return self.fc6(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMHqzJycx8XH"
      },
      "source": [
        "### Modified Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTn7iJQryAIH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e7257b1-78f3-48b2-b339-532a76536b1f"
      },
      "source": [
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(18, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 1)\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([200.0, 198.0, 200.0, 0.4, 0.2, 0.2,\n",
        "                                           200.0, 198.0, 200.0, 0.4, 0.2, 0.2,\n",
        "                                           200.0, 198.0, 200.0, 0.4, 0.2, 0.2])) # don't use numpy here - will give error later\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Overwriting model.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSPRFqyznwjI"
      },
      "source": [
        "As we know the random parameters' scaling factors, the input parameters are first scaled back to a range of (0-1) by dividing them by (200.0, 198.0, 200.0, 0.4, 0.2, 0.2). Then they are projected 5 times to the hidden dimension of 512 after the `ELu` activation function. `ELu` is chosen because we need to compute the second order differentiation of the parameters. If use ReLu, the second order differentiation will always be zero. The last layer is a linear layer that maps the hidden dimension to the predicted option price. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM8J2liPnwjJ"
      },
      "source": [
        "For training, we use [Ignite](https://github.com/pytorch/ignite) which is a high-level library to train neural networks in PyTorch. We use `MSELoss` as the loss function, `Adam` as the optimizer and `CosineAnnealingScheduler` as the learning rate scheduler. The following code is feeding the random option data to the pricing model to train it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yACi4ge13_rd"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TyZT8_AH35M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76a83fed-6898-4308-ea65-8328c1aa5308"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-ignite\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cc/c3/f472843797b5ccbb2f0e806a6927f52c7c9522bfcea8e7e881d39258368b/pytorch_ignite-0.4.5-py3-none-any.whl (221kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 23.2MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 30.9MB/s eta 0:00:01\r\u001b[K     |████▍                           | 30kB 22.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 40kB 17.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 51kB 14.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 61kB 16.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 71kB 13.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 81kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 92kB 12.4MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 102kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 112kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 122kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 133kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 143kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 153kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 163kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 174kB 13.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 184kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 194kB 13.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 204kB 13.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 215kB 13.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 13.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4Ej82G8nwjJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67d671e7-f128-4889-a1e0-c6f7146ffb84"
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import NumbaOptionDataSet\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "# dataset = NumbaOptionDataSet(max_len=10000, number_path = 1024, batch=4800)\n",
        "dataset = NumbaOptionDataSet(max_len=100, number_path = 1024, batch=8, stocks=3)\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    y_pred = model(x)\n",
        "    loss = loss_fn(y_pred[:,0], y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 100\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value())\n",
        "        \n",
        "trainer.run(dataset, max_epochs=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss 327.84576416015625 average time 0.010986774429911748\n",
            "loss 108.00291442871094 average time 0.011062823829997797\n",
            "loss 70.28480529785156 average time 0.01092968322989691\n",
            "loss 45.730613708496094 average time 0.011106731770050829\n",
            "loss 45.661712646484375 average time 0.010958484200009479\n",
            "loss 104.50160217285156 average time 0.010962304540007607\n",
            "loss 30.883731842041016 average time 0.010955852659935771\n",
            "loss 89.94718933105469 average time 0.011002375419984674\n",
            "loss 163.6074981689453 average time 0.010955309050013967\n",
            "loss 87.1591796875 average time 0.011001553570094984\n",
            "loss 109.14079284667969 average time 0.01096114337002291\n",
            "loss 94.00898742675781 average time 0.010959611590033091\n",
            "loss 130.17599487304688 average time 0.010948034840012041\n",
            "loss 137.11334228515625 average time 0.010932822519989713\n",
            "loss 174.42276000976562 average time 0.010986606170017694\n",
            "loss 64.140869140625 average time 0.010921433250023255\n",
            "loss 53.408363342285156 average time 0.01094867451999562\n",
            "loss 103.68537139892578 average time 0.010983528780034248\n",
            "loss 144.80921936035156 average time 0.011025634650004577\n",
            "loss 241.1588134765625 average time 0.011001471179997679\n",
            "loss 87.14617919921875 average time 0.0109481366399541\n",
            "loss 135.0081787109375 average time 0.01104654279004535\n",
            "loss 62.50322723388672 average time 0.01092761074003647\n",
            "loss 49.270477294921875 average time 0.01092733107987442\n",
            "loss 35.61045837402344 average time 0.010974043759815685\n",
            "loss 71.134521484375 average time 0.010940972789885563\n",
            "loss 39.12145233154297 average time 0.010934756880069472\n",
            "loss 65.70960235595703 average time 0.010922849520065938\n",
            "loss 55.98759460449219 average time 0.01097595877994536\n",
            "loss 160.67166137695312 average time 0.01095293648999359\n",
            "loss 104.64446258544922 average time 0.010945326750079403\n",
            "loss 84.42320251464844 average time 0.010893520669924328\n",
            "loss 217.808837890625 average time 0.010979557090067829\n",
            "loss 143.39260864257812 average time 0.010897639460017672\n",
            "loss 144.06707763671875 average time 0.01096897767009068\n",
            "loss 135.74729919433594 average time 0.01102283805001207\n",
            "loss 109.35981750488281 average time 0.010947088289995008\n",
            "loss 149.98052978515625 average time 0.011066124620137998\n",
            "loss 52.32969284057617 average time 0.010984853099889733\n",
            "loss 105.89198303222656 average time 0.0109509943300327\n",
            "loss 77.90574645996094 average time 0.010915231050075818\n",
            "loss 93.60649108886719 average time 0.011026594009908876\n",
            "loss 127.63133239746094 average time 0.011006222779942619\n",
            "loss 146.53091430664062 average time 0.011046360120017197\n",
            "loss 99.8280258178711 average time 0.011026543199877779\n",
            "loss 54.12464904785156 average time 0.011077164309936051\n",
            "loss 107.12399291992188 average time 0.010946569379902939\n",
            "loss 57.55843734741211 average time 0.011029847420031729\n",
            "loss 33.418052673339844 average time 0.011055668460048764\n",
            "loss 25.012447357177734 average time 0.010977848659822485\n",
            "loss 15.967641830444336 average time 0.01096577074009474\n",
            "loss 12.627518653869629 average time 0.01099840678009059\n",
            "loss 10.8822021484375 average time 0.011059377439960372\n",
            "loss 2.4267749786376953 average time 0.010946909739923285\n",
            "loss 10.9285249710083 average time 0.01115023796006426\n",
            "loss 23.20450210571289 average time 0.010962996939997537\n",
            "loss 10.591901779174805 average time 0.010836417540031108\n",
            "loss 0.8699288964271545 average time 0.0109578781100754\n",
            "loss 15.202705383300781 average time 0.010971127319899097\n",
            "loss 3.9288504123687744 average time 0.010969851830031985\n",
            "loss 11.366386413574219 average time 0.011070818580046762\n",
            "loss 22.777976989746094 average time 0.010942636579984536\n",
            "loss 5.990419387817383 average time 0.010957163400016725\n",
            "loss 22.304555892944336 average time 0.010995613690010942\n",
            "loss 9.31589126586914 average time 0.010989957040073932\n",
            "loss 5.395129203796387 average time 0.010963316000015766\n",
            "loss 12.614006042480469 average time 0.011032456570083013\n",
            "loss 4.992496013641357 average time 0.010994135420096427\n",
            "loss 11.01785659790039 average time 0.01102534123991063\n",
            "loss 3.728600025177002 average time 0.011013587060006103\n",
            "loss 5.0648956298828125 average time 0.010969108150002285\n",
            "loss 7.745179176330566 average time 0.0110568443399643\n",
            "loss 3.0880937576293945 average time 0.010891270159900159\n",
            "loss 5.635597229003906 average time 0.010959642700036056\n",
            "loss 6.0787858963012695 average time 0.011001775480017385\n",
            "loss 9.412215232849121 average time 0.011006161520017486\n",
            "loss 1.7528529167175293 average time 0.011054865650003194\n",
            "loss 7.309576034545898 average time 0.011007607440042193\n",
            "loss 5.6199727058410645 average time 0.01099763724991135\n",
            "loss 5.583054542541504 average time 0.011095608770046965\n",
            "loss 4.4259934425354 average time 0.010981075940035225\n",
            "loss 8.131766319274902 average time 0.010946920739952475\n",
            "loss 6.112756252288818 average time 0.010955573760038534\n",
            "loss 11.311795234680176 average time 0.010982169399994746\n",
            "loss 6.355409622192383 average time 0.011167211570027575\n",
            "loss 4.462891578674316 average time 0.011046037060023082\n",
            "loss 27.551654815673828 average time 0.011026727479984401\n",
            "loss 5.547902584075928 average time 0.010977676860129577\n",
            "loss 10.834480285644531 average time 0.01094071751989759\n",
            "loss 7.7875518798828125 average time 0.010951596340073593\n",
            "loss 9.94194221496582 average time 0.011032047539993073\n",
            "loss 1.7790865898132324 average time 0.011013103679961205\n",
            "loss 5.772810935974121 average time 0.010979463399926316\n",
            "loss 9.073472023010254 average time 0.010967799319969345\n",
            "loss 5.354036331176758 average time 0.010997178400066332\n",
            "loss 5.36397647857666 average time 0.010985339769958954\n",
            "loss 9.2071533203125 average time 0.010997784750015853\n",
            "loss 10.756856918334961 average time 0.010947630440059584\n",
            "loss 6.427606582641602 average time 0.011030510499804223\n",
            "loss 6.302877426147461 average time 0.010934859970038815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "State:\n",
              "\titeration: 10000\n",
              "\tepoch: 100\n",
              "\tepoch_length: 100\n",
              "\tmax_epochs: 100\n",
              "\toutput: 6.302877426147461\n",
              "\tbatch: <class 'tuple'>\n",
              "\tmetrics: <class 'dict'>\n",
              "\tdataloader: <class 'cupy_dataset.NumbaOptionDataSet'>\n",
              "\tseed: <class 'NoneType'>\n",
              "\ttimes: <class 'dict'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU1EpGuInwjJ"
      },
      "source": [
        "The loss is keeping decreasing which means the pricing model can predict the option prices better. It takes about $12ms$ to compute one mini-batch in average, In the following sections, we will try to expore the full potentials of the GPU to accelerate the training."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehmhDw8BUtLi"
      },
      "source": [
        "### Inference and Greeks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uiro43mOU0Ro"
      },
      "source": [
        "We can load the model parameters and use it to do inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svlu6tGTRx1F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a0fc97-8e53-45b5-baca-9d0bbe9cc3a9"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "model(inputs.float())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[19.0310]], device='cuda:0', grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1Iy-9pWVRDO"
      },
      "source": [
        "One of the benefits of building a deep learning model is that the [Greeks](<https://en.wikipedia.org/wiki/Greeks_(finance)#First-order_Greeks>) can be easily computed. \n",
        "We just need to take advantage of the auto-grad feature in Pytorch. We can use `grad` function to compute the first order differentiation for parameters 'K, B, S0, sigma, mu, r'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytBZaYHKSnDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d52b2fcf-72d9-4d6a-db9c-8bc710c68502"
      },
      "source": [
        "inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs.float())\n",
        "x.backward()\n",
        "first_order_gradient = inputs.grad\n",
        "first_order_gradient"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1.9283e-01, -7.2950e-03,  2.0983e-01, -1.0698e+00,  1.0458e+01,\n",
              "         -1.7996e+01, -2.3495e-01,  7.0822e-04,  2.5572e-01,  2.9383e+00,\n",
              "          1.3567e+01, -1.7193e+01, -1.7394e-01,  5.1480e-03,  1.9505e-01,\n",
              "          6.9439e-01,  1.2520e+01, -1.2341e+01]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KeijaDDVZGd"
      },
      "source": [
        "Here we are going to plot the Delta graph:-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USh3qaADSYQp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "d3dd168e-f420-4c16-94f3-63360ef77525"
      },
      "source": [
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[110.0, 100.0, S, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    x.backward()\n",
        "    first_order_gradient = inputs.grad\n",
        "    return first_order_gradient[0][2]\n",
        "prices = np.arange(10, 300, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_delta(p).item())\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff4daccfd50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLO_5nEGVcEc"
      },
      "source": [
        "Calculating the second order derivative is easy in PyTorch too. We just need to apply the `grad` function twice. Use this mechanism, we can calculate the second order derivatives $\\frac{\\partial^2 P}{\\partial K \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial B \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial S_0^2}$, $\\frac{\\partial^2 P}{\\partial \\sigma \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial \\mu \\partial S_0}$, $\\frac{\\partial^2 P}{\\partial r \\partial S_0}$ in the following example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGzj7A3sThZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9928905-952f-4651-e8e3-32fcf46c96eb"
      },
      "source": [
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import Variable\n",
        "from torch.autograd import grad\n",
        "from torch import nn\n",
        "\n",
        "inputs = torch.tensor([[110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "inputs.requires_grad = True\n",
        "x = model(inputs)\n",
        "\n",
        "# instead of using loss.backward(), use torch.autograd.grad() to compute gradients\n",
        "# https://pytorch.org/docs/stable/autograd.html#torch.autograd.grad\n",
        "loss_grads = grad(x, inputs, create_graph=True)\n",
        "drv = grad(loss_grads[0][0][2], inputs)\n",
        "drv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[-3.8606e-03, -2.3980e-05,  4.0386e-03,  1.3327e-02,  3.1901e-01,\n",
              "          -4.2827e-01,  4.9752e-04, -1.9701e-04, -5.4056e-04,  9.5595e-03,\n",
              "          -4.2074e-02, -1.6962e-02,  2.7823e-04, -4.7445e-05, -3.2643e-04,\n",
              "          -1.9450e-03, -6.0234e-02,  3.2486e-03]], device='cuda:0'),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJbZYtvhVmSo"
      },
      "source": [
        "Gamma is the second order differenation of `S`. We can plot the the Gamma curve as a function of the stock price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JpQa3EJToA0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "8e7c3125-70d3-407d-bf1c-5c763e54370b"
      },
      "source": [
        "import pylab\n",
        "import numpy as np\n",
        "def compute_gamma(S):\n",
        "    inputs = torch.tensor([[110.0, 100.0, S, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "    inputs.requires_grad = True\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    loss_grads = grad(x, inputs, create_graph=True)\n",
        "    drv = grad(loss_grads[0][0][2], inputs)\n",
        "    return drv[0][0][2]\n",
        "\n",
        "prices = np.arange(10, 200, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    deltas.append(compute_gamma(p).item())\n",
        "fig2 = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Gamma')\n",
        "fig2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff4dae3aa10>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj7NlW6GVqSA"
      },
      "source": [
        "[Implied volatility](https://en.wikipedia.org/wiki/Implied_volatility) is the forecasted volatility of the underlying asset based on the quoted prices of the option. It is the reverse mapping of price to the option parameter given the model which is hard to do with the Monte Carlo simulation approach. But if we have the deep learning pricing model, it is an easy task. We can first plot the relationship between volatility and the option price"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yrCw5UNT07t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "3e3e27e0-ccdb-4290-fd22-933606a31f44"
      },
      "source": [
        "import pylab\n",
        "import numpy as np\n",
        "def compute_price(sigma):\n",
        "    inputs = torch.tensor([[110.0, 100.0, 120.0, sigma, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05,\n",
        "                                           110.0, 100.0, 120.0, 0.35, 0.1, 0.05]]).cuda()\n",
        "    x = model(inputs.float())\n",
        "    #x = model(inputs)\n",
        "    return x.item()\n",
        "sigmas = np.arange(0, 0.5, 0.1)\n",
        "prices = []\n",
        "for s in sigmas:\n",
        "    prices.append(compute_price(s))\n",
        "fig3 = pylab.plot(sigmas, prices)\n",
        "pylab.xlabel('Sigma')\n",
        "pylab.ylabel('Price')\n",
        "fig3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff4dacb9690>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU25Cj29VtCa"
      },
      "source": [
        "Given the prices `P`, the implied volatility is the root of the function `compute_price`. We can use bisection to find the root."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddHnwm_zUBYD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "62bd4834-4a16-4c1d-c963-c02dea2dc7db"
      },
      "source": [
        "def bisection_root(small, large, fun, target, EPS=1e-6):\n",
        "    if fun(large) - target < 0:\n",
        "        print('upper bound is too small')\n",
        "        return None\n",
        "    if fun(small) - target > 0:\n",
        "        print('lower bound is too large')\n",
        "        return None\n",
        "    while large - small > EPS:\n",
        "        mid = (large + small) / 2.0\n",
        "        if fun(mid) - target >= 0:\n",
        "            large = mid\n",
        "        else:\n",
        "            small = mid\n",
        "    mid = (large + small) / 2.0\n",
        "    return mid, abs(fun(mid) - target)\n",
        "quoted_price = 16.0\n",
        "sigma, err = bisection_root(0, 0.5, compute_price, quoted_price)\n",
        "print('implied volativity', sigma, 'error', err)     "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lower bound is too large\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-ade689496c71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mquoted_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbisection_root\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_price\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquoted_price\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'implied volativity'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
          ]
        }
      ]
    }
  ]
}