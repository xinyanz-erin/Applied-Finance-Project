{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Grid Test_Knock Out Call 1stock_Old Method",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Erin/24s_Grid_Test_Knock_Out_Call_1stock_Old_Method.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IYigDkiy0HU9"
      },
      "source": [
        "# import cupy\n",
        "# import jax\n",
        "# import jax.numpy as jnp\n",
        "# from jax import random\n",
        "# from jax import jit\n",
        "# import numpy as np\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# S_range = jnp.linspace(0.75, 1.25, 10)\n",
        "# K_range = jnp.linspace(0.75, 1.25, 8)\n",
        "# B_range = jnp.linspace(0.5, 1.0, 8)\n",
        "# sigma_range = jnp.linspace(0.15, 0.45, 4)\n",
        "# r_range = jnp.linspace(0.01, 0.04, 3)\n",
        "\n",
        "# print(S_range)\n",
        "# print(K_range)\n",
        "# print(B_range)\n",
        "# print(sigma_range)\n",
        "# print(r_range)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIQxpJqK6OZr"
      },
      "source": [
        "# import cupy\n",
        "# import jax\n",
        "# import jax.numpy as jnp\n",
        "# from jax import random\n",
        "# from jax import jit\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "#     stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "#     stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "#                             jax.ops.index[0],         # initialization of stock prices\n",
        "#                             initial_stocks)\n",
        "#     noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "#     sigma = jnp.diag(cov) ** 0.5\n",
        "#     dt = T / numsteps\n",
        "#     def time_step(t, val):\n",
        "#         dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "#         val = jax.ops.index_update(val,\n",
        "#                             jax.ops.index[t],\n",
        "#                             val[t-1] * dx)\n",
        "#         return val\n",
        "#     return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "# def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T): # down-and-out call\n",
        "#     return jnp.mean(jnp.maximum((1 - jnp.any(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2) < B, axis=1).astype(int))* \n",
        "#                                 (jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2))[:,-1]-K, 0) *\n",
        "#                     jnp.exp(-r[0] * T))\n",
        "\n",
        "# goptionvalueavg = jax.grad(optionvalueavg, argnums=1)\n",
        "\n",
        "# #################################################################### Adjust all parameters here (not inside class)\n",
        "# numstocks = 1\n",
        "# numsteps = 50\n",
        "# numpaths = 2000000\n",
        "\n",
        "# rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "# rng, key = jax.random.split(rng)\n",
        "# keys = jax.random.split(key, numpaths)\n",
        "\n",
        "# S_range = jnp.linspace(0.75, 1.25, 10)\n",
        "# K_range = jnp.linspace(0.75, 1.25, 8)\n",
        "# B_range = jnp.linspace(0.5, 1.0, 8)\n",
        "# sigma_range = jnp.linspace(0.15, 0.45, 4)\n",
        "# r_range = jnp.linspace(0.01, 0.04, 3)\n",
        "# T = 1.0\n",
        "\n",
        "# fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "# batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "# ####################################################################\n",
        "\n",
        "# call = []\n",
        "# count = 0\n",
        "\n",
        "# for S in S_range:\n",
        "#   for K in K_range:\n",
        "#     for B in B_range:\n",
        "#       for r in r_range:\n",
        "#         for sigma in sigma_range:    \n",
        "\n",
        "#           initial_stocks = jnp.array([S]*numstocks) # must be float\n",
        "#           r_tmp = jnp.array([r]*numstocks)\n",
        "#           drift = r_tmp\n",
        "#           cov = jnp.identity(numstocks)*sigma*sigma\n",
        "\n",
        "#           Knock_Out_Call_price = optionvalueavg(key, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T)\n",
        "#           Deltas = goptionvalueavg(keys, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T)\n",
        "#           call.append([T, K, B, S, sigma, r, r, Knock_Out_Call_price] + list(Deltas)) #T, K, B, S, sigma, mu, r, price, delta\n",
        "          \n",
        "#           count += 1\n",
        "#           print(count)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_OUtP8GUwj5"
      },
      "source": [
        "# Thedataset = pd.DataFrame(call)\n",
        "# Thedataset"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSQKnflf6peX"
      },
      "source": [
        "# save to csv\n",
        "# Thedataset.to_csv('Knock_Out_Call_1stock_MC_Datset_v3.csv', index=False, header=False)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RsPX_tEBGFc",
        "outputId": "47ee2756-3807-47fd-a416-b627f32160d1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "skGWSSsG8TGG",
        "outputId": "c849bbbc-719d-4658-ac71-0249c6ce99c1"
      },
      "source": [
        "# read csv\n",
        "import pandas as pd\n",
        "\n",
        "Thedataset = pd.read_csv('/content/drive/MyDrive/AFP/Save_Models/Knock_Out_Call_1stock_MC_Datset_v2.csv', header=None)\n",
        "Thedataset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.048298</td>\n",
              "      <td>0.555157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.077764</td>\n",
              "      <td>0.563845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.106536</td>\n",
              "      <td>0.572229</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.010</td>\n",
              "      <td>0.133061</td>\n",
              "      <td>0.569618</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.053998</td>\n",
              "      <td>0.594301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2395</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.025</td>\n",
              "      <td>0.199720</td>\n",
              "      <td>0.471407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2396</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.15</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.100027</td>\n",
              "      <td>0.631672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2397</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.144241</td>\n",
              "      <td>0.583131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2398</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.179728</td>\n",
              "      <td>0.529840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2399</th>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.25</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.206979</td>\n",
              "      <td>0.482881</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2400 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        0     1    2     3     4      5      6         7         8\n",
              "0     1.0  0.75  0.5  0.75  0.15  0.010  0.010  0.048298  0.555157\n",
              "1     1.0  0.75  0.5  0.75  0.25  0.010  0.010  0.077764  0.563845\n",
              "2     1.0  0.75  0.5  0.75  0.35  0.010  0.010  0.106536  0.572229\n",
              "3     1.0  0.75  0.5  0.75  0.45  0.010  0.010  0.133061  0.569618\n",
              "4     1.0  0.75  0.5  0.75  0.15  0.025  0.025  0.053998  0.594301\n",
              "...   ...   ...  ...   ...   ...    ...    ...       ...       ...\n",
              "2395  1.0  1.25  1.0  1.25  0.45  0.025  0.025  0.199720  0.471407\n",
              "2396  1.0  1.25  1.0  1.25  0.15  0.040  0.040  0.100027  0.631672\n",
              "2397  1.0  1.25  1.0  1.25  0.25  0.040  0.040  0.144241  0.583131\n",
              "2398  1.0  1.25  1.0  1.25  0.35  0.040  0.040  0.179728  0.529840\n",
              "2399  1.0  1.25  1.0  1.25  0.45  0.040  0.040  0.206979  0.482881\n",
              "\n",
              "[2400 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4HV-G44th",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92560130-85ac-4103-9ccb-510e2e838e88"
      },
      "source": [
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "import torch\n",
        "torch.set_printoptions(precision=6)\n",
        "\n",
        "Thedataset_X = Thedataset.iloc[:,:7]\n",
        "Thedataset_Y = Thedataset.iloc[:,7:]\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.X = cupy.array(Thedataset_X)\n",
        "        self.Y = cupy.array(Thedataset_Y)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(self.X.toDlpack()), from_dlpack(self.Y.toDlpack()))\n",
        "\n",
        "# print\n",
        "ds = OptionDataSet(max_len = 1)\n",
        "for i in ds:\n",
        "    print(i[0])\n",
        "    print(i[0].shape)\n",
        "    print(i[1])\n",
        "    print(i[1].shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.000000, 0.750000, 0.500000,  ..., 0.150000, 0.010000, 0.010000],\n",
            "        [1.000000, 0.750000, 0.500000,  ..., 0.250000, 0.010000, 0.010000],\n",
            "        [1.000000, 0.750000, 0.500000,  ..., 0.350000, 0.010000, 0.010000],\n",
            "        ...,\n",
            "        [1.000000, 1.250000, 1.000000,  ..., 0.250000, 0.040000, 0.040000],\n",
            "        [1.000000, 1.250000, 1.000000,  ..., 0.350000, 0.040000, 0.040000],\n",
            "        [1.000000, 1.250000, 1.000000,  ..., 0.450000, 0.040000, 0.040000]],\n",
            "       device='cuda:0', dtype=torch.float64)\n",
            "torch.Size([2400, 7])\n",
            "tensor([[0.048298, 0.555157],\n",
            "        [0.077764, 0.563845],\n",
            "        [0.106536, 0.572229],\n",
            "        ...,\n",
            "        [0.144241, 0.583131],\n",
            "        [0.179728, 0.529840],\n",
            "        [0.206979, 0.482881]], device='cuda:0', dtype=torch.float64)\n",
            "torch.Size([2400, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6JO9OBHdvv",
        "outputId": "35f3bcb7-6990-4408-da37-4ada8bf1bdeb"
      },
      "source": [
        "%%writefile model.py\n",
        "# version 1,2\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(7*1, 64) # remember to change this!\n",
        "        self.fc2 = nn.Linear(64, 128)\n",
        "        self.fc3 = nn.Linear(128, 256)\n",
        "        self.fc4 = nn.Linear(256, 128)\n",
        "        self.fc5 = nn.Linear(128, 64)\n",
        "        self.fc6 = nn.Linear(64, 2) # 2 outputs: price, delta\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1.0, 0.5, 0.5, 0.5, 0.3, 0.03, 0.03]*1)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, B, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = (x - torch.tensor([0.0, 0.75, 0.5, 0.75, 0.15, 0.01, 0.01]*1).cuda()) / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlXD80xPNVc6",
        "outputId": "7b4a2ab6-f71c-4e48-efac-3eaaa9f97324"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[K     |████████████████████████████████| 240 kB 8.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EeLVZiiaDS4y",
        "outputId": "e6bc5aea-b9d1-42e5-9577-83932d669fc8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3CyULkENYKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29509b76-547c-4e85-84af-aba68903d6ad"
      },
      "source": [
        "# version 2, 7\n",
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100) # Use max_len to adjust\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    # print(x)\n",
        "    # print(x.shape)\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    # print(y.shape)\n",
        "    y_pred = model(x.float())\n",
        "    # print(y_pred)\n",
        "    # print(y_pred.shape)\n",
        "\n",
        "    # def compute_deltas(x):\n",
        "    #   inputs = x.float()\n",
        "    #   inputs.requires_grad = True\n",
        "    #   first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "    #   return first_order_gradient[0][[3]]  # Now index 3 is stock price, not 2\n",
        "\n",
        "    # deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    # y_pred = torch.cat((y_pred, deltas), 1)\n",
        "    # # print(y_pred)\n",
        "    # # print(y_pred.shape)\n",
        "\n",
        "    loss_weight = torch.tensor([1, 1]).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)\n",
        "\n",
        "model_save_name = 'jax_knock_out_1stock_oldmethod_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: DeprecationWarning: /usr/local/lib/python3.7/dist-packages/ignite/contrib/handlers/param_scheduler.py has been moved to /ignite/handlers/param_scheduler.py and will be removed in version 0.6.0.\n",
            " Please refer to the documentation for more details.\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.08333194064285472 average time 0.005725788299997703 iter num 20\n",
            "loss 0.05712179895830713 average time 0.004136971099998732 iter num 40\n",
            "loss 0.05204247186460595 average time 0.003671258683333652 iter num 60\n",
            "loss 0.04973594408246232 average time 0.003353530287500206 iter num 80\n",
            "loss 0.04923369990896368 average time 0.0031559255999979996 iter num 100\n",
            "loss 0.03771402976351076 average time 0.0022203874500036137 iter num 20\n",
            "loss 0.023786935700031323 average time 0.002241980425006318 iter num 40\n",
            "loss 0.014988224002166178 average time 0.002282044533338497 iter num 60\n",
            "loss 0.012425631380599579 average time 0.002288597850004237 iter num 80\n",
            "loss 0.012052780008469967 average time 0.0023131122800043613 iter num 100\n",
            "loss 0.009873735900677211 average time 0.002392507650003495 iter num 20\n",
            "loss 0.009729694569271356 average time 0.0024146194750045424 iter num 40\n",
            "loss 0.009646977799162097 average time 0.002366333233335164 iter num 60\n",
            "loss 0.009621436732430913 average time 0.002392840637499205 iter num 80\n",
            "loss 0.009616021948401868 average time 0.002384769550000101 iter num 100\n",
            "loss 0.009513843038002734 average time 0.002226668050002445 iter num 20\n",
            "loss 0.00942320605092899 average time 0.002234569575006162 iter num 40\n",
            "loss 0.009361958198857906 average time 0.0022787567333371803 iter num 60\n",
            "loss 0.009333361255685721 average time 0.002338116637501031 iter num 80\n",
            "loss 0.009327226140526794 average time 0.002350002050000626 iter num 100\n",
            "loss 0.0092076238702453 average time 0.0022747941499943634 iter num 20\n",
            "loss 0.009097581943604903 average time 0.002353693949990543 iter num 40\n",
            "loss 0.009022081226370368 average time 0.002341786249992121 iter num 60\n",
            "loss 0.008986661450028613 average time 0.002370559699994601 iter num 80\n",
            "loss 0.008979066955056047 average time 0.0023709526199957053 iter num 100\n",
            "loss 0.008830574753763032 average time 0.002426653500003795 iter num 20\n",
            "loss 0.008691893514449931 average time 0.0023711333500003205 iter num 40\n",
            "loss 0.008595487570445764 average time 0.0023645320499989944 iter num 60\n",
            "loss 0.008549951855702904 average time 0.0023617501499991534 iter num 80\n",
            "loss 0.008540179470482096 average time 0.002364848360000451 iter num 100\n",
            "loss 0.008348147404645586 average time 0.002441729750003674 iter num 20\n",
            "loss 0.008165819739539443 average time 0.0024181971500041753 iter num 40\n",
            "loss 0.008037371261014564 average time 0.002390342116670278 iter num 60\n",
            "loss 0.007976294304174833 average time 0.0023675236500011465 iter num 80\n",
            "loss 0.007963178375217095 average time 0.002386393989999078 iter num 100\n",
            "loss 0.007704466046990711 average time 0.0023043083999993996 iter num 20\n",
            "loss 0.0074556126832787265 average time 0.0023070526750018417 iter num 40\n",
            "loss 0.0072787971213985605 average time 0.0023291653333359363 iter num 60\n",
            "loss 0.007194561399687813 average time 0.0023284128625029156 iter num 80\n",
            "loss 0.007176510376259885 average time 0.002349449000003574 iter num 100\n",
            "loss 0.006821670705525748 average time 0.002239352399993777 iter num 20\n",
            "loss 0.006482998382681051 average time 0.002278919900000176 iter num 40\n",
            "loss 0.006246958564143127 average time 0.0022979249333332065 iter num 60\n",
            "loss 0.006136898062787542 average time 0.0022900998624997724 iter num 80\n",
            "loss 0.006113639411557927 average time 0.002335241530002463 iter num 100\n",
            "loss 0.005672028702257518 average time 0.002268468750000352 iter num 20\n",
            "loss 0.005287804317501339 average time 0.002249552349996975 iter num 40\n",
            "loss 0.0050497412076153814 average time 0.002255987233329885 iter num 60\n",
            "loss 0.004948671679646362 average time 0.0022903649374967474 iter num 80\n",
            "loss 0.004928260779986383 average time 0.0023118987799978187 iter num 100\n",
            "loss 0.00457891834010803 average time 0.0023342374499975447 iter num 20\n",
            "loss 0.004340130428750494 average time 0.0023228268750003166 iter num 40\n",
            "loss 0.004218970858298786 average time 0.0023361622333349413 iter num 60\n",
            "loss 0.004171938508838374 average time 0.0023188767625008213 iter num 80\n",
            "loss 0.004162661176328534 average time 0.0023288613300024965 iter num 100\n",
            "loss 0.004005960887283747 average time 0.0022663941499985185 iter num 20\n",
            "loss 0.003893288597468108 average time 0.0022927624000004697 iter num 40\n",
            "loss 0.0038285986149170456 average time 0.0022801140500016952 iter num 60\n",
            "loss 0.00380117315847049 average time 0.0022608429875049297 iter num 80\n",
            "loss 0.0037955657604269895 average time 0.0022898448400036388 iter num 100\n",
            "loss 0.003694915518084196 average time 0.0024047513500050854 iter num 20\n",
            "loss 0.0036147390890499255 average time 0.0023490529500051595 iter num 40\n",
            "loss 0.0035661248718708268 average time 0.0023213735500036137 iter num 60\n",
            "loss 0.0035450536405114683 average time 0.002314715825001201 iter num 80\n",
            "loss 0.0035407097988543875 average time 0.0023295968500008256 iter num 100\n",
            "loss 0.0034616757327635196 average time 0.0023922491500002253 iter num 20\n",
            "loss 0.0033971709815581314 average time 0.002351802450003504 iter num 40\n",
            "loss 0.0033573891053016772 average time 0.0023266440833367595 iter num 60\n",
            "loss 0.0033399994877985587 average time 0.0023143561000026126 iter num 80\n",
            "loss 0.003336403364016201 average time 0.0023671664900024327 iter num 100\n",
            "loss 0.0032706563880998026 average time 0.0023836332999991328 iter num 20\n",
            "loss 0.003216630638896401 average time 0.0023092083750015035 iter num 40\n",
            "loss 0.0031832326846029566 average time 0.0022781760333354367 iter num 60\n",
            "loss 0.003168635587254612 average time 0.002295042450001716 iter num 80\n",
            "loss 0.003165617824763211 average time 0.0023372231800016154 iter num 100\n",
            "loss 0.0031105160658366706 average time 0.002307335450007031 iter num 20\n",
            "loss 0.003065392182655365 average time 0.002312896775003992 iter num 40\n",
            "loss 0.003037560859207232 average time 0.0022901426333343505 iter num 60\n",
            "loss 0.003025399770001435 average time 0.002279012574999939 iter num 80\n",
            "loss 0.0030228844384615236 average time 0.0022876307999990784 iter num 100\n",
            "loss 0.002976838057758311 average time 0.0023297320000068567 iter num 20\n",
            "loss 0.0029387314483469923 average time 0.002367063674998349 iter num 40\n",
            "loss 0.0029148332971614555 average time 0.0023908526999984283 iter num 60\n",
            "loss 0.0029042414099691065 average time 0.002380824849997509 iter num 80\n",
            "loss 0.002902035380280483 average time 0.002379752249999001 iter num 100\n",
            "loss 0.0028609791197727625 average time 0.0022761007500008644 iter num 20\n",
            "loss 0.0028256831444896865 average time 0.0023780332499981683 iter num 40\n",
            "loss 0.002802744323763246 average time 0.002349853433331835 iter num 60\n",
            "loss 0.0027923463280792636 average time 0.002316488524998306 iter num 80\n",
            "loss 0.0027901603099849018 average time 0.002328095049998069 iter num 100\n",
            "loss 0.0027487266177193617 average time 0.0023235754500007034 iter num 20\n",
            "loss 0.0027118255567501206 average time 0.0023203525500022693 iter num 40\n",
            "loss 0.0026871955559065277 average time 0.0022871439166692654 iter num 60\n",
            "loss 0.002675875278492357 average time 0.0022799736250014744 iter num 80\n",
            "loss 0.002673481897930877 average time 0.0023105839000021433 iter num 100\n",
            "loss 0.0026276524759727042 average time 0.002382118599993532 iter num 20\n",
            "loss 0.002585999159100313 average time 0.0023609454499933236 iter num 40\n",
            "loss 0.002557756455869709 average time 0.0023363200666636887 iter num 60\n",
            "loss 0.0025446544248698562 average time 0.0022997893124987456 iter num 80\n",
            "loss 0.0025418742829672364 average time 0.0023314667999972017 iter num 100\n",
            "loss 0.0024882617183743143 average time 0.002281586699990612 iter num 20\n",
            "loss 0.0024388042011145106 average time 0.002331598224992604 iter num 40\n",
            "loss 0.0024048810485883406 average time 0.002366874583330514 iter num 60\n",
            "loss 0.002389046704683732 average time 0.002363758037498087 iter num 80\n",
            "loss 0.0023856795312338207 average time 0.0023753465499981984 iter num 100\n",
            "loss 0.0023204616760592687 average time 0.002339358350005227 iter num 20\n",
            "loss 0.0022597978509034606 average time 0.00241700995000258 iter num 40\n",
            "loss 0.0022180043310618147 average time 0.002375692033335023 iter num 60\n",
            "loss 0.0021984786893061675 average time 0.002343276062502042 iter num 80\n",
            "loss 0.0021943284755539983 average time 0.0023443853100036448 iter num 100\n",
            "loss 0.0021141107763332063 average time 0.0024285958500001926 iter num 20\n",
            "loss 0.0020400555265204868 average time 0.0023547729500009496 iter num 40\n",
            "loss 0.0019896176228128065 average time 0.0023215844500024713 iter num 60\n",
            "loss 0.0019662923465664428 average time 0.002294484275004294 iter num 80\n",
            "loss 0.00196136172798713 average time 0.002308714290002172 iter num 100\n",
            "loss 0.0018673222534113898 average time 0.002269243499995355 iter num 20\n",
            "loss 0.0017834075931760162 average time 0.002259666674999039 iter num 40\n",
            "loss 0.0017283030894342194 average time 0.0022622625166652216 iter num 60\n",
            "loss 0.0017034606744208286 average time 0.0022880182874999377 iter num 80\n",
            "loss 0.0016982703686522038 average time 0.002293872299999862 iter num 100\n",
            "loss 0.0016016780141977739 average time 0.002253145300002757 iter num 20\n",
            "loss 0.0015197492473980978 average time 0.002257452975003105 iter num 40\n",
            "loss 0.0014681779202935234 average time 0.0023018811333344047 iter num 60\n",
            "loss 0.0014454788487971153 average time 0.002284111137498712 iter num 80\n",
            "loss 0.001440781317032348 average time 0.002313758289996599 iter num 100\n",
            "loss 0.001354839749619686 average time 0.0027233226500044338 iter num 20\n",
            "loss 0.001284037374503104 average time 0.002526696925004046 iter num 40\n",
            "loss 0.001240236249802165 average time 0.0024884952666686406 iter num 60\n",
            "loss 0.0012210785387106239 average time 0.002502137925000625 iter num 80\n",
            "loss 0.0012171207019143102 average time 0.002463350260001107 iter num 100\n",
            "loss 0.0011446143966445759 average time 0.0022739601499949915 iter num 20\n",
            "loss 0.0010841477393977307 average time 0.002279418824996071 iter num 40\n",
            "loss 0.0010460317516487556 average time 0.0023252150166664857 iter num 60\n",
            "loss 0.0010291368336969545 average time 0.002346010000000831 iter num 80\n",
            "loss 0.0010256264664976877 average time 0.0023446061800012786 iter num 100\n",
            "loss 0.0009606566586797626 average time 0.0022784911500025374 iter num 20\n",
            "loss 0.0009056084803846459 average time 0.002283140525000249 iter num 40\n",
            "loss 0.0008707177442871073 average time 0.002290889316666759 iter num 60\n",
            "loss 0.0008552602652473222 average time 0.002309069049997703 iter num 80\n",
            "loss 0.0008520526632492038 average time 0.002305032369997093 iter num 100\n",
            "loss 0.0007929571404377321 average time 0.002418700300012233 iter num 20\n",
            "loss 0.0007434785324358898 average time 0.002450104175009926 iter num 40\n",
            "loss 0.0007124986968195745 average time 0.00241167648333942 iter num 60\n",
            "loss 0.0006988845224410971 average time 0.0024103958125046175 iter num 80\n",
            "loss 0.0006960692090121536 average time 0.0023930261400045083 iter num 100\n",
            "loss 0.0006445743894729971 average time 0.0023267578000059075 iter num 20\n",
            "loss 0.0006021122086218063 average time 0.0023351875500040365 iter num 40\n",
            "loss 0.0005758774204528408 average time 0.0023103390333356327 iter num 60\n",
            "loss 0.000564442266688987 average time 0.0023471816375021603 iter num 80\n",
            "loss 0.0005620859842497214 average time 0.002338428490001547 iter num 100\n",
            "loss 0.0005237552069594421 average time 0.0022730835499970682 iter num 20\n",
            "loss 0.00048563235923838654 average time 0.002303736550003066 iter num 40\n",
            "loss 0.0004652513069688142 average time 0.0023117716333340846 iter num 60\n",
            "loss 0.0004564435607951789 average time 0.002328971112499545 iter num 80\n",
            "loss 0.00045463969223958055 average time 0.002323909670002422 iter num 100\n",
            "loss 0.00042246783636420586 average time 0.0023107445999983158 iter num 20\n",
            "loss 0.00039666481312386427 average time 0.0022925207000000112 iter num 40\n",
            "loss 0.00038128028326573835 average time 0.0022782473166662004 iter num 60\n",
            "loss 0.00037470906329603023 average time 0.0023068541375003805 iter num 80\n",
            "loss 0.00037336502638951195 average time 0.0023342882100013183 iter num 100\n",
            "loss 0.000357184589937355 average time 0.002275232749997258 iter num 20\n",
            "loss 0.00033213772066454067 average time 0.0023145458499968185 iter num 40\n",
            "loss 0.00032141819272880933 average time 0.0023205235833311613 iter num 60\n",
            "loss 0.00031687451536942837 average time 0.002340651987497466 iter num 80\n",
            "loss 0.0003159499580637623 average time 0.002333664679999288 iter num 100\n",
            "loss 0.0002993787949206574 average time 0.002254324799986307 iter num 20\n",
            "loss 0.0002862370630695062 average time 0.002266619649994084 iter num 40\n",
            "loss 0.00027834945466824815 average time 0.0023453238666642545 iter num 60\n",
            "loss 0.0002749622119441874 average time 0.0024002340999984993 iter num 80\n",
            "loss 0.00027426755223243634 average time 0.002397463199996537 iter num 100\n",
            "loss 0.00026173954293387606 average time 0.002373501199997463 iter num 20\n",
            "loss 0.00025167064387865857 average time 0.0023505937000024347 iter num 40\n",
            "loss 0.00024553685801990483 average time 0.0023906802166682914 iter num 60\n",
            "loss 0.00024287407499751646 average time 0.002400032712499467 iter num 80\n",
            "loss 0.000242325244422601 average time 0.002381002100000842 iter num 100\n",
            "loss 0.0002405951997495097 average time 0.0023809136999972226 iter num 20\n",
            "loss 0.0002251541327249761 average time 0.0023294871249959215 iter num 40\n",
            "loss 0.00021961181971114681 average time 0.0023256564499964344 iter num 60\n",
            "loss 0.00021747313915111027 average time 0.0023364406499965184 iter num 80\n",
            "loss 0.00021702805846678168 average time 0.002318218419997038 iter num 100\n",
            "loss 0.000210233664368753 average time 0.0022056695499912847 iter num 20\n",
            "loss 0.00020286497224484868 average time 0.0022556087999930697 iter num 40\n",
            "loss 0.00019868220892857398 average time 0.002309214449995996 iter num 60\n",
            "loss 0.0001968835049086253 average time 0.0023032581749966143 iter num 80\n",
            "loss 0.00019650798601154317 average time 0.0023021946699964247 iter num 100\n",
            "loss 0.00018954035175044307 average time 0.002288219900000854 iter num 20\n",
            "loss 0.00018357824325320628 average time 0.0023362580999986447 iter num 40\n",
            "loss 0.0001797531147151668 average time 0.002312026116665796 iter num 60\n",
            "loss 0.00017804027269579183 average time 0.0023185824374998276 iter num 80\n",
            "loss 0.00017768253364921848 average time 0.0023059329899996327 iter num 100\n",
            "loss 0.00017100625648222033 average time 0.002360558500001275 iter num 20\n",
            "loss 0.00016528715607212565 average time 0.002365859975002138 iter num 40\n",
            "loss 0.00016164534860020136 average time 0.0023326581666661167 iter num 60\n",
            "loss 0.00016002993925105636 average time 0.00234052935000193 iter num 80\n",
            "loss 0.00015969426292634112 average time 0.0023272649400007594 iter num 100\n",
            "loss 0.0001606669787692538 average time 0.002269269400005669 iter num 20\n",
            "loss 0.0001486577887574456 average time 0.002313860225005726 iter num 40\n",
            "loss 0.00014531354414015985 average time 0.002294200500003285 iter num 60\n",
            "loss 0.00014388841979644915 average time 0.0023106849750035964 iter num 80\n",
            "loss 0.00014359801877516606 average time 0.0023091821900021615 iter num 100\n",
            "loss 0.00013935322173182666 average time 0.0022961546499999487 iter num 20\n",
            "loss 0.0001354280485701987 average time 0.002288304450000567 iter num 40\n",
            "loss 0.00013270245372713546 average time 0.002341723633335846 iter num 60\n",
            "loss 0.00013162090330244195 average time 0.002382549450000937 iter num 80\n",
            "loss 0.0001313956106635886 average time 0.0023713175900019223 iter num 100\n",
            "loss 0.00012740574338276686 average time 0.0022489194499968335 iter num 20\n",
            "loss 0.0001240006791576838 average time 0.002300427824999929 iter num 40\n",
            "loss 0.0001218517100223445 average time 0.0022829621666649778 iter num 60\n",
            "loss 0.00012089917812916862 average time 0.0022974502624983017 iter num 80\n",
            "loss 0.00012070113294408832 average time 0.0022992416699980822 iter num 100\n",
            "loss 0.00011703859807248187 average time 0.002305507049999278 iter num 20\n",
            "loss 0.00011395011859533588 average time 0.0023992553500036705 iter num 40\n",
            "loss 0.00011199847538767155 average time 0.0023552365833372354 iter num 60\n",
            "loss 0.00011113439677773795 average time 0.002342272600001394 iter num 80\n",
            "loss 0.00011095484264589223 average time 0.002337897420002264 iter num 100\n",
            "loss 0.00010763840559348407 average time 0.002388286150008412 iter num 20\n",
            "loss 0.00010484841978129569 average time 0.002394843425005888 iter num 40\n",
            "loss 0.00010308948534746007 average time 0.002353581433336179 iter num 60\n",
            "loss 0.00010231198909077747 average time 0.0023432621750025364 iter num 80\n",
            "loss 0.00010215058766094644 average time 0.002317896940000992 iter num 100\n",
            "loss 9.917443279170255e-05 average time 0.0022539090000122997 iter num 20\n",
            "loss 9.668113254887273e-05 average time 0.0022521474750050174 iter num 40\n",
            "loss 9.511482330216696e-05 average time 0.002234646033337147 iter num 60\n",
            "loss 9.442392803170556e-05 average time 0.002249459800000864 iter num 80\n",
            "loss 9.428060625974809e-05 average time 0.002275495570000885 iter num 100\n",
            "loss 9.164177950275428e-05 average time 0.0021886969500087617 iter num 20\n",
            "loss 8.943736358233524e-05 average time 0.002295597375004377 iter num 40\n",
            "loss 8.805571441370157e-05 average time 0.00235668215000544 iter num 60\n",
            "loss 8.744708832008701e-05 average time 0.002357449612505036 iter num 80\n",
            "loss 8.732090862654069e-05 average time 0.0023388881100044044 iter num 100\n",
            "loss 0.00012359176855497781 average time 0.00234676924999917 iter num 20\n",
            "loss 8.458522916540999e-05 average time 0.0023126527749994354 iter num 40\n",
            "loss 8.226404401079629e-05 average time 0.002293526616665531 iter num 60\n",
            "loss 8.171785253598364e-05 average time 0.002322657562499586 iter num 80\n",
            "loss 8.161816187098517e-05 average time 0.0023063142000006565 iter num 100\n",
            "loss 7.987093548039457e-05 average time 0.0022798388500035573 iter num 20\n",
            "loss 7.825447529702607e-05 average time 0.00235532964999976 iter num 40\n",
            "loss 7.728714212985806e-05 average time 0.002369322200000094 iter num 60\n",
            "loss 7.686011979925444e-05 average time 0.0023645691124990265 iter num 80\n",
            "loss 7.677146863028342e-05 average time 0.002361869140000863 iter num 100\n",
            "loss 7.513784174772363e-05 average time 0.002347260399997708 iter num 20\n",
            "loss 7.376302734250199e-05 average time 0.0023492837999995685 iter num 40\n",
            "loss 7.289798265393093e-05 average time 0.0023249266333332723 iter num 60\n",
            "loss 7.251552189442264e-05 average time 0.0023425410750007813 iter num 80\n",
            "loss 7.243612722712221e-05 average time 0.0023268246400004956 iter num 100\n",
            "loss 0.00012027405580263521 average time 0.0023066886000037813 iter num 20\n",
            "loss 7.384266979878706e-05 average time 0.0023572046249995537 iter num 40\n",
            "loss 6.93493336104037e-05 average time 0.002369030516664831 iter num 60\n",
            "loss 6.898606221918157e-05 average time 0.002441440412500384 iter num 80\n",
            "loss 6.891845727802341e-05 average time 0.002452438740000957 iter num 100\n",
            "loss 6.776766813002496e-05 average time 0.0024072913499935565 iter num 20\n",
            "loss 6.6788621258725e-05 average time 0.00244565427498884 iter num 40\n",
            "loss 6.616379828515763e-05 average time 0.0024709336999914435 iter num 60\n",
            "loss 6.588700683259305e-05 average time 0.002456861824994405 iter num 80\n",
            "loss 6.582935480594112e-05 average time 0.002440258199994787 iter num 100\n",
            "loss 6.476040215312777e-05 average time 0.002490730549993714 iter num 20\n",
            "loss 6.385184030536431e-05 average time 0.002396601024996414 iter num 40\n",
            "loss 6.327316332633663e-05 average time 0.0024724657166662685 iter num 60\n",
            "loss 6.30154869177641e-05 average time 0.0024319879749974405 iter num 80\n",
            "loss 6.296181979159231e-05 average time 0.002398227009997527 iter num 100\n",
            "loss 6.196494108531862e-05 average time 0.0022999012999974865 iter num 20\n",
            "loss 6.111538761319652e-05 average time 0.0022923082749997546 iter num 40\n",
            "loss 6.057345077861476e-05 average time 0.0023154500166668868 iter num 60\n",
            "loss 6.033186515038986e-05 average time 0.002312146137499127 iter num 80\n",
            "loss 6.028151205092404e-05 average time 0.0022982244899992566 iter num 100\n",
            "loss 6.302240255369466e-05 average time 0.0022644676999988176 iter num 20\n",
            "loss 5.8828590558765816e-05 average time 0.0022431678250015353 iter num 40\n",
            "loss 5.812271136095249e-05 average time 0.0023835281499979526 iter num 60\n",
            "loss 5.7880424124454505e-05 average time 0.0024025550374972226 iter num 80\n",
            "loss 5.78339188948276e-05 average time 0.0024046708299988494 iter num 100\n",
            "loss 0.00013658968508759262 average time 0.0024343302499858057 iter num 20\n",
            "loss 6.293753309010962e-05 average time 0.0024053763499864546 iter num 40\n",
            "loss 5.675757561947016e-05 average time 0.00248235741665989 iter num 60\n",
            "loss 5.616848711454518e-05 average time 0.0024515069499948085 iter num 80\n",
            "loss 5.613037330003973e-05 average time 0.002421656519997555 iter num 100\n",
            "loss 5.552592509695524e-05 average time 0.0024095880000089666 iter num 20\n",
            "loss 5.499849989462273e-05 average time 0.002316595475006977 iter num 40\n",
            "loss 5.466130642529799e-05 average time 0.002369734900001201 iter num 60\n",
            "loss 5.450989633970012e-05 average time 0.002369592962500633 iter num 80\n",
            "loss 5.447827733602558e-05 average time 0.0023722333699993216 iter num 100\n",
            "loss 5.388714204044006e-05 average time 0.002171558899993897 iter num 20\n",
            "loss 5.3376786907432524e-05 average time 0.002181250224995779 iter num 40\n",
            "loss 5.3047248024400675e-05 average time 0.002231096199995856 iter num 60\n",
            "loss 5.289924749779677e-05 average time 0.00224576514999697 iter num 80\n",
            "loss 5.2868345966141405e-05 average time 0.0022388392899955535 iter num 100\n",
            "loss 5.228934491225113e-05 average time 0.0022334248499987553 iter num 20\n",
            "loss 5.17888097247467e-05 average time 0.002294728100000043 iter num 40\n",
            "loss 5.146528759883129e-05 average time 0.0023582996166680915 iter num 60\n",
            "loss 5.131994928092944e-05 average time 0.00244709830000005 iter num 80\n",
            "loss 5.1289534780194205e-05 average time 0.002450544420001961 iter num 100\n",
            "loss 5.072047107524201e-05 average time 0.002378000199990993 iter num 20\n",
            "loss 5.022822669783518e-05 average time 0.0024219906499979515 iter num 40\n",
            "loss 4.9909792671144055e-05 average time 0.0023907192166698604 iter num 60\n",
            "loss 4.976668776374462e-05 average time 0.0023883439500018257 iter num 80\n",
            "loss 4.973677985950279e-05 average time 0.0023689605300018 iter num 100\n",
            "loss 4.917620432548438e-05 average time 0.0022803678499997205 iter num 20\n",
            "loss 4.869088080614293e-05 average time 0.002315789274999247 iter num 40\n",
            "loss 4.837679365815364e-05 average time 0.0023616214500018864 iter num 60\n",
            "loss 4.823558885670711e-05 average time 0.0023513715875019157 iter num 80\n",
            "loss 4.8206002964662104e-05 average time 0.0023392298600009554 iter num 100\n",
            "loss 4.765259100783343e-05 average time 0.0022720629499957566 iter num 20\n",
            "loss 4.717322585740443e-05 average time 0.0023341758000015034 iter num 40\n",
            "loss 4.686283253620363e-05 average time 0.002342559666665996 iter num 60\n",
            "loss 4.6723239562664465e-05 average time 0.002343033275001005 iter num 80\n",
            "loss 4.66940342880844e-05 average time 0.0023447178700030237 iter num 100\n",
            "loss 4.614692571047673e-05 average time 0.0022536951000034834 iter num 20\n",
            "loss 4.5672731287417834e-05 average time 0.002316743475000749 iter num 40\n",
            "loss 4.5365589346730025e-05 average time 0.002307172966668721 iter num 60\n",
            "loss 4.522742170168889e-05 average time 0.002301519437499877 iter num 80\n",
            "loss 4.5198500630670305e-05 average time 0.002326005699999882 iter num 100\n",
            "loss 4.466055350387475e-05 average time 0.0022236417499925665 iter num 20\n",
            "loss 4.418668461545002e-05 average time 0.0023427936749968125 iter num 40\n",
            "loss 4.3881921172271636e-05 average time 0.002339885483328885 iter num 60\n",
            "loss 4.374482492368703e-05 average time 0.0023599493874975506 iter num 80\n",
            "loss 4.371613490135561e-05 average time 0.0023536261999976206 iter num 100\n",
            "loss 9.012048357487202e-05 average time 0.0022621614999906114 iter num 20\n",
            "loss 4.726571080140176e-05 average time 0.0023303247249941705 iter num 40\n",
            "loss 4.269173648380217e-05 average time 0.0023249451833284715 iter num 60\n",
            "loss 4.2503001994891675e-05 average time 0.002356286662497098 iter num 80\n",
            "loss 4.247887624460212e-05 average time 0.0023621340099998635 iter num 100\n",
            "loss 4.2041804182608715e-05 average time 0.00232356525000057 iter num 20\n",
            "loss 4.166101655505864e-05 average time 0.002350553175006098 iter num 40\n",
            "loss 4.1414118565259004e-05 average time 0.0023344782833381334 iter num 60\n",
            "loss 4.130285848318183e-05 average time 0.002319218062503836 iter num 80\n",
            "loss 4.127956488303612e-05 average time 0.002323275100001183 iter num 100\n",
            "loss 4.084208651222126e-05 average time 0.0023078738999970485 iter num 20\n",
            "loss 4.046134218750926e-05 average time 0.002331567775001986 iter num 40\n",
            "loss 4.021382664936327e-05 average time 0.002323065266668323 iter num 60\n",
            "loss 4.010220365244517e-05 average time 0.002315518375002057 iter num 80\n",
            "loss 4.007883407008219e-05 average time 0.0023110764800014748 iter num 100\n",
            "loss 3.963988892051011e-05 average time 0.0021943049499867583 iter num 20\n",
            "loss 3.925776061054832e-05 average time 0.002316290324995407 iter num 40\n",
            "loss 3.900926492073455e-05 average time 0.0023210750666644723 iter num 60\n",
            "loss 3.8897234131302904e-05 average time 0.002306049474999838 iter num 80\n",
            "loss 3.8873752732849615e-05 average time 0.002339734480002562 iter num 100\n",
            "loss 3.8454089191291256e-05 average time 0.002331865900015373 iter num 20\n",
            "loss 3.80511996093118e-05 average time 0.0023745654000094873 iter num 40\n",
            "loss 3.780050044862939e-05 average time 0.002387386566671997 iter num 60\n",
            "loss 3.7688015958097544e-05 average time 0.0023878165000063233 iter num 80\n",
            "loss 3.76644815734472e-05 average time 0.0024043973400068807 iter num 100\n",
            "loss 0.00019647748980860955 average time 0.0023600637000015467 iter num 20\n",
            "loss 3.720636124751342e-05 average time 0.002451168525000469 iter num 40\n",
            "loss 3.782168023818713e-05 average time 0.0024388074499986107 iter num 60\n",
            "loss 3.685298214659802e-05 average time 0.0024419679624983815 iter num 80\n",
            "loss 3.680762186108205e-05 average time 0.0024222920099998646 iter num 100\n",
            "loss 3.651235856782295e-05 average time 0.002247795499994254 iter num 20\n",
            "loss 3.6196655362502965e-05 average time 0.002312939150000659 iter num 40\n",
            "loss 3.6005979001314564e-05 average time 0.002299579150002273 iter num 60\n",
            "loss 3.59220829168537e-05 average time 0.0022965788375017837 iter num 80\n",
            "loss 3.590452462880233e-05 average time 0.002297505630000387 iter num 100\n",
            "loss 3.557526073243964e-05 average time 0.002220390449997467 iter num 20\n",
            "loss 3.528792352850652e-05 average time 0.0022981577249950647 iter num 40\n",
            "loss 3.510062917305358e-05 average time 0.0023651536833294057 iter num 60\n",
            "loss 3.5016061007737915e-05 average time 0.002341162512496453 iter num 80\n",
            "loss 3.499830315588623e-05 average time 0.0023424896799963337 iter num 100\n",
            "loss 3.46648569963176e-05 average time 0.0025578145999958224 iter num 20\n",
            "loss 3.4373648133812e-05 average time 0.0024366679749945773 iter num 40\n",
            "loss 3.418375525054879e-05 average time 0.002434588399994671 iter num 60\n",
            "loss 3.409796789721844e-05 average time 0.002379128612496828 iter num 80\n",
            "loss 3.407997082822374e-05 average time 0.0023663393799961342 iter num 100\n",
            "loss 3.374178007643103e-05 average time 0.002513185000003659 iter num 20\n",
            "loss 3.3446340879415716e-05 average time 0.0023898314750056215 iter num 40\n",
            "loss 3.325365058927891e-05 average time 0.0023524092000059226 iter num 60\n",
            "loss 3.3166637040407595e-05 average time 0.0023352670250012864 iter num 80\n",
            "loss 3.314839917686235e-05 average time 0.002338463390001948 iter num 100\n",
            "loss 3.280522867527343e-05 average time 0.0024357826999988675 iter num 20\n",
            "loss 3.25054701383472e-05 average time 0.0023494633499979043 iter num 40\n",
            "loss 3.231000360810047e-05 average time 0.002332031833330461 iter num 60\n",
            "loss 3.222170026349587e-05 average time 0.0023368710499987342 iter num 80\n",
            "loss 3.220320113088462e-05 average time 0.0023248327299967286 iter num 100\n",
            "loss 3.185512943858993e-05 average time 0.002463221900003987 iter num 20\n",
            "loss 3.1551206677795426e-05 average time 0.002439679474996126 iter num 40\n",
            "loss 3.1353076549274965e-05 average time 0.0023800591166623993 iter num 60\n",
            "loss 3.1263619907165987e-05 average time 0.002375109787494978 iter num 80\n",
            "loss 3.1244858574022365e-05 average time 0.0023701714799960884 iter num 100\n",
            "loss 3.089290162181349e-05 average time 0.002567188849991453 iter num 20\n",
            "loss 3.058446634524666e-05 average time 0.0024560245999950326 iter num 40\n",
            "loss 3.0383781865629596e-05 average time 0.0024281610499987966 iter num 60\n",
            "loss 3.0293197668097127e-05 average time 0.0023995730624974954 iter num 80\n",
            "loss 3.0274216291592267e-05 average time 0.002377170829997226 iter num 100\n",
            "loss 9.146208758761483e-05 average time 0.002493406199999981 iter num 20\n",
            "loss 3.150812804406984e-05 average time 0.0024009622999983547 iter num 40\n",
            "loss 2.9582721288007802e-05 average time 0.002371477549997773 iter num 60\n",
            "loss 2.9437296011543205e-05 average time 0.0023606444499982616 iter num 80\n",
            "loss 2.9417605121949713e-05 average time 0.0023460400799973514 iter num 100\n",
            "loss 2.9124393886602155e-05 average time 0.0024108475499986072 iter num 20\n",
            "loss 2.8844876412265708e-05 average time 0.0023413204749957116 iter num 40\n",
            "loss 2.8654840427337885e-05 average time 0.0023213074166648084 iter num 60\n",
            "loss 2.8574514229310312e-05 average time 0.0023190912874987645 iter num 80\n",
            "loss 2.8557627829077387e-05 average time 0.0022992869899979953 iter num 100\n",
            "loss 3.2979794660330056e-05 average time 0.0024399767000005566 iter num 20\n",
            "loss 2.8157273467392755e-05 average time 0.0023867173000027718 iter num 40\n",
            "loss 2.7801569836915074e-05 average time 0.002348364899999448 iter num 60\n",
            "loss 2.7712640843062882e-05 average time 0.0023327833000003294 iter num 80\n",
            "loss 2.7695729175612243e-05 average time 0.0023372831999995468 iter num 100\n",
            "loss 6.0450206574502626e-05 average time 0.002487948149993713 iter num 20\n",
            "loss 3.169550714238712e-05 average time 0.002422430799997244 iter num 40\n",
            "loss 2.751444970391134e-05 average time 0.00236882694999944 iter num 60\n",
            "loss 2.7153106290409297e-05 average time 0.002367142837498193 iter num 80\n",
            "loss 2.712701542318082e-05 average time 0.0023520863399994598 iter num 100\n",
            "loss 2.6899091742185373e-05 average time 0.002565699900000595 iter num 20\n",
            "loss 2.6659100750829903e-05 average time 0.0024612693250006144 iter num 40\n",
            "loss 2.6515822048414755e-05 average time 0.0024176584833355717 iter num 60\n",
            "loss 2.645188495915667e-05 average time 0.002409427125001429 iter num 80\n",
            "loss 2.6438534931411673e-05 average time 0.002387367029999723 iter num 100\n",
            "loss 2.618714759108918e-05 average time 0.0023835466500031544 iter num 20\n",
            "loss 2.596755464015778e-05 average time 0.0023250533500004168 iter num 40\n",
            "loss 2.5824320280880033e-05 average time 0.002341947066664337 iter num 60\n",
            "loss 2.5759610498534255e-05 average time 0.0024092838499989 iter num 80\n",
            "loss 2.5746026876332947e-05 average time 0.0023941996099995323 iter num 100\n",
            "loss 2.5490777542860608e-05 average time 0.002427473249994705 iter num 20\n",
            "loss 2.526775132599111e-05 average time 0.0023475885249951032 iter num 40\n",
            "loss 2.5122270362593073e-05 average time 0.0022989325333298894 iter num 60\n",
            "loss 2.505654054088902e-05 average time 0.0022763421124992076 iter num 80\n",
            "loss 2.5042782199154252e-05 average time 0.0023029804599985935 iter num 100\n",
            "loss 2.4783600907707287e-05 average time 0.0023445970999972587 iter num 20\n",
            "loss 2.4557296636238948e-05 average time 0.0023039887749945363 iter num 40\n",
            "loss 2.4409756499164225e-05 average time 0.0024020648666635224 iter num 60\n",
            "loss 2.434310727137599e-05 average time 0.002425043762500678 iter num 80\n",
            "loss 2.4329136065905813e-05 average time 0.0024133410699988646 iter num 100\n",
            "loss 2.4066558384519744e-05 average time 0.0023380649500069238 iter num 20\n",
            "loss 2.3837397195225473e-05 average time 0.002367653075006615 iter num 40\n",
            "loss 2.3688044695605748e-05 average time 0.0024019674333383514 iter num 60\n",
            "loss 2.362062261224667e-05 average time 0.0023675977625032376 iter num 80\n",
            "loss 2.3606499450029004e-05 average time 0.0023812649500013095 iter num 100\n",
            "loss 2.3340905698903946e-05 average time 0.0021756451499982178 iter num 20\n",
            "loss 2.310929745265665e-05 average time 0.002216009774997474 iter num 40\n",
            "loss 2.29584256430021e-05 average time 0.0022592076833319653 iter num 60\n",
            "loss 2.289032315084914e-05 average time 0.0022864055749984404 iter num 80\n",
            "loss 2.2876076687340484e-05 average time 0.0023133980399984468 iter num 100\n",
            "loss 2.2678954991253203e-05 average time 0.0023032326000020477 iter num 20\n",
            "loss 2.23762810989205e-05 average time 0.0022886646499998163 iter num 40\n",
            "loss 2.2223166366365244e-05 average time 0.002360048666667088 iter num 60\n",
            "loss 2.215431126871763e-05 average time 0.002356447262501149 iter num 80\n",
            "loss 2.213995585844075e-05 average time 0.002377149670000449 iter num 100\n",
            "loss 0.00011526764879979552 average time 0.0023972196000045186 iter num 20\n",
            "loss 2.8025469234525852e-05 average time 0.002369422750004446 iter num 40\n",
            "loss 2.239542648212181e-05 average time 0.0023780497000018387 iter num 60\n",
            "loss 2.1863129821152537e-05 average time 0.002357970462501413 iter num 80\n",
            "loss 2.1825210748324023e-05 average time 0.0023864238100003376 iter num 100\n",
            "loss 2.1689077527593054e-05 average time 0.002315069049998897 iter num 20\n",
            "loss 2.151115179109489e-05 average time 0.002337828300002798 iter num 40\n",
            "loss 2.1413831122202866e-05 average time 0.002337268100001211 iter num 60\n",
            "loss 2.1371390772695028e-05 average time 0.002331090000001268 iter num 80\n",
            "loss 2.1362545570786952e-05 average time 0.0023334381999990227 iter num 100\n",
            "loss 2.1196198656921633e-05 average time 0.0023180616999951553 iter num 20\n",
            "loss 2.105106409188508e-05 average time 0.002292299699995226 iter num 40\n",
            "loss 2.095636809393414e-05 average time 0.002295295499997489 iter num 60\n",
            "loss 2.0913604394042648e-05 average time 0.002281861124996709 iter num 80\n",
            "loss 2.0904654207476052e-05 average time 0.0022956568299980517 iter num 100\n",
            "loss 2.073593559767365e-05 average time 0.0023100543500049753 iter num 20\n",
            "loss 2.058845951282023e-05 average time 0.002275351775003287 iter num 40\n",
            "loss 2.049221493022276e-05 average time 0.0022959072166685245 iter num 60\n",
            "loss 2.044873718048054e-05 average time 0.0022944355874997767 iter num 80\n",
            "loss 2.043961168454298e-05 average time 0.0023142019099998377 iter num 100\n",
            "loss 2.0268097565680866e-05 average time 0.0023214526499970136 iter num 20\n",
            "loss 2.0118203206266822e-05 average time 0.002288210899999399 iter num 40\n",
            "loss 2.0020374863236302e-05 average time 0.002315945483331916 iter num 60\n",
            "loss 1.9976189832764308e-05 average time 0.0023407800124985558 iter num 80\n",
            "loss 1.9966928391299562e-05 average time 0.0023437546699983615 iter num 100\n",
            "loss 1.9792651515717166e-05 average time 0.0023117187499963167 iter num 20\n",
            "loss 1.9640434469539964e-05 average time 0.00233491969999875 iter num 40\n",
            "loss 1.9541139828665195e-05 average time 0.002318070749998924 iter num 60\n",
            "loss 1.9496312675539805e-05 average time 0.0023337895624983675 iter num 80\n",
            "loss 1.948691337900071e-05 average time 0.0023652911399989307 iter num 100\n",
            "loss 1.93101089001909e-05 average time 0.0025856197499962265 iter num 20\n",
            "loss 1.915574544170844e-05 average time 0.002435493199999428 iter num 40\n",
            "loss 1.905515053214031e-05 average time 0.0024118365166638494 iter num 60\n",
            "loss 1.900968965419445e-05 average time 0.0023864441749985588 iter num 80\n",
            "loss 1.9000173408707418e-05 average time 0.0023883802199975435 iter num 100\n",
            "loss 1.882125789816092e-05 average time 0.002270846799996207 iter num 20\n",
            "loss 1.8664902386318487e-05 average time 0.002303062249993104 iter num 40\n",
            "loss 1.8563123538896704e-05 average time 0.002328011249994688 iter num 60\n",
            "loss 1.851716697670548e-05 average time 0.002317780987495155 iter num 80\n",
            "loss 1.850756854104605e-05 average time 0.002340405819995226 iter num 100\n",
            "loss 3.086673410656238e-05 average time 0.0024114334500040966 iter num 20\n",
            "loss 1.8229601255656206e-05 average time 0.0024050403250001295 iter num 40\n",
            "loss 1.8115110091364063e-05 average time 0.002362241616665983 iter num 60\n",
            "loss 1.804815387019789e-05 average time 0.002364817050003154 iter num 80\n",
            "loss 1.8034194905332566e-05 average time 0.002379045460001521 iter num 100\n",
            "loss 3.394568821102856e-05 average time 0.002226112800002511 iter num 20\n",
            "loss 2.2056492211993457e-05 average time 0.0022745177250072857 iter num 40\n",
            "loss 1.8188028483879076e-05 average time 0.002319399266671477 iter num 60\n",
            "loss 1.777952004699215e-05 average time 0.002298200025003183 iter num 80\n",
            "loss 1.776700380245734e-05 average time 0.0022993132400000605 iter num 100\n",
            "loss 1.762804889670295e-05 average time 0.0023122275999980955 iter num 20\n",
            "loss 1.749939335482863e-05 average time 0.0023178522500032273 iter num 40\n",
            "loss 1.7418471993243868e-05 average time 0.0023099357333355402 iter num 60\n",
            "loss 1.738242753772237e-05 average time 0.002311394550000756 iter num 80\n",
            "loss 1.737490936701624e-05 average time 0.002330714999999941 iter num 100\n",
            "loss 1.7233594889933554e-05 average time 0.002301779900000156 iter num 20\n",
            "loss 1.711044004288654e-05 average time 0.0022614126500016597 iter num 40\n",
            "loss 1.7030205557675446e-05 average time 0.0022664278000007697 iter num 60\n",
            "loss 1.6993969224665334e-05 average time 0.0023050966500008487 iter num 80\n",
            "loss 1.6986417744781705e-05 average time 0.0023572610100012527 iter num 100\n",
            "loss 1.684374565712496e-05 average time 0.002339003699998443 iter num 20\n",
            "loss 1.671923168403532e-05 average time 0.002310804049997728 iter num 40\n",
            "loss 1.663812892265166e-05 average time 0.0023613395666662504 iter num 60\n",
            "loss 1.660150163076907e-05 average time 0.002341862237499015 iter num 80\n",
            "loss 1.659381314509595e-05 average time 0.0023686504599987755 iter num 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_fEzULvKwR-"
      },
      "source": [
        "# "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433247f4-1349-4c97-e770-f50f8fa54eff"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_knock_out_1stock_oldmethod_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3477098f-2d46-4742-e56e-c6854c886a03"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42e7bdb7-b30f-4dc0-f50c-e1263cc961ff"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_knock_out_1stock_oldmethod_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3459b7d2-9620-4169-bdb0-5c81bda6c695"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=7, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (fc4): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc5): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc6): Linear(in_features=64, out_features=2, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57"
      },
      "source": [
        "# # version 2, 7\n",
        "# # If memory is not enough, try changing parameters and restarting session\n",
        "# # loss will converge\n",
        "\n",
        "# from ignite.engine import Engine, Events\n",
        "# from ignite.handlers import Timer\n",
        "# from torch.nn import MSELoss\n",
        "# from torch.optim import Adam\n",
        "# from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "# from ignite.handlers import ModelCheckpoint\n",
        "# from model import Net\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from torch import Tensor\n",
        "# from torch.autograd import grad\n",
        "# timer = Timer(average=True)\n",
        "# #model = Net().cuda()\n",
        "# loss_fn = MSELoss()\n",
        "# optimizer = Adam(model.parameters(), lr=1e-3, eps=1e-4, amsgrad=True) # try using higher epsilon and amsgrad\n",
        "# dataset = OptionDataSet(max_len = 100) # Use max_len to adjust\n",
        "\n",
        "# def train_update(engine, batch):\n",
        "#     model.train()\n",
        "#     optimizer.zero_grad()\n",
        "#     x = batch[0]\n",
        "#     y = batch[1]\n",
        "#     y_pred = model(x.float())\n",
        "\n",
        "#     def compute_deltas(x):\n",
        "#       inputs = x.float()\n",
        "#       inputs.requires_grad = True\n",
        "#       first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "#       return first_order_gradient[0][[3]]\n",
        "\n",
        "#     deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "#     y_pred = torch.cat((y_pred, deltas), 1)\n",
        "\n",
        "#     loss_weight = torch.tensor([1, 1]).cuda()\n",
        "#     loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "#     loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#     return loss.item()\n",
        "\n",
        "# trainer = Engine(train_update)\n",
        "# log_interval = 20\n",
        "\n",
        "# scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "# trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "# timer.attach(trainer,\n",
        "#              start=Events.EPOCH_STARTED,\n",
        "#              resume=Events.ITERATION_STARTED,\n",
        "#              pause=Events.ITERATION_COMPLETED,\n",
        "#              step=Events.ITERATION_COMPLETED)    \n",
        "# @trainer.on(Events.ITERATION_COMPLETED)\n",
        "# def log_training_loss(engine):\n",
        "#     iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "#     if iter % log_interval == 0:\n",
        "#         print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "# trainer.run(dataset, max_epochs = 100)\n",
        "\n",
        "# model_save_name = 'jax_knock_out_1stock_oldmethod_1.pth'\n",
        "# path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "# torch.save(model.state_dict(), path)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQs-OZHGEwac"
      },
      "source": [
        "# 12:00"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a3d2e91-73c9-4c4a-e0ca-98ec9bb9305f"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 1, 0.8, 1, 0.25, 0.02, 0.02]]).cuda() # T, K, B, S, sigma, mu, r\n",
        "print('price: ' + str(model(inputs.float())))\n",
        "\n",
        "# price, delta\n",
        "# should be around (0.10632345, 0.5543747)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "price: tensor([[0.105593, 0.553141]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqpasxVi0hx3",
        "outputId": "169cdff4-5b60-4251-97d8-710b61fcf7d9"
      },
      "source": [
        "# Knock out call\n",
        "\n",
        "# now change code such that 'numsteps' does not represent year\n",
        "# make dt = year / numsteps\n",
        "# Add r, and notice that noise must have mean 0, not drift, or else it'll give large option prices\n",
        "# (done)\n",
        "# after making the changes, the values are still correct\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        #dx =  drift + noise[t,:] # no need to multiply by sigma here because noise generated by cov not corr\n",
        "        dx2 = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx2)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T): # down-and-out call\n",
        "    return jnp.mean(jnp.maximum((1 - jnp.any(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2) < B, axis=1).astype(int))* \n",
        "                                (jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T), axis=2))[:,-1]-K, 0) *\n",
        "                    jnp.exp(-r[0] * T))\n",
        "    # must use '-1' not 'numsteps', or else grad will be 0\n",
        "\n",
        "numstocks = 1\n",
        "numsteps = 50\n",
        "numpaths = 2000000\n",
        "\n",
        "rng = jax.random.PRNGKey(1)\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.02]*numstocks)\n",
        "r = drift # let r = drift to match B-S\n",
        "\n",
        "cov = jnp.identity(numstocks)*0.25*0.25\n",
        "initial_stocks = jnp.array([1.]*numstocks) # must be float\n",
        "\n",
        "T = 1.0\n",
        "K = 1.0\n",
        "B = 0.8 # if B is set to 0, equivalent to European call\n",
        "\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "\n",
        "keys = jax.random.split(key, numpaths)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T)) # here numsteps different from T\n",
        "\n",
        "# delta\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, B, T)) # here numsteps different from T"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.10632345\n",
            "[0.5543747]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lovJwXo3-YEu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "0c940d45-3fa7-4443-b272-7d5d4aa6fd22"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def compute_price(S):\n",
        "    inputs = torch.tensor([[1, 1, 0.8, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())[0][0]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_prices = []\n",
        "correct_call_prices = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*numstocks) # must be float\n",
        "    model_call_prices.append(compute_price(p).item())\n",
        "    correct_call_prices.append(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T))\n",
        "\n",
        "#plt.plot(prices, model_call_prices, label = \"model_call_prices\")\n",
        "#plt.plot(prices, correct_call_prices, label = \"correct_call_prices\")\n",
        "plt.plot(prices, np.array(model_call_prices)-np.array(correct_call_prices), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwApH0GT9bBK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7a529497-56e0-4c0b-da0f-b49c8ee7a3c2"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, 0.8, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())[0][1]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*numstocks) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, 1.0, B, T))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"correct_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHgD1NjP7DOW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "4335141b-f30a-41bd-c041-50735384b426"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 0.775, 0.8, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())[0][1]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*numstocks) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, 0.775, B, T))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"correct_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7MfujMQ7oij",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "7a99c441-1ba0-4667-98b2-23b815c6bb1e"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1.225, 0.8, S, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())[0][1]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([p]*numstocks) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, 1.225, B, T))\n",
        "\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"correct_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}