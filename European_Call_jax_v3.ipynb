{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "European_Call_jax.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Pui/European_Call_jax_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1RYKgBifCYw"
      },
      "source": [
        "# Test (Skip this if not trying to test, to make sure that functions are defined correctly in cells below without running this cell)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWYfON_marpj",
        "outputId": "500ae254-513a-44ae-f9ba-9785c1b3991a"
      },
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T):\n",
        "  return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
        "\n",
        "numstocks = 3\n",
        "numsteps = 50\n",
        "numpaths = 100000\n",
        "\n",
        "rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "rng, key = jax.random.split(rng)\n",
        "\n",
        "drift = jnp.array([0.]*numstocks)\n",
        "r = drift\n",
        "cov = jnp.identity(numstocks)*0.25*0.25\n",
        "initial_stocks = jnp.array([100.]*numstocks) # must be float\n",
        "T = 1.0\n",
        "K = 110.0\n",
        "\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "keys = jax.random.split(key, numpaths)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "# option price\n",
        "print(optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "%timeit optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T)\n",
        "\n",
        "# delta test\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T))\n",
        "%timeit goptionvalueavg(keys, initial_stocks, numsteps, drift, r, cov, K, T)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.4039123\n",
            "100 loops, best of 5: 5.75 ms per loop\n",
            "[0.09444948 0.09465618 0.09468745]\n",
            "10 loops, best of 5: 44.8 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxFUnc_iBVcU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a9d788-97b4-4a06-8935-0498591914c2"
      },
      "source": [
        "%%writefile cupy_dataset.py\n",
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, T, keys): # need to pass 'keys'\n",
        "    return jnp.mean((jnp.maximum(jnp.mean(batch_simple(keys, initial_stocks, numsteps, drift, cov, T)[:,-1,:], axis=1)-K,0)) * jnp.exp(-r[0] * T))\n",
        "\n",
        "###################################################################################################\n",
        "# these 2 functions must be defined outside class in order to be used in 'optionvalueavg' function\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "###################################################################################################\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len, number_path, batch, seed, stocks):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.N_PATHS = number_path\n",
        "        self.N_STEPS = 50\n",
        "        self.N_BATCH = batch\n",
        "        self.N_STOCKS = stocks\n",
        "        self.T = 1.0 # assume T = 1, use float here\n",
        "        self.seed = seed\n",
        "        np.random.seed(seed)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "        \n",
        "        Y = cupy.zeros((self.N_BATCH, 1 + self.N_STOCKS), dtype=cupy.float32) # output: price, delta1, delta2, delta3\n",
        "        X = cupy.zeros((self.N_BATCH, self.N_STOCKS * 6), dtype = cupy.float32)\n",
        "\n",
        "        for op in range(self.N_BATCH):\n",
        "          \n",
        "          rng = jax.random.PRNGKey(self.seed)\n",
        "          rng, key = jax.random.split(rng)\n",
        "\n",
        "          ################################################################################################### generate random input numbers\n",
        "\n",
        "          initial_stocks = jnp.array(np.random.random(self.N_STOCKS) * 200.0)\n",
        "\n",
        "          corr = jnp.diag(jnp.array([1]*self.N_STOCKS)) # assume no correlation between stocks here\n",
        "          sigma = jnp.array(np.random.random(self.N_STOCKS) * 0.4)\n",
        "          cov = (jnp.diag(sigma)).dot(corr).dot(jnp.diag(sigma))\n",
        "\n",
        "          r = jnp.repeat(jnp.array(np.random.random(1) * 0.1), self.N_STOCKS)\n",
        "          drift = jnp.array(np.random.random(self.N_STOCKS) * 0.2)\n",
        "\n",
        "          T = self.T\n",
        "          K = np.random.random(1) * 200.0\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### apply functions to compute price and deltas\n",
        "          \n",
        "          keys = jax.random.split(key, self.N_PATHS)\n",
        "\n",
        "          European_Call_price = optionvalueavg(key, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "          gooptionvalue = jax.grad(optionvalueavg, argnums=1)\n",
        "          Deltas = gooptionvalue(keys, initial_stocks, self.N_STEPS, drift, r, cov, K, T, keys) # need to pass 'keys'\n",
        "\n",
        "          ###################################################################################################\n",
        "          ################################################################################################### store input and output numbers in X and Y\n",
        "\n",
        "          Y[op, 0] = European_Call_price\n",
        "          Y[op, 1:4] = cupy.array(Deltas, dtype=cupy.float32)\n",
        "\n",
        "          # T, K, S, sigma, mu, r\n",
        "          paras = (jnp.repeat(jnp.array(T), self.N_STOCKS), jnp.repeat(jnp.array(K), self.N_STOCKS), initial_stocks, sigma, drift, r)\n",
        "          paras = np.column_stack(paras).reshape(1,-1)[0]\n",
        "          X[op,] = cupy.array(paras)\n",
        "\n",
        "          ###################################################################################################\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(X.toDlpack()), from_dlpack(Y.toDlpack()))\n",
        "\n",
        "\n",
        "# ds = OptionDataSet(max_len = 2, number_path = 10000, batch = 2, seed = 15, stocks=3) # for testing purpose, use constant seed. When training, change to random seed\n",
        "# for i in ds:\n",
        "#     print(i)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cupy_dataset.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN6JO9OBHdvv",
        "outputId": "dd9f3c41-ff1a-4deb-af91-8601fd7c0d86"
      },
      "source": [
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(6*3, hidden) # remember to change this!\n",
        "        self.fc2 = nn.Linear(hidden, hidden)\n",
        "        self.fc3 = nn.Linear(hidden, hidden)\n",
        "        self.fc4 = nn.Linear(hidden, hidden)\n",
        "        self.fc5 = nn.Linear(hidden, hidden)\n",
        "        self.fc6 = nn.Linear(hidden, 4) # 4 outputs: price, delta1, delta2, delta3\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1, 200.0, 200.0, 0.4, 0.2, 0.1]*3)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = x / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlXD80xPNVc6",
        "outputId": "876af001-a767-4d45-a3c5-7857d4defbbd"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 24.3 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 12.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 11.6 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.9.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.7.4.3)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "S3CyULkENYKb",
        "outputId": "ace1ab58-6a90-4e62-fdc1-0881831392c1"
      },
      "source": [
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "timer = Timer(average=True)\n",
        "model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 1024, batch = 32, seed = np.random.randint(10000), stocks = 3) # must have random seed\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    y_pred = model(x)\n",
        "    # print(y_pred)\n",
        "    # print(y.mean(axis=0))\n",
        "    loss_weight = y.mean(axis=0)[0]/y.mean(axis=0)\n",
        "    # loss_weight = torch.tensor([1, 50, 50, 50]).cuda() # switch to this so that more weight is assigned to price\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    # print(loss_weight)\n",
        "    # print(loss_weight_normalized)\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean() * 100 # compute weighted MSE between the 2 arrays\n",
        "    # print((y_pred - y) ** 2)\n",
        "    # print((y_pred - y) ** 2 * loss_weight_normalized)\n",
        "    # print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 100)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 89.85205078125 average time 0.05556291030001148 iter num 20\n",
            "loss 91.4995346069336 average time 0.029553573625005925 iter num 40\n",
            "loss 54.47396469116211 average time 0.020723146183333558 iter num 60\n",
            "loss 44.999969482421875 average time 0.016297661912501836 iter num 80\n",
            "loss 66.22318267822266 average time 0.013648526739999625 iter num 100\n",
            "loss 22.944133758544922 average time 0.054008851200001116 iter num 20\n",
            "loss 4.066799640655518 average time 0.028557514250002212 iter num 40\n",
            "loss 2.3120083808898926 average time 0.02003492761666621 iter num 60\n",
            "loss 1.2100223302841187 average time 0.01577903541250123 iter num 80\n",
            "loss 1.7053260803222656 average time 0.013226537870001493 iter num 100\n",
            "loss 3.9082486629486084 average time 0.0545535672000085 iter num 20\n",
            "loss 0.7751726508140564 average time 0.028753806574999884 iter num 40\n",
            "loss 1.2273125648498535 average time 0.02014572915000296 iter num 60\n",
            "loss 0.31135281920433044 average time 0.015890252612504697 iter num 80\n",
            "loss 0.4193575084209442 average time 0.013331483060003393 iter num 100\n",
            "loss 0.275915265083313 average time 0.05643938285001582 iter num 20\n",
            "loss 0.4182392656803131 average time 0.029771115200009034 iter num 40\n",
            "loss 0.20203572511672974 average time 0.020851944166669984 iter num 60\n",
            "loss 0.16537651419639587 average time 0.016496259462499552 iter num 80\n",
            "loss 0.07996416836977005 average time 0.013793408600000702 iter num 100\n",
            "loss 0.275627464056015 average time 0.056328506899996 iter num 20\n",
            "loss 0.3867691457271576 average time 0.02965819725000074 iter num 40\n",
            "loss 0.3247792720794678 average time 0.020773414300000088 iter num 60\n",
            "loss 0.2389560043811798 average time 0.016309917837504885 iter num 80\n",
            "loss 0.19098512828350067 average time 0.013640317010001582 iter num 100\n",
            "loss 0.3873366713523865 average time 0.05573952055001428 iter num 20\n",
            "loss 0.15315751731395721 average time 0.0293537798000159 iter num 40\n",
            "loss 0.21618206799030304 average time 0.02055313625002479 iter num 60\n",
            "loss 0.16839222609996796 average time 0.016148551200026874 iter num 80\n",
            "loss 0.13080978393554688 average time 0.01353708406001715 iter num 100\n",
            "loss 0.15827612578868866 average time 0.05583982695000032 iter num 20\n",
            "loss 0.2707904279232025 average time 0.029410212524987857 iter num 40\n",
            "loss 0.16531941294670105 average time 0.020617442733312903 iter num 60\n",
            "loss 0.20202593505382538 average time 0.016215903199989157 iter num 80\n",
            "loss 0.2907167673110962 average time 0.013571405779998713 iter num 100\n",
            "loss 0.18462848663330078 average time 0.05508694429997831 iter num 20\n",
            "loss 0.8110172748565674 average time 0.029032453199988595 iter num 40\n",
            "loss 0.24048085510730743 average time 0.02032064589999815 iter num 60\n",
            "loss 0.1392093002796173 average time 0.01600528610000538 iter num 80\n",
            "loss 0.33451178669929504 average time 0.013394621559998541 iter num 100\n",
            "loss 0.30408698320388794 average time 0.053706455750022995 iter num 20\n",
            "loss 0.2544851303100586 average time 0.02835397542501141 iter num 40\n",
            "loss 0.28858810663223267 average time 0.019912158166679697 iter num 60\n",
            "loss 0.19117701053619385 average time 0.0157072718000137 iter num 80\n",
            "loss 0.1005982756614685 average time 0.013201555770008326 iter num 100\n",
            "loss 0.12541772425174713 average time 0.05584585330001346 iter num 20\n",
            "loss 0.12556038796901703 average time 0.02940103332500712 iter num 40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:ignite.engine.engine.Engine:Engine run is terminating due to exception: \n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-46acb864790d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'average time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'iter num'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    769\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Engine run is terminating due to exception: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 771\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    739\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 741\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m                 \u001b[0;31m# time is available for handlers but must be update after fire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_event_name\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDATALOADER_STOP_ITERATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_BATCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0miter_counter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m           \u001b[0mkeys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_PATHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m           \u001b[0mEuropean_Call_price\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptionvalueavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m           \u001b[0mgooptionvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptionvalueavg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnums\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m           \u001b[0mDeltas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgooptionvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_STEPS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/cupy_dataset.py\u001b[0m in \u001b[0;36moptionvalueavg\u001b[0;34m(key, initial_stocks, numsteps, drift, r, cov, K, T, keys)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0moptionvalueavg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# need to pass 'keys'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_stocks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumsteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrift\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m###################################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_rewriting_take\u001b[0;34m(arr, idx, indices_are_sorted, unique_indices)\u001b[0m\n\u001b[1;32m   5653\u001b[0m   \u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_split_index_for_jit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5654\u001b[0m   return _gather(arr, treedef, static_idx, dynamic_idx, indices_are_sorted,\n\u001b[0;32m-> 5655\u001b[0;31m                  unique_indices)\n\u001b[0m\u001b[1;32m   5656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5657\u001b[0m \u001b[0;31m# TODO(phawkins): re-enable jit after fixing excessive recompilation for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_gather\u001b[0;34m(arr, treedef, static_idx, dynamic_idx, indices_are_sorted, unique_indices)\u001b[0m\n\u001b[1;32m   5661\u001b[0m             unique_indices):\n\u001b[1;32m   5662\u001b[0m   \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_merge_static_and_dynamic_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtreedef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatic_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdynamic_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5663\u001b[0;31m   \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_index_to_gather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shared with _scatter_update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5664\u001b[0m   \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_index_to_gather\u001b[0;34m(x_shape, idx, normalize_indices)\u001b[0m\n\u001b[1;32m   5852\u001b[0m         \u001b[0;31m# XLA gives error when indexing into an axis of size 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5853\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"index is out of bounds for axis {x_axis} with size 0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5854\u001b[0;31m       \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_normalize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx_axis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnormalize_indices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5855\u001b[0m       \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_element_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5856\u001b[0m       \u001b[0mgather_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgather_indices_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/numpy/lax_numpy.py\u001b[0m in \u001b[0;36m_normalize_index\u001b[0;34m(index, axis_size)\u001b[0m\n\u001b[1;32m   5437\u001b[0m     \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_constant_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5438\u001b[0m     \u001b[0mlax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_size_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5439\u001b[0;31m     index)\n\u001b[0m\u001b[1;32m   5440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5441\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0m_wraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_along_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_doc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/_src/lax/lax.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(pred, on_true, on_false)\u001b[0m\n\u001b[1;32m    841\u001b[0m   \u001b[0moperator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m   \"\"\"\n\u001b[0;32m--> 843\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mselect_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_false\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m def slice(operand: Array, start_indices: Sequence[int],\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mbind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    265\u001b[0m         args, used_axis_names(self, params) if self._dispatch_on_params else None)\n\u001b[1;32m    266\u001b[0m     \u001b[0mtracers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_raise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_trace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiple_results\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mfull_lower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/core.py\u001b[0m in \u001b[0;36mprocess_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    611\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_primitive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 612\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mprocess_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprimitive\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    274\u001b[0m   \u001b[0;34m\"\"\"Impl rule that compiles and runs a single primitive 'prim' using XLA.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m   \u001b[0mcompiled_fun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxla_primitive_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0munsafe_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mcompiled_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/jax/interpreters/xla.py\u001b[0m in \u001b[0;36m_execute_compiled_primitive\u001b[0;34m(prim, compiled, result_handler, *args)\u001b[0m\n\u001b[1;32m    390\u001b[0m   \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m   \u001b[0minput_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_put\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m   \u001b[0mout_bufs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompiled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m   \u001b[0mcheck_special\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mout_bufs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82f7c7fe-6a65-4bda-9b4d-17b9e45a24c1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_test_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e37714-0eb2-49b0-dc56-7f875db39857"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a377b56-e36c-48f4-ea34-3376941f059d"
      },
      "source": [
        "import torch\n",
        "model_save_name = 'jax_european_test_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8ece109-28c3-4415-bd04-a6f1bda2fefc"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net().cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=18, out_features=1024, bias=True)\n",
            "  (fc2): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc3): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc4): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc5): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "  (fc6): Linear(in_features=1024, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "675655c6-2662-416a-d9e4-f9a1de0ff9d8"
      },
      "source": [
        "# If memory is not enough, try changing parameters and restarting session\n",
        "# loss will converge\n",
        "\n",
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "from cupy_dataset import OptionDataSet\n",
        "import numpy as np\n",
        "timer = Timer(average=True)\n",
        "#model = Net().cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "#dataset = OptionDataSet(max_len = 100, number_path = 1024, batch = 32, seed = np.random.randint(10000), stocks = 3) # must have random seed\n",
        "dataset = OptionDataSet(max_len = 100, number_path = 10000, batch = 16, seed = np.random.randint(10000), stocks = 3) # must have random seed\n",
        "\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    y_pred = model(x)\n",
        "    # print(y_pred)\n",
        "    # print(y.mean(axis=0))\n",
        "    # loss_weight = y.mean(axis=0)[0]/y.mean(axis=0)\n",
        "    loss_weight = torch.tensor([1, 10, 10, 10]).cuda() # switch to this so that more weight is assigned to price\n",
        "    #print(loss_weight)\n",
        "    loss_weight_normalized = loss_weight/loss_ weight.sum()\n",
        "    # print(loss_weight)\n",
        "    # print(loss_weight_normalized)\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean() * 100 # compute weighted MSE between the 2 arrays\n",
        "    # print((y_pred - y) ** 2)\n",
        "    # print((y_pred - y) ** 2 * loss_weight_normalized)\n",
        "    # print(loss)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 20\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 20)\n",
        "\n",
        "model_save_name = 'jax_european_test_2.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 5.864581108093262 average time 0.032327867099957074 iter num 20\n",
            "loss 3.443066358566284 average time 0.017644310349976423 iter num 40\n",
            "loss 0.9275368452072144 average time 0.012815849633314731 iter num 60\n",
            "loss 1.961557149887085 average time 0.01038908028749006 iter num 80\n",
            "loss 3.1721982955932617 average time 0.00896315276999303 iter num 100\n",
            "loss 3.1993138790130615 average time 0.0317164290999699 iter num 20\n",
            "loss 1.9581228494644165 average time 0.01744400715002712 iter num 40\n",
            "loss 1.5390417575836182 average time 0.012674938666668823 iter num 60\n",
            "loss 1.7212797403335571 average time 0.010269673424988923 iter num 80\n",
            "loss 1.6573094129562378 average time 0.008813054059987734 iter num 100\n",
            "loss 3.01438307762146 average time 0.03304381594998631 iter num 20\n",
            "loss 3.116964101791382 average time 0.018005971075012894 iter num 40\n",
            "loss 3.142531633377075 average time 0.013051205783335717 iter num 60\n",
            "loss 1.554289698600769 average time 0.010539703449984473 iter num 80\n",
            "loss 3.9280459880828857 average time 0.009040289029976521 iter num 100\n",
            "loss 1.7375820875167847 average time 0.03210276994996093 iter num 20\n",
            "loss 0.9050576686859131 average time 0.01758326454996677 iter num 40\n",
            "loss 1.0754565000534058 average time 0.01276011161664125 iter num 60\n",
            "loss 1.5965255498886108 average time 0.010346429512497934 iter num 80\n",
            "loss 1.807337760925293 average time 0.00889693733999593 iter num 100\n",
            "loss 4.290139675140381 average time 0.03203344784997171 iter num 20\n",
            "loss 1.299189805984497 average time 0.017576039174980452 iter num 40\n",
            "loss 2.5734550952911377 average time 0.012718779266666995 iter num 60\n",
            "loss 1.4311467409133911 average time 0.01028576854999983 iter num 80\n",
            "loss 2.291194438934326 average time 0.00882533236999734 iter num 100\n",
            "loss 2.742208957672119 average time 0.0323484537499553 iter num 20\n",
            "loss 2.291731119155884 average time 0.017685997349974513 iter num 40\n",
            "loss 1.737388253211975 average time 0.01282597616663376 iter num 60\n",
            "loss 1.2093425989151 average time 0.010439269512477267 iter num 80\n",
            "loss 2.6393749713897705 average time 0.008982503979977992 iter num 100\n",
            "loss 4.980865478515625 average time 0.03257324920000428 iter num 20\n",
            "loss 2.1368350982666016 average time 0.017849003249989438 iter num 40\n",
            "loss 1.5775021314620972 average time 0.012989409499990263 iter num 60\n",
            "loss 1.533843994140625 average time 0.01052998147499693 iter num 80\n",
            "loss 1.2047969102859497 average time 0.009073201099990911 iter num 100\n",
            "loss 2.93502140045166 average time 0.03283086555002228 iter num 20\n",
            "loss 1.9076913595199585 average time 0.01801609910002071 iter num 40\n",
            "loss 1.0260818004608154 average time 0.013029859416671266 iter num 60\n",
            "loss 1.4915910959243774 average time 0.010541842037497418 iter num 80\n",
            "loss 1.6905453205108643 average time 0.009066909249995661 iter num 100\n",
            "loss 1.3555984497070312 average time 0.0346266922999348 iter num 20\n",
            "loss 3.7086586952209473 average time 0.018800174524994873 iter num 40\n",
            "loss 1.4317514896392822 average time 0.013544530383319398 iter num 60\n",
            "loss 2.8046422004699707 average time 0.01093435067499513 iter num 80\n",
            "loss 2.127002716064453 average time 0.00935613886999363 iter num 100\n",
            "loss 1.4255309104919434 average time 0.03437173449990496 iter num 20\n",
            "loss 2.011389970779419 average time 0.018721531624919407 iter num 40\n",
            "loss 1.2446622848510742 average time 0.013559614866600593 iter num 60\n",
            "loss 0.5562015771865845 average time 0.010938963674936986 iter num 80\n",
            "loss 2.7339301109313965 average time 0.009406527929950243 iter num 100\n",
            "loss 4.72100830078125 average time 0.032754508899961364 iter num 20\n",
            "loss 2.5312283039093018 average time 0.01788940660001117 iter num 40\n",
            "loss 1.0042051076889038 average time 0.012946721900001042 iter num 60\n",
            "loss 2.3673853874206543 average time 0.010469384237501345 iter num 80\n",
            "loss 3.0282323360443115 average time 0.008996767209996506 iter num 100\n",
            "loss 2.6159119606018066 average time 0.032885127650024513 iter num 20\n",
            "loss 7.944008827209473 average time 0.01792916517501908 iter num 40\n",
            "loss 1.8420116901397705 average time 0.012970938600005866 iter num 60\n",
            "loss 0.5964692234992981 average time 0.010496105975011005 iter num 80\n",
            "loss 3.7789039611816406 average time 0.009011142990007102 iter num 100\n",
            "loss 4.295007705688477 average time 0.032475109550000526 iter num 20\n",
            "loss 1.1632999181747437 average time 0.01774638404996267 iter num 40\n",
            "loss 1.9535908699035645 average time 0.012876926233313194 iter num 60\n",
            "loss 0.6021362543106079 average time 0.010443326637482642 iter num 80\n",
            "loss 0.4966099262237549 average time 0.009031692189987553 iter num 100\n",
            "loss 3.8010318279266357 average time 0.032686959699981345 iter num 20\n",
            "loss 2.4939088821411133 average time 0.017842225724996295 iter num 40\n",
            "loss 0.6424331665039062 average time 0.012878402350012644 iter num 60\n",
            "loss 2.0300920009613037 average time 0.01041163636251099 iter num 80\n",
            "loss 0.729377031326294 average time 0.00895621818001473 iter num 100\n",
            "loss 1.1189063787460327 average time 0.03304471949995787 iter num 20\n",
            "loss 3.336897373199463 average time 0.018058290174963076 iter num 40\n",
            "loss 2.6164398193359375 average time 0.013056703033301649 iter num 60\n",
            "loss 1.7599331140518188 average time 0.010602485724973576 iter num 80\n",
            "loss 2.82547664642334 average time 0.009114693469973645 iter num 100\n",
            "loss 1.1799981594085693 average time 0.03297687294993921 iter num 20\n",
            "loss 3.0545153617858887 average time 0.018009319624923137 iter num 40\n",
            "loss 1.0960031747817993 average time 0.01300846369994512 iter num 60\n",
            "loss 2.271101951599121 average time 0.010515241237465034 iter num 80\n",
            "loss 0.7685878276824951 average time 0.009032308709970493 iter num 100\n",
            "loss 1.5105057954788208 average time 0.0324375389499437 iter num 20\n",
            "loss 1.2768645286560059 average time 0.01770622292497137 iter num 40\n",
            "loss 1.4906303882598877 average time 0.012823961899963857 iter num 60\n",
            "loss 1.4030752182006836 average time 0.010390387324957829 iter num 80\n",
            "loss 2.4816486835479736 average time 0.008903040999966834 iter num 100\n",
            "loss 4.985154628753662 average time 0.032784085250068526 iter num 20\n",
            "loss 1.7590768337249756 average time 0.017939082675059125 iter num 40\n",
            "loss 4.262849807739258 average time 0.012948585200039513 iter num 60\n",
            "loss 1.3617643117904663 average time 0.010449759925035097 iter num 80\n",
            "loss 2.249753952026367 average time 0.008963453300020774 iter num 100\n",
            "loss 3.360243558883667 average time 0.03269492639992677 iter num 20\n",
            "loss 8.440863609313965 average time 0.01792092429996046 iter num 40\n",
            "loss 1.2282155752182007 average time 0.012934234549993562 iter num 60\n",
            "loss 0.9683466553688049 average time 0.010497720937507893 iter num 80\n",
            "loss 0.8451489806175232 average time 0.009006608139998207 iter num 100\n",
            "loss 1.2582411766052246 average time 0.031425848149979174 iter num 20\n",
            "loss 1.4962738752365112 average time 0.017366737350005223 iter num 40\n",
            "loss 2.2299106121063232 average time 0.012605726533327774 iter num 60\n",
            "loss 0.5936872959136963 average time 0.010231580237478966 iter num 80\n",
            "loss 2.226255416870117 average time 0.008796366399997169 iter num 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3hhVHEVV06R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c02a6f31-e770-4be3-8a6e-8ff1160432a4"
      },
      "source": [
        "import torch\n",
        "inputs = torch.tensor([[1, 110.0, 100.0, 0.25, 0., 0.]*3]).cuda() # T, K, S, sigma, mu, r\n",
        "model(inputs.float())\n",
        "\n",
        "# price, delta1, delta2, delta3\n",
        "# should be around (2.3654, 0.0937, 0.0937, 0.0937)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.9772, 0.1055, 0.1035, 0.1030]], device='cuda:0',\n",
              "       grad_fn=<AddmmBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vusLScDmUvvz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "84c3a841-b80a-4c15-c517-95acc7b3b16d"
      },
      "source": [
        "import pylab\n",
        "prices = np.arange(0, 200, 0.1)\n",
        "deltas = []\n",
        "for p in prices:\n",
        "    inputs = torch.tensor([[1, 110.0, p, 0.25, 0., 0.]*3]).cuda() # T, K, S, sigma, mu, r\n",
        "    deltas.append(model(inputs.float())[0][1]) # delta for S1\n",
        "\n",
        "fig = pylab.plot(prices, deltas)\n",
        "pylab.xlabel('prices')\n",
        "pylab.ylabel('Delta')\n",
        "fig"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f0530267bd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}