{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grid_Test_Knock_In_Call_3stocks_Final_Version",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xinyanz-erin/Applied-Finance-Project/blob/Pui/15min_Grid_Test_Knock_In_Call_3stocks_Final_Version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNu4Zb1PPWVx"
      },
      "source": [
        "# Initial Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bC64N--OvYw"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPlLTzwwNfwg"
      },
      "source": [
        "nstock = 3\n",
        "model_save_name = f'jax_knock_in_{str(nstock)}stocks_1.pth'"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nlEiG5XPTj-"
      },
      "source": [
        "# Dataset generation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RsPX_tEBGFc"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIQxpJqK6OZr"
      },
      "source": [
        "# import cupy\n",
        "# import jax\n",
        "# import jax.numpy as jnp\n",
        "# from jax import random\n",
        "# from jax import jit\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "# def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "#     stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "#     stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "#                             jax.ops.index[0],         # initialization of stock prices\n",
        "#                             initial_stocks)\n",
        "#     noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "#     sigma = jnp.diag(cov) ** 0.5\n",
        "#     dt = T / numsteps\n",
        "#     def time_step(t, val):\n",
        "#         dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "#         val = jax.ops.index_update(val,\n",
        "#                             jax.ops.index[t],\n",
        "#                             val[t-1] * dx)\n",
        "#         return val\n",
        "#     return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "# def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T, numpaths): # up-and-in call\n",
        "#     out = batch_simple(keys, initial_stocks, numsteps, drift, cov, T)\n",
        "#     knock_in_index = jnp.argmax(jnp.mean(out, axis=2) >= B, axis=1)\n",
        "#     r_mean_array = jnp.tile(jnp.cumsum(r), (numpaths, 1))[jnp.arange(numpaths), knock_in_index]/(knock_in_index+1)\n",
        "\n",
        "#     return jnp.mean((1 - jnp.all(jnp.mean(out, axis=2) < B, axis=1).astype(int)) *  # knock in: 1, else: 0\n",
        "#                     (jnp.mean(out, axis=2)[jnp.arange(numpaths), knock_in_index] - K) *   # (S[knock-in]-K)\n",
        "#                     jnp.exp(- r_mean_array * (T * (knock_in_index+1) / numsteps))) # (exp(-mean(r until payoff) * (t until payoff)))\n",
        "\n",
        "# goptionvalueavg = jax.grad(optionvalueavg, argnums=1)\n",
        "\n",
        "# #################################################################### Adjust all parameters here (not inside class)\n",
        "# numstocks = 3\n",
        "# numsteps = 50\n",
        "# numpaths = 2000000\n",
        "\n",
        "# rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "# rng, key = jax.random.split(rng)\n",
        "# keys = jax.random.split(key, numpaths)\n",
        "\n",
        "# S1_range = jnp.linspace(0.75, 1.25, 6)[2:4]\n",
        "# S2_range = jnp.linspace(0.75, 1.25, 6)\n",
        "# S3_range = jnp.linspace(0.75, 1.25, 6)\n",
        "# K_range = jnp.linspace(0.75, 1.25, 5)\n",
        "# B_range = jnp.linspace(1.1, 1.6, 6)\n",
        "# sigma_range = jnp.linspace(0.15, 0.45, 3)\n",
        "# r_range = jnp.linspace(0.01, 0.04, 3)\n",
        "# T = 1.0\n",
        "\n",
        "# fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "# batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "# ####################################################################\n",
        "\n",
        "# call = []\n",
        "# count = 0\n",
        "\n",
        "# for S1 in S1_range:\n",
        "#   for S2 in S2_range:\n",
        "#     for S3 in S3_range:\n",
        "#       for K in K_range:\n",
        "#         for B in B_range:\n",
        "#           for r in r_range:\n",
        "#             for sigma in sigma_range:\n",
        "\n",
        "#               initial_stocks = jnp.array([S1, S2, S3]) # must be float\n",
        "#               r_tmp = jnp.array([r]*numsteps)\n",
        "#               drift = jnp.array([r]*numstocks)\n",
        "#               cov = jnp.identity(numstocks)*sigma*sigma\n",
        "\n",
        "#               Knock_In_Call_price = optionvalueavg(key, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T, numpaths)\n",
        "#               Deltas = goptionvalueavg(keys, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T, numpaths)\n",
        "#               call.append([T, K, B, S1, sigma, r, r,\n",
        "#                           T, K, B, S2, sigma, r, r,\n",
        "#                           T, K, B, S3, sigma, r, r, Knock_In_Call_price] + list(Deltas)) #T, K, B, S, sigma, mu, r, price, delta\n",
        "              \n",
        "#               count += 1\n",
        "#               print(count)\n",
        "\n",
        "\n",
        "# Thedataset = pd.DataFrame(call)\n",
        "\n",
        "# #save to csv\n",
        "# Thedataset.to_csv(f'/content/drive/MyDrive/AFP/Save_Models/Knock_In_Call_{str(nstock)}stocks_Datset_part{part}.csv', index=False, header=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbIT8ZodPcdy"
      },
      "source": [
        "# Access to the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LtL32xSp7mw",
        "outputId": "c007e00a-0481-42d9-b7e0-cb48be443d57"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skGWSSsG8TGG"
      },
      "source": [
        "# read csv\n",
        "Thedataset = pd.read_csv(f'/content/drive/MyDrive/Grid Datasets/Knock_In_Call_{str(nstock)}stocks_Datset.csv', header=None)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or2YUJ9cfEiF"
      },
      "source": [
        "# Construct Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-i4HV-G44th"
      },
      "source": [
        "import cupy\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "import torch\n",
        "torch.set_printoptions(precision=6)\n",
        "\n",
        "Thedataset_X = Thedataset.iloc[:,:7*nstock]\n",
        "Thedataset_Y = Thedataset.iloc[:,7*nstock:]\n",
        "\n",
        "class OptionDataSet(object):\n",
        "    \n",
        "    def __init__(self, max_len):\n",
        "        self.num = 0\n",
        "        self.max_length = max_len\n",
        "        self.X = cupy.array(Thedataset_X)\n",
        "        self.Y = cupy.array(Thedataset_Y)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "        \n",
        "    def __iter__(self):\n",
        "        self.num = 0\n",
        "        return self\n",
        "    \n",
        "    def __next__(self):\n",
        "        if self.num >= self.max_length:\n",
        "            raise StopIteration\n",
        "\n",
        "        self.num += 1\n",
        "        return (from_dlpack(self.X.toDlpack()), from_dlpack(self.Y.toDlpack()))\n",
        "\n",
        "# print\n",
        "# ds = OptionDataSet(max_len = 1)\n",
        "# for i in ds:\n",
        "#     print(i[0])\n",
        "#     print(i[0].shape)\n",
        "#     print(i[1])\n",
        "#     print(i[1].shape)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rN6JO9OBHdvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea6ed72b-a5ed-4789-ab31-a642251874fb"
      },
      "source": [
        "%%writefile model.py\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden=1024, nstock = 1):\n",
        "        self.nstock = nstock\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(7*self.nstock, 128) # remember to change this!\n",
        "        self.fc2 = nn.Linear(128, 256)\n",
        "        self.fc3 = nn.Linear(256, 512)\n",
        "        self.fc4 = nn.Linear(512, 256)\n",
        "        self.fc5 = nn.Linear(256, 128)\n",
        "        self.fc6 = nn.Linear(128, nstock + 1) # outputs: prices, delta\n",
        "        self.register_buffer('norm',\n",
        "                             torch.tensor([1.0, 0.5, 0.5, 0.5, 0.3, 0.03, 0.03] * self.nstock)) # don't use numpy here - will give error later\n",
        "                                                                               # T, K, B, S, sigma, mu, r\n",
        "\n",
        "    def forward(self, x):\n",
        "        # normalize the parameter to range [0-1] \n",
        "        x = (x - torch.tensor([0.0, 0.75, 1.1, 0.75, 0.15, 0.01, 0.01] * self.nstock).cuda()) / self.norm\n",
        "        x = F.elu(self.fc1(x))\n",
        "        x = F.elu(self.fc2(x))\n",
        "        x = F.elu(self.fc3(x))\n",
        "        x = F.elu(self.fc4(x))\n",
        "        x = F.elu(self.fc5(x))\n",
        "        return self.fc6(x)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owSrICMvyZX0"
      },
      "source": [
        "# Train Neural Net"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlXD80xPNVc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0861b9c3-7b66-4ffa-e1b0-02b8ed9109af"
      },
      "source": [
        "!pip install pytorch-ignite"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.7-py3-none-any.whl (240 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▍                              | 10 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 20 kB 20.9 MB/s eta 0:00:01\r\u001b[K     |████                            | 30 kB 11.2 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 51 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 71 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 81 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 102 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 112 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 122 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 133 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 143 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 153 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 163 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 174 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 184 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 194 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 204 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 215 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 225 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 235 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 240 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from pytorch-ignite) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch<2,>=1.3->pytorch-ignite) (3.10.0.2)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeLVZiiaDS4y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7057dca0-226d-4b51-b717-3d991c0f0454"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3CyULkENYKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d309aee-f675-484f-81ba-95118f65e413"
      },
      "source": [
        "from ignite.engine import Engine, Events\n",
        "from ignite.handlers import Timer\n",
        "from torch.nn import MSELoss\n",
        "from torch.optim import Adam\n",
        "from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "from ignite.handlers import ModelCheckpoint\n",
        "from model import Net\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from torch.autograd import grad\n",
        "timer = Timer(average=True)\n",
        "model = Net(nstock = nstock).cuda()\n",
        "loss_fn = MSELoss()\n",
        "optimizer = Adam(model.parameters(), lr=1e-3)\n",
        "dataset = OptionDataSet(max_len = 100) # Use max_len to adjust\n",
        "\n",
        "def train_update(engine, batch):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    x = batch[0]\n",
        "    # print(x)\n",
        "    # print(x.shape)\n",
        "    y = batch[1]\n",
        "    # print(y)\n",
        "    # print(y.shape)\n",
        "    y_pred = model(x.float())\n",
        "    # print(y_pred)\n",
        "    # print(y_pred.shape)\n",
        "\n",
        "    # def compute_deltas(x):\n",
        "    #   inputs = x.float()\n",
        "    #   inputs.requires_grad = True\n",
        "    #   first_order_gradient = grad(model(inputs), inputs, create_graph=False)\n",
        "    #   return first_order_gradient[0][[3]]  # Now index 3 is stock price, not 2\n",
        "\n",
        "    # deltas = torch.stack([compute_deltas(x) for x in torch.unbind(x)], dim=0)\n",
        "    # y_pred = torch.cat((y_pred, deltas), 1)\n",
        "    # # print(y_pred)\n",
        "    # # print(y_pred.shape)\n",
        "\n",
        "    loss_weight = torch.tensor([1] * (nstock+1)).cuda()\n",
        "    loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "    loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "trainer = Engine(train_update)\n",
        "log_interval = 50\n",
        "\n",
        "scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "timer.attach(trainer,\n",
        "             start=Events.EPOCH_STARTED,\n",
        "             resume=Events.ITERATION_STARTED,\n",
        "             pause=Events.ITERATION_COMPLETED,\n",
        "             step=Events.ITERATION_COMPLETED)    \n",
        "@trainer.on(Events.ITERATION_COMPLETED)\n",
        "def log_training_loss(engine):\n",
        "    iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "    if iter % log_interval == 0:\n",
        "        print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "trainer.run(dataset, max_epochs = 1000)\n",
        "\n",
        "# model_save_name = f'jax_knock_out_{str(nstock)}stocks_oldmethod_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP Project/PUI/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss 0.0017730116978301985 average time 0.02117252141999984 iter num 50\n",
            "loss 0.0017055636817753538 average time 0.019761005410001076 iter num 100\n",
            "loss 0.0015653170293148042 average time 0.018287672359998054 iter num 50\n",
            "loss 0.0015251388456513511 average time 0.01828503602000012 iter num 100\n",
            "loss 0.0013072273215055878 average time 0.01829254060000267 iter num 50\n",
            "loss 0.0012301042489325975 average time 0.01830192365000073 iter num 100\n",
            "loss 0.0007988688967311435 average time 0.018374481799998534 iter num 50\n",
            "loss 0.0006891687275511879 average time 0.018342269600000235 iter num 100\n",
            "loss 0.0004517019724581849 average time 0.01833145396000191 iter num 50\n",
            "loss 0.00041632463685303865 average time 0.018353036940000324 iter num 100\n",
            "loss 0.00032892406565951425 average time 0.018295886780001068 iter num 50\n",
            "loss 0.0003179709043099917 average time 0.01831774795000058 iter num 100\n",
            "loss 0.00028922791973499376 average time 0.01828888073999906 iter num 50\n",
            "loss 0.00028360426006473474 average time 0.018294277799999464 iter num 100\n",
            "loss 0.00026508465326513877 average time 0.0183023103999966 iter num 50\n",
            "loss 0.0002592533583119672 average time 0.018314065759998072 iter num 100\n",
            "loss 0.00023903384941948602 average time 0.018306178319998024 iter num 50\n",
            "loss 0.0002334440643680864 average time 0.018309673569999064 iter num 100\n",
            "loss 0.00020808607171266108 average time 0.018337555559998577 iter num 50\n",
            "loss 0.0002007922395975842 average time 0.01832475619999741 iter num 100\n",
            "loss 0.00016761327066449326 average time 0.018350025299998834 iter num 50\n",
            "loss 0.000158395246252084 average time 0.018309062519998632 iter num 100\n",
            "loss 0.00013330702574783398 average time 0.018299704539999767 iter num 50\n",
            "loss 0.00012423545591109023 average time 0.018324251280001248 iter num 100\n",
            "loss 0.00010050859521237964 average time 0.018317290820002653 iter num 50\n",
            "loss 9.538998466561416e-05 average time 0.01831758992000232 iter num 100\n",
            "loss 7.792306743498401e-05 average time 0.018299379780002026 iter num 50\n",
            "loss 7.429586062240705e-05 average time 0.01831705237000335 iter num 100\n",
            "loss 6.177201839840505e-05 average time 0.018378488320006454 iter num 50\n",
            "loss 5.9086336137770284e-05 average time 0.018320420950004745 iter num 100\n",
            "loss 4.995313152308222e-05 average time 0.018313292279999588 iter num 50\n",
            "loss 4.796013740840824e-05 average time 0.018313277780000022 iter num 100\n",
            "loss 4.0653014775667965e-05 average time 0.018305146239996475 iter num 50\n",
            "loss 3.899971245849131e-05 average time 0.018301416479998237 iter num 100\n",
            "loss 3.3724766487693795e-05 average time 0.01829232123999759 iter num 50\n",
            "loss 3.216687285947211e-05 average time 0.018288170700001275 iter num 100\n",
            "loss 2.7592902211497957e-05 average time 0.018309241800004657 iter num 50\n",
            "loss 2.6578158427823583e-05 average time 0.01831052538000165 iter num 100\n",
            "loss 2.3114164271153222e-05 average time 0.018345633060000636 iter num 50\n",
            "loss 2.2279132861630116e-05 average time 0.018336707139999363 iter num 100\n",
            "loss 2.080514018717364e-05 average time 0.01827314704000514 iter num 50\n",
            "loss 1.9572653527164055e-05 average time 0.018285495310000784 iter num 100\n",
            "loss 1.7603428720451088e-05 average time 0.018272451159999717 iter num 50\n",
            "loss 1.7166897365458056e-05 average time 0.018279764900001966 iter num 100\n",
            "loss 1.7331479572980354e-05 average time 0.018301481299999978 iter num 50\n",
            "loss 1.5659843146040575e-05 average time 0.018298405539998727 iter num 100\n",
            "loss 1.4454379047440355e-05 average time 0.018261383840000464 iter num 50\n",
            "loss 1.4183121520264808e-05 average time 0.018292917880000915 iter num 100\n",
            "loss 1.3185189825615123e-05 average time 0.018288345280002432 iter num 50\n",
            "loss 1.2956749615519053e-05 average time 0.018293806840002275 iter num 100\n",
            "loss 1.2107783179841229e-05 average time 0.01829431060000047 iter num 50\n",
            "loss 1.1911233093540587e-05 average time 0.018286387319996038 iter num 100\n",
            "loss 1.292025402276648e-05 average time 0.018302855260004663 iter num 50\n",
            "loss 1.1240696529133355e-05 average time 0.01829384948000097 iter num 100\n",
            "loss 1.0616580299008602e-05 average time 0.018281131320003398 iter num 50\n",
            "loss 1.047067978964447e-05 average time 0.018287884670003224 iter num 100\n",
            "loss 9.916509494373328e-06 average time 0.018255659180000522 iter num 50\n",
            "loss 9.78489696567809e-06 average time 0.018301927209998327 iter num 100\n",
            "loss 9.281344522757086e-06 average time 0.018301794939999352 iter num 50\n",
            "loss 9.161172438762047e-06 average time 0.018292884169999867 iter num 100\n",
            "loss 9.450099722994727e-06 average time 0.018278695339998877 iter num 50\n",
            "loss 8.814397686577241e-06 average time 0.018296096859999694 iter num 100\n",
            "loss 8.409747688889403e-06 average time 0.018296455379995677 iter num 50\n",
            "loss 8.315080799134193e-06 average time 0.018275901239996985 iter num 100\n",
            "loss 7.955176984717406e-06 average time 0.018262058780002234 iter num 50\n",
            "loss 7.868617353733769e-06 average time 0.01827085209000245 iter num 100\n",
            "loss 7.603133048148047e-06 average time 0.018296806120007433 iter num 50\n",
            "loss 7.469918435195526e-06 average time 0.018298940110004196 iter num 100\n",
            "loss 9.127494975687263e-06 average time 0.018326081280004018 iter num 50\n",
            "loss 7.362014408229683e-06 average time 0.018305612780001753 iter num 100\n",
            "loss 7.0619851463749845e-06 average time 0.018272769279999466 iter num 50\n",
            "loss 6.9948201568829965e-06 average time 0.018284274879999316 iter num 100\n",
            "loss 6.740316861359338e-06 average time 0.018282129659994553 iter num 50\n",
            "loss 6.679282792886742e-06 average time 0.018276233029996546 iter num 100\n",
            "loss 6.443097941235511e-06 average time 0.018314940179997165 iter num 50\n",
            "loss 6.385940338143551e-06 average time 0.01831035752999867 iter num 100\n",
            "loss 6.1638082164021004e-06 average time 0.018311362199998484 iter num 50\n",
            "loss 6.1098654810089465e-06 average time 0.018300991879999628 iter num 100\n",
            "loss 5.900020820613936e-06 average time 0.018285451779998994 iter num 50\n",
            "loss 5.848753694085852e-06 average time 0.01829769360999933 iter num 100\n",
            "loss 6.592477925985236e-06 average time 0.018307414619997645 iter num 50\n",
            "loss 5.833179590248976e-06 average time 0.01832174435999775 iter num 100\n",
            "loss 5.638995521771717e-06 average time 0.018324198599998454 iter num 50\n",
            "loss 5.597316222666456e-06 average time 0.018289949440002715 iter num 100\n",
            "loss 5.437886106913864e-06 average time 0.018295436399999972 iter num 50\n",
            "loss 5.399213803194955e-06 average time 0.018306036009999502 iter num 100\n",
            "loss 5.248197777231737e-06 average time 0.018305757579997816 iter num 50\n",
            "loss 5.211282316403815e-06 average time 0.018302431079999907 iter num 100\n",
            "loss 5.066517508788031e-06 average time 0.018292797199999312 iter num 50\n",
            "loss 5.0310009242280875e-06 average time 0.018292200189999903 iter num 100\n",
            "loss 4.892459009952137e-06 average time 0.018298696019994624 iter num 50\n",
            "loss 4.857203140325415e-06 average time 0.018293045259995894 iter num 100\n",
            "loss 7.779994201105329e-06 average time 0.018326928120001185 iter num 50\n",
            "loss 4.9248177251836466e-06 average time 0.018298920440001323 iter num 100\n",
            "loss 4.764566786967097e-06 average time 0.01827797774000487 iter num 50\n",
            "loss 4.732817884958698e-06 average time 0.018271950380000134 iter num 100\n",
            "loss 4.61269165919931e-06 average time 0.01833663396000247 iter num 50\n",
            "loss 4.58375906837407e-06 average time 0.01831852854999795 iter num 100\n",
            "loss 4.470589837584014e-06 average time 0.01836003254000161 iter num 50\n",
            "loss 4.442805927827903e-06 average time 0.018360060080003678 iter num 100\n",
            "loss 4.333195420242982e-06 average time 0.018326671919993487 iter num 50\n",
            "loss 4.3061057673154635e-06 average time 0.0183390429599973 iter num 100\n",
            "loss 4.562850293203009e-06 average time 0.01832727570000088 iter num 50\n",
            "loss 4.197410678074815e-06 average time 0.018304496099999595 iter num 100\n",
            "loss 4.339372347583045e-06 average time 0.018313044900003204 iter num 50\n",
            "loss 4.1084322542037765e-06 average time 0.018356781370003433 iter num 100\n",
            "loss 4.008393568527006e-06 average time 0.018335198020001827 iter num 50\n",
            "loss 3.983918565306504e-06 average time 0.01830952448000005 iter num 100\n",
            "loss 3.887050792910059e-06 average time 0.018305721339997943 iter num 50\n",
            "loss 3.862944107130877e-06 average time 0.01830892840999809 iter num 100\n",
            "loss 3.92225853679609e-06 average time 0.018255809400001224 iter num 50\n",
            "loss 3.79925288627629e-06 average time 0.018292560379999257 iter num 100\n",
            "loss 3.7092246209694486e-06 average time 0.018288682239999618 iter num 50\n",
            "loss 3.6867107956859223e-06 average time 0.01827601500999833 iter num 100\n",
            "loss 4.099597618030192e-06 average time 0.018306427379997103 iter num 50\n",
            "loss 3.6267007311247965e-06 average time 0.018314570379998826 iter num 100\n",
            "loss 3.5379685915045508e-06 average time 0.01833421528000031 iter num 50\n",
            "loss 3.5166373781450093e-06 average time 0.01831733473999975 iter num 100\n",
            "loss 3.4360608464880253e-06 average time 0.01831087394000406 iter num 50\n",
            "loss 3.4146073522845877e-06 average time 0.01830183191000117 iter num 100\n",
            "loss 3.749956470060438e-06 average time 0.01829327689999559 iter num 50\n",
            "loss 3.4715881796070816e-06 average time 0.01828655909999668 iter num 100\n",
            "loss 3.372671312548667e-06 average time 0.018296214659998214 iter num 50\n",
            "loss 3.3524964543535403e-06 average time 0.018293038109999885 iter num 100\n",
            "loss 3.2749427000245907e-06 average time 0.018277920999996696 iter num 50\n",
            "loss 3.2559802651218454e-06 average time 0.018284164340001324 iter num 100\n",
            "loss 3.1823544554617095e-06 average time 0.018307314720002524 iter num 50\n",
            "loss 3.162407536287056e-06 average time 0.018303973909999625 iter num 100\n",
            "loss 4.9732760746987985e-06 average time 0.01833774989999938 iter num 50\n",
            "loss 3.309344075919311e-06 average time 0.018310522159998753 iter num 100\n",
            "loss 3.1959314577437655e-06 average time 0.01831046403999949 iter num 50\n",
            "loss 3.176183147633071e-06 average time 0.018283895809999534 iter num 100\n",
            "loss 3.104588963661667e-06 average time 0.018304065159999255 iter num 50\n",
            "loss 3.0876184292481274e-06 average time 0.018322115039998154 iter num 100\n",
            "loss 3.0213998523778088e-06 average time 0.018253663200000575 iter num 50\n",
            "loss 3.0051151769430266e-06 average time 0.01827735900999926 iter num 100\n",
            "loss 2.9405685333780994e-06 average time 0.018285617620000492 iter num 50\n",
            "loss 2.924512325503525e-06 average time 0.01829462239999998 iter num 100\n",
            "loss 2.8605259285971443e-06 average time 0.018286444080000592 iter num 50\n",
            "loss 2.8445409396519473e-06 average time 0.01825462401000266 iter num 100\n",
            "loss 2.782800317387482e-06 average time 0.018233829860001834 iter num 50\n",
            "loss 2.764848783355159e-06 average time 0.01826475522999715 iter num 100\n",
            "loss 2.9688977881497407e-06 average time 0.01823485432000098 iter num 50\n",
            "loss 2.7619958619917973e-06 average time 0.018251099519999342 iter num 100\n",
            "loss 2.6992936438524815e-06 average time 0.018271271780000688 iter num 50\n",
            "loss 2.684362426756925e-06 average time 0.018296904229999314 iter num 100\n",
            "loss 2.625727191666605e-06 average time 0.018350860760006072 iter num 50\n",
            "loss 2.611120693488593e-06 average time 0.018344700870003977 iter num 100\n",
            "loss 2.5621622476730797e-06 average time 0.01827624910000054 iter num 50\n",
            "loss 2.538999701317762e-06 average time 0.018285893780000038 iter num 100\n",
            "loss 4.158555212581956e-06 average time 0.018300500279999597 iter num 50\n",
            "loss 2.6595302479130086e-06 average time 0.018297731190000378 iter num 100\n",
            "loss 2.577016493421587e-06 average time 0.018304113860001508 iter num 50\n",
            "loss 2.5614271260494575e-06 average time 0.01829216906000056 iter num 100\n",
            "loss 2.5038736669638175e-06 average time 0.018294982199994366 iter num 50\n",
            "loss 2.490033383158663e-06 average time 0.018289418259997206 iter num 100\n",
            "loss 2.4356760799964915e-06 average time 0.018274222980003287 iter num 50\n",
            "loss 2.422239592690785e-06 average time 0.018279610360000902 iter num 100\n",
            "loss 2.37017243935053e-06 average time 0.01830395868000437 iter num 50\n",
            "loss 2.355625272957119e-06 average time 0.01831900790000134 iter num 100\n",
            "loss 4.4079732836999895e-06 average time 0.01827622175999977 iter num 50\n",
            "loss 2.4529444363702746e-06 average time 0.01828417968999929 iter num 100\n",
            "loss 2.3795683544756287e-06 average time 0.018318234920003534 iter num 50\n",
            "loss 2.3661130448238594e-06 average time 0.018303957010002706 iter num 100\n",
            "loss 2.316228672386212e-06 average time 0.018284556799999338 iter num 50\n",
            "loss 2.304248848791532e-06 average time 0.018291817520001245 iter num 100\n",
            "loss 2.257171654030815e-06 average time 0.018285024140000133 iter num 50\n",
            "loss 2.245526982277379e-06 average time 0.01830669222999802 iter num 100\n",
            "loss 2.1992299938604558e-06 average time 0.018323790580006973 iter num 50\n",
            "loss 2.1876858290478307e-06 average time 0.018314195990003553 iter num 100\n",
            "loss 2.1416311248409824e-06 average time 0.01825242800000183 iter num 50\n",
            "loss 2.1301189265551373e-06 average time 0.01827191212999935 iter num 100\n",
            "loss 2.0841277807416706e-06 average time 0.018290494339998985 iter num 50\n",
            "loss 2.072620873328416e-06 average time 0.01829338599000039 iter num 100\n",
            "loss 2.0267559801117395e-06 average time 0.01830625515999941 iter num 50\n",
            "loss 2.015129981204455e-06 average time 0.01830409118999853 iter num 100\n",
            "loss 3.4827367178480822e-06 average time 0.018283135620004033 iter num 50\n",
            "loss 2.097547145118221e-06 average time 0.018286311840002442 iter num 100\n",
            "loss 2.0364698496237293e-06 average time 0.018281843440005333 iter num 50\n",
            "loss 2.024694876477196e-06 average time 0.018276786279998875 iter num 100\n",
            "loss 1.980056279867468e-06 average time 0.018282855759996438 iter num 50\n",
            "loss 1.9692199028327546e-06 average time 0.01828730709999775 iter num 100\n",
            "loss 1.926481697516308e-06 average time 0.01829059872000471 iter num 50\n",
            "loss 1.915893320875357e-06 average time 0.018306232470002896 iter num 100\n",
            "loss 1.8884963901489067e-06 average time 0.018291365700001734 iter num 50\n",
            "loss 1.8647635886924477e-06 average time 0.018276085950001287 iter num 100\n",
            "loss 3.626968114368129e-06 average time 0.018287396220000574 iter num 50\n",
            "loss 1.949494101215382e-06 average time 0.018311983059996918 iter num 100\n",
            "loss 1.8920081075009968e-06 average time 0.01828564589999928 iter num 50\n",
            "loss 1.8812568001253847e-06 average time 0.018291841000000204 iter num 100\n",
            "loss 1.8411804228151328e-06 average time 0.018256408400000056 iter num 50\n",
            "loss 1.8314921802208373e-06 average time 0.018283965320001698 iter num 100\n",
            "loss 1.7934000818644855e-06 average time 0.018298746120002533 iter num 50\n",
            "loss 1.783987576608495e-06 average time 0.01828016729000012 iter num 100\n",
            "loss 1.7466431150399378e-06 average time 0.018279547799998 iter num 50\n",
            "loss 1.737352158061955e-06 average time 0.01828308746000232 iter num 100\n",
            "loss 1.728252969528314e-06 average time 0.01830375747999824 iter num 50\n",
            "loss 1.6927859389172597e-06 average time 0.018294447719997605 iter num 100\n",
            "loss 2.311537578204177e-06 average time 0.018303404199999703 iter num 50\n",
            "loss 1.8157971090244602e-06 average time 0.018269067840001867 iter num 100\n",
            "loss 1.7458476704387751e-06 average time 0.018274403200001642 iter num 50\n",
            "loss 1.7351541696297008e-06 average time 0.01827865147999944 iter num 100\n",
            "loss 1.697586769082382e-06 average time 0.018277869700001476 iter num 50\n",
            "loss 1.6889062305398746e-06 average time 0.01825903712000297 iter num 100\n",
            "loss 1.6552944077640824e-06 average time 0.01831730218000075 iter num 50\n",
            "loss 1.6470656407839995e-06 average time 0.018331858179997197 iter num 100\n",
            "loss 1.6145322890706367e-06 average time 0.01830351414000006 iter num 50\n",
            "loss 1.6064401781285413e-06 average time 0.018286742719999437 iter num 100\n",
            "loss 1.957713402807944e-06 average time 0.01832247924000285 iter num 50\n",
            "loss 1.6100655285822354e-06 average time 0.01832641929000033 iter num 100\n",
            "loss 1.5761332619057032e-06 average time 0.01832436774000257 iter num 50\n",
            "loss 1.5675802389319733e-06 average time 0.018311437260004483 iter num 100\n",
            "loss 1.5363716318234934e-06 average time 0.0182596230799993 iter num 50\n",
            "loss 1.5286282456494688e-06 average time 0.018292786499999353 iter num 100\n",
            "loss 1.497820574668077e-06 average time 0.01829428216000224 iter num 50\n",
            "loss 1.490136320124923e-06 average time 0.018311221759998376 iter num 100\n",
            "loss 1.4595112114757872e-06 average time 0.0182873143000063 iter num 50\n",
            "loss 1.4518303704195503e-06 average time 0.018298629889999914 iter num 100\n",
            "loss 1.5061954106630885e-06 average time 0.018291918699998178 iter num 50\n",
            "loss 1.4658323075682227e-06 average time 0.018302454239996564 iter num 100\n",
            "loss 1.553965774665607e-06 average time 0.018284581219998017 iter num 50\n",
            "loss 1.4388970938735036e-06 average time 0.01829910136999956 iter num 100\n",
            "loss 1.411422475149733e-06 average time 0.0183562929600032 iter num 50\n",
            "loss 1.4013812988789483e-06 average time 0.018328904250000732 iter num 100\n",
            "loss 1.729568100924234e-06 average time 0.018292720159996632 iter num 50\n",
            "loss 1.3956957832336848e-06 average time 0.018291658700001108 iter num 100\n",
            "loss 1.3649622213996498e-06 average time 0.01826427708001006 iter num 50\n",
            "loss 1.3574856904892516e-06 average time 0.01826901267000551 iter num 100\n",
            "loss 1.3776616538718337e-06 average time 0.01829605302000118 iter num 50\n",
            "loss 1.3285741722830615e-06 average time 0.01829396261000113 iter num 100\n",
            "loss 1.5335925542450207e-06 average time 0.018270783000002667 iter num 50\n",
            "loss 1.3141582592741436e-06 average time 0.01827583572000094 iter num 100\n",
            "loss 1.671889507667901e-06 average time 0.018300877500001887 iter num 50\n",
            "loss 1.3173954751614467e-06 average time 0.018299303160001727 iter num 100\n",
            "loss 1.286745038772392e-06 average time 0.018314136459994187 iter num 50\n",
            "loss 1.279783354822986e-06 average time 0.018295359739996117 iter num 100\n",
            "loss 1.2527243061040599e-06 average time 0.018285538579993953 iter num 50\n",
            "loss 1.2458394010640375e-06 average time 0.0182741759099963 iter num 100\n",
            "loss 2.9727749674522547e-06 average time 0.018304178619998765 iter num 50\n",
            "loss 1.3302011217783633e-06 average time 0.018295418859999017 iter num 100\n",
            "loss 1.2837967734186417e-06 average time 0.018328802300000006 iter num 50\n",
            "loss 1.276001179375853e-06 average time 0.01835781248999865 iter num 100\n",
            "loss 1.2478219339717808e-06 average time 0.01830141880000042 iter num 50\n",
            "loss 1.2411383241796823e-06 average time 0.018310179939999217 iter num 100\n",
            "loss 1.2151622186160252e-06 average time 0.01830164299999865 iter num 50\n",
            "loss 1.2088075199982642e-06 average time 0.018282600690001233 iter num 100\n",
            "loss 1.1875628435914038e-06 average time 0.018326476639999784 iter num 50\n",
            "loss 1.177840120425029e-06 average time 0.01829417674999945 iter num 100\n",
            "loss 1.4093190781631734e-06 average time 0.018293962760000112 iter num 50\n",
            "loss 1.2906453621496163e-06 average time 0.018289794519999986 iter num 100\n",
            "loss 1.2374364017738705e-06 average time 0.018274375999994846 iter num 50\n",
            "loss 1.2294289919240167e-06 average time 0.01827595407999638 iter num 100\n",
            "loss 1.202678819084992e-06 average time 0.018291069839998498 iter num 50\n",
            "loss 1.1965309495437268e-06 average time 0.0182657237699982 iter num 100\n",
            "loss 1.172806295850741e-06 average time 0.018271539600007144 iter num 50\n",
            "loss 1.1670255352022177e-06 average time 0.01826926272000662 iter num 100\n",
            "loss 1.1442686581956462e-06 average time 0.018275804739998874 iter num 50\n",
            "loss 1.1386486202570175e-06 average time 0.018276588319999405 iter num 100\n",
            "loss 1.1179146073454265e-06 average time 0.01828235084000539 iter num 50\n",
            "loss 1.1109387674256065e-06 average time 0.01826002301000699 iter num 100\n",
            "loss 1.991097539533496e-06 average time 0.01825017564000291 iter num 50\n",
            "loss 1.1862966340347398e-06 average time 0.01827496567000253 iter num 100\n",
            "loss 1.1455226072260856e-06 average time 0.018306637180000963 iter num 50\n",
            "loss 1.138307577705075e-06 average time 0.01829828407999855 iter num 100\n",
            "loss 1.113292845854596e-06 average time 0.018292770719997405 iter num 50\n",
            "loss 1.107414494780834e-06 average time 0.018284909770002855 iter num 100\n",
            "loss 1.0846532745233034e-06 average time 0.0183199154600004 iter num 50\n",
            "loss 1.0791014403518506e-06 average time 0.018282921059998784 iter num 100\n",
            "loss 1.0572512597068381e-06 average time 0.018265843040004483 iter num 50\n",
            "loss 1.051855018304074e-06 average time 0.018295072930002335 iter num 100\n",
            "loss 1.0375014549926563e-06 average time 0.01826107767999929 iter num 50\n",
            "loss 1.0256946155272425e-06 average time 0.018284307570002625 iter num 100\n",
            "loss 1.7235293001082547e-06 average time 0.018247871279996844 iter num 50\n",
            "loss 1.1171470092349062e-06 average time 0.018254011959997457 iter num 100\n",
            "loss 1.079463851300116e-06 average time 0.018327987680003162 iter num 50\n",
            "loss 1.0725483327542366e-06 average time 0.018330181120001045 iter num 100\n",
            "loss 1.0484007229607186e-06 average time 0.018301707940000824 iter num 50\n",
            "loss 1.0427371667791527e-06 average time 0.01829718390000096 iter num 100\n",
            "loss 1.020876948953647e-06 average time 0.01827156877999869 iter num 50\n",
            "loss 1.0155655845417694e-06 average time 0.018285752530001673 iter num 100\n",
            "loss 9.947341498377474e-07 average time 0.01831995772000255 iter num 50\n",
            "loss 9.896084663547758e-07 average time 0.018322582510003828 iter num 100\n",
            "loss 9.693653987300548e-07 average time 0.018304589939999685 iter num 50\n",
            "loss 9.643491503643694e-07 average time 0.01827653300000179 iter num 100\n",
            "loss 1.4398721907817e-06 average time 0.018262099500002477 iter num 50\n",
            "loss 1.0514665581133885e-06 average time 0.018274874379999913 iter num 100\n",
            "loss 1.0053291500987789e-06 average time 0.018292340520005154 iter num 50\n",
            "loss 9.985908256303947e-07 average time 0.018284242500002393 iter num 100\n",
            "loss 9.77079818794571e-07 average time 0.018260457059997178 iter num 50\n",
            "loss 9.721180879254915e-07 average time 0.018257769129998564 iter num 100\n",
            "loss 9.529864028272172e-07 average time 0.01828913818000274 iter num 50\n",
            "loss 9.482843340995236e-07 average time 0.018298218600003226 iter num 100\n",
            "loss 1.4023078974433149e-06 average time 0.0183266236799966 iter num 50\n",
            "loss 9.490109238918663e-07 average time 0.018322165439998914 iter num 100\n",
            "loss 9.285522028447469e-07 average time 0.01830784399999743 iter num 50\n",
            "loss 9.23856265749862e-07 average time 0.018305843500001515 iter num 100\n",
            "loss 9.060126212941536e-07 average time 0.01831870106000224 iter num 50\n",
            "loss 9.016265648821696e-07 average time 0.01832126954000046 iter num 100\n",
            "loss 8.842917678107404e-07 average time 0.018275521499988373 iter num 50\n",
            "loss 8.799957662689388e-07 average time 0.018271813239995254 iter num 100\n",
            "loss 9.299461002490637e-07 average time 0.01829793522000273 iter num 50\n",
            "loss 8.639427161642901e-07 average time 0.0183259614500048 iter num 100\n",
            "loss 1.2443817005762088e-06 average time 0.01833429699999442 iter num 50\n",
            "loss 9.381044543275085e-07 average time 0.018309496419996095 iter num 100\n",
            "loss 9.051582099994424e-07 average time 0.018335812320008246 iter num 50\n",
            "loss 8.992877667145006e-07 average time 0.018316960810003592 iter num 100\n",
            "loss 8.788047107784647e-07 average time 0.018273225900009037 iter num 50\n",
            "loss 8.740697951650005e-07 average time 0.018279778730009185 iter num 100\n",
            "loss 8.559510018558151e-07 average time 0.018273061879997384 iter num 50\n",
            "loss 8.515648184395698e-07 average time 0.01829001495999705 iter num 100\n",
            "loss 1.2091279429837177e-06 average time 0.01823812917999703 iter num 50\n",
            "loss 8.710286478981815e-07 average time 0.018242149589998462 iter num 100\n",
            "loss 8.497722570779026e-07 average time 0.018343413739994503 iter num 50\n",
            "loss 8.444909621710374e-07 average time 0.01832642707999298 iter num 100\n",
            "loss 8.27474234219226e-07 average time 0.018270986860004543 iter num 50\n",
            "loss 8.233497645143905e-07 average time 0.018286503730006416 iter num 100\n",
            "loss 8.07161803799405e-07 average time 0.018336858200011647 iter num 50\n",
            "loss 8.031749080382838e-07 average time 0.01832496255000251 iter num 100\n",
            "loss 8.135281366520658e-07 average time 0.0183109166200029 iter num 50\n",
            "loss 7.878876264401785e-07 average time 0.018309759720002605 iter num 100\n",
            "loss 1.1332368891808181e-06 average time 0.018305885380009386 iter num 50\n",
            "loss 8.227966822883963e-07 average time 0.018293591120007023 iter num 100\n",
            "loss 8.013910060031658e-07 average time 0.01826263914000265 iter num 50\n",
            "loss 7.969494658071013e-07 average time 0.018287278879995483 iter num 100\n",
            "loss 7.80352994192442e-07 average time 0.018264681439993637 iter num 50\n",
            "loss 7.763741135208976e-07 average time 0.018293229919999023 iter num 100\n",
            "loss 7.634424190704099e-07 average time 0.018290059220012155 iter num 50\n",
            "loss 7.572312908134127e-07 average time 0.01829875369000888 iter num 100\n",
            "loss 1.4800745595827885e-06 average time 0.01832841641999039 iter num 50\n",
            "loss 8.545550915170647e-07 average time 0.018325674289997096 iter num 100\n",
            "loss 8.149328665741552e-07 average time 0.018316570580000188 iter num 50\n",
            "loss 8.088718270652982e-07 average time 0.018302255519997743 iter num 100\n",
            "loss 7.88245157650226e-07 average time 0.018256152420003672 iter num 50\n",
            "loss 7.836324499989367e-07 average time 0.018262230300001646 iter num 100\n",
            "loss 7.662929684973335e-07 average time 0.01828984463999632 iter num 50\n",
            "loss 7.621745901571823e-07 average time 0.018302074709999942 iter num 100\n",
            "loss 7.462402192821121e-07 average time 0.018258689740002866 iter num 50\n",
            "loss 7.423677736961815e-07 average time 0.01829388508000079 iter num 100\n",
            "loss 7.353355959341729e-07 average time 0.018320407960009107 iter num 50\n",
            "loss 7.240360957536447e-07 average time 0.018297297580005534 iter num 100\n",
            "loss 1.8927123097895702e-06 average time 0.01834143355999686 iter num 50\n",
            "loss 8.040945793964806e-07 average time 0.018341626109995558 iter num 100\n",
            "loss 7.733850052262088e-07 average time 0.018348176379997767 iter num 50\n",
            "loss 7.679794330163983e-07 average time 0.01834030836999318 iter num 100\n",
            "loss 7.491610852833679e-07 average time 0.01827348538000024 iter num 50\n",
            "loss 7.448566664063224e-07 average time 0.01829442967000091 iter num 100\n",
            "loss 7.2852201962384e-07 average time 0.018291282940008386 iter num 50\n",
            "loss 7.24615731598022e-07 average time 0.018275988730000563 iter num 100\n",
            "loss 7.098621199633599e-07 average time 0.018336565660004 iter num 50\n",
            "loss 7.058939539441954e-07 average time 0.01831473538000296 iter num 100\n",
            "loss 2.314451010112296e-06 average time 0.018335167059995 iter num 50\n",
            "loss 8.005281575739575e-07 average time 0.018340658869992695 iter num 100\n",
            "loss 7.594955924849499e-07 average time 0.018319256299985227 iter num 50\n",
            "loss 7.540939873267583e-07 average time 0.018331375029985112 iter num 100\n",
            "loss 7.364349909536958e-07 average time 0.01837553135999542 iter num 50\n",
            "loss 7.324853545971282e-07 average time 0.01834148781999829 iter num 100\n",
            "loss 7.175836296516816e-07 average time 0.018279645299999175 iter num 50\n",
            "loss 7.140400039934178e-07 average time 0.018300121260003833 iter num 100\n",
            "loss 7.003505417146729e-07 average time 0.01829048792000094 iter num 50\n",
            "loss 6.970342355104958e-07 average time 0.018305455579999262 iter num 100\n",
            "loss 6.840881502939655e-07 average time 0.018299026659985885 iter num 50\n",
            "loss 6.809220141168706e-07 average time 0.01829437553999469 iter num 100\n",
            "loss 6.684854868876378e-07 average time 0.018282779580006264 iter num 50\n",
            "loss 6.654270838468886e-07 average time 0.01829514766999978 iter num 100\n",
            "loss 6.538761798018387e-07 average time 0.018264741079997295 iter num 50\n",
            "loss 6.504335035883648e-07 average time 0.018264182100000425 iter num 100\n",
            "loss 1.5590736432533652e-06 average time 0.018280068140002187 iter num 50\n",
            "loss 7.293171296516646e-07 average time 0.018284271880000914 iter num 100\n",
            "loss 6.878550868957852e-07 average time 0.01827445428000601 iter num 50\n",
            "loss 6.824394372751235e-07 average time 0.01828767922001134 iter num 100\n",
            "loss 6.649535581901375e-07 average time 0.018303334479992373 iter num 50\n",
            "loss 6.611295747985247e-07 average time 0.01830751779999446 iter num 100\n",
            "loss 6.469624126893356e-07 average time 0.018302119580000636 iter num 50\n",
            "loss 6.43476528787021e-07 average time 0.01828564336999989 iter num 100\n",
            "loss 9.216561965375968e-07 average time 0.018290558319999945 iter num 50\n",
            "loss 6.752239160133927e-07 average time 0.01827895254000282 iter num 100\n",
            "loss 6.559469676782379e-07 average time 0.01828060048000225 iter num 50\n",
            "loss 6.518833389383892e-07 average time 0.018283195289994864 iter num 100\n",
            "loss 6.38073775721476e-07 average time 0.018318253980005465 iter num 50\n",
            "loss 6.34799986751699e-07 average time 0.01830725096000151 iter num 100\n",
            "loss 6.221620853158059e-07 average time 0.018291650479995952 iter num 50\n",
            "loss 6.190708321239457e-07 average time 0.01827701014999775 iter num 100\n",
            "loss 1.2758730244902922e-06 average time 0.018311172299991085 iter num 50\n",
            "loss 6.360363525062378e-07 average time 0.018307521719996202 iter num 100\n",
            "loss 6.204998321352915e-07 average time 0.01824829276000173 iter num 50\n",
            "loss 6.168792461802002e-07 average time 0.018274834539998893 iter num 100\n",
            "loss 6.04554858074203e-07 average time 0.01829254141998945 iter num 50\n",
            "loss 6.016044751550856e-07 average time 0.018278456879993427 iter num 100\n",
            "loss 5.901246923637915e-07 average time 0.018294292279999808 iter num 50\n",
            "loss 5.873217036771468e-07 average time 0.018288880769997604 iter num 100\n",
            "loss 5.775137345091818e-07 average time 0.018297913480007536 iter num 50\n",
            "loss 5.737206975779107e-07 average time 0.01829603375000602 iter num 100\n",
            "loss 8.296443245616875e-07 average time 0.01828476226000021 iter num 50\n",
            "loss 6.171933581244604e-07 average time 0.018300556159998677 iter num 100\n",
            "loss 5.983021511127112e-07 average time 0.01833234285998742 iter num 50\n",
            "loss 5.946708325636486e-07 average time 0.018330527839998466 iter num 100\n",
            "loss 5.82471312309729e-07 average time 0.01831696980000288 iter num 50\n",
            "loss 5.796682313477679e-07 average time 0.01831515513000227 iter num 100\n",
            "loss 5.697962244454597e-07 average time 0.018295751440016373 iter num 50\n",
            "loss 5.665011604833393e-07 average time 0.018275212000011153 iter num 100\n",
            "loss 1.2364913487162283e-06 average time 0.01828772779998417 iter num 50\n",
            "loss 6.310516472166163e-07 average time 0.018295753809990174 iter num 100\n",
            "loss 6.040192930582683e-07 average time 0.018315614359996745 iter num 50\n",
            "loss 5.998409537687384e-07 average time 0.01831076487000246 iter num 100\n",
            "loss 5.864454816511715e-07 average time 0.018313010160004525 iter num 50\n",
            "loss 5.8341687518456e-07 average time 0.018315726750001884 iter num 100\n",
            "loss 5.71999515769902e-07 average time 0.01830086183999583 iter num 50\n",
            "loss 5.692899538068956e-07 average time 0.01829771547999485 iter num 100\n",
            "loss 5.588522152349533e-07 average time 0.01825490319999744 iter num 50\n",
            "loss 5.563201773043333e-07 average time 0.01826597044000323 iter num 100\n",
            "loss 8.889713206514129e-07 average time 0.018284040860007737 iter num 50\n",
            "loss 5.58384192034347e-07 average time 0.01832716805000473 iter num 100\n",
            "loss 5.466396701345102e-07 average time 0.018311189259998174 iter num 50\n",
            "loss 5.441125915332035e-07 average time 0.018291465400001244 iter num 100\n",
            "loss 5.344167989060949e-07 average time 0.01830854557999828 iter num 50\n",
            "loss 5.320559185145729e-07 average time 0.018314359459998285 iter num 100\n",
            "loss 6.121481096845311e-07 average time 0.01829130079999686 iter num 50\n",
            "loss 5.264638515956139e-07 average time 0.01830230282999537 iter num 100\n",
            "loss 8.346288221996954e-07 average time 0.01828188292000277 iter num 50\n",
            "loss 5.372406301522324e-07 average time 0.01827514895000263 iter num 100\n",
            "loss 5.247783771618626e-07 average time 0.01834058775999665 iter num 50\n",
            "loss 5.221372408659117e-07 average time 0.018329669739999874 iter num 100\n",
            "loss 5.136020020391937e-07 average time 0.018343564079996214 iter num 50\n",
            "loss 5.105226214499633e-07 average time 0.018324580460002834 iter num 100\n",
            "loss 9.526547439933918e-07 average time 0.01827739206000615 iter num 50\n",
            "loss 5.557116422601102e-07 average time 0.01827973386000167 iter num 100\n",
            "loss 5.34379835722602e-07 average time 0.018277590819984653 iter num 50\n",
            "loss 5.308120379074169e-07 average time 0.018286072399989736 iter num 100\n",
            "loss 5.196678953636733e-07 average time 0.01827566651999632 iter num 50\n",
            "loss 5.171263634006465e-07 average time 0.018276829010001164 iter num 100\n",
            "loss 5.075223764005043e-07 average time 0.01832814697999538 iter num 50\n",
            "loss 5.052261550009684e-07 average time 0.018301275819991362 iter num 100\n",
            "loss 5.913076267132713e-07 average time 0.01831024062000324 iter num 50\n",
            "loss 5.044428361740331e-07 average time 0.018295720889997254 iter num 100\n",
            "loss 5.032497082067957e-07 average time 0.01827664928000104 iter num 50\n",
            "loss 4.978421871488864e-07 average time 0.018289727870009074 iter num 100\n",
            "loss 4.970449587630207e-07 average time 0.018308028039994043 iter num 50\n",
            "loss 4.884622212050319e-07 average time 0.018281880529997352 iter num 100\n",
            "loss 8.536839167020585e-07 average time 0.018310484820003695 iter num 50\n",
            "loss 4.989616317971046e-07 average time 0.018312675540006467 iter num 100\n",
            "loss 4.875885195270947e-07 average time 0.018316085080002723 iter num 50\n",
            "loss 4.85223606761278e-07 average time 0.018322659699999803 iter num 100\n",
            "loss 4.836902041346701e-07 average time 0.01831262684000194 iter num 50\n",
            "loss 4.7490024810364305e-07 average time 0.018278311680001026 iter num 100\n",
            "loss 8.829929704259159e-07 average time 0.01829942984000354 iter num 50\n",
            "loss 5.21518249671196e-07 average time 0.01828214036999839 iter num 100\n",
            "loss 5.005326594133402e-07 average time 0.018307486499995775 iter num 50\n",
            "loss 4.969244333189763e-07 average time 0.018301185229994417 iter num 100\n",
            "loss 4.857428944910983e-07 average time 0.018272598539995216 iter num 50\n",
            "loss 4.832748866583126e-07 average time 0.01827208162000261 iter num 100\n",
            "loss 4.745169648679789e-07 average time 0.018274911460005115 iter num 50\n",
            "loss 4.7193146837040253e-07 average time 0.01830162237000195 iter num 100\n",
            "loss 1.3208743166965028e-06 average time 0.018239279159995476 iter num 50\n",
            "loss 5.224606299788622e-07 average time 0.01827803229999404 iter num 100\n",
            "loss 4.985962417506924e-07 average time 0.018300935920008213 iter num 50\n",
            "loss 4.951946447520723e-07 average time 0.018283290420008598 iter num 100\n",
            "loss 4.840805459648584e-07 average time 0.018307536580000488 iter num 50\n",
            "loss 4.816126665693177e-07 average time 0.01831584985000063 iter num 100\n",
            "loss 4.724232835988291e-07 average time 0.018374924299996563 iter num 50\n",
            "loss 4.7026702426644183e-07 average time 0.01834692424999389 iter num 100\n",
            "loss 4.620251256220615e-07 average time 0.018252323680012523 iter num 50\n",
            "loss 4.600430458468924e-07 average time 0.01825281382000867 iter num 100\n",
            "loss 7.889214839686483e-07 average time 0.018309021159991515 iter num 50\n",
            "loss 4.624682239854758e-07 average time 0.018299643509999443 iter num 100\n",
            "loss 4.522680005341541e-07 average time 0.01829283079999868 iter num 50\n",
            "loss 4.5025200189063e-07 average time 0.01831420383999557 iter num 100\n",
            "loss 5.163688129745529e-07 average time 0.018258891240002413 iter num 50\n",
            "loss 4.4476418839750596e-07 average time 0.018273938440000848 iter num 100\n",
            "loss 4.673200394769493e-07 average time 0.01832150386000876 iter num 50\n",
            "loss 4.4314172489329227e-07 average time 0.018313566910006785 iter num 100\n",
            "loss 4.992789616652551e-07 average time 0.018310879060004483 iter num 50\n",
            "loss 4.498687767281194e-07 average time 0.018297519510006167 iter num 100\n",
            "loss 4.4018077773236674e-07 average time 0.01830350197999678 iter num 50\n",
            "loss 4.3812742958011906e-07 average time 0.018271841339999356 iter num 100\n",
            "loss 4.3051992071377973e-07 average time 0.018287855779997243 iter num 50\n",
            "loss 4.2871006193045726e-07 average time 0.01828827899999851 iter num 100\n",
            "loss 5.736603041236671e-07 average time 0.018263290060006057 iter num 50\n",
            "loss 4.3225134271648364e-07 average time 0.018245301760002802 iter num 100\n",
            "loss 4.374761846090932e-07 average time 0.018301751319995674 iter num 50\n",
            "loss 4.2419132077042915e-07 average time 0.018296156239999847 iter num 100\n",
            "loss 4.798014317090789e-07 average time 0.01827329711999937 iter num 50\n",
            "loss 4.411869791840223e-07 average time 0.018271203369999968 iter num 100\n",
            "loss 4.305941824301941e-07 average time 0.018297115600005326 iter num 50\n",
            "loss 4.2545486428865517e-07 average time 0.018304114860002302 iter num 100\n",
            "loss 5.456844138823636e-07 average time 0.01828452519999246 iter num 50\n",
            "loss 4.3021276513121754e-07 average time 0.018294901609998533 iter num 100\n",
            "loss 4.2057775714329673e-07 average time 0.01825256512001033 iter num 50\n",
            "loss 4.185422004899736e-07 average time 0.018269094180004684 iter num 100\n",
            "loss 4.224262109257824e-07 average time 0.01832870334000518 iter num 50\n",
            "loss 4.1095361613107893e-07 average time 0.01830319982000219 iter num 100\n",
            "loss 5.276245874871746e-07 average time 0.018319258220001303 iter num 50\n",
            "loss 4.4974040975783255e-07 average time 0.018298085250007715 iter num 100\n",
            "loss 4.309011392221691e-07 average time 0.018297222900002907 iter num 50\n",
            "loss 4.280912461916725e-07 average time 0.018291096180006433 iter num 100\n",
            "loss 4.186885105023543e-07 average time 0.018342202140008795 iter num 50\n",
            "loss 4.1662164320444904e-07 average time 0.018303777680002895 iter num 100\n",
            "loss 4.0891943268420843e-07 average time 0.018265781959994457 iter num 50\n",
            "loss 4.0710034061202927e-07 average time 0.01827933862999771 iter num 100\n",
            "loss 9.612475807765814e-07 average time 0.018313338759990073 iter num 50\n",
            "loss 4.1891907305542335e-07 average time 0.018308297669996136 iter num 100\n",
            "loss 4.0941478521530477e-07 average time 0.018284444819994406 iter num 50\n",
            "loss 4.0688032677664506e-07 average time 0.018295397229995843 iter num 100\n",
            "loss 3.995271312413725e-07 average time 0.018280373100003543 iter num 50\n",
            "loss 3.977928397897028e-07 average time 0.01829575172999853 iter num 100\n",
            "loss 4.45499269155103e-07 average time 0.01828147688000854 iter num 50\n",
            "loss 3.9177249325998634e-07 average time 0.018278154530003123 iter num 100\n",
            "loss 7.674430010660593e-07 average time 0.018305710340000586 iter num 50\n",
            "loss 4.136813214502655e-07 average time 0.018287653250000632 iter num 100\n",
            "loss 4.0155262209304686e-07 average time 0.01832681232000141 iter num 50\n",
            "loss 3.9938270644078323e-07 average time 0.018308584559999872 iter num 100\n",
            "loss 3.920282642272267e-07 average time 0.018256603679988076 iter num 50\n",
            "loss 3.9035338633594205e-07 average time 0.018263051659993153 iter num 100\n",
            "loss 3.8403605807698136e-07 average time 0.01827648975999864 iter num 50\n",
            "loss 3.8250849202255356e-07 average time 0.01829091143999676 iter num 100\n",
            "loss 9.668791499108142e-07 average time 0.01831043162000242 iter num 50\n",
            "loss 4.002065460710284e-07 average time 0.018285909800001717 iter num 100\n",
            "loss 3.875789366209668e-07 average time 0.018303661059994737 iter num 50\n",
            "loss 3.8555062642443625e-07 average time 0.018304847890003657 iter num 100\n",
            "loss 4.051391428258422e-07 average time 0.018270727999999962 iter num 50\n",
            "loss 3.7834724327257033e-07 average time 0.018282476549994726 iter num 100\n",
            "loss 7.008018185346543e-07 average time 0.018294000939997657 iter num 50\n",
            "loss 4.1278288928158686e-07 average time 0.018262454099999558 iter num 100\n",
            "loss 3.9726135913558796e-07 average time 0.018307922360002067 iter num 50\n",
            "loss 3.9469260831560086e-07 average time 0.018318572419998416 iter num 100\n",
            "loss 3.862145634554472e-07 average time 0.01830198404001294 iter num 50\n",
            "loss 3.84359722813625e-07 average time 0.01829395947000194 iter num 100\n",
            "loss 3.782484220379899e-07 average time 0.01821855042000834 iter num 50\n",
            "loss 3.759788814386444e-07 average time 0.018231872700006306 iter num 100\n",
            "loss 1.0374887350293458e-06 average time 0.01824306126000238 iter num 50\n",
            "loss 4.212588187352495e-07 average time 0.01826831899000581 iter num 100\n",
            "loss 4.0117982000756764e-07 average time 0.018290039579992482 iter num 50\n",
            "loss 3.981235618433818e-07 average time 0.01829211019999775 iter num 100\n",
            "loss 3.888623916850753e-07 average time 0.018297147439996025 iter num 50\n",
            "loss 3.868620954627899e-07 average time 0.018294012029996337 iter num 100\n",
            "loss 3.795452370556949e-07 average time 0.01825848548000522 iter num 50\n",
            "loss 3.778551762041027e-07 average time 0.018273697740003172 iter num 100\n",
            "loss 3.714550972494189e-07 average time 0.01832055655999284 iter num 50\n",
            "loss 3.699337742369186e-07 average time 0.018291978789992527 iter num 100\n",
            "loss 4.2420269568136657e-07 average time 0.018284993280005893 iter num 50\n",
            "loss 3.655205620464866e-07 average time 0.01826828051000348 iter num 100\n",
            "loss 3.9809615558486426e-07 average time 0.018265345600004822 iter num 50\n",
            "loss 3.6241066736829115e-07 average time 0.018264105360000258 iter num 100\n",
            "loss 3.59028262589695e-07 average time 0.018294732039996688 iter num 50\n",
            "loss 3.567156630172666e-07 average time 0.01829605695999476 iter num 100\n",
            "loss 3.940449611824033e-07 average time 0.018325042100000247 iter num 50\n",
            "loss 3.7136202196713103e-07 average time 0.018318533749999234 iter num 100\n",
            "loss 3.611213520148225e-07 average time 0.01833135861999381 iter num 50\n",
            "loss 3.59284016237589e-07 average time 0.01829926789999604 iter num 100\n",
            "loss 3.544511428238463e-07 average time 0.018260335119996397 iter num 50\n",
            "loss 3.521662255750425e-07 average time 0.01823418778999894 iter num 100\n",
            "loss 4.901951679825575e-07 average time 0.018255453800004488 iter num 50\n",
            "loss 3.919352657756278e-07 average time 0.018254632959996117 iter num 100\n",
            "loss 3.706912007698955e-07 average time 0.018254266640010428 iter num 50\n",
            "loss 3.6757951944047875e-07 average time 0.01827271471000472 iter num 100\n",
            "loss 4.2312058572574116e-07 average time 0.018329060460005167 iter num 50\n",
            "loss 3.634496783520486e-07 average time 0.018314494260008588 iter num 100\n",
            "loss 3.556985401585938e-07 average time 0.018310870879997766 iter num 50\n",
            "loss 3.539102502145502e-07 average time 0.018302614719998472 iter num 100\n",
            "loss 3.478596390559315e-07 average time 0.018301842840003246 iter num 50\n",
            "loss 3.4640363713348905e-07 average time 0.018296655310001596 iter num 100\n",
            "loss 3.6559444627093854e-07 average time 0.01822640968000087 iter num 50\n",
            "loss 3.4756888846445206e-07 average time 0.018252078039998877 iter num 100\n",
            "loss 5.758344385981497e-07 average time 0.01826144235999891 iter num 50\n",
            "loss 3.6686850070741176e-07 average time 0.01826850824000303 iter num 100\n",
            "loss 3.5430366248191716e-07 average time 0.018281676980004703 iter num 50\n",
            "loss 3.5229455219120544e-07 average time 0.018287675070002934 iter num 100\n",
            "loss 3.4545633974861707e-07 average time 0.018303518940015237 iter num 50\n",
            "loss 3.4392381706594856e-07 average time 0.018295001050007614 iter num 100\n",
            "loss 3.3818150226061883e-07 average time 0.018306166700003814 iter num 50\n",
            "loss 3.368261912144494e-07 average time 0.01831175203000612 iter num 100\n",
            "loss 3.63475787233165e-07 average time 0.018259638280005673 iter num 50\n",
            "loss 3.3119585289078304e-07 average time 0.018257841320000807 iter num 100\n",
            "loss 5.296602319008956e-07 average time 0.018281398280003032 iter num 50\n",
            "loss 3.8835679598912943e-07 average time 0.018269760999999107 iter num 100\n",
            "loss 3.6216706275409125e-07 average time 0.018239859439997872 iter num 50\n",
            "loss 3.58840520248985e-07 average time 0.01825358500999755 iter num 100\n",
            "loss 3.4904993098903424e-07 average time 0.018265755180009363 iter num 50\n",
            "loss 3.4705004996218855e-07 average time 0.018270416050003176 iter num 100\n",
            "loss 3.9727907291751857e-07 average time 0.018298933699995815 iter num 50\n",
            "loss 3.4311075641019603e-07 average time 0.018276690029996417 iter num 100\n",
            "loss 3.365133301498538e-07 average time 0.018285033300003306 iter num 50\n",
            "loss 3.3494688194145375e-07 average time 0.018272603240002353 iter num 100\n",
            "loss 4.3826707943801864e-07 average time 0.018279108540002652 iter num 50\n",
            "loss 3.332101306634632e-07 average time 0.018272608789997095 iter num 100\n",
            "loss 3.3477132080013633e-07 average time 0.018284922520010696 iter num 50\n",
            "loss 3.275689398344559e-07 average time 0.018292996010010255 iter num 100\n",
            "loss 5.977067128019036e-07 average time 0.018280210120001358 iter num 50\n",
            "loss 3.4912313706806136e-07 average time 0.018282671570011642 iter num 100\n",
            "loss 3.3721682347090687e-07 average time 0.018299684120008805 iter num 50\n",
            "loss 3.3524678785414133e-07 average time 0.01829956978000041 iter num 100\n",
            "loss 3.293796488067241e-07 average time 0.018268937019993246 iter num 50\n",
            "loss 3.2723769437741545e-07 average time 0.018272181739995404 iter num 100\n",
            "loss 4.125163379580162e-07 average time 0.0182550949199981 iter num 50\n",
            "loss 3.4444283733330604e-07 average time 0.018272185050000188 iter num 100\n",
            "loss 3.323770922229698e-07 average time 0.01826057938000304 iter num 50\n",
            "loss 3.305803261774689e-07 average time 0.018268902940001226 iter num 100\n",
            "loss 3.244649711555502e-07 average time 0.018303225659990402 iter num 50\n",
            "loss 3.230959706366425e-07 average time 0.018301990649994195 iter num 100\n",
            "loss 3.667870513515093e-07 average time 0.018282000380002047 iter num 50\n",
            "loss 3.2301633962847155e-07 average time 0.01828278318000116 iter num 100\n",
            "loss 3.172595254146337e-07 average time 0.01827178283999501 iter num 50\n",
            "loss 3.159740935749942e-07 average time 0.018287594919999036 iter num 100\n",
            "loss 3.187098942646422e-07 average time 0.018298417500009236 iter num 50\n",
            "loss 3.1056670676761553e-07 average time 0.01829600267000501 iter num 100\n",
            "loss 8.64490206137418e-07 average time 0.018270579699999415 iter num 50\n",
            "loss 3.354803982390966e-07 average time 0.018288173029994824 iter num 100\n",
            "loss 3.2332522099376695e-07 average time 0.01830863846000739 iter num 50\n",
            "loss 3.2144774727807413e-07 average time 0.018292842280002334 iter num 100\n",
            "loss 3.1517817139281913e-07 average time 0.01826669380000567 iter num 50\n",
            "loss 3.1379395338675815e-07 average time 0.01827739771000324 iter num 100\n",
            "loss 3.086915756482936e-07 average time 0.018279095079992657 iter num 50\n",
            "loss 3.074264275982802e-07 average time 0.018297823840000546 iter num 100\n",
            "loss 6.352766423537322e-07 average time 0.018305175560001316 iter num 50\n",
            "loss 3.242734003988446e-07 average time 0.018287703470002727 iter num 100\n",
            "loss 3.149814249823059e-07 average time 0.018292334659988682 iter num 50\n",
            "loss 3.133449391181248e-07 average time 0.018313848039994127 iter num 100\n",
            "loss 3.4762474372698565e-07 average time 0.018323623880003196 iter num 50\n",
            "loss 3.1046753990240346e-07 average time 0.018309444549994395 iter num 100\n",
            "loss 3.489671765465184e-07 average time 0.018287986240002285 iter num 50\n",
            "loss 3.0554538123880533e-07 average time 0.018294158880005396 iter num 100\n",
            "loss 3.042266298091918e-07 average time 0.018297576459992797 iter num 50\n",
            "loss 2.99729093102007e-07 average time 0.018317388469998832 iter num 100\n",
            "loss 6.33250748656837e-07 average time 0.018309553419994698 iter num 50\n",
            "loss 3.1975500125288775e-07 average time 0.018295766719995755 iter num 100\n",
            "loss 3.098576189498462e-07 average time 0.01829152046000445 iter num 50\n",
            "loss 3.081060432794681e-07 average time 0.018275588250000963 iter num 100\n",
            "loss 3.023327337195368e-07 average time 0.018238923779999822 iter num 50\n",
            "loss 3.010447495717371e-07 average time 0.01826256709000063 iter num 100\n",
            "loss 3.124453615380595e-07 average time 0.018266169299995454 iter num 50\n",
            "loss 2.956703434760846e-07 average time 0.018255039659999285 iter num 100\n",
            "loss 8.950422516305934e-07 average time 0.01826600525999311 iter num 50\n",
            "loss 3.4275241830401426e-07 average time 0.018265596919994777 iter num 100\n",
            "loss 3.1795153633563683e-07 average time 0.018308983839999654 iter num 50\n",
            "loss 3.1514926806353086e-07 average time 0.018296205340002415 iter num 100\n",
            "loss 3.0679459157251406e-07 average time 0.018269555180011138 iter num 50\n",
            "loss 3.0509982870916913e-07 average time 0.018289951140006908 iter num 100\n",
            "loss 3.0941109806034096e-07 average time 0.018339852499996142 iter num 50\n",
            "loss 2.9868276726090346e-07 average time 0.01830809729000066 iter num 100\n",
            "loss 4.6121006316161844e-07 average time 0.018270175459988422 iter num 50\n",
            "loss 3.067391895881583e-07 average time 0.018253866309996737 iter num 100\n",
            "loss 2.9873830135984444e-07 average time 0.01828051045999018 iter num 50\n",
            "loss 2.9713865068072014e-07 average time 0.018288077619993147 iter num 100\n",
            "loss 2.920151240010354e-07 average time 0.018264593960011552 iter num 50\n",
            "loss 2.90831801521319e-07 average time 0.018272356430007904 iter num 100\n",
            "loss 3.245444614075006e-07 average time 0.018287901599983343 iter num 50\n",
            "loss 2.92562483596574e-07 average time 0.018295370439998352 iter num 100\n",
            "loss 2.996457003386292e-07 average time 0.018270794699990347 iter num 50\n",
            "loss 2.880426475263061e-07 average time 0.01826991594999299 iter num 100\n",
            "loss 3.0502423869856605e-07 average time 0.018332494520002456 iter num 50\n",
            "loss 2.849234039842314e-07 average time 0.01830578654999954 iter num 100\n",
            "loss 2.8895064397862296e-07 average time 0.018298349119993416 iter num 50\n",
            "loss 2.8187836273496664e-07 average time 0.018287742759999902 iter num 100\n",
            "loss 4.190143336762102e-07 average time 0.01830061886000294 iter num 50\n",
            "loss 2.9245532209450133e-07 average time 0.018295707860004312 iter num 100\n",
            "loss 2.8940677643622213e-07 average time 0.01828757536000012 iter num 50\n",
            "loss 2.843897475814188e-07 average time 0.018288855759997204 iter num 100\n",
            "loss 5.379959167087254e-07 average time 0.018264278780006863 iter num 50\n",
            "loss 2.9448202691367593e-07 average time 0.01827737011000295 iter num 100\n",
            "loss 2.8595478428747296e-07 average time 0.018289745140004924 iter num 50\n",
            "loss 2.845447231875938e-07 average time 0.018275945260006664 iter num 100\n",
            "loss 2.79777514726611e-07 average time 0.01831457755999736 iter num 50\n",
            "loss 2.785203293409706e-07 average time 0.018314926010002636 iter num 100\n",
            "loss 3.5618625581527703e-07 average time 0.01829877577999923 iter num 50\n",
            "loss 2.9793643965718966e-07 average time 0.018294650160000855 iter num 100\n",
            "loss 2.868705131281586e-07 average time 0.01828491304000636 iter num 50\n",
            "loss 2.851796140418705e-07 average time 0.018274565479998728 iter num 100\n",
            "loss 2.7977660657234186e-07 average time 0.018283666739998806 iter num 50\n",
            "loss 2.785971008641023e-07 average time 0.018286586270000953 iter num 100\n",
            "loss 2.747832108167518e-07 average time 0.01831345634000854 iter num 50\n",
            "loss 2.73309957962343e-07 average time 0.018285248210004282 iter num 100\n",
            "loss 3.502779481893903e-07 average time 0.01828604412000459 iter num 50\n",
            "loss 3.0472625561498586e-07 average time 0.018274355360001663 iter num 100\n",
            "loss 2.871178245162947e-07 average time 0.018267456660005336 iter num 50\n",
            "loss 2.8508721411118104e-07 average time 0.01830824288000258 iter num 100\n",
            "loss 2.789566104435208e-07 average time 0.018279976479991546 iter num 50\n",
            "loss 2.774895460070003e-07 average time 0.01828241520000347 iter num 100\n",
            "loss 4.174412742342033e-07 average time 0.018291245820000766 iter num 50\n",
            "loss 2.823861283240996e-07 average time 0.01827109368999686 iter num 100\n",
            "loss 2.759536077578939e-07 average time 0.018305829879998327 iter num 50\n",
            "loss 2.74681012361634e-07 average time 0.01829336008000041 iter num 100\n",
            "loss 2.703159488785586e-07 average time 0.0182856227999946 iter num 50\n",
            "loss 2.692120610184981e-07 average time 0.018280786859995714 iter num 100\n",
            "loss 5.787896710851624e-07 average time 0.01829110196000329 iter num 50\n",
            "loss 2.8789356862184124e-07 average time 0.01831335127999978 iter num 100\n",
            "loss 2.783365159570153e-07 average time 0.018315051520005454 iter num 50\n",
            "loss 2.7669286652352713e-07 average time 0.018286207270010665 iter num 100\n",
            "loss 2.7154150113368864e-07 average time 0.018269274940007563 iter num 50\n",
            "loss 2.7040238953933433e-07 average time 0.018258390190002274 iter num 100\n",
            "loss 3.309798603250869e-07 average time 0.018251199120013554 iter num 50\n",
            "loss 2.74214009052703e-07 average time 0.01827483121001137 iter num 100\n",
            "loss 2.6835440989329063e-07 average time 0.01827958653999076 iter num 50\n",
            "loss 2.6705184189295077e-07 average time 0.018301378969994175 iter num 100\n",
            "loss 2.6293001667068237e-07 average time 0.01828707447999477 iter num 50\n",
            "loss 2.6196588178221894e-07 average time 0.018303202490002377 iter num 100\n",
            "loss 2.765626604366622e-07 average time 0.018258794859989394 iter num 50\n",
            "loss 2.6319951696736363e-07 average time 0.018271160999997847 iter num 100\n",
            "loss 2.9619387477502554e-07 average time 0.018331713860009133 iter num 50\n",
            "loss 2.6062581291035975e-07 average time 0.01830561489000843 iter num 100\n",
            "loss 2.6211885477778895e-07 average time 0.0183093331200007 iter num 50\n",
            "loss 2.5622187187389936e-07 average time 0.018293622129999677 iter num 100\n",
            "loss 6.173050314433376e-07 average time 0.018320840939995833 iter num 50\n",
            "loss 2.7098446192888867e-07 average time 0.018323864949998096 iter num 100\n",
            "loss 2.6238990591820186e-07 average time 0.01828454083999759 iter num 50\n",
            "loss 2.6103606203137047e-07 average time 0.0182775104299958 iter num 100\n",
            "loss 2.875271330281077e-07 average time 0.018329212180001376 iter num 50\n",
            "loss 2.5800775328590117e-07 average time 0.018306329150000238 iter num 100\n",
            "loss 3.724316762733214e-07 average time 0.0182742000799999 iter num 50\n",
            "loss 2.6123657399507264e-07 average time 0.0182669386200007 iter num 100\n",
            "loss 2.562539265142493e-07 average time 0.018325163179997616 iter num 50\n",
            "loss 2.551431344366103e-07 average time 0.0183047893799926 iter num 100\n",
            "loss 5.046355029294875e-07 average time 0.018304817239982184 iter num 50\n",
            "loss 2.6081947149283264e-07 average time 0.01830601623998291 iter num 100\n",
            "loss 2.549878655426396e-07 average time 0.018270286800002394 iter num 50\n",
            "loss 2.538750971891275e-07 average time 0.018257647010004804 iter num 100\n",
            "loss 2.5464729719850483e-07 average time 0.01825918059999594 iter num 50\n",
            "loss 2.4982922704773757e-07 average time 0.018275472330002457 iter num 100\n",
            "loss 4.918399226186708e-07 average time 0.018278159199994662 iter num 50\n",
            "loss 2.7147321689674775e-07 average time 0.01827519779999193 iter num 100\n",
            "loss 2.6076583205059444e-07 average time 0.01830053022000584 iter num 50\n",
            "loss 2.5919815323348676e-07 average time 0.018284169590002647 iter num 100\n",
            "loss 2.542506751160877e-07 average time 0.018282005720006964 iter num 50\n",
            "loss 2.531861883116359e-07 average time 0.018280517230003852 iter num 100\n",
            "loss 2.519928902288169e-07 average time 0.01829830913999558 iter num 50\n",
            "loss 2.484961037468963e-07 average time 0.01828918091999867 iter num 100\n",
            "loss 5.686070137217457e-07 average time 0.01827350021999564 iter num 50\n",
            "loss 2.847304205253212e-07 average time 0.018264721310000596 iter num 100\n",
            "loss 2.6575952731914676e-07 average time 0.018334786720004104 iter num 50\n",
            "loss 2.636429688192725e-07 average time 0.01832714415000396 iter num 100\n",
            "loss 2.7851203950157e-07 average time 0.018281381879992297 iter num 50\n",
            "loss 2.5662830361271375e-07 average time 0.018270647099997178 iter num 100\n",
            "loss 4.138029017745462e-07 average time 0.018244248699993477 iter num 50\n",
            "loss 2.663668113835119e-07 average time 0.018253383499996972 iter num 100\n",
            "loss 2.5786642223539084e-07 average time 0.018284593180005686 iter num 50\n",
            "loss 2.5649966579603474e-07 average time 0.01828722953999545 iter num 100\n",
            "loss 2.518352395515523e-07 average time 0.01825581469999861 iter num 50\n",
            "loss 2.508032116950387e-07 average time 0.018269950950005977 iter num 100\n",
            "loss 3.737644608882399e-07 average time 0.018287008879992753 iter num 50\n",
            "loss 2.509827788355884e-07 average time 0.01830817177999734 iter num 100\n",
            "loss 2.465986627453061e-07 average time 0.01831224459999248 iter num 50\n",
            "loss 2.455886113162509e-07 average time 0.018292642399995885 iter num 100\n",
            "loss 2.421678194823015e-07 average time 0.01829641339998943 iter num 50\n",
            "loss 2.413344167770076e-07 average time 0.018285654179995846 iter num 100\n",
            "loss 2.734224136189525e-07 average time 0.01828989578001256 iter num 50\n",
            "loss 2.533853570759275e-07 average time 0.018287285350010053 iter num 100\n",
            "loss 2.464984794760092e-07 average time 0.018276960120006153 iter num 50\n",
            "loss 2.44994817302639e-07 average time 0.01827217993000204 iter num 100\n",
            "loss 3.018404715198227e-07 average time 0.018269945280003412 iter num 50\n",
            "loss 2.469585862660112e-07 average time 0.0182913640199979 iter num 100\n",
            "loss 2.419456048906253e-07 average time 0.018300891399999273 iter num 50\n",
            "loss 2.409782325857925e-07 average time 0.01828251033000129 iter num 100\n",
            "loss 2.3774351041391333e-07 average time 0.018248783579995233 iter num 50\n",
            "loss 2.367390670984027e-07 average time 0.018267330989996253 iter num 100\n",
            "loss 3.585177578919496e-07 average time 0.018270022140002312 iter num 50\n",
            "loss 2.514202471640072e-07 average time 0.018248181820002856 iter num 100\n",
            "loss 2.697990239673779e-07 average time 0.01827947372000608 iter num 50\n",
            "loss 2.4187152796976407e-07 average time 0.018301312820004797 iter num 100\n",
            "loss 4.5314887405526127e-07 average time 0.01826852949999875 iter num 50\n",
            "loss 2.584004283636214e-07 average time 0.01825488099000836 iter num 100\n",
            "loss 2.4805719298855806e-07 average time 0.018245836180003607 iter num 50\n",
            "loss 2.4656117989019414e-07 average time 0.018241440000000466 iter num 100\n",
            "loss 2.4167871760399906e-07 average time 0.018251444559991795 iter num 50\n",
            "loss 2.406336056204783e-07 average time 0.018245283689996086 iter num 100\n",
            "loss 3.843860733751928e-07 average time 0.01828122366000571 iter num 50\n",
            "loss 2.4064841867750466e-07 average time 0.018289746650007144 iter num 100\n",
            "loss 2.3729236621244315e-07 average time 0.018288354359995082 iter num 50\n",
            "loss 2.3553411082467961e-07 average time 0.018270980259994758 iter num 100\n",
            "loss 4.843387802024866e-07 average time 0.018283870200011734 iter num 50\n",
            "loss 2.4656583629330003e-07 average time 0.018290352570001004 iter num 100\n",
            "loss 2.3857075651578233e-07 average time 0.018276702239995758 iter num 50\n",
            "loss 2.3740400042710395e-07 average time 0.0182696301399983 iter num 100\n",
            "loss 2.4696447716213753e-07 average time 0.01824185755999906 iter num 50\n",
            "loss 2.3300691904904177e-07 average time 0.01826343012999814 iter num 100\n",
            "loss 4.7277151217199644e-07 average time 0.018305958739999822 iter num 50\n",
            "loss 2.497769186378895e-07 average time 0.01828705705999937 iter num 100\n",
            "loss 2.403697030955696e-07 average time 0.018311511159997736 iter num 50\n",
            "loss 2.390035064427998e-07 average time 0.01830124344000069 iter num 100\n",
            "loss 2.3468274272376837e-07 average time 0.018275141059993984 iter num 50\n",
            "loss 2.3375367364138637e-07 average time 0.01827633836000132 iter num 100\n",
            "loss 2.7304664519084804e-07 average time 0.018311080759997368 iter num 50\n",
            "loss 2.3197472331570746e-07 average time 0.018279657899998938 iter num 100\n",
            "loss 2.6098871984331317e-07 average time 0.018279076979997626 iter num 50\n",
            "loss 2.3137598511765372e-07 average time 0.018292701719998375 iter num 100\n",
            "loss 2.2802597824693883e-07 average time 0.01829294394000499 iter num 50\n",
            "loss 2.2709187049392875e-07 average time 0.018270474739999827 iter num 100\n",
            "loss 3.6073023089015176e-07 average time 0.018297583200005647 iter num 50\n",
            "loss 2.2964075847616688e-07 average time 0.018317723230001092 iter num 100\n",
            "loss 3.2154123085026117e-07 average time 0.018293612479994864 iter num 50\n",
            "loss 2.3581219928611106e-07 average time 0.0182840366699952 iter num 100\n",
            "loss 2.3150987277689094e-07 average time 0.01829567060000045 iter num 50\n",
            "loss 2.2879810432111256e-07 average time 0.01828752523999924 iter num 100\n",
            "loss 2.377432312720534e-07 average time 0.018313926339997125 iter num 50\n",
            "loss 2.2887867698813051e-07 average time 0.018312370500003682 iter num 100\n",
            "loss 2.251332299725795e-07 average time 0.018279489459998785 iter num 50\n",
            "loss 2.2424070399574963e-07 average time 0.018275930390000212 iter num 100\n",
            "loss 6.69659339393322e-07 average time 0.01828367111999796 iter num 50\n",
            "loss 2.3905007935484765e-07 average time 0.018284728130000757 iter num 100\n",
            "loss 2.2962093732485294e-07 average time 0.01828568771999471 iter num 50\n",
            "loss 2.282127063742654e-07 average time 0.018267799699992794 iter num 100\n",
            "loss 2.425540849359078e-07 average time 0.018283976420002547 iter num 50\n",
            "loss 2.2470173014993915e-07 average time 0.018257774930000324 iter num 100\n",
            "loss 2.3781216412343803e-07 average time 0.01828515161999576 iter num 50\n",
            "loss 2.26766072440333e-07 average time 0.018280405269999845 iter num 100\n",
            "loss 2.2266705217164548e-07 average time 0.018278235820000644 iter num 50\n",
            "loss 2.2170929554449321e-07 average time 0.018278657300006673 iter num 100\n",
            "loss 2.4402208231201906e-07 average time 0.018265561939990675 iter num 50\n",
            "loss 2.204985322312631e-07 average time 0.01827062530999342 iter num 100\n",
            "loss 2.7222225518236795e-07 average time 0.018298588839995772 iter num 50\n",
            "loss 2.2089893660379423e-07 average time 0.01830832493999651 iter num 100\n",
            "loss 2.553385781835672e-07 average time 0.018307716740005163 iter num 50\n",
            "loss 2.203928666997946e-07 average time 0.018306456120002396 iter num 100\n",
            "loss 2.3399887289849048e-07 average time 0.018227266859994415 iter num 50\n",
            "loss 2.1702650529133424e-07 average time 0.018268915669991656 iter num 100\n",
            "loss 3.4758601714303555e-07 average time 0.018332209239988514 iter num 50\n",
            "loss 2.214098261759604e-07 average time 0.018304976699994313 iter num 100\n",
            "loss 2.6081889574204273e-07 average time 0.018287865039992537 iter num 50\n",
            "loss 2.21423275622e-07 average time 0.01827732832999118 iter num 100\n",
            "loss 2.2546069725284182e-07 average time 0.01830918989998963 iter num 50\n",
            "loss 2.171625193961103e-07 average time 0.018282169069996145 iter num 100\n",
            "loss 2.403527421746952e-07 average time 0.018312506200004464 iter num 50\n",
            "loss 2.162179958370226e-07 average time 0.01829965119000235 iter num 100\n",
            "loss 2.1661465595192197e-07 average time 0.018288999479998437 iter num 50\n",
            "loss 2.128321786801435e-07 average time 0.018286949960000812 iter num 100\n",
            "loss 3.398085495986704e-07 average time 0.018290419000002202 iter num 50\n",
            "loss 2.2580358922836235e-07 average time 0.0182775620800021 iter num 100\n",
            "loss 2.181904222077794e-07 average time 0.018255708219992357 iter num 50\n",
            "loss 2.1710238315748952e-07 average time 0.018270000019990674 iter num 100\n",
            "loss 2.1785323800683082e-07 average time 0.018265050060001613 iter num 50\n",
            "loss 2.1302475080620197e-07 average time 0.018256463820001727 iter num 100\n",
            "loss 4.929432225962333e-07 average time 0.018303041019999 iter num 50\n",
            "loss 2.3189411517364326e-07 average time 0.018283189490005042 iter num 100\n",
            "loss 2.2231231051394367e-07 average time 0.018291545499996575 iter num 50\n",
            "loss 2.209412855900635e-07 average time 0.018299383940000098 iter num 100\n",
            "loss 2.1680373593970336e-07 average time 0.018303708339999503 iter num 50\n",
            "loss 2.1592926191665347e-07 average time 0.01829683713999316 iter num 100\n",
            "loss 3.4766257820077853e-07 average time 0.018305255760008094 iter num 50\n",
            "loss 2.1595849301022967e-07 average time 0.018279438950000896 iter num 100\n",
            "loss 2.2694441600597822e-07 average time 0.018272495140001864 iter num 50\n",
            "loss 2.1282583328162133e-07 average time 0.018287185219998038 iter num 100\n",
            "loss 2.4942441715624883e-07 average time 0.018329999279999357 iter num 50\n",
            "loss 2.120100838205619e-07 average time 0.01828624701999843 iter num 100\n",
            "loss 2.1853539280843795e-07 average time 0.018299029120000795 iter num 50\n",
            "loss 2.0868240218986637e-07 average time 0.01829839608000043 iter num 100\n",
            "loss 2.652562771504858e-07 average time 0.01830236236000246 iter num 50\n",
            "loss 2.1944956745233334e-07 average time 0.0182958256000029 iter num 100\n",
            "loss 2.1437674044735844e-07 average time 0.018317270760003338 iter num 50\n",
            "loss 2.1182672838925674e-07 average time 0.018307192080001186 iter num 100\n",
            "loss 2.7436195989946126e-07 average time 0.0183023424799876 iter num 50\n",
            "loss 2.1467151382856775e-07 average time 0.018294702989994676 iter num 100\n",
            "loss 2.0999107707019791e-07 average time 0.018304679459997714 iter num 50\n",
            "loss 2.089801868244186e-07 average time 0.018297607500001048 iter num 100\n",
            "loss 2.9781991597478824e-07 average time 0.018321602859994072 iter num 50\n",
            "loss 2.1904009479922279e-07 average time 0.018311450439997542 iter num 100\n",
            "loss 2.1180978000508377e-07 average time 0.018283157999992455 iter num 50\n",
            "loss 2.1072546114144437e-07 average time 0.01829427137999346 iter num 100\n",
            "loss 2.0729126377755494e-07 average time 0.01828895456000282 iter num 50\n",
            "loss 2.0653169886700575e-07 average time 0.018292649160000566 iter num 100\n",
            "loss 2.0903322178955297e-07 average time 0.018219164860011006 iter num 50\n",
            "loss 2.031819332203256e-07 average time 0.01823767986999201 iter num 100\n",
            "loss 8.254696303887336e-07 average time 0.01827792996002245 iter num 50\n",
            "loss 2.544505833087916e-07 average time 0.01824520610002537 iter num 100\n",
            "loss 2.2853941692548536e-07 average time 0.01823753501999363 iter num 50\n",
            "loss 2.2582078829891276e-07 average time 0.018265737229999104 iter num 100\n",
            "loss 2.186799141124582e-07 average time 0.018278910220019498 iter num 50\n",
            "loss 2.1736059463834644e-07 average time 0.018256539950004935 iter num 100\n",
            "loss 2.129293118407197e-07 average time 0.018288704500005224 iter num 50\n",
            "loss 2.1198294213535555e-07 average time 0.018283342449985866 iter num 100\n",
            "loss 2.085835703103854e-07 average time 0.01829717024000274 iter num 50\n",
            "loss 2.0780187300267238e-07 average time 0.01828731273000358 iter num 100\n",
            "loss 4.1235013548421557e-07 average time 0.01827779768001619 iter num 50\n",
            "loss 2.094770250996709e-07 average time 0.018309088850010084 iter num 100\n",
            "loss 2.0577298005806742e-07 average time 0.01826940862000356 iter num 50\n",
            "loss 2.0485135682975838e-07 average time 0.018256484950006778 iter num 100\n",
            "loss 2.3684774711530221e-07 average time 0.018257777920007358 iter num 50\n",
            "loss 2.0907580295512646e-07 average time 0.01825557170000138 iter num 100\n",
            "loss 2.051132462914924e-07 average time 0.01826679095997861 iter num 50\n",
            "loss 2.034432234728801e-07 average time 0.018273280519981654 iter num 100\n",
            "loss 3.4289318207532894e-07 average time 0.018292752540019136 iter num 50\n",
            "loss 2.1087578843107443e-07 average time 0.018295545750013388 iter num 100\n",
            "loss 2.05537116366559e-07 average time 0.018288931540000705 iter num 50\n",
            "loss 2.0462989117686585e-07 average time 0.018302472410009613 iter num 100\n",
            "loss 2.0163663809453055e-07 average time 0.018244307780009877 iter num 50\n",
            "loss 2.0096970744355264e-07 average time 0.018279106010008945 iter num 100\n",
            "loss 5.460920110692212e-07 average time 0.018320391880006354 iter num 50\n",
            "loss 2.0953918492656856e-07 average time 0.01832753708000155 iter num 100\n",
            "loss 2.0313752706329918e-07 average time 0.018216116600010535 iter num 50\n",
            "loss 2.0202714445402663e-07 average time 0.01824647164001135 iter num 100\n",
            "loss 2.0169451446965353e-07 average time 0.018263028100000155 iter num 50\n",
            "loss 1.985093328101205e-07 average time 0.018285670410009516 iter num 100\n",
            "loss 4.4542173437102057e-07 average time 0.018320843379988218 iter num 50\n",
            "loss 2.1660126452987586e-07 average time 0.01830483463999144 iter num 100\n",
            "loss 2.0717794595967953e-07 average time 0.018298152899969864 iter num 50\n",
            "loss 2.0585662040999623e-07 average time 0.018296111589982046 iter num 100\n",
            "loss 2.0191169475703087e-07 average time 0.01829320916000597 iter num 50\n",
            "loss 2.01075899733938e-07 average time 0.018282232100004875 iter num 100\n",
            "loss 2.4425227654120263e-07 average time 0.018272349900003065 iter num 50\n",
            "loss 2.0069267984271658e-07 average time 0.018273105600007965 iter num 100\n",
            "loss 2.015132485527395e-07 average time 0.018311745279993373 iter num 50\n",
            "loss 1.9745873082795297e-07 average time 0.018293754039989382 iter num 100\n",
            "loss 2.330597371002005e-07 average time 0.018238171720008724 iter num 50\n",
            "loss 1.9852814785002935e-07 average time 0.01824122209000734 iter num 100\n",
            "loss 2.0083390759713818e-07 average time 0.018274893900002098 iter num 50\n",
            "loss 1.949473374923154e-07 average time 0.01825793350000822 iter num 100\n",
            "loss 2.0974472343195293e-07 average time 0.018282970239988573 iter num 50\n",
            "loss 1.977826276725582e-07 average time 0.018285874819991933 iter num 100\n",
            "loss 1.9431980794507854e-07 average time 0.018261906519983315 iter num 50\n",
            "loss 1.9354152717358038e-07 average time 0.01827879952998501 iter num 100\n",
            "loss 4.085450910039694e-07 average time 0.018283245359998545 iter num 50\n",
            "loss 1.9885492166448358e-07 average time 0.018291361820006388 iter num 100\n",
            "loss 1.9537216112055538e-07 average time 0.018258355839993783 iter num 50\n",
            "loss 1.9338827471766889e-07 average time 0.018291471519989954 iter num 100\n",
            "loss 2.3403313140659782e-07 average time 0.018311979179989068 iter num 50\n",
            "loss 1.9471831553240226e-07 average time 0.01830167672000698 iter num 100\n",
            "loss 4.187612753309464e-07 average time 0.018282109959968693 iter num 50\n",
            "loss 2.0382688913075037e-07 average time 0.018286371129986493 iter num 100\n",
            "loss 1.9692859068519992e-07 average time 0.01830805656001303 iter num 50\n",
            "loss 1.95898858190989e-07 average time 0.018307801240002846 iter num 100\n",
            "loss 1.9287943956164658e-07 average time 0.01828719635998823 iter num 50\n",
            "loss 1.919612270353284e-07 average time 0.018299458399999368 iter num 100\n",
            "loss 2.925322359879749e-07 average time 0.01830174131999229 iter num 50\n",
            "loss 2.016944691278561e-07 average time 0.0182916829900023 iter num 100\n",
            "loss 1.9472015076864121e-07 average time 0.018323396939999837 iter num 50\n",
            "loss 1.9371422384155788e-07 average time 0.018284743560006974 iter num 100\n",
            "loss 1.90662943387539e-07 average time 0.0182809833400006 iter num 50\n",
            "loss 1.8999188915801957e-07 average time 0.018276421229984408 iter num 100\n",
            "loss 2.044327056188769e-07 average time 0.018282988340010888 iter num 50\n",
            "loss 1.8770026549615717e-07 average time 0.01828223346000186 iter num 100\n",
            "loss 3.0930672317953465e-07 average time 0.018277359339981557 iter num 50\n",
            "loss 2.1897616895101203e-07 average time 0.018270520799990208 iter num 100\n",
            "loss 2.040173734304603e-07 average time 0.018290426920002573 iter num 50\n",
            "loss 2.0228227213460938e-07 average time 0.01827136065000559 iter num 100\n",
            "loss 1.9727693756349985e-07 average time 0.018286765180023395 iter num 50\n",
            "loss 1.962850130810613e-07 average time 0.018277773590023118 iter num 100\n",
            "loss 1.9278654897699606e-07 average time 0.018305972119987926 iter num 50\n",
            "loss 1.920033277161597e-07 average time 0.018287094330005402 iter num 100\n",
            "loss 2.0839734783389242e-07 average time 0.018259100920026868 iter num 50\n",
            "loss 1.891007530466763e-07 average time 0.018277921100011554 iter num 100\n",
            "loss 3.308680515651458e-07 average time 0.018278478360007285 iter num 50\n",
            "loss 1.9542254809949709e-07 average time 0.018281796990011118 iter num 100\n",
            "loss 1.9032507975366374e-07 average time 0.01826917865998894 iter num 50\n",
            "loss 1.8944462513607823e-07 average time 0.018268500129988752 iter num 100\n",
            "loss 1.8899843312009185e-07 average time 0.018309793279977383 iter num 50\n",
            "loss 1.8643625386509104e-07 average time 0.018302082369980325 iter num 100\n",
            "loss 2.928976893849207e-07 average time 0.018257195719993433 iter num 50\n",
            "loss 2.0401784008145841e-07 average time 0.018255708929993942 iter num 100\n",
            "loss 1.9552716736277423e-07 average time 0.018293964160025097 iter num 50\n",
            "loss 1.941657361973608e-07 average time 0.018289353150016723 iter num 100\n",
            "loss 1.903557023993763e-07 average time 0.01829518547998305 iter num 50\n",
            "loss 1.8956534181969433e-07 average time 0.01826967489997969 iter num 100\n",
            "loss 1.867305912345212e-07 average time 0.018326569240007303 iter num 50\n",
            "loss 1.8608892480272239e-07 average time 0.018316071590002137 iter num 100\n",
            "loss 1.9554246139695632e-07 average time 0.018279424959991956 iter num 50\n",
            "loss 1.8335892950651292e-07 average time 0.018272757350002847 iter num 100\n",
            "loss 5.809614799511312e-07 average time 0.018281467880015043 iter num 50\n",
            "loss 2.1325721761439837e-07 average time 0.01830068111001765 iter num 100\n",
            "loss 1.980714421854512e-07 average time 0.01826045221999266 iter num 50\n",
            "loss 1.9643161798510502e-07 average time 0.018267070439999315 iter num 100\n",
            "loss 1.917607658914685e-07 average time 0.018241931399988972 iter num 50\n",
            "loss 1.908421468884259e-07 average time 0.01823289502999387 iter num 100\n",
            "loss 1.8760369920866253e-07 average time 0.018297125740014054 iter num 50\n",
            "loss 1.8687798159835606e-07 average time 0.01828591644999733 iter num 100\n",
            "loss 1.8950738275924612e-07 average time 0.01829880249996677 iter num 50\n",
            "loss 1.8372503488243702e-07 average time 0.01830582648997961 iter num 100\n",
            "loss 5.556210204081485e-07 average time 0.01829047234000427 iter num 50\n",
            "loss 2.224295874698361e-07 average time 0.018295967950000432 iter num 100\n",
            "loss 2.022595975850151e-07 average time 0.018242826319992675 iter num 50\n",
            "loss 2.0017191291833112e-07 average time 0.018227388879995487 iter num 100\n",
            "loss 1.9424122081916962e-07 average time 0.018285754280022957 iter num 50\n",
            "loss 1.9312112360719323e-07 average time 0.01826798558001201 iter num 100\n",
            "loss 1.893569788845468e-07 average time 0.018231355900011296 iter num 50\n",
            "loss 1.8850521279774956e-07 average time 0.018245459510001182 iter num 100\n",
            "loss 3.969899234029262e-07 average time 0.018308171779995063 iter num 50\n",
            "loss 1.984901516794598e-07 average time 0.01831544018999466 iter num 100\n",
            "loss 1.9075077387090184e-07 average time 0.018254901399973277 iter num 50\n",
            "loss 1.8970035461995908e-07 average time 0.01828178744998695 iter num 100\n",
            "loss 1.8633991545804937e-07 average time 0.01826412233998326 iter num 50\n",
            "loss 1.8560911336445847e-07 average time 0.018273490229985326 iter num 100\n",
            "loss 1.8291484301739735e-07 average time 0.018289411000000654 iter num 50\n",
            "loss 1.8229014581285598e-07 average time 0.018285056539996278 iter num 100\n",
            "loss 1.8129218373246474e-07 average time 0.018291871700002956 iter num 50\n",
            "loss 1.7943740571584245e-07 average time 0.018297029750001456 iter num 100\n",
            "loss 3.053763774630599e-07 average time 0.01831498099999408 iter num 50\n",
            "loss 2.0356571729284702e-07 average time 0.01831185524999228 iter num 100\n",
            "loss 1.9122979545716409e-07 average time 0.018278914620004798 iter num 50\n",
            "loss 1.8982640023904235e-07 average time 0.01828585141000076 iter num 100\n",
            "loss 1.8562941850119917e-07 average time 0.01828768603998924 iter num 50\n",
            "loss 1.8477686372833697e-07 average time 0.018283233449990346 iter num 100\n",
            "loss 1.8174454673285726e-07 average time 0.018306324059999497 iter num 50\n",
            "loss 1.8105203127236948e-07 average time 0.01828561355999682 iter num 100\n",
            "loss 2.721727319999065e-07 average time 0.01829901794000307 iter num 50\n",
            "loss 1.8256903786332528e-07 average time 0.018283342229999562 iter num 100\n",
            "loss 2.0031838514992266e-07 average time 0.018251552059978166 iter num 50\n",
            "loss 1.7999545063029297e-07 average time 0.018264919129985627 iter num 100\n",
            "loss 1.7905346569386247e-07 average time 0.018303912499991384 iter num 50\n",
            "loss 1.76958062871092e-07 average time 0.018279516339991916 iter num 100\n",
            "loss 2.3250272672602713e-07 average time 0.01828304419998858 iter num 50\n",
            "loss 1.8392256134358319e-07 average time 0.018289585709987934 iter num 100\n",
            "loss 1.7900944608287732e-07 average time 0.01828899689998707 iter num 50\n",
            "loss 1.7819070553521958e-07 average time 0.01829573596998671 iter num 100\n",
            "loss 1.7638368916914788e-07 average time 0.01832259722002618 iter num 50\n",
            "loss 1.7499393892507202e-07 average time 0.018319614180009013 iter num 100\n",
            "loss 3.376707982516459e-07 average time 0.01825649763999536 iter num 50\n",
            "loss 1.8731988255441102e-07 average time 0.01827190721000079 iter num 100\n",
            "loss 1.800498785154358e-07 average time 0.01825749478000489 iter num 50\n",
            "loss 1.790442663896024e-07 average time 0.01828451770001493 iter num 100\n",
            "loss 1.7598311856612432e-07 average time 0.018302569859974936 iter num 50\n",
            "loss 1.753333339733443e-07 average time 0.01830433923998726 iter num 100\n",
            "loss 2.29817019152564e-07 average time 0.01829392957998152 iter num 50\n",
            "loss 1.737724021974101e-07 average time 0.018274195429994505 iter num 100\n",
            "loss 2.5194516951167463e-07 average time 0.018239297740024085 iter num 50\n",
            "loss 1.791321190172638e-07 average time 0.018268179230010447 iter num 100\n",
            "loss 1.751133987533171e-07 average time 0.018207026840009348 iter num 50\n",
            "loss 1.7425040234148672e-07 average time 0.018225859199999375 iter num 100\n",
            "loss 1.98498371113055e-07 average time 0.01830664773999615 iter num 50\n",
            "loss 1.724763496267711e-07 average time 0.018286283639995418 iter num 100\n",
            "loss 1.8392697710528334e-07 average time 0.018283058340002753 iter num 50\n",
            "loss 1.7459255135261642e-07 average time 0.018283811410010457 iter num 100\n",
            "loss 1.83052876920144e-07 average time 0.01828010230000473 iter num 50\n",
            "loss 1.7167529777544196e-07 average time 0.01828146858000764 iter num 100\n",
            "loss 1.9944483064417064e-07 average time 0.018292095080000764 iter num 50\n",
            "loss 1.7279317742034691e-07 average time 0.018291666800007534 iter num 100\n",
            "loss 2.927036653360275e-07 average time 0.01829036714000267 iter num 50\n",
            "loss 1.753932157331267e-07 average time 0.018316603220007437 iter num 100\n",
            "loss 1.7163010271346489e-07 average time 0.018326856219996444 iter num 50\n",
            "loss 1.7092449005025447e-07 average time 0.018330567679993238 iter num 100\n",
            "loss 1.6854630829150502e-07 average time 0.0183331470200028 iter num 50\n",
            "loss 1.6798994505125017e-07 average time 0.018318420750001677 iter num 100\n",
            "loss 2.9838161947948047e-07 average time 0.018269516699988345 iter num 50\n",
            "loss 1.700544102726585e-07 average time 0.01828081836999672 iter num 100\n",
            "loss 2.560115686758468e-07 average time 0.01832218331999684 iter num 50\n",
            "loss 1.7088973196164823e-07 average time 0.01831501520000529 iter num 100\n",
            "loss 1.6916063603989932e-07 average time 0.018259801240010348 iter num 50\n",
            "loss 1.6811053171797118e-07 average time 0.018264517410007102 iter num 100\n",
            "loss 2.0666296160514143e-07 average time 0.018340265120023104 iter num 50\n",
            "loss 1.6864745146162966e-07 average time 0.01832542572003149 iter num 100\n",
            "loss 2.122945517641056e-07 average time 0.018309312440010217 iter num 50\n",
            "loss 1.6846595879015958e-07 average time 0.018292814700002963 iter num 100\n",
            "loss 1.7189867519523554e-07 average time 0.018295175859998382 iter num 50\n",
            "loss 1.6569903511201397e-07 average time 0.018286459469995863 iter num 100\n",
            "loss 1.9683741071444316e-07 average time 0.018295740579997073 iter num 50\n",
            "loss 1.7128978343381867e-07 average time 0.018296079229987754 iter num 100\n",
            "loss 1.8125081774283586e-07 average time 0.018285239780002484 iter num 50\n",
            "loss 1.691876100398544e-07 average time 0.01826910687999316 iter num 100\n",
            "loss 1.6805784788659207e-07 average time 0.01830537024000023 iter num 50\n",
            "loss 1.6559460472556785e-07 average time 0.01827041682999834 iter num 100\n",
            "loss 3.0206937024862905e-07 average time 0.018239052140020248 iter num 50\n",
            "loss 1.7589381793157334e-07 average time 0.01826952167001309 iter num 100\n",
            "loss 1.6941194418463141e-07 average time 0.018272968939995735 iter num 50\n",
            "loss 1.684372385394031e-07 average time 0.018258425949998127 iter num 100\n",
            "loss 1.6816113576872447e-07 average time 0.018312645999994857 iter num 50\n",
            "loss 1.6508527072695795e-07 average time 0.018295173140002133 iter num 100\n",
            "loss 5.520110760917902e-07 average time 0.018257973599997968 iter num 50\n",
            "loss 1.8505337493132637e-07 average time 0.018276139179993153 iter num 100\n",
            "loss 1.7468015165198698e-07 average time 0.018304956139986645 iter num 50\n",
            "loss 1.734463923644001e-07 average time 0.0182857719099934 iter num 100\n",
            "loss 1.696944836558253e-07 average time 0.01828990928001076 iter num 50\n",
            "loss 1.6892344077023495e-07 average time 0.018286008680004216 iter num 100\n",
            "loss 1.6616446558332223e-07 average time 0.018273737460008307 iter num 50\n",
            "loss 1.655365180607576e-07 average time 0.0182934704700142 iter num 100\n",
            "loss 2.5425488120291687e-07 average time 0.018307395619981435 iter num 50\n",
            "loss 1.6616939716855177e-07 average time 0.01828463210999871 iter num 100\n",
            "loss 2.0943254408420922e-07 average time 0.018291943040026126 iter num 50\n",
            "loss 1.668041020983388e-07 average time 0.01829665716002637 iter num 100\n",
            "loss 1.6384503777246106e-07 average time 0.018327125779974265 iter num 50\n",
            "loss 1.6322924312233162e-07 average time 0.018299075079985416 iter num 100\n",
            "loss 1.6112303699729768e-07 average time 0.018260815419980644 iter num 50\n",
            "loss 1.6061475413499095e-07 average time 0.018261521799977344 iter num 100\n",
            "loss 4.3859182445570744e-07 average time 0.018295601040013026 iter num 50\n",
            "loss 1.6732235453323647e-07 average time 0.018280415000006087 iter num 100\n",
            "loss 1.6418503560621887e-07 average time 0.018303803599992535 iter num 50\n",
            "loss 1.621471963387838e-07 average time 0.01829335814999922 iter num 100\n",
            "loss 2.834954487648223e-07 average time 0.018277713400007087 iter num 50\n",
            "loss 1.6752737711319116e-07 average time 0.018284813220016075 iter num 100\n",
            "loss 1.6318535934282422e-07 average time 0.018265147040001466 iter num 50\n",
            "loss 1.624228659962565e-07 average time 0.018272502269994675 iter num 100\n",
            "loss 1.6133504220963864e-07 average time 0.018300229740002578 iter num 50\n",
            "loss 1.5958157008035032e-07 average time 0.018285830510014877 iter num 100\n",
            "loss 4.2289498538889975e-07 average time 0.018247497679990374 iter num 50\n",
            "loss 1.7337333266537277e-07 average time 0.01824678513999743 iter num 100\n",
            "loss 1.6562640423360373e-07 average time 0.018280577440013986 iter num 50\n",
            "loss 1.646340824212291e-07 average time 0.018287030320020676 iter num 100\n",
            "loss 1.6158511733681008e-07 average time 0.01824104048000663 iter num 50\n",
            "loss 1.6094473466008296e-07 average time 0.01826006408999774 iter num 100\n",
            "loss 1.6656783557014378e-07 average time 0.018273413839992828 iter num 50\n",
            "loss 1.5830388702211582e-07 average time 0.018293020260005052 iter num 100\n",
            "loss 4.68820202628181e-07 average time 0.01830136270001276 iter num 50\n",
            "loss 1.8307626665216394e-07 average time 0.018301588710010037 iter num 100\n",
            "loss 1.7016235232696403e-07 average time 0.01827157730000181 iter num 50\n",
            "loss 1.682901512228935e-07 average time 0.01826279232999241 iter num 100\n",
            "loss 2.140236445107389e-07 average time 0.018292965319983524 iter num 50\n",
            "loss 1.6525431981984046e-07 average time 0.018262269619988274 iter num 100\n",
            "loss 1.6241165896589207e-07 average time 0.01827232343997821 iter num 50\n",
            "loss 1.6137445622905953e-07 average time 0.01825617283997417 iter num 100\n",
            "loss 1.769820573043826e-07 average time 0.01822161547996984 iter num 50\n",
            "loss 1.6533038206218373e-07 average time 0.018264570259984795 iter num 100\n",
            "loss 1.6147583638974828e-07 average time 0.018268548280007055 iter num 50\n",
            "loss 1.6075286670751336e-07 average time 0.01828112375000501 iter num 100\n",
            "loss 1.5844138757857386e-07 average time 0.018262835239993364 iter num 50\n",
            "loss 1.579189861150463e-07 average time 0.018258337779996053 iter num 100\n",
            "loss 1.908038121744295e-07 average time 0.018266131500008668 iter num 50\n",
            "loss 1.578724378195379e-07 average time 0.018255307900010394 iter num 100\n",
            "loss 2.7280397231846577e-07 average time 0.01826770407999902 iter num 50\n",
            "loss 1.6864288681204537e-07 average time 0.018263690340006633 iter num 100\n",
            "loss 1.6203981106761214e-07 average time 0.018240643519984587 iter num 50\n",
            "loss 1.6111696866177267e-07 average time 0.01825852546000533 iter num 100\n",
            "loss 1.5830419925729602e-07 average time 0.01829471017998003 iter num 50\n",
            "loss 1.5770638469142178e-07 average time 0.018296834450000007 iter num 100\n",
            "loss 1.5553327160507685e-07 average time 0.018312147899996488 iter num 50\n",
            "loss 1.5502733910479837e-07 average time 0.018296590009992997 iter num 100\n",
            "loss 3.1453268340151446e-07 average time 0.018252441239965264 iter num 50\n",
            "loss 1.567300244665884e-07 average time 0.018244874309989428 iter num 100\n",
            "loss 2.91854291747222e-07 average time 0.01827129990000685 iter num 50\n",
            "loss 1.6145954789143938e-07 average time 0.018290932469999462 iter num 100\n",
            "loss 1.5701984227375646e-07 average time 0.018223195380001014 iter num 50\n",
            "loss 1.5631970833247024e-07 average time 0.018234486740002467 iter num 100\n",
            "loss 1.5560866076985725e-07 average time 0.018256242160014154 iter num 50\n",
            "loss 1.5353916839328193e-07 average time 0.01824540485000398 iter num 100\n",
            "loss 2.614015246868841e-07 average time 0.01827155718000995 iter num 50\n",
            "loss 1.6977812734331615e-07 average time 0.018286601160002646 iter num 100\n",
            "loss 1.6031114142393935e-07 average time 0.01829430827998749 iter num 50\n",
            "loss 1.59248503674041e-07 average time 0.01828202876998603 iter num 100\n",
            "loss 1.5606051886803943e-07 average time 0.018276779099969644 iter num 50\n",
            "loss 1.554108722828887e-07 average time 0.018270831189988714 iter num 100\n",
            "loss 1.532159181449479e-07 average time 0.01828043657998478 iter num 50\n",
            "loss 1.5262112427584366e-07 average time 0.01828210917999513 iter num 100\n",
            "loss 4.4789048299280697e-07 average time 0.01825632360000327 iter num 50\n",
            "loss 1.7414707317496766e-07 average time 0.018261583989992686 iter num 100\n",
            "loss 1.6252342287479114e-07 average time 0.0182620153200196 iter num 50\n",
            "loss 1.6116700221385055e-07 average time 0.018268081300006997 iter num 100\n",
            "loss 1.5746744404840112e-07 average time 0.01829117081997083 iter num 50\n",
            "loss 1.5674342286348914e-07 average time 0.01828225949998114 iter num 100\n",
            "loss 1.7245247099027802e-07 average time 0.018255051140013166 iter num 50\n",
            "loss 1.555229968447618e-07 average time 0.018247163109999746 iter num 100\n",
            "loss 1.6929318530048824e-07 average time 0.018279718440007853 iter num 50\n",
            "loss 1.5379178763372337e-07 average time 0.018280686720001996 iter num 100\n",
            "loss 1.535093199419004e-07 average time 0.01828609747997234 iter num 50\n",
            "loss 1.5127120584385608e-07 average time 0.018277281709981708 iter num 100\n",
            "loss 2.7798783573889987e-07 average time 0.018238915460005955 iter num 50\n",
            "loss 1.5532803350980508e-07 average time 0.018275691120002192 iter num 100\n",
            "loss 1.5177079818564527e-07 average time 0.01826747902000534 iter num 50\n",
            "loss 1.5113913321213265e-07 average time 0.018255529620009838 iter num 100\n",
            "loss 2.3394180655233015e-07 average time 0.018250734960015506 iter num 50\n",
            "loss 1.5541875863208107e-07 average time 0.018242389790016203 iter num 100\n",
            "loss 1.5711297317747457e-07 average time 0.018272545719987647 iter num 50\n",
            "loss 1.5136993870178599e-07 average time 0.01827654384999505 iter num 100\n",
            "loss 1.6053054083449516e-07 average time 0.018301430159999653 iter num 50\n",
            "loss 1.5077865417470975e-07 average time 0.01831080221000093 iter num 100\n",
            "loss 1.488427549168859e-07 average time 0.01829338557998199 iter num 50\n",
            "loss 1.4806528627295576e-07 average time 0.018266076919983335 iter num 100\n",
            "loss 1.533758857044218e-07 average time 0.018295753200018226 iter num 50\n",
            "loss 1.4649712430992993e-07 average time 0.01826789426999767 iter num 100\n",
            "loss 3.489784879267238e-07 average time 0.018257791719984196 iter num 50\n",
            "loss 1.5236019353879155e-07 average time 0.01826590728998326 iter num 100\n",
            "loss 1.4968963498274712e-07 average time 0.018292546700022286 iter num 50\n",
            "loss 1.4781738820193965e-07 average time 0.018263371880009344 iter num 100\n",
            "loss 1.8897682733504242e-07 average time 0.018267517859990222 iter num 50\n",
            "loss 1.558963676540321e-07 average time 0.01826059659999146 iter num 100\n",
            "loss 1.5167087685821212e-07 average time 0.018290989539973452 iter num 50\n",
            "loss 1.5000450120680893e-07 average time 0.018275723139977343 iter num 100\n",
            "loss 2.0328590243832986e-07 average time 0.01828533724000863 iter num 50\n",
            "loss 1.4981631705319582e-07 average time 0.018280322540013005 iter num 100\n",
            "loss 1.5126066396832347e-07 average time 0.018280144199979986 iter num 50\n",
            "loss 1.4704837240295404e-07 average time 0.018275011329981227 iter num 100\n",
            "loss 2.1638253692682999e-07 average time 0.01829344173998379 iter num 50\n",
            "loss 1.4909233298195493e-07 average time 0.01829350212999316 iter num 100\n",
            "loss 1.4736636611428174e-07 average time 0.0182480523599952 iter num 50\n",
            "loss 1.4582972596662017e-07 average time 0.018264418769983876 iter num 100\n",
            "loss 1.8766661627485985e-07 average time 0.018263268799992148 iter num 50\n",
            "loss 1.5034768038320945e-07 average time 0.01826489570000149 iter num 100\n",
            "loss 1.4666840904112395e-07 average time 0.01828547756001626 iter num 50\n",
            "loss 1.4603331188167065e-07 average time 0.018283870320003642 iter num 100\n",
            "loss 1.4443092386357753e-07 average time 0.018282529680013794 iter num 50\n",
            "loss 1.4351783887114143e-07 average time 0.0182781152600046 iter num 100\n",
            "loss 3.302869104280214e-07 average time 0.01827164102000097 iter num 50\n",
            "loss 1.6452403071836113e-07 average time 0.018260905329993873 iter num 100\n",
            "loss 1.5291345718710617e-07 average time 0.018267927760007296 iter num 50\n",
            "loss 1.5166596170465832e-07 average time 0.018272637260010924 iter num 100\n",
            "loss 1.4810632664625552e-07 average time 0.018332457679980506 iter num 50\n",
            "loss 1.4740545216126987e-07 average time 0.018306328179985485 iter num 100\n",
            "loss 1.9013512365321428e-07 average time 0.01831200307997733 iter num 50\n",
            "loss 1.4618293331026912e-07 average time 0.018278426249983114 iter num 100\n",
            "loss 1.7643854205169907e-07 average time 0.01829086560000178 iter num 50\n",
            "loss 1.4698034245454483e-07 average time 0.018298280020005678 iter num 100\n",
            "loss 1.4500709811957917e-07 average time 0.01829044778000025 iter num 50\n",
            "loss 1.437651547011421e-07 average time 0.018273835170004984 iter num 100\n",
            "loss 2.1248477512267268e-07 average time 0.01830014754003969 iter num 50\n",
            "loss 1.440655699372903e-07 average time 0.01829004547002569 iter num 100\n",
            "loss 1.6728153893299172e-07 average time 0.01827454256001147 iter num 50\n",
            "loss 1.4416934047210905e-07 average time 0.018274210010019942 iter num 100\n",
            "loss 1.4424337125861697e-07 average time 0.01831069983999896 iter num 50\n",
            "loss 1.4147167696471812e-07 average time 0.018323064000005617 iter num 100\n",
            "loss 2.537750938784927e-07 average time 0.018280673620001835 iter num 50\n",
            "loss 1.4839019231042643e-07 average time 0.018285595410006864 iter num 100\n",
            "loss 1.438740703881395e-07 average time 0.018266226739997365 iter num 50\n",
            "loss 1.430126192366144e-07 average time 0.01826087403999054 iter num 100\n",
            "loss 2.4735172865919987e-07 average time 0.01831203079999341 iter num 50\n",
            "loss 1.4446225363116896e-07 average time 0.01833497462000878 iter num 100\n",
            "loss 1.417984422652224e-07 average time 0.018292176979989562 iter num 50\n",
            "loss 1.4101521704496915e-07 average time 0.01829813022999133 iter num 100\n",
            "loss 2.964044572383714e-07 average time 0.018276014679981925 iter num 50\n",
            "loss 1.440349998566867e-07 average time 0.01827126243998464 iter num 100\n",
            "loss 1.4138206483218603e-07 average time 0.018231805700006588 iter num 50\n",
            "loss 1.4044016827214725e-07 average time 0.0182716881599913 iter num 100\n",
            "loss 2.772933052484904e-07 average time 0.018307071119988905 iter num 50\n",
            "loss 1.4564364850639078e-07 average time 0.01831635591999202 iter num 100\n",
            "loss 1.4171318349787588e-07 average time 0.01833103918000688 iter num 50\n",
            "loss 1.410748177984416e-07 average time 0.018319848450003066 iter num 100\n",
            "loss 1.3902221022110832e-07 average time 0.01828233784000531 iter num 50\n",
            "loss 1.3856709736028092e-07 average time 0.018297871510001187 iter num 100\n",
            "loss 1.3891109698744986e-07 average time 0.018286719599996105 iter num 50\n",
            "loss 1.365380612600348e-07 average time 0.018301823530005094 iter num 100\n",
            "loss 6.071913199921835e-07 average time 0.018248129319999862 iter num 50\n",
            "loss 1.7170535043628538e-07 average time 0.018271275619997595 iter num 100\n",
            "loss 1.536296152171033e-07 average time 0.0182807659799937 iter num 50\n",
            "loss 1.518070104183536e-07 average time 0.018273890090001715 iter num 100\n",
            "loss 1.4693624844507027e-07 average time 0.0182668030600189 iter num 50\n",
            "loss 1.4606150705861363e-07 average time 0.01827111676000186 iter num 100\n",
            "loss 1.4352296949175078e-07 average time 0.018240054940001756 iter num 50\n",
            "loss 1.4259004282977513e-07 average time 0.01826537564999853 iter num 100\n",
            "loss 4.5764742245785735e-07 average time 0.018277429560021118 iter num 50\n",
            "loss 1.5731608804300485e-07 average time 0.01826623997002116 iter num 100\n",
            "loss 1.4761739153903798e-07 average time 0.018233857000013814 iter num 50\n",
            "loss 1.4655297881075826e-07 average time 0.01825984800000697 iter num 100\n",
            "loss 1.4342454467854628e-07 average time 0.01828794917999403 iter num 50\n",
            "loss 1.427894623130145e-07 average time 0.018270580939993123 iter num 100\n",
            "loss 1.4053650243343182e-07 average time 0.018328286360001583 iter num 50\n",
            "loss 1.400316297969679e-07 average time 0.018293218010007876 iter num 100\n",
            "loss 1.3818402802242608e-07 average time 0.01830990913998903 iter num 50\n",
            "loss 1.377352487107656e-07 average time 0.018298322649984586 iter num 100\n",
            "loss 2.4591206806797656e-07 average time 0.018278978619987354 iter num 50\n",
            "loss 1.4722099379360141e-07 average time 0.01826826105999089 iter num 100\n",
            "loss 1.41054661542626e-07 average time 0.01826683333999881 iter num 50\n",
            "loss 1.402578710014646e-07 average time 0.018246614869985932 iter num 100\n",
            "loss 1.379257561885611e-07 average time 0.01828382949998286 iter num 50\n",
            "loss 1.3742844906821e-07 average time 0.01827572766999083 iter num 100\n",
            "loss 1.4301228122996597e-07 average time 0.01824145538000266 iter num 50\n",
            "loss 1.3551629926878283e-07 average time 0.018248163800001292 iter num 100\n",
            "loss 1.771043038618154e-07 average time 0.018294560960002856 iter num 50\n",
            "loss 1.51657480208545e-07 average time 0.018280523870005255 iter num 100\n",
            "loss 1.4291314773612508e-07 average time 0.01829284057998848 iter num 50\n",
            "loss 1.4189181879269143e-07 average time 0.018306530919994658 iter num 100\n",
            "loss 1.389246916137669e-07 average time 0.018278171140000268 iter num 50\n",
            "loss 1.3833682259815213e-07 average time 0.01829412898998726 iter num 100\n",
            "loss 1.365801596438348e-07 average time 0.018288449759988907 iter num 50\n",
            "loss 1.35868615680044e-07 average time 0.018291622059991824 iter num 100\n",
            "loss 3.983062781679011e-07 average time 0.018294652460008366 iter num 50\n",
            "loss 1.6314882402824333e-07 average time 0.01828189326999791 iter num 100\n",
            "loss 1.4850613490250021e-07 average time 0.01828277478002292 iter num 50\n",
            "loss 1.4696735437045085e-07 average time 0.01826993585001219 iter num 100\n",
            "loss 1.4292866824202726e-07 average time 0.0182576144199993 iter num 50\n",
            "loss 1.4216560174827437e-07 average time 0.018270396990005794 iter num 100\n",
            "loss 1.395579308486482e-07 average time 0.01831097500001306 iter num 50\n",
            "loss 1.389924755592111e-07 average time 0.018306688000011492 iter num 100\n",
            "loss 1.3824702174668988e-07 average time 0.018324779820009098 iter num 50\n",
            "loss 1.365652018752181e-07 average time 0.018313244949990804 iter num 100\n",
            "loss 4.6705819934747963e-07 average time 0.018307733620004 iter num 50\n",
            "loss 1.5965400462625812e-07 average time 0.01828877940000666 iter num 100\n",
            "loss 1.467626168181091e-07 average time 0.01826274507997823 iter num 50\n",
            "loss 1.4539329151812458e-07 average time 0.018268289869970433 iter num 100\n",
            "loss 1.4162782888309655e-07 average time 0.018315556060015295 iter num 50\n",
            "loss 1.4089600948801345e-07 average time 0.018295122010017623 iter num 100\n",
            "loss 1.3835723709003072e-07 average time 0.018330973019997147 iter num 50\n",
            "loss 1.37798890038003e-07 average time 0.018325283239998953 iter num 100\n",
            "loss 1.357687725531574e-07 average time 0.018281165700000202 iter num 50\n",
            "loss 1.35291564684117e-07 average time 0.018280030710011486 iter num 100\n",
            "loss 3.2734061594946827e-07 average time 0.01827603000001545 iter num 50\n",
            "loss 1.3972528706911572e-07 average time 0.0182858546000125 iter num 100\n",
            "loss 1.365630685448865e-07 average time 0.018279954880013063 iter num 50\n",
            "loss 1.3514964082756065e-07 average time 0.01827240123000138 iter num 100\n",
            "loss 1.6660896684424217e-07 average time 0.018261915660013985 iter num 50\n",
            "loss 1.37825773967654e-07 average time 0.018267714300009175 iter num 100\n",
            "loss 1.3449680574374675e-07 average time 0.018258217760012484 iter num 50\n",
            "loss 1.3393955492286002e-07 average time 0.018241237540009933 iter num 100\n",
            "loss 1.521512117698218e-07 average time 0.01826614833999429 iter num 50\n",
            "loss 1.3280871967249116e-07 average time 0.018263123140000063 iter num 100\n",
            "loss 1.3161782646294725e-07 average time 0.018270785759978026 iter num 50\n",
            "loss 1.306856445706139e-07 average time 0.018271965139981604 iter num 100\n",
            "loss 1.548967046415714e-07 average time 0.018314205259985103 iter num 50\n",
            "loss 1.320870199970411e-07 average time 0.018282565779998095 iter num 100\n",
            "loss 1.451274570065562e-07 average time 0.018264006020003762 iter num 50\n",
            "loss 1.3036701460117509e-07 average time 0.018273138520005432 iter num 100\n",
            "loss 2.2889847454464458e-07 average time 0.01825512816000355 iter num 50\n",
            "loss 1.358711182446235e-07 average time 0.018278953980011465 iter num 100\n",
            "loss 1.3250191912580507e-07 average time 0.018306095120010468 iter num 50\n",
            "loss 1.3142820355507207e-07 average time 0.018316744140008723 iter num 100\n",
            "loss 2.811086466298545e-07 average time 0.018285665419994074 iter num 50\n",
            "loss 1.341896308803353e-07 average time 0.018267705920000026 iter num 100\n",
            "loss 1.3077043763534332e-07 average time 0.018271306780006852 iter num 50\n",
            "loss 1.302533526829646e-07 average time 0.01826726769000743 iter num 100\n",
            "loss 1.428557607511258e-07 average time 0.018258295340001496 iter num 50\n",
            "loss 1.2927221189439484e-07 average time 0.018275635569991663 iter num 100\n",
            "loss 1.6275020666184577e-07 average time 0.01829871488000208 iter num 50\n",
            "loss 1.3297249547172755e-07 average time 0.01827969276001113 iter num 100\n",
            "loss 1.2971917463375685e-07 average time 0.018275685900021016 iter num 50\n",
            "loss 1.2914815649041828e-07 average time 0.018284962950010596 iter num 100\n",
            "loss 1.7825398872939049e-07 average time 0.018277329999978064 iter num 50\n",
            "loss 1.2905975853660142e-07 average time 0.018281603419989096 iter num 100\n",
            "loss 1.4458040078840576e-07 average time 0.018295422220016917 iter num 50\n",
            "loss 1.2934237277323697e-07 average time 0.01827642830000741 iter num 100\n",
            "loss 1.3678274087251273e-07 average time 0.018283029540002646 iter num 50\n",
            "loss 1.2831299115990432e-07 average time 0.018307917529994028 iter num 100\n",
            "loss 1.3279255171687638e-07 average time 0.018280552440014617 iter num 50\n",
            "loss 1.2681376880178619e-07 average time 0.018274209690014233 iter num 100\n",
            "loss 1.487977486206899e-07 average time 0.01829779814001995 iter num 50\n",
            "loss 1.268775086193198e-07 average time 0.01828447015001302 iter num 100\n",
            "loss 1.5884967652521034e-07 average time 0.01826725032001377 iter num 50\n",
            "loss 1.2764825957554345e-07 average time 0.018277341979999164 iter num 100\n",
            "loss 1.579322801952479e-07 average time 0.018328212579999673 iter num 50\n",
            "loss 1.272922403380859e-07 average time 0.018311493550004342 iter num 100\n",
            "loss 1.2971439339138673e-07 average time 0.01823982273998354 iter num 50\n",
            "loss 1.2528825898478e-07 average time 0.018257691240000894 iter num 100\n",
            "loss 1.8840075229233298e-07 average time 0.018263084539989906 iter num 50\n",
            "loss 1.279577764534152e-07 average time 0.018247183650000807 iter num 100\n",
            "loss 1.5813078674972294e-07 average time 0.018269683200001056 iter num 50\n",
            "loss 1.2811667262270825e-07 average time 0.01827717987000142 iter num 100\n",
            "loss 1.2568183004781394e-07 average time 0.01830110805998629 iter num 50\n",
            "loss 1.2511453162244204e-07 average time 0.018305517009994218 iter num 100\n",
            "loss 1.2417328602132537e-07 average time 0.018301985520001837 iter num 50\n",
            "loss 1.2311244086759815e-07 average time 0.018273382460004085 iter num 100\n",
            "loss 2.4827722250584244e-07 average time 0.018259559800026182 iter num 50\n",
            "loss 1.3700698253539692e-07 average time 0.01824539387001778 iter num 100\n",
            "loss 1.2937901458709276e-07 average time 0.018230106639980478 iter num 50\n",
            "loss 1.2853518984228753e-07 average time 0.01823419720999027 iter num 100\n",
            "loss 1.2607564965121017e-07 average time 0.018279042340004707 iter num 50\n",
            "loss 1.2558518964681516e-07 average time 0.01827436974999955 iter num 100\n",
            "loss 1.273685582409539e-07 average time 0.018272886940003445 iter num 50\n",
            "loss 1.235878567321202e-07 average time 0.0183042653599955 iter num 100\n",
            "loss 3.269240031108037e-07 average time 0.01827326496002115 iter num 50\n",
            "loss 1.4247743210472222e-07 average time 0.0182696723600111 iter num 100\n",
            "loss 1.3209997501880436e-07 average time 0.018253735939988473 iter num 50\n",
            "loss 1.310371977707896e-07 average time 0.018262046179993375 iter num 100\n",
            "loss 1.4312686585542699e-07 average time 0.01823753327999384 iter num 50\n",
            "loss 1.2793571103098804e-07 average time 0.0182540828399965 iter num 100\n",
            "loss 1.3608015421113425e-07 average time 0.01827038462000928 iter num 50\n",
            "loss 1.283663320182219e-07 average time 0.018263698470004783 iter num 100\n",
            "loss 1.258079783780572e-07 average time 0.01829888819999269 iter num 50\n",
            "loss 1.253080636844808e-07 average time 0.018283868629998777 iter num 100\n",
            "loss 1.24092797571248e-07 average time 0.018260618039994368 iter num 50\n",
            "loss 1.231699601269306e-07 average time 0.018264429270000163 iter num 100\n",
            "loss 3.1798408579482966e-07 average time 0.018255164400006834 iter num 50\n",
            "loss 1.3369487721351605e-07 average time 0.018253687310004808 iter num 100\n",
            "loss 1.2767305118147052e-07 average time 0.018295547379998424 iter num 50\n",
            "loss 1.2691945794097678e-07 average time 0.018291747219986974 iter num 100\n",
            "loss 1.2455786311427912e-07 average time 0.018302793039997597 iter num 50\n",
            "loss 1.2406062668935507e-07 average time 0.018298178169986842 iter num 100\n",
            "loss 1.6992801812966708e-07 average time 0.018280780379991483 iter num 50\n",
            "loss 1.2381573437381546e-07 average time 0.01826901257000145 iter num 100\n",
            "loss 1.221467491714971e-07 average time 0.01830279554000299 iter num 50\n",
            "loss 1.2144456517241474e-07 average time 0.018284796879997886 iter num 100\n",
            "loss 1.4846605510865886e-07 average time 0.018311488780000218 iter num 50\n",
            "loss 1.2232447131944732e-07 average time 0.01828755329000387 iter num 100\n",
            "loss 1.2381579738159335e-07 average time 0.018314285040005415 iter num 50\n",
            "loss 1.2098062172783717e-07 average time 0.018347168279999552 iter num 100\n",
            "loss 1.321006820972565e-07 average time 0.018314850819979255 iter num 50\n",
            "loss 1.2037616876451703e-07 average time 0.0183231968999894 iter num 100\n",
            "loss 2.19168869269105e-07 average time 0.01831165136000891 iter num 50\n",
            "loss 1.2398198694782072e-07 average time 0.01830426767000972 iter num 100\n",
            "loss 1.2406733624538438e-07 average time 0.018287762299996756 iter num 50\n",
            "loss 1.2084318617149022e-07 average time 0.01829835177000177 iter num 100\n",
            "loss 1.550055075972314e-07 average time 0.018266137719988366 iter num 50\n",
            "loss 1.2518265067105748e-07 average time 0.018261100300003365 iter num 100\n",
            "loss 1.21657815573333e-07 average time 0.01829161834000388 iter num 50\n",
            "loss 1.2106277893498262e-07 average time 0.018296651770006066 iter num 100\n",
            "loss 1.2675710648771306e-07 average time 0.01826444021998668 iter num 50\n",
            "loss 1.1910295624891858e-07 average time 0.01829585927000153 iter num 100\n",
            "loss 2.129137332815949e-07 average time 0.018328373839981395 iter num 50\n",
            "loss 1.2774037128824118e-07 average time 0.01833295517999204 iter num 100\n",
            "loss 1.2249159348999137e-07 average time 0.01832065845998841 iter num 50\n",
            "loss 1.2178397763521658e-07 average time 0.018301256279989957 iter num 100\n",
            "loss 1.4097829668649145e-07 average time 0.018277249840002695 iter num 50\n",
            "loss 1.204373243447856e-07 average time 0.01827788536001208 iter num 100\n",
            "loss 1.2757946641390752e-07 average time 0.01824675270001535 iter num 50\n",
            "loss 1.1906638585094342e-07 average time 0.01825410327000782 iter num 100\n",
            "loss 1.7593470814056056e-07 average time 0.01830501309999363 iter num 50\n",
            "loss 1.2122838304579957e-07 average time 0.018283410480005386 iter num 100\n",
            "loss 1.1962129149943821e-07 average time 0.018268790560005074 iter num 50\n",
            "loss 1.1831556342565265e-07 average time 0.018260950110006887 iter num 100\n",
            "loss 1.388135616002949e-07 average time 0.018305295519999164 iter num 50\n",
            "loss 1.1695704577340815e-07 average time 0.018280603319990405 iter num 100\n",
            "loss 2.98550645442764e-07 average time 0.018291180240003087 iter num 50\n",
            "loss 1.3888933287206744e-07 average time 0.018276981570002137 iter num 100\n",
            "loss 1.274143305048069e-07 average time 0.01827665488000548 iter num 50\n",
            "loss 1.261101917932364e-07 average time 0.01829163686999891 iter num 100\n",
            "loss 1.2253460148913033e-07 average time 0.01830601918000866 iter num 50\n",
            "loss 1.2186674838915838e-07 average time 0.01829628189001369 iter num 100\n",
            "loss 1.2069271966173805e-07 average time 0.01829239909998705 iter num 50\n",
            "loss 1.1916701702340918e-07 average time 0.018285561669990784 iter num 100\n",
            "loss 2.2052734136143787e-07 average time 0.018265401340008793 iter num 50\n",
            "loss 1.3473873082757427e-07 average time 0.018283378110013473 iter num 100\n",
            "loss 1.2559905318339073e-07 average time 0.018304930320000495 iter num 50\n",
            "loss 1.2463150813639545e-07 average time 0.01831076935000283 iter num 100\n",
            "loss 1.2181441155785719e-07 average time 0.018292312680005127 iter num 50\n",
            "loss 1.2125006574861084e-07 average time 0.01829755157000818 iter num 100\n",
            "loss 1.1926635323326916e-07 average time 0.018264382459988154 iter num 50\n",
            "loss 1.1881932362234852e-07 average time 0.018259646519998115 iter num 100\n",
            "loss 3.154334264909845e-07 average time 0.018292174120006166 iter num 50\n",
            "loss 1.2547662499893525e-07 average time 0.01826188029999912 iter num 100\n",
            "loss 1.2070017122924994e-07 average time 0.018295397100000627 iter num 50\n",
            "loss 1.200218767126588e-07 average time 0.01829059533000418 iter num 100\n",
            "loss 1.1797894821712437e-07 average time 0.01829334188001667 iter num 50\n",
            "loss 1.175445128584511e-07 average time 0.018295152950011016 iter num 100\n",
            "loss 1.1596395213656235e-07 average time 0.01827592629999799 iter num 50\n",
            "loss 1.1560086677811638e-07 average time 0.018292500849981935 iter num 100\n",
            "loss 1.700539611572059e-07 average time 0.018261462100003883 iter num 50\n",
            "loss 1.1695165296204993e-07 average time 0.018266918640006225 iter num 100\n",
            "loss 1.2604634514359577e-07 average time 0.018261138420011775 iter num 50\n",
            "loss 1.1629725423970843e-07 average time 0.018285621030006496 iter num 100\n",
            "loss 1.1716669868342312e-07 average time 0.018268579099999443 iter num 50\n",
            "loss 1.1454729654711809e-07 average time 0.018276546200004306 iter num 100\n",
            "loss 1.2572387769961234e-07 average time 0.01827561225999034 iter num 50\n",
            "loss 1.1553003489634769e-07 average time 0.018266252099999748 iter num 100\n",
            "loss 1.2299859575455105e-07 average time 0.01830961089999164 iter num 50\n",
            "loss 1.1362780166639234e-07 average time 0.018290507859990156 iter num 100\n",
            "loss 1.6135902106439968e-07 average time 0.018269144060013787 iter num 50\n",
            "loss 1.1448871476840778e-07 average time 0.01825707875000944 iter num 100\n",
            "loss 1.2017788698733566e-07 average time 0.018324446259994145 iter num 50\n",
            "loss 1.1262805724244672e-07 average time 0.018305800409993935 iter num 100\n",
            "loss 2.4183737875044024e-07 average time 0.018285141859996655 iter num 50\n",
            "loss 1.208495805196649e-07 average time 0.0182739854700003 iter num 100\n",
            "loss 1.1648461409530967e-07 average time 0.01828036205999524 iter num 50\n",
            "loss 1.15332029511798e-07 average time 0.018290333999993892 iter num 100\n",
            "loss 1.66073489759736e-07 average time 0.01834269540000605 iter num 50\n",
            "loss 1.1593838983117151e-07 average time 0.018326292440001453 iter num 100\n",
            "loss 1.1367248888738418e-07 average time 0.018310084240015387 iter num 50\n",
            "loss 1.1325701582767792e-07 average time 0.0182917185500105 iter num 100\n",
            "loss 1.1918392853341038e-07 average time 0.018250532560000466 iter num 50\n",
            "loss 1.1175323418580557e-07 average time 0.018260797719988203 iter num 100\n",
            "loss 1.9407121855355937e-07 average time 0.01827213235995714 iter num 50\n",
            "loss 1.1927583161391186e-07 average time 0.0182833015999654 iter num 100\n",
            "loss 1.1483416865147856e-07 average time 0.018258315519988175 iter num 50\n",
            "loss 1.1426776076999177e-07 average time 0.018293050559991572 iter num 100\n",
            "loss 1.1257439906582435e-07 average time 0.018307916480007406 iter num 50\n",
            "loss 1.120633670411534e-07 average time 0.018294327210010123 iter num 100\n",
            "loss 2.6809520432831054e-07 average time 0.018254726099994515 iter num 50\n",
            "loss 1.277932044092175e-07 average time 0.018278226069996892 iter num 100\n",
            "loss 1.1856787772361077e-07 average time 0.018267007820004438 iter num 50\n",
            "loss 1.175671997477843e-07 average time 0.01825682540001253 iter num 100\n",
            "loss 1.147524132934137e-07 average time 0.01829773718000979 iter num 50\n",
            "loss 1.1421464724590949e-07 average time 0.018298713669996688 iter num 100\n",
            "loss 1.1461361182105487e-07 average time 0.0182629695399919 iter num 50\n",
            "loss 1.1209315039408458e-07 average time 0.018291935249997095 iter num 100\n",
            "loss 2.08457820148012e-07 average time 0.01826310961999752 iter num 50\n",
            "loss 1.2285910917614598e-07 average time 0.018248738149995915 iter num 100\n",
            "loss 1.1653964494080114e-07 average time 0.018227004059999673 iter num 50\n",
            "loss 1.1580167318818008e-07 average time 0.01826110335999829 iter num 100\n",
            "loss 1.1353581153205592e-07 average time 0.018282751039992037 iter num 50\n",
            "loss 1.1306880631692969e-07 average time 0.018280164079985752 iter num 100\n",
            "loss 1.1140919965118009e-07 average time 0.01825358299999152 iter num 50\n",
            "loss 1.1102677112113011e-07 average time 0.01828209513999127 iter num 100\n",
            "loss 1.8872666324638435e-07 average time 0.018332944900002986 iter num 50\n",
            "loss 1.2088185752302682e-07 average time 0.018340639099999407 iter num 100\n",
            "loss 1.146362437514542e-07 average time 0.018269905980005205 iter num 50\n",
            "loss 1.13908044771813e-07 average time 0.018277255610007613 iter num 100\n",
            "loss 1.1177048345189106e-07 average time 0.01831143577999683 iter num 50\n",
            "loss 1.1133471997756268e-07 average time 0.018295780819994435 iter num 100\n",
            "loss 1.0978536635491179e-07 average time 0.01830408014002387 iter num 50\n",
            "loss 1.0943175683635099e-07 average time 0.01830638665999686 iter num 100\n",
            "loss 2.833992664748917e-07 average time 0.01829925954002192 iter num 50\n",
            "loss 1.1612459334747653e-07 average time 0.018304169750017536 iter num 100\n",
            "loss 1.1184628179789121e-07 average time 0.018276492800009692 iter num 50\n",
            "loss 1.1125186107806996e-07 average time 0.018281595410014687 iter num 100\n",
            "loss 1.096025500647222e-07 average time 0.01827937651999491 iter num 50\n",
            "loss 1.0924561600177455e-07 average time 0.01827017415999535 iter num 100\n",
            "loss 1.8551648435586717e-07 average time 0.018280920259994674 iter num 50\n",
            "loss 1.1148589456205473e-07 average time 0.018275682560006317 iter num 100\n",
            "loss 1.0922877851810051e-07 average time 0.01822726772000806 iter num 50\n",
            "loss 1.0874454935254146e-07 average time 0.018236244030008494 iter num 100\n",
            "loss 1.0740318781595096e-07 average time 0.01826325722002821 iter num 50\n",
            "loss 1.070970029436768e-07 average time 0.01829514525001059 iter num 100\n",
            "loss 1.0744852080064558e-07 average time 0.018297299299997575 iter num 50\n",
            "loss 1.0582282296457076e-07 average time 0.018299981979985204 iter num 100\n",
            "loss 2.9467920728532037e-07 average time 0.01826137667999319 iter num 50\n",
            "loss 1.331472340074668e-07 average time 0.018281346879998637 iter num 100\n",
            "loss 1.1809494407680046e-07 average time 0.018266158599994923 iter num 50\n",
            "loss 1.168370819274438e-07 average time 0.018280727129995285 iter num 100\n",
            "loss 1.1352663532494829e-07 average time 0.018302697859971885 iter num 50\n",
            "loss 1.129156465863918e-07 average time 0.018265358159972038 iter num 100\n",
            "loss 1.5088401243212183e-07 average time 0.01827176494000014 iter num 50\n",
            "loss 1.1133006833093618e-07 average time 0.018263988350008732 iter num 100\n",
            "loss 1.1227685209425278e-07 average time 0.01826968883999143 iter num 50\n",
            "loss 1.0980712843354328e-07 average time 0.01825579459999517 iter num 100\n",
            "loss 1.188700666041351e-07 average time 0.018277270139988103 iter num 50\n",
            "loss 1.0890898218375845e-07 average time 0.01826403766999647 iter num 100\n",
            "loss 1.9755261160427996e-07 average time 0.018253820580011963 iter num 50\n",
            "loss 1.1135171405984505e-07 average time 0.018246325910020005 iter num 100\n",
            "loss 1.0854237335988168e-07 average time 0.01828565110000909 iter num 50\n",
            "loss 1.0804362388783256e-07 average time 0.018284242150002683 iter num 100\n",
            "loss 1.0876851646367088e-07 average time 0.018256146939988865 iter num 50\n",
            "loss 1.0632650612600746e-07 average time 0.018262028579993057 iter num 100\n",
            "loss 2.4091202371088917e-07 average time 0.018281491999996433 iter num 50\n",
            "loss 1.2994027084989095e-07 average time 0.0182621477100065 iter num 100\n",
            "loss 1.1697975574326332e-07 average time 0.018236822659991957 iter num 50\n",
            "loss 1.1558706146290107e-07 average time 0.018247155999988537 iter num 100\n",
            "loss 1.1201580083378685e-07 average time 0.018287328479982535 iter num 50\n",
            "loss 1.1137312764610716e-07 average time 0.01827300822999405 iter num 100\n",
            "loss 1.092557916949658e-07 average time 0.018299642460015093 iter num 50\n",
            "loss 1.0881154341979659e-07 average time 0.018286390140012827 iter num 100\n",
            "loss 1.0871361890629121e-07 average time 0.018246373099991615 iter num 50\n",
            "loss 1.0694417636832935e-07 average time 0.018271179239991397 iter num 100\n",
            "loss 2.1302689962113865e-07 average time 0.018316340000005767 iter num 50\n",
            "loss 1.1955618006289072e-07 average time 0.0182991871299987 iter num 100\n",
            "loss 1.1199959791225261e-07 average time 0.01824669754001661 iter num 50\n",
            "loss 1.1112753381336621e-07 average time 0.018260774230009248 iter num 100\n",
            "loss 1.0886500702167305e-07 average time 0.018292978120011866 iter num 50\n",
            "loss 1.0841469863633383e-07 average time 0.018301425090010072 iter num 100\n",
            "loss 1.0683409671154446e-07 average time 0.018227543799998785 iter num 50\n",
            "loss 1.0648302375102456e-07 average time 0.01824331252000093 iter num 100\n",
            "loss 1.0519717692218059e-07 average time 0.018266891939983907 iter num 50\n",
            "loss 1.048861513856683e-07 average time 0.018243371330001992 iter num 100\n",
            "loss 3.671918091839456e-07 average time 0.018322597740002493 iter num 50\n",
            "loss 1.164017044425473e-07 average time 0.018311711010005637 iter num 100\n",
            "loss 1.0948433927023263e-07 average time 0.018259565199987265 iter num 50\n",
            "loss 1.087518115013422e-07 average time 0.018260764289987037 iter num 100\n",
            "loss 1.0665033868210643e-07 average time 0.01829104163999091 iter num 50\n",
            "loss 1.0622122598312674e-07 average time 0.018292472879995785 iter num 100\n",
            "loss 1.3095975879578446e-07 average time 0.018328439280021484 iter num 50\n",
            "loss 1.0597040631377129e-07 average time 0.018306432700012466 iter num 100\n",
            "loss 1.1413603000737514e-07 average time 0.018263188059986533 iter num 50\n",
            "loss 1.0525471535204182e-07 average time 0.018275880600006077 iter num 100\n",
            "loss 1.5093489111758532e-07 average time 0.01828017981999892 iter num 50\n",
            "loss 1.0590987401844279e-07 average time 0.0183095027499985 iter num 100\n",
            "loss 1.0397428610530018e-07 average time 0.01831993826001053 iter num 50\n",
            "loss 1.0359698534344836e-07 average time 0.018306438220013207 iter num 100\n",
            "loss 1.0586273225624513e-07 average time 0.018295144979988437 iter num 50\n",
            "loss 1.0248262435059425e-07 average time 0.01827383295999198 iter num 100\n",
            "loss 1.5737954861653143e-07 average time 0.018302226140012864 iter num 50\n",
            "loss 1.0475953480840279e-07 average time 0.01830984607000346 iter num 100\n",
            "loss 1.3917127093854395e-07 average time 0.018289030219998493 iter num 50\n",
            "loss 1.0659572284933066e-07 average time 0.018311659539983795 iter num 100\n",
            "loss 1.0387666942402113e-07 average time 0.018340893559993673 iter num 50\n",
            "loss 1.0343216828373467e-07 average time 0.0183361834099901 iter num 100\n",
            "loss 1.0202694243514043e-07 average time 0.01829463085999123 iter num 50\n",
            "loss 1.0167237929679956e-07 average time 0.01828147622998813 iter num 100\n",
            "loss 1.7416336984496075e-07 average time 0.01829704027999469 iter num 50\n",
            "loss 1.05669920914448e-07 average time 0.01828649964998931 iter num 100\n",
            "loss 1.1814004789349896e-07 average time 0.018275060900000428 iter num 50\n",
            "loss 1.0330537117694662e-07 average time 0.018296841629992285 iter num 100\n",
            "loss 1.0312789230672678e-07 average time 0.018335804799999095 iter num 50\n",
            "loss 1.014684228856385e-07 average time 0.01829743707000489 iter num 100\n",
            "loss 1.7644786993372144e-07 average time 0.01834893756000838 iter num 50\n",
            "loss 1.0817839121824276e-07 average time 0.01830577076000509 iter num 100\n",
            "loss 1.260789428829258e-07 average time 0.018329919080001672 iter num 50\n",
            "loss 1.0389508517825215e-07 average time 0.018290393750007752 iter num 100\n",
            "loss 1.0425229508631677e-07 average time 0.018240725739979098 iter num 50\n",
            "loss 1.0180349481740235e-07 average time 0.018256027149996044 iter num 100\n",
            "loss 1.0996349735843464e-07 average time 0.018277408480021223 iter num 50\n",
            "loss 1.0036307839015619e-07 average time 0.018279744310004845 iter num 100\n",
            "loss 2.0704653559409983e-07 average time 0.018268254660010825 iter num 50\n",
            "loss 1.0792837898714237e-07 average time 0.018250774130001444 iter num 100\n",
            "loss 1.0363161201109835e-07 average time 0.018269151400008923 iter num 50\n",
            "loss 1.0302351177592082e-07 average time 0.018289616190004382 iter num 100\n",
            "loss 1.26442719312729e-07 average time 0.018290597320014968 iter num 50\n",
            "loss 1.0164112926468617e-07 average time 0.0182831441000053 iter num 100\n",
            "loss 1.0456550117165864e-07 average time 0.018316503240002932 iter num 50\n",
            "loss 1.0094018178541262e-07 average time 0.018310200790003818 iter num 100\n",
            "loss 1.112986567099994e-07 average time 0.01827984510002352 iter num 50\n",
            "loss 1.0396433959884166e-07 average time 0.018285956770005215 iter num 100\n",
            "loss 1.0133871419593721e-07 average time 0.018334408840000833 iter num 50\n",
            "loss 1.0079234216162022e-07 average time 0.018319651719996274 iter num 100\n",
            "loss 1.2428522729690488e-07 average time 0.018301841859997694 iter num 50\n",
            "loss 1.008084857079871e-07 average time 0.01830717318000552 iter num 100\n",
            "loss 1.0878405192307053e-07 average time 0.018311407740002325 iter num 50\n",
            "loss 1.0015340085904772e-07 average time 0.018288141520004048 iter num 100\n",
            "loss 1.0228576378326419e-07 average time 0.018284811019980224 iter num 50\n",
            "loss 9.884147036643031e-08 average time 0.018274119359991802 iter num 100\n",
            "loss 1.564188728750986e-07 average time 0.018302230200010854 iter num 50\n",
            "loss 1.0230601932204238e-07 average time 0.01829511929999626 iter num 100\n",
            "loss 9.970503583847336e-08 average time 0.01827010319997953 iter num 50\n",
            "loss 9.914647975046855e-08 average time 0.0182924082599925 iter num 100\n",
            "loss 1.255737488133071e-07 average time 0.018304041860001233 iter num 50\n",
            "loss 9.874675736426757e-08 average time 0.01830539653000187 iter num 100\n",
            "loss 1.7433139202419004e-07 average time 0.01827683258000434 iter num 50\n",
            "loss 1.0354310333244036e-07 average time 0.018286007630006224 iter num 100\n",
            "loss 1.0062734356017681e-07 average time 0.0182576723800139 iter num 50\n",
            "loss 9.961624460498539e-08 average time 0.018277651910009355 iter num 100\n",
            "loss 1.2122214377970364e-07 average time 0.018267156380002234 iter num 50\n",
            "loss 9.975786186797429e-08 average time 0.018272932479999327 iter num 100\n",
            "loss 1.172898161723183e-07 average time 0.01825670788000025 iter num 50\n",
            "loss 9.843066496293125e-08 average time 0.01826827524000464 iter num 100\n",
            "loss 1.2856348165040966e-07 average time 0.018274685639999007 iter num 50\n",
            "loss 1.0035133315058606e-07 average time 0.01827220526000474 iter num 100\n",
            "loss 9.85115412877246e-08 average time 0.018274620199999845 iter num 50\n",
            "loss 9.787715639330652e-08 average time 0.018271037440003964 iter num 100\n",
            "loss 1.3985337635779624e-07 average time 0.0182676715199932 iter num 50\n",
            "loss 9.805647606694302e-08 average time 0.018282228039995515 iter num 100\n",
            "loss 1.1702347272941089e-07 average time 0.018293266900018354 iter num 50\n",
            "loss 9.788742200364389e-08 average time 0.018273341240005722 iter num 100\n",
            "loss 1.0875600448335633e-07 average time 0.018256765240007553 iter num 50\n",
            "loss 9.70481039652891e-08 average time 0.018258783179999228 iter num 100\n",
            "loss 1.0899944881890748e-07 average time 0.01828968672000883 iter num 50\n",
            "loss 9.64724794149661e-08 average time 0.018301448520007854 iter num 100\n",
            "loss 1.216405618646767e-07 average time 0.018268355540017184 iter num 50\n",
            "loss 9.621108442743993e-08 average time 0.018277819970005566 iter num 100\n",
            "loss 1.6582168975572435e-07 average time 0.018281422600025507 iter num 50\n",
            "loss 1.0289852872431167e-07 average time 0.018285662210012106 iter num 100\n",
            "loss 9.81399651626931e-08 average time 0.018277604720001363 iter num 50\n",
            "loss 9.763923284559229e-08 average time 0.01827228752999872 iter num 100\n",
            "loss 9.609208188246988e-08 average time 0.018270767419985533 iter num 50\n",
            "loss 9.576966336049688e-08 average time 0.018263059799999155 iter num 100\n",
            "loss 3.5011368039051576e-07 average time 0.01824699048000639 iter num 50\n",
            "loss 1.0496370001728102e-07 average time 0.01826978318001238 iter num 100\n",
            "loss 9.900231951671362e-08 average time 0.01830485349999435 iter num 50\n",
            "loss 9.834678553227459e-08 average time 0.01829751553998676 iter num 100\n",
            "loss 9.657630505993275e-08 average time 0.01827562748000673 iter num 50\n",
            "loss 9.622069922287101e-08 average time 0.018265000090004833 iter num 100\n",
            "loss 1.9716825972505607e-07 average time 0.018268215080011033 iter num 50\n",
            "loss 9.865222213879759e-08 average time 0.018269433050013505 iter num 100\n",
            "loss 9.63677656893011e-08 average time 0.018260551100001975 iter num 50\n",
            "loss 9.582448072838901e-08 average time 0.018265058340014094 iter num 100\n",
            "loss 1.2170840538124332e-07 average time 0.018324861239998425 iter num 50\n",
            "loss 9.510400466642982e-08 average time 0.018327108750002027 iter num 100\n",
            "loss 1.5677154113831886e-07 average time 0.01821564584000498 iter num 50\n",
            "loss 9.948210787768038e-08 average time 0.018260205710005264 iter num 100\n",
            "loss 9.646948580152216e-08 average time 0.018271772100001728 iter num 50\n",
            "loss 9.601334797355179e-08 average time 0.018257876089996898 iter num 100\n",
            "loss 9.60409618141493e-08 average time 0.018280266500014478 iter num 50\n",
            "loss 9.436731771478695e-08 average time 0.01827544047999936 iter num 100\n",
            "loss 1.4302652171639168e-07 average time 0.018285505400008333 iter num 50\n",
            "loss 1.0582810632768908e-07 average time 0.01828353354999308 iter num 100\n",
            "loss 9.904224025946209e-08 average time 0.01832127550000223 iter num 50\n",
            "loss 9.826971108169634e-08 average time 0.018287434880003273 iter num 100\n",
            "loss 9.610098847305414e-08 average time 0.018223085180011367 iter num 50\n",
            "loss 9.568297117019952e-08 average time 0.01822899294000081 iter num 100\n",
            "loss 1.0033148742697186e-07 average time 0.018260345240009884 iter num 50\n",
            "loss 9.642810194398945e-08 average time 0.01824391231000618 iter num 100\n",
            "loss 9.44781446567515e-08 average time 0.01832518873997742 iter num 50\n",
            "loss 9.414759795430265e-08 average time 0.018309796289979658 iter num 100\n",
            "loss 9.3067820851641e-08 average time 0.018267249820009965 iter num 50\n",
            "loss 9.280964094087593e-08 average time 0.018254085739995388 iter num 100\n",
            "loss 1.391406992805254e-07 average time 0.018248183039981995 iter num 50\n",
            "loss 9.869472907414752e-08 average time 0.018280287809993752 iter num 100\n",
            "loss 9.485213744037894e-08 average time 0.01826857186000325 iter num 50\n",
            "loss 9.43991814533064e-08 average time 0.018239421800003583 iter num 100\n",
            "loss 9.307651263974785e-08 average time 0.01827670479999597 iter num 50\n",
            "loss 9.272529204894823e-08 average time 0.018273558959990624 iter num 100\n",
            "loss 2.6114454537675257e-07 average time 0.01828957731999253 iter num 50\n",
            "loss 1.0055120234409899e-07 average time 0.018289352000006146 iter num 100\n",
            "loss 1.0432199799720157e-07 average time 0.018249077080008648 iter num 50\n",
            "loss 9.613658599843703e-08 average time 0.018242614330004018 iter num 100\n",
            "loss 9.447214202063993e-08 average time 0.018261085839999396 iter num 50\n",
            "loss 9.398574827556376e-08 average time 0.018276672699992103 iter num 100\n",
            "loss 9.485334047135957e-08 average time 0.018237670279991108 iter num 50\n",
            "loss 9.258974815387159e-08 average time 0.018258026799992423 iter num 100\n",
            "loss 2.9446455128139053e-07 average time 0.018237093339998865 iter num 50\n",
            "loss 1.0681519558100932e-07 average time 0.018250983090003958 iter num 100\n",
            "loss 9.838499405898384e-08 average time 0.018287643599992406 iter num 50\n",
            "loss 9.757315261852572e-08 average time 0.018314054379995923 iter num 100\n",
            "loss 9.554933838455101e-08 average time 0.01827246284000921 iter num 50\n",
            "loss 9.488370960678838e-08 average time 0.01825490897000236 iter num 100\n",
            "loss 1.67266966657444e-07 average time 0.018309547819999352 iter num 50\n",
            "loss 1.0281298037192607e-07 average time 0.018309230210015813 iter num 100\n",
            "loss 9.747481696339833e-08 average time 0.018293785400014712 iter num 50\n",
            "loss 9.684015721694838e-08 average time 0.018293341190001228 iter num 100\n",
            "loss 9.500083124515181e-08 average time 0.01828393233999577 iter num 50\n",
            "loss 9.462450287036548e-08 average time 0.018284174799996434 iter num 100\n",
            "loss 9.329113886441137e-08 average time 0.018273779739997734 iter num 50\n",
            "loss 9.299237452067038e-08 average time 0.018258933619997607 iter num 100\n",
            "loss 9.548231844922421e-08 average time 0.01824158797999189 iter num 50\n",
            "loss 9.185247617830549e-08 average time 0.01824978752998959 iter num 100\n",
            "loss 1.6558866641584063e-07 average time 0.018257346659997894 iter num 50\n",
            "loss 9.935988593417391e-08 average time 0.01826203975000226 iter num 100\n",
            "loss 9.508839344443973e-08 average time 0.01827753018002113 iter num 50\n",
            "loss 9.456305999538288e-08 average time 0.018292271260002053 iter num 100\n",
            "loss 9.295696409237834e-08 average time 0.018305360079998535 iter num 50\n",
            "loss 9.262367685350602e-08 average time 0.018302184079982454 iter num 100\n",
            "loss 9.150633224325373e-08 average time 0.01828681948000849 iter num 50\n",
            "loss 9.116298061157041e-08 average time 0.018267811270011407 iter num 100\n",
            "loss 2.2890876227927588e-07 average time 0.01824497422002878 iter num 50\n",
            "loss 9.87546093483275e-08 average time 0.018249210200010565 iter num 100\n",
            "loss 9.521381641348684e-08 average time 0.01829195953996532 iter num 50\n",
            "loss 9.361279266848844e-08 average time 0.018268251869981215 iter num 100\n",
            "loss 1.2088210187365583e-07 average time 0.01822674911998547 iter num 50\n",
            "loss 9.534620418364485e-08 average time 0.01826090065998642 iter num 100\n",
            "loss 9.277389172975567e-08 average time 0.018354830820003373 iter num 50\n",
            "loss 9.236325199760891e-08 average time 0.018317470010001672 iter num 100\n",
            "loss 9.10565017889362e-08 average time 0.01829184474000158 iter num 50\n",
            "loss 9.075704441476675e-08 average time 0.01828885023000794 iter num 100\n",
            "loss 1.0134787835063618e-07 average time 0.018267162919978545 iter num 50\n",
            "loss 8.996820538304921e-08 average time 0.018287628449988914 iter num 100\n",
            "loss 1.7342073195940524e-07 average time 0.018299718280013623 iter num 50\n",
            "loss 9.652757958530068e-08 average time 0.018295032100004393 iter num 100\n",
            "loss 9.415249760312172e-08 average time 0.01831675034 iter num 50\n",
            "loss 9.228521703396037e-08 average time 0.018299308650000512 iter num 100\n",
            "loss 1.0407046038637798e-07 average time 0.01828269507997902 iter num 50\n",
            "loss 9.22140455203378e-08 average time 0.0182994382999982 iter num 100\n",
            "loss 9.062741820977185e-08 average time 0.018300005119990602 iter num 50\n",
            "loss 9.032028279666861e-08 average time 0.018284650199987026 iter num 100\n",
            "loss 8.924078711107672e-08 average time 0.018299138700035654 iter num 50\n",
            "loss 8.898961884812838e-08 average time 0.01831141119001586 iter num 100\n",
            "loss 1.4548821838294847e-07 average time 0.018289921000000504 iter num 50\n",
            "loss 9.064584948573172e-08 average time 0.01828352723999842 iter num 100\n",
            "loss 2.129890822071433e-07 average time 0.01829724200000783 iter num 50\n",
            "loss 9.662504573039202e-08 average time 0.018278493360007815 iter num 100\n",
            "loss 9.212478612858891e-08 average time 0.018323397839976677 iter num 50\n",
            "loss 9.157249173169051e-08 average time 0.01831560371997739 iter num 100\n",
            "loss 8.998606120308934e-08 average time 0.01828814263998993 iter num 50\n",
            "loss 8.966540749783993e-08 average time 0.01829276920998609 iter num 100\n",
            "loss 8.854559381732243e-08 average time 0.018287811999998668 iter num 50\n",
            "loss 8.827109178251974e-08 average time 0.0182975033700086 iter num 100\n",
            "loss 2.3113870145851044e-07 average time 0.01834143699998549 iter num 50\n",
            "loss 9.312209687253917e-08 average time 0.018334144360003392 iter num 100\n",
            "loss 9.021770768192282e-08 average time 0.018277029039991247 iter num 50\n",
            "loss 8.976193882242248e-08 average time 0.018289509629994427 iter num 100\n",
            "loss 8.851521431778218e-08 average time 0.01824722719999045 iter num 50\n",
            "loss 8.824122550813939e-08 average time 0.0182350451100001 iter num 100\n",
            "loss 1.5949014346294514e-07 average time 0.01829706071997862 iter num 50\n",
            "loss 9.06879286459573e-08 average time 0.01828535341997849 iter num 100\n",
            "loss 1.1326283684864036e-07 average time 0.018360866240000176 iter num 50\n",
            "loss 8.943574625025349e-08 average time 0.018306820539985436 iter num 100\n",
            "loss 8.819116737915755e-08 average time 0.0183307125599913 iter num 50\n",
            "loss 8.76773694529686e-08 average time 0.018294797599990035 iter num 100\n",
            "loss 1.4947493742691513e-07 average time 0.018288288180001472 iter num 50\n",
            "loss 9.381053508244168e-08 average time 0.01829167860000325 iter num 100\n",
            "loss 9.002861861062405e-08 average time 0.01830511250001564 iter num 50\n",
            "loss 8.951006687968796e-08 average time 0.01829241595000667 iter num 100\n",
            "loss 9.396371052523756e-08 average time 0.018264562740005204 iter num 50\n",
            "loss 8.794862843572358e-08 average time 0.018286361920006586 iter num 100\n",
            "loss 1.705361998442224e-07 average time 0.018334016040003006 iter num 50\n",
            "loss 9.904392648531668e-08 average time 0.018333401529998808 iter num 100\n",
            "loss 9.212599386435602e-08 average time 0.01829996888000551 iter num 50\n",
            "loss 9.132102822108229e-08 average time 0.018292053960005886 iter num 100\n",
            "loss 9.580691198609764e-08 average time 0.0182954691599889 iter num 50\n",
            "loss 8.898125626459958e-08 average time 0.01828812113998765 iter num 100\n",
            "loss 1.8424055866227105e-07 average time 0.018268776539998727 iter num 50\n",
            "loss 9.357904181854536e-08 average time 0.018274445020008443 iter num 100\n",
            "loss 9.017534066106685e-08 average time 0.01822826292001082 iter num 50\n",
            "loss 8.968776519706449e-08 average time 0.01824482858001829 iter num 100\n",
            "loss 8.827045149009982e-08 average time 0.018233384880013546 iter num 50\n",
            "loss 8.797183624071446e-08 average time 0.018245206240007975 iter num 100\n",
            "loss 8.689402040031553e-08 average time 0.018288329039983182 iter num 50\n",
            "loss 8.664800389662233e-08 average time 0.018282100749984237 iter num 100\n",
            "loss 2.306719563776083e-07 average time 0.01820993452001403 iter num 50\n",
            "loss 9.08257859191383e-08 average time 0.01821635371002458 iter num 100\n",
            "loss 8.796780827527273e-08 average time 0.01827267629999824 iter num 50\n",
            "loss 8.757627013496077e-08 average time 0.018278173740004604 iter num 100\n",
            "loss 8.63988188821659e-08 average time 0.018259985440013223 iter num 50\n",
            "loss 8.614136662639505e-08 average time 0.018270136660007666 iter num 100\n",
            "loss 1.2176318166119243e-07 average time 0.01831219262000559 iter num 50\n",
            "loss 8.629563958466795e-08 average time 0.018293325039996942 iter num 100\n",
            "loss 8.612331491988765e-08 average time 0.018253137820011034 iter num 50\n",
            "loss 8.525696964146358e-08 average time 0.018266669380002442 iter num 100\n",
            "loss 1.1512964329407814e-07 average time 0.018281175939991953 iter num 50\n",
            "loss 8.566283299753243e-08 average time 0.018277679649993387 iter num 100\n",
            "loss 1.4051080648710233e-07 average time 0.018274416120011665 iter num 50\n",
            "loss 8.824650905474898e-08 average time 0.018273316920012803 iter num 100\n",
            "loss 8.614889856759601e-08 average time 0.018281611819998034 iter num 50\n",
            "loss 8.567709831260069e-08 average time 0.018275866930005123 iter num 100\n",
            "loss 9.994860227357296e-08 average time 0.018304385080023168 iter num 50\n",
            "loss 8.604249595009779e-08 average time 0.018301401360010915 iter num 100\n",
            "loss 9.781538873271494e-08 average time 0.01825830672000393 iter num 50\n",
            "loss 8.693820284400024e-08 average time 0.01828156836999824 iter num 100\n",
            "loss 8.589623077204163e-08 average time 0.018342964980010947 iter num 50\n",
            "loss 8.503684532363532e-08 average time 0.01831343914000172 iter num 100\n",
            "loss 1.1886338115672652e-07 average time 0.018311416379992805 iter num 50\n",
            "loss 8.648217286585061e-08 average time 0.01828712593999171 iter num 100\n",
            "loss 8.73628967697241e-08 average time 0.018260930219998955 iter num 50\n",
            "loss 8.451940993426823e-08 average time 0.01827678762000687 iter num 100\n",
            "loss 1.1614674843351959e-07 average time 0.018272192060017005 iter num 50\n",
            "loss 8.900317668794091e-08 average time 0.018247501790017395 iter num 100\n",
            "loss 8.5660245272255e-08 average time 0.01829640376000498 iter num 50\n",
            "loss 8.521435074422247e-08 average time 0.018288947890011967 iter num 100\n",
            "loss 9.256487280049812e-08 average time 0.018273520259976975 iter num 50\n",
            "loss 8.452558112621907e-08 average time 0.01827453362999222 iter num 100\n",
            "loss 1.0931610442160566e-07 average time 0.018212171360023604 iter num 50\n",
            "loss 8.435423627511058e-08 average time 0.018223862380025366 iter num 100\n",
            "loss 9.04327799750381e-08 average time 0.018233400120016084 iter num 50\n",
            "loss 8.36867211987352e-08 average time 0.018261950640003306 iter num 100\n",
            "loss 1.3383495465019996e-07 average time 0.018276208220008812 iter num 50\n",
            "loss 8.409315921236533e-08 average time 0.01828418533000331 iter num 100\n",
            "loss 1.1638268063757023e-07 average time 0.018296220419997553 iter num 50\n",
            "loss 8.489547282984543e-08 average time 0.018293787150000754 iter num 100\n",
            "loss 8.348918778300427e-08 average time 0.018284568280009808 iter num 50\n",
            "loss 8.311224391913334e-08 average time 0.018308538440005576 iter num 100\n",
            "loss 1.6520724818915575e-07 average time 0.018281643599975722 iter num 50\n",
            "loss 8.616372887350799e-08 average time 0.01827468715998293 iter num 100\n",
            "loss 8.441664781868013e-08 average time 0.018247976979996566 iter num 50\n",
            "loss 8.380039037242142e-08 average time 0.01824983345999044 iter num 100\n",
            "loss 1.1984498778706897e-07 average time 0.018286173020001115 iter num 50\n",
            "loss 8.429672897969937e-08 average time 0.01828939923000462 iter num 100\n",
            "loss 8.28533304534333e-08 average time 0.018265508579984272 iter num 50\n",
            "loss 8.255511602734414e-08 average time 0.018253299639989107 iter num 100\n",
            "loss 1.789054585999867e-07 average time 0.01827100192000671 iter num 50\n",
            "loss 8.598952998183095e-08 average time 0.01827168512000526 iter num 100\n",
            "loss 1.0266530097737017e-07 average time 0.01827897846000724 iter num 50\n",
            "loss 8.40012155209428e-08 average time 0.01826087715000085 iter num 100\n",
            "loss 8.374066738284554e-08 average time 0.018309535280013733 iter num 50\n",
            "loss 8.242244578650836e-08 average time 0.018290989650001848 iter num 100\n",
            "loss 1.6146379382475861e-07 average time 0.018257883199994468 iter num 50\n",
            "loss 8.547636373268906e-08 average time 0.018261072889999924 iter num 100\n",
            "loss 8.328957102034028e-08 average time 0.018275749039999026 iter num 50\n",
            "loss 8.294411231832241e-08 average time 0.018279371520002315 iter num 100\n",
            "loss 8.18743682220679e-08 average time 0.018302274980010226 iter num 50\n",
            "loss 8.163922498665217e-08 average time 0.018291923480012427 iter num 100\n",
            "loss 1.0400876948638147e-07 average time 0.018290968980022627 iter num 50\n",
            "loss 8.106930180855142e-08 average time 0.01828119412000433 iter num 100\n",
            "loss 3.5646901449159594e-07 average time 0.01824873741998999 iter num 50\n",
            "loss 9.651729438635081e-08 average time 0.018279686339990348 iter num 100\n",
            "loss 8.836012290804716e-08 average time 0.0183304754800065 iter num 50\n",
            "loss 8.758910536470507e-08 average time 0.01831080164000241 iter num 100\n",
            "loss 8.543493470330024e-08 average time 0.018267569239992554 iter num 50\n",
            "loss 8.502920431525322e-08 average time 0.018275006519997986 iter num 100\n",
            "loss 8.365347955085871e-08 average time 0.018277619320001576 iter num 50\n",
            "loss 8.335772848537094e-08 average time 0.018274856929995167 iter num 100\n",
            "loss 8.293979467750851e-08 average time 0.01833121704001769 iter num 50\n",
            "loss 8.208954301976731e-08 average time 0.018293121270003213 iter num 100\n",
            "loss 1.642731246150543e-07 average time 0.018260163219993047 iter num 50\n",
            "loss 9.178892793168225e-08 average time 0.01827477134000219 iter num 100\n",
            "loss 8.633209424997965e-08 average time 0.018269643120011097 iter num 50\n",
            "loss 8.576676568806045e-08 average time 0.018266601520001587 iter num 100\n",
            "loss 8.414315870003097e-08 average time 0.018294274760000916 iter num 50\n",
            "loss 8.381846814487311e-08 average time 0.018303961400015396 iter num 100\n",
            "loss 8.266982401744746e-08 average time 0.01830541875999188 iter num 50\n",
            "loss 8.241261384391881e-08 average time 0.018266046409985394 iter num 100\n",
            "loss 9.716974021310715e-08 average time 0.018222642360010467 iter num 50\n",
            "loss 8.155374948069637e-08 average time 0.01825644812001201 iter num 100\n",
            "loss 2.2628152181213672e-07 average time 0.018299288519974654 iter num 50\n",
            "loss 9.560111104259274e-08 average time 0.018273335539979597 iter num 100\n",
            "loss 8.752657169186798e-08 average time 0.018247241999988548 iter num 50\n",
            "loss 8.666681572836691e-08 average time 0.018287870210010625 iter num 100\n",
            "loss 8.449473187816603e-08 average time 0.018241600860028483 iter num 50\n",
            "loss 8.410016160947108e-08 average time 0.018240246070017747 iter num 100\n",
            "loss 8.277931028091468e-08 average time 0.01824990152000737 iter num 50\n",
            "loss 8.249694819426602e-08 average time 0.018232199419994686 iter num 100\n",
            "loss 9.747513126759935e-08 average time 0.018315138879993354 iter num 50\n",
            "loss 8.291076905401921e-08 average time 0.018308080029999018 iter num 100\n",
            "loss 8.155468583055e-08 average time 0.018279262840005684 iter num 50\n",
            "loss 8.128662119032672e-08 average time 0.01826213883000264 iter num 100\n",
            "loss 8.054338273168146e-08 average time 0.018268704920001256 iter num 50\n",
            "loss 8.021866319328125e-08 average time 0.018272190679999765 iter num 100\n",
            "loss 2.0734339089901093e-07 average time 0.018267273939991356 iter num 50\n",
            "loss 8.445506912080337e-08 average time 0.01826535010998896 iter num 100\n",
            "loss 8.161150039016835e-08 average time 0.01830822229999285 iter num 50\n",
            "loss 8.128742363490133e-08 average time 0.01830256046000386 iter num 100\n",
            "loss 9.358456500652338e-08 average time 0.018229916080003933 iter num 50\n",
            "loss 8.066943398099118e-08 average time 0.018251785370009658 iter num 100\n",
            "loss 1.3137075229135217e-07 average time 0.018239793160009867 iter num 50\n",
            "loss 8.243910652688617e-08 average time 0.01825379867000038 iter num 100\n",
            "loss 8.065023986685868e-08 average time 0.018253951960009545 iter num 50\n",
            "loss 8.03534084447117e-08 average time 0.018268461860004664 iter num 100\n",
            "loss 1.6483762678281626e-07 average time 0.018250513540010616 iter num 50\n",
            "loss 8.45628340310229e-08 average time 0.018250130769999942 iter num 100\n",
            "loss 8.173142820572322e-08 average time 0.0183290952599873 iter num 50\n",
            "loss 8.135106887482371e-08 average time 0.01827046682000173 iter num 100\n",
            "loss 8.020099300020176e-08 average time 0.018273383300006572 iter num 50\n",
            "loss 7.995191179191207e-08 average time 0.01826538287000858 iter num 100\n",
            "loss 1.0702695898590975e-07 average time 0.018231186700022592 iter num 50\n",
            "loss 7.959470590095743e-08 average time 0.01824598114001901 iter num 100\n",
            "loss 1.8795572209142735e-07 average time 0.018302939160007553 iter num 50\n",
            "loss 8.508678444474355e-08 average time 0.01829115044001128 iter num 100\n",
            "loss 8.166871224586336e-08 average time 0.018231764319998546 iter num 50\n",
            "loss 8.125469421830598e-08 average time 0.018249798209999425 iter num 100\n",
            "loss 8.00172721409069e-08 average time 0.018266252199991867 iter num 50\n",
            "loss 7.97542801125102e-08 average time 0.018269504910008436 iter num 100\n",
            "loss 1.1916321064306229e-07 average time 0.0182382367199898 iter num 50\n",
            "loss 7.998980780240218e-08 average time 0.01824650265000628 iter num 100\n",
            "loss 9.268855080847734e-08 average time 0.018262496940001257 iter num 50\n",
            "loss 7.97111595037423e-08 average time 0.018268669900000988 iter num 100\n",
            "loss 7.980027234610472e-08 average time 0.018346592560005773 iter num 50\n",
            "loss 7.860187708581416e-08 average time 0.018300751360006872 iter num 100\n",
            "loss 1.4729985032991262e-07 average time 0.018278116659985244 iter num 50\n",
            "loss 8.28695852400282e-08 average time 0.0183057498499943 iter num 100\n",
            "loss 8.021574840052738e-08 average time 0.0182669357199984 iter num 50\n",
            "loss 7.98111271676767e-08 average time 0.018266495470006704 iter num 100\n",
            "loss 8.093719170558412e-08 average time 0.01824056186000689 iter num 50\n",
            "loss 7.856375921063857e-08 average time 0.01825448541001151 iter num 100\n",
            "loss 1.74313262504804e-07 average time 0.01826303137997911 iter num 50\n",
            "loss 8.652030641259439e-08 average time 0.01825568274999796 iter num 100\n",
            "loss 8.17205036493657e-08 average time 0.018248153239983366 iter num 50\n",
            "loss 8.120738685096681e-08 average time 0.018242693549991598 iter num 100\n",
            "loss 7.974811079147164e-08 average time 0.018279017459994974 iter num 50\n",
            "loss 7.94528387392412e-08 average time 0.018259101250005186 iter num 100\n",
            "loss 7.8530147689864e-08 average time 0.018242760460016143 iter num 50\n",
            "loss 7.826277191853582e-08 average time 0.018247841840013733 iter num 100\n",
            "loss 2.783066186463803e-07 average time 0.01831285745999594 iter num 50\n",
            "loss 8.849606451827235e-08 average time 0.018297278679995088 iter num 100\n",
            "loss 8.170956124551113e-08 average time 0.0183138142000098 iter num 50\n",
            "loss 8.09774215197334e-08 average time 0.018312627850011722 iter num 100\n",
            "loss 1.4215822584447297e-07 average time 0.018303489839991017 iter num 50\n",
            "loss 8.110638272750055e-08 average time 0.01828652484000031 iter num 100\n",
            "loss 7.935672788621941e-08 average time 0.018271731419999923 iter num 50\n",
            "loss 7.904514437755564e-08 average time 0.018256091790008214 iter num 100\n",
            "loss 7.805424875428462e-08 average time 0.018249263900002005 iter num 50\n",
            "loss 7.783586407232626e-08 average time 0.018266440039994905 iter num 100\n",
            "loss 7.714537594519443e-08 average time 0.01825259634000304 iter num 50\n",
            "loss 7.686523771107551e-08 average time 0.018247333320000506 iter num 100\n",
            "loss 1.9876758964802403e-07 average time 0.018260322439978154 iter num 50\n",
            "loss 8.168886995486237e-08 average time 0.01826049264998801 iter num 100\n",
            "loss 7.887136722437298e-08 average time 0.01824979596002322 iter num 50\n",
            "loss 7.850599630255904e-08 average time 0.01824248143002478 iter num 100\n",
            "loss 7.744297827102581e-08 average time 0.0182182745199907 iter num 50\n",
            "loss 7.719830907218368e-08 average time 0.01822074963998375 iter num 100\n",
            "loss 2.637626521976227e-07 average time 0.018309988519990838 iter num 50\n",
            "loss 8.334555567448099e-08 average time 0.018290845999990778 iter num 100\n",
            "loss 7.966136662575523e-08 average time 0.018289617739997086 iter num 50\n",
            "loss 7.891504973721286e-08 average time 0.018275833139987298 iter num 100\n",
            "loss 8.538883476088651e-08 average time 0.018248092520011597 iter num 50\n",
            "loss 7.894490239503778e-08 average time 0.01825583941001469 iter num 100\n",
            "loss 7.759595626875575e-08 average time 0.01829119098002593 iter num 50\n",
            "loss 7.734403280117054e-08 average time 0.01828642554001135 iter num 100\n",
            "loss 1.1428820798029555e-07 average time 0.018331643059987072 iter num 50\n",
            "loss 7.860143290085896e-08 average time 0.01832095219998564 iter num 100\n",
            "loss 7.807661599739937e-08 average time 0.018249055500004944 iter num 50\n",
            "loss 7.681764122621575e-08 average time 0.018259916140000314 iter num 100\n",
            "loss 1.0868997623520969e-07 average time 0.01826428632000898 iter num 50\n",
            "loss 7.779091807903825e-08 average time 0.01823040829001002 iter num 100\n",
            "loss 7.686629154192103e-08 average time 0.018234313380007736 iter num 50\n",
            "loss 7.629809814152656e-08 average time 0.018254369350004254 iter num 100\n",
            "loss 1.8266373569162725e-07 average time 0.018306900639995547 iter num 50\n",
            "loss 8.07018331730847e-08 average time 0.018288471089997527 iter num 100\n",
            "loss 7.79449251882821e-08 average time 0.018250646140022583 iter num 50\n",
            "loss 7.714502393213649e-08 average time 0.018233062910016997 iter num 100\n",
            "loss 1.1865948576475934e-07 average time 0.018289783619989067 iter num 50\n",
            "loss 7.776615572046554e-08 average time 0.018301211509997303 iter num 100\n",
            "loss 7.642694105251012e-08 average time 0.018264805719991273 iter num 50\n",
            "loss 7.609759622172166e-08 average time 0.018270335219990556 iter num 100\n",
            "loss 8.504968217891151e-08 average time 0.01827584619999925 iter num 50\n",
            "loss 7.656252173931426e-08 average time 0.018272437189984884 iter num 100\n",
            "loss 7.631591714775613e-08 average time 0.018287928720010314 iter num 50\n",
            "loss 7.52835761888656e-08 average time 0.018267698600006953 iter num 100\n",
            "loss 1.04110409026091e-07 average time 0.01823856282001543 iter num 50\n",
            "loss 7.661862904461207e-08 average time 0.018266363020009068 iter num 100\n",
            "loss 7.92536878952152e-08 average time 0.018231356279993633 iter num 50\n",
            "loss 7.63567715671773e-08 average time 0.018251784939989194 iter num 100\n",
            "loss 7.711573395620422e-08 average time 0.01825095870001405 iter num 50\n",
            "loss 7.525368311098565e-08 average time 0.018259070190008515 iter num 100\n",
            "loss 8.129530005633508e-08 average time 0.01824969222000618 iter num 50\n",
            "loss 7.5169021409263e-08 average time 0.018243658000008055 iter num 100\n",
            "loss 8.55983753865218e-08 average time 0.018241858000010325 iter num 50\n",
            "loss 7.501834032280747e-08 average time 0.01823835531999521 iter num 100\n",
            "loss 2.173533931076307e-07 average time 0.018310991779999314 iter num 50\n",
            "loss 8.046520469196605e-08 average time 0.018304309430002375 iter num 100\n",
            "loss 7.745604448446e-08 average time 0.018263797920021717 iter num 50\n",
            "loss 7.662435849795307e-08 average time 0.018266704290008418 iter num 100\n",
            "loss 9.690772265429545e-08 average time 0.018252353500006393 iter num 50\n",
            "loss 7.779054642456274e-08 average time 0.018254362610002774 iter num 100\n",
            "loss 7.575613163722199e-08 average time 0.018319015920001222 iter num 50\n",
            "loss 7.542391965379785e-08 average time 0.018300758110001425 iter num 100\n",
            "loss 7.801746506032284e-08 average time 0.018240036819984196 iter num 50\n",
            "loss 7.46546092589352e-08 average time 0.018255430869985503 iter num 100\n",
            "loss 8.918230444848357e-08 average time 0.018268685860016377 iter num 50\n",
            "loss 7.604352099178656e-08 average time 0.01824385232999248 iter num 100\n",
            "loss 8.916506719683386e-08 average time 0.018265113299994484 iter num 50\n",
            "loss 7.589134678365001e-08 average time 0.01827343418000055 iter num 100\n",
            "loss 8.020493905313055e-08 average time 0.018312820880005347 iter num 50\n",
            "loss 7.477241217126222e-08 average time 0.018309369440000865 iter num 100\n",
            "loss 1.0600686512053942e-07 average time 0.018239013320003324 iter num 50\n",
            "loss 7.560286282277095e-08 average time 0.018267411370004538 iter num 100\n",
            "loss 7.445414616086671e-08 average time 0.01826362016000985 iter num 50\n",
            "loss 7.394924615766232e-08 average time 0.01826045938000334 iter num 100\n",
            "loss 9.324239368562636e-08 average time 0.018292868859998635 iter num 50\n",
            "loss 7.409082971839465e-08 average time 0.018302809489989615 iter num 100\n",
            "loss 1.1120579352978993e-07 average time 0.018290329940004995 iter num 50\n",
            "loss 7.581226293133619e-08 average time 0.018286319690005257 iter num 100\n",
            "loss 7.679762777368632e-08 average time 0.01829071182000007 iter num 50\n",
            "loss 7.383769134057696e-08 average time 0.01828084094999667 iter num 100\n",
            "loss 1.1471517696152632e-07 average time 0.018258034160016905 iter num 50\n",
            "loss 7.462633402614059e-08 average time 0.018275739260004684 iter num 100\n",
            "loss 7.521909272097186e-08 average time 0.01829824503999589 iter num 50\n",
            "loss 7.317976513041765e-08 average time 0.018289002339988657 iter num 100\n",
            "loss 1.997913941890025e-07 average time 0.018265950279997015 iter num 50\n",
            "loss 8.25057774706525e-08 average time 0.01826673019000509 iter num 100\n",
            "loss 7.704836876971448e-08 average time 0.018267218299997695 iter num 50\n",
            "loss 7.651135829696818e-08 average time 0.018269962530000614 iter num 100\n",
            "loss 7.506455230328632e-08 average time 0.018217473479990077 iter num 50\n",
            "loss 7.477964436080972e-08 average time 0.018231734540004253 iter num 100\n",
            "loss 7.533660662553397e-08 average time 0.018262148520002484 iter num 50\n",
            "loss 7.358810827705875e-08 average time 0.018287318829998185 iter num 100\n",
            "loss 2.8854104710030427e-07 average time 0.018280852519978907 iter num 50\n",
            "loss 8.567503034042205e-08 average time 0.018291753089986287 iter num 100\n",
            "loss 7.83288429070763e-08 average time 0.018282964660038488 iter num 50\n",
            "loss 7.766396462769885e-08 average time 0.018268900370012487 iter num 100\n",
            "loss 7.584786674203495e-08 average time 0.01825665780005693 iter num 50\n",
            "loss 7.55105498904134e-08 average time 0.018284092530029737 iter num 100\n",
            "loss 7.437870266086086e-08 average time 0.018299747840001147 iter num 50\n",
            "loss 7.413718733472737e-08 average time 0.01828458488999331 iter num 100\n",
            "loss 7.520805491196029e-08 average time 0.018259391019964825 iter num 50\n",
            "loss 7.313324225294387e-08 average time 0.018233641889969475 iter num 100\n",
            "loss 1.2513168025749057e-07 average time 0.01828345552000428 iter num 50\n",
            "loss 8.501202431641706e-08 average time 0.0182913794499882 iter num 100\n",
            "loss 7.789432584972552e-08 average time 0.018258330099979504 iter num 50\n",
            "loss 7.727895272806399e-08 average time 0.018235209020017466 iter num 100\n",
            "loss 7.559138780640515e-08 average time 0.018226612179996663 iter num 50\n",
            "loss 7.52729762859731e-08 average time 0.018236120069991556 iter num 100\n",
            "loss 7.418900755372644e-08 average time 0.018301840840031218 iter num 50\n",
            "loss 7.395372332528382e-08 average time 0.018284546370000498 iter num 100\n",
            "loss 7.581439205021962e-08 average time 0.01824493431996416 iter num 50\n",
            "loss 7.305462553063483e-08 average time 0.01824740834995737 iter num 100\n",
            "loss 1.5799771388152109e-07 average time 0.01825100955996277 iter num 50\n",
            "loss 7.864732854410747e-08 average time 0.018275611869971727 iter num 100\n",
            "loss 7.548079572515775e-08 average time 0.018231706779970408 iter num 50\n",
            "loss 7.510572858995329e-08 average time 0.018248739629980262 iter num 100\n",
            "loss 7.396001225337204e-08 average time 0.018253628219990787 iter num 50\n",
            "loss 7.371737244280274e-08 average time 0.01827265759999591 iter num 100\n",
            "loss 8.982540162103784e-08 average time 0.018243447519944313 iter num 50\n",
            "loss 7.310680603964888e-08 average time 0.018255888999979108 iter num 100\n",
            "loss 1.1835703082733921e-07 average time 0.018311675200020545 iter num 50\n",
            "loss 8.112452940274312e-08 average time 0.01830855361001795 iter num 100\n",
            "loss 7.586481839006296e-08 average time 0.01824116935998063 iter num 50\n",
            "loss 7.534004433138553e-08 average time 0.01827833311998802 iter num 100\n",
            "loss 8.300242238391236e-08 average time 0.01833203193998088 iter num 50\n",
            "loss 7.401340807879517e-08 average time 0.018302051260029657 iter num 100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOxUYnbSVTnl"
      },
      "source": [
        "**Save Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mq_GDLdvU9ib"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNEAqIJAVa-6"
      },
      "source": [
        "import torch\n",
        "# model_save_name = f'jax_knock_out_{str(nstock)}stocks_oldmethod_1.pth'\n",
        "path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXkmXlAVdEh"
      },
      "source": [
        "**Load Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjERL5bcVcXS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b72d18-4987-40c0-a2ad-5f462e67a2ba"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIJoo5Z7VjAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b3e440-39bc-46b4-d75c-08899f2fdc6b"
      },
      "source": [
        "import torch\n",
        "# model_save_name = f'jax_knock_out_{str(nstock)}stocks_oldmethod_1.pth'\n",
        "path = F\"/content/drive/MyDrive/Grid PTH/{model_save_name}\" \n",
        "state_dict = torch.load(path)\n",
        "print(state_dict.keys())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "odict_keys(['norm', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias', 'fc4.weight', 'fc4.bias', 'fc5.weight', 'fc5.bias', 'fc6.weight', 'fc6.bias'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSkrjknWVlL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1247d93d-97ac-4172-e723-03fa44a056d9"
      },
      "source": [
        "# need to run 'Writing cupy_dataset.py' and 'Writing model.py' above before this\n",
        "from model import Net\n",
        "model = Net(nstock = nstock).cuda()\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "print(model)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=21, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=128, bias=True)\n",
            "  (fc3): Linear(in_features=128, out_features=256, bias=True)\n",
            "  (fc4): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (fc5): Linear(in_features=128, out_features=64, bias=True)\n",
            "  (fc6): Linear(in_features=64, out_features=4, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5MbsAwEVmff"
      },
      "source": [
        "**Continue to train model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "moxMKMLEhJR7"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aQYxo1IXVl57"
      },
      "source": [
        "# from ignite.engine import Engine, Events\n",
        "# from ignite.handlers import Timer\n",
        "# from torch.nn import MSELoss\n",
        "# from torch.optim import Adam\n",
        "# from ignite.contrib.handlers.param_scheduler import CosineAnnealingScheduler\n",
        "# from ignite.handlers import ModelCheckpoint\n",
        "# from model import Net\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from torch import Tensor\n",
        "# from torch.autograd import grad\n",
        "# timer = Timer(average=True)\n",
        "# #model = Net(nstock = nstock).cuda()\n",
        "# loss_fn = MSELoss()\n",
        "# optimizer = Adam(model.parameters(), lr=1e-3, eps=1e-4, amsgrad=True) # try using higher epsilon and amsgrad\n",
        "# dataset = OptionDataSet(max_len = 100) # Use max_len to adjust\n",
        "\n",
        "# def train_update(engine, batch):\n",
        "#     model.train()\n",
        "#     optimizer.zero_grad()\n",
        "#     x = batch[0]\n",
        "#     y = batch[1]\n",
        "#     y_pred = model(x.float())\n",
        "\n",
        "#     loss_weight = torch.tensor([1] * (nstock+1)).cuda()\n",
        "#     loss_weight_normalized = loss_weight/loss_weight.sum()\n",
        "#     loss = ((y_pred - y) ** 2 * loss_weight_normalized).mean(axis=0).sum() # compute weighted MSE between the 2 arrays\n",
        "\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "#     return loss.item()\n",
        "\n",
        "# trainer = Engine(train_update)\n",
        "# log_interval = 20\n",
        "\n",
        "# scheduler = CosineAnnealingScheduler(optimizer, 'lr', 1e-4, 1e-6, len(dataset))\n",
        "# trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
        "# timer.attach(trainer,\n",
        "#              start=Events.EPOCH_STARTED,\n",
        "#              resume=Events.ITERATION_STARTED,\n",
        "#              pause=Events.ITERATION_COMPLETED,\n",
        "#              step=Events.ITERATION_COMPLETED)    \n",
        "# @trainer.on(Events.ITERATION_COMPLETED)\n",
        "# def log_training_loss(engine):\n",
        "#     iter = (engine.state.iteration - 1) % len(dataset) + 1\n",
        "#     if iter % log_interval == 0:\n",
        "#         print('loss', engine.state.output, 'average time', timer.value(), 'iter num', iter)\n",
        "        \n",
        "# trainer.run(dataset, max_epochs = 500)\n",
        "\n",
        "# model_save_name = model_save_name[:-4] + '_continue.pth'\n",
        "# path = F\"/content/drive/MyDrive/AFP/Save_Models/{model_save_name}\" \n",
        "# torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONLZ1zpgV2Zv"
      },
      "source": [
        "#Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqpasxVi0hx3"
      },
      "source": [
        "# Knock in call\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random\n",
        "from jax import jit\n",
        "import numpy as np\n",
        "from torch.utils.dlpack import from_dlpack\n",
        "\n",
        "def Brownian_motion(key, initial_stocks, numsteps, drift, cov, T):\n",
        "    stocks_init = jnp.zeros((numsteps + 1, initial_stocks.shape[0]))\n",
        "    stocks_init = jax.ops.index_update(stocks_init,   # jax.ops.index_update(x, idx, y) <-> Pure equivalent of x[idx] = y\n",
        "                            jax.ops.index[0],         # initialization of stock prices\n",
        "                            initial_stocks)\n",
        "    noise = jax.random.multivariate_normal(key,  jnp.array([0]*initial_stocks.shape[0]), cov, (numsteps+1,)) # noise must have mean 0\n",
        "    sigma = jnp.diag(cov) ** 0.5\n",
        "    dt = T / numsteps\n",
        "    def time_step(t, val):\n",
        "        dx = jnp.exp((drift - sigma ** 2. / 2.) * dt + jnp.sqrt(dt) * noise[t,:])\n",
        "        val = jax.ops.index_update(val,\n",
        "                            jax.ops.index[t],\n",
        "                            val[t-1] * dx)\n",
        "        return val\n",
        "    return jax.lax.fori_loop(1, numsteps+1, time_step, stocks_init)[1:] # jax.lax.fori_loop(lower, upper, body_fun, init_val)\n",
        "\n",
        "def optionvalueavg(key, initial_stocks, numsteps, drift, r, cov, K, B, T, numpaths): # up-and-in call\n",
        "    out = batch_simple(keys, initial_stocks, numsteps, drift, cov, T)\n",
        "    knock_in_index = jnp.argmax(jnp.mean(out, axis=2) >= B, axis=1)\n",
        "    r_mean_array = jnp.tile(jnp.cumsum(r), (numpaths, 1))[jnp.arange(numpaths), knock_in_index]/(knock_in_index+1)\n",
        "\n",
        "    return jnp.mean((1 - jnp.all(jnp.mean(out, axis=2) < B, axis=1).astype(int)) *  # knock in: 1, else: 0\n",
        "                    (jnp.mean(out, axis=2)[jnp.arange(numpaths), knock_in_index] - K) *   # (S[knock-in]-K)\n",
        "                    jnp.exp(- r_mean_array * (T * (knock_in_index+1) / numsteps))) # (exp(-mean(r until payoff) * (t until payoff)))\n",
        "\n",
        "goptionvalueavg = jax.grad(optionvalueavg, argnums=1)\n",
        "\n",
        "#################################################################### Adjust all parameters here (not inside class)\n",
        "numstocks = 3\n",
        "numsteps = 50\n",
        "numpaths = 2000000\n",
        "\n",
        "rng = jax.random.PRNGKey(np.random.randint(10000))\n",
        "rng, key = jax.random.split(rng)\n",
        "keys = jax.random.split(key, numpaths)\n",
        "\n",
        "K = 1.0\n",
        "T = 1.0\n",
        "r = 0.02\n",
        "sigma = 0.25\n",
        "B = 1.15\n",
        "initial_stocks = jnp.array([1.]*numstocks) # must be float\n",
        "r_tmp = jnp.array([r]*numsteps)\n",
        "drift = jnp.array([r]*numstocks)\n",
        "cov = jnp.identity(numstocks)*sigma*sigma\n",
        "\n",
        "fast_simple = jax.jit(Brownian_motion, static_argnums=2)\n",
        "\n",
        "keys = jax.random.split(key, numpaths)\n",
        "batch_simple = jax.vmap(fast_simple, in_axes=(0, None, None, None, None, None))\n",
        "\n",
        "# option price\n",
        "# print(optionvalueavg(key, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T, numpaths)) # here numsteps different from T\n",
        "\n",
        "# delta\n",
        "goptionvalueavg = jax.grad(optionvalueavg,argnums=1)\n",
        "# print(goptionvalueavg(keys, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T, numpaths)) # here numsteps different from T"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "pZCvr0rpboE3",
        "outputId": "cb43e90f-6483-4042-e183-3b04dadecf85"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "B = 1.15\n",
        "s1 = 1.\n",
        "s3 = 1.15\n",
        "\n",
        "def compute_price(S):\n",
        "    inputs = torch.tensor([[1, 1, B, s1, 0.25, 0.02, 0.02] + [1, 1, B, S, 0.25, 0.02, 0.02] + [1, 1, B, s3, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())[0][0]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_prices = []\n",
        "correct_call_prices = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([s1, p, s3]) # must be float\n",
        "    model_call_prices.append(compute_price(p).item())\n",
        "    correct_call_prices.append(optionvalueavg(key, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T, numpaths))\n",
        "\n",
        "#plt.plot(prices, model_call_prices, label = \"model_call_prices\")\n",
        "#plt.plot(prices, correct_call_prices, label = \"JAX_call_prices\")\n",
        "plt.plot(prices, np.array(model_call_prices)-np.array(correct_call_prices), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fVR9u56Uu3X"
      },
      "source": [
        "# Delta"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwApH0GT9bBK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "outputId": "02f8a5c3-a84d-4742-fca9-875d93e37e76"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "B = 1.15\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, B, s1, 0.25, 0.02, 0.02] + [1, 1, B, S, 0.25, 0.02, 0.02] + [1, 1, B, s3, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())[0][2]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([s1, p, s3]) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(key, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T, numpaths)[1])\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"JAX_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "zpumhjvIOBGX",
        "outputId": "e0e7151e-7314-4ac1-99e8-92662487c57f"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "B = 1.35\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, B, s1, 0.25, 0.02, 0.02] + [1, 1, B, S, 0.25, 0.02, 0.02] + [1, 1, B, s3, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())[0][2]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([s1, p, s3]) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(key, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T, numpaths)[1])\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"JAX_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "s3AefiqOOB0v",
        "outputId": "f417465e-d3a4-4da6-db68-84a971b78c06"
      },
      "source": [
        "##Using gradient, Change only 1 S0 at a time\n",
        "%matplotlib inline\n",
        "from torch.autograd import grad\n",
        "import pylab\n",
        "import numpy as np\n",
        "\n",
        "B = 1.55\n",
        "\n",
        "def compute_delta(S):\n",
        "    inputs = torch.tensor([[1, 1, B, s1, 0.25, 0.02, 0.02] + [1, 1, B, S, 0.25, 0.02, 0.02] + [1, 1, B, s3, 0.25, 0.02, 0.02]]).cuda()\n",
        "    return model(inputs.float())[0][2]\n",
        "\n",
        "prices = np.arange(0.75, 1.25, 0.01)\n",
        "model_call_deltas = []\n",
        "correct_call_deltas = []\n",
        "for p in prices:\n",
        "    initial_stocks = jnp.array([s1, p, s3]) # must be float\n",
        "    model_call_deltas.append(compute_delta(p).item())\n",
        "    correct_call_deltas.append(goptionvalueavg(key, initial_stocks, numsteps, drift, r_tmp, cov, K, B, T, numpaths)[1])\n",
        "plt.plot(prices, model_call_deltas, label = \"model_call_deltas\")\n",
        "plt.plot(prices, correct_call_deltas, label = \"JAX_call_deltas\")\n",
        "#plt.plot(prices, np.array(model_call_deltas)-np.array(correct_call_deltas), label = \"Differences\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udY43Wwshzl5"
      },
      "source": [
        "# Comparison on speed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xHBEX8bfLo8",
        "outputId": "1d37105b-308e-484c-ba6c-8039530c3921"
      },
      "source": [
        "%timeit goptionvalueavg(key, initial_stocks, numsteps, drift, r_tmp, cov, 0.75, B, T, numpaths)\n",
        "%timeit compute_delta(1).item()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 888 ms per loop\n",
            "The slowest run took 2008.81 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 366 µs per loop\n"
          ]
        }
      ]
    }
  ]
}